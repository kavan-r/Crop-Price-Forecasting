{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce99422-0610-45a0-9b64-be0b240f826c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0a1ec90-8ff4-4083-9010-ae522c162ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: prophet in c:\\users\\ravik\\appdata\\roaming\\python\\python313\\site-packages (1.2.1)\n",
      "Requirement already satisfied: cmdstanpy>=1.0.4 in c:\\users\\ravik\\appdata\\roaming\\python\\python313\\site-packages (from prophet) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.15.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from prophet) (2.1.3)\n",
      "Requirement already satisfied: matplotlib>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from prophet) (3.10.0)\n",
      "Requirement already satisfied: pandas>=1.0.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from prophet) (2.2.3)\n",
      "Requirement already satisfied: holidays<1,>=0.25 in c:\\users\\ravik\\appdata\\roaming\\python\\python313\\site-packages (from prophet) (0.85)\n",
      "Requirement already satisfied: tqdm>=4.36.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from prophet) (4.67.1)\n",
      "Requirement already satisfied: importlib_resources in c:\\users\\ravik\\appdata\\roaming\\python\\python313\\site-packages (from prophet) (6.5.2)\n",
      "Requirement already satisfied: python-dateutil in c:\\programdata\\anaconda3\\lib\\site-packages (from holidays<1,>=0.25->prophet) (2.9.0.post0)\n",
      "Requirement already satisfied: stanio<2.0.0,>=0.4.0 in c:\\users\\ravik\\appdata\\roaming\\python\\python313\\site-packages (from cmdstanpy>=1.0.4->prophet) (0.5.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (3.2.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=1.0.4->prophet) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=1.0.4->prophet) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil->holidays<1,>=0.25->prophet) (1.17.0)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm>=4.36.1->prophet) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10243870-d985-42ea-bdbb-1e034e4e848b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Processing: wheat_Bagalkot_daily.csv ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:27:42 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:28:14 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for wheat_Bagalkot_daily.csv:\n",
      "  MAE        : 571.57\n",
      "  RMSE       : 679.1\n",
      "  R²         : 0.1622\n",
      "  MAPE(%)    : 33.12\n",
      "  Accuracy(%) : 66.88\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: prophet_output_csv\\wheat_Bagalkot_daily_prophet_updated.csv\n",
      "========== Processing: wheat_Bangalore_daily.csv ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:28:24 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:28:34 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for wheat_Bangalore_daily.csv:\n",
      "  MAE        : 441.8\n",
      "  RMSE       : 615.5\n",
      "  R²         : 0.2799\n",
      "  MAPE(%)    : 15.43\n",
      "  Accuracy(%) : 84.57\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: prophet_output_csv\\wheat_Bangalore_daily_prophet_updated.csv\n",
      "========== Processing: wheat_Belgaum_daily.csv ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:28:48 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:29:45 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for wheat_Belgaum_daily.csv:\n",
      "  MAE        : 446.83\n",
      "  RMSE       : 630.82\n",
      "  R²         : 0.0024\n",
      "  MAPE(%)    : 21.63\n",
      "  Accuracy(%) : 78.37\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: prophet_output_csv\\wheat_Belgaum_daily_prophet_updated.csv\n",
      "========== Processing: wheat_Bellary_daily.csv ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:29:50 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:30:01 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for wheat_Bellary_daily.csv:\n",
      "  MAE        : 568.68\n",
      "  RMSE       : 870.18\n",
      "  R²         : -0.1579\n",
      "  MAPE(%)    : 45.89\n",
      "  Accuracy(%) : 54.11\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: prophet_output_csv\\wheat_Bellary_daily_prophet_updated.csv\n",
      "========== Processing: wheat_Bidar_daily.csv ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:30:05 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:30:25 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for wheat_Bidar_daily.csv:\n",
      "  MAE        : 543.14\n",
      "  RMSE       : 642.22\n",
      "  R²         : 0.0882\n",
      "  MAPE(%)    : 31.09\n",
      "  Accuracy(%) : 68.91\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: prophet_output_csv\\wheat_Bidar_daily_prophet_updated.csv\n",
      "========== Processing: wheat_Bijapur_daily.csv ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:30:28 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:30:55 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for wheat_Bijapur_daily.csv:\n",
      "  MAE        : 444.32\n",
      "  RMSE       : 649.35\n",
      "  R²         : 0.412\n",
      "  MAPE(%)    : 20.11\n",
      "  Accuracy(%) : 79.89\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: prophet_output_csv\\wheat_Bijapur_daily_prophet_updated.csv\n",
      "========== Processing: wheat_Chikmagalur_daily.csv ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:30:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:31:07 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for wheat_Chikmagalur_daily.csv:\n",
      "  MAE        : 416.7\n",
      "  RMSE       : 492.27\n",
      "  R²         : -0.9456\n",
      "  MAPE(%)    : 38.15\n",
      "  Accuracy(%) : 61.85\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: prophet_output_csv\\wheat_Chikmagalur_daily_prophet_updated.csv\n",
      "========== Processing: wheat_Chitradurga_daily.csv ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:31:11 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:31:14 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for wheat_Chitradurga_daily.csv:\n",
      "  MAE        : 327.69\n",
      "  RMSE       : 388.28\n",
      "  R²         : 0.2294\n",
      "  MAPE(%)    : 16.56\n",
      "  Accuracy(%) : 83.44\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: prophet_output_csv\\wheat_Chitradurga_daily_prophet_updated.csv\n",
      "========== Processing: wheat_Davangere_daily.csv ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:31:17 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:31:31 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for wheat_Davangere_daily.csv:\n",
      "  MAE        : 317.37\n",
      "  RMSE       : 365.82\n",
      "  R²         : 0.5018\n",
      "  MAPE(%)    : 13.45\n",
      "  Accuracy(%) : 86.55\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: prophet_output_csv\\wheat_Davangere_daily_prophet_updated.csv\n",
      "========== Processing: wheat_Dharwad_daily.csv ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:31:35 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:32:04 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for wheat_Dharwad_daily.csv:\n",
      "  MAE        : 287.78\n",
      "  RMSE       : 496.91\n",
      "  R²         : -0.3188\n",
      "  MAPE(%)    : 17.56\n",
      "  Accuracy(%) : 82.44\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: prophet_output_csv\\wheat_Dharwad_daily_prophet_updated.csv\n",
      "========== Processing: wheat_Gadag_daily.csv ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:32:08 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:32:28 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for wheat_Gadag_daily.csv:\n",
      "  MAE        : 368.29\n",
      "  RMSE       : 559.92\n",
      "  R²         : 0.4763\n",
      "  MAPE(%)    : 14.91\n",
      "  Accuracy(%) : 85.09\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: prophet_output_csv\\wheat_Gadag_daily_prophet_updated.csv\n",
      "========== Processing: wheat_Hassan_daily.csv ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:32:32 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:32:41 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for wheat_Hassan_daily.csv:\n",
      "  MAE        : 208.26\n",
      "  RMSE       : 528.84\n",
      "  R²         : 0.4096\n",
      "  MAPE(%)    : 8.96\n",
      "  Accuracy(%) : 91.04\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: prophet_output_csv\\wheat_Hassan_daily_prophet_updated.csv\n",
      "========== Processing: wheat_Haveri_daily.csv ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:32:44 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:32:58 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for wheat_Haveri_daily.csv:\n",
      "  MAE        : 339.5\n",
      "  RMSE       : 465.98\n",
      "  R²         : -3.0842\n",
      "  MAPE(%)    : 24.36\n",
      "  Accuracy(%) : 75.64\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: prophet_output_csv\\wheat_Haveri_daily_prophet_updated.csv\n",
      "========== Processing: wheat_Kalburgi_daily.csv ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:33:02 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:33:08 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for wheat_Kalburgi_daily.csv:\n",
      "  MAE        : 317.35\n",
      "  RMSE       : 378.13\n",
      "  R²         : 0.3667\n",
      "  MAPE(%)    : 16.83\n",
      "  Accuracy(%) : 83.17\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: prophet_output_csv\\wheat_Kalburgi_daily_prophet_updated.csv\n",
      "========== Processing: wheat_Kolar_daily.csv ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:33:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:33:21 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for wheat_Kolar_daily.csv:\n",
      "  MAE        : 169.0\n",
      "  RMSE       : 225.69\n",
      "  R²         : 0.8597\n",
      "  MAPE(%)    : 6.86\n",
      "  Accuracy(%) : 93.14\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: prophet_output_csv\\wheat_Kolar_daily_prophet_updated.csv\n",
      "========== Processing: wheat_Koppal_daily.csv ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:33:24 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:33:34 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for wheat_Koppal_daily.csv:\n",
      "  MAE        : 229.78\n",
      "  RMSE       : 279.09\n",
      "  R²         : 0.609\n",
      "  MAPE(%)    : 12.45\n",
      "  Accuracy(%) : 87.55\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: prophet_output_csv\\wheat_Koppal_daily_prophet_updated.csv\n",
      "========== Processing: wheat_MadikeriKodagu_daily.csv ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:33:37 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:33:39 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for wheat_MadikeriKodagu_daily.csv:\n",
      "  MAE        : 41.08\n",
      "  RMSE       : 87.64\n",
      "  R²         : 0.9998\n",
      "  MAPE(%)    : 1.14\n",
      "  Accuracy(%) : 98.86\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: prophet_output_csv\\wheat_MadikeriKodagu_daily_prophet_updated.csv\n",
      "========== Processing: wheat_Mandya_daily.csv ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:33:41 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:33:42 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for wheat_Mandya_daily.csv:\n",
      "  MAE        : 169.95\n",
      "  RMSE       : 256.2\n",
      "  R²         : -0.3266\n",
      "  MAPE(%)    : 7.72\n",
      "  Accuracy(%) : 92.28\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: prophet_output_csv\\wheat_Mandya_daily_prophet_updated.csv\n",
      "========== Processing: wheat_Mysore_daily.csv ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:33:44 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:33:48 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for wheat_Mysore_daily.csv:\n",
      "  MAE        : 592.63\n",
      "  RMSE       : 955.33\n",
      "  R²         : -0.1149\n",
      "  MAPE(%)    : 21.74\n",
      "  Accuracy(%) : 78.26\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: prophet_output_csv\\wheat_Mysore_daily_prophet_updated.csv\n",
      "========== Processing: wheat_Raichur_daily.csv ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:33:51 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:34:02 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for wheat_Raichur_daily.csv:\n",
      "  MAE        : 106.0\n",
      "  RMSE       : 173.12\n",
      "  R²         : 0.8043\n",
      "  MAPE(%)    : 6.5\n",
      "  Accuracy(%) : 93.5\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: prophet_output_csv\\wheat_Raichur_daily_prophet_updated.csv\n",
      "========== Processing: wheat_Shimoga_daily.csv ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:34:05 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:34:11 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for wheat_Shimoga_daily.csv:\n",
      "  MAE        : 341.66\n",
      "  RMSE       : 432.38\n",
      "  R²         : 0.0053\n",
      "  MAPE(%)    : 15.06\n",
      "  Accuracy(%) : 84.94\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: prophet_output_csv\\wheat_Shimoga_daily_prophet_updated.csv\n",
      "========== Processing: wheat_Tumkur_daily.csv ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:34:14 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:34:25 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for wheat_Tumkur_daily.csv:\n",
      "  MAE        : 656.85\n",
      "  RMSE       : 854.17\n",
      "  R²         : -1.5187\n",
      "  MAPE(%)    : 32.93\n",
      "  Accuracy(%) : 67.07\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: prophet_output_csv\\wheat_Tumkur_daily_prophet_updated.csv\n",
      "✅ Multiple CSVs processed! Metrics saved to prophet_metrics.csv. Models, updated CSVs, and graphs saved in respective folders.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from prophet import Prophet\n",
    "import joblib\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "# -----------------------------\n",
    "# Suppress warnings\n",
    "# -----------------------------\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# -----------------------------\n",
    "# Paths\n",
    "# -----------------------------\n",
    "input_folder = \"dataset\"\n",
    "output_models = \"prophet_output_models\"\n",
    "output_csv = \"prophet_output_csv\"\n",
    "output_metrics_csv = \"prophet_metrics.csv\"\n",
    "output_graphs = \"prophet_output_graphs\"\n",
    "\n",
    "os.makedirs(output_models, exist_ok=True)\n",
    "os.makedirs(output_csv, exist_ok=True)\n",
    "os.makedirs(output_graphs, exist_ok=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Prepare metrics storage\n",
    "# -----------------------------\n",
    "metrics_list = []\n",
    "\n",
    "# -----------------------------\n",
    "# Function to robustly parse dates (all formats)\n",
    "# -----------------------------\n",
    "def parse_dates_safe(date_series):\n",
    "    return pd.to_datetime(date_series, errors='coerce', dayfirst=False, infer_datetime_format=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Function to calculate MAPE safely\n",
    "# -----------------------------\n",
    "def mean_absolute_percentage_error_safe(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    # Avoid division by zero\n",
    "    mask = y_true != 0\n",
    "    if mask.sum() == 0:\n",
    "        return np.nan\n",
    "    mape = np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100\n",
    "    # Handle any remaining inf or NaN\n",
    "    if np.isnan(mape) or np.isinf(mape):\n",
    "        return np.nan\n",
    "    return mape\n",
    "\n",
    "# -----------------------------\n",
    "# Process each CSV\n",
    "# -----------------------------\n",
    "for file in os.listdir(input_folder):\n",
    "    if file.endswith(\".csv\"):\n",
    "        file_path = os.path.join(input_folder, file)\n",
    "        print(f\"========== Processing: {file} ==========\")\n",
    "\n",
    "        # Load CSV\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # -----------------------------\n",
    "        # Convert 'Date' column safely\n",
    "        # -----------------------------\n",
    "        df['Date'] = parse_dates_safe(df['Date'])\n",
    "        df = df.sort_values('Date')\n",
    "\n",
    "        # Drop rows with NaT after conversion\n",
    "        df = df.dropna(subset=['Date'])\n",
    "        if df.empty:\n",
    "            print(f\"⚠️ No valid dates found in {file}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        # -----------------------------\n",
    "        # Handle missing values in Average Price\n",
    "        # -----------------------------\n",
    "        if df['Average Price'].isna().sum() > 0:\n",
    "            mean_value = df['Average Price'].mean()\n",
    "            df['Average Price'].fillna(mean_value, inplace=True)\n",
    "            print(f\"Filled {df['Average Price'].isna().sum()} missing values with mean: {mean_value:.2f}\")\n",
    "\n",
    "        # Round actual values\n",
    "        df['Average Price'] = df['Average Price'].round(2)\n",
    "\n",
    "        # -----------------------------\n",
    "        # Prepare data for Prophet\n",
    "        # -----------------------------\n",
    "        prophet_df = df[['Date', 'Average Price']].rename(columns={'Date': 'ds', 'Average Price': 'y'})\n",
    "\n",
    "        # Skip files with less than 2 valid rows (Prophet requirement)\n",
    "        if len(prophet_df) < 2:\n",
    "            print(f\"⚠️ Not enough data points in {file} for Prophet. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        # Build and fit Prophet model\n",
    "        model = Prophet(daily_seasonality=True)\n",
    "        model.fit(prophet_df)\n",
    "\n",
    "        # Predict for existing dates\n",
    "        future = model.make_future_dataframe(periods=0)\n",
    "        forecast = model.predict(future)\n",
    "        df['Predicted'] = forecast['yhat']  # keep full precision for metrics\n",
    "\n",
    "        # -----------------------------\n",
    "        # Handle NaNs in predictions for metrics\n",
    "        # -----------------------------\n",
    "        metrics_df = df.dropna(subset=['Average Price', 'Predicted'])\n",
    "        y_true = metrics_df['Average Price'].values\n",
    "        y_pred = metrics_df['Predicted'].values\n",
    "\n",
    "        # Round predictions for saving\n",
    "        df['Predicted'] = df['Predicted'].round(2)\n",
    "\n",
    "        # Rename Average Price to Actual in main df for plotting\n",
    "        df.rename(columns={'Average Price': 'Actual'}, inplace=True)\n",
    "\n",
    "        # -----------------------------\n",
    "        # Calculate metrics\n",
    "        # -----------------------------\n",
    "        mae = round(mean_absolute_error(y_true, y_pred), 2)\n",
    "        rmse = round(np.sqrt(mean_squared_error(y_true, y_pred)), 2)\n",
    "        r2 = round(r2_score(y_true, y_pred), 4)\n",
    "        mape = round(mean_absolute_percentage_error_safe(y_true, y_pred), 2)\n",
    "        accuracy = round(100 - mape if not np.isnan(mape) else np.nan, 2)\n",
    "\n",
    "        print(f\"Metrics for {file}:\")\n",
    "        print(f\"  MAE        : {mae}\")\n",
    "        print(f\"  RMSE       : {rmse}\")\n",
    "        print(f\"  R²         : {r2}\")\n",
    "        print(f\"  MAPE(%)    : {mape}\")\n",
    "        print(f\"  Accuracy(%) : {accuracy}\\n\")\n",
    "\n",
    "        # Save metrics\n",
    "        metrics_list.append({\n",
    "            'File': file,\n",
    "            'MAE': mae,\n",
    "            'RMSE': rmse,\n",
    "            'R2': r2,\n",
    "            'MAPE(%)': mape,\n",
    "            'Accuracy(%)': accuracy\n",
    "        })\n",
    "\n",
    "        # -----------------------------\n",
    "        # Save model\n",
    "        # -----------------------------\n",
    "        model_file = os.path.join(output_models, file.replace(\".csv\", \"_prophet_model.pkl\"))\n",
    "        joblib.dump(model, model_file)\n",
    "\n",
    "        # -----------------------------\n",
    "        # Save CSV with only Date, Actual, and Predicted\n",
    "        # -----------------------------\n",
    "        save_df = df[['Date', 'Actual', 'Predicted']]\n",
    "        updated_csv_path = os.path.join(output_csv, file.replace(\".csv\", \"_prophet_updated.csv\"))\n",
    "        save_df.to_csv(updated_csv_path, index=False)\n",
    "        print(f\"Saved updated CSV with Date, Actual & Predicted: {updated_csv_path}\")\n",
    "\n",
    "        # -----------------------------\n",
    "        # Add MA7 & MA30 for graphs\n",
    "        # -----------------------------\n",
    "        df['MA7'] = df['Actual'].rolling(7).mean()\n",
    "        df['MA30'] = df['Actual'].rolling(30).mean()\n",
    "\n",
    "        # -----------------------------\n",
    "        # Plot graph\n",
    "        # -----------------------------\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(df['Date'], df['Actual'], label='Actual', color='blue')\n",
    "        plt.plot(df['Date'], df['Predicted'], label='Predicted', color='red')\n",
    "        plt.plot(df['Date'], df['MA7'], label='MA7', color='green', linestyle='--')\n",
    "        plt.plot(df['Date'], df['MA30'], label='MA30', color='orange', linestyle='--')\n",
    "        plt.title(f\"{file} - Actual vs Predicted with Moving Averages\")\n",
    "        plt.xlabel(\"Date\")\n",
    "        plt.ylabel(\"Price\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        graph_path = os.path.join(output_graphs, file.replace(\".csv\", \"_prophet_graph.png\"))\n",
    "        plt.savefig(graph_path, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "# -----------------------------\n",
    "# Save all metrics to CSV\n",
    "# -----------------------------\n",
    "metrics_df = pd.DataFrame(metrics_list)\n",
    "metrics_df.to_csv(output_metrics_csv, index=False)\n",
    "print(f\"✅ Multiple CSVs processed! Metrics saved to {output_metrics_csv}. Models, updated CSVs, and graphs saved in respective folders.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41db63ab-8bff-4fb2-8bc8-2ef283178c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73faeb9d-6265-4e55-8c48-f77fcd4a2733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Processing: wheat_Bagalkot_daily.csv ==========\n",
      "Metrics for wheat_Bagalkot_daily.csv:\n",
      "  MAE        : 412.82\n",
      "  RMSE       : 580.07\n",
      "  R²         : 0.3447\n",
      "  MAPE(%)    : 20.69\n",
      "  Accuracy(%) : 79.31\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: arima_output_csv\\wheat_Bagalkot_daily_arima_updated.csv\n",
      "========== Processing: wheat_Bangalore_daily.csv ==========\n",
      "Metrics for wheat_Bangalore_daily.csv:\n",
      "  MAE        : 331.3\n",
      "  RMSE       : 450.42\n",
      "  R²         : 0.5802\n",
      "  MAPE(%)    : 14.69\n",
      "  Accuracy(%) : 85.31\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: arima_output_csv\\wheat_Bangalore_daily_arima_updated.csv\n",
      "========== Processing: wheat_Belgaum_daily.csv ==========\n",
      "Metrics for wheat_Belgaum_daily.csv:\n",
      "  MAE        : 327.88\n",
      "  RMSE       : 437.19\n",
      "  R²         : 0.4962\n",
      "  MAPE(%)    : 15.76\n",
      "  Accuracy(%) : 84.24\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: arima_output_csv\\wheat_Belgaum_daily_arima_updated.csv\n",
      "========== Processing: wheat_Bellary_daily.csv ==========\n",
      "Metrics for wheat_Bellary_daily.csv:\n",
      "  MAE        : 345.93\n",
      "  RMSE       : 454.65\n",
      "  R²         : 0.5756\n",
      "  MAPE(%)    : 22.53\n",
      "  Accuracy(%) : 77.47\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: arima_output_csv\\wheat_Bellary_daily_arima_updated.csv\n",
      "========== Processing: wheat_Bidar_daily.csv ==========\n",
      "Metrics for wheat_Bidar_daily.csv:\n",
      "  MAE        : 255.91\n",
      "  RMSE       : 338.89\n",
      "  R²         : 0.6791\n",
      "  MAPE(%)    : 13.01\n",
      "  Accuracy(%) : 86.99\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: arima_output_csv\\wheat_Bidar_daily_arima_updated.csv\n",
      "========== Processing: wheat_Bijapur_daily.csv ==========\n",
      "Metrics for wheat_Bijapur_daily.csv:\n",
      "  MAE        : 353.07\n",
      "  RMSE       : 498.0\n",
      "  R²         : 0.6305\n",
      "  MAPE(%)    : 16.69\n",
      "  Accuracy(%) : 83.31\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: arima_output_csv\\wheat_Bijapur_daily_arima_updated.csv\n",
      "========== Processing: wheat_Chikmagalur_daily.csv ==========\n",
      "Metrics for wheat_Chikmagalur_daily.csv:\n",
      "  MAE        : 390.81\n",
      "  RMSE       : 596.05\n",
      "  R²         : 0.3965\n",
      "  MAPE(%)    : 20.87\n",
      "  Accuracy(%) : 79.13\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: arima_output_csv\\wheat_Chikmagalur_daily_arima_updated.csv\n",
      "========== Processing: wheat_Chitradurga_daily.csv ==========\n",
      "Metrics for wheat_Chitradurga_daily.csv:\n",
      "  MAE        : 161.94\n",
      "  RMSE       : 271.92\n",
      "  R²         : 0.7819\n",
      "  MAPE(%)    : 7.94\n",
      "  Accuracy(%) : 92.06\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: arima_output_csv\\wheat_Chitradurga_daily_arima_updated.csv\n",
      "========== Processing: wheat_Davangere_daily.csv ==========\n",
      "Metrics for wheat_Davangere_daily.csv:\n",
      "  MAE        : 237.51\n",
      "  RMSE       : 321.16\n",
      "  R²         : 0.6295\n",
      "  MAPE(%)    : 12.08\n",
      "  Accuracy(%) : 87.92\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: arima_output_csv\\wheat_Davangere_daily_arima_updated.csv\n",
      "========== Processing: wheat_Dharwad_daily.csv ==========\n",
      "Metrics for wheat_Dharwad_daily.csv:\n",
      "  MAE        : 233.28\n",
      "  RMSE       : 337.09\n",
      "  R²         : 0.5591\n",
      "  MAPE(%)    : 12.13\n",
      "  Accuracy(%) : 87.87\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: arima_output_csv\\wheat_Dharwad_daily_arima_updated.csv\n",
      "========== Processing: wheat_Gadag_daily.csv ==========\n",
      "Metrics for wheat_Gadag_daily.csv:\n",
      "  MAE        : 271.0\n",
      "  RMSE       : 404.9\n",
      "  R²         : 0.5391\n",
      "  MAPE(%)    : 13.97\n",
      "  Accuracy(%) : 86.03\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: arima_output_csv\\wheat_Gadag_daily_arima_updated.csv\n",
      "========== Processing: wheat_Hassan_daily.csv ==========\n",
      "Metrics for wheat_Hassan_daily.csv:\n",
      "  MAE        : 169.82\n",
      "  RMSE       : 298.57\n",
      "  R²         : 0.8112\n",
      "  MAPE(%)    : 9.25\n",
      "  Accuracy(%) : 90.75\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: arima_output_csv\\wheat_Hassan_daily_arima_updated.csv\n",
      "========== Processing: wheat_Haveri_daily.csv ==========\n",
      "Metrics for wheat_Haveri_daily.csv:\n",
      "  MAE        : 196.55\n",
      "  RMSE       : 271.25\n",
      "  R²         : 0.5731\n",
      "  MAPE(%)    : 10.9\n",
      "  Accuracy(%) : 89.1\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: arima_output_csv\\wheat_Haveri_daily_arima_updated.csv\n",
      "========== Processing: wheat_Kalburgi_daily.csv ==========\n",
      "Metrics for wheat_Kalburgi_daily.csv:\n",
      "  MAE        : 286.46\n",
      "  RMSE       : 393.92\n",
      "  R²         : 0.5339\n",
      "  MAPE(%)    : 14.09\n",
      "  Accuracy(%) : 85.91\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: arima_output_csv\\wheat_Kalburgi_daily_arima_updated.csv\n",
      "========== Processing: wheat_Kolar_daily.csv ==========\n",
      "Metrics for wheat_Kolar_daily.csv:\n",
      "  MAE        : 160.15\n",
      "  RMSE       : 255.12\n",
      "  R²         : 0.7832\n",
      "  MAPE(%)    : 7.43\n",
      "  Accuracy(%) : 92.57\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: arima_output_csv\\wheat_Kolar_daily_arima_updated.csv\n",
      "========== Processing: wheat_Koppal_daily.csv ==========\n",
      "Metrics for wheat_Koppal_daily.csv:\n",
      "  MAE        : 184.45\n",
      "  RMSE       : 233.43\n",
      "  R²         : 0.7492\n",
      "  MAPE(%)    : 11.19\n",
      "  Accuracy(%) : 88.81\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: arima_output_csv\\wheat_Koppal_daily_arima_updated.csv\n",
      "========== Processing: wheat_MadikeriKodagu_daily.csv ==========\n",
      "Metrics for wheat_MadikeriKodagu_daily.csv:\n",
      "  MAE        : 15.44\n",
      "  RMSE       : 363.15\n",
      "  R²         : 0.9964\n",
      "  MAPE(%)    : 0.25\n",
      "  Accuracy(%) : 99.75\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: arima_output_csv\\wheat_MadikeriKodagu_daily_arima_updated.csv\n",
      "========== Processing: wheat_Mandya_daily.csv ==========\n",
      "Metrics for wheat_Mandya_daily.csv:\n",
      "  MAE        : 113.96\n",
      "  RMSE       : 226.3\n",
      "  R²         : 0.7081\n",
      "  MAPE(%)    : 6.37\n",
      "  Accuracy(%) : 93.63\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: arima_output_csv\\wheat_Mandya_daily_arima_updated.csv\n",
      "========== Processing: wheat_Mysore_daily.csv ==========\n",
      "Metrics for wheat_Mysore_daily.csv:\n",
      "  MAE        : 409.85\n",
      "  RMSE       : 672.07\n",
      "  R²         : 0.35\n",
      "  MAPE(%)    : 26.25\n",
      "  Accuracy(%) : 73.75\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: arima_output_csv\\wheat_Mysore_daily_arima_updated.csv\n",
      "========== Processing: wheat_Raichur_daily.csv ==========\n",
      "Metrics for wheat_Raichur_daily.csv:\n",
      "  MAE        : 143.74\n",
      "  RMSE       : 217.53\n",
      "  R²         : 0.6511\n",
      "  MAPE(%)    : 8.6\n",
      "  Accuracy(%) : 91.4\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: arima_output_csv\\wheat_Raichur_daily_arima_updated.csv\n",
      "========== Processing: wheat_Shimoga_daily.csv ==========\n",
      "Metrics for wheat_Shimoga_daily.csv:\n",
      "  MAE        : 433.23\n",
      "  RMSE       : 820.06\n",
      "  R²         : 0.2362\n",
      "  MAPE(%)    : 20.1\n",
      "  Accuracy(%) : 79.9\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: arima_output_csv\\wheat_Shimoga_daily_arima_updated.csv\n",
      "========== Processing: wheat_Tumkur_daily.csv ==========\n",
      "Metrics for wheat_Tumkur_daily.csv:\n",
      "  MAE        : 317.03\n",
      "  RMSE       : 720.92\n",
      "  R²         : 0.556\n",
      "  MAPE(%)    : 11.57\n",
      "  Accuracy(%) : 88.43\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: arima_output_csv\\wheat_Tumkur_daily_arima_updated.csv\n",
      "✅ Multiple CSVs processed! Metrics saved to arima_metrics.csv. Models, updated CSVs, and graphs saved in respective folders.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import joblib\n",
    "import warnings\n",
    "\n",
    "# -----------------------------\n",
    "# Suppress warnings\n",
    "# -----------------------------\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# -----------------------------\n",
    "# Paths\n",
    "# -----------------------------\n",
    "input_folder = \"dataset\"\n",
    "output_models = \"arima_output_models\"\n",
    "output_csv = \"arima_output_csv\"\n",
    "output_metrics_csv = \"arima_metrics.csv\"\n",
    "output_graphs = \"arima_output_graphs\"\n",
    "\n",
    "os.makedirs(output_models, exist_ok=True)\n",
    "os.makedirs(output_csv, exist_ok=True)\n",
    "os.makedirs(output_graphs, exist_ok=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Metrics storage\n",
    "# -----------------------------\n",
    "metrics_list = []\n",
    "\n",
    "# -----------------------------\n",
    "# Robust date parsing (allow all formats)\n",
    "# -----------------------------\n",
    "def parse_dates_safe(date_series):\n",
    "    return pd.to_datetime(date_series, errors='coerce', infer_datetime_format=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Safe MAPE calculation (handle NaN/Inf)\n",
    "# -----------------------------\n",
    "def mean_absolute_percentage_error_safe(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    mask = y_true != 0\n",
    "    if mask.sum() == 0:\n",
    "        return 0.0\n",
    "    mape = np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100\n",
    "    if np.isnan(mape) or np.isinf(mape):\n",
    "        return 0.0\n",
    "    return mape\n",
    "\n",
    "# -----------------------------\n",
    "# Process each CSV\n",
    "# -----------------------------\n",
    "for file in os.listdir(input_folder):\n",
    "    if file.endswith(\".csv\"):\n",
    "        file_path = os.path.join(input_folder, file)\n",
    "        print(f\"========== Processing: {file} ==========\")\n",
    "\n",
    "        # Load CSV\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # -----------------------------\n",
    "        # Convert 'Date' column safely\n",
    "        # -----------------------------\n",
    "        df['Date'] = parse_dates_safe(df['Date'])\n",
    "        df = df.sort_values('Date')\n",
    "\n",
    "        # Drop rows with invalid dates\n",
    "        df = df.dropna(subset=['Date'])\n",
    "        if df.empty:\n",
    "            print(f\"⚠️ No valid dates found in {file}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        # -----------------------------\n",
    "        # Handle missing Average Price\n",
    "        # -----------------------------\n",
    "        if df['Average Price'].isna().sum() > 0:\n",
    "            mean_value = df['Average Price'].mean()\n",
    "            df['Average Price'].fillna(mean_value, inplace=True)\n",
    "            print(f\"Filled {df['Average Price'].isna().sum()} missing values with mean: {mean_value:.2f}\")\n",
    "\n",
    "        df['Average Price'] = df['Average Price'].round(2)\n",
    "\n",
    "        # -----------------------------\n",
    "        # Fit ARIMA model\n",
    "        # -----------------------------\n",
    "        order = (5, 1, 0)\n",
    "        model = ARIMA(df['Average Price'], order=order)\n",
    "        model_fit = model.fit()\n",
    "\n",
    "        # Predict for existing dates\n",
    "        df['Predicted'] = model_fit.predict(start=0, end=len(df)-1)\n",
    "        df['Predicted'] = df['Predicted'].round(2)\n",
    "\n",
    "        # -----------------------------\n",
    "        # Rename Average Price to Actual\n",
    "        # -----------------------------\n",
    "        df.rename(columns={'Average Price': 'Actual'}, inplace=True)\n",
    "\n",
    "        # -----------------------------\n",
    "        # Calculate metrics\n",
    "        # -----------------------------\n",
    "        y_true = df['Actual'].values\n",
    "        y_pred = df['Predicted'].values\n",
    "        mae = round(mean_absolute_error(y_true, y_pred), 2)\n",
    "        rmse = round(np.sqrt(mean_squared_error(y_true, y_pred)), 2)\n",
    "        r2 = round(r2_score(y_true, y_pred), 4)\n",
    "        mape = round(mean_absolute_percentage_error_safe(y_true, y_pred), 2)\n",
    "        accuracy = round(100 - mape, 2)\n",
    "\n",
    "        print(f\"Metrics for {file}:\")\n",
    "        print(f\"  MAE        : {mae}\")\n",
    "        print(f\"  RMSE       : {rmse}\")\n",
    "        print(f\"  R²         : {r2}\")\n",
    "        print(f\"  MAPE(%)    : {mape}\")\n",
    "        print(f\"  Accuracy(%) : {accuracy}\\n\")\n",
    "\n",
    "        # Save metrics\n",
    "        metrics_list.append({\n",
    "            'File': file,\n",
    "            'MAE': mae,\n",
    "            'RMSE': rmse,\n",
    "            'R2': r2,\n",
    "            'MAPE(%)': mape,\n",
    "            'Accuracy(%)': accuracy\n",
    "        })\n",
    "\n",
    "        # -----------------------------\n",
    "        # Save model\n",
    "        # -----------------------------\n",
    "        model_file = os.path.join(output_models, file.replace(\".csv\", \"_arima_model.pkl\"))\n",
    "        joblib.dump(model_fit, model_file)\n",
    "\n",
    "        # -----------------------------\n",
    "        # Save CSV with only Date, Actual, Predicted\n",
    "        # -----------------------------\n",
    "        save_df = df[['Date', 'Actual', 'Predicted']]\n",
    "        updated_csv_path = os.path.join(output_csv, file.replace(\".csv\", \"_arima_updated.csv\"))\n",
    "        save_df.to_csv(updated_csv_path, index=False)\n",
    "        print(f\"Saved updated CSV with Date, Actual & Predicted: {updated_csv_path}\")\n",
    "\n",
    "        # -----------------------------\n",
    "        # Add MA7 & MA30 for graphs\n",
    "        # -----------------------------\n",
    "        df['MA7'] = df['Actual'].rolling(7).mean()\n",
    "        df['MA30'] = df['Actual'].rolling(30).mean()\n",
    "\n",
    "        # -----------------------------\n",
    "        # Plot graph\n",
    "        # -----------------------------\n",
    "        plt.figure(figsize=(12,6))\n",
    "        plt.plot(df['Date'], df['Actual'], label='Actual', color='blue')\n",
    "        plt.plot(df['Date'], df['Predicted'], label='Predicted', color='red')\n",
    "        plt.plot(df['Date'], df['MA7'], label='MA7', color='green', linestyle='--')\n",
    "        plt.plot(df['Date'], df['MA30'], label='MA30', color='orange', linestyle='--')\n",
    "        plt.title(f\"{file} - Actual vs Predicted with Moving Averages\")\n",
    "        plt.xlabel(\"Date\")\n",
    "        plt.ylabel(\"Price\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        graph_path = os.path.join(output_graphs, file.replace(\".csv\", \"_arima_graph.png\"))\n",
    "        plt.savefig(graph_path, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "# -----------------------------\n",
    "# Save all metrics to CSV\n",
    "# -----------------------------\n",
    "metrics_df = pd.DataFrame(metrics_list)\n",
    "metrics_df.to_csv(output_metrics_csv, index=False)\n",
    "print(f\"✅ Multiple CSVs processed! Metrics saved to {output_metrics_csv}. Models, updated CSVs, and graphs saved in respective folders.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705f7bd4-2335-4742-aff1-ef7228ce6c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SARIMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a2d3689-4b88-46a1-b542-26dbb3ed2e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Processing: wheat_Bagalkot_daily.csv ==========\n",
      "Metrics for wheat_Bagalkot_daily.csv:\n",
      "  MAE        : 385.5\n",
      "  RMSE       : 537.68\n",
      "  R²         : 0.437\n",
      "  MAPE(%)    : 19.34\n",
      "  Accuracy(%) : 80.66\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: sarimax_output_csv\\wheat_Bagalkot_daily_sarimax_updated.csv\n",
      "========== Processing: wheat_Bangalore_daily.csv ==========\n",
      "Metrics for wheat_Bangalore_daily.csv:\n",
      "  MAE        : 326.51\n",
      "  RMSE       : 443.29\n",
      "  R²         : 0.5934\n",
      "  MAPE(%)    : 14.41\n",
      "  Accuracy(%) : 85.59\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: sarimax_output_csv\\wheat_Bangalore_daily_sarimax_updated.csv\n",
      "========== Processing: wheat_Belgaum_daily.csv ==========\n",
      "Metrics for wheat_Belgaum_daily.csv:\n",
      "  MAE        : 300.78\n",
      "  RMSE       : 398.88\n",
      "  R²         : 0.5806\n",
      "  MAPE(%)    : 14.47\n",
      "  Accuracy(%) : 85.53\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: sarimax_output_csv\\wheat_Belgaum_daily_sarimax_updated.csv\n",
      "========== Processing: wheat_Bellary_daily.csv ==========\n",
      "Metrics for wheat_Bellary_daily.csv:\n",
      "  MAE        : 329.41\n",
      "  RMSE       : 430.76\n",
      "  R²         : 0.619\n",
      "  MAPE(%)    : 21.43\n",
      "  Accuracy(%) : 78.57\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: sarimax_output_csv\\wheat_Bellary_daily_sarimax_updated.csv\n",
      "========== Processing: wheat_Bidar_daily.csv ==========\n",
      "Metrics for wheat_Bidar_daily.csv:\n",
      "  MAE        : 249.4\n",
      "  RMSE       : 328.4\n",
      "  R²         : 0.6987\n",
      "  MAPE(%)    : 12.65\n",
      "  Accuracy(%) : 87.35\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: sarimax_output_csv\\wheat_Bidar_daily_sarimax_updated.csv\n",
      "========== Processing: wheat_Bijapur_daily.csv ==========\n",
      "Metrics for wheat_Bijapur_daily.csv:\n",
      "  MAE        : 352.84\n",
      "  RMSE       : 492.15\n",
      "  R²         : 0.6391\n",
      "  MAPE(%)    : 16.75\n",
      "  Accuracy(%) : 83.25\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: sarimax_output_csv\\wheat_Bijapur_daily_sarimax_updated.csv\n",
      "========== Processing: wheat_Chikmagalur_daily.csv ==========\n",
      "Metrics for wheat_Chikmagalur_daily.csv:\n",
      "  MAE        : 381.35\n",
      "  RMSE       : 563.7\n",
      "  R²         : 0.4603\n",
      "  MAPE(%)    : 21.35\n",
      "  Accuracy(%) : 78.65\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: sarimax_output_csv\\wheat_Chikmagalur_daily_sarimax_updated.csv\n",
      "========== Processing: wheat_Chitradurga_daily.csv ==========\n",
      "Metrics for wheat_Chitradurga_daily.csv:\n",
      "  MAE        : 163.39\n",
      "  RMSE       : 261.8\n",
      "  R²         : 0.7979\n",
      "  MAPE(%)    : 7.97\n",
      "  Accuracy(%) : 92.03\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: sarimax_output_csv\\wheat_Chitradurga_daily_sarimax_updated.csv\n",
      "========== Processing: wheat_Davangere_daily.csv ==========\n",
      "Metrics for wheat_Davangere_daily.csv:\n",
      "  MAE        : 238.51\n",
      "  RMSE       : 309.92\n",
      "  R²         : 0.655\n",
      "  MAPE(%)    : 12.16\n",
      "  Accuracy(%) : 87.84\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: sarimax_output_csv\\wheat_Davangere_daily_sarimax_updated.csv\n",
      "========== Processing: wheat_Dharwad_daily.csv ==========\n",
      "Metrics for wheat_Dharwad_daily.csv:\n",
      "  MAE        : 227.5\n",
      "  RMSE       : 326.86\n",
      "  R²         : 0.5854\n",
      "  MAPE(%)    : 11.81\n",
      "  Accuracy(%) : 88.19\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: sarimax_output_csv\\wheat_Dharwad_daily_sarimax_updated.csv\n",
      "========== Processing: wheat_Gadag_daily.csv ==========\n",
      "Metrics for wheat_Gadag_daily.csv:\n",
      "  MAE        : 259.68\n",
      "  RMSE       : 385.8\n",
      "  R²         : 0.5816\n",
      "  MAPE(%)    : 13.36\n",
      "  Accuracy(%) : 86.64\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: sarimax_output_csv\\wheat_Gadag_daily_sarimax_updated.csv\n",
      "========== Processing: wheat_Hassan_daily.csv ==========\n",
      "Metrics for wheat_Hassan_daily.csv:\n",
      "  MAE        : 174.35\n",
      "  RMSE       : 314.36\n",
      "  R²         : 0.7907\n",
      "  MAPE(%)    : 9.42\n",
      "  Accuracy(%) : 90.58\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: sarimax_output_csv\\wheat_Hassan_daily_sarimax_updated.csv\n",
      "========== Processing: wheat_Haveri_daily.csv ==========\n",
      "Metrics for wheat_Haveri_daily.csv:\n",
      "  MAE        : 191.3\n",
      "  RMSE       : 256.87\n",
      "  R²         : 0.6171\n",
      "  MAPE(%)    : 10.6\n",
      "  Accuracy(%) : 89.4\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: sarimax_output_csv\\wheat_Haveri_daily_sarimax_updated.csv\n",
      "========== Processing: wheat_Kalburgi_daily.csv ==========\n",
      "Metrics for wheat_Kalburgi_daily.csv:\n",
      "  MAE        : 295.99\n",
      "  RMSE       : 381.43\n",
      "  R²         : 0.563\n",
      "  MAPE(%)    : 14.44\n",
      "  Accuracy(%) : 85.56\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: sarimax_output_csv\\wheat_Kalburgi_daily_sarimax_updated.csv\n",
      "========== Processing: wheat_Kolar_daily.csv ==========\n",
      "Metrics for wheat_Kolar_daily.csv:\n",
      "  MAE        : 165.18\n",
      "  RMSE       : 248.64\n",
      "  R²         : 0.794\n",
      "  MAPE(%)    : 7.72\n",
      "  Accuracy(%) : 92.28\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: sarimax_output_csv\\wheat_Kolar_daily_sarimax_updated.csv\n",
      "========== Processing: wheat_Koppal_daily.csv ==========\n",
      "Metrics for wheat_Koppal_daily.csv:\n",
      "  MAE        : 181.05\n",
      "  RMSE       : 225.06\n",
      "  R²         : 0.7668\n",
      "  MAPE(%)    : 11.03\n",
      "  Accuracy(%) : 88.97\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: sarimax_output_csv\\wheat_Koppal_daily_sarimax_updated.csv\n",
      "========== Processing: wheat_MadikeriKodagu_daily.csv ==========\n",
      "Metrics for wheat_MadikeriKodagu_daily.csv:\n",
      "  MAE        : 22.63\n",
      "  RMSE       : 365.41\n",
      "  R²         : 0.9963\n",
      "  MAPE(%)    : 0.4\n",
      "  Accuracy(%) : 99.6\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: sarimax_output_csv\\wheat_MadikeriKodagu_daily_sarimax_updated.csv\n",
      "========== Processing: wheat_Mandya_daily.csv ==========\n",
      "Metrics for wheat_Mandya_daily.csv:\n",
      "  MAE        : 124.9\n",
      "  RMSE       : 222.46\n",
      "  R²         : 0.718\n",
      "  MAPE(%)    : 6.89\n",
      "  Accuracy(%) : 93.11\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: sarimax_output_csv\\wheat_Mandya_daily_sarimax_updated.csv\n",
      "========== Processing: wheat_Mysore_daily.csv ==========\n",
      "Metrics for wheat_Mysore_daily.csv:\n",
      "  MAE        : 390.59\n",
      "  RMSE       : 635.52\n",
      "  R²         : 0.4188\n",
      "  MAPE(%)    : 24.78\n",
      "  Accuracy(%) : 75.22\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: sarimax_output_csv\\wheat_Mysore_daily_sarimax_updated.csv\n",
      "========== Processing: wheat_Raichur_daily.csv ==========\n",
      "Metrics for wheat_Raichur_daily.csv:\n",
      "  MAE        : 146.24\n",
      "  RMSE       : 209.9\n",
      "  R²         : 0.6752\n",
      "  MAPE(%)    : 8.74\n",
      "  Accuracy(%) : 91.26\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: sarimax_output_csv\\wheat_Raichur_daily_sarimax_updated.csv\n",
      "========== Processing: wheat_Shimoga_daily.csv ==========\n",
      "Metrics for wheat_Shimoga_daily.csv:\n",
      "  MAE        : 417.46\n",
      "  RMSE       : 809.67\n",
      "  R²         : 0.2554\n",
      "  MAPE(%)    : 19.28\n",
      "  Accuracy(%) : 80.72\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: sarimax_output_csv\\wheat_Shimoga_daily_sarimax_updated.csv\n",
      "========== Processing: wheat_Tumkur_daily.csv ==========\n",
      "Metrics for wheat_Tumkur_daily.csv:\n",
      "  MAE        : 310.34\n",
      "  RMSE       : 703.91\n",
      "  R²         : 0.5767\n",
      "  MAPE(%)    : 11.29\n",
      "  Accuracy(%) : 88.71\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: sarimax_output_csv\\wheat_Tumkur_daily_sarimax_updated.csv\n",
      "✅ Multiple CSVs processed! Metrics saved to sarimax_metrics.csv. Models, updated CSVs, and graphs saved in respective folders.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import warnings\n",
    "import joblib\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")  # Ignore warnings\n",
    "\n",
    "# -----------------------------\n",
    "# Paths\n",
    "# -----------------------------\n",
    "input_folder = \"dataset\"\n",
    "output_models = \"sarimax_output_models\"\n",
    "output_csv = \"sarimax_output_csv\"\n",
    "output_graphs = \"sarimax_output_graphs\"\n",
    "output_metrics_csv = \"sarimax_metrics.csv\"\n",
    "\n",
    "os.makedirs(output_models, exist_ok=True)\n",
    "os.makedirs(output_csv, exist_ok=True)\n",
    "os.makedirs(output_graphs, exist_ok=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Metrics storage\n",
    "# -----------------------------\n",
    "metrics_list = []\n",
    "\n",
    "# -----------------------------\n",
    "# Robust date parsing (allow all formats)\n",
    "# -----------------------------\n",
    "def parse_dates_safe(date_series):\n",
    "    return pd.to_datetime(date_series, errors='coerce', infer_datetime_format=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Safe MAPE calculation (handle NaN/Inf)\n",
    "# -----------------------------\n",
    "def mean_absolute_percentage_error_safe(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    mask = y_true != 0\n",
    "    if mask.sum() == 0:\n",
    "        return 0.0\n",
    "    mape = np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100\n",
    "    if np.isnan(mape) or np.isinf(mape):\n",
    "        return 0.0\n",
    "    return mape\n",
    "\n",
    "# -----------------------------\n",
    "# Process each CSV\n",
    "# -----------------------------\n",
    "for file in os.listdir(input_folder):\n",
    "    if file.endswith(\".csv\"):\n",
    "        file_path = os.path.join(input_folder, file)\n",
    "        print(f\"========== Processing: {file} ==========\")\n",
    "\n",
    "        # Load CSV\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # -----------------------------\n",
    "        # Convert 'Date' column safely\n",
    "        # -----------------------------\n",
    "        df['Date'] = parse_dates_safe(df['Date'])\n",
    "        df = df.sort_values('Date')\n",
    "        df.set_index('Date', inplace=True)\n",
    "\n",
    "        # Drop rows with invalid dates\n",
    "        df = df.dropna(subset=['Average Price'])\n",
    "        if df.empty:\n",
    "            print(f\"⚠️ No valid data found in {file}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        # Handle missing values\n",
    "        if df['Average Price'].isna().sum() > 0:\n",
    "            mean_value = df['Average Price'].mean()\n",
    "            df['Average Price'].fillna(mean_value, inplace=True)\n",
    "            print(f\"Filled {df['Average Price'].isna().sum()} missing values with mean: {mean_value:.2f}\")\n",
    "\n",
    "        # Round actual values\n",
    "        df['Average Price'] = df['Average Price'].round(2)\n",
    "\n",
    "        # Add moving averages\n",
    "        df['MA_7'] = df['Average Price'].rolling(window=7).mean()\n",
    "        df['MA_30'] = df['Average Price'].rolling(window=30).mean()\n",
    "\n",
    "        # SARIMAX order (tune if needed)\n",
    "        order = (1, 1, 1)\n",
    "        seasonal_order = (1, 1, 1, 7)\n",
    "\n",
    "        # Fit SARIMAX model\n",
    "        model = SARIMAX(df['Average Price'],\n",
    "                        order=order,\n",
    "                        seasonal_order=seasonal_order,\n",
    "                        enforce_stationarity=False,\n",
    "                        enforce_invertibility=False)\n",
    "        model_fit = model.fit(disp=False)\n",
    "\n",
    "        # Save model\n",
    "        model_file = os.path.join(output_models, file.replace(\".csv\", \"_sarimax_model.pkl\"))\n",
    "        joblib.dump(model_fit, model_file)\n",
    "\n",
    "        # Predictions\n",
    "        df['Predicted'] = model_fit.predict(start=0, end=len(df)-1)\n",
    "        df['Predicted'] = df['Predicted'].round(2)  # round predictions\n",
    "\n",
    "        # Rename Average Price to Actual\n",
    "        df.rename(columns={'Average Price': 'Actual'}, inplace=True)\n",
    "\n",
    "        # Calculate metrics\n",
    "        y_true = df['Actual'].values\n",
    "        y_pred = df['Predicted'].values\n",
    "        mae = round(mean_absolute_error(y_true, y_pred), 2)\n",
    "        rmse = round(np.sqrt(mean_squared_error(y_true, y_pred)), 2)\n",
    "        r2 = round(r2_score(y_true, y_pred), 4)\n",
    "        mape = round(mean_absolute_percentage_error_safe(y_true, y_pred), 2)\n",
    "        accuracy = round(100 - mape, 2)\n",
    "\n",
    "        print(f\"Metrics for {file}:\")\n",
    "        print(f\"  MAE        : {mae}\")\n",
    "        print(f\"  RMSE       : {rmse}\")\n",
    "        print(f\"  R²         : {r2}\")\n",
    "        print(f\"  MAPE(%)    : {mape}\")\n",
    "        print(f\"  Accuracy(%) : {accuracy}\\n\")\n",
    "\n",
    "        # Save metrics\n",
    "        metrics_list.append({\n",
    "            'File': file,\n",
    "            'MAE': mae,\n",
    "            'RMSE': rmse,\n",
    "            'R2': r2,\n",
    "            'MAPE(%)': mape,\n",
    "            'Accuracy(%)': accuracy\n",
    "        })\n",
    "\n",
    "        # -----------------------------\n",
    "        # Save updated CSV with only Date, Actual, Predicted\n",
    "        # -----------------------------\n",
    "        save_df = df[['Actual', 'Predicted']].copy()\n",
    "        save_df['Date'] = df.index\n",
    "        save_df = save_df[['Date', 'Actual', 'Predicted']]\n",
    "        updated_csv_path = os.path.join(output_csv, file.replace(\".csv\", \"_sarimax_updated.csv\"))\n",
    "        save_df.to_csv(updated_csv_path, index=False)\n",
    "        print(f\"Saved updated CSV with Date, Actual & Predicted: {updated_csv_path}\")\n",
    "\n",
    "        # -----------------------------\n",
    "        # Plot graph\n",
    "        # -----------------------------\n",
    "        plt.figure(figsize=(12,6))\n",
    "        plt.plot(df.index, df['Actual'], label=\"Actual\", color=\"blue\")\n",
    "        plt.plot(df.index, df['Predicted'], label=\"Predicted\", color=\"red\", linestyle=\"dashed\")\n",
    "        plt.plot(df.index, df['MA_7'], label=\"MA 7\", color=\"orange\")\n",
    "        plt.plot(df.index, df['MA_30'], label=\"MA 30\", color=\"green\")\n",
    "        plt.xlabel(\"Date\")\n",
    "        plt.ylabel(\"Average Price\")\n",
    "        plt.title(f\"Price Prediction (SARIMAX) - {file}\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        graph_file = os.path.join(output_graphs, file.replace(\".csv\", \"_sarimax_graph.png\"))\n",
    "        plt.savefig(graph_file, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "# Save all metrics to CSV\n",
    "metrics_df = pd.DataFrame(metrics_list)\n",
    "metrics_df.to_csv(output_metrics_csv, index=False)\n",
    "print(f\"✅ Multiple CSVs processed! Metrics saved to {output_metrics_csv}. Models, updated CSVs, and graphs saved in respective folders.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf8eee6-1f55-47f6-a276-5ba67bd4d344",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TAT+MHA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24e5a520-5643-4f7c-8610-a68592d06921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Processing: wheat_Bagalkot_daily.csv\n",
      "Epoch 1/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - loss: 0.0012 - mae: 0.0248 - val_loss: 0.0044 - val_mae: 0.0478\n",
      "Epoch 2/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 0.0012 - mae: 0.0244 - val_loss: 0.0038 - val_mae: 0.0447\n",
      "Epoch 3/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 0.0012 - mae: 0.0244 - val_loss: 0.0050 - val_mae: 0.0522\n",
      "Epoch 4/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 0.0012 - mae: 0.0244 - val_loss: 0.0045 - val_mae: 0.0485\n",
      "Epoch 5/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0244 - val_loss: 0.0042 - val_mae: 0.0464\n",
      "Epoch 6/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0244 - val_loss: 0.0047 - val_mae: 0.0500\n",
      "Epoch 7/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0244 - val_loss: 0.0044 - val_mae: 0.0478\n",
      "Epoch 8/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 0.0012 - mae: 0.0244 - val_loss: 0.0044 - val_mae: 0.0477\n",
      "Epoch 9/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 0.0012 - mae: 0.0244 - val_loss: 0.0037 - val_mae: 0.0441\n",
      "Epoch 10/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 0.0012 - mae: 0.0244 - val_loss: 0.0043 - val_mae: 0.0470\n",
      "Epoch 11/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0244 - val_loss: 0.0048 - val_mae: 0.0504\n",
      "Epoch 12/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0244 - val_loss: 0.0046 - val_mae: 0.0493\n",
      "Epoch 13/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 0.0012 - mae: 0.0244 - val_loss: 0.0047 - val_mae: 0.0498\n",
      "Epoch 14/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0243 - val_loss: 0.0046 - val_mae: 0.0489\n",
      "Epoch 15/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0244 - val_loss: 0.0041 - val_mae: 0.0457\n",
      "Epoch 16/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 0.0012 - mae: 0.0244 - val_loss: 0.0045 - val_mae: 0.0485\n",
      "Epoch 17/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 0.0012 - mae: 0.0244 - val_loss: 0.0044 - val_mae: 0.0473\n",
      "Epoch 18/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0244 - val_loss: 0.0049 - val_mae: 0.0514\n",
      "Epoch 19/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0244 - val_loss: 0.0041 - val_mae: 0.0459\n",
      "Epoch 20/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 0.0012 - mae: 0.0244 - val_loss: 0.0036 - val_mae: 0.0439\n",
      "Epoch 21/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0244 - val_loss: 0.0042 - val_mae: 0.0460\n",
      "Epoch 22/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0244 - val_loss: 0.0043 - val_mae: 0.0467\n",
      "Epoch 23/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0244 - val_loss: 0.0045 - val_mae: 0.0481\n",
      "Epoch 24/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 0.0012 - mae: 0.0244 - val_loss: 0.0041 - val_mae: 0.0458\n",
      "Epoch 25/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 0.0012 - mae: 0.0244 - val_loss: 0.0044 - val_mae: 0.0475\n",
      "Epoch 26/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 0.0012 - mae: 0.0244 - val_loss: 0.0039 - val_mae: 0.0450\n",
      "Epoch 27/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 0.0012 - mae: 0.0244 - val_loss: 0.0042 - val_mae: 0.0462\n",
      "Epoch 28/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 0.0012 - mae: 0.0244 - val_loss: 0.0046 - val_mae: 0.0490\n",
      "Epoch 29/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0243 - val_loss: 0.0044 - val_mae: 0.0475\n",
      "Epoch 30/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0244 - val_loss: 0.0047 - val_mae: 0.0495\n",
      "Epoch 31/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0244 - val_loss: 0.0043 - val_mae: 0.0470\n",
      "Epoch 32/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 0.0012 - mae: 0.0244 - val_loss: 0.0044 - val_mae: 0.0476\n",
      "Epoch 33/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0244 - val_loss: 0.0046 - val_mae: 0.0493\n",
      "Epoch 34/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0244 - val_loss: 0.0042 - val_mae: 0.0459\n",
      "Epoch 35/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 0.0012 - mae: 0.0244 - val_loss: 0.0043 - val_mae: 0.0469\n",
      "Epoch 36/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 0.0012 - mae: 0.0243 - val_loss: 0.0039 - val_mae: 0.0450\n",
      "Epoch 37/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 0.0012 - mae: 0.0243 - val_loss: 0.0043 - val_mae: 0.0467\n",
      "Epoch 38/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 0.0012 - mae: 0.0244 - val_loss: 0.0041 - val_mae: 0.0456\n",
      "Epoch 39/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 0.0012 - mae: 0.0244 - val_loss: 0.0045 - val_mae: 0.0485\n",
      "Epoch 40/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 0.0012 - mae: 0.0244 - val_loss: 0.0043 - val_mae: 0.0467\n",
      "Epoch 41/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0244 - val_loss: 0.0040 - val_mae: 0.0454\n",
      "Epoch 42/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0243 - val_loss: 0.0044 - val_mae: 0.0473\n",
      "Epoch 43/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 0.0012 - mae: 0.0243 - val_loss: 0.0042 - val_mae: 0.0462\n",
      "Epoch 44/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0244 - val_loss: 0.0035 - val_mae: 0.0436\n",
      "Epoch 45/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 15ms/step - loss: 0.0012 - mae: 0.0244 - val_loss: 0.0041 - val_mae: 0.0458\n",
      "Epoch 46/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 0.0012 - mae: 0.0244 - val_loss: 0.0043 - val_mae: 0.0468\n",
      "Epoch 47/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 0.0012 - mae: 0.0244 - val_loss: 0.0044 - val_mae: 0.0472\n",
      "Epoch 48/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0244 - val_loss: 0.0043 - val_mae: 0.0466\n",
      "Epoch 49/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0244 - val_loss: 0.0042 - val_mae: 0.0461\n",
      "Epoch 50/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 0.0012 - mae: 0.0244 - val_loss: 0.0044 - val_mae: 0.0478\n",
      "Epoch 51/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0243 - val_loss: 0.0044 - val_mae: 0.0475\n",
      "Epoch 52/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0244 - val_loss: 0.0041 - val_mae: 0.0458\n",
      "Epoch 53/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0243 - val_loss: 0.0045 - val_mae: 0.0479\n",
      "Epoch 54/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0244 - val_loss: 0.0045 - val_mae: 0.0484\n",
      "Epoch 55/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0243 - val_loss: 0.0044 - val_mae: 0.0473\n",
      "Epoch 56/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0243 - val_loss: 0.0044 - val_mae: 0.0477\n",
      "Epoch 57/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0244 - val_loss: 0.0040 - val_mae: 0.0453\n",
      "Epoch 58/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0243 - val_loss: 0.0044 - val_mae: 0.0477\n",
      "Epoch 59/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0244 - val_loss: 0.0043 - val_mae: 0.0468\n",
      "Epoch 60/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0243 - val_loss: 0.0043 - val_mae: 0.0469\n",
      "Epoch 61/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0243 - val_loss: 0.0045 - val_mae: 0.0485\n",
      "Epoch 62/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0244 - val_loss: 0.0041 - val_mae: 0.0455\n",
      "Epoch 63/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0243 - val_loss: 0.0041 - val_mae: 0.0456\n",
      "Epoch 64/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0244 - val_loss: 0.0044 - val_mae: 0.0474\n",
      "Epoch 65/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0243 - val_loss: 0.0040 - val_mae: 0.0454\n",
      "Epoch 66/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0243 - val_loss: 0.0044 - val_mae: 0.0474\n",
      "Epoch 67/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0243 - val_loss: 0.0041 - val_mae: 0.0456\n",
      "Epoch 68/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0244 - val_loss: 0.0042 - val_mae: 0.0463\n",
      "Epoch 69/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0243 - val_loss: 0.0042 - val_mae: 0.0460\n",
      "Epoch 70/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0243 - val_loss: 0.0043 - val_mae: 0.0467\n",
      "Epoch 71/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0243 - val_loss: 0.0045 - val_mae: 0.0484\n",
      "Epoch 72/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0243 - val_loss: 0.0040 - val_mae: 0.0453\n",
      "Epoch 73/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0243 - val_loss: 0.0045 - val_mae: 0.0482\n",
      "Epoch 74/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 0.0012 - mae: 0.0243 - val_loss: 0.0042 - val_mae: 0.0464\n",
      "Epoch 75/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0243 - val_loss: 0.0043 - val_mae: 0.0467\n",
      "Epoch 76/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0243 - val_loss: 0.0039 - val_mae: 0.0449\n",
      "Epoch 77/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0243 - val_loss: 0.0041 - val_mae: 0.0456\n",
      "Epoch 78/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0243 - val_loss: 0.0042 - val_mae: 0.0465\n",
      "Epoch 79/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0243 - val_loss: 0.0040 - val_mae: 0.0454\n",
      "Epoch 80/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0243 - val_loss: 0.0044 - val_mae: 0.0477\n",
      "Epoch 81/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0243 - val_loss: 0.0043 - val_mae: 0.0465\n",
      "Epoch 82/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0243 - val_loss: 0.0045 - val_mae: 0.0483\n",
      "Epoch 83/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - loss: 0.0012 - mae: 0.0243 - val_loss: 0.0041 - val_mae: 0.0457\n",
      "Epoch 84/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0243 - val_loss: 0.0045 - val_mae: 0.0479\n",
      "Epoch 85/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0243 - val_loss: 0.0042 - val_mae: 0.0462\n",
      "Epoch 86/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 0.0012 - mae: 0.0243 - val_loss: 0.0044 - val_mae: 0.0473\n",
      "Epoch 87/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0243 - val_loss: 0.0039 - val_mae: 0.0450\n",
      "Epoch 88/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0243 - val_loss: 0.0044 - val_mae: 0.0478\n",
      "Epoch 89/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0243 - val_loss: 0.0042 - val_mae: 0.0462\n",
      "Epoch 90/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 0.0012 - mae: 0.0243 - val_loss: 0.0042 - val_mae: 0.0459\n",
      "Epoch 91/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0243 - val_loss: 0.0046 - val_mae: 0.0489\n",
      "Epoch 92/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0243 - val_loss: 0.0040 - val_mae: 0.0454\n",
      "Epoch 93/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 0.0012 - mae: 0.0243 - val_loss: 0.0041 - val_mae: 0.0456\n",
      "Epoch 94/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0243 - val_loss: 0.0040 - val_mae: 0.0451\n",
      "Epoch 95/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 0.0012 - mae: 0.0243 - val_loss: 0.0041 - val_mae: 0.0458\n",
      "Epoch 96/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0243 - val_loss: 0.0047 - val_mae: 0.0498\n",
      "Epoch 97/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0243 - val_loss: 0.0041 - val_mae: 0.0459\n",
      "Epoch 98/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0243 - val_loss: 0.0042 - val_mae: 0.0462\n",
      "Epoch 99/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0243 - val_loss: 0.0041 - val_mae: 0.0459\n",
      "Epoch 100/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 0.0012 - mae: 0.0243 - val_loss: 0.0042 - val_mae: 0.0463\n",
      "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step\n",
      "✅ Done with wheat_Bagalkot_daily.csv | MAE=499.22, RMSE=730.06, R2=-0.0374, MAPE=23.32%, Accuracy=76.68%\n",
      "\n",
      "🚀 Processing: wheat_Bangalore_daily.csv\n",
      "Epoch 1/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - loss: 9.3054e-04 - mae: 0.0242 - val_loss: 0.0052 - val_mae: 0.0581\n",
      "Epoch 2/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 8.9889e-04 - mae: 0.0239 - val_loss: 0.0051 - val_mae: 0.0575\n",
      "Epoch 3/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 9.0227e-04 - mae: 0.0239 - val_loss: 0.0047 - val_mae: 0.0542\n",
      "Epoch 4/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 9.0225e-04 - mae: 0.0239 - val_loss: 0.0050 - val_mae: 0.0568\n",
      "Epoch 5/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 8.9894e-04 - mae: 0.0239 - val_loss: 0.0050 - val_mae: 0.0568\n",
      "Epoch 6/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 9.0232e-04 - mae: 0.0239 - val_loss: 0.0048 - val_mae: 0.0545\n",
      "Epoch 7/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 9.0262e-04 - mae: 0.0240 - val_loss: 0.0056 - val_mae: 0.0614\n",
      "Epoch 8/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 9.0143e-04 - mae: 0.0239 - val_loss: 0.0044 - val_mae: 0.0516\n",
      "Epoch 9/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 9.0144e-04 - mae: 0.0239 - val_loss: 0.0050 - val_mae: 0.0569\n",
      "Epoch 10/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 9.0056e-04 - mae: 0.0239 - val_loss: 0.0050 - val_mae: 0.0567\n",
      "Epoch 11/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 8.9900e-04 - mae: 0.0239 - val_loss: 0.0050 - val_mae: 0.0566\n",
      "Epoch 12/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 9.0129e-04 - mae: 0.0239 - val_loss: 0.0046 - val_mae: 0.0531\n",
      "Epoch 13/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 9.0055e-04 - mae: 0.0239 - val_loss: 0.0054 - val_mae: 0.0604\n",
      "Epoch 14/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 9.0031e-04 - mae: 0.0239 - val_loss: 0.0050 - val_mae: 0.0570\n",
      "Epoch 15/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 9.0176e-04 - mae: 0.0239 - val_loss: 0.0049 - val_mae: 0.0563\n",
      "Epoch 16/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 9.0177e-04 - mae: 0.0239 - val_loss: 0.0049 - val_mae: 0.0558\n",
      "Epoch 17/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 9.0067e-04 - mae: 0.0239 - val_loss: 0.0048 - val_mae: 0.0554\n",
      "Epoch 18/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 9.0034e-04 - mae: 0.0239 - val_loss: 0.0052 - val_mae: 0.0584\n",
      "Epoch 19/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 9.0022e-04 - mae: 0.0239 - val_loss: 0.0049 - val_mae: 0.0562\n",
      "Epoch 20/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 9.0293e-04 - mae: 0.0239 - val_loss: 0.0050 - val_mae: 0.0571\n",
      "Epoch 21/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 9.0280e-04 - mae: 0.0239 - val_loss: 0.0051 - val_mae: 0.0580\n",
      "Epoch 22/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 8.9929e-04 - mae: 0.0239 - val_loss: 0.0048 - val_mae: 0.0554\n",
      "Epoch 23/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 8.9996e-04 - mae: 0.0239 - val_loss: 0.0052 - val_mae: 0.0583\n",
      "Epoch 24/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 8.9842e-04 - mae: 0.0239 - val_loss: 0.0051 - val_mae: 0.0580\n",
      "Epoch 25/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 8.9956e-04 - mae: 0.0239 - val_loss: 0.0051 - val_mae: 0.0577\n",
      "Epoch 26/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 8.9920e-04 - mae: 0.0239 - val_loss: 0.0052 - val_mae: 0.0582\n",
      "Epoch 27/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 8.9979e-04 - mae: 0.0239 - val_loss: 0.0050 - val_mae: 0.0569\n",
      "Epoch 28/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 8.9860e-04 - mae: 0.0239 - val_loss: 0.0054 - val_mae: 0.0605\n",
      "Epoch 29/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 9.0147e-04 - mae: 0.0239 - val_loss: 0.0050 - val_mae: 0.0570\n",
      "Epoch 30/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 9.0002e-04 - mae: 0.0239 - val_loss: 0.0049 - val_mae: 0.0556\n",
      "Epoch 31/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 8.9720e-04 - mae: 0.0239 - val_loss: 0.0053 - val_mae: 0.0594\n",
      "Epoch 32/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 9.0096e-04 - mae: 0.0239 - val_loss: 0.0050 - val_mae: 0.0567\n",
      "Epoch 33/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 8.9997e-04 - mae: 0.0239 - val_loss: 0.0054 - val_mae: 0.0599\n",
      "Epoch 34/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 8.9927e-04 - mae: 0.0239 - val_loss: 0.0050 - val_mae: 0.0570\n",
      "Epoch 35/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 8.9924e-04 - mae: 0.0239 - val_loss: 0.0053 - val_mae: 0.0590\n",
      "Epoch 36/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 8.9889e-04 - mae: 0.0239 - val_loss: 0.0050 - val_mae: 0.0563\n",
      "Epoch 37/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 8.9894e-04 - mae: 0.0239 - val_loss: 0.0051 - val_mae: 0.0574\n",
      "Epoch 38/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 8.9784e-04 - mae: 0.0239 - val_loss: 0.0050 - val_mae: 0.0571\n",
      "Epoch 39/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 8.9744e-04 - mae: 0.0239 - val_loss: 0.0048 - val_mae: 0.0553\n",
      "Epoch 40/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 8.9807e-04 - mae: 0.0239 - val_loss: 0.0047 - val_mae: 0.0540\n",
      "Epoch 41/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 9.0097e-04 - mae: 0.0239 - val_loss: 0.0050 - val_mae: 0.0566\n",
      "Epoch 42/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 8.9624e-04 - mae: 0.0239 - val_loss: 0.0052 - val_mae: 0.0582\n",
      "Epoch 43/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 8.9910e-04 - mae: 0.0239 - val_loss: 0.0052 - val_mae: 0.0583\n",
      "Epoch 44/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 8.9837e-04 - mae: 0.0239 - val_loss: 0.0049 - val_mae: 0.0557\n",
      "Epoch 45/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 8.9838e-04 - mae: 0.0239 - val_loss: 0.0053 - val_mae: 0.0591\n",
      "Epoch 46/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 8.9876e-04 - mae: 0.0239 - val_loss: 0.0053 - val_mae: 0.0590\n",
      "Epoch 47/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 8.9951e-04 - mae: 0.0239 - val_loss: 0.0053 - val_mae: 0.0592\n",
      "Epoch 48/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 8.9835e-04 - mae: 0.0239 - val_loss: 0.0050 - val_mae: 0.0570\n",
      "Epoch 49/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 8.9844e-04 - mae: 0.0239 - val_loss: 0.0049 - val_mae: 0.0561\n",
      "Epoch 50/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 8.9871e-04 - mae: 0.0239 - val_loss: 0.0050 - val_mae: 0.0570\n",
      "Epoch 51/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 8.9845e-04 - mae: 0.0239 - val_loss: 0.0050 - val_mae: 0.0565\n",
      "Epoch 52/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 8.9818e-04 - mae: 0.0238 - val_loss: 0.0051 - val_mae: 0.0576\n",
      "Epoch 53/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 8.9872e-04 - mae: 0.0239 - val_loss: 0.0049 - val_mae: 0.0555\n",
      "Epoch 54/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 8.9909e-04 - mae: 0.0239 - val_loss: 0.0051 - val_mae: 0.0580\n",
      "Epoch 55/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 8.9898e-04 - mae: 0.0239 - val_loss: 0.0048 - val_mae: 0.0551\n",
      "Epoch 56/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 8.9818e-04 - mae: 0.0239 - val_loss: 0.0050 - val_mae: 0.0566\n",
      "Epoch 57/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 8.9834e-04 - mae: 0.0239 - val_loss: 0.0053 - val_mae: 0.0594\n",
      "Epoch 58/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 8.9773e-04 - mae: 0.0239 - val_loss: 0.0049 - val_mae: 0.0558\n",
      "Epoch 59/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 8.9949e-04 - mae: 0.0239 - val_loss: 0.0050 - val_mae: 0.0570\n",
      "Epoch 60/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 8.9942e-04 - mae: 0.0239 - val_loss: 0.0050 - val_mae: 0.0568\n",
      "Epoch 61/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 8.9814e-04 - mae: 0.0239 - val_loss: 0.0052 - val_mae: 0.0584\n",
      "Epoch 62/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 8.9921e-04 - mae: 0.0239 - val_loss: 0.0042 - val_mae: 0.0497\n",
      "Epoch 63/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 8.9738e-04 - mae: 0.0239 - val_loss: 0.0049 - val_mae: 0.0562\n",
      "Epoch 64/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 8.9822e-04 - mae: 0.0239 - val_loss: 0.0052 - val_mae: 0.0583\n",
      "Epoch 65/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 8.9879e-04 - mae: 0.0239 - val_loss: 0.0048 - val_mae: 0.0550\n",
      "Epoch 66/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 8.9859e-04 - mae: 0.0239 - val_loss: 0.0049 - val_mae: 0.0556\n",
      "Epoch 67/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 8.9793e-04 - mae: 0.0239 - val_loss: 0.0051 - val_mae: 0.0579\n",
      "Epoch 68/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 8.9855e-04 - mae: 0.0239 - val_loss: 0.0045 - val_mae: 0.0522\n",
      "Epoch 69/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 8.9719e-04 - mae: 0.0239 - val_loss: 0.0047 - val_mae: 0.0543\n",
      "Epoch 70/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 8.9898e-04 - mae: 0.0239 - val_loss: 0.0048 - val_mae: 0.0552\n",
      "Epoch 71/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 8.9805e-04 - mae: 0.0239 - val_loss: 0.0052 - val_mae: 0.0584\n",
      "Epoch 72/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 8.9718e-04 - mae: 0.0239 - val_loss: 0.0047 - val_mae: 0.0541\n",
      "Epoch 73/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 8.9796e-04 - mae: 0.0239 - val_loss: 0.0049 - val_mae: 0.0556\n",
      "Epoch 74/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 8.9878e-04 - mae: 0.0239 - val_loss: 0.0051 - val_mae: 0.0577\n",
      "Epoch 75/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 8.9690e-04 - mae: 0.0239 - val_loss: 0.0052 - val_mae: 0.0582\n",
      "Epoch 76/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 8.9798e-04 - mae: 0.0239 - val_loss: 0.0046 - val_mae: 0.0528\n",
      "Epoch 77/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 8.9845e-04 - mae: 0.0239 - val_loss: 0.0051 - val_mae: 0.0574\n",
      "Epoch 78/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 8.9787e-04 - mae: 0.0239 - val_loss: 0.0052 - val_mae: 0.0584\n",
      "Epoch 79/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 8.9687e-04 - mae: 0.0238 - val_loss: 0.0051 - val_mae: 0.0573\n",
      "Epoch 80/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 8.9726e-04 - mae: 0.0238 - val_loss: 0.0049 - val_mae: 0.0562\n",
      "Epoch 81/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 8.9767e-04 - mae: 0.0239 - val_loss: 0.0053 - val_mae: 0.0597\n",
      "Epoch 82/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 8.9900e-04 - mae: 0.0239 - val_loss: 0.0048 - val_mae: 0.0548\n",
      "Epoch 83/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 8.9780e-04 - mae: 0.0239 - val_loss: 0.0048 - val_mae: 0.0545\n",
      "Epoch 84/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 8.9860e-04 - mae: 0.0239 - val_loss: 0.0048 - val_mae: 0.0547\n",
      "Epoch 85/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 8.9879e-04 - mae: 0.0239 - val_loss: 0.0049 - val_mae: 0.0559\n",
      "Epoch 86/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 8.9955e-04 - mae: 0.0239 - val_loss: 0.0050 - val_mae: 0.0566\n",
      "Epoch 87/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 8.9896e-04 - mae: 0.0239 - val_loss: 0.0054 - val_mae: 0.0601\n",
      "Epoch 88/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 8.9769e-04 - mae: 0.0239 - val_loss: 0.0051 - val_mae: 0.0580\n",
      "Epoch 89/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 8.9731e-04 - mae: 0.0239 - val_loss: 0.0047 - val_mae: 0.0536\n",
      "Epoch 90/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 8.9740e-04 - mae: 0.0239 - val_loss: 0.0048 - val_mae: 0.0546\n",
      "Epoch 91/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 8.9822e-04 - mae: 0.0239 - val_loss: 0.0049 - val_mae: 0.0555\n",
      "Epoch 92/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 8.9804e-04 - mae: 0.0239 - val_loss: 0.0050 - val_mae: 0.0566\n",
      "Epoch 93/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 8.9806e-04 - mae: 0.0239 - val_loss: 0.0049 - val_mae: 0.0560\n",
      "Epoch 94/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 8.9879e-04 - mae: 0.0239 - val_loss: 0.0052 - val_mae: 0.0582\n",
      "Epoch 95/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 8.9978e-04 - mae: 0.0239 - val_loss: 0.0052 - val_mae: 0.0583\n",
      "Epoch 96/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 8.9863e-04 - mae: 0.0239 - val_loss: 0.0049 - val_mae: 0.0562\n",
      "Epoch 97/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 8.9931e-04 - mae: 0.0239 - val_loss: 0.0051 - val_mae: 0.0579\n",
      "Epoch 98/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 8.9771e-04 - mae: 0.0239 - val_loss: 0.0045 - val_mae: 0.0521\n",
      "Epoch 99/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 8.9912e-04 - mae: 0.0239 - val_loss: 0.0051 - val_mae: 0.0579\n",
      "Epoch 100/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 8.9760e-04 - mae: 0.0239 - val_loss: 0.0050 - val_mae: 0.0563\n",
      "\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step\n",
      "✅ Done with wheat_Bangalore_daily.csv | MAE=529.95, RMSE=721.82, R2=-0.0775, MAPE=22.49%, Accuracy=77.51%\n",
      "\n",
      "🚀 Processing: wheat_Belgaum_daily.csv\n",
      "Epoch 1/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 0.0110 - mae: 0.0798 - val_loss: 0.0291 - val_mae: 0.1529\n",
      "Epoch 2/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - loss: 0.0086 - mae: 0.0726 - val_loss: 0.0283 - val_mae: 0.1505\n",
      "Epoch 3/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - loss: 0.0086 - mae: 0.0726 - val_loss: 0.0275 - val_mae: 0.1480\n",
      "Epoch 4/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - loss: 0.0086 - mae: 0.0725 - val_loss: 0.0290 - val_mae: 0.1525\n",
      "Epoch 5/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0086 - mae: 0.0726 - val_loss: 0.0305 - val_mae: 0.1569\n",
      "Epoch 6/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - loss: 0.0086 - mae: 0.0725 - val_loss: 0.0276 - val_mae: 0.1484\n",
      "Epoch 7/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0086 - mae: 0.0726 - val_loss: 0.0297 - val_mae: 0.1545\n",
      "Epoch 8/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - loss: 0.0086 - mae: 0.0725 - val_loss: 0.0288 - val_mae: 0.1519\n",
      "Epoch 9/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - loss: 0.0086 - mae: 0.0725 - val_loss: 0.0293 - val_mae: 0.1534\n",
      "Epoch 10/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0086 - mae: 0.0726 - val_loss: 0.0278 - val_mae: 0.1489\n",
      "Epoch 11/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - loss: 0.0086 - mae: 0.0726 - val_loss: 0.0293 - val_mae: 0.1533\n",
      "Epoch 12/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0086 - mae: 0.0726 - val_loss: 0.0290 - val_mae: 0.1525\n",
      "Epoch 13/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0086 - mae: 0.0725 - val_loss: 0.0304 - val_mae: 0.1563\n",
      "Epoch 14/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - loss: 0.0086 - mae: 0.0726 - val_loss: 0.0294 - val_mae: 0.1535\n",
      "Epoch 15/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0086 - mae: 0.0726 - val_loss: 0.0294 - val_mae: 0.1538\n",
      "Epoch 16/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0086 - mae: 0.0726 - val_loss: 0.0274 - val_mae: 0.1478\n",
      "Epoch 17/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0086 - mae: 0.0726 - val_loss: 0.0279 - val_mae: 0.1494\n",
      "Epoch 18/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - loss: 0.0086 - mae: 0.0725 - val_loss: 0.0296 - val_mae: 0.1542\n",
      "Epoch 19/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - loss: 0.0086 - mae: 0.0726 - val_loss: 0.0276 - val_mae: 0.1483\n",
      "Epoch 20/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - loss: 0.0086 - mae: 0.0726 - val_loss: 0.0275 - val_mae: 0.1482\n",
      "Epoch 21/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - loss: 0.0086 - mae: 0.0726 - val_loss: 0.0301 - val_mae: 0.1557\n",
      "Epoch 22/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - loss: 0.0086 - mae: 0.0725 - val_loss: 0.0238 - val_mae: 0.1368\n",
      "Epoch 23/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - loss: 0.0086 - mae: 0.0726 - val_loss: 0.0306 - val_mae: 0.1571\n",
      "Epoch 24/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0086 - mae: 0.0725 - val_loss: 0.0287 - val_mae: 0.1517\n",
      "Epoch 25/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0086 - mae: 0.0726 - val_loss: 0.0291 - val_mae: 0.1527\n",
      "Epoch 26/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - loss: 0.0086 - mae: 0.0726 - val_loss: 0.0297 - val_mae: 0.1545\n",
      "Epoch 27/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0086 - mae: 0.0726 - val_loss: 0.0283 - val_mae: 0.1505\n",
      "Epoch 28/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - loss: 0.0086 - mae: 0.0726 - val_loss: 0.0281 - val_mae: 0.1498\n",
      "Epoch 29/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0086 - mae: 0.0725 - val_loss: 0.0289 - val_mae: 0.1521\n",
      "Epoch 30/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - loss: 0.0086 - mae: 0.0726 - val_loss: 0.0253 - val_mae: 0.1415\n",
      "Epoch 31/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0086 - mae: 0.0726 - val_loss: 0.0307 - val_mae: 0.1573\n",
      "Epoch 32/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0086 - mae: 0.0725 - val_loss: 0.0289 - val_mae: 0.1521\n",
      "Epoch 33/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0086 - mae: 0.0726 - val_loss: 0.0297 - val_mae: 0.1545\n",
      "Epoch 34/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0086 - mae: 0.0725 - val_loss: 0.0289 - val_mae: 0.1521\n",
      "Epoch 35/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0086 - mae: 0.0725 - val_loss: 0.0293 - val_mae: 0.1533\n",
      "Epoch 36/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0086 - mae: 0.0726 - val_loss: 0.0281 - val_mae: 0.1498\n",
      "Epoch 37/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0086 - mae: 0.0726 - val_loss: 0.0305 - val_mae: 0.1568\n",
      "Epoch 38/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - loss: 0.0086 - mae: 0.0725 - val_loss: 0.0259 - val_mae: 0.1433\n",
      "Epoch 39/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0086 - mae: 0.0726 - val_loss: 0.0269 - val_mae: 0.1464\n",
      "Epoch 40/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0086 - mae: 0.0725 - val_loss: 0.0270 - val_mae: 0.1466\n",
      "Epoch 41/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0086 - mae: 0.0726 - val_loss: 0.0296 - val_mae: 0.1542\n",
      "Epoch 42/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0086 - mae: 0.0726 - val_loss: 0.0318 - val_mae: 0.1602\n",
      "Epoch 43/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0086 - mae: 0.0726 - val_loss: 0.0282 - val_mae: 0.1501\n",
      "Epoch 44/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - loss: 0.0086 - mae: 0.0726 - val_loss: 0.0287 - val_mae: 0.1517\n",
      "Epoch 45/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - loss: 0.0086 - mae: 0.0726 - val_loss: 0.0277 - val_mae: 0.1488\n",
      "Epoch 46/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - loss: 0.0086 - mae: 0.0725 - val_loss: 0.0279 - val_mae: 0.1493\n",
      "Epoch 47/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0086 - mae: 0.0726 - val_loss: 0.0295 - val_mae: 0.1538\n",
      "Epoch 48/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - loss: 0.0086 - mae: 0.0726 - val_loss: 0.0284 - val_mae: 0.1507\n",
      "Epoch 49/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - loss: 0.0086 - mae: 0.0726 - val_loss: 0.0302 - val_mae: 0.1560\n",
      "Epoch 50/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - loss: 0.0086 - mae: 0.0725 - val_loss: 0.0296 - val_mae: 0.1541\n",
      "Epoch 51/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0086 - mae: 0.0726 - val_loss: 0.0271 - val_mae: 0.1469\n",
      "Epoch 52/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - loss: 0.0086 - mae: 0.0725 - val_loss: 0.0282 - val_mae: 0.1503\n",
      "Epoch 53/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0086 - mae: 0.0725 - val_loss: 0.0301 - val_mae: 0.1557\n",
      "Epoch 54/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0086 - mae: 0.0725 - val_loss: 0.0278 - val_mae: 0.1491\n",
      "Epoch 55/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0086 - mae: 0.0726 - val_loss: 0.0305 - val_mae: 0.1567\n",
      "Epoch 56/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - loss: 0.0086 - mae: 0.0726 - val_loss: 0.0314 - val_mae: 0.1591\n",
      "Epoch 57/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0086 - mae: 0.0725 - val_loss: 0.0304 - val_mae: 0.1566\n",
      "Epoch 58/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0086 - mae: 0.0725 - val_loss: 0.0306 - val_mae: 0.1571\n",
      "Epoch 59/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - loss: 0.0086 - mae: 0.0725 - val_loss: 0.0302 - val_mae: 0.1560\n",
      "Epoch 60/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0086 - mae: 0.0725 - val_loss: 0.0295 - val_mae: 0.1540\n",
      "Epoch 61/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0086 - mae: 0.0726 - val_loss: 0.0268 - val_mae: 0.1460\n",
      "Epoch 62/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - loss: 0.0086 - mae: 0.0725 - val_loss: 0.0275 - val_mae: 0.1482\n",
      "Epoch 63/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - loss: 0.0086 - mae: 0.0726 - val_loss: 0.0276 - val_mae: 0.1484\n",
      "Epoch 64/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - loss: 0.0086 - mae: 0.0725 - val_loss: 0.0281 - val_mae: 0.1500\n",
      "Epoch 65/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - loss: 0.0086 - mae: 0.0725 - val_loss: 0.0292 - val_mae: 0.1530\n",
      "Epoch 66/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - loss: 0.0086 - mae: 0.0726 - val_loss: 0.0308 - val_mae: 0.1577\n",
      "Epoch 67/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - loss: 0.0086 - mae: 0.0726 - val_loss: 0.0287 - val_mae: 0.1517\n",
      "Epoch 68/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - loss: 0.0086 - mae: 0.0725 - val_loss: 0.0305 - val_mae: 0.1566\n",
      "Epoch 69/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - loss: 0.0086 - mae: 0.0726 - val_loss: 0.0320 - val_mae: 0.1608\n",
      "Epoch 70/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - loss: 0.0086 - mae: 0.0726 - val_loss: 0.0307 - val_mae: 0.1574\n",
      "Epoch 71/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - loss: 0.0086 - mae: 0.0725 - val_loss: 0.0300 - val_mae: 0.1554\n",
      "Epoch 72/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - loss: 0.0086 - mae: 0.0726 - val_loss: 0.0291 - val_mae: 0.1529\n",
      "Epoch 73/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - loss: 0.0086 - mae: 0.0725 - val_loss: 0.0306 - val_mae: 0.1570\n",
      "Epoch 74/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - loss: 0.0086 - mae: 0.0725 - val_loss: 0.0281 - val_mae: 0.1498\n",
      "Epoch 75/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - loss: 0.0086 - mae: 0.0725 - val_loss: 0.0295 - val_mae: 0.1538\n",
      "Epoch 76/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - loss: 0.0086 - mae: 0.0725 - val_loss: 0.0282 - val_mae: 0.1503\n",
      "Epoch 77/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - loss: 0.0086 - mae: 0.0726 - val_loss: 0.0266 - val_mae: 0.1454\n",
      "Epoch 78/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - loss: 0.0086 - mae: 0.0726 - val_loss: 0.0309 - val_mae: 0.1579\n",
      "Epoch 79/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - loss: 0.0086 - mae: 0.0725 - val_loss: 0.0283 - val_mae: 0.1503\n",
      "Epoch 80/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0086 - mae: 0.0726 - val_loss: 0.0292 - val_mae: 0.1531\n",
      "Epoch 81/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - loss: 0.0086 - mae: 0.0725 - val_loss: 0.0287 - val_mae: 0.1515\n",
      "Epoch 82/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - loss: 0.0086 - mae: 0.0725 - val_loss: 0.0298 - val_mae: 0.1548\n",
      "Epoch 83/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0086 - mae: 0.0725 - val_loss: 0.0286 - val_mae: 0.1514\n",
      "Epoch 84/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - loss: 0.0086 - mae: 0.0726 - val_loss: 0.0291 - val_mae: 0.1528\n",
      "Epoch 85/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0086 - mae: 0.0725 - val_loss: 0.0285 - val_mae: 0.1509\n",
      "Epoch 86/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - loss: 0.0086 - mae: 0.0725 - val_loss: 0.0281 - val_mae: 0.1499\n",
      "Epoch 87/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - loss: 0.0086 - mae: 0.0726 - val_loss: 0.0298 - val_mae: 0.1548\n",
      "Epoch 88/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - loss: 0.0086 - mae: 0.0725 - val_loss: 0.0271 - val_mae: 0.1468\n",
      "Epoch 89/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - loss: 0.0086 - mae: 0.0726 - val_loss: 0.0281 - val_mae: 0.1498\n",
      "Epoch 90/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - loss: 0.0086 - mae: 0.0726 - val_loss: 0.0302 - val_mae: 0.1560\n",
      "Epoch 91/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - loss: 0.0086 - mae: 0.0725 - val_loss: 0.0290 - val_mae: 0.1524\n",
      "Epoch 92/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - loss: 0.0086 - mae: 0.0725 - val_loss: 0.0293 - val_mae: 0.1534\n",
      "Epoch 93/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - loss: 0.0086 - mae: 0.0726 - val_loss: 0.0297 - val_mae: 0.1545\n",
      "Epoch 94/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - loss: 0.0086 - mae: 0.0726 - val_loss: 0.0294 - val_mae: 0.1536\n",
      "Epoch 95/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - loss: 0.0086 - mae: 0.0725 - val_loss: 0.0280 - val_mae: 0.1495\n",
      "Epoch 96/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0086 - mae: 0.0726 - val_loss: 0.0265 - val_mae: 0.1451\n",
      "Epoch 97/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - loss: 0.0086 - mae: 0.0726 - val_loss: 0.0302 - val_mae: 0.1558\n",
      "Epoch 98/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - loss: 0.0086 - mae: 0.0726 - val_loss: 0.0288 - val_mae: 0.1521\n",
      "Epoch 99/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0086 - mae: 0.0725 - val_loss: 0.0292 - val_mae: 0.1530\n",
      "Epoch 100/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - loss: 0.0086 - mae: 0.0726 - val_loss: 0.0299 - val_mae: 0.1552\n",
      "\u001b[1m1030/1030\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step\n",
      "✅ Done with wheat_Belgaum_daily.csv | MAE=504.62, RMSE=643.76, R2=-0.0925, MAPE=23.0%, Accuracy=77.0%\n",
      "\n",
      "🚀 Processing: wheat_Bellary_daily.csv\n",
      "Epoch 1/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 0.0047 - mae: 0.0527 - val_loss: 0.0330 - val_mae: 0.1349\n",
      "Epoch 2/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0347 - val_mae: 0.1395\n",
      "Epoch 3/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0336 - val_mae: 0.1367\n",
      "Epoch 4/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0331 - val_mae: 0.1353\n",
      "Epoch 5/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0355 - val_mae: 0.1414\n",
      "Epoch 6/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0333 - val_mae: 0.1358\n",
      "Epoch 7/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0337 - val_mae: 0.1370\n",
      "Epoch 8/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0334 - val_mae: 0.1360\n",
      "Epoch 9/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0345 - val_mae: 0.1389\n",
      "Epoch 10/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0354 - val_mae: 0.1412\n",
      "Epoch 11/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0346 - val_mae: 0.1391\n",
      "Epoch 12/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0341 - val_mae: 0.1379\n",
      "Epoch 13/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0339 - val_mae: 0.1374\n",
      "Epoch 14/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0038 - mae: 0.0488 - val_loss: 0.0353 - val_mae: 0.1408\n",
      "Epoch 15/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0320 - val_mae: 0.1324\n",
      "Epoch 16/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0337 - val_mae: 0.1370\n",
      "Epoch 17/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0341 - val_mae: 0.1380\n",
      "Epoch 18/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0344 - val_mae: 0.1385\n",
      "Epoch 19/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0340 - val_mae: 0.1376\n",
      "Epoch 20/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0325 - val_mae: 0.1337\n",
      "Epoch 21/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0038 - mae: 0.0488 - val_loss: 0.0322 - val_mae: 0.1330\n",
      "Epoch 22/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0346 - val_mae: 0.1392\n",
      "Epoch 23/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0332 - val_mae: 0.1355\n",
      "Epoch 24/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0334 - val_mae: 0.1362\n",
      "Epoch 25/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0337 - val_mae: 0.1368\n",
      "Epoch 26/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0038 - mae: 0.0488 - val_loss: 0.0321 - val_mae: 0.1327\n",
      "Epoch 27/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0349 - val_mae: 0.1399\n",
      "Epoch 28/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0038 - mae: 0.0488 - val_loss: 0.0318 - val_mae: 0.1318\n",
      "Epoch 29/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0335 - val_mae: 0.1365\n",
      "Epoch 30/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0038 - mae: 0.0490 - val_loss: 0.0345 - val_mae: 0.1388\n",
      "Epoch 31/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0038 - mae: 0.0488 - val_loss: 0.0322 - val_mae: 0.1330\n",
      "Epoch 32/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0336 - val_mae: 0.1365\n",
      "Epoch 33/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0335 - val_mae: 0.1364\n",
      "Epoch 34/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0344 - val_mae: 0.1386\n",
      "Epoch 35/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0326 - val_mae: 0.1340\n",
      "Epoch 36/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0352 - val_mae: 0.1406\n",
      "Epoch 37/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0338 - val_mae: 0.1372\n",
      "Epoch 38/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0335 - val_mae: 0.1364\n",
      "Epoch 39/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0348 - val_mae: 0.1396\n",
      "Epoch 40/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0038 - mae: 0.0488 - val_loss: 0.0344 - val_mae: 0.1386\n",
      "Epoch 41/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0328 - val_mae: 0.1344\n",
      "Epoch 42/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0347 - val_mae: 0.1395\n",
      "Epoch 43/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0038 - mae: 0.0488 - val_loss: 0.0346 - val_mae: 0.1393\n",
      "Epoch 44/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0359 - val_mae: 0.1423\n",
      "Epoch 45/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0038 - mae: 0.0488 - val_loss: 0.0322 - val_mae: 0.1329\n",
      "Epoch 46/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0337 - val_mae: 0.1369\n",
      "Epoch 47/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0038 - mae: 0.0488 - val_loss: 0.0333 - val_mae: 0.1358\n",
      "Epoch 48/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0338 - val_mae: 0.1372\n",
      "Epoch 49/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0346 - val_mae: 0.1392\n",
      "Epoch 50/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0337 - val_mae: 0.1368\n",
      "Epoch 51/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0327 - val_mae: 0.1341\n",
      "Epoch 52/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0338 - val_mae: 0.1372\n",
      "Epoch 53/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0362 - val_mae: 0.1432\n",
      "Epoch 54/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0038 - mae: 0.0488 - val_loss: 0.0327 - val_mae: 0.1343\n",
      "Epoch 55/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0338 - val_mae: 0.1372\n",
      "Epoch 56/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0343 - val_mae: 0.1384\n",
      "Epoch 57/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0038 - mae: 0.0488 - val_loss: 0.0332 - val_mae: 0.1355\n",
      "Epoch 58/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0038 - mae: 0.0488 - val_loss: 0.0355 - val_mae: 0.1415\n",
      "Epoch 59/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0038 - mae: 0.0488 - val_loss: 0.0359 - val_mae: 0.1424\n",
      "Epoch 60/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0038 - mae: 0.0488 - val_loss: 0.0322 - val_mae: 0.1330\n",
      "Epoch 61/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0323 - val_mae: 0.1331\n",
      "Epoch 62/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0344 - val_mae: 0.1386\n",
      "Epoch 63/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0344 - val_mae: 0.1386\n",
      "Epoch 64/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0341 - val_mae: 0.1379\n",
      "Epoch 65/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0338 - val_mae: 0.1372\n",
      "Epoch 66/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0344 - val_mae: 0.1387\n",
      "Epoch 67/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0349 - val_mae: 0.1399\n",
      "Epoch 68/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0333 - val_mae: 0.1359\n",
      "Epoch 69/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0038 - mae: 0.0488 - val_loss: 0.0345 - val_mae: 0.1390\n",
      "Epoch 70/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0038 - mae: 0.0488 - val_loss: 0.0323 - val_mae: 0.1333\n",
      "Epoch 71/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0346 - val_mae: 0.1393\n",
      "Epoch 72/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0345 - val_mae: 0.1389\n",
      "Epoch 73/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0038 - mae: 0.0488 - val_loss: 0.0346 - val_mae: 0.1391\n",
      "Epoch 74/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0344 - val_mae: 0.1387\n",
      "Epoch 75/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0335 - val_mae: 0.1364\n",
      "Epoch 76/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0345 - val_mae: 0.1389\n",
      "Epoch 77/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0038 - mae: 0.0488 - val_loss: 0.0338 - val_mae: 0.1370\n",
      "Epoch 78/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0330 - val_mae: 0.1350\n",
      "Epoch 79/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0038 - mae: 0.0488 - val_loss: 0.0341 - val_mae: 0.1378\n",
      "Epoch 80/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0339 - val_mae: 0.1373\n",
      "Epoch 81/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0327 - val_mae: 0.1343\n",
      "Epoch 82/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0038 - mae: 0.0488 - val_loss: 0.0344 - val_mae: 0.1385\n",
      "Epoch 83/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0038 - mae: 0.0488 - val_loss: 0.0346 - val_mae: 0.1393\n",
      "Epoch 84/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0038 - mae: 0.0488 - val_loss: 0.0340 - val_mae: 0.1377\n",
      "Epoch 85/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0038 - mae: 0.0488 - val_loss: 0.0318 - val_mae: 0.1319\n",
      "Epoch 86/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0038 - mae: 0.0490 - val_loss: 0.0340 - val_mae: 0.1376\n",
      "Epoch 87/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0331 - val_mae: 0.1354\n",
      "Epoch 88/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0331 - val_mae: 0.1354\n",
      "Epoch 89/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0357 - val_mae: 0.1420\n",
      "Epoch 90/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0354 - val_mae: 0.1412\n",
      "Epoch 91/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0342 - val_mae: 0.1380\n",
      "Epoch 92/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0038 - mae: 0.0488 - val_loss: 0.0329 - val_mae: 0.1349\n",
      "Epoch 93/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0349 - val_mae: 0.1400\n",
      "Epoch 94/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0038 - mae: 0.0488 - val_loss: 0.0342 - val_mae: 0.1380\n",
      "Epoch 95/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0336 - val_mae: 0.1367\n",
      "Epoch 96/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0334 - val_mae: 0.1361\n",
      "Epoch 97/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0334 - val_mae: 0.1360\n",
      "Epoch 98/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0038 - mae: 0.0488 - val_loss: 0.0337 - val_mae: 0.1369\n",
      "Epoch 99/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0331 - val_mae: 0.1354\n",
      "Epoch 100/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0327 - val_mae: 0.1341\n",
      "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step\n",
      "✅ Done with wheat_Bellary_daily.csv | MAE=487.89, RMSE=714.93, R2=-0.0485, MAPE=28.46%, Accuracy=71.54%\n",
      "\n",
      "🚀 Processing: wheat_Bidar_daily.csv\n",
      "Epoch 1/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 15ms/step - loss: 0.0134 - mae: 0.0931 - val_loss: 0.0299 - val_mae: 0.1504\n",
      "Epoch 2/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 0.0101 - mae: 0.0837 - val_loss: 0.0299 - val_mae: 0.1503\n",
      "Epoch 3/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - loss: 0.0101 - mae: 0.0837 - val_loss: 0.0304 - val_mae: 0.1518\n",
      "Epoch 4/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0101 - mae: 0.0837 - val_loss: 0.0289 - val_mae: 0.1469\n",
      "Epoch 5/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0101 - mae: 0.0837 - val_loss: 0.0274 - val_mae: 0.1420\n",
      "Epoch 6/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0101 - mae: 0.0837 - val_loss: 0.0323 - val_mae: 0.1577\n",
      "Epoch 7/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 0.0101 - mae: 0.0837 - val_loss: 0.0281 - val_mae: 0.1442\n",
      "Epoch 8/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 0.0101 - mae: 0.0837 - val_loss: 0.0284 - val_mae: 0.1453\n",
      "Epoch 9/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.0101 - mae: 0.0837 - val_loss: 0.0266 - val_mae: 0.1392\n",
      "Epoch 10/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 0.0101 - mae: 0.0837 - val_loss: 0.0294 - val_mae: 0.1486\n",
      "Epoch 11/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - loss: 0.0101 - mae: 0.0837 - val_loss: 0.0287 - val_mae: 0.1462\n",
      "Epoch 12/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - loss: 0.0101 - mae: 0.0837 - val_loss: 0.0297 - val_mae: 0.1496\n",
      "Epoch 13/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 0.0101 - mae: 0.0837 - val_loss: 0.0309 - val_mae: 0.1535\n",
      "Epoch 14/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 0.0101 - mae: 0.0837 - val_loss: 0.0309 - val_mae: 0.1536\n",
      "Epoch 15/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 0.0101 - mae: 0.0837 - val_loss: 0.0287 - val_mae: 0.1462\n",
      "Epoch 16/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 0.0101 - mae: 0.0837 - val_loss: 0.0266 - val_mae: 0.1394\n",
      "Epoch 17/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - loss: 0.0101 - mae: 0.0836 - val_loss: 0.0310 - val_mae: 0.1537\n",
      "Epoch 18/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.0101 - mae: 0.0837 - val_loss: 0.0287 - val_mae: 0.1463\n",
      "Epoch 19/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.0101 - mae: 0.0837 - val_loss: 0.0272 - val_mae: 0.1414\n",
      "Epoch 20/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 0.0101 - mae: 0.0837 - val_loss: 0.0273 - val_mae: 0.1417\n",
      "Epoch 21/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 0.0101 - mae: 0.0837 - val_loss: 0.0286 - val_mae: 0.1459\n",
      "Epoch 22/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.0101 - mae: 0.0837 - val_loss: 0.0280 - val_mae: 0.1439\n",
      "Epoch 23/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - loss: 0.0101 - mae: 0.0836 - val_loss: 0.0279 - val_mae: 0.1437\n",
      "Epoch 24/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.0101 - mae: 0.0837 - val_loss: 0.0269 - val_mae: 0.1403\n",
      "Epoch 25/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.0101 - mae: 0.0837 - val_loss: 0.0294 - val_mae: 0.1486\n",
      "Epoch 26/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.0101 - mae: 0.0836 - val_loss: 0.0305 - val_mae: 0.1523\n",
      "Epoch 27/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.0101 - mae: 0.0837 - val_loss: 0.0296 - val_mae: 0.1493\n",
      "Epoch 28/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.0101 - mae: 0.0836 - val_loss: 0.0299 - val_mae: 0.1501\n",
      "Epoch 29/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.0101 - mae: 0.0837 - val_loss: 0.0274 - val_mae: 0.1418\n",
      "Epoch 30/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.0101 - mae: 0.0837 - val_loss: 0.0300 - val_mae: 0.1506\n",
      "Epoch 31/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 0.0101 - mae: 0.0836 - val_loss: 0.0311 - val_mae: 0.1539\n",
      "Epoch 32/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0101 - mae: 0.0837 - val_loss: 0.0310 - val_mae: 0.1538\n",
      "Epoch 33/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0101 - mae: 0.0837 - val_loss: 0.0265 - val_mae: 0.1388\n",
      "Epoch 34/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0101 - mae: 0.0837 - val_loss: 0.0287 - val_mae: 0.1464\n",
      "Epoch 35/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0101 - mae: 0.0837 - val_loss: 0.0292 - val_mae: 0.1479\n",
      "Epoch 36/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0101 - mae: 0.0837 - val_loss: 0.0277 - val_mae: 0.1430\n",
      "Epoch 37/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0101 - mae: 0.0837 - val_loss: 0.0265 - val_mae: 0.1387\n",
      "Epoch 38/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0101 - mae: 0.0837 - val_loss: 0.0306 - val_mae: 0.1524\n",
      "Epoch 39/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0101 - mae: 0.0836 - val_loss: 0.0295 - val_mae: 0.1488\n",
      "Epoch 40/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0101 - mae: 0.0837 - val_loss: 0.0256 - val_mae: 0.1356\n",
      "Epoch 41/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0101 - mae: 0.0837 - val_loss: 0.0281 - val_mae: 0.1443\n",
      "Epoch 42/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0101 - mae: 0.0836 - val_loss: 0.0257 - val_mae: 0.1360\n",
      "Epoch 43/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0101 - mae: 0.0836 - val_loss: 0.0267 - val_mae: 0.1396\n",
      "Epoch 44/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0101 - mae: 0.0837 - val_loss: 0.0287 - val_mae: 0.1462\n",
      "Epoch 45/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0101 - mae: 0.0837 - val_loss: 0.0293 - val_mae: 0.1483\n",
      "Epoch 46/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0101 - mae: 0.0837 - val_loss: 0.0323 - val_mae: 0.1577\n",
      "Epoch 47/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0101 - mae: 0.0837 - val_loss: 0.0306 - val_mae: 0.1525\n",
      "Epoch 48/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0101 - mae: 0.0837 - val_loss: 0.0281 - val_mae: 0.1442\n",
      "Epoch 49/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0101 - mae: 0.0837 - val_loss: 0.0303 - val_mae: 0.1515\n",
      "Epoch 50/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0101 - mae: 0.0836 - val_loss: 0.0289 - val_mae: 0.1468\n",
      "Epoch 51/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0101 - mae: 0.0837 - val_loss: 0.0262 - val_mae: 0.1380\n",
      "Epoch 52/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0101 - mae: 0.0836 - val_loss: 0.0288 - val_mae: 0.1465\n",
      "Epoch 53/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0101 - mae: 0.0836 - val_loss: 0.0286 - val_mae: 0.1459\n",
      "Epoch 54/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0101 - mae: 0.0836 - val_loss: 0.0272 - val_mae: 0.1414\n",
      "Epoch 55/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0101 - mae: 0.0837 - val_loss: 0.0294 - val_mae: 0.1487\n",
      "Epoch 56/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0101 - mae: 0.0837 - val_loss: 0.0284 - val_mae: 0.1453\n",
      "Epoch 57/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0101 - mae: 0.0837 - val_loss: 0.0287 - val_mae: 0.1464\n",
      "Epoch 58/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0101 - mae: 0.0837 - val_loss: 0.0291 - val_mae: 0.1476\n",
      "Epoch 59/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0101 - mae: 0.0837 - val_loss: 0.0279 - val_mae: 0.1435\n",
      "Epoch 60/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0101 - mae: 0.0837 - val_loss: 0.0290 - val_mae: 0.1473\n",
      "Epoch 61/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0101 - mae: 0.0836 - val_loss: 0.0286 - val_mae: 0.1461\n",
      "Epoch 62/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0101 - mae: 0.0837 - val_loss: 0.0280 - val_mae: 0.1439\n",
      "Epoch 63/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0101 - mae: 0.0837 - val_loss: 0.0287 - val_mae: 0.1462\n",
      "Epoch 64/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0101 - mae: 0.0837 - val_loss: 0.0275 - val_mae: 0.1424\n",
      "Epoch 65/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0101 - mae: 0.0837 - val_loss: 0.0280 - val_mae: 0.1439\n",
      "Epoch 66/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0101 - mae: 0.0837 - val_loss: 0.0291 - val_mae: 0.1475\n",
      "Epoch 67/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0101 - mae: 0.0836 - val_loss: 0.0287 - val_mae: 0.1462\n",
      "Epoch 68/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0101 - mae: 0.0836 - val_loss: 0.0279 - val_mae: 0.1436\n",
      "Epoch 69/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0101 - mae: 0.0836 - val_loss: 0.0283 - val_mae: 0.1451\n",
      "Epoch 70/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0101 - mae: 0.0837 - val_loss: 0.0271 - val_mae: 0.1409\n",
      "Epoch 71/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0101 - mae: 0.0837 - val_loss: 0.0265 - val_mae: 0.1387\n",
      "Epoch 72/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0101 - mae: 0.0837 - val_loss: 0.0281 - val_mae: 0.1442\n",
      "Epoch 73/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0101 - mae: 0.0837 - val_loss: 0.0278 - val_mae: 0.1432\n",
      "Epoch 74/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0101 - mae: 0.0836 - val_loss: 0.0281 - val_mae: 0.1443\n",
      "Epoch 75/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0101 - mae: 0.0837 - val_loss: 0.0283 - val_mae: 0.1450\n",
      "Epoch 76/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0101 - mae: 0.0837 - val_loss: 0.0271 - val_mae: 0.1409\n",
      "Epoch 77/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0101 - mae: 0.0837 - val_loss: 0.0301 - val_mae: 0.1508\n",
      "Epoch 78/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0101 - mae: 0.0837 - val_loss: 0.0287 - val_mae: 0.1464\n",
      "Epoch 79/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0101 - mae: 0.0837 - val_loss: 0.0276 - val_mae: 0.1425\n",
      "Epoch 80/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0101 - mae: 0.0837 - val_loss: 0.0279 - val_mae: 0.1437\n",
      "Epoch 81/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0101 - mae: 0.0837 - val_loss: 0.0280 - val_mae: 0.1440\n",
      "Epoch 82/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0101 - mae: 0.0837 - val_loss: 0.0277 - val_mae: 0.1430\n",
      "Epoch 83/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0101 - mae: 0.0837 - val_loss: 0.0294 - val_mae: 0.1486\n",
      "Epoch 84/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0101 - mae: 0.0837 - val_loss: 0.0284 - val_mae: 0.1453\n",
      "Epoch 85/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0101 - mae: 0.0837 - val_loss: 0.0268 - val_mae: 0.1400\n",
      "Epoch 86/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0101 - mae: 0.0837 - val_loss: 0.0276 - val_mae: 0.1425\n",
      "Epoch 87/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0101 - mae: 0.0836 - val_loss: 0.0287 - val_mae: 0.1463\n",
      "Epoch 88/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0101 - mae: 0.0837 - val_loss: 0.0287 - val_mae: 0.1462\n",
      "Epoch 89/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0101 - mae: 0.0837 - val_loss: 0.0289 - val_mae: 0.1471\n",
      "Epoch 90/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0101 - mae: 0.0837 - val_loss: 0.0271 - val_mae: 0.1408\n",
      "Epoch 91/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0101 - mae: 0.0837 - val_loss: 0.0291 - val_mae: 0.1475\n",
      "Epoch 92/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0101 - mae: 0.0837 - val_loss: 0.0322 - val_mae: 0.1575\n",
      "Epoch 93/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0101 - mae: 0.0837 - val_loss: 0.0291 - val_mae: 0.1477\n",
      "Epoch 94/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0101 - mae: 0.0837 - val_loss: 0.0289 - val_mae: 0.1468\n",
      "Epoch 95/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0101 - mae: 0.0837 - val_loss: 0.0270 - val_mae: 0.1406\n",
      "Epoch 96/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0101 - mae: 0.0837 - val_loss: 0.0280 - val_mae: 0.1440\n",
      "Epoch 97/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0101 - mae: 0.0837 - val_loss: 0.0274 - val_mae: 0.1419\n",
      "Epoch 98/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0101 - mae: 0.0836 - val_loss: 0.0263 - val_mae: 0.1380\n",
      "Epoch 99/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0101 - mae: 0.0836 - val_loss: 0.0282 - val_mae: 0.1447\n",
      "Epoch 100/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0101 - mae: 0.0837 - val_loss: 0.0270 - val_mae: 0.1407\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step\n",
      "✅ Done with wheat_Bidar_daily.csv | MAE=499.25, RMSE=610.23, R2=-0.0408, MAPE=25.31%, Accuracy=74.69%\n",
      "\n",
      "🚀 Processing: wheat_Bijapur_daily.csv\n",
      "Epoch 1/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0160 - mae: 0.0936 - val_loss: 0.0092 - val_mae: 0.0776\n",
      "Epoch 2/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0108 - mae: 0.0797 - val_loss: 0.0110 - val_mae: 0.0877\n",
      "Epoch 3/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0108 - mae: 0.0794 - val_loss: 0.0093 - val_mae: 0.0779\n",
      "Epoch 4/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0109 - mae: 0.0796 - val_loss: 0.0095 - val_mae: 0.0793\n",
      "Epoch 5/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0109 - mae: 0.0797 - val_loss: 0.0115 - val_mae: 0.0901\n",
      "Epoch 6/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0109 - mae: 0.0798 - val_loss: 0.0134 - val_mae: 0.0998\n",
      "Epoch 7/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0108 - mae: 0.0795 - val_loss: 0.0089 - val_mae: 0.0757\n",
      "Epoch 8/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0108 - mae: 0.0798 - val_loss: 0.0127 - val_mae: 0.0966\n",
      "Epoch 9/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0109 - mae: 0.0796 - val_loss: 0.0102 - val_mae: 0.0835\n",
      "Epoch 10/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0108 - mae: 0.0796 - val_loss: 0.0088 - val_mae: 0.0755\n",
      "Epoch 11/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0108 - mae: 0.0798 - val_loss: 0.0119 - val_mae: 0.0923\n",
      "Epoch 12/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0109 - mae: 0.0796 - val_loss: 0.0101 - val_mae: 0.0828\n",
      "Epoch 13/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0109 - mae: 0.0797 - val_loss: 0.0091 - val_mae: 0.0768\n",
      "Epoch 14/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0109 - mae: 0.0798 - val_loss: 0.0093 - val_mae: 0.0782\n",
      "Epoch 15/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0108 - mae: 0.0797 - val_loss: 0.0109 - val_mae: 0.0872\n",
      "Epoch 16/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.0109 - mae: 0.0796 - val_loss: 0.0099 - val_mae: 0.0813\n",
      "Epoch 17/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0109 - mae: 0.0797 - val_loss: 0.0102 - val_mae: 0.0834\n",
      "Epoch 18/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0108 - mae: 0.0796 - val_loss: 0.0114 - val_mae: 0.0900\n",
      "Epoch 19/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0109 - mae: 0.0796 - val_loss: 0.0093 - val_mae: 0.0783\n",
      "Epoch 20/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0109 - mae: 0.0797 - val_loss: 0.0112 - val_mae: 0.0887\n",
      "Epoch 21/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0109 - mae: 0.0796 - val_loss: 0.0104 - val_mae: 0.0845\n",
      "Epoch 22/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0108 - mae: 0.0796 - val_loss: 0.0101 - val_mae: 0.0826\n",
      "Epoch 23/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0108 - mae: 0.0796 - val_loss: 0.0093 - val_mae: 0.0780\n",
      "Epoch 24/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0109 - mae: 0.0797 - val_loss: 0.0106 - val_mae: 0.0854\n",
      "Epoch 25/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0109 - mae: 0.0796 - val_loss: 0.0099 - val_mae: 0.0818\n",
      "Epoch 26/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0108 - mae: 0.0797 - val_loss: 0.0136 - val_mae: 0.1008\n",
      "Epoch 27/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0108 - mae: 0.0796 - val_loss: 0.0088 - val_mae: 0.0753\n",
      "Epoch 28/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0109 - mae: 0.0797 - val_loss: 0.0103 - val_mae: 0.0835\n",
      "Epoch 29/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0108 - mae: 0.0798 - val_loss: 0.0111 - val_mae: 0.0883\n",
      "Epoch 30/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0109 - mae: 0.0797 - val_loss: 0.0107 - val_mae: 0.0859\n",
      "Epoch 31/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0109 - mae: 0.0797 - val_loss: 0.0089 - val_mae: 0.0758\n",
      "Epoch 32/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0109 - mae: 0.0798 - val_loss: 0.0102 - val_mae: 0.0834\n",
      "Epoch 33/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0108 - mae: 0.0796 - val_loss: 0.0102 - val_mae: 0.0829\n",
      "Epoch 34/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0108 - mae: 0.0796 - val_loss: 0.0121 - val_mae: 0.0935\n",
      "Epoch 35/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0108 - mae: 0.0796 - val_loss: 0.0109 - val_mae: 0.0872\n",
      "Epoch 36/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0109 - mae: 0.0797 - val_loss: 0.0101 - val_mae: 0.0826\n",
      "Epoch 37/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0109 - mae: 0.0798 - val_loss: 0.0102 - val_mae: 0.0831\n",
      "Epoch 38/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0109 - mae: 0.0796 - val_loss: 0.0110 - val_mae: 0.0876\n",
      "Epoch 39/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0108 - mae: 0.0796 - val_loss: 0.0109 - val_mae: 0.0869\n",
      "Epoch 40/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0108 - mae: 0.0797 - val_loss: 0.0095 - val_mae: 0.0792\n",
      "Epoch 41/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0109 - mae: 0.0797 - val_loss: 0.0097 - val_mae: 0.0806\n",
      "Epoch 42/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0109 - mae: 0.0797 - val_loss: 0.0105 - val_mae: 0.0849\n",
      "Epoch 43/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0109 - mae: 0.0797 - val_loss: 0.0105 - val_mae: 0.0847\n",
      "Epoch 44/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0109 - mae: 0.0798 - val_loss: 0.0108 - val_mae: 0.0867\n",
      "Epoch 45/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0109 - mae: 0.0797 - val_loss: 0.0119 - val_mae: 0.0926\n",
      "Epoch 46/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0109 - mae: 0.0797 - val_loss: 0.0099 - val_mae: 0.0814\n",
      "Epoch 47/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0109 - mae: 0.0797 - val_loss: 0.0100 - val_mae: 0.0822\n",
      "Epoch 48/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0109 - mae: 0.0797 - val_loss: 0.0102 - val_mae: 0.0829\n",
      "Epoch 49/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0108 - mae: 0.0796 - val_loss: 0.0115 - val_mae: 0.0903\n",
      "Epoch 50/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0109 - mae: 0.0796 - val_loss: 0.0094 - val_mae: 0.0789\n",
      "Epoch 51/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0109 - mae: 0.0797 - val_loss: 0.0090 - val_mae: 0.0764\n",
      "Epoch 52/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0108 - mae: 0.0797 - val_loss: 0.0103 - val_mae: 0.0835\n",
      "Epoch 53/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0109 - mae: 0.0797 - val_loss: 0.0104 - val_mae: 0.0842\n",
      "Epoch 54/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0108 - mae: 0.0796 - val_loss: 0.0089 - val_mae: 0.0761\n",
      "Epoch 55/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0108 - mae: 0.0796 - val_loss: 0.0081 - val_mae: 0.0712\n",
      "Epoch 56/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0109 - mae: 0.0797 - val_loss: 0.0094 - val_mae: 0.0787\n",
      "Epoch 57/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0109 - mae: 0.0797 - val_loss: 0.0110 - val_mae: 0.0875\n",
      "Epoch 58/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0109 - mae: 0.0795 - val_loss: 0.0095 - val_mae: 0.0795\n",
      "Epoch 59/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0109 - mae: 0.0797 - val_loss: 0.0102 - val_mae: 0.0832\n",
      "Epoch 60/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0109 - mae: 0.0796 - val_loss: 0.0100 - val_mae: 0.0818\n",
      "Epoch 61/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0109 - mae: 0.0797 - val_loss: 0.0103 - val_mae: 0.0835\n",
      "Epoch 62/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0109 - mae: 0.0797 - val_loss: 0.0105 - val_mae: 0.0850\n",
      "Epoch 63/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0109 - mae: 0.0798 - val_loss: 0.0106 - val_mae: 0.0855\n",
      "Epoch 64/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0108 - mae: 0.0797 - val_loss: 0.0106 - val_mae: 0.0854\n",
      "Epoch 65/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0108 - mae: 0.0796 - val_loss: 0.0100 - val_mae: 0.0822\n",
      "Epoch 66/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0109 - mae: 0.0797 - val_loss: 0.0112 - val_mae: 0.0886\n",
      "Epoch 67/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0109 - mae: 0.0797 - val_loss: 0.0116 - val_mae: 0.0908\n",
      "Epoch 68/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0109 - mae: 0.0796 - val_loss: 0.0096 - val_mae: 0.0800\n",
      "Epoch 69/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0109 - mae: 0.0797 - val_loss: 0.0112 - val_mae: 0.0886\n",
      "Epoch 70/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0108 - mae: 0.0796 - val_loss: 0.0099 - val_mae: 0.0814\n",
      "Epoch 71/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0108 - mae: 0.0797 - val_loss: 0.0119 - val_mae: 0.0922\n",
      "Epoch 72/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0109 - mae: 0.0797 - val_loss: 0.0115 - val_mae: 0.0904\n",
      "Epoch 73/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0109 - mae: 0.0796 - val_loss: 0.0096 - val_mae: 0.0800\n",
      "Epoch 74/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0108 - mae: 0.0798 - val_loss: 0.0109 - val_mae: 0.0868\n",
      "Epoch 75/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0109 - mae: 0.0796 - val_loss: 0.0102 - val_mae: 0.0830\n",
      "Epoch 76/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0109 - mae: 0.0798 - val_loss: 0.0114 - val_mae: 0.0896\n",
      "Epoch 77/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0109 - mae: 0.0796 - val_loss: 0.0104 - val_mae: 0.0844\n",
      "Epoch 78/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0108 - mae: 0.0796 - val_loss: 0.0099 - val_mae: 0.0814\n",
      "Epoch 79/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0108 - mae: 0.0796 - val_loss: 0.0098 - val_mae: 0.0810\n",
      "Epoch 80/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0109 - mae: 0.0797 - val_loss: 0.0109 - val_mae: 0.0870\n",
      "Epoch 81/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0109 - mae: 0.0796 - val_loss: 0.0093 - val_mae: 0.0784\n",
      "Epoch 82/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0109 - mae: 0.0797 - val_loss: 0.0102 - val_mae: 0.0830\n",
      "Epoch 83/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0109 - mae: 0.0797 - val_loss: 0.0100 - val_mae: 0.0819\n",
      "Epoch 84/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0109 - mae: 0.0797 - val_loss: 0.0098 - val_mae: 0.0811\n",
      "Epoch 85/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0108 - mae: 0.0796 - val_loss: 0.0098 - val_mae: 0.0810\n",
      "Epoch 86/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0108 - mae: 0.0797 - val_loss: 0.0098 - val_mae: 0.0812\n",
      "Epoch 87/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.0108 - mae: 0.0797 - val_loss: 0.0110 - val_mae: 0.0875\n",
      "Epoch 88/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0109 - mae: 0.0797 - val_loss: 0.0100 - val_mae: 0.0821\n",
      "Epoch 89/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0109 - mae: 0.0798 - val_loss: 0.0107 - val_mae: 0.0862\n",
      "Epoch 90/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0108 - mae: 0.0796 - val_loss: 0.0109 - val_mae: 0.0872\n",
      "Epoch 91/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0109 - mae: 0.0796 - val_loss: 0.0094 - val_mae: 0.0786\n",
      "Epoch 92/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0109 - mae: 0.0797 - val_loss: 0.0107 - val_mae: 0.0861\n",
      "Epoch 93/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0109 - mae: 0.0796 - val_loss: 0.0101 - val_mae: 0.0827\n",
      "Epoch 94/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0109 - mae: 0.0798 - val_loss: 0.0115 - val_mae: 0.0902\n",
      "Epoch 95/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0108 - mae: 0.0797 - val_loss: 0.0112 - val_mae: 0.0889\n",
      "Epoch 96/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0108 - mae: 0.0797 - val_loss: 0.0111 - val_mae: 0.0880\n",
      "Epoch 97/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0109 - mae: 0.0797 - val_loss: 0.0102 - val_mae: 0.0831\n",
      "Epoch 98/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0109 - mae: 0.0798 - val_loss: 0.0111 - val_mae: 0.0884\n",
      "Epoch 99/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0108 - mae: 0.0796 - val_loss: 0.0099 - val_mae: 0.0814\n",
      "Epoch 100/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0108 - mae: 0.0796 - val_loss: 0.0097 - val_mae: 0.0803\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step\n",
      "✅ Done with wheat_Bijapur_daily.csv | MAE=646.33, RMSE=824.09, R2=-0.0138, MAPE=31.35%, Accuracy=68.65%\n",
      "\n",
      "🚀 Processing: wheat_Chikmagalur_daily.csv\n",
      "Epoch 1/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 0.0450 - mae: 0.1442 - val_loss: 0.0133 - val_mae: 0.0726\n",
      "Epoch 2/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0263 - mae: 0.1052 - val_loss: 0.0134 - val_mae: 0.0736\n",
      "Epoch 3/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0263 - mae: 0.1051 - val_loss: 0.0118 - val_mae: 0.0649\n",
      "Epoch 4/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0264 - mae: 0.1054 - val_loss: 0.0140 - val_mae: 0.0768\n",
      "Epoch 5/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0263 - mae: 0.1050 - val_loss: 0.0119 - val_mae: 0.0655\n",
      "Epoch 6/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0264 - mae: 0.1055 - val_loss: 0.0133 - val_mae: 0.0729\n",
      "Epoch 7/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0263 - mae: 0.1054 - val_loss: 0.0155 - val_mae: 0.0859\n",
      "Epoch 8/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0264 - mae: 0.1050 - val_loss: 0.0135 - val_mae: 0.0742\n",
      "Epoch 9/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0263 - mae: 0.1054 - val_loss: 0.0134 - val_mae: 0.0735\n",
      "Epoch 10/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0264 - mae: 0.1053 - val_loss: 0.0144 - val_mae: 0.0795\n",
      "Epoch 11/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0264 - mae: 0.1051 - val_loss: 0.0135 - val_mae: 0.0739\n",
      "Epoch 12/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0264 - mae: 0.1052 - val_loss: 0.0131 - val_mae: 0.0719\n",
      "Epoch 13/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0264 - mae: 0.1052 - val_loss: 0.0126 - val_mae: 0.0690\n",
      "Epoch 14/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0264 - mae: 0.1054 - val_loss: 0.0135 - val_mae: 0.0737\n",
      "Epoch 15/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0264 - mae: 0.1052 - val_loss: 0.0130 - val_mae: 0.0711\n",
      "Epoch 16/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0263 - mae: 0.1053 - val_loss: 0.0139 - val_mae: 0.0762\n",
      "Epoch 17/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0263 - mae: 0.1051 - val_loss: 0.0146 - val_mae: 0.0804\n",
      "Epoch 18/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0263 - mae: 0.1051 - val_loss: 0.0127 - val_mae: 0.0697\n",
      "Epoch 19/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0263 - mae: 0.1053 - val_loss: 0.0131 - val_mae: 0.0716\n",
      "Epoch 20/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0263 - mae: 0.1054 - val_loss: 0.0148 - val_mae: 0.0821\n",
      "Epoch 21/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0264 - mae: 0.1051 - val_loss: 0.0129 - val_mae: 0.0706\n",
      "Epoch 22/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0263 - mae: 0.1055 - val_loss: 0.0143 - val_mae: 0.0790\n",
      "Epoch 23/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0263 - mae: 0.1048 - val_loss: 0.0125 - val_mae: 0.0683\n",
      "Epoch 24/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0264 - mae: 0.1055 - val_loss: 0.0135 - val_mae: 0.0741\n",
      "Epoch 25/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0264 - mae: 0.1051 - val_loss: 0.0129 - val_mae: 0.0706\n",
      "Epoch 26/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0264 - mae: 0.1054 - val_loss: 0.0137 - val_mae: 0.0751\n",
      "Epoch 27/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0264 - mae: 0.1054 - val_loss: 0.0148 - val_mae: 0.0821\n",
      "Epoch 28/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0264 - mae: 0.1050 - val_loss: 0.0127 - val_mae: 0.0698\n",
      "Epoch 29/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0263 - mae: 0.1054 - val_loss: 0.0131 - val_mae: 0.0718\n",
      "Epoch 30/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0264 - mae: 0.1053 - val_loss: 0.0138 - val_mae: 0.0758\n",
      "Epoch 31/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0264 - mae: 0.1050 - val_loss: 0.0129 - val_mae: 0.0704\n",
      "Epoch 32/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0264 - mae: 0.1054 - val_loss: 0.0129 - val_mae: 0.0705\n",
      "Epoch 33/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0264 - mae: 0.1053 - val_loss: 0.0141 - val_mae: 0.0773\n",
      "Epoch 34/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0264 - mae: 0.1052 - val_loss: 0.0134 - val_mae: 0.0731\n",
      "Epoch 35/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0263 - mae: 0.1052 - val_loss: 0.0131 - val_mae: 0.0717\n",
      "Epoch 36/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0263 - mae: 0.1050 - val_loss: 0.0136 - val_mae: 0.0747\n",
      "Epoch 37/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0264 - mae: 0.1053 - val_loss: 0.0125 - val_mae: 0.0685\n",
      "Epoch 38/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0264 - mae: 0.1055 - val_loss: 0.0145 - val_mae: 0.0802\n",
      "Epoch 39/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0263 - mae: 0.1048 - val_loss: 0.0111 - val_mae: 0.0622\n",
      "Epoch 40/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0264 - mae: 0.1057 - val_loss: 0.0141 - val_mae: 0.0777\n",
      "Epoch 41/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0263 - mae: 0.1053 - val_loss: 0.0163 - val_mae: 0.0906\n",
      "Epoch 42/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0264 - mae: 0.1052 - val_loss: 0.0154 - val_mae: 0.0854\n",
      "Epoch 43/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0264 - mae: 0.1052 - val_loss: 0.0143 - val_mae: 0.0789\n",
      "Epoch 44/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0263 - mae: 0.1052 - val_loss: 0.0140 - val_mae: 0.0771\n",
      "Epoch 45/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0264 - mae: 0.1053 - val_loss: 0.0145 - val_mae: 0.0799\n",
      "Epoch 46/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0263 - mae: 0.1053 - val_loss: 0.0126 - val_mae: 0.0692\n",
      "Epoch 47/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0264 - mae: 0.1054 - val_loss: 0.0128 - val_mae: 0.0698\n",
      "Epoch 48/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0263 - mae: 0.1050 - val_loss: 0.0125 - val_mae: 0.0685\n",
      "Epoch 49/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0263 - mae: 0.1052 - val_loss: 0.0121 - val_mae: 0.0665\n",
      "Epoch 50/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0263 - mae: 0.1054 - val_loss: 0.0135 - val_mae: 0.0739\n",
      "Epoch 51/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0264 - mae: 0.1054 - val_loss: 0.0143 - val_mae: 0.0787\n",
      "Epoch 52/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0264 - mae: 0.1054 - val_loss: 0.0144 - val_mae: 0.0794\n",
      "Epoch 53/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0264 - mae: 0.1050 - val_loss: 0.0127 - val_mae: 0.0695\n",
      "Epoch 54/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.0264 - mae: 0.1052 - val_loss: 0.0128 - val_mae: 0.0700\n",
      "Epoch 55/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0264 - mae: 0.1055 - val_loss: 0.0135 - val_mae: 0.0739\n",
      "Epoch 56/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0263 - mae: 0.1053 - val_loss: 0.0122 - val_mae: 0.0667\n",
      "Epoch 57/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.0264 - mae: 0.1056 - val_loss: 0.0149 - val_mae: 0.0826\n",
      "Epoch 58/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0264 - mae: 0.1050 - val_loss: 0.0135 - val_mae: 0.0738\n",
      "Epoch 59/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.0263 - mae: 0.1053 - val_loss: 0.0132 - val_mae: 0.0722\n",
      "Epoch 60/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0264 - mae: 0.1050 - val_loss: 0.0123 - val_mae: 0.0674\n",
      "Epoch 61/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.0264 - mae: 0.1055 - val_loss: 0.0132 - val_mae: 0.0722\n",
      "Epoch 62/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0264 - mae: 0.1053 - val_loss: 0.0130 - val_mae: 0.0713\n",
      "Epoch 63/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0263 - mae: 0.1050 - val_loss: 0.0127 - val_mae: 0.0694\n",
      "Epoch 64/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0264 - mae: 0.1054 - val_loss: 0.0138 - val_mae: 0.0759\n",
      "Epoch 65/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0264 - mae: 0.1051 - val_loss: 0.0136 - val_mae: 0.0745\n",
      "Epoch 66/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0264 - mae: 0.1053 - val_loss: 0.0146 - val_mae: 0.0805\n",
      "Epoch 67/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0263 - mae: 0.1053 - val_loss: 0.0146 - val_mae: 0.0803\n",
      "Epoch 68/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0264 - mae: 0.1054 - val_loss: 0.0150 - val_mae: 0.0828\n",
      "Epoch 69/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0264 - mae: 0.1052 - val_loss: 0.0139 - val_mae: 0.0766\n",
      "Epoch 70/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0264 - mae: 0.1051 - val_loss: 0.0134 - val_mae: 0.0731\n",
      "Epoch 71/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0264 - mae: 0.1053 - val_loss: 0.0130 - val_mae: 0.0711\n",
      "Epoch 72/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0263 - mae: 0.1055 - val_loss: 0.0150 - val_mae: 0.0833\n",
      "Epoch 73/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0264 - mae: 0.1052 - val_loss: 0.0147 - val_mae: 0.0814\n",
      "Epoch 74/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0264 - mae: 0.1052 - val_loss: 0.0140 - val_mae: 0.0770\n",
      "Epoch 75/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0264 - mae: 0.1051 - val_loss: 0.0125 - val_mae: 0.0684\n",
      "Epoch 76/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0264 - mae: 0.1053 - val_loss: 0.0137 - val_mae: 0.0751\n",
      "Epoch 77/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0263 - mae: 0.1051 - val_loss: 0.0133 - val_mae: 0.0727\n",
      "Epoch 78/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0264 - mae: 0.1052 - val_loss: 0.0136 - val_mae: 0.0747\n",
      "Epoch 79/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0264 - mae: 0.1053 - val_loss: 0.0152 - val_mae: 0.0840\n",
      "Epoch 80/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0264 - mae: 0.1053 - val_loss: 0.0133 - val_mae: 0.0730\n",
      "Epoch 81/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0264 - mae: 0.1051 - val_loss: 0.0130 - val_mae: 0.0714\n",
      "Epoch 82/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0263 - mae: 0.1053 - val_loss: 0.0141 - val_mae: 0.0776\n",
      "Epoch 83/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0263 - mae: 0.1052 - val_loss: 0.0139 - val_mae: 0.0761\n",
      "Epoch 84/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0264 - mae: 0.1053 - val_loss: 0.0133 - val_mae: 0.0729\n",
      "Epoch 85/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0263 - mae: 0.1052 - val_loss: 0.0138 - val_mae: 0.0757\n",
      "Epoch 86/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0264 - mae: 0.1053 - val_loss: 0.0138 - val_mae: 0.0759\n",
      "Epoch 87/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0263 - mae: 0.1049 - val_loss: 0.0125 - val_mae: 0.0686\n",
      "Epoch 88/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0264 - mae: 0.1057 - val_loss: 0.0144 - val_mae: 0.0795\n",
      "Epoch 89/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0263 - mae: 0.1050 - val_loss: 0.0134 - val_mae: 0.0731\n",
      "Epoch 90/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0264 - mae: 0.1051 - val_loss: 0.0126 - val_mae: 0.0691\n",
      "Epoch 91/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0264 - mae: 0.1055 - val_loss: 0.0147 - val_mae: 0.0811\n",
      "Epoch 92/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0263 - mae: 0.1052 - val_loss: 0.0147 - val_mae: 0.0815\n",
      "Epoch 93/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0264 - mae: 0.1050 - val_loss: 0.0136 - val_mae: 0.0746\n",
      "Epoch 94/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0263 - mae: 0.1052 - val_loss: 0.0138 - val_mae: 0.0759\n",
      "Epoch 95/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0264 - mae: 0.1054 - val_loss: 0.0143 - val_mae: 0.0790\n",
      "Epoch 96/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0264 - mae: 0.1050 - val_loss: 0.0125 - val_mae: 0.0687\n",
      "Epoch 97/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0264 - mae: 0.1055 - val_loss: 0.0152 - val_mae: 0.0843\n",
      "Epoch 98/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0264 - mae: 0.1050 - val_loss: 0.0137 - val_mae: 0.0749\n",
      "Epoch 99/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0264 - mae: 0.1053 - val_loss: 0.0145 - val_mae: 0.0798\n",
      "Epoch 100/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0263 - mae: 0.1049 - val_loss: 0.0127 - val_mae: 0.0696\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step\n",
      "✅ Done with wheat_Chikmagalur_daily.csv | MAE=505.66, RMSE=768.6, R2=-0.0029, MAPE=32.67%, Accuracy=67.33%\n",
      "\n",
      "🚀 Processing: wheat_Chitradurga_daily.csv\n",
      "Epoch 1/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 0.0989 - mae: 0.2481 - val_loss: 0.2766 - val_mae: 0.5245\n",
      "Epoch 2/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0697 - mae: 0.2429 - val_loss: 0.2543 - val_mae: 0.5028\n",
      "Epoch 3/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0696 - mae: 0.2435 - val_loss: 0.2560 - val_mae: 0.5045\n",
      "Epoch 4/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0697 - mae: 0.2437 - val_loss: 0.2591 - val_mae: 0.5076\n",
      "Epoch 5/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0696 - mae: 0.2432 - val_loss: 0.2458 - val_mae: 0.4943\n",
      "Epoch 6/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0696 - mae: 0.2438 - val_loss: 0.2553 - val_mae: 0.5038\n",
      "Epoch 7/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0697 - mae: 0.2437 - val_loss: 0.2607 - val_mae: 0.5092\n",
      "Epoch 8/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0696 - mae: 0.2435 - val_loss: 0.2613 - val_mae: 0.5097\n",
      "Epoch 9/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0697 - mae: 0.2435 - val_loss: 0.2551 - val_mae: 0.5036\n",
      "Epoch 10/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0697 - mae: 0.2437 - val_loss: 0.2550 - val_mae: 0.5035\n",
      "Epoch 11/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0697 - mae: 0.2436 - val_loss: 0.2610 - val_mae: 0.5095\n",
      "Epoch 12/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0697 - mae: 0.2437 - val_loss: 0.2530 - val_mae: 0.5015\n",
      "Epoch 13/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0697 - mae: 0.2436 - val_loss: 0.2466 - val_mae: 0.4951\n",
      "Epoch 14/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0696 - mae: 0.2439 - val_loss: 0.2671 - val_mae: 0.5154\n",
      "Epoch 15/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0697 - mae: 0.2433 - val_loss: 0.2719 - val_mae: 0.5201\n",
      "Epoch 16/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0697 - mae: 0.2434 - val_loss: 0.2579 - val_mae: 0.5064\n",
      "Epoch 17/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0697 - mae: 0.2435 - val_loss: 0.2570 - val_mae: 0.5055\n",
      "Epoch 18/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0697 - mae: 0.2434 - val_loss: 0.2488 - val_mae: 0.4973\n",
      "Epoch 19/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0696 - mae: 0.2438 - val_loss: 0.2657 - val_mae: 0.5140\n",
      "Epoch 20/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0696 - mae: 0.2432 - val_loss: 0.2609 - val_mae: 0.5093\n",
      "Epoch 21/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0697 - mae: 0.2435 - val_loss: 0.2629 - val_mae: 0.5113\n",
      "Epoch 22/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0697 - mae: 0.2436 - val_loss: 0.2515 - val_mae: 0.5001\n",
      "Epoch 23/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0697 - mae: 0.2437 - val_loss: 0.2609 - val_mae: 0.5093\n",
      "Epoch 24/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0697 - mae: 0.2433 - val_loss: 0.2573 - val_mae: 0.5058\n",
      "Epoch 25/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0696 - mae: 0.2435 - val_loss: 0.2517 - val_mae: 0.5003\n",
      "Epoch 26/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0697 - mae: 0.2437 - val_loss: 0.2503 - val_mae: 0.4988\n",
      "Epoch 27/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0697 - mae: 0.2438 - val_loss: 0.2554 - val_mae: 0.5039\n",
      "Epoch 28/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0697 - mae: 0.2436 - val_loss: 0.2515 - val_mae: 0.5000\n",
      "Epoch 29/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0696 - mae: 0.2433 - val_loss: 0.2438 - val_mae: 0.4923\n",
      "Epoch 30/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0697 - mae: 0.2438 - val_loss: 0.2565 - val_mae: 0.5050\n",
      "Epoch 31/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0697 - mae: 0.2436 - val_loss: 0.2520 - val_mae: 0.5005\n",
      "Epoch 32/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0697 - mae: 0.2436 - val_loss: 0.2580 - val_mae: 0.5065\n",
      "Epoch 33/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0696 - mae: 0.2437 - val_loss: 0.2675 - val_mae: 0.5158\n",
      "Epoch 34/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0696 - mae: 0.2430 - val_loss: 0.2428 - val_mae: 0.4912\n",
      "Epoch 35/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0697 - mae: 0.2436 - val_loss: 0.2502 - val_mae: 0.4988\n",
      "Epoch 36/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0697 - mae: 0.2436 - val_loss: 0.2574 - val_mae: 0.5059\n",
      "Epoch 37/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0697 - mae: 0.2435 - val_loss: 0.2519 - val_mae: 0.5004\n",
      "Epoch 38/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0697 - mae: 0.2434 - val_loss: 0.2474 - val_mae: 0.4959\n",
      "Epoch 39/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0697 - mae: 0.2437 - val_loss: 0.2654 - val_mae: 0.5137\n",
      "Epoch 40/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0697 - mae: 0.2435 - val_loss: 0.2540 - val_mae: 0.5025\n",
      "Epoch 41/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0697 - mae: 0.2437 - val_loss: 0.2613 - val_mae: 0.5098\n",
      "Epoch 42/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0697 - mae: 0.2433 - val_loss: 0.2592 - val_mae: 0.5077\n",
      "Epoch 43/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0696 - mae: 0.2433 - val_loss: 0.2450 - val_mae: 0.4934\n",
      "Epoch 44/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0696 - mae: 0.2435 - val_loss: 0.2448 - val_mae: 0.4933\n",
      "Epoch 45/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0697 - mae: 0.2438 - val_loss: 0.2485 - val_mae: 0.4970\n",
      "Epoch 46/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0697 - mae: 0.2437 - val_loss: 0.2497 - val_mae: 0.4982\n",
      "Epoch 47/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0696 - mae: 0.2433 - val_loss: 0.2456 - val_mae: 0.4941\n",
      "Epoch 48/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0696 - mae: 0.2438 - val_loss: 0.2680 - val_mae: 0.5163\n",
      "Epoch 49/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0697 - mae: 0.2437 - val_loss: 0.2679 - val_mae: 0.5162\n",
      "Epoch 50/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0697 - mae: 0.2435 - val_loss: 0.2555 - val_mae: 0.5040\n",
      "Epoch 51/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0696 - mae: 0.2431 - val_loss: 0.2490 - val_mae: 0.4976\n",
      "Epoch 52/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0697 - mae: 0.2434 - val_loss: 0.2479 - val_mae: 0.4965\n",
      "Epoch 53/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0697 - mae: 0.2437 - val_loss: 0.2576 - val_mae: 0.5061\n",
      "Epoch 54/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0697 - mae: 0.2436 - val_loss: 0.2564 - val_mae: 0.5049\n",
      "Epoch 55/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0696 - mae: 0.2432 - val_loss: 0.2507 - val_mae: 0.4992\n",
      "Epoch 56/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0697 - mae: 0.2439 - val_loss: 0.2492 - val_mae: 0.4977\n",
      "Epoch 57/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0697 - mae: 0.2435 - val_loss: 0.2407 - val_mae: 0.4892\n",
      "Epoch 58/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0697 - mae: 0.2439 - val_loss: 0.2578 - val_mae: 0.5063\n",
      "Epoch 59/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0696 - mae: 0.2437 - val_loss: 0.2729 - val_mae: 0.5210\n",
      "Epoch 60/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0697 - mae: 0.2434 - val_loss: 0.2635 - val_mae: 0.5119\n",
      "Epoch 61/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0697 - mae: 0.2436 - val_loss: 0.2587 - val_mae: 0.5072\n",
      "Epoch 62/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0697 - mae: 0.2436 - val_loss: 0.2541 - val_mae: 0.5026\n",
      "Epoch 63/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0696 - mae: 0.2436 - val_loss: 0.2635 - val_mae: 0.5119\n",
      "Epoch 64/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0697 - mae: 0.2433 - val_loss: 0.2546 - val_mae: 0.5031\n",
      "Epoch 65/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0696 - mae: 0.2435 - val_loss: 0.2584 - val_mae: 0.5069\n",
      "Epoch 66/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0697 - mae: 0.2434 - val_loss: 0.2525 - val_mae: 0.5010\n",
      "Epoch 67/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0697 - mae: 0.2436 - val_loss: 0.2567 - val_mae: 0.5052\n",
      "Epoch 68/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0697 - mae: 0.2437 - val_loss: 0.2560 - val_mae: 0.5045\n",
      "Epoch 69/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0697 - mae: 0.2436 - val_loss: 0.2553 - val_mae: 0.5038\n",
      "Epoch 70/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0697 - mae: 0.2436 - val_loss: 0.2481 - val_mae: 0.4966\n",
      "Epoch 71/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0697 - mae: 0.2439 - val_loss: 0.2697 - val_mae: 0.5179\n",
      "Epoch 72/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0697 - mae: 0.2432 - val_loss: 0.2516 - val_mae: 0.5001\n",
      "Epoch 73/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0696 - mae: 0.2439 - val_loss: 0.2740 - val_mae: 0.5220\n",
      "Epoch 74/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0697 - mae: 0.2434 - val_loss: 0.2541 - val_mae: 0.5026\n",
      "Epoch 75/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0697 - mae: 0.2437 - val_loss: 0.2669 - val_mae: 0.5152\n",
      "Epoch 76/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0697 - mae: 0.2434 - val_loss: 0.2619 - val_mae: 0.5103\n",
      "Epoch 77/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0697 - mae: 0.2437 - val_loss: 0.2501 - val_mae: 0.4986\n",
      "Epoch 78/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0697 - mae: 0.2438 - val_loss: 0.2597 - val_mae: 0.5082\n",
      "Epoch 79/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0696 - mae: 0.2435 - val_loss: 0.2594 - val_mae: 0.5079\n",
      "Epoch 80/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0696 - mae: 0.2433 - val_loss: 0.2587 - val_mae: 0.5072\n",
      "Epoch 81/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0697 - mae: 0.2436 - val_loss: 0.2545 - val_mae: 0.5030\n",
      "Epoch 82/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0697 - mae: 0.2436 - val_loss: 0.2511 - val_mae: 0.4996\n",
      "Epoch 83/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0697 - mae: 0.2438 - val_loss: 0.2600 - val_mae: 0.5085\n",
      "Epoch 84/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0697 - mae: 0.2436 - val_loss: 0.2616 - val_mae: 0.5100\n",
      "Epoch 85/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0697 - mae: 0.2436 - val_loss: 0.2569 - val_mae: 0.5054\n",
      "Epoch 86/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0696 - mae: 0.2431 - val_loss: 0.2373 - val_mae: 0.4857\n",
      "Epoch 87/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0698 - mae: 0.2442 - val_loss: 0.2632 - val_mae: 0.5116\n",
      "Epoch 88/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0697 - mae: 0.2435 - val_loss: 0.2552 - val_mae: 0.5037\n",
      "Epoch 89/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0697 - mae: 0.2439 - val_loss: 0.2645 - val_mae: 0.5129\n",
      "Epoch 90/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0697 - mae: 0.2433 - val_loss: 0.2607 - val_mae: 0.5091\n",
      "Epoch 91/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0697 - mae: 0.2437 - val_loss: 0.2617 - val_mae: 0.5101\n",
      "Epoch 92/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0697 - mae: 0.2432 - val_loss: 0.2486 - val_mae: 0.4972\n",
      "Epoch 93/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0697 - mae: 0.2437 - val_loss: 0.2483 - val_mae: 0.4968\n",
      "Epoch 94/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0697 - mae: 0.2437 - val_loss: 0.2606 - val_mae: 0.5091\n",
      "Epoch 95/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0697 - mae: 0.2436 - val_loss: 0.2584 - val_mae: 0.5069\n",
      "Epoch 96/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0697 - mae: 0.2437 - val_loss: 0.2578 - val_mae: 0.5063\n",
      "Epoch 97/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0697 - mae: 0.2435 - val_loss: 0.2516 - val_mae: 0.5001\n",
      "Epoch 98/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0697 - mae: 0.2435 - val_loss: 0.2588 - val_mae: 0.5073\n",
      "Epoch 99/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0697 - mae: 0.2436 - val_loss: 0.2551 - val_mae: 0.5036\n",
      "Epoch 100/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0696 - mae: 0.2438 - val_loss: 0.2631 - val_mae: 0.5115\n",
      "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step   \n",
      "✅ Done with wheat_Chitradurga_daily.csv | MAE=553.97, RMSE=614.85, R2=-0.1185, MAPE=24.51%, Accuracy=75.49%\n",
      "\n",
      "🚀 Processing: wheat_Davangere_daily.csv\n",
      "Epoch 1/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - loss: 0.0346 - mae: 0.1422 - val_loss: 0.0797 - val_mae: 0.2613\n",
      "Epoch 2/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0207 - mae: 0.1149 - val_loss: 0.0811 - val_mae: 0.2637\n",
      "Epoch 3/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0208 - mae: 0.1149 - val_loss: 0.0809 - val_mae: 0.2634\n",
      "Epoch 4/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0208 - mae: 0.1149 - val_loss: 0.0832 - val_mae: 0.2676\n",
      "Epoch 5/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0208 - mae: 0.1149 - val_loss: 0.0838 - val_mae: 0.2686\n",
      "Epoch 6/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0208 - mae: 0.1148 - val_loss: 0.0827 - val_mae: 0.2668\n",
      "Epoch 7/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0208 - mae: 0.1149 - val_loss: 0.0836 - val_mae: 0.2683\n",
      "Epoch 8/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0208 - mae: 0.1149 - val_loss: 0.0815 - val_mae: 0.2645\n",
      "Epoch 9/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0208 - mae: 0.1148 - val_loss: 0.0795 - val_mae: 0.2609\n",
      "Epoch 10/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0208 - mae: 0.1150 - val_loss: 0.0800 - val_mae: 0.2618\n",
      "Epoch 11/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0208 - mae: 0.1148 - val_loss: 0.0808 - val_mae: 0.2633\n",
      "Epoch 12/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0208 - mae: 0.1150 - val_loss: 0.0813 - val_mae: 0.2641\n",
      "Epoch 13/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0208 - mae: 0.1149 - val_loss: 0.0800 - val_mae: 0.2617\n",
      "Epoch 14/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0208 - mae: 0.1150 - val_loss: 0.0809 - val_mae: 0.2634\n",
      "Epoch 15/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0207 - mae: 0.1148 - val_loss: 0.0842 - val_mae: 0.2694\n",
      "Epoch 16/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0207 - mae: 0.1146 - val_loss: 0.0761 - val_mae: 0.2544\n",
      "Epoch 17/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0208 - mae: 0.1150 - val_loss: 0.0779 - val_mae: 0.2578\n",
      "Epoch 18/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0208 - mae: 0.1148 - val_loss: 0.0754 - val_mae: 0.2532\n",
      "Epoch 19/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0208 - mae: 0.1150 - val_loss: 0.0796 - val_mae: 0.2610\n",
      "Epoch 20/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0208 - mae: 0.1149 - val_loss: 0.0817 - val_mae: 0.2648\n",
      "Epoch 21/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0207 - mae: 0.1149 - val_loss: 0.0864 - val_mae: 0.2733\n",
      "Epoch 22/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0208 - mae: 0.1148 - val_loss: 0.0806 - val_mae: 0.2629\n",
      "Epoch 23/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0208 - mae: 0.1149 - val_loss: 0.0770 - val_mae: 0.2561\n",
      "Epoch 24/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0208 - mae: 0.1150 - val_loss: 0.0812 - val_mae: 0.2640\n",
      "Epoch 25/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0207 - mae: 0.1148 - val_loss: 0.0772 - val_mae: 0.2566\n",
      "Epoch 26/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0207 - mae: 0.1149 - val_loss: 0.0820 - val_mae: 0.2654\n",
      "Epoch 27/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0208 - mae: 0.1150 - val_loss: 0.0847 - val_mae: 0.2703\n",
      "Epoch 28/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0208 - mae: 0.1148 - val_loss: 0.0817 - val_mae: 0.2649\n",
      "Epoch 29/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0208 - mae: 0.1148 - val_loss: 0.0780 - val_mae: 0.2580\n",
      "Epoch 30/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0208 - mae: 0.1148 - val_loss: 0.0766 - val_mae: 0.2555\n",
      "Epoch 31/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0208 - mae: 0.1150 - val_loss: 0.0830 - val_mae: 0.2673\n",
      "Epoch 32/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0208 - mae: 0.1149 - val_loss: 0.0811 - val_mae: 0.2639\n",
      "Epoch 33/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0208 - mae: 0.1147 - val_loss: 0.0793 - val_mae: 0.2604\n",
      "Epoch 34/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0208 - mae: 0.1148 - val_loss: 0.0760 - val_mae: 0.2543\n",
      "Epoch 35/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0208 - mae: 0.1151 - val_loss: 0.0813 - val_mae: 0.2641\n",
      "Epoch 36/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0208 - mae: 0.1149 - val_loss: 0.0793 - val_mae: 0.2606\n",
      "Epoch 37/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0208 - mae: 0.1150 - val_loss: 0.0801 - val_mae: 0.2620\n",
      "Epoch 38/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0208 - mae: 0.1148 - val_loss: 0.0820 - val_mae: 0.2655\n",
      "Epoch 39/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0207 - mae: 0.1150 - val_loss: 0.0868 - val_mae: 0.2740\n",
      "Epoch 40/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0208 - mae: 0.1147 - val_loss: 0.0766 - val_mae: 0.2555\n",
      "Epoch 41/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0208 - mae: 0.1150 - val_loss: 0.0785 - val_mae: 0.2589\n",
      "Epoch 42/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0208 - mae: 0.1149 - val_loss: 0.0798 - val_mae: 0.2614\n",
      "Epoch 43/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0208 - mae: 0.1149 - val_loss: 0.0826 - val_mae: 0.2664\n",
      "Epoch 44/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0208 - mae: 0.1148 - val_loss: 0.0789 - val_mae: 0.2597\n",
      "Epoch 45/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0208 - mae: 0.1148 - val_loss: 0.0795 - val_mae: 0.2609\n",
      "Epoch 46/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0208 - mae: 0.1150 - val_loss: 0.0808 - val_mae: 0.2632\n",
      "Epoch 47/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0208 - mae: 0.1149 - val_loss: 0.0802 - val_mae: 0.2621\n",
      "Epoch 48/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0207 - mae: 0.1148 - val_loss: 0.0817 - val_mae: 0.2649\n",
      "Epoch 49/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0208 - mae: 0.1149 - val_loss: 0.0816 - val_mae: 0.2646\n",
      "Epoch 50/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0207 - mae: 0.1146 - val_loss: 0.0741 - val_mae: 0.2506\n",
      "Epoch 51/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0208 - mae: 0.1150 - val_loss: 0.0797 - val_mae: 0.2613\n",
      "Epoch 52/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0208 - mae: 0.1149 - val_loss: 0.0770 - val_mae: 0.2562\n",
      "Epoch 53/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0208 - mae: 0.1151 - val_loss: 0.0828 - val_mae: 0.2669\n",
      "Epoch 54/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0208 - mae: 0.1147 - val_loss: 0.0804 - val_mae: 0.2624\n",
      "Epoch 55/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0208 - mae: 0.1150 - val_loss: 0.0803 - val_mae: 0.2623\n",
      "Epoch 56/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0208 - mae: 0.1149 - val_loss: 0.0821 - val_mae: 0.2655\n",
      "Epoch 57/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0208 - mae: 0.1150 - val_loss: 0.0839 - val_mae: 0.2688\n",
      "Epoch 58/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0208 - mae: 0.1147 - val_loss: 0.0803 - val_mae: 0.2623\n",
      "Epoch 59/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0208 - mae: 0.1150 - val_loss: 0.0813 - val_mae: 0.2642\n",
      "Epoch 60/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0208 - mae: 0.1148 - val_loss: 0.0833 - val_mae: 0.2678\n",
      "Epoch 61/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0208 - mae: 0.1149 - val_loss: 0.0839 - val_mae: 0.2688\n",
      "Epoch 62/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0208 - mae: 0.1148 - val_loss: 0.0831 - val_mae: 0.2674\n",
      "Epoch 63/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0208 - mae: 0.1150 - val_loss: 0.0831 - val_mae: 0.2674\n",
      "Epoch 64/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0208 - mae: 0.1149 - val_loss: 0.0821 - val_mae: 0.2657\n",
      "Epoch 65/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0208 - mae: 0.1147 - val_loss: 0.0781 - val_mae: 0.2583\n",
      "Epoch 66/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0208 - mae: 0.1148 - val_loss: 0.0790 - val_mae: 0.2600\n",
      "Epoch 67/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0208 - mae: 0.1151 - val_loss: 0.0855 - val_mae: 0.2716\n",
      "Epoch 68/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0208 - mae: 0.1148 - val_loss: 0.0806 - val_mae: 0.2628\n",
      "Epoch 69/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0208 - mae: 0.1149 - val_loss: 0.0829 - val_mae: 0.2670\n",
      "Epoch 70/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0208 - mae: 0.1149 - val_loss: 0.0806 - val_mae: 0.2628\n",
      "Epoch 71/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0208 - mae: 0.1149 - val_loss: 0.0789 - val_mae: 0.2597\n",
      "Epoch 72/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0208 - mae: 0.1151 - val_loss: 0.0832 - val_mae: 0.2676\n",
      "Epoch 73/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0208 - mae: 0.1148 - val_loss: 0.0789 - val_mae: 0.2598\n",
      "Epoch 74/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0207 - mae: 0.1149 - val_loss: 0.0821 - val_mae: 0.2657\n",
      "Epoch 75/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0208 - mae: 0.1147 - val_loss: 0.0787 - val_mae: 0.2595\n",
      "Epoch 76/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0208 - mae: 0.1151 - val_loss: 0.0854 - val_mae: 0.2715\n",
      "Epoch 77/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0207 - mae: 0.1148 - val_loss: 0.0781 - val_mae: 0.2583\n",
      "Epoch 78/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0207 - mae: 0.1147 - val_loss: 0.0741 - val_mae: 0.2507\n",
      "Epoch 79/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0208 - mae: 0.1150 - val_loss: 0.0830 - val_mae: 0.2672\n",
      "Epoch 80/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0208 - mae: 0.1149 - val_loss: 0.0823 - val_mae: 0.2660\n",
      "Epoch 81/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0208 - mae: 0.1148 - val_loss: 0.0816 - val_mae: 0.2648\n",
      "Epoch 82/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0208 - mae: 0.1149 - val_loss: 0.0826 - val_mae: 0.2666\n",
      "Epoch 83/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0208 - mae: 0.1149 - val_loss: 0.0801 - val_mae: 0.2620\n",
      "Epoch 84/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0208 - mae: 0.1148 - val_loss: 0.0776 - val_mae: 0.2574\n",
      "Epoch 85/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0208 - mae: 0.1150 - val_loss: 0.0837 - val_mae: 0.2685\n",
      "Epoch 86/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0208 - mae: 0.1148 - val_loss: 0.0793 - val_mae: 0.2606\n",
      "Epoch 87/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0208 - mae: 0.1149 - val_loss: 0.0845 - val_mae: 0.2700\n",
      "Epoch 88/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0207 - mae: 0.1148 - val_loss: 0.0828 - val_mae: 0.2670\n",
      "Epoch 89/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0208 - mae: 0.1148 - val_loss: 0.0842 - val_mae: 0.2694\n",
      "Epoch 90/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0208 - mae: 0.1148 - val_loss: 0.0816 - val_mae: 0.2647\n",
      "Epoch 91/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0208 - mae: 0.1149 - val_loss: 0.0801 - val_mae: 0.2620\n",
      "Epoch 92/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0208 - mae: 0.1149 - val_loss: 0.0805 - val_mae: 0.2626\n",
      "Epoch 93/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0207 - mae: 0.1148 - val_loss: 0.0801 - val_mae: 0.2620\n",
      "Epoch 94/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0207 - mae: 0.1148 - val_loss: 0.0786 - val_mae: 0.2591\n",
      "Epoch 95/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0207 - mae: 0.1148 - val_loss: 0.0776 - val_mae: 0.2572\n",
      "Epoch 96/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0208 - mae: 0.1148 - val_loss: 0.0771 - val_mae: 0.2563\n",
      "Epoch 97/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0208 - mae: 0.1150 - val_loss: 0.0825 - val_mae: 0.2663\n",
      "Epoch 98/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0208 - mae: 0.1148 - val_loss: 0.0816 - val_mae: 0.2647\n",
      "Epoch 99/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0208 - mae: 0.1150 - val_loss: 0.0844 - val_mae: 0.2697\n",
      "Epoch 100/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0208 - mae: 0.1149 - val_loss: 0.0822 - val_mae: 0.2658\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step\n",
      "✅ Done with wheat_Davangere_daily.csv | MAE=440.54, RMSE=554.13, R2=-0.0999, MAPE=21.88%, Accuracy=78.12%\n",
      "\n",
      "🚀 Processing: wheat_Dharwad_daily.csv\n",
      "Epoch 1/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - loss: 0.0120 - mae: 0.0788 - val_loss: 0.0424 - val_mae: 0.1659\n",
      "Epoch 2/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0092 - mae: 0.0700 - val_loss: 0.0424 - val_mae: 0.1659\n",
      "Epoch 3/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0093 - mae: 0.0700 - val_loss: 0.0447 - val_mae: 0.1714\n",
      "Epoch 4/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0093 - mae: 0.0700 - val_loss: 0.0448 - val_mae: 0.1717\n",
      "Epoch 5/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 0.0093 - mae: 0.0701 - val_loss: 0.0406 - val_mae: 0.1615\n",
      "Epoch 6/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0093 - mae: 0.0701 - val_loss: 0.0443 - val_mae: 0.1703\n",
      "Epoch 7/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 0.0093 - mae: 0.0700 - val_loss: 0.0429 - val_mae: 0.1671\n",
      "Epoch 8/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0093 - mae: 0.0701 - val_loss: 0.0443 - val_mae: 0.1705\n",
      "Epoch 9/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - loss: 0.0093 - mae: 0.0700 - val_loss: 0.0436 - val_mae: 0.1687\n",
      "Epoch 10/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0093 - mae: 0.0700 - val_loss: 0.0431 - val_mae: 0.1676\n",
      "Epoch 11/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - loss: 0.0093 - mae: 0.0701 - val_loss: 0.0435 - val_mae: 0.1685\n",
      "Epoch 12/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0092 - mae: 0.0700 - val_loss: 0.0423 - val_mae: 0.1657\n",
      "Epoch 13/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0093 - mae: 0.0701 - val_loss: 0.0443 - val_mae: 0.1704\n",
      "Epoch 14/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - loss: 0.0092 - mae: 0.0700 - val_loss: 0.0433 - val_mae: 0.1681\n",
      "Epoch 15/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0093 - mae: 0.0701 - val_loss: 0.0438 - val_mae: 0.1693\n",
      "Epoch 16/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0093 - mae: 0.0701 - val_loss: 0.0419 - val_mae: 0.1647\n",
      "Epoch 17/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - loss: 0.0093 - mae: 0.0701 - val_loss: 0.0446 - val_mae: 0.1711\n",
      "Epoch 18/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0093 - mae: 0.0700 - val_loss: 0.0458 - val_mae: 0.1742\n",
      "Epoch 19/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 0.0093 - mae: 0.0700 - val_loss: 0.0418 - val_mae: 0.1644\n",
      "Epoch 20/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0093 - mae: 0.0701 - val_loss: 0.0493 - val_mae: 0.1826\n",
      "Epoch 21/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0093 - mae: 0.0700 - val_loss: 0.0440 - val_mae: 0.1697\n",
      "Epoch 22/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0093 - mae: 0.0700 - val_loss: 0.0423 - val_mae: 0.1657\n",
      "Epoch 23/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - loss: 0.0093 - mae: 0.0701 - val_loss: 0.0444 - val_mae: 0.1706\n",
      "Epoch 24/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0093 - mae: 0.0700 - val_loss: 0.0427 - val_mae: 0.1666\n",
      "Epoch 25/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0093 - mae: 0.0700 - val_loss: 0.0446 - val_mae: 0.1712\n",
      "Epoch 26/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0093 - mae: 0.0700 - val_loss: 0.0441 - val_mae: 0.1700\n",
      "Epoch 27/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0093 - mae: 0.0700 - val_loss: 0.0448 - val_mae: 0.1718\n",
      "Epoch 28/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0092 - mae: 0.0700 - val_loss: 0.0451 - val_mae: 0.1725\n",
      "Epoch 29/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0093 - mae: 0.0700 - val_loss: 0.0448 - val_mae: 0.1718\n",
      "Epoch 30/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0093 - mae: 0.0700 - val_loss: 0.0454 - val_mae: 0.1730\n",
      "Epoch 31/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 0.0093 - mae: 0.0700 - val_loss: 0.0412 - val_mae: 0.1629\n",
      "Epoch 32/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0093 - mae: 0.0700 - val_loss: 0.0459 - val_mae: 0.1743\n",
      "Epoch 33/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - loss: 0.0093 - mae: 0.0700 - val_loss: 0.0444 - val_mae: 0.1707\n",
      "Epoch 34/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - loss: 0.0093 - mae: 0.0700 - val_loss: 0.0424 - val_mae: 0.1657\n",
      "Epoch 35/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0093 - mae: 0.0700 - val_loss: 0.0419 - val_mae: 0.1645\n",
      "Epoch 36/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0092 - mae: 0.0700 - val_loss: 0.0424 - val_mae: 0.1657\n",
      "Epoch 37/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0093 - mae: 0.0700 - val_loss: 0.0439 - val_mae: 0.1694\n",
      "Epoch 38/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0093 - mae: 0.0700 - val_loss: 0.0445 - val_mae: 0.1709\n",
      "Epoch 39/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0093 - mae: 0.0700 - val_loss: 0.0443 - val_mae: 0.1704\n",
      "Epoch 40/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0093 - mae: 0.0700 - val_loss: 0.0445 - val_mae: 0.1710\n",
      "Epoch 41/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - loss: 0.0093 - mae: 0.0700 - val_loss: 0.0419 - val_mae: 0.1647\n",
      "Epoch 42/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0092 - mae: 0.0700 - val_loss: 0.0420 - val_mae: 0.1649\n",
      "Epoch 43/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0092 - mae: 0.0699 - val_loss: 0.0405 - val_mae: 0.1612\n",
      "Epoch 44/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - loss: 0.0093 - mae: 0.0701 - val_loss: 0.0462 - val_mae: 0.1750\n",
      "Epoch 45/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0093 - mae: 0.0700 - val_loss: 0.0458 - val_mae: 0.1741\n",
      "Epoch 46/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0093 - mae: 0.0700 - val_loss: 0.0425 - val_mae: 0.1660\n",
      "Epoch 47/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - loss: 0.0093 - mae: 0.0700 - val_loss: 0.0430 - val_mae: 0.1673\n",
      "Epoch 48/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0093 - mae: 0.0701 - val_loss: 0.0443 - val_mae: 0.1705\n",
      "Epoch 49/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - loss: 0.0093 - mae: 0.0700 - val_loss: 0.0443 - val_mae: 0.1704\n",
      "Epoch 50/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0093 - mae: 0.0700 - val_loss: 0.0432 - val_mae: 0.1678\n",
      "Epoch 51/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0093 - mae: 0.0700 - val_loss: 0.0426 - val_mae: 0.1662\n",
      "Epoch 52/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0093 - mae: 0.0700 - val_loss: 0.0427 - val_mae: 0.1666\n",
      "Epoch 53/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0092 - mae: 0.0700 - val_loss: 0.0445 - val_mae: 0.1710\n",
      "Epoch 54/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0093 - mae: 0.0701 - val_loss: 0.0450 - val_mae: 0.1722\n",
      "Epoch 55/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0093 - mae: 0.0701 - val_loss: 0.0429 - val_mae: 0.1671\n",
      "Epoch 56/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - loss: 0.0092 - mae: 0.0700 - val_loss: 0.0423 - val_mae: 0.1655\n",
      "Epoch 57/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0092 - mae: 0.0700 - val_loss: 0.0444 - val_mae: 0.1708\n",
      "Epoch 58/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0092 - mae: 0.0700 - val_loss: 0.0435 - val_mae: 0.1685\n",
      "Epoch 59/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0093 - mae: 0.0700 - val_loss: 0.0441 - val_mae: 0.1699\n",
      "Epoch 60/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - loss: 0.0092 - mae: 0.0700 - val_loss: 0.0460 - val_mae: 0.1745\n",
      "Epoch 61/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - loss: 0.0093 - mae: 0.0701 - val_loss: 0.0450 - val_mae: 0.1722\n",
      "Epoch 62/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - loss: 0.0092 - mae: 0.0700 - val_loss: 0.0441 - val_mae: 0.1700\n",
      "Epoch 63/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - loss: 0.0093 - mae: 0.0700 - val_loss: 0.0424 - val_mae: 0.1658\n",
      "Epoch 64/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0093 - mae: 0.0701 - val_loss: 0.0460 - val_mae: 0.1746\n",
      "Epoch 65/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 0.0245 - mae: 0.1140 - val_loss: 0.0581 - val_mae: 0.2079\n",
      "\u001b[1m497/497\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step\n",
      "✅ Done with wheat_Haveri_daily.csv | MAE=318.34, RMSE=426.09, R2=-0.0543, MAPE=17.52%, Accuracy=82.48%\n",
      "\n",
      "🚀 Processing: wheat_Kalburgi_daily.csv\n",
      "Epoch 1/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 13ms/step - loss: 0.0391 - mae: 0.1533 - val_loss: 0.0446 - val_mae: 0.1543\n",
      "Epoch 2/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0221 - mae: 0.1166 - val_loss: 0.0473 - val_mae: 0.1629\n",
      "Epoch 3/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0222 - mae: 0.1165 - val_loss: 0.0439 - val_mae: 0.1522\n",
      "Epoch 4/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0222 - mae: 0.1166 - val_loss: 0.0466 - val_mae: 0.1607\n",
      "Epoch 5/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0222 - mae: 0.1165 - val_loss: 0.0429 - val_mae: 0.1488\n",
      "Epoch 6/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0222 - mae: 0.1167 - val_loss: 0.0437 - val_mae: 0.1516\n",
      "Epoch 7/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0222 - mae: 0.1166 - val_loss: 0.0428 - val_mae: 0.1484\n",
      "Epoch 8/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0222 - mae: 0.1168 - val_loss: 0.0438 - val_mae: 0.1518\n",
      "Epoch 9/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0222 - mae: 0.1167 - val_loss: 0.0436 - val_mae: 0.1512\n",
      "Epoch 10/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0222 - mae: 0.1167 - val_loss: 0.0436 - val_mae: 0.1512\n",
      "Epoch 11/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0222 - mae: 0.1165 - val_loss: 0.0429 - val_mae: 0.1489\n",
      "Epoch 12/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0222 - mae: 0.1167 - val_loss: 0.0422 - val_mae: 0.1466\n",
      "Epoch 13/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0222 - mae: 0.1169 - val_loss: 0.0438 - val_mae: 0.1517\n",
      "Epoch 14/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0222 - mae: 0.1169 - val_loss: 0.0452 - val_mae: 0.1563\n",
      "Epoch 33/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0222 - mae: 0.1166 - val_loss: 0.0441 - val_mae: 0.1529\n",
      "Epoch 34/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0222 - mae: 0.1167 - val_loss: 0.0446 - val_mae: 0.1544\n",
      "Epoch 35/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0222 - mae: 0.1168 - val_loss: 0.0419 - val_mae: 0.1456\n",
      "Epoch 36/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0222 - mae: 0.1167 - val_loss: 0.0433 - val_mae: 0.1500\n",
      "Epoch 37/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0222 - mae: 0.1167 - val_loss: 0.0441 - val_mae: 0.1528\n",
      "Epoch 38/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0222 - mae: 0.1168 - val_loss: 0.0435 - val_mae: 0.1508\n",
      "Epoch 39/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0222 - mae: 0.1167 - val_loss: 0.0446 - val_mae: 0.1544\n",
      "Epoch 40/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0222 - mae: 0.1166 - val_loss: 0.0421 - val_mae: 0.1461\n",
      "Epoch 41/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0222 - mae: 0.1168 - val_loss: 0.0437 - val_mae: 0.1515\n",
      "Epoch 42/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0222 - mae: 0.1166 - val_loss: 0.0442 - val_mae: 0.1533\n",
      "Epoch 43/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0222 - mae: 0.1166 - val_loss: 0.0445 - val_mae: 0.1542\n",
      "Epoch 44/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0222 - mae: 0.1166 - val_loss: 0.0457 - val_mae: 0.1579\n",
      "Epoch 45/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0222 - mae: 0.1166 - val_loss: 0.0450 - val_mae: 0.1559\n",
      "Epoch 46/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0222 - mae: 0.1168 - val_loss: 0.0417 - val_mae: 0.1450\n",
      "Epoch 47/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0222 - mae: 0.1168 - val_loss: 0.0435 - val_mae: 0.1510\n",
      "Epoch 81/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0222 - mae: 0.1167 - val_loss: 0.0445 - val_mae: 0.1540\n",
      "Epoch 82/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0222 - mae: 0.1165 - val_loss: 0.0436 - val_mae: 0.1513\n",
      "Epoch 83/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0222 - mae: 0.1168 - val_loss: 0.0433 - val_mae: 0.1502\n",
      "Epoch 84/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0222 - mae: 0.1168 - val_loss: 0.0462 - val_mae: 0.1594\n",
      "Epoch 85/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0222 - mae: 0.1167 - val_loss: 0.0431 - val_mae: 0.1494\n",
      "Epoch 86/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0222 - mae: 0.1167 - val_loss: 0.0439 - val_mae: 0.1522\n",
      "Epoch 87/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0222 - mae: 0.1165 - val_loss: 0.0442 - val_mae: 0.1532\n",
      "Epoch 88/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0222 - mae: 0.1168 - val_loss: 0.0447 - val_mae: 0.1546\n",
      "Epoch 89/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0222 - mae: 0.1166 - val_loss: 0.0462 - val_mae: 0.1595\n",
      "Epoch 90/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0222 - mae: 0.1166 - val_loss: 0.0446 - val_mae: 0.1545\n",
      "Epoch 91/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0222 - mae: 0.1165 - val_loss: 0.0414 - val_mae: 0.1438\n",
      "Epoch 92/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0222 - mae: 0.1168 - val_loss: 0.0443 - val_mae: 0.1533\n",
      "Epoch 93/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0222 - mae: 0.1166 - val_loss: 0.0438 - val_mae: 0.1517\n",
      "Epoch 94/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0222 - mae: 0.1167 - val_loss: 0.0447 - val_mae: 0.1549\n",
      "Epoch 95/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0222 - mae: 0.1166 - val_loss: 0.0434 - val_mae: 0.1505\n",
      "Epoch 96/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0158 - mae: 0.1036 - val_loss: 0.0864 - val_mae: 0.2388\n",
      "Epoch 32/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0158 - mae: 0.1037 - val_loss: 0.0806 - val_mae: 0.2274\n",
      "Epoch 33/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0158 - mae: 0.1036 - val_loss: 0.0843 - val_mae: 0.2345\n",
      "Epoch 34/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0158 - mae: 0.1036 - val_loss: 0.0880 - val_mae: 0.2420\n",
      "Epoch 35/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0158 - mae: 0.1036 - val_loss: 0.0838 - val_mae: 0.2335\n",
      "Epoch 36/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0158 - mae: 0.1037 - val_loss: 0.0855 - val_mae: 0.2369\n",
      "Epoch 37/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0158 - mae: 0.1036 - val_loss: 0.0801 - val_mae: 0.2265\n",
      "Epoch 38/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0158 - mae: 0.1035 - val_loss: 0.0885 - val_mae: 0.2430\n",
      "Epoch 39/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0158 - mae: 0.1037 - val_loss: 0.0881 - val_mae: 0.2424\n",
      "Epoch 40/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0158 - mae: 0.1036 - val_loss: 0.0875 - val_mae: 0.2411\n",
      "Epoch 41/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0158 - mae: 0.1036 - val_loss: 0.0842 - val_mae: 0.2343\n",
      "Epoch 42/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0158 - mae: 0.1036 - val_loss: 0.0870 - val_mae: 0.2401\n",
      "Epoch 43/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0158 - mae: 0.1036 - val_loss: 0.0820 - val_mae: 0.2299\n",
      "Epoch 44/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0158 - mae: 0.1037 - val_loss: 0.0850 - val_mae: 0.2359\n",
      "Epoch 45/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0158 - mae: 0.1036 - val_loss: 0.0852 - val_mae: 0.2363\n",
      "Epoch 46/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0158 - mae: 0.1037 - val_loss: 0.0838 - val_mae: 0.2336\n",
      "Epoch 47/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0158 - mae: 0.1036 - val_loss: 0.0860 - val_mae: 0.2379\n",
      "Epoch 48/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0158 - mae: 0.1036 - val_loss: 0.0872 - val_mae: 0.2403\n",
      "Epoch 97/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0158 - mae: 0.1036 - val_loss: 0.0847 - val_mae: 0.2354\n",
      "Epoch 98/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0158 - mae: 0.1035 - val_loss: 0.0888 - val_mae: 0.2437\n",
      "Epoch 99/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0158 - mae: 0.1036 - val_loss: 0.0882 - val_mae: 0.2426\n",
      "Epoch 100/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0158 - mae: 0.1037 - val_loss: 0.0845 - val_mae: 0.2348\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step\n",
      "✅ Done with wheat_Kolar_daily.csv | MAE=427.61, RMSE=566.8, R2=-0.0695, MAPE=20.23%, Accuracy=79.77%\n",
      "\n",
      "🚀 Processing: wheat_Koppal_daily.csv\n",
      "Epoch 1/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0324 - mae: 0.1395 - val_loss: 0.0950 - val_mae: 0.2761\n",
      "Epoch 2/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0271 - mae: 0.1312 - val_loss: 0.0964 - val_mae: 0.2786\n",
      "Epoch 3/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0271 - mae: 0.1312 - val_loss: 0.1021 - val_mae: 0.2887\n",
      "Epoch 4/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0271 - mae: 0.1311 - val_loss: 0.0952 - val_mae: 0.2764\n",
      "Epoch 5/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0271 - mae: 0.1312 - val_loss: 0.0921 - val_mae: 0.2707\n",
      "Epoch 6/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0271 - mae: 0.1312 - val_loss: 0.0970 - val_mae: 0.2796\n",
      "Epoch 7/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0271 - mae: 0.1312 - val_loss: 0.0926 - val_mae: 0.2717\n",
      "Epoch 8/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0271 - mae: 0.1312 - val_loss: 0.0956 - val_mae: 0.2772\n",
      "Epoch 9/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0271 - mae: 0.1312 - val_loss: 0.0950 - val_mae: 0.2760\n",
      "Epoch 31/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0271 - mae: 0.1311 - val_loss: 0.0975 - val_mae: 0.2805\n",
      "Epoch 32/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0271 - mae: 0.1312 - val_loss: 0.0960 - val_mae: 0.2778\n",
      "Epoch 33/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0271 - mae: 0.1312 - val_loss: 0.0954 - val_mae: 0.2769\n",
      "Epoch 34/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0271 - mae: 0.1312 - val_loss: 0.1034 - val_mae: 0.2909\n",
      "Epoch 35/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0271 - mae: 0.1311 - val_loss: 0.0975 - val_mae: 0.2806\n",
      "Epoch 36/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0271 - mae: 0.1311 - val_loss: 0.0886 - val_mae: 0.2641\n",
      "Epoch 37/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0271 - mae: 0.1312 - val_loss: 0.0929 - val_mae: 0.2722\n",
      "Epoch 38/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0271 - mae: 0.1311 - val_loss: 0.0912 - val_mae: 0.2691\n",
      "Epoch 39/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0271 - mae: 0.1313 - val_loss: 0.1054 - val_mae: 0.2944\n",
      "Epoch 40/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0271 - mae: 0.1311 - val_loss: 0.0983 - val_mae: 0.2820\n",
      "Epoch 41/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0271 - mae: 0.1312 - val_loss: 0.0985 - val_mae: 0.2823\n",
      "Epoch 42/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0271 - mae: 0.1312 - val_loss: 0.0924 - val_mae: 0.2713\n",
      "Epoch 43/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0271 - mae: 0.1312 - val_loss: 0.0962 - val_mae: 0.2783\n",
      "Epoch 68/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0271 - mae: 0.1313 - val_loss: 0.1004 - val_mae: 0.2856\n",
      "Epoch 69/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0271 - mae: 0.1312 - val_loss: 0.0926 - val_mae: 0.2717\n",
      "Epoch 70/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - loss: 0.0271 - mae: 0.1311 - val_loss: 0.0913 - val_mae: 0.2693\n",
      "Epoch 71/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0271 - mae: 0.1313 - val_loss: 0.0974 - val_mae: 0.2804\n",
      "Epoch 72/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0271 - mae: 0.1313 - val_loss: 0.1028 - val_mae: 0.2899\n",
      "Epoch 73/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0271 - mae: 0.1311 - val_loss: 0.0967 - val_mae: 0.2791\n",
      "Epoch 74/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0271 - mae: 0.1311 - val_loss: 0.0946 - val_mae: 0.2753\n",
      "Epoch 75/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0271 - mae: 0.1311 - val_loss: 0.0885 - val_mae: 0.2641\n",
      "Epoch 76/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0271 - mae: 0.1313 - val_loss: 0.0925 - val_mae: 0.2715\n",
      "Epoch 77/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0271 - mae: 0.1313 - val_loss: 0.1012 - val_mae: 0.2871\n",
      "Epoch 78/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0271 - mae: 0.1312 - val_loss: 0.0966 - val_mae: 0.2789\n",
      "Epoch 79/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0271 - mae: 0.1312 - val_loss: 0.1000 - val_mae: 0.2849\n",
      "Epoch 80/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1112 - mae: 0.2914 - val_loss: 0.1004 - val_mae: 0.3077\n",
      "Epoch 32/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1112 - mae: 0.2913 - val_loss: 0.0950 - val_mae: 0.2987\n",
      "Epoch 33/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1111 - mae: 0.2915 - val_loss: 0.0943 - val_mae: 0.2976\n",
      "Epoch 34/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1113 - mae: 0.2916 - val_loss: 0.0930 - val_mae: 0.2954\n",
      "Epoch 35/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1112 - mae: 0.2914 - val_loss: 0.0923 - val_mae: 0.2942\n",
      "Epoch 36/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1111 - mae: 0.2915 - val_loss: 0.1003 - val_mae: 0.3076\n",
      "Epoch 37/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1111 - mae: 0.2911 - val_loss: 0.0898 - val_mae: 0.2900\n",
      "Epoch 38/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1112 - mae: 0.2916 - val_loss: 0.0955 - val_mae: 0.2997\n",
      "Epoch 39/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1111 - mae: 0.2915 - val_loss: 0.0971 - val_mae: 0.3023\n",
      "Epoch 40/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1111 - mae: 0.2912 - val_loss: 0.0944 - val_mae: 0.2977\n",
      "Epoch 41/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1111 - mae: 0.2917 - val_loss: 0.1036 - val_mae: 0.3128\n",
      "Epoch 42/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1112 - mae: 0.2915 - val_loss: 0.1011 - val_mae: 0.3088\n",
      "Epoch 43/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1112 - mae: 0.2905 - val_loss: 0.0868 - val_mae: 0.2847\n",
      "Epoch 44/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1112 - mae: 0.2920 - val_loss: 0.0977 - val_mae: 0.3032\n",
      "Epoch 45/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1112 - mae: 0.2914 - val_loss: 0.0963 - val_mae: 0.3010\n",
      "Epoch 46/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1111 - mae: 0.2913 - val_loss: 0.0941 - val_mae: 0.2973\n",
      "Epoch 47/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1110 - mae: 0.2907 - val_loss: 0.0863 - val_mae: 0.2839\n",
      "Epoch 48/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1111 - mae: 0.2920 - val_loss: 0.1036 - val_mae: 0.3128\n",
      "Epoch 49/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1112 - mae: 0.2910 - val_loss: 0.0940 - val_mae: 0.2970\n",
      "Epoch 50/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1112 - mae: 0.2913 - val_loss: 0.0913 - val_mae: 0.2925\n",
      "Epoch 51/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1111 - mae: 0.2916 - val_loss: 0.0976 - val_mae: 0.3031\n",
      "Epoch 52/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1112 - mae: 0.2915 - val_loss: 0.0996 - val_mae: 0.3063\n",
      "Epoch 53/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.1111 - mae: 0.2914 - val_loss: 0.0972 - val_mae: 0.3025\n",
      "Epoch 54/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1111 - mae: 0.2915 - val_loss: 0.0987 - val_mae: 0.3048\n",
      "Epoch 55/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1111 - mae: 0.2913 - val_loss: 0.0938 - val_mae: 0.2968\n",
      "Epoch 56/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1112 - mae: 0.2913 - val_loss: 0.0936 - val_mae: 0.2964\n",
      "Epoch 57/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1111 - mae: 0.2916 - val_loss: 0.0988 - val_mae: 0.3051\n",
      "Epoch 58/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1112 - mae: 0.2914 - val_loss: 0.0935 - val_mae: 0.2963\n",
      "Epoch 59/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1111 - mae: 0.2912 - val_loss: 0.0913 - val_mae: 0.2925\n",
      "Epoch 60/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1112 - mae: 0.2915 - val_loss: 0.0942 - val_mae: 0.2973\n",
      "Epoch 61/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1111 - mae: 0.2914 - val_loss: 0.0972 - val_mae: 0.3024\n",
      "Epoch 62/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1111 - mae: 0.2910 - val_loss: 0.0930 - val_mae: 0.2954\n",
      "Epoch 63/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1113 - mae: 0.2917 - val_loss: 0.0938 - val_mae: 0.2968\n",
      "Epoch 64/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1111 - mae: 0.2916 - val_loss: 0.0992 - val_mae: 0.3057\n",
      "Epoch 65/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1111 - mae: 0.2913 - val_loss: 0.0965 - val_mae: 0.3013\n",
      "Epoch 66/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1111 - mae: 0.2913 - val_loss: 0.0942 - val_mae: 0.2975\n",
      "Epoch 67/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1111 - mae: 0.2914 - val_loss: 0.0929 - val_mae: 0.2953\n",
      "Epoch 68/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1112 - mae: 0.2915 - val_loss: 0.0926 - val_mae: 0.2947\n",
      "Epoch 69/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1111 - mae: 0.2916 - val_loss: 0.0976 - val_mae: 0.3031\n",
      "Epoch 70/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1112 - mae: 0.2914 - val_loss: 0.0972 - val_mae: 0.3025\n",
      "Epoch 71/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1111 - mae: 0.2914 - val_loss: 0.0942 - val_mae: 0.2975\n",
      "Epoch 72/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1111 - mae: 0.2916 - val_loss: 0.1008 - val_mae: 0.3082\n",
      "Epoch 73/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1111 - mae: 0.2913 - val_loss: 0.0955 - val_mae: 0.2996\n",
      "Epoch 74/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0524 - mae: 0.1853 - val_loss: 0.0452 - val_mae: 0.1674\n",
      "Epoch 78/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0524 - mae: 0.1873 - val_loss: 0.0450 - val_mae: 0.1669\n",
      "Epoch 79/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0524 - mae: 0.1873 - val_loss: 0.0434 - val_mae: 0.1629\n",
      "Epoch 80/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0524 - mae: 0.1853 - val_loss: 0.0478 - val_mae: 0.1736\n",
      "Epoch 81/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0524 - mae: 0.1877 - val_loss: 0.0411 - val_mae: 0.1573\n",
      "Epoch 82/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0525 - mae: 0.1865 - val_loss: 0.0415 - val_mae: 0.1584\n",
      "Epoch 83/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0523 - mae: 0.1874 - val_loss: 0.0372 - val_mae: 0.1479\n",
      "Epoch 84/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0525 - mae: 0.1857 - val_loss: 0.0416 - val_mae: 0.1586\n",
      "Epoch 85/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0525 - mae: 0.1864 - val_loss: 0.0403 - val_mae: 0.1554\n",
      "Epoch 86/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0524 - mae: 0.1857 - val_loss: 0.0447 - val_mae: 0.1661\n",
      "Epoch 87/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0525 - mae: 0.1870 - val_loss: 0.0440 - val_mae: 0.1644\n",
      "Epoch 88/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0524 - mae: 0.1866 - val_loss: 0.0433 - val_mae: 0.1628\n",
      "Epoch 89/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0524 - mae: 0.1864 - val_loss: 0.0423 - val_mae: 0.1603\n",
      "Epoch 90/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0524 - mae: 0.1853 - val_loss: 0.0479 - val_mae: 0.1739\n",
      "Epoch 91/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0525 - mae: 0.1882 - val_loss: 0.0429 - val_mae: 0.1618\n",
      "Epoch 92/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0524 - mae: 0.1852 - val_loss: 0.0448 - val_mae: 0.1663\n",
      "Epoch 93/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0525 - mae: 0.1875 - val_loss: 0.0438 - val_mae: 0.1638\n",
      "Epoch 94/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0524 - mae: 0.1856 - val_loss: 0.0473 - val_mae: 0.1724\n",
      "Epoch 95/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0524 - mae: 0.1881 - val_loss: 0.0404 - val_mae: 0.1558\n",
      "Epoch 96/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0524 - mae: 0.1864 - val_loss: 0.0429 - val_mae: 0.1618\n",
      "Epoch 97/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0524 - mae: 0.1862 - val_loss: 0.0416 - val_mae: 0.1586\n",
      "Epoch 98/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0524 - mae: 0.1858 - val_loss: 0.0437 - val_mae: 0.1637\n",
      "Epoch 99/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0524 - mae: 0.1867 - val_loss: 0.0444 - val_mae: 0.1654\n",
      "Epoch 100/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0524 - mae: 0.1873 - val_loss: 0.0413 - val_mae: 0.1578\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step   \n",
      "✅ Done with wheat_Mandya_daily.csv | MAE=331.19, RMSE=415.18, R2=-0.014, MAPE=17.29%, Accuracy=82.71%\n",
      "\n",
      "🚀 Processing: wheat_Mysore_daily.csv\n",
      "Epoch 1/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - loss: 2.5309e-04 - mae: 0.0112 - val_loss: 0.0021 - val_mae: 0.0340\n",
      "Epoch 2/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 2.2559e-04 - mae: 0.0107 - val_loss: 0.0019 - val_mae: 0.0317\n",
      "Epoch 3/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 2.2610e-04 - mae: 0.0107 - val_loss: 0.0020 - val_mae: 0.0332\n",
      "Epoch 21/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 2.2501e-04 - mae: 0.0107 - val_loss: 0.0019 - val_mae: 0.0324\n",
      "Epoch 22/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 2.2578e-04 - mae: 0.0107 - val_loss: 0.0018 - val_mae: 0.0313\n",
      "Epoch 23/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 2.2511e-04 - mae: 0.0107 - val_loss: 0.0020 - val_mae: 0.0328\n",
      "Epoch 24/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - loss: 2.2489e-04 - mae: 0.0107 - val_loss: 0.0020 - val_mae: 0.0329\n",
      "Epoch 25/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 2.2544e-04 - mae: 0.0107 - val_loss: 0.0019 - val_mae: 0.0325\n",
      "Epoch 26/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 2.2603e-04 - mae: 0.0107 - val_loss: 0.0020 - val_mae: 0.0329\n",
      "Epoch 27/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 2.2505e-04 - mae: 0.0107 - val_loss: 0.0020 - val_mae: 0.0337\n",
      "Epoch 28/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 2.2473e-04 - mae: 0.0107 - val_loss: 0.0019 - val_mae: 0.0320\n",
      "Epoch 29/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 2.2446e-04 - mae: 0.0107 - val_loss: 0.0020 - val_mae: 0.0334\n",
      "Epoch 55/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 2.2505e-04 - mae: 0.0107 - val_loss: 0.0019 - val_mae: 0.0316\n",
      "Epoch 56/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 2.2444e-04 - mae: 0.0107 - val_loss: 0.0020 - val_mae: 0.0330\n",
      "Epoch 57/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 2.2454e-04 - mae: 0.0107 - val_loss: 0.0020 - val_mae: 0.0325\n",
      "Epoch 58/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 2.2523e-04 - mae: 0.0107 - val_loss: 0.0019 - val_mae: 0.0320\n",
      "Epoch 59/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 2.2494e-04 - mae: 0.0107 - val_loss: 0.0020 - val_mae: 0.0334\n",
      "Epoch 60/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 2.2487e-04 - mae: 0.0107 - val_loss: 0.0020 - val_mae: 0.0326\n",
      "Epoch 61/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 2.2534e-04 - mae: 0.0107 - val_loss: 0.0019 - val_mae: 0.0325\n",
      "Epoch 62/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 2.2520e-04 - mae: 0.0107 - val_loss: 0.0019 - val_mae: 0.0321\n",
      "Epoch 89/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 2.2452e-04 - mae: 0.0107 - val_loss: 0.0020 - val_mae: 0.0331\n",
      "Epoch 90/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 2.2489e-04 - mae: 0.0107 - val_loss: 0.0019 - val_mae: 0.0316\n",
      "Epoch 91/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 2.2438e-04 - mae: 0.0107 - val_loss: 0.0020 - val_mae: 0.0326\n",
      "Epoch 92/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 2.2468e-04 - mae: 0.0107 - val_loss: 0.0020 - val_mae: 0.0328\n",
      "Epoch 93/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 2.2498e-04 - mae: 0.0107 - val_loss: 0.0019 - val_mae: 0.0324\n",
      "Epoch 94/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 2.2509e-04 - mae: 0.0107 - val_loss: 0.0019 - val_mae: 0.0320\n",
      "Epoch 95/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0134 - mae: 0.0935 - val_loss: 0.0308 - val_mae: 0.1488\n",
      "Epoch 20/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0134 - mae: 0.0936 - val_loss: 0.0308 - val_mae: 0.1488\n",
      "Epoch 21/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0134 - mae: 0.0935 - val_loss: 0.0326 - val_mae: 0.1531\n",
      "Epoch 22/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0134 - mae: 0.0936 - val_loss: 0.0318 - val_mae: 0.1512\n",
      "Epoch 23/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0134 - mae: 0.0934 - val_loss: 0.0313 - val_mae: 0.1500\n",
      "Epoch 24/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0134 - mae: 0.0935 - val_loss: 0.0305 - val_mae: 0.1478\n",
      "Epoch 25/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0134 - mae: 0.0935 - val_loss: 0.0333 - val_mae: 0.1549\n",
      "Epoch 26/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0134 - mae: 0.0935 - val_loss: 0.0285 - val_mae: 0.1424\n",
      "Epoch 27/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0134 - mae: 0.0935 - val_loss: 0.0310 - val_mae: 0.1491\n",
      "Epoch 28/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0134 - mae: 0.0935 - val_loss: 0.0299 - val_mae: 0.1462\n",
      "Epoch 55/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0134 - mae: 0.0935 - val_loss: 0.0313 - val_mae: 0.1499\n",
      "Epoch 56/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0134 - mae: 0.0935 - val_loss: 0.0324 - val_mae: 0.1526\n",
      "Epoch 57/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0134 - mae: 0.0935 - val_loss: 0.0318 - val_mae: 0.1511\n",
      "Epoch 58/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0134 - mae: 0.0935 - val_loss: 0.0327 - val_mae: 0.1535\n",
      "Epoch 59/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0134 - mae: 0.0934 - val_loss: 0.0284 - val_mae: 0.1421\n",
      "Epoch 60/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0134 - mae: 0.0935 - val_loss: 0.0330 - val_mae: 0.1542\n",
      "Epoch 61/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0134 - mae: 0.0935 - val_loss: 0.0315 - val_mae: 0.1503\n",
      "Epoch 62/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0134 - mae: 0.0935 - val_loss: 0.0305 - val_mae: 0.1478\n",
      "Epoch 63/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0134 - mae: 0.0935 - val_loss: 0.0317 - val_mae: 0.1509\n",
      "Epoch 64/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0134 - mae: 0.0935 - val_loss: 0.0320 - val_mae: 0.1517\n",
      "Epoch 65/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0134 - mae: 0.0934 - val_loss: 0.0310 - val_mae: 0.1492\n",
      "Epoch 66/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0134 - mae: 0.0934 - val_loss: 0.0309 - val_mae: 0.1490\n",
      "Epoch 91/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0134 - mae: 0.0935 - val_loss: 0.0319 - val_mae: 0.1515\n",
      "Epoch 92/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0134 - mae: 0.0934 - val_loss: 0.0319 - val_mae: 0.1515\n",
      "Epoch 93/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0134 - mae: 0.0935 - val_loss: 0.0309 - val_mae: 0.1490\n",
      "Epoch 94/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0134 - mae: 0.0935 - val_loss: 0.0324 - val_mae: 0.1526\n",
      "Epoch 95/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0134 - mae: 0.0935 - val_loss: 0.0316 - val_mae: 0.1507\n",
      "Epoch 96/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0134 - mae: 0.0934 - val_loss: 0.0315 - val_mae: 0.1504\n",
      "Epoch 97/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0134 - mae: 0.0934 - val_loss: 0.0336 - val_mae: 0.1556\n",
      "Epoch 98/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0134 - mae: 0.0935 - val_loss: 0.0315 - val_mae: 0.1504\n",
      "Epoch 99/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0134 - mae: 0.0935 - val_loss: 0.0323 - val_mae: 0.1525\n",
      "Epoch 100/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 9.0452e-05 - mae: 0.0082 - val_loss: 8.1411e-04 - val_mae: 0.0122\n",
      "Epoch 30/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 9.0680e-05 - mae: 0.0082 - val_loss: 8.5540e-04 - val_mae: 0.0134\n",
      "Epoch 31/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 9.0381e-05 - mae: 0.0082 - val_loss: 8.4106e-04 - val_mae: 0.0130\n",
      "Epoch 32/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 9.0845e-05 - mae: 0.0082 - val_loss: 8.3824e-04 - val_mae: 0.0129\n",
      "Epoch 33/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 9.0203e-05 - mae: 0.0082 - val_loss: 7.7747e-04 - val_mae: 0.0112\n",
      "Epoch 34/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 9.0695e-05 - mae: 0.0082 - val_loss: 8.2691e-04 - val_mae: 0.0126\n",
      "Epoch 35/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 9.0147e-05 - mae: 0.0082 - val_loss: 8.4258e-04 - val_mae: 0.0131\n",
      "Epoch 36/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 9.0556e-05 - mae: 0.0082 - val_loss: 8.2331e-04 - val_mae: 0.0125\n",
      "Epoch 37/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 9.0151e-05 - mae: 0.0082 - val_loss: 8.2207e-04 - val_mae: 0.0124\n",
      "Epoch 38/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 9.0650e-05 - mae: 0.0082 - val_loss: 8.3297e-04 - val_mae: 0.0128\n",
      "Epoch 39/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 9.0268e-05 - mae: 0.0082 - val_loss: 7.9188e-04 - val_mae: 0.0116\n",
      "Epoch 62/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 9.0544e-05 - mae: 0.0082 - val_loss: 8.2395e-04 - val_mae: 0.0125\n",
      "Epoch 63/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 9.0611e-05 - mae: 0.0082 - val_loss: 8.3624e-04 - val_mae: 0.0129\n",
      "Epoch 64/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 9.0226e-05 - mae: 0.0082 - val_loss: 8.0851e-04 - val_mae: 0.0121\n",
      "Epoch 65/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 9.0244e-05 - mae: 0.0082 - val_loss: 8.9090e-04 - val_mae: 0.0145\n",
      "Epoch 66/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 9.0702e-05 - mae: 0.0082 - val_loss: 8.7000e-04 - val_mae: 0.0139\n",
      "Epoch 67/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 9.0500e-05 - mae: 0.0082 - val_loss: 8.1290e-04 - val_mae: 0.0122\n",
      "Epoch 68/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 9.0415e-05 - mae: 0.0082 - val_loss: 7.9868e-04 - val_mae: 0.0118\n",
      "Epoch 69/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 9.0545e-05 - mae: 0.0082 - val_loss: 8.1507e-04 - val_mae: 0.0122\n",
      "Epoch 70/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 9.0290e-05 - mae: 0.0082 - val_loss: 8.1652e-04 - val_mae: 0.0123\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step \n",
      "✅ Done with wheat_Shimoga_daily.csv | MAE=555.03, RMSE=947.44, R2=-0.0179, MAPE=24.64%, Accuracy=75.36%\n",
      "\n",
      "🚀 Processing: wheat_Tumkur_daily.csv\n",
      "Epoch 1/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 0.0022 - mae: 0.0253 - val_loss: 0.0102 - val_mae: 0.0489\n",
      "Epoch 2/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0021 - mae: 0.0246 - val_loss: 0.0110 - val_mae: 0.0532\n",
      "Epoch 3/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0021 - mae: 0.0246 - val_loss: 0.0108 - val_mae: 0.0522\n",
      "Epoch 4/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0022 - mae: 0.0246 - val_loss: 0.0105 - val_mae: 0.0510\n",
      "Epoch 5/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0021 - mae: 0.0246 - val_loss: 0.0110 - val_mae: 0.0536\n",
      "Epoch 6/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0021 - mae: 0.0246 - val_loss: 0.0106 - val_mae: 0.0515\n",
      "Epoch 7/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0021 - mae: 0.0246 - val_loss: 0.0104 - val_mae: 0.0503\n",
      "Epoch 8/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0021 - mae: 0.0246 - val_loss: 0.0114 - val_mae: 0.0558\n",
      "Epoch 9/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0022 - mae: 0.0247 - val_loss: 0.0102 - val_mae: 0.0493\n",
      "Epoch 10/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0021 - mae: 0.0247 - val_loss: 0.0101 - val_mae: 0.0484\n",
      "Epoch 11/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0021 - mae: 0.0246 - val_loss: 0.0104 - val_mae: 0.0503\n",
      "Epoch 12/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0022 - mae: 0.0247 - val_loss: 0.0103 - val_mae: 0.0497\n",
      "Epoch 13/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0021 - mae: 0.0245 - val_loss: 0.0102 - val_mae: 0.0494\n",
      "Epoch 14/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0021 - mae: 0.0246 - val_loss: 0.0104 - val_mae: 0.0504\n",
      "Epoch 43/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0021 - mae: 0.0246 - val_loss: 0.0105 - val_mae: 0.0508\n",
      "Epoch 44/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0021 - mae: 0.0244 - val_loss: 0.0107 - val_mae: 0.0518\n",
      "Epoch 45/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0021 - mae: 0.0247 - val_loss: 0.0108 - val_mae: 0.0525\n",
      "Epoch 46/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0021 - mae: 0.0247 - val_loss: 0.0109 - val_mae: 0.0530\n",
      "Epoch 47/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0021 - mae: 0.0246 - val_loss: 0.0105 - val_mae: 0.0508\n",
      "Epoch 48/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0021 - mae: 0.0245 - val_loss: 0.0106 - val_mae: 0.0514\n",
      "Epoch 49/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0022 - mae: 0.0247 - val_loss: 0.0101 - val_mae: 0.0485\n",
      "Epoch 50/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0021 - mae: 0.0246 - val_loss: 0.0102 - val_mae: 0.0492\n",
      "Epoch 51/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0021 - mae: 0.0246 - val_loss: 0.0102 - val_mae: 0.0493\n",
      "Epoch 52/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0021 - mae: 0.0246 - val_loss: 0.0104 - val_mae: 0.0503\n",
      "Epoch 53/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0021 - mae: 0.0246 - val_loss: 0.0108 - val_mae: 0.0526\n",
      "Epoch 54/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0021 - mae: 0.0246 - val_loss: 0.0106 - val_mae: 0.0514\n",
      "Epoch 55/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0021 - mae: 0.0246 - val_loss: 0.0104 - val_mae: 0.0505\n",
      "Epoch 97/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0021 - mae: 0.0245 - val_loss: 0.0106 - val_mae: 0.0515\n",
      "Epoch 98/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0021 - mae: 0.0245 - val_loss: 0.0104 - val_mae: 0.0503\n",
      "Epoch 99/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0021 - mae: 0.0246 - val_loss: 0.0106 - val_mae: 0.0516\n",
      "Epoch 100/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0021 - mae: 0.0246 - val_loss: 0.0105 - val_mae: 0.0508\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step\n",
      "✅ Done with wheat_Tumkur_daily.csv | MAE=528.28, RMSE=1093.34, R2=-0.0208, MAPE=19.96%, Accuracy=80.04%\n",
      "\n",
      "📊 Metrics saved to tat_metrics.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "import joblib  # For saving models as .pkl\n",
    "\n",
    "# -----------------------------\n",
    "# Output directories\n",
    "# -----------------------------\n",
    "input_folder = \"dataset\"\n",
    "output_models = \"tat_output_models\"\n",
    "output_csv = \"tat_output_csv\"\n",
    "output_graphs = \"tat_output_graphs\"\n",
    "output_logs = \"tat_output_logs\"\n",
    "metrics_file = \"tat_metrics.csv\"\n",
    "\n",
    "os.makedirs(output_models, exist_ok=True)\n",
    "os.makedirs(output_csv, exist_ok=True)\n",
    "os.makedirs(output_graphs, exist_ok=True)\n",
    "os.makedirs(output_logs, exist_ok=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Function to create dataset\n",
    "# -----------------------------\n",
    "def create_dataset(data, look_back=30):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - look_back):\n",
    "        X.append(data[i:i+look_back, 0])\n",
    "        y.append(data[i+look_back, 0])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# -----------------------------\n",
    "# Define Temporal Attention Transformer Model\n",
    "# -----------------------------\n",
    "def build_tat_model(input_shape, d_model=64, num_heads=4, ff_dim=128, dropout_rate=0.2):\n",
    "    inputs = layers.Input(shape=input_shape)  # (look_back, 1)\n",
    "    \n",
    "    # Multi-Head Attention\n",
    "    x = layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)(inputs, inputs)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x + inputs)  # Residual connection\n",
    "    \n",
    "    # Feed-Forward Network\n",
    "    ff = layers.Dense(ff_dim, activation='relu')(x)\n",
    "    ff = layers.Dense(input_shape[1])(ff)\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x + ff)  # Residual connection\n",
    "    \n",
    "    # Global Pooling\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    \n",
    "    # Output\n",
    "    outputs = layers.Dense(1)(x)\n",
    "    \n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=0.001),\n",
    "                  loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# -----------------------------\n",
    "# Function to robustly parse dates\n",
    "# -----------------------------\n",
    "def parse_dates_safe(date_series):\n",
    "    # First try strict ISO format (avoids warning)\n",
    "    try:\n",
    "        return pd.to_datetime(date_series, format=\"%Y-%m-%d\", errors='coerce')\n",
    "    except:\n",
    "        # Fallback flexible parsing\n",
    "        return pd.to_datetime(date_series, errors='coerce', dayfirst=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Metrics storage\n",
    "# -----------------------------\n",
    "metrics_list = []\n",
    "\n",
    "# -----------------------------\n",
    "# Process each CSV file\n",
    "# -----------------------------\n",
    "look_back = 30\n",
    "for file in os.listdir(input_folder):\n",
    "    if file.endswith(\".csv\"):\n",
    "        file_path = os.path.join(input_folder, file)\n",
    "        print(f\"🚀 Processing: {file}\")\n",
    "\n",
    "        # Load CSV\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Robust date parsing\n",
    "        df['Date'] = parse_dates_safe(df['Date'])\n",
    "        df = df.dropna(subset=['Date'])\n",
    "        df = df.sort_values('Date')\n",
    "\n",
    "        # Replace NaN in 'Average Price' with column mean (future-proof)\n",
    "        df['Average Price'] = df['Average Price'].fillna(df['Average Price'].mean())\n",
    "        df['Average Price'] = df['Average Price'].round(2)\n",
    "\n",
    "        # Add moving averages (future-proof fill)\n",
    "        df['MA_7'] = df['Average Price'].rolling(window=7).mean()\n",
    "        df['MA_30'] = df['Average Price'].rolling(window=30).mean()\n",
    "        df['MA_7'] = df['MA_7'].fillna(df['MA_7'].mean())\n",
    "        df['MA_30'] = df['MA_30'].fillna(df['MA_30'].mean())\n",
    "\n",
    "        # Prepare data using MinMaxScaler\n",
    "        values = df[['Average Price']].values.astype('float32')\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        scaled_values = scaler.fit_transform(values)\n",
    "\n",
    "        # Create sequences\n",
    "        X, y = create_dataset(scaled_values, look_back)\n",
    "        X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
    "\n",
    "        # Build model\n",
    "        model = build_tat_model(input_shape=(look_back,1))\n",
    "\n",
    "        # Train model\n",
    "        history = model.fit(X, y, epochs=100, batch_size=16, validation_split=0.2, verbose=1)\n",
    "\n",
    "        # Save training logs\n",
    "        log_file = os.path.join(output_logs, file.replace(\".csv\", \"_tat_training.txt\"))\n",
    "        with open(log_file, \"w\") as f:\n",
    "            f.write(\"Training Loss per Epoch:\\n\")\n",
    "            for i, loss in enumerate(history.history['loss']):\n",
    "                f.write(f\"Epoch {i+1}: Loss={loss}, Val_Loss={history.history['val_loss'][i]}\\n\")\n",
    "\n",
    "        # Predictions\n",
    "        predictions = model.predict(X)\n",
    "        predictions_rescaled = scaler.inverse_transform(predictions)\n",
    "        df['Predicted'] = [np.nan]*look_back + list(predictions_rescaled.flatten())\n",
    "        df['Predicted'] = df['Predicted'].round(2)\n",
    "\n",
    "        # Compute metrics safely\n",
    "        y_true = df['Average Price'].values[look_back:]\n",
    "        y_pred = predictions_rescaled.flatten()\n",
    "\n",
    "        # Avoid divide-by-zero in MAPE\n",
    "        non_zero_idx = y_true != 0\n",
    "        if np.any(non_zero_idx):\n",
    "            mape = round(np.mean(np.abs((y_true[non_zero_idx] - y_pred[non_zero_idx]) / y_true[non_zero_idx])) * 100, 2)\n",
    "            accuracy = round(100 - mape, 2)\n",
    "        else:\n",
    "            mape, accuracy = np.nan, np.nan\n",
    "\n",
    "        mae = round(mean_absolute_error(y_true, y_pred), 2)\n",
    "        rmse = round(np.sqrt(mean_squared_error(y_true, y_pred)), 2)\n",
    "        r2 = round(r2_score(y_true, y_pred), 4)\n",
    "\n",
    "        metrics_list.append([file.replace(\".csv\",\"\"), mae, rmse, r2, mape, accuracy])\n",
    "\n",
    "        # Save model as .pkl\n",
    "        model_file = os.path.join(output_models, file.replace(\".csv\", \"_tat_model.pkl\"))\n",
    "        joblib.dump(model, model_file)\n",
    "\n",
    "        # Save CSV with only Date, Actual, Predicted\n",
    "        save_df = df[['Average Price', 'Predicted']].copy()\n",
    "        save_df.rename(columns={'Average Price':'Actual'}, inplace=True)\n",
    "        save_df['Date'] = df['Date']\n",
    "        save_df = save_df[['Date', 'Actual', 'Predicted']]\n",
    "        updated_csv_path = os.path.join(output_csv, file.replace(\".csv\", \"_tat_updated.csv\"))\n",
    "        save_df.to_csv(updated_csv_path, index=False)\n",
    "\n",
    "        # Save graph\n",
    "        plt.figure(figsize=(12,6))\n",
    "        plt.plot(df['Date'], df['Average Price'], label='Actual', color='blue')\n",
    "        plt.plot(df['Date'], df['Predicted'], label='Predicted', color='red', linestyle='dashed')\n",
    "        plt.plot(df['Date'], df['MA_7'], label='MA 7', color='orange')\n",
    "        plt.plot(df['Date'], df['MA_30'], label='MA 30', color='green')\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Average Price')\n",
    "        plt.title(f'Price Prediction (TAT) - {file}')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        graph_file = os.path.join(output_graphs, file.replace(\".csv\", \"_tat_graph.png\"))\n",
    "        plt.savefig(graph_file, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "        print(f\"✅ Done with {file} | MAE={mae}, RMSE={rmse}, R2={r2}, MAPE={mape}%, Accuracy={accuracy}%\\n\")\n",
    "\n",
    "# Save all metrics\n",
    "metrics_df = pd.DataFrame(metrics_list, columns=['District', 'MAE', 'RMSE', 'R2', 'MAPE(%)', 'Accuracy(%)'])\n",
    "metrics_df.to_csv(metrics_file, index=False)\n",
    "print(f\"📊 Metrics saved to {metrics_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7cd1e8-d2c8-4e82-892f-9a784db85225",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TAT+MQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b382445-e27f-4bbf-8f37-a443ff890893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Processing: wheat_Bagalkot_daily.csv\n",
      "WARNING:tensorflow:From C:\\Users\\ravik\\AppData\\Roaming\\Python\\Python313\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:232: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_22\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_22\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_query_attention         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">17,216</span> │ input_layer_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiQueryAttention</span>)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_44 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_query_attention[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                               │                           │                 │ input_layer_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_44        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_44[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_73 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ layer_normalization_44[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_74 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dense_73[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_45 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_44[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                               │                           │                 │ dense_74[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_45        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_45[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_22   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_45[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_75 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ global_average_pooling1d_… │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_22 (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_query_attention         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │          \u001b[38;5;34m17,216\u001b[0m │ input_layer_22[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mMultiQueryAttention\u001b[0m)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_44 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ multi_query_attention[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                               │                           │                 │ input_layer_22[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_44        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ add_44[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_73 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │           \u001b[38;5;34m8,320\u001b[0m │ layer_normalization_44[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_74 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │             \u001b[38;5;34m129\u001b[0m │ dense_73[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_45 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_44[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                               │                           │                 │ dense_74[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_45        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ add_45[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_22   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_45[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_75 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │              \u001b[38;5;34m65\u001b[0m │ global_average_pooling1d_… │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,986</span> (101.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25,986\u001b[0m (101.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,986</span> (101.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m25,986\u001b[0m (101.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 10ms/step - loss: 0.0287 - mae: 0.0811 - val_loss: 0.0017 - val_mae: 0.0337\n",
      "Epoch 2/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0020 - mae: 0.0338 - val_loss: 0.0025 - val_mae: 0.0379\n",
      "Epoch 3/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0013 - mae: 0.0269 - val_loss: 0.0024 - val_mae: 0.0376\n",
      "Epoch 4/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - loss: 9.2459e-04 - mae: 0.0218 - val_loss: 0.0016 - val_mae: 0.0316\n",
      "Epoch 19/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 9.2847e-04 - mae: 0.0217 - val_loss: 0.0015 - val_mae: 0.0312\n",
      "Epoch 20/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 9.3334e-04 - mae: 0.0219 - val_loss: 0.0017 - val_mae: 0.0331\n",
      "Epoch 21/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 9.1433e-04 - mae: 0.0215 - val_loss: 0.0016 - val_mae: 0.0319\n",
      "Epoch 22/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 9.2108e-04 - mae: 0.0217 - val_loss: 0.0016 - val_mae: 0.0326\n",
      "Epoch 23/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 9.1270e-04 - mae: 0.0215 - val_loss: 0.0015 - val_mae: 0.0307\n",
      "Epoch 24/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 9.0813e-04 - mae: 0.0214 - val_loss: 0.0015 - val_mae: 0.0317\n",
      "Epoch 25/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 9.0274e-04 - mae: 0.0213 - val_loss: 0.0016 - val_mae: 0.0313\n",
      "Epoch 26/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 8.9851e-04 - mae: 0.0213 - val_loss: 0.0015 - val_mae: 0.0316\n",
      "Epoch 27/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 8.9520e-04 - mae: 0.0213 - val_loss: 0.0016 - val_mae: 0.0317\n",
      "Epoch 28/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 8.8992e-04 - mae: 0.0212 - val_loss: 0.0015 - val_mae: 0.0314\n",
      "Epoch 29/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 8.9082e-04 - mae: 0.0212 - val_loss: 0.0015 - val_mae: 0.0307\n",
      "Epoch 30/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - loss: 8.8941e-04 - mae: 0.0212 - val_loss: 0.0016 - val_mae: 0.0319\n",
      "Epoch 31/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 8.9085e-04 - mae: 0.0212 - val_loss: 0.0016 - val_mae: 0.0318\n",
      "Epoch 32/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 8.8804e-04 - mae: 0.0211 - val_loss: 0.0016 - val_mae: 0.0320\n",
      "Epoch 33/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - loss: 8.8909e-04 - mae: 0.0211 - val_loss: 0.0015 - val_mae: 0.0311\n",
      "Epoch 34/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 8.8324e-04 - mae: 0.0210 - val_loss: 0.0015 - val_mae: 0.0309\n",
      "Epoch 35/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 8.8529e-04 - mae: 0.0211 - val_loss: 0.0015 - val_mae: 0.0306\n",
      "Epoch 36/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 8.8453e-04 - mae: 0.0210 - val_loss: 0.0017 - val_mae: 0.0317\n",
      "Epoch 37/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 8.8505e-04 - mae: 0.0211 - val_loss: 0.0015 - val_mae: 0.0308\n",
      "Epoch 38/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - loss: 8.8317e-04 - mae: 0.0210 - val_loss: 0.0015 - val_mae: 0.0309\n",
      "Epoch 39/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 8.8036e-04 - mae: 0.0210 - val_loss: 0.0015 - val_mae: 0.0312\n",
      "Epoch 40/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 8.8150e-04 - mae: 0.0209 - val_loss: 0.0015 - val_mae: 0.0304\n",
      "Epoch 41/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 8.8493e-04 - mae: 0.0210 - val_loss: 0.0016 - val_mae: 0.0317\n",
      "Epoch 42/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 8.8582e-04 - mae: 0.0211 - val_loss: 0.0015 - val_mae: 0.0306\n",
      "Epoch 43/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 8.8602e-04 - mae: 0.0211 - val_loss: 0.0016 - val_mae: 0.0312\n",
      "Epoch 44/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 8.8014e-04 - mae: 0.0210 - val_loss: 0.0017 - val_mae: 0.0322\n",
      "Epoch 45/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 8.8403e-04 - mae: 0.0210 - val_loss: 0.0015 - val_mae: 0.0310\n",
      "Epoch 46/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 8.7945e-04 - mae: 0.0209 - val_loss: 0.0015 - val_mae: 0.0306\n",
      "Epoch 47/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 8.8180e-04 - mae: 0.0210 - val_loss: 0.0015 - val_mae: 0.0303\n",
      "Epoch 48/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 8.8023e-04 - mae: 0.0210 - val_loss: 0.0015 - val_mae: 0.0306\n",
      "Epoch 49/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 8.8059e-04 - mae: 0.0210 - val_loss: 0.0016 - val_mae: 0.0311\n",
      "Epoch 50/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 8.7975e-04 - mae: 0.0210 - val_loss: 0.0015 - val_mae: 0.0299\n",
      "Epoch 51/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 8.8179e-04 - mae: 0.0210 - val_loss: 0.0016 - val_mae: 0.0310\n",
      "Epoch 52/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 8.8040e-04 - mae: 0.0210 - val_loss: 0.0017 - val_mae: 0.0308\n",
      "Epoch 53/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 8.8047e-04 - mae: 0.0210 - val_loss: 0.0015 - val_mae: 0.0301\n",
      "Epoch 54/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 8.8164e-04 - mae: 0.0210 - val_loss: 0.0015 - val_mae: 0.0301\n",
      "Epoch 55/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 8.8136e-04 - mae: 0.0210 - val_loss: 0.0015 - val_mae: 0.0304\n",
      "Epoch 56/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 8.8143e-04 - mae: 0.0210 - val_loss: 0.0015 - val_mae: 0.0307\n",
      "Epoch 57/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 8.7989e-04 - mae: 0.0209 - val_loss: 0.0016 - val_mae: 0.0320\n",
      "Epoch 58/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 8.8111e-04 - mae: 0.0210 - val_loss: 0.0015 - val_mae: 0.0306\n",
      "Epoch 59/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 8.8113e-04 - mae: 0.0210 - val_loss: 0.0015 - val_mae: 0.0306\n",
      "Epoch 60/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 8.7960e-04 - mae: 0.0210 - val_loss: 0.0015 - val_mae: 0.0307\n",
      "Epoch 61/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 8.8241e-04 - mae: 0.0210 - val_loss: 0.0015 - val_mae: 0.0307\n",
      "Epoch 62/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 8.7602e-04 - mae: 0.0210 - val_loss: 0.0015 - val_mae: 0.0300\n",
      "Epoch 63/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 8.7822e-04 - mae: 0.0210 - val_loss: 0.0015 - val_mae: 0.0306\n",
      "Epoch 64/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 8.7962e-04 - mae: 0.0210 - val_loss: 0.0015 - val_mae: 0.0309\n",
      "Epoch 65/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 8.7714e-04 - mae: 0.0209 - val_loss: 0.0015 - val_mae: 0.0305\n",
      "Epoch 66/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 8.7985e-04 - mae: 0.0209 - val_loss: 0.0015 - val_mae: 0.0305\n",
      "Epoch 67/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 8.7625e-04 - mae: 0.0209 - val_loss: 0.0015 - val_mae: 0.0307\n",
      "Epoch 68/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 8.7786e-04 - mae: 0.0210 - val_loss: 0.0015 - val_mae: 0.0300\n",
      "Epoch 69/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 8.7834e-04 - mae: 0.0210 - val_loss: 0.0015 - val_mae: 0.0304\n",
      "Epoch 70/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 8.8151e-04 - mae: 0.0210 - val_loss: 0.0015 - val_mae: 0.0314\n",
      "Epoch 71/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 8.7931e-04 - mae: 0.0210 - val_loss: 0.0015 - val_mae: 0.0311\n",
      "Epoch 72/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - loss: 8.7926e-04 - mae: 0.0209 - val_loss: 0.0015 - val_mae: 0.0310\n",
      "Epoch 73/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 8.7835e-04 - mae: 0.0209 - val_loss: 0.0015 - val_mae: 0.0304\n",
      "Epoch 74/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 8.7911e-04 - mae: 0.0210 - val_loss: 0.0015 - val_mae: 0.0298\n",
      "Epoch 75/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 8.7591e-04 - mae: 0.0209 - val_loss: 0.0015 - val_mae: 0.0302\n",
      "Epoch 76/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 8.7830e-04 - mae: 0.0209 - val_loss: 0.0015 - val_mae: 0.0305\n",
      "Epoch 77/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 8.7892e-04 - mae: 0.0209 - val_loss: 0.0015 - val_mae: 0.0306\n",
      "Epoch 78/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 8.7801e-04 - mae: 0.0210 - val_loss: 0.0015 - val_mae: 0.0306\n",
      "Epoch 79/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 8.7779e-04 - mae: 0.0209 - val_loss: 0.0015 - val_mae: 0.0302\n",
      "Epoch 80/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 8.7472e-04 - mae: 0.0209 - val_loss: 0.0015 - val_mae: 0.0312\n",
      "Epoch 81/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 8.7587e-04 - mae: 0.0209 - val_loss: 0.0015 - val_mae: 0.0309\n",
      "Epoch 82/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 8.7914e-04 - mae: 0.0209 - val_loss: 0.0015 - val_mae: 0.0309\n",
      "Epoch 83/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 8.7923e-04 - mae: 0.0209 - val_loss: 0.0015 - val_mae: 0.0304\n",
      "Epoch 84/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 8.7966e-04 - mae: 0.0210 - val_loss: 0.0015 - val_mae: 0.0305\n",
      "Epoch 85/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 8.7567e-04 - mae: 0.0209 - val_loss: 0.0015 - val_mae: 0.0306\n",
      "Epoch 86/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 8.7796e-04 - mae: 0.0209 - val_loss: 0.0015 - val_mae: 0.0297\n",
      "Epoch 87/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 8.7772e-04 - mae: 0.0209 - val_loss: 0.0015 - val_mae: 0.0304\n",
      "Epoch 88/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 8.7699e-04 - mae: 0.0209 - val_loss: 0.0015 - val_mae: 0.0302\n",
      "Epoch 89/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 8.7994e-04 - mae: 0.0210 - val_loss: 0.0015 - val_mae: 0.0302\n",
      "Epoch 90/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 8.7401e-04 - mae: 0.0209 - val_loss: 0.0017 - val_mae: 0.0313\n",
      "Epoch 91/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 8.7680e-04 - mae: 0.0209 - val_loss: 0.0015 - val_mae: 0.0304\n",
      "Epoch 92/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 8.7704e-04 - mae: 0.0209 - val_loss: 0.0015 - val_mae: 0.0306\n",
      "Epoch 93/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 8.7767e-04 - mae: 0.0209 - val_loss: 0.0015 - val_mae: 0.0309\n",
      "Epoch 94/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 8.7819e-04 - mae: 0.0210 - val_loss: 0.0016 - val_mae: 0.0312\n",
      "Epoch 95/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 8.7597e-04 - mae: 0.0209 - val_loss: 0.0015 - val_mae: 0.0302\n",
      "Epoch 96/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 8.7901e-04 - mae: 0.0210 - val_loss: 0.0015 - val_mae: 0.0298\n",
      "Epoch 97/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 8.7613e-04 - mae: 0.0209 - val_loss: 0.0015 - val_mae: 0.0301\n",
      "Epoch 98/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 8.7555e-04 - mae: 0.0209 - val_loss: 0.0016 - val_mae: 0.0312\n",
      "Epoch 99/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 8.7849e-04 - mae: 0.0209 - val_loss: 0.0016 - val_mae: 0.0309\n",
      "Epoch 100/100\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 8.7441e-04 - mae: 0.0209 - val_loss: 0.0015 - val_mae: 0.0300\n",
      "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step\n",
      "✅ Done with wheat_Bagalkot_daily.csv | MAE=393.61, RMSE=551.7, R2=0.4076, MAPE=19.15%, Accuracy=80.85%\n",
      "Saved updated CSV with Date, Actual & Predicted: tat_mqa_output_csv\\wheat_Bagalkot_daily_tat_mqa_updated.csv\n",
      "🚀 Processing: wheat_Bangalore_daily.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_23\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_23\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_query_attention_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">17,216</span> │ input_layer_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiQueryAttention</span>)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_46 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_query_attention_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                               │                           │                 │ input_layer_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_46        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_46[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_83 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ layer_normalization_46[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_84 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dense_83[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_47 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_46[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                               │                           │                 │ dense_84[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_47        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_47[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_23   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_47[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_85 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ global_average_pooling1d_… │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_23 (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_query_attention_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │          \u001b[38;5;34m17,216\u001b[0m │ input_layer_23[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mMultiQueryAttention\u001b[0m)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_46 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ multi_query_attention_1[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                               │                           │                 │ input_layer_23[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_46        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ add_46[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_83 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │           \u001b[38;5;34m8,320\u001b[0m │ layer_normalization_46[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_84 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │             \u001b[38;5;34m129\u001b[0m │ dense_83[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_47 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_46[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                               │                           │                 │ dense_84[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_47        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ add_47[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_23   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_47[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_85 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │              \u001b[38;5;34m65\u001b[0m │ global_average_pooling1d_… │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,986</span> (101.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25,986\u001b[0m (101.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,986</span> (101.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m25,986\u001b[0m (101.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - loss: 0.0391 - mae: 0.0941 - val_loss: 0.0015 - val_mae: 0.0286\n",
      "Epoch 2/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0023 - mae: 0.0370 - val_loss: 0.0021 - val_mae: 0.0316\n",
      "Epoch 3/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.0014 - mae: 0.0287 - val_loss: 0.0023 - val_mae: 0.0330\n",
      "Epoch 4/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0010 - mae: 0.0252 - val_loss: 0.0022 - val_mae: 0.0321\n",
      "Epoch 5/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 9.0562e-04 - mae: 0.0235 - val_loss: 0.0021 - val_mae: 0.0309\n",
      "Epoch 6/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 8.1884e-04 - mae: 0.0225 - val_loss: 0.0018 - val_mae: 0.0290\n",
      "Epoch 7/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 7.7948e-04 - mae: 0.0220 - val_loss: 0.0026 - val_mae: 0.0352\n",
      "Epoch 8/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 7.6279e-04 - mae: 0.0218 - val_loss: 0.0032 - val_mae: 0.0412\n",
      "Epoch 9/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 7.5853e-04 - mae: 0.0218 - val_loss: 0.0024 - val_mae: 0.0341\n",
      "Epoch 10/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 7.3282e-04 - mae: 0.0214 - val_loss: 0.0025 - val_mae: 0.0347\n",
      "Epoch 11/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 7.1955e-04 - mae: 0.0213 - val_loss: 0.0026 - val_mae: 0.0353\n",
      "Epoch 12/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 7.3078e-04 - mae: 0.0214 - val_loss: 0.0023 - val_mae: 0.0328\n",
      "Epoch 13/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 7.1062e-04 - mae: 0.0211 - val_loss: 0.0025 - val_mae: 0.0347\n",
      "Epoch 14/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 6.9863e-04 - mae: 0.0210 - val_loss: 0.0019 - val_mae: 0.0296\n",
      "Epoch 15/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 6.8212e-04 - mae: 0.0208 - val_loss: 0.0016 - val_mae: 0.0283\n",
      "Epoch 16/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 7.1525e-04 - mae: 0.0212 - val_loss: 0.0022 - val_mae: 0.0319\n",
      "Epoch 17/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 6.7496e-04 - mae: 0.0208 - val_loss: 0.0017 - val_mae: 0.0286\n",
      "Epoch 18/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 6.8217e-04 - mae: 0.0208 - val_loss: 0.0018 - val_mae: 0.0288\n",
      "Epoch 19/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 6.6769e-04 - mae: 0.0206 - val_loss: 0.0026 - val_mae: 0.0347\n",
      "Epoch 20/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 6.3687e-04 - mae: 0.0203 - val_loss: 0.0024 - val_mae: 0.0329\n",
      "Epoch 21/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 6.5028e-04 - mae: 0.0204 - val_loss: 0.0018 - val_mae: 0.0289\n",
      "Epoch 22/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 6.5608e-04 - mae: 0.0205 - val_loss: 0.0017 - val_mae: 0.0282\n",
      "Epoch 23/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 6.5814e-04 - mae: 0.0205 - val_loss: 0.0028 - val_mae: 0.0368\n",
      "Epoch 24/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 6.7150e-04 - mae: 0.0206 - val_loss: 0.0027 - val_mae: 0.0367\n",
      "Epoch 25/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 6.4531e-04 - mae: 0.0203 - val_loss: 0.0015 - val_mae: 0.0276\n",
      "Epoch 26/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 6.4476e-04 - mae: 0.0204 - val_loss: 0.0014 - val_mae: 0.0284\n",
      "Epoch 27/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 6.4786e-04 - mae: 0.0204 - val_loss: 0.0016 - val_mae: 0.0281\n",
      "Epoch 28/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 6.3883e-04 - mae: 0.0203 - val_loss: 0.0022 - val_mae: 0.0310\n",
      "Epoch 29/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 6.3043e-04 - mae: 0.0202 - val_loss: 0.0015 - val_mae: 0.0277\n",
      "Epoch 30/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 6.2433e-04 - mae: 0.0201 - val_loss: 0.0015 - val_mae: 0.0277\n",
      "Epoch 31/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 6.2418e-04 - mae: 0.0201 - val_loss: 0.0015 - val_mae: 0.0276\n",
      "Epoch 32/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 6.2341e-04 - mae: 0.0202 - val_loss: 0.0019 - val_mae: 0.0291\n",
      "Epoch 33/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 6.2783e-04 - mae: 0.0201 - val_loss: 0.0016 - val_mae: 0.0280\n",
      "Epoch 34/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 6.3453e-04 - mae: 0.0203 - val_loss: 0.0014 - val_mae: 0.0276\n",
      "Epoch 35/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 6.2053e-04 - mae: 0.0201 - val_loss: 0.0017 - val_mae: 0.0282\n",
      "Epoch 36/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 6.2614e-04 - mae: 0.0201 - val_loss: 0.0016 - val_mae: 0.0279\n",
      "Epoch 37/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 6.2554e-04 - mae: 0.0202 - val_loss: 0.0015 - val_mae: 0.0276\n",
      "Epoch 38/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 6.1873e-04 - mae: 0.0201 - val_loss: 0.0014 - val_mae: 0.0276\n",
      "Epoch 39/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 6.1584e-04 - mae: 0.0200 - val_loss: 0.0014 - val_mae: 0.0278\n",
      "Epoch 40/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 6.2688e-04 - mae: 0.0202 - val_loss: 0.0016 - val_mae: 0.0278\n",
      "Epoch 41/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 6.1439e-04 - mae: 0.0201 - val_loss: 0.0015 - val_mae: 0.0276\n",
      "Epoch 42/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 6.1349e-04 - mae: 0.0201 - val_loss: 0.0016 - val_mae: 0.0278\n",
      "Epoch 43/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 6.1106e-04 - mae: 0.0200 - val_loss: 0.0014 - val_mae: 0.0276\n",
      "Epoch 44/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 6.0775e-04 - mae: 0.0200 - val_loss: 0.0014 - val_mae: 0.0276\n",
      "Epoch 45/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 6.0992e-04 - mae: 0.0200 - val_loss: 0.0015 - val_mae: 0.0277\n",
      "Epoch 46/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 6.1114e-04 - mae: 0.0200 - val_loss: 0.0015 - val_mae: 0.0276\n",
      "Epoch 47/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 6.0693e-04 - mae: 0.0200 - val_loss: 0.0014 - val_mae: 0.0276\n",
      "Epoch 48/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 6.0712e-04 - mae: 0.0200 - val_loss: 0.0015 - val_mae: 0.0275\n",
      "Epoch 49/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 6.0949e-04 - mae: 0.0200 - val_loss: 0.0014 - val_mae: 0.0276\n",
      "Epoch 50/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 6.0626e-04 - mae: 0.0201 - val_loss: 0.0015 - val_mae: 0.0276\n",
      "Epoch 51/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 6.0923e-04 - mae: 0.0200 - val_loss: 0.0014 - val_mae: 0.0277\n",
      "Epoch 52/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 6.0376e-04 - mae: 0.0200 - val_loss: 0.0014 - val_mae: 0.0276\n",
      "Epoch 53/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 6.1096e-04 - mae: 0.0200 - val_loss: 0.0015 - val_mae: 0.0276\n",
      "Epoch 54/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 6.0701e-04 - mae: 0.0200 - val_loss: 0.0014 - val_mae: 0.0276\n",
      "Epoch 55/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 6.0297e-04 - mae: 0.0199 - val_loss: 0.0014 - val_mae: 0.0277\n",
      "Epoch 56/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 6.0517e-04 - mae: 0.0200 - val_loss: 0.0015 - val_mae: 0.0275\n",
      "Epoch 57/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 6.0283e-04 - mae: 0.0200 - val_loss: 0.0014 - val_mae: 0.0277\n",
      "Epoch 58/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 6.0178e-04 - mae: 0.0199 - val_loss: 0.0015 - val_mae: 0.0277\n",
      "Epoch 59/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 6.0247e-04 - mae: 0.0199 - val_loss: 0.0015 - val_mae: 0.0276\n",
      "Epoch 60/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 6.0276e-04 - mae: 0.0200 - val_loss: 0.0017 - val_mae: 0.0281\n",
      "Epoch 61/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 6.0065e-04 - mae: 0.0200 - val_loss: 0.0015 - val_mae: 0.0276\n",
      "Epoch 62/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 6.0099e-04 - mae: 0.0199 - val_loss: 0.0014 - val_mae: 0.0276\n",
      "Epoch 63/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 6.0028e-04 - mae: 0.0199 - val_loss: 0.0014 - val_mae: 0.0276\n",
      "Epoch 64/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 6.0057e-04 - mae: 0.0200 - val_loss: 0.0015 - val_mae: 0.0276\n",
      "Epoch 65/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 6.0161e-04 - mae: 0.0200 - val_loss: 0.0015 - val_mae: 0.0276\n",
      "Epoch 66/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 6.0036e-04 - mae: 0.0199 - val_loss: 0.0016 - val_mae: 0.0279\n",
      "Epoch 67/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 5.9993e-04 - mae: 0.0199 - val_loss: 0.0014 - val_mae: 0.0276\n",
      "Epoch 68/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 6.0324e-04 - mae: 0.0200 - val_loss: 0.0015 - val_mae: 0.0275\n",
      "Epoch 69/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 5.9643e-04 - mae: 0.0199 - val_loss: 0.0014 - val_mae: 0.0277\n",
      "Epoch 70/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 5.9980e-04 - mae: 0.0199 - val_loss: 0.0015 - val_mae: 0.0275\n",
      "Epoch 71/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 6.0114e-04 - mae: 0.0199 - val_loss: 0.0014 - val_mae: 0.0276\n",
      "Epoch 72/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 5.9829e-04 - mae: 0.0199 - val_loss: 0.0014 - val_mae: 0.0276\n",
      "Epoch 73/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 6.0003e-04 - mae: 0.0199 - val_loss: 0.0015 - val_mae: 0.0275\n",
      "Epoch 74/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 5.9923e-04 - mae: 0.0199 - val_loss: 0.0014 - val_mae: 0.0276\n",
      "Epoch 75/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 5.9823e-04 - mae: 0.0199 - val_loss: 0.0015 - val_mae: 0.0276\n",
      "Epoch 76/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 5.9915e-04 - mae: 0.0199 - val_loss: 0.0014 - val_mae: 0.0276\n",
      "Epoch 77/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 5.9808e-04 - mae: 0.0199 - val_loss: 0.0014 - val_mae: 0.0276\n",
      "Epoch 78/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 5.9753e-04 - mae: 0.0199 - val_loss: 0.0014 - val_mae: 0.0276\n",
      "Epoch 79/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 6.0026e-04 - mae: 0.0199 - val_loss: 0.0014 - val_mae: 0.0276\n",
      "Epoch 80/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 5.9884e-04 - mae: 0.0200 - val_loss: 0.0015 - val_mae: 0.0275\n",
      "Epoch 81/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 6.0031e-04 - mae: 0.0200 - val_loss: 0.0015 - val_mae: 0.0275\n",
      "Epoch 82/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 5.9939e-04 - mae: 0.0199 - val_loss: 0.0014 - val_mae: 0.0277\n",
      "Epoch 83/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 6.0086e-04 - mae: 0.0200 - val_loss: 0.0014 - val_mae: 0.0277\n",
      "Epoch 84/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 5.9969e-04 - mae: 0.0200 - val_loss: 0.0016 - val_mae: 0.0277\n",
      "Epoch 85/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 5.9847e-04 - mae: 0.0200 - val_loss: 0.0014 - val_mae: 0.0275\n",
      "Epoch 86/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 5.9998e-04 - mae: 0.0200 - val_loss: 0.0014 - val_mae: 0.0275\n",
      "Epoch 87/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 6.0026e-04 - mae: 0.0199 - val_loss: 0.0014 - val_mae: 0.0276\n",
      "Epoch 88/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 6.0041e-04 - mae: 0.0200 - val_loss: 0.0014 - val_mae: 0.0276\n",
      "Epoch 89/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 6.0155e-04 - mae: 0.0200 - val_loss: 0.0014 - val_mae: 0.0277\n",
      "Epoch 90/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 5.9581e-04 - mae: 0.0199 - val_loss: 0.0014 - val_mae: 0.0276\n",
      "Epoch 91/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 6.0004e-04 - mae: 0.0200 - val_loss: 0.0014 - val_mae: 0.0276\n",
      "Epoch 92/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 5.9971e-04 - mae: 0.0199 - val_loss: 0.0014 - val_mae: 0.0275\n",
      "Epoch 93/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 5.9782e-04 - mae: 0.0199 - val_loss: 0.0015 - val_mae: 0.0275\n",
      "Epoch 94/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 5.9880e-04 - mae: 0.0199 - val_loss: 0.0014 - val_mae: 0.0277\n",
      "Epoch 95/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 6.0360e-04 - mae: 0.0200 - val_loss: 0.0014 - val_mae: 0.0275\n",
      "Epoch 96/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 5.9905e-04 - mae: 0.0199 - val_loss: 0.0015 - val_mae: 0.0275\n",
      "Epoch 97/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 5.9877e-04 - mae: 0.0199 - val_loss: 0.0014 - val_mae: 0.0276\n",
      "Epoch 98/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 5.9733e-04 - mae: 0.0200 - val_loss: 0.0015 - val_mae: 0.0275\n",
      "Epoch 99/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 5.9830e-04 - mae: 0.0199 - val_loss: 0.0015 - val_mae: 0.0275\n",
      "Epoch 100/100\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 5.9867e-04 - mae: 0.0200 - val_loss: 0.0016 - val_mae: 0.0277\n",
      "\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step\n",
      "✅ Done with wheat_Bangalore_daily.csv | MAE=370.69, RMSE=489.94, R2=0.5036, MAPE=15.99%, Accuracy=84.01%\n",
      "Saved updated CSV with Date, Actual & Predicted: tat_mqa_output_csv\\wheat_Bangalore_daily_tat_mqa_updated.csv\n",
      "🚀 Processing: wheat_Belgaum_daily.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_24\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_24\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_query_attention_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">17,216</span> │ input_layer_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiQueryAttention</span>)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_query_attention_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                               │                           │                 │ input_layer_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_48        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_48[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_93 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ layer_normalization_48[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_94 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dense_93[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_48[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                               │                           │                 │ dense_94[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_49        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_49[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_24   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_49[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_95 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ global_average_pooling1d_… │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_24 (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_query_attention_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │          \u001b[38;5;34m17,216\u001b[0m │ input_layer_24[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mMultiQueryAttention\u001b[0m)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_48 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ multi_query_attention_2[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                               │                           │                 │ input_layer_24[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_48        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ add_48[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_93 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │           \u001b[38;5;34m8,320\u001b[0m │ layer_normalization_48[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_94 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │             \u001b[38;5;34m129\u001b[0m │ dense_93[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_49 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_48[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                               │                           │                 │ dense_94[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_49        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ add_49[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_24   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_49[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_95 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │              \u001b[38;5;34m65\u001b[0m │ global_average_pooling1d_… │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,986</span> (101.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25,986\u001b[0m (101.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,986</span> (101.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m25,986\u001b[0m (101.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 11ms/step - loss: 0.0153 - mae: 0.0787 - val_loss: 0.0065 - val_mae: 0.0625\n",
      "Epoch 2/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - loss: 0.0062 - mae: 0.0593 - val_loss: 0.0058 - val_mae: 0.0581\n",
      "Epoch 3/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - loss: 0.0062 - mae: 0.0591 - val_loss: 0.0054 - val_mae: 0.0548\n",
      "Epoch 4/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - loss: 0.0060 - mae: 0.0584 - val_loss: 0.0056 - val_mae: 0.0564\n",
      "Epoch 5/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - loss: 0.0058 - mae: 0.0573 - val_loss: 0.0060 - val_mae: 0.0591\n",
      "Epoch 6/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - loss: 0.0058 - mae: 0.0573 - val_loss: 0.0046 - val_mae: 0.0506\n",
      "Epoch 7/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - loss: 0.0057 - mae: 0.0568 - val_loss: 0.0048 - val_mae: 0.0517\n",
      "Epoch 8/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - loss: 0.0057 - mae: 0.0565 - val_loss: 0.0051 - val_mae: 0.0535\n",
      "Epoch 9/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - loss: 0.0056 - mae: 0.0562 - val_loss: 0.0070 - val_mae: 0.0692\n",
      "Epoch 10/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - loss: 0.0056 - mae: 0.0562 - val_loss: 0.0042 - val_mae: 0.0510\n",
      "Epoch 11/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - loss: 0.0055 - mae: 0.0557 - val_loss: 0.0042 - val_mae: 0.0517\n",
      "Epoch 12/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - loss: 0.0055 - mae: 0.0555 - val_loss: 0.0051 - val_mae: 0.0538\n",
      "Epoch 13/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - loss: 0.0055 - mae: 0.0555 - val_loss: 0.0042 - val_mae: 0.0521\n",
      "Epoch 14/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - loss: 0.0055 - mae: 0.0555 - val_loss: 0.0043 - val_mae: 0.0507\n",
      "Epoch 15/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - loss: 0.0055 - mae: 0.0554 - val_loss: 0.0042 - val_mae: 0.0508\n",
      "Epoch 16/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - loss: 0.0055 - mae: 0.0554 - val_loss: 0.0042 - val_mae: 0.0509\n",
      "Epoch 17/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - loss: 0.0055 - mae: 0.0552 - val_loss: 0.0043 - val_mae: 0.0525\n",
      "Epoch 18/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - loss: 0.0055 - mae: 0.0552 - val_loss: 0.0041 - val_mae: 0.0514\n",
      "Epoch 19/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - loss: 0.0054 - mae: 0.0552 - val_loss: 0.0055 - val_mae: 0.0612\n",
      "Epoch 20/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - loss: 0.0054 - mae: 0.0552 - val_loss: 0.0043 - val_mae: 0.0525\n",
      "Epoch 21/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - loss: 0.0054 - mae: 0.0550 - val_loss: 0.0043 - val_mae: 0.0508\n",
      "Epoch 22/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - loss: 0.0055 - mae: 0.0553 - val_loss: 0.0046 - val_mae: 0.0547\n",
      "Epoch 23/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - loss: 0.0054 - mae: 0.0552 - val_loss: 0.0049 - val_mae: 0.0528\n",
      "Epoch 24/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - loss: 0.0054 - mae: 0.0551 - val_loss: 0.0042 - val_mae: 0.0511\n",
      "Epoch 25/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - loss: 0.0054 - mae: 0.0551 - val_loss: 0.0042 - val_mae: 0.0514\n",
      "Epoch 26/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 10ms/step - loss: 0.0054 - mae: 0.0551 - val_loss: 0.0047 - val_mae: 0.0517\n",
      "Epoch 27/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - loss: 0.0054 - mae: 0.0550 - val_loss: 0.0042 - val_mae: 0.0506\n",
      "Epoch 28/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - loss: 0.0054 - mae: 0.0550 - val_loss: 0.0046 - val_mae: 0.0546\n",
      "Epoch 29/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - loss: 0.0054 - mae: 0.0549 - val_loss: 0.0045 - val_mae: 0.0511\n",
      "Epoch 30/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - loss: 0.0054 - mae: 0.0549 - val_loss: 0.0045 - val_mae: 0.0512\n",
      "Epoch 31/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - loss: 0.0054 - mae: 0.0551 - val_loss: 0.0042 - val_mae: 0.0516\n",
      "Epoch 32/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - loss: 0.0054 - mae: 0.0549 - val_loss: 0.0046 - val_mae: 0.0518\n",
      "Epoch 33/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - loss: 0.0054 - mae: 0.0549 - val_loss: 0.0042 - val_mae: 0.0510\n",
      "Epoch 34/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - loss: 0.0054 - mae: 0.0549 - val_loss: 0.0043 - val_mae: 0.0508\n",
      "Epoch 35/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - loss: 0.0054 - mae: 0.0550 - val_loss: 0.0042 - val_mae: 0.0507\n",
      "Epoch 36/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - loss: 0.0054 - mae: 0.0549 - val_loss: 0.0053 - val_mae: 0.0600\n",
      "Epoch 37/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - loss: 0.0054 - mae: 0.0549 - val_loss: 0.0042 - val_mae: 0.0510\n",
      "Epoch 38/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - loss: 0.0054 - mae: 0.0549 - val_loss: 0.0056 - val_mae: 0.0566\n",
      "Epoch 39/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - loss: 0.0054 - mae: 0.0549 - val_loss: 0.0043 - val_mae: 0.0525\n",
      "Epoch 40/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - loss: 0.0054 - mae: 0.0549 - val_loss: 0.0044 - val_mae: 0.0504\n",
      "Epoch 41/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - loss: 0.0054 - mae: 0.0549 - val_loss: 0.0058 - val_mae: 0.0580\n",
      "Epoch 42/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - loss: 0.0054 - mae: 0.0549 - val_loss: 0.0043 - val_mae: 0.0504\n",
      "Epoch 43/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - loss: 0.0054 - mae: 0.0549 - val_loss: 0.0047 - val_mae: 0.0513\n",
      "Epoch 44/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - loss: 0.0054 - mae: 0.0548 - val_loss: 0.0043 - val_mae: 0.0504\n",
      "Epoch 45/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - loss: 0.0054 - mae: 0.0548 - val_loss: 0.0045 - val_mae: 0.0504\n",
      "Epoch 46/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - loss: 0.0054 - mae: 0.0549 - val_loss: 0.0045 - val_mae: 0.0503\n",
      "Epoch 47/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - loss: 0.0054 - mae: 0.0549 - val_loss: 0.0044 - val_mae: 0.0503\n",
      "Epoch 48/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - loss: 0.0054 - mae: 0.0549 - val_loss: 0.0048 - val_mae: 0.0517\n",
      "Epoch 49/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - loss: 0.0054 - mae: 0.0549 - val_loss: 0.0050 - val_mae: 0.0523\n",
      "Epoch 50/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - loss: 0.0054 - mae: 0.0548 - val_loss: 0.0043 - val_mae: 0.0513\n",
      "Epoch 51/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - loss: 0.0054 - mae: 0.0548 - val_loss: 0.0043 - val_mae: 0.0507\n",
      "Epoch 52/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - loss: 0.0054 - mae: 0.0548 - val_loss: 0.0045 - val_mae: 0.0506\n",
      "Epoch 53/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - loss: 0.0054 - mae: 0.0549 - val_loss: 0.0048 - val_mae: 0.0514\n",
      "Epoch 54/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - loss: 0.0054 - mae: 0.0547 - val_loss: 0.0044 - val_mae: 0.0503\n",
      "Epoch 55/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - loss: 0.0054 - mae: 0.0548 - val_loss: 0.0047 - val_mae: 0.0511\n",
      "Epoch 56/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - loss: 0.0054 - mae: 0.0547 - val_loss: 0.0044 - val_mae: 0.0503\n",
      "Epoch 57/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - loss: 0.0054 - mae: 0.0549 - val_loss: 0.0044 - val_mae: 0.0503\n",
      "Epoch 58/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - loss: 0.0054 - mae: 0.0548 - val_loss: 0.0043 - val_mae: 0.0506\n",
      "Epoch 59/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - loss: 0.0054 - mae: 0.0548 - val_loss: 0.0048 - val_mae: 0.0515\n",
      "Epoch 60/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - loss: 0.0054 - mae: 0.0547 - val_loss: 0.0048 - val_mae: 0.0514\n",
      "Epoch 61/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - loss: 0.0054 - mae: 0.0548 - val_loss: 0.0043 - val_mae: 0.0506\n",
      "Epoch 62/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - loss: 0.0054 - mae: 0.0547 - val_loss: 0.0045 - val_mae: 0.0504\n",
      "Epoch 63/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - loss: 0.0054 - mae: 0.0548 - val_loss: 0.0044 - val_mae: 0.0503\n",
      "Epoch 64/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - loss: 0.0054 - mae: 0.0547 - val_loss: 0.0046 - val_mae: 0.0508\n",
      "Epoch 65/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - loss: 0.0054 - mae: 0.0548 - val_loss: 0.0044 - val_mae: 0.0503\n",
      "Epoch 66/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - loss: 0.0054 - mae: 0.0548 - val_loss: 0.0043 - val_mae: 0.0506\n",
      "Epoch 67/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - loss: 0.0054 - mae: 0.0548 - val_loss: 0.0057 - val_mae: 0.0571\n",
      "Epoch 68/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - loss: 0.0054 - mae: 0.0547 - val_loss: 0.0043 - val_mae: 0.0505\n",
      "Epoch 69/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - loss: 0.0054 - mae: 0.0548 - val_loss: 0.0044 - val_mae: 0.0506\n",
      "Epoch 70/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - loss: 0.0054 - mae: 0.0548 - val_loss: 0.0044 - val_mae: 0.0504\n",
      "Epoch 71/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - loss: 0.0054 - mae: 0.0547 - val_loss: 0.0044 - val_mae: 0.0503\n",
      "Epoch 72/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - loss: 0.0054 - mae: 0.0548 - val_loss: 0.0043 - val_mae: 0.0506\n",
      "Epoch 73/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - loss: 0.0054 - mae: 0.0548 - val_loss: 0.0051 - val_mae: 0.0528\n",
      "Epoch 74/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - loss: 0.0054 - mae: 0.0547 - val_loss: 0.0045 - val_mae: 0.0504\n",
      "Epoch 75/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - loss: 0.0054 - mae: 0.0548 - val_loss: 0.0051 - val_mae: 0.0527\n",
      "Epoch 76/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - loss: 0.0054 - mae: 0.0547 - val_loss: 0.0048 - val_mae: 0.0517\n",
      "Epoch 77/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - loss: 0.0054 - mae: 0.0548 - val_loss: 0.0043 - val_mae: 0.0510\n",
      "Epoch 78/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - loss: 0.0054 - mae: 0.0548 - val_loss: 0.0044 - val_mae: 0.0504\n",
      "Epoch 79/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - loss: 0.0054 - mae: 0.0547 - val_loss: 0.0044 - val_mae: 0.0503\n",
      "Epoch 80/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - loss: 0.0054 - mae: 0.0548 - val_loss: 0.0045 - val_mae: 0.0503\n",
      "Epoch 81/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - loss: 0.0054 - mae: 0.0547 - val_loss: 0.0043 - val_mae: 0.0506\n",
      "Epoch 82/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - loss: 0.0054 - mae: 0.0547 - val_loss: 0.0043 - val_mae: 0.0510\n",
      "Epoch 83/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - loss: 0.0054 - mae: 0.0548 - val_loss: 0.0046 - val_mae: 0.0505\n",
      "Epoch 84/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - loss: 0.0054 - mae: 0.0548 - val_loss: 0.0044 - val_mae: 0.0503\n",
      "Epoch 85/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - loss: 0.0054 - mae: 0.0547 - val_loss: 0.0043 - val_mae: 0.0504\n",
      "Epoch 86/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - loss: 0.0054 - mae: 0.0548 - val_loss: 0.0043 - val_mae: 0.0516\n",
      "Epoch 87/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - loss: 0.0054 - mae: 0.0548 - val_loss: 0.0043 - val_mae: 0.0507\n",
      "Epoch 88/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - loss: 0.0054 - mae: 0.0547 - val_loss: 0.0045 - val_mae: 0.0503\n",
      "Epoch 89/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - loss: 0.0054 - mae: 0.0548 - val_loss: 0.0044 - val_mae: 0.0503\n",
      "Epoch 90/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - loss: 0.0054 - mae: 0.0548 - val_loss: 0.0045 - val_mae: 0.0505\n",
      "Epoch 91/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - loss: 0.0054 - mae: 0.0548 - val_loss: 0.0044 - val_mae: 0.0503\n",
      "Epoch 92/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - loss: 0.0054 - mae: 0.0548 - val_loss: 0.0043 - val_mae: 0.0503\n",
      "Epoch 93/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - loss: 0.0054 - mae: 0.0548 - val_loss: 0.0045 - val_mae: 0.0505\n",
      "Epoch 94/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - loss: 0.0054 - mae: 0.0547 - val_loss: 0.0042 - val_mae: 0.0506\n",
      "Epoch 95/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - loss: 0.0054 - mae: 0.0548 - val_loss: 0.0043 - val_mae: 0.0503\n",
      "Epoch 96/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - loss: 0.0054 - mae: 0.0548 - val_loss: 0.0047 - val_mae: 0.0509\n",
      "Epoch 97/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - loss: 0.0054 - mae: 0.0548 - val_loss: 0.0044 - val_mae: 0.0503\n",
      "Epoch 98/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - loss: 0.0054 - mae: 0.0549 - val_loss: 0.0043 - val_mae: 0.0504\n",
      "Epoch 99/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - loss: 0.0054 - mae: 0.0547 - val_loss: 0.0044 - val_mae: 0.0502\n",
      "Epoch 100/100\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - loss: 0.0054 - mae: 0.0548 - val_loss: 0.0045 - val_mae: 0.0503\n",
      "\u001b[1m1030/1030\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step\n",
      "✅ Done with wheat_Belgaum_daily.csv | MAE=304.55, RMSE=409.13, R2=0.5587, MAPE=14.5%, Accuracy=85.5%\n",
      "Saved updated CSV with Date, Actual & Predicted: tat_mqa_output_csv\\wheat_Belgaum_daily_tat_mqa_updated.csv\n",
      "🚀 Processing: wheat_Bellary_daily.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_25\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_25\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_query_attention_3       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">17,216</span> │ input_layer_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiQueryAttention</span>)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_query_attention_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                               │                           │                 │ input_layer_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_50        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_50[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_103 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ layer_normalization_50[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_104 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dense_103[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_51 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_50[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                               │                           │                 │ dense_104[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_51        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_51[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_25   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_51[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_105 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ global_average_pooling1d_… │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_25 (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_query_attention_3       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │          \u001b[38;5;34m17,216\u001b[0m │ input_layer_25[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mMultiQueryAttention\u001b[0m)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_50 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ multi_query_attention_3[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                               │                           │                 │ input_layer_25[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_50        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ add_50[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_103 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │           \u001b[38;5;34m8,320\u001b[0m │ layer_normalization_50[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_104 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │             \u001b[38;5;34m129\u001b[0m │ dense_103[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_51 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_50[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                               │                           │                 │ dense_104[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_51        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ add_51[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_25   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_51[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_105 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │              \u001b[38;5;34m65\u001b[0m │ global_average_pooling1d_… │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,986</span> (101.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25,986\u001b[0m (101.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,986</span> (101.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m25,986\u001b[0m (101.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 18ms/step - loss: 0.0138 - mae: 0.0717 - val_loss: 0.0141 - val_mae: 0.0892\n",
      "Epoch 2/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - loss: 0.0039 - mae: 0.0495 - val_loss: 0.0173 - val_mae: 0.0958\n",
      "Epoch 3/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - loss: 0.0036 - mae: 0.0475 - val_loss: 0.0221 - val_mae: 0.1071\n",
      "Epoch 4/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 19ms/step - loss: 0.0036 - mae: 0.0474 - val_loss: 0.0197 - val_mae: 0.1005\n",
      "Epoch 5/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 19ms/step - loss: 0.0035 - mae: 0.0464 - val_loss: 0.0171 - val_mae: 0.0953\n",
      "Epoch 6/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - loss: 0.0035 - mae: 0.0465 - val_loss: 0.0181 - val_mae: 0.0975\n",
      "Epoch 7/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - loss: 0.0035 - mae: 0.0465 - val_loss: 0.0194 - val_mae: 0.0999\n",
      "Epoch 8/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - loss: 0.0033 - mae: 0.0454 - val_loss: 0.0167 - val_mae: 0.0946\n",
      "Epoch 9/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - loss: 0.0033 - mae: 0.0455 - val_loss: 0.0136 - val_mae: 0.0881\n",
      "Epoch 10/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - loss: 0.0034 - mae: 0.0458 - val_loss: 0.0142 - val_mae: 0.0893\n",
      "Epoch 11/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - loss: 0.0033 - mae: 0.0454 - val_loss: 0.0137 - val_mae: 0.0883\n",
      "Epoch 12/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 19ms/step - loss: 0.0033 - mae: 0.0450 - val_loss: 0.0142 - val_mae: 0.0892\n",
      "Epoch 13/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 20ms/step - loss: 0.0033 - mae: 0.0452 - val_loss: 0.0150 - val_mae: 0.0909\n",
      "Epoch 14/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 19ms/step - loss: 0.0033 - mae: 0.0455 - val_loss: 0.0164 - val_mae: 0.0939\n",
      "Epoch 15/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - loss: 0.0032 - mae: 0.0449 - val_loss: 0.0140 - val_mae: 0.0889\n",
      "Epoch 16/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - loss: 0.0033 - mae: 0.0452 - val_loss: 0.0138 - val_mae: 0.0884\n",
      "Epoch 17/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - loss: 0.0032 - mae: 0.0448 - val_loss: 0.0149 - val_mae: 0.0907\n",
      "Epoch 18/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - loss: 0.0032 - mae: 0.0448 - val_loss: 0.0122 - val_mae: 0.0848\n",
      "Epoch 19/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - loss: 0.0032 - mae: 0.0449 - val_loss: 0.0150 - val_mae: 0.0907\n",
      "Epoch 20/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - loss: 0.0032 - mae: 0.0445 - val_loss: 0.0133 - val_mae: 0.0870\n",
      "Epoch 21/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - loss: 0.0032 - mae: 0.0444 - val_loss: 0.0106 - val_mae: 0.0810\n",
      "Epoch 22/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - loss: 0.0032 - mae: 0.0445 - val_loss: 0.0121 - val_mae: 0.0846\n",
      "Epoch 23/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - loss: 0.0032 - mae: 0.0444 - val_loss: 0.0130 - val_mae: 0.0863\n",
      "Epoch 24/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - loss: 0.0031 - mae: 0.0441 - val_loss: 0.0113 - val_mae: 0.0827\n",
      "Epoch 25/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - loss: 0.0032 - mae: 0.0442 - val_loss: 0.0098 - val_mae: 0.0798\n",
      "Epoch 26/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 0.0031 - mae: 0.0443 - val_loss: 0.0115 - val_mae: 0.0829\n",
      "Epoch 27/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - loss: 0.0031 - mae: 0.0442 - val_loss: 0.0112 - val_mae: 0.0823\n",
      "Epoch 28/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - loss: 0.0031 - mae: 0.0440 - val_loss: 0.0116 - val_mae: 0.0832\n",
      "Epoch 29/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 0.0031 - mae: 0.0441 - val_loss: 0.0116 - val_mae: 0.0827\n",
      "Epoch 30/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 0.0031 - mae: 0.0441 - val_loss: 0.0093 - val_mae: 0.0793\n",
      "Epoch 31/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - loss: 0.0032 - mae: 0.0442 - val_loss: 0.0104 - val_mae: 0.0807\n",
      "Epoch 32/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - loss: 0.0031 - mae: 0.0439 - val_loss: 0.0120 - val_mae: 0.0837\n",
      "Epoch 33/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - loss: 0.0031 - mae: 0.0441 - val_loss: 0.0104 - val_mae: 0.0809\n",
      "Epoch 34/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - loss: 0.0031 - mae: 0.0439 - val_loss: 0.0094 - val_mae: 0.0794\n",
      "Epoch 35/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - loss: 0.0031 - mae: 0.0439 - val_loss: 0.0107 - val_mae: 0.0812\n",
      "Epoch 36/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - loss: 0.0031 - mae: 0.0441 - val_loss: 0.0091 - val_mae: 0.0791\n",
      "Epoch 37/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - loss: 0.0031 - mae: 0.0440 - val_loss: 0.0131 - val_mae: 0.0862\n",
      "Epoch 38/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 15ms/step - loss: 0.0031 - mae: 0.0439 - val_loss: 0.0125 - val_mae: 0.0849\n",
      "Epoch 39/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - loss: 0.0031 - mae: 0.0439 - val_loss: 0.0101 - val_mae: 0.0802\n",
      "Epoch 40/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - loss: 0.0031 - mae: 0.0440 - val_loss: 0.0121 - val_mae: 0.0841\n",
      "Epoch 41/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - loss: 0.0031 - mae: 0.0439 - val_loss: 0.0094 - val_mae: 0.0792\n",
      "Epoch 42/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - loss: 0.0031 - mae: 0.0440 - val_loss: 0.0095 - val_mae: 0.0794\n",
      "Epoch 43/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - loss: 0.0031 - mae: 0.0438 - val_loss: 0.0097 - val_mae: 0.0796\n",
      "Epoch 44/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - loss: 0.0031 - mae: 0.0439 - val_loss: 0.0092 - val_mae: 0.0790\n",
      "Epoch 45/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - loss: 0.0031 - mae: 0.0439 - val_loss: 0.0104 - val_mae: 0.0805\n",
      "Epoch 46/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 15ms/step - loss: 0.0031 - mae: 0.0440 - val_loss: 0.0098 - val_mae: 0.0795\n",
      "Epoch 47/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - loss: 0.0031 - mae: 0.0439 - val_loss: 0.0113 - val_mae: 0.0822\n",
      "Epoch 48/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - loss: 0.0031 - mae: 0.0438 - val_loss: 0.0104 - val_mae: 0.0806\n",
      "Epoch 49/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - loss: 0.0031 - mae: 0.0438 - val_loss: 0.0090 - val_mae: 0.0789\n",
      "Epoch 50/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - loss: 0.0031 - mae: 0.0439 - val_loss: 0.0106 - val_mae: 0.0810\n",
      "Epoch 51/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - loss: 0.0031 - mae: 0.0437 - val_loss: 0.0095 - val_mae: 0.0792\n",
      "Epoch 52/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - loss: 0.0031 - mae: 0.0437 - val_loss: 0.0108 - val_mae: 0.0812\n",
      "Epoch 53/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - loss: 0.0031 - mae: 0.0437 - val_loss: 0.0107 - val_mae: 0.0810\n",
      "Epoch 54/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - loss: 0.0031 - mae: 0.0437 - val_loss: 0.0095 - val_mae: 0.0791\n",
      "Epoch 55/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - loss: 0.0031 - mae: 0.0438 - val_loss: 0.0102 - val_mae: 0.0802\n",
      "Epoch 56/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - loss: 0.0031 - mae: 0.0437 - val_loss: 0.0109 - val_mae: 0.0811\n",
      "Epoch 57/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - loss: 0.0031 - mae: 0.0438 - val_loss: 0.0105 - val_mae: 0.0804\n",
      "Epoch 58/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - loss: 0.0031 - mae: 0.0439 - val_loss: 0.0117 - val_mae: 0.0834\n",
      "Epoch 59/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - loss: 0.0031 - mae: 0.0437 - val_loss: 0.0112 - val_mae: 0.0819\n",
      "Epoch 60/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - loss: 0.0031 - mae: 0.0437 - val_loss: 0.0108 - val_mae: 0.0810\n",
      "Epoch 61/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - loss: 0.0031 - mae: 0.0437 - val_loss: 0.0115 - val_mae: 0.0823\n",
      "Epoch 62/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - loss: 0.0031 - mae: 0.0437 - val_loss: 0.0110 - val_mae: 0.0812\n",
      "Epoch 63/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - loss: 0.0031 - mae: 0.0437 - val_loss: 0.0107 - val_mae: 0.0805\n",
      "Epoch 64/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - loss: 0.0031 - mae: 0.0437 - val_loss: 0.0116 - val_mae: 0.0827\n",
      "Epoch 65/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - loss: 0.0031 - mae: 0.0437 - val_loss: 0.0094 - val_mae: 0.0790\n",
      "Epoch 66/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - loss: 0.0031 - mae: 0.0437 - val_loss: 0.0110 - val_mae: 0.0812\n",
      "Epoch 67/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - loss: 0.0031 - mae: 0.0437 - val_loss: 0.0111 - val_mae: 0.0814\n",
      "Epoch 68/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - loss: 0.0031 - mae: 0.0437 - val_loss: 0.0105 - val_mae: 0.0799\n",
      "Epoch 69/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - loss: 0.0031 - mae: 0.0437 - val_loss: 0.0115 - val_mae: 0.0826\n",
      "Epoch 70/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - loss: 0.0031 - mae: 0.0437 - val_loss: 0.0117 - val_mae: 0.0826\n",
      "Epoch 71/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - loss: 0.0031 - mae: 0.0436 - val_loss: 0.0111 - val_mae: 0.0815\n",
      "Epoch 72/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - loss: 0.0031 - mae: 0.0437 - val_loss: 0.0109 - val_mae: 0.0808\n",
      "Epoch 73/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - loss: 0.0031 - mae: 0.0438 - val_loss: 0.0104 - val_mae: 0.0794\n",
      "Epoch 74/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - loss: 0.0031 - mae: 0.0437 - val_loss: 0.0115 - val_mae: 0.0823\n",
      "Epoch 75/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - loss: 0.0031 - mae: 0.0436 - val_loss: 0.0133 - val_mae: 0.0863\n",
      "Epoch 76/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - loss: 0.0031 - mae: 0.0436 - val_loss: 0.0111 - val_mae: 0.0814\n",
      "Epoch 77/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - loss: 0.0031 - mae: 0.0437 - val_loss: 0.0114 - val_mae: 0.0823\n",
      "Epoch 78/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - loss: 0.0031 - mae: 0.0436 - val_loss: 0.0107 - val_mae: 0.0800\n",
      "Epoch 79/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - loss: 0.0031 - mae: 0.0437 - val_loss: 0.0122 - val_mae: 0.0834\n",
      "Epoch 80/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - loss: 0.0031 - mae: 0.0437 - val_loss: 0.0125 - val_mae: 0.0845\n",
      "Epoch 81/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - loss: 0.0031 - mae: 0.0437 - val_loss: 0.0118 - val_mae: 0.0830\n",
      "Epoch 82/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - loss: 0.0031 - mae: 0.0436 - val_loss: 0.0119 - val_mae: 0.0829\n",
      "Epoch 83/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - loss: 0.0031 - mae: 0.0437 - val_loss: 0.0106 - val_mae: 0.0795\n",
      "Epoch 84/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - loss: 0.0030 - mae: 0.0436 - val_loss: 0.0123 - val_mae: 0.0836\n",
      "Epoch 85/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - loss: 0.0030 - mae: 0.0436 - val_loss: 0.0111 - val_mae: 0.0808\n",
      "Epoch 86/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - loss: 0.0030 - mae: 0.0436 - val_loss: 0.0136 - val_mae: 0.0868\n",
      "Epoch 87/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - loss: 0.0030 - mae: 0.0436 - val_loss: 0.0121 - val_mae: 0.0835\n",
      "Epoch 88/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - loss: 0.0031 - mae: 0.0436 - val_loss: 0.0118 - val_mae: 0.0826\n",
      "Epoch 89/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - loss: 0.0030 - mae: 0.0436 - val_loss: 0.0122 - val_mae: 0.0839\n",
      "Epoch 90/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - loss: 0.0030 - mae: 0.0436 - val_loss: 0.0129 - val_mae: 0.0849\n",
      "Epoch 91/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - loss: 0.0030 - mae: 0.0435 - val_loss: 0.0110 - val_mae: 0.0811\n",
      "Epoch 92/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - loss: 0.0030 - mae: 0.0436 - val_loss: 0.0130 - val_mae: 0.0851\n",
      "Epoch 93/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - loss: 0.0030 - mae: 0.0436 - val_loss: 0.0128 - val_mae: 0.0850\n",
      "Epoch 94/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - loss: 0.0030 - mae: 0.0436 - val_loss: 0.0115 - val_mae: 0.0823\n",
      "Epoch 95/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - loss: 0.0030 - mae: 0.0436 - val_loss: 0.0124 - val_mae: 0.0833\n",
      "Epoch 96/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - loss: 0.0030 - mae: 0.0436 - val_loss: 0.0119 - val_mae: 0.0832\n",
      "Epoch 97/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - loss: 0.0030 - mae: 0.0435 - val_loss: 0.0122 - val_mae: 0.0828\n",
      "Epoch 98/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - loss: 0.0030 - mae: 0.0436 - val_loss: 0.0115 - val_mae: 0.0824\n",
      "Epoch 99/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - loss: 0.0030 - mae: 0.0436 - val_loss: 0.0118 - val_mae: 0.0830\n",
      "Epoch 100/100\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - loss: 0.0030 - mae: 0.0435 - val_loss: 0.0127 - val_mae: 0.0842\n",
      "\u001b[1m484/484\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step \n",
      "✅ Done with wheat_Bellary_daily.csv | MAE=374.72, RMSE=512.27, R2=0.4617, MAPE=23.1%, Accuracy=76.9%\n",
      "Saved updated CSV with Date, Actual & Predicted: tat_mqa_output_csv\\wheat_Bellary_daily_tat_mqa_updated.csv\n",
      "🚀 Processing: wheat_Bidar_daily.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_26\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_26\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_query_attention_4       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">17,216</span> │ input_layer_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiQueryAttention</span>)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_52 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_query_attention_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                               │                           │                 │ input_layer_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_52        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_52[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_113 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ layer_normalization_52[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_114 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dense_113[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_53 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_52[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                               │                           │                 │ dense_114[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_53        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_53[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_26   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_53[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_115 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ global_average_pooling1d_… │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_26 (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_query_attention_4       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │          \u001b[38;5;34m17,216\u001b[0m │ input_layer_26[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mMultiQueryAttention\u001b[0m)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_52 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ multi_query_attention_4[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                               │                           │                 │ input_layer_26[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_52        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ add_52[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_113 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │           \u001b[38;5;34m8,320\u001b[0m │ layer_normalization_52[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_114 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │             \u001b[38;5;34m129\u001b[0m │ dense_113[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_53 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_52[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                               │                           │                 │ dense_114[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_53        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ add_53[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_26   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_53[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_115 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │              \u001b[38;5;34m65\u001b[0m │ global_average_pooling1d_… │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,986</span> (101.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25,986\u001b[0m (101.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,986</span> (101.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m25,986\u001b[0m (101.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - loss: 0.0284 - mae: 0.0932 - val_loss: 0.0072 - val_mae: 0.0636\n",
      "Epoch 2/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.0060 - mae: 0.0609 - val_loss: 0.0068 - val_mae: 0.0618\n",
      "Epoch 3/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - loss: 0.0054 - mae: 0.0579 - val_loss: 0.0080 - val_mae: 0.0673\n",
      "Epoch 4/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.0049 - mae: 0.0549 - val_loss: 0.0106 - val_mae: 0.0789\n",
      "Epoch 5/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - loss: 0.0048 - mae: 0.0544 - val_loss: 0.0065 - val_mae: 0.0605\n",
      "Epoch 6/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.0047 - mae: 0.0537 - val_loss: 0.0059 - val_mae: 0.0587\n",
      "Epoch 7/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 0.0046 - mae: 0.0527 - val_loss: 0.0071 - val_mae: 0.0628\n",
      "Epoch 8/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 0.0045 - mae: 0.0522 - val_loss: 0.0056 - val_mae: 0.0580\n",
      "Epoch 9/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 0.0044 - mae: 0.0514 - val_loss: 0.0055 - val_mae: 0.0566\n",
      "Epoch 10/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 0.0043 - mae: 0.0511 - val_loss: 0.0063 - val_mae: 0.0598\n",
      "Epoch 11/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.0043 - mae: 0.0508 - val_loss: 0.0054 - val_mae: 0.0569\n",
      "Epoch 12/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 0.0042 - mae: 0.0504 - val_loss: 0.0054 - val_mae: 0.0560\n",
      "Epoch 13/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.0042 - mae: 0.0500 - val_loss: 0.0057 - val_mae: 0.0587\n",
      "Epoch 14/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 0.0042 - mae: 0.0502 - val_loss: 0.0059 - val_mae: 0.0596\n",
      "Epoch 15/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0042 - mae: 0.0499 - val_loss: 0.0065 - val_mae: 0.0630\n",
      "Epoch 16/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.0042 - mae: 0.0499 - val_loss: 0.0093 - val_mae: 0.0795\n",
      "Epoch 17/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.0042 - mae: 0.0499 - val_loss: 0.0062 - val_mae: 0.0615\n",
      "Epoch 18/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.0041 - mae: 0.0491 - val_loss: 0.0054 - val_mae: 0.0569\n",
      "Epoch 19/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.0041 - mae: 0.0495 - val_loss: 0.0057 - val_mae: 0.0582\n",
      "Epoch 20/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.0041 - mae: 0.0493 - val_loss: 0.0065 - val_mae: 0.0633\n",
      "Epoch 21/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.0041 - mae: 0.0492 - val_loss: 0.0060 - val_mae: 0.0603\n",
      "Epoch 22/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 0.0040 - mae: 0.0490 - val_loss: 0.0055 - val_mae: 0.0574\n",
      "Epoch 23/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 0.0041 - mae: 0.0493 - val_loss: 0.0069 - val_mae: 0.0649\n",
      "Epoch 24/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.0041 - mae: 0.0492 - val_loss: 0.0060 - val_mae: 0.0603\n",
      "Epoch 25/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.0041 - mae: 0.0491 - val_loss: 0.0071 - val_mae: 0.0664\n",
      "Epoch 26/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.0041 - mae: 0.0492 - val_loss: 0.0057 - val_mae: 0.0588\n",
      "Epoch 27/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.0040 - mae: 0.0490 - val_loss: 0.0057 - val_mae: 0.0586\n",
      "Epoch 28/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 0.0041 - mae: 0.0491 - val_loss: 0.0055 - val_mae: 0.0572\n",
      "Epoch 29/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 0.0041 - mae: 0.0492 - val_loss: 0.0060 - val_mae: 0.0598\n",
      "Epoch 30/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.0040 - mae: 0.0491 - val_loss: 0.0058 - val_mae: 0.0591\n",
      "Epoch 31/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.0040 - mae: 0.0489 - val_loss: 0.0054 - val_mae: 0.0570\n",
      "Epoch 32/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 0.0040 - mae: 0.0488 - val_loss: 0.0070 - val_mae: 0.0658\n",
      "Epoch 33/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0040 - mae: 0.0490 - val_loss: 0.0067 - val_mae: 0.0640\n",
      "Epoch 34/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - loss: 0.0040 - mae: 0.0489 - val_loss: 0.0053 - val_mae: 0.0561\n",
      "Epoch 35/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.0040 - mae: 0.0488 - val_loss: 0.0067 - val_mae: 0.0643\n",
      "Epoch 36/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - loss: 0.0040 - mae: 0.0490 - val_loss: 0.0076 - val_mae: 0.0693\n",
      "Epoch 37/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 0.0040 - mae: 0.0488 - val_loss: 0.0053 - val_mae: 0.0561\n",
      "Epoch 38/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 0.0040 - mae: 0.0490 - val_loss: 0.0068 - val_mae: 0.0650\n",
      "Epoch 39/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.0040 - mae: 0.0489 - val_loss: 0.0063 - val_mae: 0.0618\n",
      "Epoch 40/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0040 - mae: 0.0488 - val_loss: 0.0071 - val_mae: 0.0667\n",
      "Epoch 41/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 0.0040 - mae: 0.0488 - val_loss: 0.0072 - val_mae: 0.0667\n",
      "Epoch 42/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.0040 - mae: 0.0487 - val_loss: 0.0080 - val_mae: 0.0718\n",
      "Epoch 43/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.0040 - mae: 0.0488 - val_loss: 0.0057 - val_mae: 0.0585\n",
      "Epoch 44/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0040 - mae: 0.0490 - val_loss: 0.0065 - val_mae: 0.0633\n",
      "Epoch 45/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.0040 - mae: 0.0489 - val_loss: 0.0060 - val_mae: 0.0602\n",
      "Epoch 46/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.0040 - mae: 0.0487 - val_loss: 0.0058 - val_mae: 0.0589\n",
      "Epoch 47/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.0040 - mae: 0.0488 - val_loss: 0.0053 - val_mae: 0.0561\n",
      "Epoch 48/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.0040 - mae: 0.0486 - val_loss: 0.0068 - val_mae: 0.0646\n",
      "Epoch 49/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.0040 - mae: 0.0487 - val_loss: 0.0062 - val_mae: 0.0612\n",
      "Epoch 50/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 0.0040 - mae: 0.0487 - val_loss: 0.0060 - val_mae: 0.0597\n",
      "Epoch 51/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0040 - mae: 0.0487 - val_loss: 0.0066 - val_mae: 0.0633\n",
      "Epoch 52/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.0040 - mae: 0.0489 - val_loss: 0.0053 - val_mae: 0.0563\n",
      "Epoch 53/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.0040 - mae: 0.0486 - val_loss: 0.0070 - val_mae: 0.0657\n",
      "Epoch 54/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - loss: 0.0040 - mae: 0.0487 - val_loss: 0.0062 - val_mae: 0.0610\n",
      "Epoch 55/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - loss: 0.0040 - mae: 0.0487 - val_loss: 0.0068 - val_mae: 0.0647\n",
      "Epoch 56/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 0.0040 - mae: 0.0488 - val_loss: 0.0077 - val_mae: 0.0698\n",
      "Epoch 57/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.0040 - mae: 0.0487 - val_loss: 0.0056 - val_mae: 0.0577\n",
      "Epoch 58/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 0.0040 - mae: 0.0486 - val_loss: 0.0070 - val_mae: 0.0659\n",
      "Epoch 59/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.0040 - mae: 0.0488 - val_loss: 0.0053 - val_mae: 0.0564\n",
      "Epoch 60/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.0040 - mae: 0.0487 - val_loss: 0.0082 - val_mae: 0.0728\n",
      "Epoch 61/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.0040 - mae: 0.0487 - val_loss: 0.0055 - val_mae: 0.0573\n",
      "Epoch 62/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.0040 - mae: 0.0487 - val_loss: 0.0064 - val_mae: 0.0623\n",
      "Epoch 63/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.0040 - mae: 0.0486 - val_loss: 0.0061 - val_mae: 0.0607\n",
      "Epoch 64/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.0040 - mae: 0.0486 - val_loss: 0.0058 - val_mae: 0.0588\n",
      "Epoch 65/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.0040 - mae: 0.0488 - val_loss: 0.0070 - val_mae: 0.0661\n",
      "Epoch 66/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0040 - mae: 0.0485 - val_loss: 0.0054 - val_mae: 0.0571\n",
      "Epoch 67/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.0040 - mae: 0.0487 - val_loss: 0.0071 - val_mae: 0.0665\n",
      "Epoch 68/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0040 - mae: 0.0487 - val_loss: 0.0059 - val_mae: 0.0595\n",
      "Epoch 69/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.0040 - mae: 0.0486 - val_loss: 0.0056 - val_mae: 0.0582\n",
      "Epoch 70/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 0.0040 - mae: 0.0486 - val_loss: 0.0054 - val_mae: 0.0570\n",
      "Epoch 71/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.0040 - mae: 0.0486 - val_loss: 0.0063 - val_mae: 0.0617\n",
      "Epoch 72/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 0.0040 - mae: 0.0486 - val_loss: 0.0058 - val_mae: 0.0589\n",
      "Epoch 73/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0040 - mae: 0.0486 - val_loss: 0.0067 - val_mae: 0.0637\n",
      "Epoch 74/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - loss: 0.0040 - mae: 0.0486 - val_loss: 0.0060 - val_mae: 0.0600\n",
      "Epoch 75/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0040 - mae: 0.0486 - val_loss: 0.0067 - val_mae: 0.0635\n",
      "Epoch 76/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.0040 - mae: 0.0485 - val_loss: 0.0058 - val_mae: 0.0590\n",
      "Epoch 77/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.0040 - mae: 0.0485 - val_loss: 0.0056 - val_mae: 0.0579\n",
      "Epoch 78/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 0.0040 - mae: 0.0486 - val_loss: 0.0058 - val_mae: 0.0587\n",
      "Epoch 79/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 0.0040 - mae: 0.0485 - val_loss: 0.0054 - val_mae: 0.0565\n",
      "Epoch 80/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0040 - mae: 0.0485 - val_loss: 0.0055 - val_mae: 0.0573\n",
      "Epoch 81/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0040 - mae: 0.0486 - val_loss: 0.0068 - val_mae: 0.0643\n",
      "Epoch 82/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.0040 - mae: 0.0485 - val_loss: 0.0069 - val_mae: 0.0651\n",
      "Epoch 83/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 0.0040 - mae: 0.0485 - val_loss: 0.0057 - val_mae: 0.0585\n",
      "Epoch 84/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 0.0040 - mae: 0.0485 - val_loss: 0.0066 - val_mae: 0.0632\n",
      "Epoch 85/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 0.0040 - mae: 0.0486 - val_loss: 0.0053 - val_mae: 0.0561\n",
      "Epoch 86/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0040 - mae: 0.0485 - val_loss: 0.0058 - val_mae: 0.0591\n",
      "Epoch 87/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.0040 - mae: 0.0486 - val_loss: 0.0057 - val_mae: 0.0582\n",
      "Epoch 88/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0040 - mae: 0.0485 - val_loss: 0.0055 - val_mae: 0.0572\n",
      "Epoch 89/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.0040 - mae: 0.0485 - val_loss: 0.0062 - val_mae: 0.0613\n",
      "Epoch 90/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.0040 - mae: 0.0485 - val_loss: 0.0062 - val_mae: 0.0608\n",
      "Epoch 91/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.0040 - mae: 0.0486 - val_loss: 0.0060 - val_mae: 0.0598\n",
      "Epoch 92/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.0040 - mae: 0.0486 - val_loss: 0.0057 - val_mae: 0.0586\n",
      "Epoch 93/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.0040 - mae: 0.0484 - val_loss: 0.0074 - val_mae: 0.0676\n",
      "Epoch 94/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 0.0040 - mae: 0.0486 - val_loss: 0.0075 - val_mae: 0.0685\n",
      "Epoch 95/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.0040 - mae: 0.0486 - val_loss: 0.0058 - val_mae: 0.0589\n",
      "Epoch 96/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0040 - mae: 0.0485 - val_loss: 0.0057 - val_mae: 0.0582\n",
      "Epoch 97/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.0040 - mae: 0.0486 - val_loss: 0.0054 - val_mae: 0.0569\n",
      "Epoch 98/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0040 - mae: 0.0486 - val_loss: 0.0066 - val_mae: 0.0630\n",
      "Epoch 99/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.0040 - mae: 0.0485 - val_loss: 0.0060 - val_mae: 0.0597\n",
      "Epoch 100/100\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0040 - mae: 0.0486 - val_loss: 0.0058 - val_mae: 0.0591\n",
      "\u001b[1m508/508\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step\n",
      "✅ Done with wheat_Bidar_daily.csv | MAE=275.9, RMSE=350.38, R2=0.6569, MAPE=14.28%, Accuracy=85.72%\n",
      "Saved updated CSV with Date, Actual & Predicted: tat_mqa_output_csv\\wheat_Bidar_daily_tat_mqa_updated.csv\n",
      "🚀 Processing: wheat_Bijapur_daily.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_27\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_27\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_query_attention_5       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">17,216</span> │ input_layer_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiQueryAttention</span>)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_54 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_query_attention_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                               │                           │                 │ input_layer_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_54        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_54[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_123 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ layer_normalization_54[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_124 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dense_123[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_55 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_54[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                               │                           │                 │ dense_124[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_55        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_55[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_27   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_55[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_125 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ global_average_pooling1d_… │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_27 (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_query_attention_5       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │          \u001b[38;5;34m17,216\u001b[0m │ input_layer_27[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mMultiQueryAttention\u001b[0m)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_54 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ multi_query_attention_5[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                               │                           │                 │ input_layer_27[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_54        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ add_54[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_123 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │           \u001b[38;5;34m8,320\u001b[0m │ layer_normalization_54[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_124 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │             \u001b[38;5;34m129\u001b[0m │ dense_123[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_55 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_54[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                               │                           │                 │ dense_124[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_55        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ add_55[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_27   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_55[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_125 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │              \u001b[38;5;34m65\u001b[0m │ global_average_pooling1d_… │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,986</span> (101.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25,986\u001b[0m (101.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,986</span> (101.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m25,986\u001b[0m (101.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 13ms/step - loss: 0.0246 - mae: 0.0953 - val_loss: 0.0028 - val_mae: 0.0428\n",
      "Epoch 2/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.0070 - mae: 0.0646 - val_loss: 0.0019 - val_mae: 0.0346\n",
      "Epoch 3/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 0.0064 - mae: 0.0617 - val_loss: 0.0057 - val_mae: 0.0653\n",
      "Epoch 4/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.0059 - mae: 0.0591 - val_loss: 0.0018 - val_mae: 0.0325\n",
      "Epoch 5/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.0059 - mae: 0.0590 - val_loss: 0.0018 - val_mae: 0.0321\n",
      "Epoch 6/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.0057 - mae: 0.0581 - val_loss: 0.0024 - val_mae: 0.0395\n",
      "Epoch 7/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.0056 - mae: 0.0572 - val_loss: 0.0016 - val_mae: 0.0307\n",
      "Epoch 8/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.0055 - mae: 0.0567 - val_loss: 0.0025 - val_mae: 0.0410\n",
      "Epoch 9/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.0054 - mae: 0.0563 - val_loss: 0.0015 - val_mae: 0.0280\n",
      "Epoch 10/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.0054 - mae: 0.0561 - val_loss: 0.0015 - val_mae: 0.0289\n",
      "Epoch 11/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - loss: 0.0054 - mae: 0.0559 - val_loss: 0.0041 - val_mae: 0.0558\n",
      "Epoch 12/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.0053 - mae: 0.0554 - val_loss: 0.0014 - val_mae: 0.0264\n",
      "Epoch 13/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.0052 - mae: 0.0544 - val_loss: 0.0014 - val_mae: 0.0273\n",
      "Epoch 14/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.0053 - mae: 0.0552 - val_loss: 0.0016 - val_mae: 0.0293\n",
      "Epoch 15/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.0051 - mae: 0.0541 - val_loss: 0.0014 - val_mae: 0.0264\n",
      "Epoch 16/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 0.0051 - mae: 0.0539 - val_loss: 0.0019 - val_mae: 0.0327\n",
      "Epoch 17/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.0051 - mae: 0.0542 - val_loss: 0.0016 - val_mae: 0.0294\n",
      "Epoch 18/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 0.0051 - mae: 0.0538 - val_loss: 0.0014 - val_mae: 0.0268\n",
      "Epoch 19/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 0.0051 - mae: 0.0537 - val_loss: 0.0031 - val_mae: 0.0466\n",
      "Epoch 20/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.0051 - mae: 0.0538 - val_loss: 0.0022 - val_mae: 0.0376\n",
      "Epoch 21/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.0051 - mae: 0.0540 - val_loss: 0.0019 - val_mae: 0.0335\n",
      "Epoch 22/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.0051 - mae: 0.0536 - val_loss: 0.0022 - val_mae: 0.0369\n",
      "Epoch 23/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 0.0050 - mae: 0.0534 - val_loss: 0.0054 - val_mae: 0.0661\n",
      "Epoch 24/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.0051 - mae: 0.0536 - val_loss: 0.0014 - val_mae: 0.0261\n",
      "Epoch 25/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.0051 - mae: 0.0536 - val_loss: 0.0071 - val_mae: 0.0763\n",
      "Epoch 26/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.0051 - mae: 0.0536 - val_loss: 0.0014 - val_mae: 0.0270\n",
      "Epoch 27/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.0050 - mae: 0.0534 - val_loss: 0.0042 - val_mae: 0.0573\n",
      "Epoch 28/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.0050 - mae: 0.0533 - val_loss: 0.0016 - val_mae: 0.0299\n",
      "Epoch 29/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.0050 - mae: 0.0533 - val_loss: 0.0031 - val_mae: 0.0470\n",
      "Epoch 30/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.0050 - mae: 0.0534 - val_loss: 0.0026 - val_mae: 0.0416\n",
      "Epoch 31/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.0050 - mae: 0.0533 - val_loss: 0.0017 - val_mae: 0.0302\n",
      "Epoch 32/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.0050 - mae: 0.0532 - val_loss: 0.0018 - val_mae: 0.0315\n",
      "Epoch 33/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 0.0051 - mae: 0.0536 - val_loss: 0.0016 - val_mae: 0.0292\n",
      "Epoch 34/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.0050 - mae: 0.0532 - val_loss: 0.0021 - val_mae: 0.0354\n",
      "Epoch 35/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.0050 - mae: 0.0531 - val_loss: 0.0014 - val_mae: 0.0271\n",
      "Epoch 36/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.0050 - mae: 0.0530 - val_loss: 0.0022 - val_mae: 0.0370\n",
      "Epoch 37/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.0050 - mae: 0.0529 - val_loss: 0.0015 - val_mae: 0.0279\n",
      "Epoch 38/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 0.0050 - mae: 0.0530 - val_loss: 0.0024 - val_mae: 0.0390\n",
      "Epoch 39/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.0050 - mae: 0.0529 - val_loss: 0.0030 - val_mae: 0.0459\n",
      "Epoch 40/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.0050 - mae: 0.0533 - val_loss: 0.0028 - val_mae: 0.0436\n",
      "Epoch 41/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 0.0050 - mae: 0.0531 - val_loss: 0.0050 - val_mae: 0.0638\n",
      "Epoch 42/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.0050 - mae: 0.0530 - val_loss: 0.0039 - val_mae: 0.0545\n",
      "Epoch 43/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.0050 - mae: 0.0529 - val_loss: 0.0019 - val_mae: 0.0338\n",
      "Epoch 44/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.0050 - mae: 0.0528 - val_loss: 0.0023 - val_mae: 0.0380\n",
      "Epoch 45/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.0050 - mae: 0.0529 - val_loss: 0.0026 - val_mae: 0.0418\n",
      "Epoch 46/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.0050 - mae: 0.0530 - val_loss: 0.0023 - val_mae: 0.0382\n",
      "Epoch 47/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - loss: 0.0050 - mae: 0.0529 - val_loss: 0.0029 - val_mae: 0.0445\n",
      "Epoch 48/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.0050 - mae: 0.0528 - val_loss: 0.0015 - val_mae: 0.0281\n",
      "Epoch 49/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.0050 - mae: 0.0528 - val_loss: 0.0016 - val_mae: 0.0291\n",
      "Epoch 50/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.0050 - mae: 0.0528 - val_loss: 0.0039 - val_mae: 0.0545\n",
      "Epoch 51/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.0050 - mae: 0.0527 - val_loss: 0.0021 - val_mae: 0.0359\n",
      "Epoch 52/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.0050 - mae: 0.0527 - val_loss: 0.0019 - val_mae: 0.0336\n",
      "Epoch 53/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0050 - mae: 0.0528 - val_loss: 0.0019 - val_mae: 0.0336\n",
      "Epoch 54/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.0050 - mae: 0.0528 - val_loss: 0.0019 - val_mae: 0.0337\n",
      "Epoch 55/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.0050 - mae: 0.0527 - val_loss: 0.0014 - val_mae: 0.0277\n",
      "Epoch 56/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.0050 - mae: 0.0529 - val_loss: 0.0016 - val_mae: 0.0294\n",
      "Epoch 57/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.0050 - mae: 0.0528 - val_loss: 0.0026 - val_mae: 0.0402\n",
      "Epoch 58/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.0050 - mae: 0.0529 - val_loss: 0.0024 - val_mae: 0.0393\n",
      "Epoch 59/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.0050 - mae: 0.0527 - val_loss: 0.0022 - val_mae: 0.0366\n",
      "Epoch 60/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0050 - mae: 0.0525 - val_loss: 0.0016 - val_mae: 0.0290\n",
      "Epoch 61/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.0050 - mae: 0.0527 - val_loss: 0.0024 - val_mae: 0.0399\n",
      "Epoch 62/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.0050 - mae: 0.0528 - val_loss: 0.0026 - val_mae: 0.0414\n",
      "Epoch 63/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.0050 - mae: 0.0528 - val_loss: 0.0026 - val_mae: 0.0413\n",
      "Epoch 64/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.0049 - mae: 0.0525 - val_loss: 0.0017 - val_mae: 0.0311\n",
      "Epoch 65/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.0049 - mae: 0.0525 - val_loss: 0.0016 - val_mae: 0.0295\n",
      "Epoch 66/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.0050 - mae: 0.0527 - val_loss: 0.0014 - val_mae: 0.0266\n",
      "Epoch 67/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.0049 - mae: 0.0525 - val_loss: 0.0018 - val_mae: 0.0315\n",
      "Epoch 68/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.0050 - mae: 0.0525 - val_loss: 0.0017 - val_mae: 0.0311\n",
      "Epoch 69/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.0050 - mae: 0.0527 - val_loss: 0.0022 - val_mae: 0.0369\n",
      "Epoch 70/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.0050 - mae: 0.0526 - val_loss: 0.0025 - val_mae: 0.0402\n",
      "Epoch 71/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.0050 - mae: 0.0527 - val_loss: 0.0030 - val_mae: 0.0449\n",
      "Epoch 72/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 0.0049 - mae: 0.0525 - val_loss: 0.0014 - val_mae: 0.0261\n",
      "Epoch 73/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.0049 - mae: 0.0525 - val_loss: 0.0027 - val_mae: 0.0420\n",
      "Epoch 74/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.0049 - mae: 0.0526 - val_loss: 0.0020 - val_mae: 0.0345\n",
      "Epoch 75/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.0050 - mae: 0.0526 - val_loss: 0.0020 - val_mae: 0.0345\n",
      "Epoch 76/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.0049 - mae: 0.0525 - val_loss: 0.0017 - val_mae: 0.0304\n",
      "Epoch 77/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.0050 - mae: 0.0526 - val_loss: 0.0026 - val_mae: 0.0412\n",
      "Epoch 78/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.0050 - mae: 0.0527 - val_loss: 0.0026 - val_mae: 0.0415\n",
      "Epoch 79/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.0050 - mae: 0.0527 - val_loss: 0.0023 - val_mae: 0.0383\n",
      "Epoch 80/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.0049 - mae: 0.0525 - val_loss: 0.0026 - val_mae: 0.0411\n",
      "Epoch 81/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.0049 - mae: 0.0524 - val_loss: 0.0015 - val_mae: 0.0277\n",
      "Epoch 82/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.0049 - mae: 0.0526 - val_loss: 0.0014 - val_mae: 0.0273\n",
      "Epoch 83/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.0050 - mae: 0.0526 - val_loss: 0.0015 - val_mae: 0.0281\n",
      "Epoch 84/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0050 - mae: 0.0525 - val_loss: 0.0019 - val_mae: 0.0326\n",
      "Epoch 85/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.0049 - mae: 0.0525 - val_loss: 0.0020 - val_mae: 0.0340\n",
      "Epoch 86/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.0049 - mae: 0.0525 - val_loss: 0.0035 - val_mae: 0.0492\n",
      "Epoch 87/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.0049 - mae: 0.0525 - val_loss: 0.0016 - val_mae: 0.0298\n",
      "Epoch 88/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.0049 - mae: 0.0525 - val_loss: 0.0032 - val_mae: 0.0469\n",
      "Epoch 89/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.0049 - mae: 0.0524 - val_loss: 0.0022 - val_mae: 0.0369\n",
      "Epoch 90/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.0049 - mae: 0.0525 - val_loss: 0.0022 - val_mae: 0.0371\n",
      "Epoch 91/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0049 - mae: 0.0524 - val_loss: 0.0017 - val_mae: 0.0306\n",
      "Epoch 92/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.0049 - mae: 0.0525 - val_loss: 0.0018 - val_mae: 0.0325\n",
      "Epoch 93/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.0050 - mae: 0.0526 - val_loss: 0.0033 - val_mae: 0.0484\n",
      "Epoch 94/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.0049 - mae: 0.0525 - val_loss: 0.0017 - val_mae: 0.0311\n",
      "Epoch 95/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.0050 - mae: 0.0527 - val_loss: 0.0015 - val_mae: 0.0280\n",
      "Epoch 96/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.0049 - mae: 0.0526 - val_loss: 0.0016 - val_mae: 0.0289\n",
      "Epoch 97/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 0.0050 - mae: 0.0526 - val_loss: 0.0026 - val_mae: 0.0404\n",
      "Epoch 98/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.0049 - mae: 0.0524 - val_loss: 0.0027 - val_mae: 0.0421\n",
      "Epoch 99/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.0049 - mae: 0.0525 - val_loss: 0.0025 - val_mae: 0.0394\n",
      "Epoch 100/100\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0049 - mae: 0.0524 - val_loss: 0.0017 - val_mae: 0.0307\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step\n",
      "✅ Done with wheat_Bijapur_daily.csv | MAE=391.77, RMSE=528.58, R2=0.5829, MAPE=19.89%, Accuracy=80.11%\n",
      "Saved updated CSV with Date, Actual & Predicted: tat_mqa_output_csv\\wheat_Bijapur_daily_tat_mqa_updated.csv\n",
      "🚀 Processing: wheat_Chikmagalur_daily.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_28\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_28\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_query_attention_6       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">17,216</span> │ input_layer_28[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiQueryAttention</span>)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_56 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_query_attention_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                               │                           │                 │ input_layer_28[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_56        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_56[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_133 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ layer_normalization_56[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_134 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dense_133[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_57 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_56[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                               │                           │                 │ dense_134[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_57        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_57[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_28   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_57[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_135 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ global_average_pooling1d_… │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_28 (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_query_attention_6       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │          \u001b[38;5;34m17,216\u001b[0m │ input_layer_28[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mMultiQueryAttention\u001b[0m)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_56 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ multi_query_attention_6[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                               │                           │                 │ input_layer_28[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_56        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ add_56[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_133 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │           \u001b[38;5;34m8,320\u001b[0m │ layer_normalization_56[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_134 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │             \u001b[38;5;34m129\u001b[0m │ dense_133[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_57 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_56[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                               │                           │                 │ dense_134[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_57        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ add_57[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_28   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_57[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_135 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │              \u001b[38;5;34m65\u001b[0m │ global_average_pooling1d_… │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,986</span> (101.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25,986\u001b[0m (101.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,986</span> (101.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m25,986\u001b[0m (101.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - loss: 0.0362 - mae: 0.1236 - val_loss: 0.0095 - val_mae: 0.0674\n",
      "Epoch 2/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 0.0188 - mae: 0.1002 - val_loss: 0.0093 - val_mae: 0.0698\n",
      "Epoch 3/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.0180 - mae: 0.0978 - val_loss: 0.0079 - val_mae: 0.0717\n",
      "Epoch 4/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 0.0178 - mae: 0.0978 - val_loss: 0.0078 - val_mae: 0.0700\n",
      "Epoch 5/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.0176 - mae: 0.0965 - val_loss: 0.0084 - val_mae: 0.0776\n",
      "Epoch 6/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 0.0176 - mae: 0.0964 - val_loss: 0.0080 - val_mae: 0.0723\n",
      "Epoch 7/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 0.0174 - mae: 0.0956 - val_loss: 0.0078 - val_mae: 0.0681\n",
      "Epoch 8/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - loss: 0.0173 - mae: 0.0955 - val_loss: 0.0086 - val_mae: 0.0774\n",
      "Epoch 9/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 0.0170 - mae: 0.0944 - val_loss: 0.0093 - val_mae: 0.0830\n",
      "Epoch 10/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 0.0170 - mae: 0.0946 - val_loss: 0.0081 - val_mae: 0.0694\n",
      "Epoch 11/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - loss: 0.0169 - mae: 0.0942 - val_loss: 0.0079 - val_mae: 0.0688\n",
      "Epoch 12/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - loss: 0.0168 - mae: 0.0944 - val_loss: 0.0094 - val_mae: 0.0771\n",
      "Epoch 13/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 0.0167 - mae: 0.0936 - val_loss: 0.0081 - val_mae: 0.0708\n",
      "Epoch 14/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - loss: 0.0167 - mae: 0.0940 - val_loss: 0.0082 - val_mae: 0.0720\n",
      "Epoch 15/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 0.0170 - mae: 0.0946 - val_loss: 0.0087 - val_mae: 0.0781\n",
      "Epoch 16/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - loss: 0.0166 - mae: 0.0932 - val_loss: 0.0082 - val_mae: 0.0706\n",
      "Epoch 17/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - loss: 0.0168 - mae: 0.0943 - val_loss: 0.0079 - val_mae: 0.0695\n",
      "Epoch 18/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - loss: 0.0167 - mae: 0.0937 - val_loss: 0.0087 - val_mae: 0.0739\n",
      "Epoch 19/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - loss: 0.0166 - mae: 0.0936 - val_loss: 0.0092 - val_mae: 0.0762\n",
      "Epoch 20/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 0.0167 - mae: 0.0937 - val_loss: 0.0082 - val_mae: 0.0710\n",
      "Epoch 21/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - loss: 0.0166 - mae: 0.0934 - val_loss: 0.0082 - val_mae: 0.0710\n",
      "Epoch 22/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - loss: 0.0166 - mae: 0.0934 - val_loss: 0.0089 - val_mae: 0.0764\n",
      "Epoch 23/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 0.0166 - mae: 0.0935 - val_loss: 0.0080 - val_mae: 0.0699\n",
      "Epoch 24/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - loss: 0.0166 - mae: 0.0932 - val_loss: 0.0092 - val_mae: 0.0778\n",
      "Epoch 25/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 0.0167 - mae: 0.0940 - val_loss: 0.0091 - val_mae: 0.0748\n",
      "Epoch 26/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - loss: 0.0165 - mae: 0.0931 - val_loss: 0.0080 - val_mae: 0.0709\n",
      "Epoch 27/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - loss: 0.0165 - mae: 0.0930 - val_loss: 0.0085 - val_mae: 0.0722\n",
      "Epoch 28/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 0.0166 - mae: 0.0933 - val_loss: 0.0080 - val_mae: 0.0698\n",
      "Epoch 29/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 0.0165 - mae: 0.0934 - val_loss: 0.0084 - val_mae: 0.0741\n",
      "Epoch 30/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - loss: 0.0165 - mae: 0.0933 - val_loss: 0.0081 - val_mae: 0.0712\n",
      "Epoch 31/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - loss: 0.0165 - mae: 0.0932 - val_loss: 0.0082 - val_mae: 0.0713\n",
      "Epoch 32/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - loss: 0.0166 - mae: 0.0934 - val_loss: 0.0082 - val_mae: 0.0727\n",
      "Epoch 33/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - loss: 0.0165 - mae: 0.0934 - val_loss: 0.0084 - val_mae: 0.0738\n",
      "Epoch 34/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.0165 - mae: 0.0932 - val_loss: 0.0083 - val_mae: 0.0724\n",
      "Epoch 35/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.0164 - mae: 0.0930 - val_loss: 0.0083 - val_mae: 0.0729\n",
      "Epoch 36/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.0165 - mae: 0.0933 - val_loss: 0.0083 - val_mae: 0.0710\n",
      "Epoch 37/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.0165 - mae: 0.0932 - val_loss: 0.0085 - val_mae: 0.0753\n",
      "Epoch 38/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.0164 - mae: 0.0931 - val_loss: 0.0083 - val_mae: 0.0736\n",
      "Epoch 39/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.0165 - mae: 0.0933 - val_loss: 0.0080 - val_mae: 0.0696\n",
      "Epoch 40/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.0165 - mae: 0.0932 - val_loss: 0.0084 - val_mae: 0.0750\n",
      "Epoch 41/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.0165 - mae: 0.0932 - val_loss: 0.0087 - val_mae: 0.0761\n",
      "Epoch 42/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 0.0165 - mae: 0.0932 - val_loss: 0.0090 - val_mae: 0.0775\n",
      "Epoch 43/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - loss: 0.0164 - mae: 0.0930 - val_loss: 0.0085 - val_mae: 0.0727\n",
      "Epoch 44/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - loss: 0.0163 - mae: 0.0931 - val_loss: 0.0094 - val_mae: 0.0783\n",
      "Epoch 45/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - loss: 0.0164 - mae: 0.0932 - val_loss: 0.0083 - val_mae: 0.0736\n",
      "Epoch 46/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 0.0164 - mae: 0.0930 - val_loss: 0.0093 - val_mae: 0.0785\n",
      "Epoch 47/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - loss: 0.0164 - mae: 0.0930 - val_loss: 0.0084 - val_mae: 0.0752\n",
      "Epoch 48/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 0.0164 - mae: 0.0931 - val_loss: 0.0088 - val_mae: 0.0780\n",
      "Epoch 49/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 0.0163 - mae: 0.0928 - val_loss: 0.0093 - val_mae: 0.0765\n",
      "Epoch 50/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - loss: 0.0163 - mae: 0.0930 - val_loss: 0.0091 - val_mae: 0.0764\n",
      "Epoch 51/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - loss: 0.0162 - mae: 0.0923 - val_loss: 0.0087 - val_mae: 0.0751\n",
      "Epoch 52/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 0.0160 - mae: 0.0920 - val_loss: 0.0108 - val_mae: 0.0830\n",
      "Epoch 53/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 0.0160 - mae: 0.0919 - val_loss: 0.0089 - val_mae: 0.0782\n",
      "Epoch 54/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 0.0159 - mae: 0.0914 - val_loss: 0.0104 - val_mae: 0.0840\n",
      "Epoch 55/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.0157 - mae: 0.0902 - val_loss: 0.0100 - val_mae: 0.0791\n",
      "Epoch 56/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 0.0155 - mae: 0.0894 - val_loss: 0.0082 - val_mae: 0.0714\n",
      "Epoch 57/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 0.0154 - mae: 0.0887 - val_loss: 0.0125 - val_mae: 0.0911\n",
      "Epoch 58/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 0.0154 - mae: 0.0879 - val_loss: 0.0104 - val_mae: 0.0812\n",
      "Epoch 59/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - loss: 0.0152 - mae: 0.0873 - val_loss: 0.0095 - val_mae: 0.0755\n",
      "Epoch 60/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - loss: 0.0150 - mae: 0.0866 - val_loss: 0.0097 - val_mae: 0.0798\n",
      "Epoch 61/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 0.0149 - mae: 0.0861 - val_loss: 0.0113 - val_mae: 0.0899\n",
      "Epoch 62/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 0.0150 - mae: 0.0863 - val_loss: 0.0102 - val_mae: 0.0839\n",
      "Epoch 63/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - loss: 0.0148 - mae: 0.0859 - val_loss: 0.0117 - val_mae: 0.0880\n",
      "Epoch 64/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - loss: 0.0149 - mae: 0.0858 - val_loss: 0.0093 - val_mae: 0.0790\n",
      "Epoch 65/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 0.0149 - mae: 0.0863 - val_loss: 0.0114 - val_mae: 0.0890\n",
      "Epoch 66/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 0.0150 - mae: 0.0863 - val_loss: 0.0108 - val_mae: 0.0838\n",
      "Epoch 67/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - loss: 0.0151 - mae: 0.0864 - val_loss: 0.0126 - val_mae: 0.0918\n",
      "Epoch 68/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - loss: 0.0147 - mae: 0.0853 - val_loss: 0.0128 - val_mae: 0.0939\n",
      "Epoch 69/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 0.0147 - mae: 0.0852 - val_loss: 0.0094 - val_mae: 0.0807\n",
      "Epoch 70/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 0.0149 - mae: 0.0861 - val_loss: 0.0123 - val_mae: 0.0916\n",
      "Epoch 71/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - loss: 0.0150 - mae: 0.0861 - val_loss: 0.0139 - val_mae: 0.0973\n",
      "Epoch 72/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - loss: 0.0149 - mae: 0.0859 - val_loss: 0.0128 - val_mae: 0.0947\n",
      "Epoch 73/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - loss: 0.0149 - mae: 0.0860 - val_loss: 0.0140 - val_mae: 0.0970\n",
      "Epoch 74/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - loss: 0.0149 - mae: 0.0856 - val_loss: 0.0129 - val_mae: 0.0953\n",
      "Epoch 75/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 0.0147 - mae: 0.0855 - val_loss: 0.0118 - val_mae: 0.0901\n",
      "Epoch 76/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 0.0148 - mae: 0.0853 - val_loss: 0.0110 - val_mae: 0.0893\n",
      "Epoch 77/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 0.0148 - mae: 0.0856 - val_loss: 0.0104 - val_mae: 0.0854\n",
      "Epoch 78/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 0.0148 - mae: 0.0857 - val_loss: 0.0136 - val_mae: 0.0978\n",
      "Epoch 79/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 0.0147 - mae: 0.0851 - val_loss: 0.0115 - val_mae: 0.0892\n",
      "Epoch 80/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.0150 - mae: 0.0855 - val_loss: 0.0111 - val_mae: 0.0832\n",
      "Epoch 81/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.0149 - mae: 0.0862 - val_loss: 0.0119 - val_mae: 0.0919\n",
      "Epoch 82/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.0147 - mae: 0.0856 - val_loss: 0.0125 - val_mae: 0.0944\n",
      "Epoch 83/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.0147 - mae: 0.0852 - val_loss: 0.0135 - val_mae: 0.0981\n",
      "Epoch 84/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.0148 - mae: 0.0854 - val_loss: 0.0144 - val_mae: 0.0992\n",
      "Epoch 85/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.0148 - mae: 0.0855 - val_loss: 0.0114 - val_mae: 0.0909\n",
      "Epoch 86/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.0148 - mae: 0.0856 - val_loss: 0.0148 - val_mae: 0.1016\n",
      "Epoch 87/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 0.0150 - mae: 0.0860 - val_loss: 0.0108 - val_mae: 0.0864\n",
      "Epoch 88/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.0148 - mae: 0.0855 - val_loss: 0.0131 - val_mae: 0.0965\n",
      "Epoch 89/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.0147 - mae: 0.0849 - val_loss: 0.0150 - val_mae: 0.1030\n",
      "Epoch 90/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.0148 - mae: 0.0852 - val_loss: 0.0121 - val_mae: 0.0915\n",
      "Epoch 91/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.0147 - mae: 0.0852 - val_loss: 0.0121 - val_mae: 0.0920\n",
      "Epoch 92/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 0.0147 - mae: 0.0852 - val_loss: 0.0152 - val_mae: 0.1025\n",
      "Epoch 93/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - loss: 0.0147 - mae: 0.0847 - val_loss: 0.0128 - val_mae: 0.0933\n",
      "Epoch 94/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.0148 - mae: 0.0850 - val_loss: 0.0107 - val_mae: 0.0874\n",
      "Epoch 95/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.0147 - mae: 0.0856 - val_loss: 0.0139 - val_mae: 0.0985\n",
      "Epoch 96/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.0146 - mae: 0.0848 - val_loss: 0.0136 - val_mae: 0.0965\n",
      "Epoch 97/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.0147 - mae: 0.0850 - val_loss: 0.0153 - val_mae: 0.1033\n",
      "Epoch 98/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.0145 - mae: 0.0844 - val_loss: 0.0109 - val_mae: 0.0875\n",
      "Epoch 99/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.0147 - mae: 0.0851 - val_loss: 0.0111 - val_mae: 0.0878\n",
      "Epoch 100/100\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.0147 - mae: 0.0853 - val_loss: 0.0135 - val_mae: 0.0956\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step\n",
      "✅ Done with wheat_Chikmagalur_daily.csv | MAE=451.9, RMSE=604.1, R2=0.3804, MAPE=24.19%, Accuracy=75.81%\n",
      "Saved updated CSV with Date, Actual & Predicted: tat_mqa_output_csv\\wheat_Chikmagalur_daily_tat_mqa_updated.csv\n",
      "🚀 Processing: wheat_Chitradurga_daily.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_29\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_29\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_query_attention_7       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">17,216</span> │ input_layer_29[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiQueryAttention</span>)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_58 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_query_attention_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                               │                           │                 │ input_layer_29[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_58        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_58[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_143 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ layer_normalization_58[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_144 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dense_143[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_59 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_58[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                               │                           │                 │ dense_144[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_59        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_59[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_29   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_59[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_145 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ global_average_pooling1d_… │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_29 (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_query_attention_7       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │          \u001b[38;5;34m17,216\u001b[0m │ input_layer_29[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mMultiQueryAttention\u001b[0m)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_58 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ multi_query_attention_7[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                               │                           │                 │ input_layer_29[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_58        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ add_58[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_143 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │           \u001b[38;5;34m8,320\u001b[0m │ layer_normalization_58[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_144 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │             \u001b[38;5;34m129\u001b[0m │ dense_143[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_59 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_58[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                               │                           │                 │ dense_144[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_59        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ add_59[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_29   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_59[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_145 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │              \u001b[38;5;34m65\u001b[0m │ global_average_pooling1d_… │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,986</span> (101.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25,986\u001b[0m (101.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,986</span> (101.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m25,986\u001b[0m (101.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - loss: 0.0732 - mae: 0.2172 - val_loss: 0.1042 - val_mae: 0.3208\n",
      "Epoch 2/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0489 - mae: 0.1897 - val_loss: 0.0878 - val_mae: 0.2941\n",
      "Epoch 3/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0467 - mae: 0.1859 - val_loss: 0.1480 - val_mae: 0.3832\n",
      "Epoch 4/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0441 - mae: 0.1807 - val_loss: 0.0469 - val_mae: 0.2141\n",
      "Epoch 5/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0418 - mae: 0.1758 - val_loss: 0.0311 - val_mae: 0.1738\n",
      "Epoch 6/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0399 - mae: 0.1704 - val_loss: 0.0138 - val_mae: 0.1140\n",
      "Epoch 7/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 0.0391 - mae: 0.1676 - val_loss: 0.0137 - val_mae: 0.1144\n",
      "Epoch 8/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 0.0385 - mae: 0.1658 - val_loss: 0.0058 - val_mae: 0.0730\n",
      "Epoch 9/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0373 - mae: 0.1623 - val_loss: 0.0028 - val_mae: 0.0502\n",
      "Epoch 10/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0367 - mae: 0.1611 - val_loss: 4.5429e-04 - val_mae: 0.0174\n",
      "Epoch 11/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0374 - mae: 0.1630 - val_loss: 0.0012 - val_mae: 0.0314\n",
      "Epoch 12/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 0.0364 - mae: 0.1602 - val_loss: 6.2416e-04 - val_mae: 0.0232\n",
      "Epoch 13/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0365 - mae: 0.1609 - val_loss: 9.8401e-05 - val_mae: 0.0081\n",
      "Epoch 14/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 0.0358 - mae: 0.1588 - val_loss: 9.2127e-04 - val_mae: 0.0299\n",
      "Epoch 15/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0359 - mae: 0.1598 - val_loss: 0.0027 - val_mae: 0.0517\n",
      "Epoch 16/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 0.0365 - mae: 0.1612 - val_loss: 2.8403e-04 - val_mae: 0.0166\n",
      "Epoch 17/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 0.0358 - mae: 0.1593 - val_loss: 5.9181e-05 - val_mae: 0.0056\n",
      "Epoch 18/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0358 - mae: 0.1595 - val_loss: 1.2060e-04 - val_mae: 0.0096\n",
      "Epoch 19/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0357 - mae: 0.1594 - val_loss: 0.0037 - val_mae: 0.0604\n",
      "Epoch 20/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0358 - mae: 0.1592 - val_loss: 2.4630e-05 - val_mae: 0.0033\n",
      "Epoch 21/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0355 - mae: 0.1585 - val_loss: 2.3267e-04 - val_mae: 0.0146\n",
      "Epoch 22/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0360 - mae: 0.1608 - val_loss: 1.4639e-04 - val_mae: 0.0117\n",
      "Epoch 23/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0352 - mae: 0.1576 - val_loss: 1.5515e-04 - val_mae: 0.0122\n",
      "Epoch 24/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 0.0352 - mae: 0.1579 - val_loss: 6.7697e-05 - val_mae: 0.0076\n",
      "Epoch 25/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 0.0358 - mae: 0.1601 - val_loss: 0.0105 - val_mae: 0.1023\n",
      "Epoch 26/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0355 - mae: 0.1590 - val_loss: 0.0014 - val_mae: 0.0368\n",
      "Epoch 27/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0355 - mae: 0.1590 - val_loss: 0.0020 - val_mae: 0.0442\n",
      "Epoch 28/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0349 - mae: 0.1570 - val_loss: 0.0120 - val_mae: 0.1093\n",
      "Epoch 29/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0350 - mae: 0.1576 - val_loss: 0.0077 - val_mae: 0.0878\n",
      "Epoch 30/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 0.0348 - mae: 0.1566 - val_loss: 4.9384e-04 - val_mae: 0.0219\n",
      "Epoch 31/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 0.0350 - mae: 0.1584 - val_loss: 2.1799e-05 - val_mae: 0.0030\n",
      "Epoch 32/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0352 - mae: 0.1583 - val_loss: 0.0032 - val_mae: 0.0562\n",
      "Epoch 33/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0349 - mae: 0.1568 - val_loss: 0.0025 - val_mae: 0.0502\n",
      "Epoch 34/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0346 - mae: 0.1561 - val_loss: 0.0074 - val_mae: 0.0861\n",
      "Epoch 35/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0350 - mae: 0.1579 - val_loss: 0.0045 - val_mae: 0.0671\n",
      "Epoch 36/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0347 - mae: 0.1562 - val_loss: 2.6576e-05 - val_mae: 0.0038\n",
      "Epoch 37/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0357 - mae: 0.1587 - val_loss: 0.0124 - val_mae: 0.1111\n",
      "Epoch 38/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 0.0348 - mae: 0.1569 - val_loss: 0.0093 - val_mae: 0.0959\n",
      "Epoch 39/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0347 - mae: 0.1567 - val_loss: 0.0059 - val_mae: 0.0769\n",
      "Epoch 40/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 0.0348 - mae: 0.1570 - val_loss: 2.5460e-04 - val_mae: 0.0153\n",
      "Epoch 41/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 0.0347 - mae: 0.1570 - val_loss: 2.7442e-04 - val_mae: 0.0160\n",
      "Epoch 42/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0350 - mae: 0.1578 - val_loss: 0.0111 - val_mae: 0.1053\n",
      "Epoch 43/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0347 - mae: 0.1563 - val_loss: 0.0022 - val_mae: 0.0470\n",
      "Epoch 44/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 0.0346 - mae: 0.1569 - val_loss: 0.0222 - val_mae: 0.1487\n",
      "Epoch 45/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0345 - mae: 0.1558 - val_loss: 7.6037e-04 - val_mae: 0.0273\n",
      "Epoch 46/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0351 - mae: 0.1575 - val_loss: 0.0038 - val_mae: 0.0620\n",
      "Epoch 47/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 0.0346 - mae: 0.1564 - val_loss: 0.0156 - val_mae: 0.1248\n",
      "Epoch 48/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 0.0346 - mae: 0.1566 - val_loss: 0.0063 - val_mae: 0.0792\n",
      "Epoch 49/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0348 - mae: 0.1573 - val_loss: 0.0077 - val_mae: 0.0877\n",
      "Epoch 50/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0350 - mae: 0.1571 - val_loss: 0.0011 - val_mae: 0.0333\n",
      "Epoch 51/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0348 - mae: 0.1575 - val_loss: 1.8443e-04 - val_mae: 0.0126\n",
      "Epoch 52/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0346 - mae: 0.1559 - val_loss: 1.3466e-04 - val_mae: 0.0099\n",
      "Epoch 53/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0345 - mae: 0.1561 - val_loss: 0.0034 - val_mae: 0.0584\n",
      "Epoch 54/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0344 - mae: 0.1553 - val_loss: 5.4988e-04 - val_mae: 0.0224\n",
      "Epoch 55/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 0.0345 - mae: 0.1558 - val_loss: 0.0011 - val_mae: 0.0331\n",
      "Epoch 56/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0345 - mae: 0.1560 - val_loss: 0.0063 - val_mae: 0.0790\n",
      "Epoch 57/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0348 - mae: 0.1561 - val_loss: 0.0016 - val_mae: 0.0386\n",
      "Epoch 58/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0345 - mae: 0.1550 - val_loss: 0.0095 - val_mae: 0.0973\n",
      "Epoch 59/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0347 - mae: 0.1566 - val_loss: 0.0028 - val_mae: 0.0530\n",
      "Epoch 60/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0344 - mae: 0.1557 - val_loss: 0.0161 - val_mae: 0.1266\n",
      "Epoch 61/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0347 - mae: 0.1562 - val_loss: 0.0092 - val_mae: 0.0959\n",
      "Epoch 62/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0345 - mae: 0.1558 - val_loss: 0.0056 - val_mae: 0.0742\n",
      "Epoch 63/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0346 - mae: 0.1556 - val_loss: 0.0062 - val_mae: 0.0784\n",
      "Epoch 64/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0346 - mae: 0.1561 - val_loss: 0.0070 - val_mae: 0.0833\n",
      "Epoch 65/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0343 - mae: 0.1548 - val_loss: 0.0028 - val_mae: 0.0519\n",
      "Epoch 66/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0345 - mae: 0.1564 - val_loss: 0.0117 - val_mae: 0.1076\n",
      "Epoch 67/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0343 - mae: 0.1551 - val_loss: 0.0023 - val_mae: 0.0471\n",
      "Epoch 68/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0343 - mae: 0.1546 - val_loss: 0.0074 - val_mae: 0.0853\n",
      "Epoch 69/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0346 - mae: 0.1558 - val_loss: 0.0064 - val_mae: 0.0791\n",
      "Epoch 70/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0343 - mae: 0.1549 - val_loss: 0.0040 - val_mae: 0.0620\n",
      "Epoch 71/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0345 - mae: 0.1557 - val_loss: 0.0043 - val_mae: 0.0642\n",
      "Epoch 72/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0343 - mae: 0.1548 - val_loss: 0.0025 - val_mae: 0.0489\n",
      "Epoch 73/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 0.0345 - mae: 0.1555 - val_loss: 0.0046 - val_mae: 0.0664\n",
      "Epoch 74/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0344 - mae: 0.1551 - val_loss: 0.0072 - val_mae: 0.0837\n",
      "Epoch 75/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0342 - mae: 0.1545 - val_loss: 0.0147 - val_mae: 0.1204\n",
      "Epoch 76/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0344 - mae: 0.1555 - val_loss: 3.2193e-04 - val_mae: 0.0151\n",
      "Epoch 77/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0345 - mae: 0.1559 - val_loss: 0.0013 - val_mae: 0.0340\n",
      "Epoch 78/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0343 - mae: 0.1544 - val_loss: 0.0197 - val_mae: 0.1395\n",
      "Epoch 79/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0345 - mae: 0.1550 - val_loss: 0.0029 - val_mae: 0.0518\n",
      "Epoch 80/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0342 - mae: 0.1544 - val_loss: 0.0033 - val_mae: 0.0561\n",
      "Epoch 81/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0344 - mae: 0.1551 - val_loss: 3.8479e-04 - val_mae: 0.0163\n",
      "Epoch 82/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0346 - mae: 0.1555 - val_loss: 0.0050 - val_mae: 0.0688\n",
      "Epoch 83/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0347 - mae: 0.1558 - val_loss: 5.1359e-04 - val_mae: 0.0180\n",
      "Epoch 84/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0342 - mae: 0.1540 - val_loss: 0.0090 - val_mae: 0.0935\n",
      "Epoch 85/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0341 - mae: 0.1540 - val_loss: 0.0046 - val_mae: 0.0659\n",
      "Epoch 86/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0342 - mae: 0.1540 - val_loss: 0.0036 - val_mae: 0.0587\n",
      "Epoch 87/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0344 - mae: 0.1549 - val_loss: 4.0648e-04 - val_mae: 0.0169\n",
      "Epoch 88/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0344 - mae: 0.1544 - val_loss: 0.0037 - val_mae: 0.0580\n",
      "Epoch 89/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0343 - mae: 0.1538 - val_loss: 0.0012 - val_mae: 0.0300\n",
      "Epoch 90/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0343 - mae: 0.1548 - val_loss: 0.0039 - val_mae: 0.0592\n",
      "Epoch 91/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 0.0342 - mae: 0.1538 - val_loss: 7.3363e-04 - val_mae: 0.0214\n",
      "Epoch 92/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0342 - mae: 0.1544 - val_loss: 5.8860e-04 - val_mae: 0.0202\n",
      "Epoch 93/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0343 - mae: 0.1545 - val_loss: 0.0044 - val_mae: 0.0638\n",
      "Epoch 94/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0343 - mae: 0.1544 - val_loss: 0.0139 - val_mae: 0.1161\n",
      "Epoch 95/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0341 - mae: 0.1538 - val_loss: 0.0071 - val_mae: 0.0815\n",
      "Epoch 96/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0341 - mae: 0.1535 - val_loss: 0.0014 - val_mae: 0.0328\n",
      "Epoch 97/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0343 - mae: 0.1543 - val_loss: 0.0015 - val_mae: 0.0333\n",
      "Epoch 98/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0342 - mae: 0.1538 - val_loss: 4.7392e-04 - val_mae: 0.0181\n",
      "Epoch 99/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0341 - mae: 0.1545 - val_loss: 0.0040 - val_mae: 0.0600\n",
      "Epoch 100/100\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0342 - mae: 0.1540 - val_loss: 0.0060 - val_mae: 0.0748\n",
      "\u001b[1m169/169\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step   \n",
      "✅ Done with wheat_Chitradurga_daily.csv | MAE=265.17, RMSE=318.52, R2=0.6998, MAPE=12.54%, Accuracy=87.46%\n",
      "Saved updated CSV with Date, Actual & Predicted: tat_mqa_output_csv\\wheat_Chitradurga_daily_tat_mqa_updated.csv\n",
      "🚀 Processing: wheat_Davangere_daily.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_30\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_30\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_query_attention_8       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">17,216</span> │ input_layer_30[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiQueryAttention</span>)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_60 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_query_attention_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                               │                           │                 │ input_layer_30[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_60        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_60[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_153 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ layer_normalization_60[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_154 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dense_153[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_61 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_60[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                               │                           │                 │ dense_154[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_61        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_61[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_30   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_61[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_155 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ global_average_pooling1d_… │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_30 (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_query_attention_8       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │          \u001b[38;5;34m17,216\u001b[0m │ input_layer_30[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mMultiQueryAttention\u001b[0m)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_60 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ multi_query_attention_8[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                               │                           │                 │ input_layer_30[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_60        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ add_60[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_153 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │           \u001b[38;5;34m8,320\u001b[0m │ layer_normalization_60[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_154 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │             \u001b[38;5;34m129\u001b[0m │ dense_153[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_61 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_60[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                               │                           │                 │ dense_154[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_61        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ add_61[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_30   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_61[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_155 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │              \u001b[38;5;34m65\u001b[0m │ global_average_pooling1d_… │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,986</span> (101.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25,986\u001b[0m (101.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,986</span> (101.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m25,986\u001b[0m (101.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 15ms/step - loss: 0.0318 - mae: 0.1301 - val_loss: 0.0357 - val_mae: 0.1663\n",
      "Epoch 2/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - loss: 0.0171 - mae: 0.1070 - val_loss: 0.0650 - val_mae: 0.2355\n",
      "Epoch 3/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0154 - mae: 0.1039 - val_loss: 0.0459 - val_mae: 0.1944\n",
      "Epoch 4/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0150 - mae: 0.1032 - val_loss: 0.0216 - val_mae: 0.1252\n",
      "Epoch 5/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - loss: 0.0145 - mae: 0.1034 - val_loss: 0.0187 - val_mae: 0.1146\n",
      "Epoch 6/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 0.0148 - mae: 0.1037 - val_loss: 0.0308 - val_mae: 0.1590\n",
      "Epoch 7/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0144 - mae: 0.1031 - val_loss: 0.0267 - val_mae: 0.1464\n",
      "Epoch 8/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0146 - mae: 0.1033 - val_loss: 0.0189 - val_mae: 0.1187\n",
      "Epoch 9/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0140 - mae: 0.1027 - val_loss: 0.0200 - val_mae: 0.1245\n",
      "Epoch 10/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - loss: 0.0138 - mae: 0.1026 - val_loss: 0.0152 - val_mae: 0.1039\n",
      "Epoch 11/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0139 - mae: 0.1029 - val_loss: 0.0212 - val_mae: 0.1292\n",
      "Epoch 12/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0138 - mae: 0.1027 - val_loss: 0.0219 - val_mae: 0.1328\n",
      "Epoch 13/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 0.0137 - mae: 0.1027 - val_loss: 0.0175 - val_mae: 0.1156\n",
      "Epoch 14/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - loss: 0.0137 - mae: 0.1023 - val_loss: 0.0150 - val_mae: 0.1050\n",
      "Epoch 15/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0138 - mae: 0.1031 - val_loss: 0.0130 - val_mae: 0.0949\n",
      "Epoch 16/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 0.0136 - mae: 0.1028 - val_loss: 0.0153 - val_mae: 0.1060\n",
      "Epoch 17/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 0.0135 - mae: 0.1022 - val_loss: 0.0103 - val_mae: 0.0777\n",
      "Epoch 18/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - loss: 0.0137 - mae: 0.1028 - val_loss: 0.0133 - val_mae: 0.0963\n",
      "Epoch 19/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0136 - mae: 0.1025 - val_loss: 0.0153 - val_mae: 0.1056\n",
      "Epoch 20/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0135 - mae: 0.1024 - val_loss: 0.0138 - val_mae: 0.0988\n",
      "Epoch 21/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 0.0135 - mae: 0.1028 - val_loss: 0.0174 - val_mae: 0.1158\n",
      "Epoch 22/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 0.0135 - mae: 0.1028 - val_loss: 0.0175 - val_mae: 0.1147\n",
      "Epoch 23/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0134 - mae: 0.1025 - val_loss: 0.0131 - val_mae: 0.0934\n",
      "Epoch 24/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0135 - mae: 0.1029 - val_loss: 0.0160 - val_mae: 0.1078\n",
      "Epoch 25/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 0.0134 - mae: 0.1028 - val_loss: 0.0119 - val_mae: 0.0874\n",
      "Epoch 26/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0134 - mae: 0.1029 - val_loss: 0.0112 - val_mae: 0.0843\n",
      "Epoch 27/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0134 - mae: 0.1031 - val_loss: 0.0123 - val_mae: 0.0908\n",
      "Epoch 28/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - loss: 0.0134 - mae: 0.1030 - val_loss: 0.0097 - val_mae: 0.0732\n",
      "Epoch 29/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 0.0133 - mae: 0.1030 - val_loss: 0.0085 - val_mae: 0.0650\n",
      "Epoch 30/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0134 - mae: 0.1027 - val_loss: 0.0086 - val_mae: 0.0658\n",
      "Epoch 31/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0133 - mae: 0.1025 - val_loss: 0.0093 - val_mae: 0.0705\n",
      "Epoch 32/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0133 - mae: 0.1026 - val_loss: 0.0121 - val_mae: 0.0872\n",
      "Epoch 33/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0133 - mae: 0.1026 - val_loss: 0.0070 - val_mae: 0.0523\n",
      "Epoch 34/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0133 - mae: 0.1026 - val_loss: 0.0129 - val_mae: 0.0919\n",
      "Epoch 35/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - loss: 0.0133 - mae: 0.1026 - val_loss: 0.0123 - val_mae: 0.0898\n",
      "Epoch 36/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0133 - mae: 0.1027 - val_loss: 0.0098 - val_mae: 0.0744\n",
      "Epoch 37/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - loss: 0.0132 - mae: 0.1025 - val_loss: 0.0083 - val_mae: 0.0628\n",
      "Epoch 38/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - loss: 0.0133 - mae: 0.1029 - val_loss: 0.0095 - val_mae: 0.0716\n",
      "Epoch 39/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0132 - mae: 0.1028 - val_loss: 0.0120 - val_mae: 0.0880\n",
      "Epoch 40/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 14ms/step - loss: 0.0133 - mae: 0.1028 - val_loss: 0.0122 - val_mae: 0.0886\n",
      "Epoch 41/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0133 - mae: 0.1026 - val_loss: 0.0075 - val_mae: 0.0557\n",
      "Epoch 42/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0132 - mae: 0.1028 - val_loss: 0.0118 - val_mae: 0.0864\n",
      "Epoch 43/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - loss: 0.0133 - mae: 0.1028 - val_loss: 0.0082 - val_mae: 0.0607\n",
      "Epoch 44/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - loss: 0.0132 - mae: 0.1026 - val_loss: 0.0094 - val_mae: 0.0700\n",
      "Epoch 45/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0132 - mae: 0.1025 - val_loss: 0.0112 - val_mae: 0.0844\n",
      "Epoch 46/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0132 - mae: 0.1026 - val_loss: 0.0134 - val_mae: 0.0951\n",
      "Epoch 47/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0132 - mae: 0.1024 - val_loss: 0.0083 - val_mae: 0.0623\n",
      "Epoch 48/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0132 - mae: 0.1025 - val_loss: 0.0091 - val_mae: 0.0680\n",
      "Epoch 49/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0132 - mae: 0.1025 - val_loss: 0.0088 - val_mae: 0.0665\n",
      "Epoch 50/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0132 - mae: 0.1025 - val_loss: 0.0157 - val_mae: 0.1058\n",
      "Epoch 51/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0132 - mae: 0.1026 - val_loss: 0.0146 - val_mae: 0.1000\n",
      "Epoch 52/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0131 - mae: 0.1023 - val_loss: 0.0118 - val_mae: 0.0849\n",
      "Epoch 53/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0131 - mae: 0.1022 - val_loss: 0.0158 - val_mae: 0.1066\n",
      "Epoch 54/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0132 - mae: 0.1024 - val_loss: 0.0166 - val_mae: 0.1100\n",
      "Epoch 55/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - loss: 0.0132 - mae: 0.1024 - val_loss: 0.0107 - val_mae: 0.0795\n",
      "Epoch 56/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0132 - mae: 0.1023 - val_loss: 0.0083 - val_mae: 0.0624\n",
      "Epoch 57/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0132 - mae: 0.1023 - val_loss: 0.0102 - val_mae: 0.0756\n",
      "Epoch 58/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0132 - mae: 0.1021 - val_loss: 0.0103 - val_mae: 0.0764\n",
      "Epoch 59/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0132 - mae: 0.1024 - val_loss: 0.0181 - val_mae: 0.1161\n",
      "Epoch 60/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0132 - mae: 0.1024 - val_loss: 0.0123 - val_mae: 0.0898\n",
      "Epoch 61/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 0.0132 - mae: 0.1022 - val_loss: 0.0164 - val_mae: 0.1087\n",
      "Epoch 62/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0132 - mae: 0.1022 - val_loss: 0.0133 - val_mae: 0.0930\n",
      "Epoch 63/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 0.0132 - mae: 0.1024 - val_loss: 0.0140 - val_mae: 0.0982\n",
      "Epoch 64/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 0.0132 - mae: 0.1023 - val_loss: 0.0142 - val_mae: 0.0977\n",
      "Epoch 65/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0131 - mae: 0.1022 - val_loss: 0.0199 - val_mae: 0.1230\n",
      "Epoch 66/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0131 - mae: 0.1023 - val_loss: 0.0149 - val_mae: 0.1022\n",
      "Epoch 67/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0131 - mae: 0.1021 - val_loss: 0.0199 - val_mae: 0.1220\n",
      "Epoch 68/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0131 - mae: 0.1023 - val_loss: 0.0177 - val_mae: 0.1154\n",
      "Epoch 69/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0132 - mae: 0.1023 - val_loss: 0.0178 - val_mae: 0.1154\n",
      "Epoch 70/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0131 - mae: 0.1021 - val_loss: 0.0111 - val_mae: 0.0802\n",
      "Epoch 71/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0131 - mae: 0.1022 - val_loss: 0.0148 - val_mae: 0.1016\n",
      "Epoch 72/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0131 - mae: 0.1022 - val_loss: 0.0085 - val_mae: 0.0644\n",
      "Epoch 73/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0132 - mae: 0.1023 - val_loss: 0.0133 - val_mae: 0.0937\n",
      "Epoch 74/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 0.0132 - mae: 0.1020 - val_loss: 0.0132 - val_mae: 0.0935\n",
      "Epoch 75/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0132 - mae: 0.1020 - val_loss: 0.0153 - val_mae: 0.1030\n",
      "Epoch 76/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0131 - mae: 0.1022 - val_loss: 0.0201 - val_mae: 0.1238\n",
      "Epoch 77/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0131 - mae: 0.1022 - val_loss: 0.0114 - val_mae: 0.0823\n",
      "Epoch 78/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 0.0131 - mae: 0.1021 - val_loss: 0.0153 - val_mae: 0.1034\n",
      "Epoch 79/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0131 - mae: 0.1018 - val_loss: 0.0092 - val_mae: 0.0688\n",
      "Epoch 80/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 0.0131 - mae: 0.1022 - val_loss: 0.0137 - val_mae: 0.0952\n",
      "Epoch 81/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 0.0132 - mae: 0.1020 - val_loss: 0.0156 - val_mae: 0.1055\n",
      "Epoch 82/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0131 - mae: 0.1018 - val_loss: 0.0175 - val_mae: 0.1156\n",
      "Epoch 83/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0131 - mae: 0.1021 - val_loss: 0.0126 - val_mae: 0.0894\n",
      "Epoch 84/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0131 - mae: 0.1022 - val_loss: 0.0163 - val_mae: 0.1089\n",
      "Epoch 85/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0132 - mae: 0.1023 - val_loss: 0.0163 - val_mae: 0.1081\n",
      "Epoch 86/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 0.0132 - mae: 0.1020 - val_loss: 0.0131 - val_mae: 0.0927\n",
      "Epoch 87/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - loss: 0.0131 - mae: 0.1021 - val_loss: 0.0110 - val_mae: 0.0796\n",
      "Epoch 88/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 14ms/step - loss: 0.0131 - mae: 0.1020 - val_loss: 0.0130 - val_mae: 0.0906\n",
      "Epoch 89/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - loss: 0.0132 - mae: 0.1021 - val_loss: 0.0204 - val_mae: 0.1249\n",
      "Epoch 90/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0131 - mae: 0.1019 - val_loss: 0.0170 - val_mae: 0.1116\n",
      "Epoch 91/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0131 - mae: 0.1020 - val_loss: 0.0166 - val_mae: 0.1095\n",
      "Epoch 92/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 14ms/step - loss: 0.0131 - mae: 0.1023 - val_loss: 0.0126 - val_mae: 0.0895\n",
      "Epoch 93/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0131 - mae: 0.1020 - val_loss: 0.0117 - val_mae: 0.0843\n",
      "Epoch 94/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - loss: 0.0131 - mae: 0.1024 - val_loss: 0.0114 - val_mae: 0.0830\n",
      "Epoch 95/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - loss: 0.0131 - mae: 0.1020 - val_loss: 0.0095 - val_mae: 0.0695\n",
      "Epoch 96/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0132 - mae: 0.1021 - val_loss: 0.0145 - val_mae: 0.0997\n",
      "Epoch 97/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 14ms/step - loss: 0.0130 - mae: 0.1018 - val_loss: 0.0112 - val_mae: 0.0819\n",
      "Epoch 98/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - loss: 0.0131 - mae: 0.1019 - val_loss: 0.0119 - val_mae: 0.0863\n",
      "Epoch 99/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - loss: 0.0131 - mae: 0.1021 - val_loss: 0.0114 - val_mae: 0.0821\n",
      "Epoch 100/100\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0131 - mae: 0.1019 - val_loss: 0.0122 - val_mae: 0.0867\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step\n",
      "✅ Done with wheat_Davangere_daily.csv | MAE=316.73, RMSE=353.19, R2=0.5532, MAPE=16.19%, Accuracy=83.81%\n",
      "Saved updated CSV with Date, Actual & Predicted: tat_mqa_output_csv\\wheat_Davangere_daily_tat_mqa_updated.csv\n",
      "🚀 Processing: wheat_Dharwad_daily.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_31\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_31\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_query_attention_9       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">17,216</span> │ input_layer_31[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiQueryAttention</span>)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_62 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_query_attention_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                               │                           │                 │ input_layer_31[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_62        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_62[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_163 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ layer_normalization_62[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_164 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dense_163[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_63 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_62[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                               │                           │                 │ dense_164[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_63        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_63[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_31   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_63[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_165 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ global_average_pooling1d_… │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_31 (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_query_attention_9       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │          \u001b[38;5;34m17,216\u001b[0m │ input_layer_31[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mMultiQueryAttention\u001b[0m)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_62 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ multi_query_attention_9[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                               │                           │                 │ input_layer_31[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_62        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ add_62[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_163 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │           \u001b[38;5;34m8,320\u001b[0m │ layer_normalization_62[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_164 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │             \u001b[38;5;34m129\u001b[0m │ dense_163[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_63 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_62[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                               │                           │                 │ dense_164[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_63        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ add_63[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_31   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_63[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_165 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │              \u001b[38;5;34m65\u001b[0m │ global_average_pooling1d_… │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,986</span> (101.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25,986\u001b[0m (101.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,986</span> (101.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m25,986\u001b[0m (101.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 21ms/step - loss: 0.0185 - mae: 0.0843 - val_loss: 0.0185 - val_mae: 0.0991\n",
      "Epoch 2/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 17ms/step - loss: 0.0064 - mae: 0.0582 - val_loss: 0.0167 - val_mae: 0.0942\n",
      "Epoch 3/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 22ms/step - loss: 0.0061 - mae: 0.0565 - val_loss: 0.0150 - val_mae: 0.0883\n",
      "Epoch 4/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 21ms/step - loss: 0.0057 - mae: 0.0539 - val_loss: 0.0153 - val_mae: 0.0895\n",
      "Epoch 5/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 21ms/step - loss: 0.0057 - mae: 0.0533 - val_loss: 0.0166 - val_mae: 0.0922\n",
      "Epoch 6/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 23ms/step - loss: 0.0056 - mae: 0.0528 - val_loss: 0.0129 - val_mae: 0.0825\n",
      "Epoch 7/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 22ms/step - loss: 0.0055 - mae: 0.0522 - val_loss: 0.0127 - val_mae: 0.0822\n",
      "Epoch 8/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 25ms/step - loss: 0.0055 - mae: 0.0520 - val_loss: 0.0121 - val_mae: 0.0808\n",
      "Epoch 9/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 23ms/step - loss: 0.0055 - mae: 0.0520 - val_loss: 0.0119 - val_mae: 0.0804\n",
      "Epoch 10/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 21ms/step - loss: 0.0054 - mae: 0.0511 - val_loss: 0.0119 - val_mae: 0.0796\n",
      "Epoch 11/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 22ms/step - loss: 0.0054 - mae: 0.0513 - val_loss: 0.0119 - val_mae: 0.0799\n",
      "Epoch 12/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 18ms/step - loss: 0.0054 - mae: 0.0507 - val_loss: 0.0115 - val_mae: 0.0803\n",
      "Epoch 13/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 20ms/step - loss: 0.0054 - mae: 0.0507 - val_loss: 0.0111 - val_mae: 0.0815\n",
      "Epoch 14/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 23ms/step - loss: 0.0053 - mae: 0.0504 - val_loss: 0.0113 - val_mae: 0.0817\n",
      "Epoch 15/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 21ms/step - loss: 0.0053 - mae: 0.0506 - val_loss: 0.0120 - val_mae: 0.0799\n",
      "Epoch 16/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 21ms/step - loss: 0.0053 - mae: 0.0503 - val_loss: 0.0118 - val_mae: 0.0793\n",
      "Epoch 17/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 23ms/step - loss: 0.0053 - mae: 0.0503 - val_loss: 0.0111 - val_mae: 0.0816\n",
      "Epoch 18/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 21ms/step - loss: 0.0053 - mae: 0.0504 - val_loss: 0.0114 - val_mae: 0.0847\n",
      "Epoch 19/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 21ms/step - loss: 0.0053 - mae: 0.0502 - val_loss: 0.0115 - val_mae: 0.0797\n",
      "Epoch 20/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 22ms/step - loss: 0.0053 - mae: 0.0501 - val_loss: 0.0116 - val_mae: 0.0795\n",
      "Epoch 21/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 23ms/step - loss: 0.0053 - mae: 0.0501 - val_loss: 0.0112 - val_mae: 0.0804\n",
      "Epoch 22/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 23ms/step - loss: 0.0053 - mae: 0.0500 - val_loss: 0.0111 - val_mae: 0.0803\n",
      "Epoch 23/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 22ms/step - loss: 0.0053 - mae: 0.0501 - val_loss: 0.0112 - val_mae: 0.0799\n",
      "Epoch 24/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 23ms/step - loss: 0.0053 - mae: 0.0501 - val_loss: 0.0111 - val_mae: 0.0805\n",
      "Epoch 25/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 22ms/step - loss: 0.0053 - mae: 0.0501 - val_loss: 0.0111 - val_mae: 0.0794\n",
      "Epoch 26/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 19ms/step - loss: 0.0053 - mae: 0.0500 - val_loss: 0.0111 - val_mae: 0.0819\n",
      "Epoch 27/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 19ms/step - loss: 0.0053 - mae: 0.0500 - val_loss: 0.0111 - val_mae: 0.0810\n",
      "Epoch 28/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 21ms/step - loss: 0.0053 - mae: 0.0500 - val_loss: 0.0113 - val_mae: 0.0805\n",
      "Epoch 29/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 19ms/step - loss: 0.0053 - mae: 0.0501 - val_loss: 0.0112 - val_mae: 0.0831\n",
      "Epoch 30/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 18ms/step - loss: 0.0052 - mae: 0.0498 - val_loss: 0.0111 - val_mae: 0.0820\n",
      "Epoch 31/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 20ms/step - loss: 0.0052 - mae: 0.0499 - val_loss: 0.0110 - val_mae: 0.0819\n",
      "Epoch 32/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 19ms/step - loss: 0.0052 - mae: 0.0499 - val_loss: 0.0111 - val_mae: 0.0824\n",
      "Epoch 33/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 20ms/step - loss: 0.0052 - mae: 0.0500 - val_loss: 0.0112 - val_mae: 0.0821\n",
      "Epoch 34/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 20ms/step - loss: 0.0052 - mae: 0.0499 - val_loss: 0.0113 - val_mae: 0.0790\n",
      "Epoch 35/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 23ms/step - loss: 0.0052 - mae: 0.0499 - val_loss: 0.0114 - val_mae: 0.0789\n",
      "Epoch 36/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 23ms/step - loss: 0.0052 - mae: 0.0499 - val_loss: 0.0115 - val_mae: 0.0788\n",
      "Epoch 37/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 23ms/step - loss: 0.0052 - mae: 0.0497 - val_loss: 0.0114 - val_mae: 0.0782\n",
      "Epoch 38/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 23ms/step - loss: 0.0052 - mae: 0.0498 - val_loss: 0.0111 - val_mae: 0.0821\n",
      "Epoch 39/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 23ms/step - loss: 0.0052 - mae: 0.0499 - val_loss: 0.0110 - val_mae: 0.0808\n",
      "Epoch 40/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 23ms/step - loss: 0.0052 - mae: 0.0498 - val_loss: 0.0111 - val_mae: 0.0819\n",
      "Epoch 41/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 22ms/step - loss: 0.0052 - mae: 0.0496 - val_loss: 0.0112 - val_mae: 0.0800\n",
      "Epoch 42/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 23ms/step - loss: 0.0052 - mae: 0.0498 - val_loss: 0.0114 - val_mae: 0.0795\n",
      "Epoch 43/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 23ms/step - loss: 0.0052 - mae: 0.0497 - val_loss: 0.0117 - val_mae: 0.0788\n",
      "Epoch 44/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 21ms/step - loss: 0.0052 - mae: 0.0497 - val_loss: 0.0113 - val_mae: 0.0797\n",
      "Epoch 45/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 22ms/step - loss: 0.0052 - mae: 0.0499 - val_loss: 0.0117 - val_mae: 0.0790\n",
      "Epoch 46/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 22ms/step - loss: 0.0052 - mae: 0.0497 - val_loss: 0.0117 - val_mae: 0.0797\n",
      "Epoch 47/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 24ms/step - loss: 0.0052 - mae: 0.0497 - val_loss: 0.0122 - val_mae: 0.0788\n",
      "Epoch 48/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 20ms/step - loss: 0.0052 - mae: 0.0496 - val_loss: 0.0124 - val_mae: 0.0785\n",
      "Epoch 49/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 23ms/step - loss: 0.0052 - mae: 0.0496 - val_loss: 0.0116 - val_mae: 0.0803\n",
      "Epoch 50/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 19ms/step - loss: 0.0052 - mae: 0.0496 - val_loss: 0.0123 - val_mae: 0.0795\n",
      "Epoch 51/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 21ms/step - loss: 0.0052 - mae: 0.0496 - val_loss: 0.0118 - val_mae: 0.0790\n",
      "Epoch 52/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 20ms/step - loss: 0.0052 - mae: 0.0496 - val_loss: 0.0116 - val_mae: 0.0791\n",
      "Epoch 53/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 22ms/step - loss: 0.0052 - mae: 0.0498 - val_loss: 0.0150 - val_mae: 0.0854\n",
      "Epoch 54/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 21ms/step - loss: 0.0052 - mae: 0.0496 - val_loss: 0.0132 - val_mae: 0.0803\n",
      "Epoch 55/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 22ms/step - loss: 0.0052 - mae: 0.0496 - val_loss: 0.0117 - val_mae: 0.0792\n",
      "Epoch 56/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 22ms/step - loss: 0.0052 - mae: 0.0497 - val_loss: 0.0116 - val_mae: 0.0820\n",
      "Epoch 57/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 20ms/step - loss: 0.0052 - mae: 0.0497 - val_loss: 0.0126 - val_mae: 0.0791\n",
      "Epoch 58/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 21ms/step - loss: 0.0052 - mae: 0.0495 - val_loss: 0.0118 - val_mae: 0.0786\n",
      "Epoch 59/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 23ms/step - loss: 0.0052 - mae: 0.0496 - val_loss: 0.0122 - val_mae: 0.0788\n",
      "Epoch 60/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 23ms/step - loss: 0.0052 - mae: 0.0497 - val_loss: 0.0117 - val_mae: 0.0790\n",
      "Epoch 61/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 22ms/step - loss: 0.0052 - mae: 0.0498 - val_loss: 0.0118 - val_mae: 0.0788\n",
      "Epoch 62/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 21ms/step - loss: 0.0052 - mae: 0.0496 - val_loss: 0.0116 - val_mae: 0.0788\n",
      "Epoch 63/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 21ms/step - loss: 0.0052 - mae: 0.0497 - val_loss: 0.0119 - val_mae: 0.0786\n",
      "Epoch 64/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 21ms/step - loss: 0.0052 - mae: 0.0498 - val_loss: 0.0131 - val_mae: 0.0801\n",
      "Epoch 65/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 20ms/step - loss: 0.0052 - mae: 0.0496 - val_loss: 0.0120 - val_mae: 0.0789\n",
      "Epoch 66/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 23ms/step - loss: 0.0052 - mae: 0.0496 - val_loss: 0.0119 - val_mae: 0.0783\n",
      "Epoch 67/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 21ms/step - loss: 0.0052 - mae: 0.0496 - val_loss: 0.0131 - val_mae: 0.0799\n",
      "Epoch 68/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 23ms/step - loss: 0.0052 - mae: 0.0496 - val_loss: 0.0122 - val_mae: 0.0783\n",
      "Epoch 69/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 18ms/step - loss: 0.0052 - mae: 0.0496 - val_loss: 0.0118 - val_mae: 0.0790\n",
      "Epoch 70/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 19ms/step - loss: 0.0052 - mae: 0.0496 - val_loss: 0.0120 - val_mae: 0.0783\n",
      "Epoch 71/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 20ms/step - loss: 0.0052 - mae: 0.0496 - val_loss: 0.0115 - val_mae: 0.0789\n",
      "Epoch 72/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 21ms/step - loss: 0.0052 - mae: 0.0497 - val_loss: 0.0130 - val_mae: 0.0798\n",
      "Epoch 73/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 19ms/step - loss: 0.0052 - mae: 0.0496 - val_loss: 0.0129 - val_mae: 0.0802\n",
      "Epoch 74/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 19ms/step - loss: 0.0052 - mae: 0.0497 - val_loss: 0.0119 - val_mae: 0.0781\n",
      "Epoch 75/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 19ms/step - loss: 0.0052 - mae: 0.0495 - val_loss: 0.0123 - val_mae: 0.0783\n",
      "Epoch 76/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 19ms/step - loss: 0.0052 - mae: 0.0496 - val_loss: 0.0127 - val_mae: 0.0790\n",
      "Epoch 77/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 22ms/step - loss: 0.0052 - mae: 0.0497 - val_loss: 0.0136 - val_mae: 0.0810\n",
      "Epoch 78/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 22ms/step - loss: 0.0052 - mae: 0.0496 - val_loss: 0.0119 - val_mae: 0.0781\n",
      "Epoch 79/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 20ms/step - loss: 0.0052 - mae: 0.0495 - val_loss: 0.0120 - val_mae: 0.0781\n",
      "Epoch 80/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 22ms/step - loss: 0.0052 - mae: 0.0495 - val_loss: 0.0121 - val_mae: 0.0790\n",
      "Epoch 81/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 23ms/step - loss: 0.0052 - mae: 0.0496 - val_loss: 0.0122 - val_mae: 0.0786\n",
      "Epoch 82/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 23ms/step - loss: 0.0052 - mae: 0.0495 - val_loss: 0.0117 - val_mae: 0.0784\n",
      "Epoch 83/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 20ms/step - loss: 0.0052 - mae: 0.0496 - val_loss: 0.0117 - val_mae: 0.0783\n",
      "Epoch 84/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 18ms/step - loss: 0.0052 - mae: 0.0496 - val_loss: 0.0124 - val_mae: 0.0789\n",
      "Epoch 85/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 19ms/step - loss: 0.0052 - mae: 0.0497 - val_loss: 0.0127 - val_mae: 0.0795\n",
      "Epoch 86/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 21ms/step - loss: 0.0052 - mae: 0.0494 - val_loss: 0.0121 - val_mae: 0.0781\n",
      "Epoch 87/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 19ms/step - loss: 0.0052 - mae: 0.0494 - val_loss: 0.0118 - val_mae: 0.0781\n",
      "Epoch 88/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 23ms/step - loss: 0.0052 - mae: 0.0495 - val_loss: 0.0118 - val_mae: 0.0783\n",
      "Epoch 89/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 19ms/step - loss: 0.0052 - mae: 0.0496 - val_loss: 0.0123 - val_mae: 0.0786\n",
      "Epoch 90/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 21ms/step - loss: 0.0052 - mae: 0.0495 - val_loss: 0.0131 - val_mae: 0.0799\n",
      "Epoch 91/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 23ms/step - loss: 0.0052 - mae: 0.0496 - val_loss: 0.0120 - val_mae: 0.0780\n",
      "Epoch 92/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 21ms/step - loss: 0.0052 - mae: 0.0496 - val_loss: 0.0127 - val_mae: 0.0794\n",
      "Epoch 93/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 21ms/step - loss: 0.0052 - mae: 0.0495 - val_loss: 0.0119 - val_mae: 0.0783\n",
      "Epoch 94/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 22ms/step - loss: 0.0052 - mae: 0.0496 - val_loss: 0.0128 - val_mae: 0.0794\n",
      "Epoch 95/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 22ms/step - loss: 0.0052 - mae: 0.0495 - val_loss: 0.0119 - val_mae: 0.0779\n",
      "Epoch 96/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 22ms/step - loss: 0.0052 - mae: 0.0496 - val_loss: 0.0129 - val_mae: 0.0803\n",
      "Epoch 97/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 23ms/step - loss: 0.0052 - mae: 0.0496 - val_loss: 0.0125 - val_mae: 0.0789\n",
      "Epoch 98/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 23ms/step - loss: 0.0052 - mae: 0.0495 - val_loss: 0.0113 - val_mae: 0.0821\n",
      "Epoch 99/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 23ms/step - loss: 0.0052 - mae: 0.0496 - val_loss: 0.0124 - val_mae: 0.0788\n",
      "Epoch 100/100\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 19ms/step - loss: 0.0052 - mae: 0.0496 - val_loss: 0.0128 - val_mae: 0.0797\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step\n",
      "✅ Done with wheat_Dharwad_daily.csv | MAE=232.39, RMSE=337.81, R2=0.5571, MAPE=11.99%, Accuracy=88.01%\n",
      "Saved updated CSV with Date, Actual & Predicted: tat_mqa_output_csv\\wheat_Dharwad_daily_tat_mqa_updated.csv\n",
      "🚀 Processing: wheat_Gadag_daily.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_32\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_32\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_query_attention_10      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">17,216</span> │ input_layer_32[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiQueryAttention</span>)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_64 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_query_attention_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                               │                           │                 │ input_layer_32[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_64        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_64[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_173 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ layer_normalization_64[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_174 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dense_173[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_65 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_64[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                               │                           │                 │ dense_174[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_65        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_65[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_32   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_65[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_175 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ global_average_pooling1d_… │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_32 (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_query_attention_10      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │          \u001b[38;5;34m17,216\u001b[0m │ input_layer_32[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mMultiQueryAttention\u001b[0m)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_64 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ multi_query_attention_10[\u001b[38;5;34m…\u001b[0m │\n",
       "│                               │                           │                 │ input_layer_32[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_64        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ add_64[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_173 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │           \u001b[38;5;34m8,320\u001b[0m │ layer_normalization_64[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_174 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │             \u001b[38;5;34m129\u001b[0m │ dense_173[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_65 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_64[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                               │                           │                 │ dense_174[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_65        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ add_65[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_32   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_65[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_175 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │              \u001b[38;5;34m65\u001b[0m │ global_average_pooling1d_… │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,986</span> (101.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25,986\u001b[0m (101.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,986</span> (101.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m25,986\u001b[0m (101.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 15ms/step - loss: 0.0430 - mae: 0.0992 - val_loss: 0.0021 - val_mae: 0.0331\n",
      "Epoch 2/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 18ms/step - loss: 0.0029 - mae: 0.0421 - val_loss: 0.0019 - val_mae: 0.0314\n",
      "Epoch 3/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17ms/step - loss: 0.0013 - mae: 0.0272 - val_loss: 0.0015 - val_mae: 0.0287\n",
      "Epoch 4/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15ms/step - loss: 9.4237e-04 - mae: 0.0228 - val_loss: 0.0015 - val_mae: 0.0282\n",
      "Epoch 5/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 8.7095e-04 - mae: 0.0216 - val_loss: 0.0025 - val_mae: 0.0370\n",
      "Epoch 6/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 17ms/step - loss: 8.4725e-04 - mae: 0.0214 - val_loss: 0.0020 - val_mae: 0.0318\n",
      "Epoch 7/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 18ms/step - loss: 7.9179e-04 - mae: 0.0205 - val_loss: 0.0014 - val_mae: 0.0276\n",
      "Epoch 8/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14ms/step - loss: 8.1619e-04 - mae: 0.0208 - val_loss: 0.0017 - val_mae: 0.0296\n",
      "Epoch 9/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 7.3135e-04 - mae: 0.0191 - val_loss: 0.0019 - val_mae: 0.0312\n",
      "Epoch 10/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17ms/step - loss: 7.0682e-04 - mae: 0.0188 - val_loss: 0.0014 - val_mae: 0.0290\n",
      "Epoch 11/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15ms/step - loss: 7.1761e-04 - mae: 0.0189 - val_loss: 0.0013 - val_mae: 0.0263\n",
      "Epoch 12/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14ms/step - loss: 6.9735e-04 - mae: 0.0186 - val_loss: 0.0013 - val_mae: 0.0271\n",
      "Epoch 13/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15ms/step - loss: 6.8419e-04 - mae: 0.0184 - val_loss: 0.0017 - val_mae: 0.0293\n",
      "Epoch 14/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15ms/step - loss: 6.7415e-04 - mae: 0.0181 - val_loss: 0.0015 - val_mae: 0.0272\n",
      "Epoch 15/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15ms/step - loss: 6.6644e-04 - mae: 0.0180 - val_loss: 0.0013 - val_mae: 0.0262\n",
      "Epoch 16/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 14ms/step - loss: 6.5222e-04 - mae: 0.0176 - val_loss: 0.0015 - val_mae: 0.0269\n",
      "Epoch 17/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15ms/step - loss: 6.4656e-04 - mae: 0.0176 - val_loss: 0.0015 - val_mae: 0.0270\n",
      "Epoch 18/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15ms/step - loss: 6.5124e-04 - mae: 0.0176 - val_loss: 0.0013 - val_mae: 0.0253\n",
      "Epoch 19/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15ms/step - loss: 6.3943e-04 - mae: 0.0174 - val_loss: 0.0013 - val_mae: 0.0259\n",
      "Epoch 20/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15ms/step - loss: 6.4012e-04 - mae: 0.0174 - val_loss: 0.0013 - val_mae: 0.0259\n",
      "Epoch 21/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15ms/step - loss: 6.3515e-04 - mae: 0.0173 - val_loss: 0.0013 - val_mae: 0.0255\n",
      "Epoch 22/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 6.3281e-04 - mae: 0.0172 - val_loss: 0.0012 - val_mae: 0.0261\n",
      "Epoch 23/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14ms/step - loss: 6.3224e-04 - mae: 0.0172 - val_loss: 0.0012 - val_mae: 0.0252\n",
      "Epoch 24/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15ms/step - loss: 6.3147e-04 - mae: 0.0171 - val_loss: 0.0012 - val_mae: 0.0253\n",
      "Epoch 25/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 6.3202e-04 - mae: 0.0172 - val_loss: 0.0013 - val_mae: 0.0254\n",
      "Epoch 26/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 6.3660e-04 - mae: 0.0172 - val_loss: 0.0013 - val_mae: 0.0272\n",
      "Epoch 27/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17ms/step - loss: 6.2843e-04 - mae: 0.0171 - val_loss: 0.0013 - val_mae: 0.0253\n",
      "Epoch 28/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - loss: 6.2506e-04 - mae: 0.0170 - val_loss: 0.0012 - val_mae: 0.0252\n",
      "Epoch 29/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 6.3031e-04 - mae: 0.0171 - val_loss: 0.0013 - val_mae: 0.0253\n",
      "Epoch 30/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17ms/step - loss: 6.2437e-04 - mae: 0.0170 - val_loss: 0.0013 - val_mae: 0.0255\n",
      "Epoch 31/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17ms/step - loss: 6.2488e-04 - mae: 0.0170 - val_loss: 0.0014 - val_mae: 0.0259\n",
      "Epoch 32/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17ms/step - loss: 6.2165e-04 - mae: 0.0169 - val_loss: 0.0012 - val_mae: 0.0254\n",
      "Epoch 33/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 6.2513e-04 - mae: 0.0170 - val_loss: 0.0012 - val_mae: 0.0252\n",
      "Epoch 34/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17ms/step - loss: 6.2219e-04 - mae: 0.0170 - val_loss: 0.0012 - val_mae: 0.0251\n",
      "Epoch 35/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 15ms/step - loss: 6.1973e-04 - mae: 0.0169 - val_loss: 0.0012 - val_mae: 0.0251\n",
      "Epoch 36/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 15ms/step - loss: 6.2204e-04 - mae: 0.0169 - val_loss: 0.0012 - val_mae: 0.0251\n",
      "Epoch 37/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 6.2109e-04 - mae: 0.0169 - val_loss: 0.0013 - val_mae: 0.0255\n",
      "Epoch 38/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 6.2099e-04 - mae: 0.0169 - val_loss: 0.0012 - val_mae: 0.0252\n",
      "Epoch 39/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14ms/step - loss: 6.2040e-04 - mae: 0.0169 - val_loss: 0.0012 - val_mae: 0.0252\n",
      "Epoch 40/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 6.2025e-04 - mae: 0.0169 - val_loss: 0.0012 - val_mae: 0.0256\n",
      "Epoch 41/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 6.1873e-04 - mae: 0.0169 - val_loss: 0.0013 - val_mae: 0.0253\n",
      "Epoch 42/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15ms/step - loss: 6.2117e-04 - mae: 0.0170 - val_loss: 0.0013 - val_mae: 0.0253\n",
      "Epoch 43/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 6.2060e-04 - mae: 0.0169 - val_loss: 0.0012 - val_mae: 0.0252\n",
      "Epoch 44/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 6.1882e-04 - mae: 0.0169 - val_loss: 0.0016 - val_mae: 0.0278\n",
      "Epoch 45/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - loss: 6.2251e-04 - mae: 0.0169 - val_loss: 0.0013 - val_mae: 0.0252\n",
      "Epoch 46/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 6.2171e-04 - mae: 0.0170 - val_loss: 0.0013 - val_mae: 0.0254\n",
      "Epoch 47/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 6.2311e-04 - mae: 0.0169 - val_loss: 0.0012 - val_mae: 0.0263\n",
      "Epoch 48/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15ms/step - loss: 6.2124e-04 - mae: 0.0169 - val_loss: 0.0013 - val_mae: 0.0258\n",
      "Epoch 49/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 6.1965e-04 - mae: 0.0169 - val_loss: 0.0012 - val_mae: 0.0261\n",
      "Epoch 50/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 6.1889e-04 - mae: 0.0169 - val_loss: 0.0013 - val_mae: 0.0252\n",
      "Epoch 51/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17ms/step - loss: 6.1851e-04 - mae: 0.0169 - val_loss: 0.0012 - val_mae: 0.0252\n",
      "Epoch 52/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 6.1644e-04 - mae: 0.0168 - val_loss: 0.0013 - val_mae: 0.0256\n",
      "Epoch 53/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14ms/step - loss: 6.1748e-04 - mae: 0.0169 - val_loss: 0.0013 - val_mae: 0.0255\n",
      "Epoch 54/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 6.1825e-04 - mae: 0.0169 - val_loss: 0.0012 - val_mae: 0.0250\n",
      "Epoch 55/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 6.1722e-04 - mae: 0.0169 - val_loss: 0.0012 - val_mae: 0.0251\n",
      "Epoch 56/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15ms/step - loss: 6.1710e-04 - mae: 0.0168 - val_loss: 0.0012 - val_mae: 0.0250\n",
      "Epoch 57/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - loss: 6.1906e-04 - mae: 0.0169 - val_loss: 0.0013 - val_mae: 0.0255\n",
      "Epoch 58/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 15ms/step - loss: 6.1829e-04 - mae: 0.0169 - val_loss: 0.0012 - val_mae: 0.0251\n",
      "Epoch 59/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17ms/step - loss: 6.1788e-04 - mae: 0.0168 - val_loss: 0.0013 - val_mae: 0.0258\n",
      "Epoch 60/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 6.1744e-04 - mae: 0.0168 - val_loss: 0.0013 - val_mae: 0.0254\n",
      "Epoch 61/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17ms/step - loss: 6.1766e-04 - mae: 0.0169 - val_loss: 0.0012 - val_mae: 0.0257\n",
      "Epoch 62/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - loss: 6.1920e-04 - mae: 0.0169 - val_loss: 0.0013 - val_mae: 0.0257\n",
      "Epoch 63/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17ms/step - loss: 6.1911e-04 - mae: 0.0169 - val_loss: 0.0012 - val_mae: 0.0252\n",
      "Epoch 64/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 6.1690e-04 - mae: 0.0169 - val_loss: 0.0012 - val_mae: 0.0251\n",
      "Epoch 65/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 6.2039e-04 - mae: 0.0169 - val_loss: 0.0014 - val_mae: 0.0258\n",
      "Epoch 66/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15ms/step - loss: 6.1843e-04 - mae: 0.0168 - val_loss: 0.0012 - val_mae: 0.0251\n",
      "Epoch 67/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 6.1720e-04 - mae: 0.0169 - val_loss: 0.0016 - val_mae: 0.0282\n",
      "Epoch 68/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 6.2007e-04 - mae: 0.0169 - val_loss: 0.0012 - val_mae: 0.0251\n",
      "Epoch 69/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - loss: 6.1641e-04 - mae: 0.0168 - val_loss: 0.0013 - val_mae: 0.0255\n",
      "Epoch 70/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17ms/step - loss: 6.1901e-04 - mae: 0.0169 - val_loss: 0.0013 - val_mae: 0.0259\n",
      "Epoch 71/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - loss: 6.1717e-04 - mae: 0.0168 - val_loss: 0.0012 - val_mae: 0.0251\n",
      "Epoch 72/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 6.1626e-04 - mae: 0.0168 - val_loss: 0.0012 - val_mae: 0.0261\n",
      "Epoch 73/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 6.1776e-04 - mae: 0.0169 - val_loss: 0.0012 - val_mae: 0.0251\n",
      "Epoch 74/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17ms/step - loss: 6.1639e-04 - mae: 0.0168 - val_loss: 0.0012 - val_mae: 0.0257\n",
      "Epoch 75/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14ms/step - loss: 6.1755e-04 - mae: 0.0169 - val_loss: 0.0013 - val_mae: 0.0253\n",
      "Epoch 76/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15ms/step - loss: 6.1675e-04 - mae: 0.0168 - val_loss: 0.0012 - val_mae: 0.0250\n",
      "Epoch 77/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15ms/step - loss: 6.1734e-04 - mae: 0.0169 - val_loss: 0.0012 - val_mae: 0.0252\n",
      "Epoch 78/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15ms/step - loss: 6.1724e-04 - mae: 0.0168 - val_loss: 0.0012 - val_mae: 0.0258\n",
      "Epoch 79/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - loss: 6.1601e-04 - mae: 0.0168 - val_loss: 0.0013 - val_mae: 0.0257\n",
      "Epoch 80/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15ms/step - loss: 6.1609e-04 - mae: 0.0168 - val_loss: 0.0012 - val_mae: 0.0251\n",
      "Epoch 81/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15ms/step - loss: 6.1469e-04 - mae: 0.0168 - val_loss: 0.0012 - val_mae: 0.0251\n",
      "Epoch 82/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14ms/step - loss: 6.1564e-04 - mae: 0.0168 - val_loss: 0.0012 - val_mae: 0.0253\n",
      "Epoch 83/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - loss: 6.1709e-04 - mae: 0.0168 - val_loss: 0.0012 - val_mae: 0.0251\n",
      "Epoch 84/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15ms/step - loss: 6.1691e-04 - mae: 0.0168 - val_loss: 0.0012 - val_mae: 0.0256\n",
      "Epoch 85/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14ms/step - loss: 6.1558e-04 - mae: 0.0168 - val_loss: 0.0012 - val_mae: 0.0251\n",
      "Epoch 86/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - loss: 6.1890e-04 - mae: 0.0169 - val_loss: 0.0014 - val_mae: 0.0261\n",
      "Epoch 87/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 6.1822e-04 - mae: 0.0169 - val_loss: 0.0012 - val_mae: 0.0252\n",
      "Epoch 88/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 6.1569e-04 - mae: 0.0168 - val_loss: 0.0012 - val_mae: 0.0251\n",
      "Epoch 89/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 6.1817e-04 - mae: 0.0169 - val_loss: 0.0012 - val_mae: 0.0251\n",
      "Epoch 90/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 15ms/step - loss: 6.1569e-04 - mae: 0.0168 - val_loss: 0.0012 - val_mae: 0.0252\n",
      "Epoch 91/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 6.1613e-04 - mae: 0.0168 - val_loss: 0.0012 - val_mae: 0.0254\n",
      "Epoch 92/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17ms/step - loss: 6.1668e-04 - mae: 0.0168 - val_loss: 0.0013 - val_mae: 0.0253\n",
      "Epoch 93/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17ms/step - loss: 6.1664e-04 - mae: 0.0168 - val_loss: 0.0012 - val_mae: 0.0256\n",
      "Epoch 94/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 6.1654e-04 - mae: 0.0168 - val_loss: 0.0012 - val_mae: 0.0252\n",
      "Epoch 95/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17ms/step - loss: 6.1641e-04 - mae: 0.0168 - val_loss: 0.0012 - val_mae: 0.0251\n",
      "Epoch 96/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - loss: 6.1673e-04 - mae: 0.0168 - val_loss: 0.0013 - val_mae: 0.0256\n",
      "Epoch 97/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - loss: 6.1653e-04 - mae: 0.0169 - val_loss: 0.0013 - val_mae: 0.0252\n",
      "Epoch 98/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 6.1704e-04 - mae: 0.0168 - val_loss: 0.0013 - val_mae: 0.0254\n",
      "Epoch 99/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 6.1768e-04 - mae: 0.0168 - val_loss: 0.0012 - val_mae: 0.0251\n",
      "Epoch 100/100\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 6.1574e-04 - mae: 0.0168 - val_loss: 0.0012 - val_mae: 0.0255\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step\n",
      "✅ Done with wheat_Gadag_daily.csv | MAE=271.66, RMSE=395.06, R2=0.5614, MAPE=14.29%, Accuracy=85.71%\n",
      "Saved updated CSV with Date, Actual & Predicted: tat_mqa_output_csv\\wheat_Gadag_daily_tat_mqa_updated.csv\n",
      "🚀 Processing: wheat_Hassan_daily.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_33\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_33\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_query_attention_11      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">17,216</span> │ input_layer_33[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiQueryAttention</span>)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_66 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_query_attention_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                               │                           │                 │ input_layer_33[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_66        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_66[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_183 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ layer_normalization_66[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_184 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dense_183[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_67 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_66[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                               │                           │                 │ dense_184[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_67        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_67[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_33   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_67[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_185 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ global_average_pooling1d_… │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_33 (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_query_attention_11      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │          \u001b[38;5;34m17,216\u001b[0m │ input_layer_33[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mMultiQueryAttention\u001b[0m)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_66 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ multi_query_attention_11[\u001b[38;5;34m…\u001b[0m │\n",
       "│                               │                           │                 │ input_layer_33[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_66        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ add_66[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_183 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │           \u001b[38;5;34m8,320\u001b[0m │ layer_normalization_66[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_184 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │             \u001b[38;5;34m129\u001b[0m │ dense_183[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_67 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_66[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                               │                           │                 │ dense_184[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_67        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ add_67[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_33   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_67[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_185 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │              \u001b[38;5;34m65\u001b[0m │ global_average_pooling1d_… │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,986</span> (101.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25,986\u001b[0m (101.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,986</span> (101.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m25,986\u001b[0m (101.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0175 - mae: 0.0748 - val_loss: 7.9966e-04 - val_mae: 0.0218\n",
      "Epoch 2/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - loss: 0.0020 - mae: 0.0315 - val_loss: 8.6264e-04 - val_mae: 0.0229\n",
      "Epoch 3/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - loss: 0.0015 - mae: 0.0244 - val_loss: 4.9160e-04 - val_mae: 0.0185\n",
      "Epoch 4/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - loss: 0.0012 - mae: 0.0213 - val_loss: 0.0012 - val_mae: 0.0281\n",
      "Epoch 5/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - loss: 0.0012 - mae: 0.0203 - val_loss: 0.0011 - val_mae: 0.0270\n",
      "Epoch 6/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - loss: 0.0012 - mae: 0.0207 - val_loss: 4.2991e-04 - val_mae: 0.0158\n",
      "Epoch 7/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - loss: 0.0011 - mae: 0.0193 - val_loss: 4.1454e-04 - val_mae: 0.0157\n",
      "Epoch 8/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - loss: 0.0011 - mae: 0.0193 - val_loss: 0.0013 - val_mae: 0.0301\n",
      "Epoch 9/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - loss: 0.0011 - mae: 0.0195 - val_loss: 0.0011 - val_mae: 0.0264\n",
      "Epoch 10/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - loss: 0.0012 - mae: 0.0207 - val_loss: 7.9080e-04 - val_mae: 0.0220\n",
      "Epoch 11/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - loss: 0.0011 - mae: 0.0196 - val_loss: 3.7433e-04 - val_mae: 0.0160\n",
      "Epoch 12/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - loss: 0.0011 - mae: 0.0195 - val_loss: 0.0013 - val_mae: 0.0300\n",
      "Epoch 13/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - loss: 0.0011 - mae: 0.0190 - val_loss: 4.3471e-04 - val_mae: 0.0160\n",
      "Epoch 14/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - loss: 0.0010 - mae: 0.0188 - val_loss: 8.5119e-04 - val_mae: 0.0231\n",
      "Epoch 15/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - loss: 0.0011 - mae: 0.0192 - val_loss: 0.0015 - val_mae: 0.0345\n",
      "Epoch 16/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - loss: 0.0010 - mae: 0.0184 - val_loss: 4.7510e-04 - val_mae: 0.0170\n",
      "Epoch 17/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 15ms/step - loss: 0.0011 - mae: 0.0194 - val_loss: 4.4174e-04 - val_mae: 0.0162\n",
      "Epoch 18/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - loss: 0.0010 - mae: 0.0192 - val_loss: 3.6636e-04 - val_mae: 0.0159\n",
      "Epoch 19/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - loss: 0.0010 - mae: 0.0187 - val_loss: 3.5492e-04 - val_mae: 0.0151\n",
      "Epoch 20/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - loss: 0.0010 - mae: 0.0185 - val_loss: 4.1064e-04 - val_mae: 0.0169\n",
      "Epoch 21/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - loss: 0.0010 - mae: 0.0179 - val_loss: 2.8728e-04 - val_mae: 0.0141\n",
      "Epoch 22/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - loss: 0.0010 - mae: 0.0187 - val_loss: 4.0584e-04 - val_mae: 0.0158\n",
      "Epoch 23/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - loss: 0.0010 - mae: 0.0180 - val_loss: 4.5438e-04 - val_mae: 0.0167\n",
      "Epoch 24/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - loss: 0.0010 - mae: 0.0180 - val_loss: 3.3490e-04 - val_mae: 0.0150\n",
      "Epoch 25/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - loss: 0.0010 - mae: 0.0184 - val_loss: 3.1775e-04 - val_mae: 0.0144\n",
      "Epoch 26/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - loss: 0.0010 - mae: 0.0180 - val_loss: 5.9138e-04 - val_mae: 0.0189\n",
      "Epoch 27/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - loss: 9.9600e-04 - mae: 0.0175 - val_loss: 3.9095e-04 - val_mae: 0.0155\n",
      "Epoch 28/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - loss: 9.7323e-04 - mae: 0.0179 - val_loss: 4.0759e-04 - val_mae: 0.0158\n",
      "Epoch 29/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - loss: 9.8040e-04 - mae: 0.0180 - val_loss: 8.5643e-04 - val_mae: 0.0233\n",
      "Epoch 30/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - loss: 9.6783e-04 - mae: 0.0172 - val_loss: 6.1487e-04 - val_mae: 0.0203\n",
      "Epoch 31/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - loss: 9.8961e-04 - mae: 0.0178 - val_loss: 2.7380e-04 - val_mae: 0.0139\n",
      "Epoch 32/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - loss: 9.8223e-04 - mae: 0.0175 - val_loss: 4.5578e-04 - val_mae: 0.0166\n",
      "Epoch 33/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - loss: 9.6674e-04 - mae: 0.0171 - val_loss: 2.7894e-04 - val_mae: 0.0139\n",
      "Epoch 34/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 9.7448e-04 - mae: 0.0175 - val_loss: 3.0040e-04 - val_mae: 0.0141\n",
      "Epoch 35/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - loss: 9.5932e-04 - mae: 0.0172 - val_loss: 5.4541e-04 - val_mae: 0.0182\n",
      "Epoch 36/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - loss: 9.5268e-04 - mae: 0.0176 - val_loss: 3.7264e-04 - val_mae: 0.0153\n",
      "Epoch 37/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - loss: 9.6953e-04 - mae: 0.0173 - val_loss: 2.9351e-04 - val_mae: 0.0140\n",
      "Epoch 38/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - loss: 9.5466e-04 - mae: 0.0173 - val_loss: 3.0034e-04 - val_mae: 0.0142\n",
      "Epoch 39/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - loss: 9.4196e-04 - mae: 0.0174 - val_loss: 3.3359e-04 - val_mae: 0.0147\n",
      "Epoch 40/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - loss: 9.4731e-04 - mae: 0.0171 - val_loss: 4.5789e-04 - val_mae: 0.0171\n",
      "Epoch 41/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - loss: 9.4726e-04 - mae: 0.0173 - val_loss: 2.7276e-04 - val_mae: 0.0140\n",
      "Epoch 42/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - loss: 9.5023e-04 - mae: 0.0172 - val_loss: 2.7463e-04 - val_mae: 0.0140\n",
      "Epoch 43/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - loss: 9.4034e-04 - mae: 0.0169 - val_loss: 2.7230e-04 - val_mae: 0.0139\n",
      "Epoch 44/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - loss: 9.3494e-04 - mae: 0.0171 - val_loss: 4.0427e-04 - val_mae: 0.0159\n",
      "Epoch 45/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - loss: 9.3724e-04 - mae: 0.0168 - val_loss: 3.4162e-04 - val_mae: 0.0146\n",
      "Epoch 46/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - loss: 9.3074e-04 - mae: 0.0171 - val_loss: 2.9156e-04 - val_mae: 0.0142\n",
      "Epoch 47/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - loss: 9.3442e-04 - mae: 0.0170 - val_loss: 6.9095e-04 - val_mae: 0.0216\n",
      "Epoch 48/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - loss: 9.3439e-04 - mae: 0.0169 - val_loss: 7.6136e-04 - val_mae: 0.0222\n",
      "Epoch 49/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - loss: 9.3111e-04 - mae: 0.0171 - val_loss: 4.1300e-04 - val_mae: 0.0161\n",
      "Epoch 50/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - loss: 9.3302e-04 - mae: 0.0168 - val_loss: 2.9449e-04 - val_mae: 0.0141\n",
      "Epoch 51/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - loss: 9.3855e-04 - mae: 0.0171 - val_loss: 2.7095e-04 - val_mae: 0.0139\n",
      "Epoch 52/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - loss: 9.2319e-04 - mae: 0.0170 - val_loss: 0.0026 - val_mae: 0.0441\n",
      "Epoch 53/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - loss: 9.3429e-04 - mae: 0.0168 - val_loss: 4.1218e-04 - val_mae: 0.0158\n",
      "Epoch 54/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - loss: 9.1371e-04 - mae: 0.0171 - val_loss: 5.1768e-04 - val_mae: 0.0176\n",
      "Epoch 55/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - loss: 9.1359e-04 - mae: 0.0168 - val_loss: 0.0011 - val_mae: 0.0274\n",
      "Epoch 56/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - loss: 9.0972e-04 - mae: 0.0168 - val_loss: 7.7989e-04 - val_mae: 0.0231\n",
      "Epoch 57/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - loss: 9.0674e-04 - mae: 0.0169 - val_loss: 4.1420e-04 - val_mae: 0.0159\n",
      "Epoch 58/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - loss: 9.0878e-04 - mae: 0.0169 - val_loss: 2.8678e-04 - val_mae: 0.0141\n",
      "Epoch 59/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - loss: 9.2587e-04 - mae: 0.0168 - val_loss: 6.1735e-04 - val_mae: 0.0192\n",
      "Epoch 60/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - loss: 9.2633e-04 - mae: 0.0168 - val_loss: 3.4659e-04 - val_mae: 0.0149\n",
      "Epoch 61/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - loss: 9.1032e-04 - mae: 0.0166 - val_loss: 0.0021 - val_mae: 0.0407\n",
      "Epoch 62/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 9.1649e-04 - mae: 0.0167 - val_loss: 6.3114e-04 - val_mae: 0.0195\n",
      "Epoch 63/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 9.2245e-04 - mae: 0.0167 - val_loss: 3.5044e-04 - val_mae: 0.0150\n",
      "Epoch 64/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - loss: 9.2601e-04 - mae: 0.0168 - val_loss: 9.5994e-04 - val_mae: 0.0262\n",
      "Epoch 65/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - loss: 8.9986e-04 - mae: 0.0166 - val_loss: 3.4086e-04 - val_mae: 0.0149\n",
      "Epoch 66/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 9.1817e-04 - mae: 0.0168 - val_loss: 2.8827e-04 - val_mae: 0.0143\n",
      "Epoch 67/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - loss: 9.1198e-04 - mae: 0.0167 - val_loss: 8.0529e-04 - val_mae: 0.0223\n",
      "Epoch 68/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 9.2588e-04 - mae: 0.0168 - val_loss: 3.0492e-04 - val_mae: 0.0145\n",
      "Epoch 69/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - loss: 9.1427e-04 - mae: 0.0169 - val_loss: 4.6051e-04 - val_mae: 0.0166\n",
      "Epoch 70/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 8.9939e-04 - mae: 0.0167 - val_loss: 2.8814e-04 - val_mae: 0.0143\n",
      "Epoch 71/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - loss: 8.9916e-04 - mae: 0.0166 - val_loss: 0.0019 - val_mae: 0.0364\n",
      "Epoch 72/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - loss: 8.9810e-04 - mae: 0.0167 - val_loss: 7.0102e-04 - val_mae: 0.0207\n",
      "Epoch 73/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - loss: 9.3135e-04 - mae: 0.0168 - val_loss: 3.4463e-04 - val_mae: 0.0150\n",
      "Epoch 74/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 9.0418e-04 - mae: 0.0165 - val_loss: 7.2462e-04 - val_mae: 0.0209\n",
      "Epoch 75/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 9.0682e-04 - mae: 0.0168 - val_loss: 4.0018e-04 - val_mae: 0.0157\n",
      "Epoch 76/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - loss: 9.1194e-04 - mae: 0.0165 - val_loss: 0.0012 - val_mae: 0.0290\n",
      "Epoch 77/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 8.9337e-04 - mae: 0.0166 - val_loss: 0.0018 - val_mae: 0.0343\n",
      "Epoch 78/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - loss: 9.2081e-04 - mae: 0.0167 - val_loss: 3.5260e-04 - val_mae: 0.0152\n",
      "Epoch 79/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 9.1553e-04 - mae: 0.0167 - val_loss: 6.7439e-04 - val_mae: 0.0198\n",
      "Epoch 80/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - loss: 8.9264e-04 - mae: 0.0167 - val_loss: 3.9542e-04 - val_mae: 0.0158\n",
      "Epoch 81/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 9.1702e-04 - mae: 0.0166 - val_loss: 5.0427e-04 - val_mae: 0.0174\n",
      "Epoch 82/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - loss: 8.9906e-04 - mae: 0.0168 - val_loss: 2.9467e-04 - val_mae: 0.0144\n",
      "Epoch 83/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - loss: 8.8718e-04 - mae: 0.0165 - val_loss: 0.0033 - val_mae: 0.0483\n",
      "Epoch 84/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 8.9602e-04 - mae: 0.0168 - val_loss: 2.9765e-04 - val_mae: 0.0144\n",
      "Epoch 85/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - loss: 9.1102e-04 - mae: 0.0167 - val_loss: 7.4947e-04 - val_mae: 0.0213\n",
      "Epoch 86/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - loss: 8.9789e-04 - mae: 0.0168 - val_loss: 0.0011 - val_mae: 0.0263\n",
      "Epoch 87/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - loss: 9.1642e-04 - mae: 0.0168 - val_loss: 8.3928e-04 - val_mae: 0.0227\n",
      "Epoch 88/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - loss: 9.1049e-04 - mae: 0.0167 - val_loss: 0.0016 - val_mae: 0.0325\n",
      "Epoch 89/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - loss: 9.0133e-04 - mae: 0.0167 - val_loss: 0.0014 - val_mae: 0.0297\n",
      "Epoch 90/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - loss: 9.0123e-04 - mae: 0.0166 - val_loss: 4.3412e-04 - val_mae: 0.0165\n",
      "Epoch 91/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - loss: 9.2090e-04 - mae: 0.0168 - val_loss: 0.0011 - val_mae: 0.0267\n",
      "Epoch 92/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - loss: 8.9896e-04 - mae: 0.0166 - val_loss: 8.0776e-04 - val_mae: 0.0222\n",
      "Epoch 93/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - loss: 9.0603e-04 - mae: 0.0167 - val_loss: 0.0019 - val_mae: 0.0359\n",
      "Epoch 94/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 9.0497e-04 - mae: 0.0167 - val_loss: 0.0022 - val_mae: 0.0396\n",
      "Epoch 95/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - loss: 9.1417e-04 - mae: 0.0166 - val_loss: 0.0011 - val_mae: 0.0259\n",
      "Epoch 96/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - loss: 8.9592e-04 - mae: 0.0165 - val_loss: 7.8747e-04 - val_mae: 0.0215\n",
      "Epoch 97/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - loss: 9.0581e-04 - mae: 0.0165 - val_loss: 0.0019 - val_mae: 0.0351\n",
      "Epoch 98/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - loss: 9.0356e-04 - mae: 0.0167 - val_loss: 0.0033 - val_mae: 0.0473\n",
      "Epoch 99/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - loss: 9.1568e-04 - mae: 0.0170 - val_loss: 4.0499e-04 - val_mae: 0.0160\n",
      "Epoch 100/100\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 9.0160e-04 - mae: 0.0164 - val_loss: 0.0011 - val_mae: 0.0256\n",
      "\u001b[1m389/389\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step\n",
      "✅ Done with wheat_Hassan_daily.csv | MAE=245.72, RMSE=394.59, R2=0.6709, MAPE=12.08%, Accuracy=87.92%\n",
      "Saved updated CSV with Date, Actual & Predicted: tat_mqa_output_csv\\wheat_Hassan_daily_tat_mqa_updated.csv\n",
      "🚀 Processing: wheat_Haveri_daily.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_34\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_34\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_query_attention_12      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">17,216</span> │ input_layer_34[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiQueryAttention</span>)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_68 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_query_attention_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                               │                           │                 │ input_layer_34[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_68        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_68[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_193 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ layer_normalization_68[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_194 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dense_193[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_69 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_68[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                               │                           │                 │ dense_194[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_69        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_69[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_34   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_69[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_195 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ global_average_pooling1d_… │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_34 (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_query_attention_12      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │          \u001b[38;5;34m17,216\u001b[0m │ input_layer_34[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mMultiQueryAttention\u001b[0m)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_68 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ multi_query_attention_12[\u001b[38;5;34m…\u001b[0m │\n",
       "│                               │                           │                 │ input_layer_34[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_68        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ add_68[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_193 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │           \u001b[38;5;34m8,320\u001b[0m │ layer_normalization_68[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_194 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │             \u001b[38;5;34m129\u001b[0m │ dense_193[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_69 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_68[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                               │                           │                 │ dense_194[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_69        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ add_69[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_34   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_69[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_195 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │              \u001b[38;5;34m65\u001b[0m │ global_average_pooling1d_… │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,986</span> (101.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25,986\u001b[0m (101.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,986</span> (101.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m25,986\u001b[0m (101.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 15ms/step - loss: 0.0264 - mae: 0.1119 - val_loss: 0.0312 - val_mae: 0.1417\n",
      "Epoch 2/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 0.0142 - mae: 0.0907 - val_loss: 0.0213 - val_mae: 0.1228\n",
      "Epoch 3/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - loss: 0.0132 - mae: 0.0871 - val_loss: 0.0204 - val_mae: 0.1203\n",
      "Epoch 4/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - loss: 0.0127 - mae: 0.0855 - val_loss: 0.0208 - val_mae: 0.1231\n",
      "Epoch 5/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 0.0127 - mae: 0.0850 - val_loss: 0.0196 - val_mae: 0.1191\n",
      "Epoch 6/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - loss: 0.0126 - mae: 0.0851 - val_loss: 0.0189 - val_mae: 0.1162\n",
      "Epoch 7/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - loss: 0.0124 - mae: 0.0843 - val_loss: 0.0230 - val_mae: 0.1249\n",
      "Epoch 8/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - loss: 0.0124 - mae: 0.0843 - val_loss: 0.0199 - val_mae: 0.1188\n",
      "Epoch 9/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - loss: 0.0124 - mae: 0.0841 - val_loss: 0.0198 - val_mae: 0.1171\n",
      "Epoch 10/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 0.0122 - mae: 0.0834 - val_loss: 0.0184 - val_mae: 0.1123\n",
      "Epoch 11/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 0.0122 - mae: 0.0835 - val_loss: 0.0170 - val_mae: 0.1073\n",
      "Epoch 12/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - loss: 0.0120 - mae: 0.0825 - val_loss: 0.0171 - val_mae: 0.1091\n",
      "Epoch 13/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 0.0121 - mae: 0.0831 - val_loss: 0.0165 - val_mae: 0.1045\n",
      "Epoch 14/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 0.0122 - mae: 0.0832 - val_loss: 0.0169 - val_mae: 0.1079\n",
      "Epoch 15/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 0.0121 - mae: 0.0830 - val_loss: 0.0175 - val_mae: 0.1103\n",
      "Epoch 16/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - loss: 0.0121 - mae: 0.0831 - val_loss: 0.0175 - val_mae: 0.1099\n",
      "Epoch 17/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - loss: 0.0121 - mae: 0.0828 - val_loss: 0.0201 - val_mae: 0.1190\n",
      "Epoch 18/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - loss: 0.0120 - mae: 0.0827 - val_loss: 0.0167 - val_mae: 0.1067\n",
      "Epoch 19/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - loss: 0.0120 - mae: 0.0824 - val_loss: 0.0167 - val_mae: 0.1057\n",
      "Epoch 20/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 0.0120 - mae: 0.0828 - val_loss: 0.0209 - val_mae: 0.1221\n",
      "Epoch 21/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 0.0119 - mae: 0.0824 - val_loss: 0.0177 - val_mae: 0.1106\n",
      "Epoch 22/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 0.0120 - mae: 0.0829 - val_loss: 0.0169 - val_mae: 0.1068\n",
      "Epoch 23/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - loss: 0.0119 - mae: 0.0827 - val_loss: 0.0168 - val_mae: 0.1061\n",
      "Epoch 24/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - loss: 0.0119 - mae: 0.0828 - val_loss: 0.0173 - val_mae: 0.1087\n",
      "Epoch 25/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - loss: 0.0119 - mae: 0.0825 - val_loss: 0.0166 - val_mae: 0.1045\n",
      "Epoch 26/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 0.0119 - mae: 0.0826 - val_loss: 0.0163 - val_mae: 0.1025\n",
      "Epoch 27/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 0.0119 - mae: 0.0830 - val_loss: 0.0164 - val_mae: 0.1043\n",
      "Epoch 28/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 0.0119 - mae: 0.0826 - val_loss: 0.0161 - val_mae: 0.1008\n",
      "Epoch 29/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - loss: 0.0119 - mae: 0.0825 - val_loss: 0.0168 - val_mae: 0.1058\n",
      "Epoch 30/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - loss: 0.0119 - mae: 0.0828 - val_loss: 0.0163 - val_mae: 0.1027\n",
      "Epoch 31/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - loss: 0.0118 - mae: 0.0827 - val_loss: 0.0161 - val_mae: 0.1010\n",
      "Epoch 32/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - loss: 0.0118 - mae: 0.0825 - val_loss: 0.0166 - val_mae: 0.1054\n",
      "Epoch 33/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - loss: 0.0119 - mae: 0.0829 - val_loss: 0.0171 - val_mae: 0.1086\n",
      "Epoch 34/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - loss: 0.0119 - mae: 0.0828 - val_loss: 0.0208 - val_mae: 0.1237\n",
      "Epoch 35/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - loss: 0.0118 - mae: 0.0824 - val_loss: 0.0174 - val_mae: 0.1086\n",
      "Epoch 36/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 0.0118 - mae: 0.0827 - val_loss: 0.0171 - val_mae: 0.1089\n",
      "Epoch 37/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - loss: 0.0119 - mae: 0.0827 - val_loss: 0.0162 - val_mae: 0.1024\n",
      "Epoch 38/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - loss: 0.0118 - mae: 0.0827 - val_loss: 0.0167 - val_mae: 0.1062\n",
      "Epoch 39/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - loss: 0.0118 - mae: 0.0827 - val_loss: 0.0162 - val_mae: 0.1021\n",
      "Epoch 40/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - loss: 0.0119 - mae: 0.0829 - val_loss: 0.0172 - val_mae: 0.1088\n",
      "Epoch 41/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - loss: 0.0118 - mae: 0.0828 - val_loss: 0.0159 - val_mae: 0.0985\n",
      "Epoch 42/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - loss: 0.0118 - mae: 0.0826 - val_loss: 0.0159 - val_mae: 0.0991\n",
      "Epoch 43/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - loss: 0.0118 - mae: 0.0826 - val_loss: 0.0160 - val_mae: 0.1010\n",
      "Epoch 44/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - loss: 0.0118 - mae: 0.0828 - val_loss: 0.0167 - val_mae: 0.1059\n",
      "Epoch 45/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - loss: 0.0118 - mae: 0.0826 - val_loss: 0.0163 - val_mae: 0.1039\n",
      "Epoch 46/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 0.0118 - mae: 0.0826 - val_loss: 0.0163 - val_mae: 0.1026\n",
      "Epoch 47/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - loss: 0.0117 - mae: 0.0823 - val_loss: 0.0161 - val_mae: 0.1009\n",
      "Epoch 48/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 0.0118 - mae: 0.0826 - val_loss: 0.0178 - val_mae: 0.1119\n",
      "Epoch 49/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - loss: 0.0118 - mae: 0.0826 - val_loss: 0.0162 - val_mae: 0.1032\n",
      "Epoch 50/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 0.0118 - mae: 0.0824 - val_loss: 0.0160 - val_mae: 0.1004\n",
      "Epoch 51/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - loss: 0.0118 - mae: 0.0824 - val_loss: 0.0166 - val_mae: 0.1052\n",
      "Epoch 52/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 0.0118 - mae: 0.0826 - val_loss: 0.0171 - val_mae: 0.1082\n",
      "Epoch 53/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - loss: 0.0117 - mae: 0.0824 - val_loss: 0.0164 - val_mae: 0.1043\n",
      "Epoch 54/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - loss: 0.0118 - mae: 0.0825 - val_loss: 0.0161 - val_mae: 0.1011\n",
      "Epoch 55/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - loss: 0.0117 - mae: 0.0824 - val_loss: 0.0161 - val_mae: 0.1009\n",
      "Epoch 56/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - loss: 0.0117 - mae: 0.0823 - val_loss: 0.0166 - val_mae: 0.1056\n",
      "Epoch 57/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 0.0118 - mae: 0.0826 - val_loss: 0.0165 - val_mae: 0.1044\n",
      "Epoch 58/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - loss: 0.0118 - mae: 0.0824 - val_loss: 0.0167 - val_mae: 0.1057\n",
      "Epoch 59/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - loss: 0.0118 - mae: 0.0825 - val_loss: 0.0166 - val_mae: 0.1047\n",
      "Epoch 60/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - loss: 0.0118 - mae: 0.0824 - val_loss: 0.0162 - val_mae: 0.1018\n",
      "Epoch 61/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - loss: 0.0118 - mae: 0.0824 - val_loss: 0.0178 - val_mae: 0.1100\n",
      "Epoch 62/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - loss: 0.0118 - mae: 0.0823 - val_loss: 0.0165 - val_mae: 0.1041\n",
      "Epoch 63/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - loss: 0.0117 - mae: 0.0824 - val_loss: 0.0163 - val_mae: 0.1027\n",
      "Epoch 64/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - loss: 0.0117 - mae: 0.0823 - val_loss: 0.0163 - val_mae: 0.1022\n",
      "Epoch 65/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 0.0118 - mae: 0.0825 - val_loss: 0.0165 - val_mae: 0.1039\n",
      "Epoch 66/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - loss: 0.0117 - mae: 0.0824 - val_loss: 0.0164 - val_mae: 0.1040\n",
      "Epoch 67/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 0.0117 - mae: 0.0823 - val_loss: 0.0162 - val_mae: 0.1016\n",
      "Epoch 68/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - loss: 0.0117 - mae: 0.0822 - val_loss: 0.0163 - val_mae: 0.1031\n",
      "Epoch 69/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - loss: 0.0117 - mae: 0.0823 - val_loss: 0.0165 - val_mae: 0.1037\n",
      "Epoch 70/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.0117 - mae: 0.0823 - val_loss: 0.0168 - val_mae: 0.1061\n",
      "Epoch 71/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 0.0117 - mae: 0.0822 - val_loss: 0.0165 - val_mae: 0.1041\n",
      "Epoch 72/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 0.0117 - mae: 0.0825 - val_loss: 0.0164 - val_mae: 0.1028\n",
      "Epoch 73/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 0.0117 - mae: 0.0822 - val_loss: 0.0171 - val_mae: 0.1077\n",
      "Epoch 74/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 0.0117 - mae: 0.0822 - val_loss: 0.0170 - val_mae: 0.1085\n",
      "Epoch 75/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 0.0117 - mae: 0.0823 - val_loss: 0.0165 - val_mae: 0.1042\n",
      "Epoch 76/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 0.0117 - mae: 0.0823 - val_loss: 0.0163 - val_mae: 0.1037\n",
      "Epoch 77/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - loss: 0.0117 - mae: 0.0823 - val_loss: 0.0166 - val_mae: 0.1054\n",
      "Epoch 78/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - loss: 0.0117 - mae: 0.0822 - val_loss: 0.0164 - val_mae: 0.1032\n",
      "Epoch 79/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - loss: 0.0117 - mae: 0.0822 - val_loss: 0.0168 - val_mae: 0.1066\n",
      "Epoch 80/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - loss: 0.0118 - mae: 0.0825 - val_loss: 0.0166 - val_mae: 0.1045\n",
      "Epoch 81/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 0.0117 - mae: 0.0824 - val_loss: 0.0169 - val_mae: 0.1068\n",
      "Epoch 82/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 0.0117 - mae: 0.0822 - val_loss: 0.0165 - val_mae: 0.1044\n",
      "Epoch 83/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - loss: 0.0117 - mae: 0.0821 - val_loss: 0.0165 - val_mae: 0.1037\n",
      "Epoch 84/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - loss: 0.0117 - mae: 0.0824 - val_loss: 0.0167 - val_mae: 0.1060\n",
      "Epoch 85/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 0.0117 - mae: 0.0823 - val_loss: 0.0165 - val_mae: 0.1036\n",
      "Epoch 86/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - loss: 0.0117 - mae: 0.0822 - val_loss: 0.0171 - val_mae: 0.1074\n",
      "Epoch 87/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - loss: 0.0117 - mae: 0.0821 - val_loss: 0.0164 - val_mae: 0.1032\n",
      "Epoch 88/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 0.0117 - mae: 0.0823 - val_loss: 0.0168 - val_mae: 0.1068\n",
      "Epoch 89/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - loss: 0.0117 - mae: 0.0822 - val_loss: 0.0167 - val_mae: 0.1057\n",
      "Epoch 90/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - loss: 0.0117 - mae: 0.0822 - val_loss: 0.0164 - val_mae: 0.1032\n",
      "Epoch 91/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - loss: 0.0117 - mae: 0.0822 - val_loss: 0.0165 - val_mae: 0.1038\n",
      "Epoch 92/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - loss: 0.0117 - mae: 0.0823 - val_loss: 0.0167 - val_mae: 0.1055\n",
      "Epoch 93/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - loss: 0.0117 - mae: 0.0821 - val_loss: 0.0170 - val_mae: 0.1072\n",
      "Epoch 94/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - loss: 0.0117 - mae: 0.0821 - val_loss: 0.0162 - val_mae: 0.1012\n",
      "Epoch 95/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - loss: 0.0117 - mae: 0.0822 - val_loss: 0.0166 - val_mae: 0.1053\n",
      "Epoch 96/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - loss: 0.0117 - mae: 0.0823 - val_loss: 0.0163 - val_mae: 0.1025\n",
      "Epoch 97/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 0.0117 - mae: 0.0822 - val_loss: 0.0164 - val_mae: 0.1037\n",
      "Epoch 98/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 0.0117 - mae: 0.0821 - val_loss: 0.0175 - val_mae: 0.1091\n",
      "Epoch 99/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - loss: 0.0116 - mae: 0.0821 - val_loss: 0.0197 - val_mae: 0.1148\n",
      "Epoch 100/100\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - loss: 0.0117 - mae: 0.0821 - val_loss: 0.0165 - val_mae: 0.1041\n",
      "\u001b[1m497/497\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step\n",
      "✅ Done with wheat_Haveri_daily.csv | MAE=215.14, RMSE=275.67, R2=0.5587, MAPE=12.16%, Accuracy=87.84%\n",
      "Saved updated CSV with Date, Actual & Predicted: tat_mqa_output_csv\\wheat_Haveri_daily_tat_mqa_updated.csv\n",
      "🚀 Processing: wheat_Kalburgi_daily.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_35\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_35\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_query_attention_13      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">17,216</span> │ input_layer_35[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiQueryAttention</span>)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_70 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_query_attention_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                               │                           │                 │ input_layer_35[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_70        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_70[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_203 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ layer_normalization_70[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_204 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dense_203[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_71 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_70[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                               │                           │                 │ dense_204[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_71        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_71[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_35   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_71[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_205 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ global_average_pooling1d_… │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_35 (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_query_attention_13      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │          \u001b[38;5;34m17,216\u001b[0m │ input_layer_35[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mMultiQueryAttention\u001b[0m)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_70 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ multi_query_attention_13[\u001b[38;5;34m…\u001b[0m │\n",
       "│                               │                           │                 │ input_layer_35[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_70        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ add_70[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_203 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │           \u001b[38;5;34m8,320\u001b[0m │ layer_normalization_70[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_204 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │             \u001b[38;5;34m129\u001b[0m │ dense_203[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_71 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_70[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                               │                           │                 │ dense_204[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_71        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ add_71[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_35   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_71[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_205 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │              \u001b[38;5;34m65\u001b[0m │ global_average_pooling1d_… │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,986</span> (101.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25,986\u001b[0m (101.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,986</span> (101.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m25,986\u001b[0m (101.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 17ms/step - loss: 0.0398 - mae: 0.1405 - val_loss: 0.0153 - val_mae: 0.0992\n",
      "Epoch 2/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0180 - mae: 0.1119 - val_loss: 0.0146 - val_mae: 0.0895\n",
      "Epoch 3/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - loss: 0.0172 - mae: 0.1100 - val_loss: 0.0149 - val_mae: 0.0952\n",
      "Epoch 4/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - loss: 0.0168 - mae: 0.1087 - val_loss: 0.0148 - val_mae: 0.0883\n",
      "Epoch 5/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - loss: 0.0164 - mae: 0.1078 - val_loss: 0.0140 - val_mae: 0.0876\n",
      "Epoch 6/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0166 - mae: 0.1086 - val_loss: 0.0211 - val_mae: 0.1099\n",
      "Epoch 7/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0162 - mae: 0.1080 - val_loss: 0.0140 - val_mae: 0.0898\n",
      "Epoch 8/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - loss: 0.0160 - mae: 0.1070 - val_loss: 0.0152 - val_mae: 0.0855\n",
      "Epoch 9/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - loss: 0.0160 - mae: 0.1078 - val_loss: 0.0141 - val_mae: 0.0936\n",
      "Epoch 10/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - loss: 0.0161 - mae: 0.1078 - val_loss: 0.0140 - val_mae: 0.0837\n",
      "Epoch 11/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - loss: 0.0160 - mae: 0.1076 - val_loss: 0.0132 - val_mae: 0.0840\n",
      "Epoch 12/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - loss: 0.0158 - mae: 0.1073 - val_loss: 0.0156 - val_mae: 0.0881\n",
      "Epoch 13/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - loss: 0.0158 - mae: 0.1071 - val_loss: 0.0132 - val_mae: 0.0879\n",
      "Epoch 14/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - loss: 0.0156 - mae: 0.1067 - val_loss: 0.0156 - val_mae: 0.1070\n",
      "Epoch 15/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - loss: 0.0156 - mae: 0.1071 - val_loss: 0.0127 - val_mae: 0.0835\n",
      "Epoch 16/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - loss: 0.0156 - mae: 0.1071 - val_loss: 0.0125 - val_mae: 0.0781\n",
      "Epoch 17/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - loss: 0.0154 - mae: 0.1063 - val_loss: 0.0123 - val_mae: 0.0778\n",
      "Epoch 18/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - loss: 0.0155 - mae: 0.1068 - val_loss: 0.0120 - val_mae: 0.0752\n",
      "Epoch 19/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - loss: 0.0156 - mae: 0.1073 - val_loss: 0.0122 - val_mae: 0.0743\n",
      "Epoch 20/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - loss: 0.0153 - mae: 0.1062 - val_loss: 0.0122 - val_mae: 0.0833\n",
      "Epoch 21/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - loss: 0.0154 - mae: 0.1064 - val_loss: 0.0117 - val_mae: 0.0716\n",
      "Epoch 22/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - loss: 0.0153 - mae: 0.1062 - val_loss: 0.0115 - val_mae: 0.0686\n",
      "Epoch 23/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - loss: 0.0153 - mae: 0.1064 - val_loss: 0.0123 - val_mae: 0.0841\n",
      "Epoch 24/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - loss: 0.0152 - mae: 0.1063 - val_loss: 0.0121 - val_mae: 0.0821\n",
      "Epoch 25/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - loss: 0.0154 - mae: 0.1067 - val_loss: 0.0117 - val_mae: 0.0757\n",
      "Epoch 26/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - loss: 0.0152 - mae: 0.1061 - val_loss: 0.0119 - val_mae: 0.0794\n",
      "Epoch 27/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - loss: 0.0153 - mae: 0.1063 - val_loss: 0.0116 - val_mae: 0.0706\n",
      "Epoch 28/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - loss: 0.0153 - mae: 0.1067 - val_loss: 0.0116 - val_mae: 0.0700\n",
      "Epoch 29/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - loss: 0.0153 - mae: 0.1065 - val_loss: 0.0115 - val_mae: 0.0722\n",
      "Epoch 30/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - loss: 0.0153 - mae: 0.1066 - val_loss: 0.0116 - val_mae: 0.0717\n",
      "Epoch 31/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - loss: 0.0153 - mae: 0.1063 - val_loss: 0.0120 - val_mae: 0.0801\n",
      "Epoch 32/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - loss: 0.0152 - mae: 0.1059 - val_loss: 0.0119 - val_mae: 0.0782\n",
      "Epoch 33/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - loss: 0.0153 - mae: 0.1061 - val_loss: 0.0123 - val_mae: 0.0808\n",
      "Epoch 34/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - loss: 0.0153 - mae: 0.1061 - val_loss: 0.0128 - val_mae: 0.0877\n",
      "Epoch 35/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - loss: 0.0152 - mae: 0.1063 - val_loss: 0.0122 - val_mae: 0.0722\n",
      "Epoch 36/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - loss: 0.0152 - mae: 0.1062 - val_loss: 0.0135 - val_mae: 0.0916\n",
      "Epoch 37/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - loss: 0.0152 - mae: 0.1062 - val_loss: 0.0128 - val_mae: 0.0865\n",
      "Epoch 38/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - loss: 0.0152 - mae: 0.1062 - val_loss: 0.0130 - val_mae: 0.0865\n",
      "Epoch 39/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - loss: 0.0153 - mae: 0.1062 - val_loss: 0.0182 - val_mae: 0.1136\n",
      "Epoch 40/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - loss: 0.0152 - mae: 0.1062 - val_loss: 0.0125 - val_mae: 0.0710\n",
      "Epoch 41/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - loss: 0.0152 - mae: 0.1061 - val_loss: 0.0132 - val_mae: 0.0762\n",
      "Epoch 42/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - loss: 0.0152 - mae: 0.1062 - val_loss: 0.0151 - val_mae: 0.0963\n",
      "Epoch 43/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - loss: 0.0152 - mae: 0.1059 - val_loss: 0.0151 - val_mae: 0.0991\n",
      "Epoch 44/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - loss: 0.0152 - mae: 0.1061 - val_loss: 0.0131 - val_mae: 0.0768\n",
      "Epoch 45/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - loss: 0.0152 - mae: 0.1061 - val_loss: 0.0143 - val_mae: 0.0920\n",
      "Epoch 46/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - loss: 0.0152 - mae: 0.1061 - val_loss: 0.0130 - val_mae: 0.0702\n",
      "Epoch 47/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - loss: 0.0152 - mae: 0.1063 - val_loss: 0.0143 - val_mae: 0.0892\n",
      "Epoch 48/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0151 - mae: 0.1058 - val_loss: 0.0135 - val_mae: 0.0751\n",
      "Epoch 49/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - loss: 0.0152 - mae: 0.1060 - val_loss: 0.0145 - val_mae: 0.0871\n",
      "Epoch 50/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0151 - mae: 0.1057 - val_loss: 0.0168 - val_mae: 0.1038\n",
      "Epoch 51/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - loss: 0.0152 - mae: 0.1061 - val_loss: 0.0146 - val_mae: 0.0764\n",
      "Epoch 52/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 0.0152 - mae: 0.1061 - val_loss: 0.0145 - val_mae: 0.0749\n",
      "Epoch 53/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 0.0152 - mae: 0.1058 - val_loss: 0.0154 - val_mae: 0.0789\n",
      "Epoch 54/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0152 - mae: 0.1062 - val_loss: 0.0167 - val_mae: 0.0908\n",
      "Epoch 55/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 0.0151 - mae: 0.1059 - val_loss: 0.0168 - val_mae: 0.0855\n",
      "Epoch 56/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 0.0152 - mae: 0.1062 - val_loss: 0.0175 - val_mae: 0.0891\n",
      "Epoch 57/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - loss: 0.0152 - mae: 0.1059 - val_loss: 0.0181 - val_mae: 0.0926\n",
      "Epoch 58/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - loss: 0.0151 - mae: 0.1058 - val_loss: 0.0183 - val_mae: 0.0878\n",
      "Epoch 59/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - loss: 0.0151 - mae: 0.1057 - val_loss: 0.0198 - val_mae: 0.0958\n",
      "Epoch 60/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0151 - mae: 0.1058 - val_loss: 0.0215 - val_mae: 0.1008\n",
      "Epoch 61/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0151 - mae: 0.1056 - val_loss: 0.0225 - val_mae: 0.0991\n",
      "Epoch 62/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - loss: 0.0152 - mae: 0.1061 - val_loss: 0.0220 - val_mae: 0.0983\n",
      "Epoch 63/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0150 - mae: 0.1056 - val_loss: 0.0224 - val_mae: 0.1005\n",
      "Epoch 64/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0151 - mae: 0.1061 - val_loss: 0.0246 - val_mae: 0.1001\n",
      "Epoch 65/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 0.0151 - mae: 0.1059 - val_loss: 0.0225 - val_mae: 0.1046\n",
      "Epoch 66/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - loss: 0.0151 - mae: 0.1058 - val_loss: 0.0243 - val_mae: 0.0979\n",
      "Epoch 67/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0151 - mae: 0.1057 - val_loss: 0.0259 - val_mae: 0.1047\n",
      "Epoch 68/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - loss: 0.0151 - mae: 0.1060 - val_loss: 0.0260 - val_mae: 0.1044\n",
      "Epoch 69/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - loss: 0.0151 - mae: 0.1058 - val_loss: 0.0220 - val_mae: 0.0882\n",
      "Epoch 70/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0151 - mae: 0.1057 - val_loss: 0.0262 - val_mae: 0.1100\n",
      "Epoch 71/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 0.0151 - mae: 0.1058 - val_loss: 0.0243 - val_mae: 0.0988\n",
      "Epoch 72/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - loss: 0.0151 - mae: 0.1059 - val_loss: 0.0271 - val_mae: 0.1118\n",
      "Epoch 73/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 0.0151 - mae: 0.1056 - val_loss: 0.0273 - val_mae: 0.1120\n",
      "Epoch 74/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - loss: 0.0151 - mae: 0.1058 - val_loss: 0.0243 - val_mae: 0.1028\n",
      "Epoch 75/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - loss: 0.0151 - mae: 0.1058 - val_loss: 0.0229 - val_mae: 0.1032\n",
      "Epoch 76/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0151 - mae: 0.1059 - val_loss: 0.0240 - val_mae: 0.0951\n",
      "Epoch 77/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - loss: 0.0151 - mae: 0.1057 - val_loss: 0.0243 - val_mae: 0.1017\n",
      "Epoch 78/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0150 - mae: 0.1058 - val_loss: 0.0266 - val_mae: 0.1069\n",
      "Epoch 79/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0151 - mae: 0.1057 - val_loss: 0.0243 - val_mae: 0.0986\n",
      "Epoch 80/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 0.0151 - mae: 0.1059 - val_loss: 0.0261 - val_mae: 0.1042\n",
      "Epoch 81/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - loss: 0.0150 - mae: 0.1057 - val_loss: 0.0265 - val_mae: 0.0973\n",
      "Epoch 82/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - loss: 0.0151 - mae: 0.1059 - val_loss: 0.0257 - val_mae: 0.0966\n",
      "Epoch 83/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - loss: 0.0152 - mae: 0.1059 - val_loss: 0.0264 - val_mae: 0.0985\n",
      "Epoch 84/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - loss: 0.0151 - mae: 0.1056 - val_loss: 0.0238 - val_mae: 0.0993\n",
      "Epoch 85/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - loss: 0.0151 - mae: 0.1058 - val_loss: 0.0262 - val_mae: 0.1007\n",
      "Epoch 86/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - loss: 0.0150 - mae: 0.1054 - val_loss: 0.0261 - val_mae: 0.1076\n",
      "Epoch 87/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - loss: 0.0151 - mae: 0.1061 - val_loss: 0.0252 - val_mae: 0.1056\n",
      "Epoch 88/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - loss: 0.0150 - mae: 0.1055 - val_loss: 0.0286 - val_mae: 0.1033\n",
      "Epoch 89/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - loss: 0.0150 - mae: 0.1054 - val_loss: 0.0275 - val_mae: 0.1007\n",
      "Epoch 90/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - loss: 0.0151 - mae: 0.1055 - val_loss: 0.0242 - val_mae: 0.1039\n",
      "Epoch 91/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - loss: 0.0151 - mae: 0.1057 - val_loss: 0.0285 - val_mae: 0.1082\n",
      "Epoch 92/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - loss: 0.0151 - mae: 0.1058 - val_loss: 0.0252 - val_mae: 0.1008\n",
      "Epoch 93/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - loss: 0.0150 - mae: 0.1056 - val_loss: 0.0265 - val_mae: 0.0994\n",
      "Epoch 94/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - loss: 0.0151 - mae: 0.1057 - val_loss: 0.0267 - val_mae: 0.1020\n",
      "Epoch 95/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - loss: 0.0150 - mae: 0.1056 - val_loss: 0.0268 - val_mae: 0.1014\n",
      "Epoch 96/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - loss: 0.0152 - mae: 0.1059 - val_loss: 0.0250 - val_mae: 0.1025\n",
      "Epoch 97/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - loss: 0.0151 - mae: 0.1056 - val_loss: 0.0265 - val_mae: 0.1101\n",
      "Epoch 98/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - loss: 0.0151 - mae: 0.1057 - val_loss: 0.0260 - val_mae: 0.0989\n",
      "Epoch 99/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - loss: 0.0151 - mae: 0.1057 - val_loss: 0.0247 - val_mae: 0.0964\n",
      "Epoch 100/100\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - loss: 0.0150 - mae: 0.1055 - val_loss: 0.0282 - val_mae: 0.1066\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step\n",
      "✅ Done with wheat_Kalburgi_daily.csv | MAE=382.09, RMSE=486.18, R2=0.2918, MAPE=18.55%, Accuracy=81.45%\n",
      "Saved updated CSV with Date, Actual & Predicted: tat_mqa_output_csv\\wheat_Kalburgi_daily_tat_mqa_updated.csv\n",
      "🚀 Processing: wheat_Kolar_daily.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_36\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_36\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_query_attention_14      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">17,216</span> │ input_layer_36[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiQueryAttention</span>)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_72 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_query_attention_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                               │                           │                 │ input_layer_36[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_72        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_72[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_213 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ layer_normalization_72[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_214 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dense_213[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_73 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_72[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                               │                           │                 │ dense_214[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_73        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_73[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_36   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_73[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_215 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ global_average_pooling1d_… │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_36 (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_query_attention_14      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │          \u001b[38;5;34m17,216\u001b[0m │ input_layer_36[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mMultiQueryAttention\u001b[0m)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_72 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ multi_query_attention_14[\u001b[38;5;34m…\u001b[0m │\n",
       "│                               │                           │                 │ input_layer_36[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_72        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ add_72[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_213 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │           \u001b[38;5;34m8,320\u001b[0m │ layer_normalization_72[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_214 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │             \u001b[38;5;34m129\u001b[0m │ dense_213[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_73 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_72[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                               │                           │                 │ dense_214[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_73        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ add_73[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_36   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_73[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_215 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │              \u001b[38;5;34m65\u001b[0m │ global_average_pooling1d_… │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,986</span> (101.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25,986\u001b[0m (101.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,986</span> (101.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m25,986\u001b[0m (101.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17ms/step - loss: 0.0396 - mae: 0.1205 - val_loss: 0.0292 - val_mae: 0.1649\n",
      "Epoch 2/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 0.0096 - mae: 0.0797 - val_loss: 0.0394 - val_mae: 0.1802\n",
      "Epoch 3/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - loss: 0.0084 - mae: 0.0750 - val_loss: 0.0456 - val_mae: 0.1854\n",
      "Epoch 4/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - loss: 0.0075 - mae: 0.0714 - val_loss: 0.0407 - val_mae: 0.1802\n",
      "Epoch 5/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - loss: 0.0070 - mae: 0.0696 - val_loss: 0.0356 - val_mae: 0.1732\n",
      "Epoch 6/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 0.0066 - mae: 0.0682 - val_loss: 0.0430 - val_mae: 0.1802\n",
      "Epoch 7/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 0.0065 - mae: 0.0668 - val_loss: 0.0283 - val_mae: 0.1613\n",
      "Epoch 8/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.0062 - mae: 0.0655 - val_loss: 0.0302 - val_mae: 0.1637\n",
      "Epoch 9/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 0.0060 - mae: 0.0647 - val_loss: 0.0303 - val_mae: 0.1630\n",
      "Epoch 10/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.0060 - mae: 0.0644 - val_loss: 0.0249 - val_mae: 0.1520\n",
      "Epoch 11/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - loss: 0.0061 - mae: 0.0643 - val_loss: 0.0229 - val_mae: 0.1452\n",
      "Epoch 12/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - loss: 0.0059 - mae: 0.0631 - val_loss: 0.0229 - val_mae: 0.1453\n",
      "Epoch 13/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - loss: 0.0057 - mae: 0.0622 - val_loss: 0.0224 - val_mae: 0.1432\n",
      "Epoch 14/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 0.0056 - mae: 0.0614 - val_loss: 0.0225 - val_mae: 0.1431\n",
      "Epoch 15/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - loss: 0.0056 - mae: 0.0610 - val_loss: 0.0216 - val_mae: 0.1390\n",
      "Epoch 16/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - loss: 0.0055 - mae: 0.0606 - val_loss: 0.0207 - val_mae: 0.1334\n",
      "Epoch 17/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 0.0054 - mae: 0.0600 - val_loss: 0.0205 - val_mae: 0.1262\n",
      "Epoch 18/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 0.0053 - mae: 0.0595 - val_loss: 0.0203 - val_mae: 0.1301\n",
      "Epoch 19/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 0.0056 - mae: 0.0609 - val_loss: 0.0202 - val_mae: 0.1282\n",
      "Epoch 20/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 0.0054 - mae: 0.0597 - val_loss: 0.0202 - val_mae: 0.1241\n",
      "Epoch 21/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.0054 - mae: 0.0596 - val_loss: 0.0208 - val_mae: 0.1259\n",
      "Epoch 22/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.0053 - mae: 0.0590 - val_loss: 0.0203 - val_mae: 0.1259\n",
      "Epoch 23/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - loss: 0.0053 - mae: 0.0588 - val_loss: 0.0203 - val_mae: 0.1302\n",
      "Epoch 24/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 0.0053 - mae: 0.0590 - val_loss: 0.0225 - val_mae: 0.1327\n",
      "Epoch 25/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 0.0053 - mae: 0.0589 - val_loss: 0.0201 - val_mae: 0.1250\n",
      "Epoch 26/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 0.0052 - mae: 0.0585 - val_loss: 0.0212 - val_mae: 0.1336\n",
      "Epoch 27/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0052 - mae: 0.0583 - val_loss: 0.0203 - val_mae: 0.1278\n",
      "Epoch 28/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.0052 - mae: 0.0584 - val_loss: 0.0227 - val_mae: 0.1328\n",
      "Epoch 29/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - loss: 0.0052 - mae: 0.0582 - val_loss: 0.0200 - val_mae: 0.1257\n",
      "Epoch 30/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - loss: 0.0052 - mae: 0.0583 - val_loss: 0.0211 - val_mae: 0.1288\n",
      "Epoch 31/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.0052 - mae: 0.0582 - val_loss: 0.0215 - val_mae: 0.1302\n",
      "Epoch 32/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - loss: 0.0052 - mae: 0.0579 - val_loss: 0.0206 - val_mae: 0.1293\n",
      "Epoch 33/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 0.0052 - mae: 0.0582 - val_loss: 0.0203 - val_mae: 0.1265\n",
      "Epoch 34/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.0052 - mae: 0.0582 - val_loss: 0.0223 - val_mae: 0.1330\n",
      "Epoch 35/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.0051 - mae: 0.0576 - val_loss: 0.0200 - val_mae: 0.1270\n",
      "Epoch 36/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - loss: 0.0051 - mae: 0.0577 - val_loss: 0.0202 - val_mae: 0.1252\n",
      "Epoch 37/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - loss: 0.0051 - mae: 0.0577 - val_loss: 0.0208 - val_mae: 0.1286\n",
      "Epoch 38/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.0051 - mae: 0.0576 - val_loss: 0.0206 - val_mae: 0.1268\n",
      "Epoch 39/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 0.0052 - mae: 0.0577 - val_loss: 0.0205 - val_mae: 0.1261\n",
      "Epoch 40/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 0.0051 - mae: 0.0574 - val_loss: 0.0213 - val_mae: 0.1277\n",
      "Epoch 41/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - loss: 0.0052 - mae: 0.0581 - val_loss: 0.0204 - val_mae: 0.1290\n",
      "Epoch 42/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - loss: 0.0052 - mae: 0.0579 - val_loss: 0.0205 - val_mae: 0.1248\n",
      "Epoch 43/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - loss: 0.0051 - mae: 0.0574 - val_loss: 0.0202 - val_mae: 0.1286\n",
      "Epoch 44/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - loss: 0.0051 - mae: 0.0577 - val_loss: 0.0215 - val_mae: 0.1277\n",
      "Epoch 45/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 0.0052 - mae: 0.0585 - val_loss: 0.0209 - val_mae: 0.1260\n",
      "Epoch 46/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 0.0051 - mae: 0.0575 - val_loss: 0.0209 - val_mae: 0.1257\n",
      "Epoch 47/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0052 - mae: 0.0577 - val_loss: 0.0221 - val_mae: 0.1292\n",
      "Epoch 48/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 0.0051 - mae: 0.0575 - val_loss: 0.0209 - val_mae: 0.1342\n",
      "Epoch 49/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 0.0051 - mae: 0.0571 - val_loss: 0.0236 - val_mae: 0.1307\n",
      "Epoch 50/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.0051 - mae: 0.0576 - val_loss: 0.0208 - val_mae: 0.1245\n",
      "Epoch 51/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0051 - mae: 0.0572 - val_loss: 0.0220 - val_mae: 0.1281\n",
      "Epoch 52/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 0.0051 - mae: 0.0575 - val_loss: 0.0209 - val_mae: 0.1345\n",
      "Epoch 53/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - loss: 0.0051 - mae: 0.0571 - val_loss: 0.0236 - val_mae: 0.1309\n",
      "Epoch 54/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.0051 - mae: 0.0576 - val_loss: 0.0208 - val_mae: 0.1253\n",
      "Epoch 55/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - loss: 0.0052 - mae: 0.0581 - val_loss: 0.0215 - val_mae: 0.1256\n",
      "Epoch 56/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.0051 - mae: 0.0574 - val_loss: 0.0228 - val_mae: 0.1307\n",
      "Epoch 57/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - loss: 0.0051 - mae: 0.0570 - val_loss: 0.0214 - val_mae: 0.1259\n",
      "Epoch 58/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - loss: 0.0051 - mae: 0.0570 - val_loss: 0.0205 - val_mae: 0.1313\n",
      "Epoch 59/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - loss: 0.0051 - mae: 0.0574 - val_loss: 0.0208 - val_mae: 0.1252\n",
      "Epoch 60/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - loss: 0.0051 - mae: 0.0576 - val_loss: 0.0206 - val_mae: 0.1291\n",
      "Epoch 61/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - loss: 0.0051 - mae: 0.0573 - val_loss: 0.0207 - val_mae: 0.1266\n",
      "Epoch 62/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 0.0051 - mae: 0.0572 - val_loss: 0.0209 - val_mae: 0.1279\n",
      "Epoch 63/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.0051 - mae: 0.0577 - val_loss: 0.0206 - val_mae: 0.1277\n",
      "Epoch 64/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.0052 - mae: 0.0578 - val_loss: 0.0206 - val_mae: 0.1277\n",
      "Epoch 65/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 0.0051 - mae: 0.0573 - val_loss: 0.0223 - val_mae: 0.1423\n",
      "Epoch 66/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - loss: 0.0052 - mae: 0.0576 - val_loss: 0.0210 - val_mae: 0.1292\n",
      "Epoch 67/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - loss: 0.0051 - mae: 0.0571 - val_loss: 0.0210 - val_mae: 0.1354\n",
      "Epoch 68/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - loss: 0.0051 - mae: 0.0574 - val_loss: 0.0211 - val_mae: 0.1359\n",
      "Epoch 69/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.0051 - mae: 0.0575 - val_loss: 0.0209 - val_mae: 0.1283\n",
      "Epoch 70/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - loss: 0.0050 - mae: 0.0567 - val_loss: 0.0209 - val_mae: 0.1265\n",
      "Epoch 71/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.0050 - mae: 0.0568 - val_loss: 0.0204 - val_mae: 0.1245\n",
      "Epoch 72/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 0.0050 - mae: 0.0568 - val_loss: 0.0218 - val_mae: 0.1398\n",
      "Epoch 73/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.0051 - mae: 0.0573 - val_loss: 0.0209 - val_mae: 0.1345\n",
      "Epoch 74/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 0.0051 - mae: 0.0567 - val_loss: 0.0204 - val_mae: 0.1303\n",
      "Epoch 75/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - loss: 0.0051 - mae: 0.0570 - val_loss: 0.0207 - val_mae: 0.1322\n",
      "Epoch 76/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 0.0050 - mae: 0.0570 - val_loss: 0.0203 - val_mae: 0.1289\n",
      "Epoch 77/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0051 - mae: 0.0575 - val_loss: 0.0214 - val_mae: 0.1370\n",
      "Epoch 78/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 0.0050 - mae: 0.0566 - val_loss: 0.0207 - val_mae: 0.1284\n",
      "Epoch 79/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.0051 - mae: 0.0571 - val_loss: 0.0204 - val_mae: 0.1278\n",
      "Epoch 80/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 0.0050 - mae: 0.0563 - val_loss: 0.0206 - val_mae: 0.1254\n",
      "Epoch 81/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.0050 - mae: 0.0568 - val_loss: 0.0206 - val_mae: 0.1246\n",
      "Epoch 82/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.0051 - mae: 0.0572 - val_loss: 0.0208 - val_mae: 0.1268\n",
      "Epoch 83/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.0050 - mae: 0.0564 - val_loss: 0.0209 - val_mae: 0.1351\n",
      "Epoch 84/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.0050 - mae: 0.0567 - val_loss: 0.0210 - val_mae: 0.1350\n",
      "Epoch 85/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - loss: 0.0050 - mae: 0.0565 - val_loss: 0.0205 - val_mae: 0.1311\n",
      "Epoch 86/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 0.0050 - mae: 0.0566 - val_loss: 0.0204 - val_mae: 0.1282\n",
      "Epoch 87/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - loss: 0.0050 - mae: 0.0566 - val_loss: 0.0209 - val_mae: 0.1333\n",
      "Epoch 88/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0050 - mae: 0.0566 - val_loss: 0.0208 - val_mae: 0.1275\n",
      "Epoch 89/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - loss: 0.0050 - mae: 0.0566 - val_loss: 0.0212 - val_mae: 0.1369\n",
      "Epoch 90/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.0049 - mae: 0.0561 - val_loss: 0.0205 - val_mae: 0.1313\n",
      "Epoch 91/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.0050 - mae: 0.0568 - val_loss: 0.0209 - val_mae: 0.1339\n",
      "Epoch 92/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.0050 - mae: 0.0563 - val_loss: 0.0212 - val_mae: 0.1286\n",
      "Epoch 93/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0050 - mae: 0.0567 - val_loss: 0.0209 - val_mae: 0.1355\n",
      "Epoch 94/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.0049 - mae: 0.0563 - val_loss: 0.0206 - val_mae: 0.1305\n",
      "Epoch 95/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0049 - mae: 0.0564 - val_loss: 0.0210 - val_mae: 0.1353\n",
      "Epoch 96/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - loss: 0.0049 - mae: 0.0562 - val_loss: 0.0214 - val_mae: 0.1389\n",
      "Epoch 97/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.0049 - mae: 0.0563 - val_loss: 0.0204 - val_mae: 0.1287\n",
      "Epoch 98/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - loss: 0.0049 - mae: 0.0561 - val_loss: 0.0211 - val_mae: 0.1371\n",
      "Epoch 99/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.0050 - mae: 0.0566 - val_loss: 0.0209 - val_mae: 0.1317\n",
      "Epoch 100/100\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - loss: 0.0049 - mae: 0.0563 - val_loss: 0.0224 - val_mae: 0.1439\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step\n",
      "✅ Done with wheat_Kolar_daily.csv | MAE=255.43, RMSE=309.54, R2=0.681, MAPE=12.17%, Accuracy=87.83%\n",
      "Saved updated CSV with Date, Actual & Predicted: tat_mqa_output_csv\\wheat_Kolar_daily_tat_mqa_updated.csv\n",
      "🚀 Processing: wheat_Koppal_daily.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_37\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_37\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_query_attention_15      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">17,216</span> │ input_layer_37[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiQueryAttention</span>)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_74 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_query_attention_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                               │                           │                 │ input_layer_37[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_74        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_74[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_223 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ layer_normalization_74[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_224 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dense_223[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_75 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_74[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                               │                           │                 │ dense_224[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_75        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_75[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_37   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_75[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_225 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ global_average_pooling1d_… │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_37 (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_query_attention_15      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │          \u001b[38;5;34m17,216\u001b[0m │ input_layer_37[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mMultiQueryAttention\u001b[0m)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_74 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ multi_query_attention_15[\u001b[38;5;34m…\u001b[0m │\n",
       "│                               │                           │                 │ input_layer_37[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_74        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ add_74[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_223 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │           \u001b[38;5;34m8,320\u001b[0m │ layer_normalization_74[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_224 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │             \u001b[38;5;34m129\u001b[0m │ dense_223[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_75 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_74[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                               │                           │                 │ dense_224[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_75        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ add_75[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_37   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_75[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_225 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │              \u001b[38;5;34m65\u001b[0m │ global_average_pooling1d_… │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,986</span> (101.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25,986\u001b[0m (101.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,986</span> (101.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m25,986\u001b[0m (101.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 18ms/step - loss: 0.0342 - mae: 0.1301 - val_loss: 0.0237 - val_mae: 0.1026\n",
      "Epoch 2/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 0.0137 - mae: 0.0950 - val_loss: 0.0178 - val_mae: 0.0971\n",
      "Epoch 3/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - loss: 0.0117 - mae: 0.0896 - val_loss: 0.0167 - val_mae: 0.1129\n",
      "Epoch 4/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 0.0111 - mae: 0.0881 - val_loss: 0.0154 - val_mae: 0.1079\n",
      "Epoch 5/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - loss: 0.0108 - mae: 0.0876 - val_loss: 0.0189 - val_mae: 0.1005\n",
      "Epoch 6/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - loss: 0.0110 - mae: 0.0878 - val_loss: 0.0150 - val_mae: 0.1007\n",
      "Epoch 7/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - loss: 0.0105 - mae: 0.0869 - val_loss: 0.0159 - val_mae: 0.1094\n",
      "Epoch 8/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - loss: 0.0108 - mae: 0.0878 - val_loss: 0.0149 - val_mae: 0.1052\n",
      "Epoch 9/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - loss: 0.0106 - mae: 0.0870 - val_loss: 0.0153 - val_mae: 0.0988\n",
      "Epoch 10/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - loss: 0.0104 - mae: 0.0863 - val_loss: 0.0177 - val_mae: 0.1151\n",
      "Epoch 11/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - loss: 0.0105 - mae: 0.0869 - val_loss: 0.0149 - val_mae: 0.1051\n",
      "Epoch 12/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - loss: 0.0105 - mae: 0.0869 - val_loss: 0.0147 - val_mae: 0.1035\n",
      "Epoch 13/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - loss: 0.0104 - mae: 0.0864 - val_loss: 0.0162 - val_mae: 0.1108\n",
      "Epoch 14/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - loss: 0.0103 - mae: 0.0862 - val_loss: 0.0172 - val_mae: 0.1129\n",
      "Epoch 15/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 18ms/step - loss: 0.0103 - mae: 0.0860 - val_loss: 0.0147 - val_mae: 0.1031\n",
      "Epoch 16/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - loss: 0.0103 - mae: 0.0864 - val_loss: 0.0154 - val_mae: 0.1075\n",
      "Epoch 17/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 18ms/step - loss: 0.0102 - mae: 0.0862 - val_loss: 0.0157 - val_mae: 0.1088\n",
      "Epoch 18/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - loss: 0.0102 - mae: 0.0861 - val_loss: 0.0162 - val_mae: 0.1108\n",
      "Epoch 19/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 18ms/step - loss: 0.0100 - mae: 0.0855 - val_loss: 0.0154 - val_mae: 0.1079\n",
      "Epoch 20/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 18ms/step - loss: 0.0101 - mae: 0.0859 - val_loss: 0.0148 - val_mae: 0.1020\n",
      "Epoch 21/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 18ms/step - loss: 0.0101 - mae: 0.0857 - val_loss: 0.0210 - val_mae: 0.1220\n",
      "Epoch 22/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - loss: 0.0102 - mae: 0.0859 - val_loss: 0.0158 - val_mae: 0.1082\n",
      "Epoch 23/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 18ms/step - loss: 0.0101 - mae: 0.0857 - val_loss: 0.0204 - val_mae: 0.1203\n",
      "Epoch 24/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 18ms/step - loss: 0.0101 - mae: 0.0857 - val_loss: 0.0159 - val_mae: 0.1098\n",
      "Epoch 25/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 18ms/step - loss: 0.0101 - mae: 0.0858 - val_loss: 0.0169 - val_mae: 0.1124\n",
      "Epoch 26/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - loss: 0.0100 - mae: 0.0854 - val_loss: 0.0158 - val_mae: 0.1094\n",
      "Epoch 27/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - loss: 0.0100 - mae: 0.0855 - val_loss: 0.0158 - val_mae: 0.1098\n",
      "Epoch 28/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 18ms/step - loss: 0.0100 - mae: 0.0855 - val_loss: 0.0194 - val_mae: 0.1179\n",
      "Epoch 29/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - loss: 0.0101 - mae: 0.0859 - val_loss: 0.0153 - val_mae: 0.1074\n",
      "Epoch 30/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - loss: 0.0100 - mae: 0.0855 - val_loss: 0.0195 - val_mae: 0.1193\n",
      "Epoch 31/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 18ms/step - loss: 0.0100 - mae: 0.0856 - val_loss: 0.0149 - val_mae: 0.1050\n",
      "Epoch 32/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - loss: 0.0100 - mae: 0.0855 - val_loss: 0.0173 - val_mae: 0.1141\n",
      "Epoch 33/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 18ms/step - loss: 0.0099 - mae: 0.0854 - val_loss: 0.0157 - val_mae: 0.1096\n",
      "Epoch 34/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - loss: 0.0100 - mae: 0.0853 - val_loss: 0.0257 - val_mae: 0.1353\n",
      "Epoch 35/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - loss: 0.0099 - mae: 0.0854 - val_loss: 0.0162 - val_mae: 0.1112\n",
      "Epoch 36/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 0.0100 - mae: 0.0856 - val_loss: 0.0197 - val_mae: 0.1207\n",
      "Epoch 37/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 18ms/step - loss: 0.0100 - mae: 0.0856 - val_loss: 0.0149 - val_mae: 0.1048\n",
      "Epoch 38/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - loss: 0.0101 - mae: 0.0858 - val_loss: 0.0197 - val_mae: 0.1203\n",
      "Epoch 39/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - loss: 0.0100 - mae: 0.0857 - val_loss: 0.0195 - val_mae: 0.1204\n",
      "Epoch 40/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - loss: 0.0100 - mae: 0.0856 - val_loss: 0.0162 - val_mae: 0.1112\n",
      "Epoch 41/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - loss: 0.0099 - mae: 0.0856 - val_loss: 0.0170 - val_mae: 0.1139\n",
      "Epoch 42/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - loss: 0.0099 - mae: 0.0853 - val_loss: 0.0150 - val_mae: 0.1057\n",
      "Epoch 43/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - loss: 0.0100 - mae: 0.0855 - val_loss: 0.0197 - val_mae: 0.1211\n",
      "Epoch 44/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - loss: 0.0099 - mae: 0.0856 - val_loss: 0.0154 - val_mae: 0.1085\n",
      "Epoch 45/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 18ms/step - loss: 0.0099 - mae: 0.0854 - val_loss: 0.0153 - val_mae: 0.1080\n",
      "Epoch 46/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - loss: 0.0099 - mae: 0.0855 - val_loss: 0.0189 - val_mae: 0.1192\n",
      "Epoch 47/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - loss: 0.0099 - mae: 0.0854 - val_loss: 0.0159 - val_mae: 0.1106\n",
      "Epoch 48/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 18ms/step - loss: 0.0099 - mae: 0.0855 - val_loss: 0.0150 - val_mae: 0.1020\n",
      "Epoch 49/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - loss: 0.0099 - mae: 0.0854 - val_loss: 0.0172 - val_mae: 0.1144\n",
      "Epoch 50/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 0.0099 - mae: 0.0856 - val_loss: 0.0175 - val_mae: 0.1156\n",
      "Epoch 51/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - loss: 0.0099 - mae: 0.0856 - val_loss: 0.0151 - val_mae: 0.1070\n",
      "Epoch 52/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 18ms/step - loss: 0.0099 - mae: 0.0858 - val_loss: 0.0186 - val_mae: 0.1187\n",
      "Epoch 53/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - loss: 0.0099 - mae: 0.0856 - val_loss: 0.0205 - val_mae: 0.1240\n",
      "Epoch 54/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - loss: 0.0099 - mae: 0.0857 - val_loss: 0.0158 - val_mae: 0.1106\n",
      "Epoch 55/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 18ms/step - loss: 0.0099 - mae: 0.0857 - val_loss: 0.0175 - val_mae: 0.1158\n",
      "Epoch 56/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - loss: 0.0099 - mae: 0.0855 - val_loss: 0.0184 - val_mae: 0.1183\n",
      "Epoch 57/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - loss: 0.0099 - mae: 0.0858 - val_loss: 0.0156 - val_mae: 0.1096\n",
      "Epoch 58/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 17ms/step - loss: 0.0099 - mae: 0.0857 - val_loss: 0.0149 - val_mae: 0.1033\n",
      "Epoch 59/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - loss: 0.0098 - mae: 0.0856 - val_loss: 0.0160 - val_mae: 0.1115\n",
      "Epoch 60/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - loss: 0.0099 - mae: 0.0857 - val_loss: 0.0167 - val_mae: 0.1136\n",
      "Epoch 61/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 18ms/step - loss: 0.0098 - mae: 0.0856 - val_loss: 0.0169 - val_mae: 0.1143\n",
      "Epoch 62/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 18ms/step - loss: 0.0098 - mae: 0.0856 - val_loss: 0.0154 - val_mae: 0.1090\n",
      "Epoch 63/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - loss: 0.0098 - mae: 0.0855 - val_loss: 0.0180 - val_mae: 0.1177\n",
      "Epoch 64/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 18ms/step - loss: 0.0099 - mae: 0.0859 - val_loss: 0.0161 - val_mae: 0.1116\n",
      "Epoch 65/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - loss: 0.0099 - mae: 0.0856 - val_loss: 0.0153 - val_mae: 0.1086\n",
      "Epoch 66/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 18ms/step - loss: 0.0099 - mae: 0.0857 - val_loss: 0.0164 - val_mae: 0.1129\n",
      "Epoch 67/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 18ms/step - loss: 0.0099 - mae: 0.0858 - val_loss: 0.0169 - val_mae: 0.1143\n",
      "Epoch 68/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - loss: 0.0098 - mae: 0.0856 - val_loss: 0.0156 - val_mae: 0.1097\n",
      "Epoch 69/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - loss: 0.0098 - mae: 0.0854 - val_loss: 0.0172 - val_mae: 0.1154\n",
      "Epoch 70/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - loss: 0.0099 - mae: 0.0857 - val_loss: 0.0155 - val_mae: 0.1094\n",
      "Epoch 71/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - loss: 0.0098 - mae: 0.0856 - val_loss: 0.0156 - val_mae: 0.1097\n",
      "Epoch 72/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - loss: 0.0098 - mae: 0.0856 - val_loss: 0.0175 - val_mae: 0.1160\n",
      "Epoch 73/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 17ms/step - loss: 0.0098 - mae: 0.0857 - val_loss: 0.0159 - val_mae: 0.1110\n",
      "Epoch 74/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 17ms/step - loss: 0.0098 - mae: 0.0857 - val_loss: 0.0157 - val_mae: 0.1099\n",
      "Epoch 75/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 18ms/step - loss: 0.0098 - mae: 0.0857 - val_loss: 0.0163 - val_mae: 0.1125\n",
      "Epoch 76/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - loss: 0.0098 - mae: 0.0856 - val_loss: 0.0158 - val_mae: 0.1106\n",
      "Epoch 77/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - loss: 0.0098 - mae: 0.0856 - val_loss: 0.0150 - val_mae: 0.1064\n",
      "Epoch 78/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - loss: 0.0098 - mae: 0.0855 - val_loss: 0.0161 - val_mae: 0.1118\n",
      "Epoch 79/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - loss: 0.0098 - mae: 0.0857 - val_loss: 0.0175 - val_mae: 0.1162\n",
      "Epoch 80/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - loss: 0.0098 - mae: 0.0856 - val_loss: 0.0152 - val_mae: 0.1073\n",
      "Epoch 81/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - loss: 0.0098 - mae: 0.0857 - val_loss: 0.0156 - val_mae: 0.1096\n",
      "Epoch 82/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 0.0098 - mae: 0.0857 - val_loss: 0.0149 - val_mae: 0.1046\n",
      "Epoch 83/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - loss: 0.0098 - mae: 0.0855 - val_loss: 0.0149 - val_mae: 0.1039\n",
      "Epoch 84/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - loss: 0.0098 - mae: 0.0856 - val_loss: 0.0150 - val_mae: 0.1055\n",
      "Epoch 85/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - loss: 0.0098 - mae: 0.0854 - val_loss: 0.0149 - val_mae: 0.1023\n",
      "Epoch 86/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 0.0098 - mae: 0.0856 - val_loss: 0.0161 - val_mae: 0.1117\n",
      "Epoch 87/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 0.0098 - mae: 0.0855 - val_loss: 0.0155 - val_mae: 0.1094\n",
      "Epoch 88/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0098 - mae: 0.0856 - val_loss: 0.0150 - val_mae: 0.1065\n",
      "Epoch 89/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - loss: 0.0099 - mae: 0.0857 - val_loss: 0.0154 - val_mae: 0.1092\n",
      "Epoch 90/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - loss: 0.0098 - mae: 0.0854 - val_loss: 0.0193 - val_mae: 0.1208\n",
      "Epoch 91/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - loss: 0.0098 - mae: 0.0857 - val_loss: 0.0148 - val_mae: 0.1030\n",
      "Epoch 92/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - loss: 0.0098 - mae: 0.0855 - val_loss: 0.0150 - val_mae: 0.1070\n",
      "Epoch 93/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - loss: 0.0098 - mae: 0.0857 - val_loss: 0.0148 - val_mae: 0.1048\n",
      "Epoch 94/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 0.0099 - mae: 0.0857 - val_loss: 0.0149 - val_mae: 0.1021\n",
      "Epoch 95/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 0.0098 - mae: 0.0853 - val_loss: 0.0155 - val_mae: 0.1094\n",
      "Epoch 96/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - loss: 0.0098 - mae: 0.0857 - val_loss: 0.0149 - val_mae: 0.1028\n",
      "Epoch 97/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - loss: 0.0098 - mae: 0.0856 - val_loss: 0.0152 - val_mae: 0.1082\n",
      "Epoch 98/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - loss: 0.0098 - mae: 0.0856 - val_loss: 0.0163 - val_mae: 0.1123\n",
      "Epoch 99/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - loss: 0.0098 - mae: 0.0857 - val_loss: 0.0157 - val_mae: 0.0990\n",
      "Epoch 100/100\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - loss: 0.0098 - mae: 0.0855 - val_loss: 0.0170 - val_mae: 0.1145\n",
      "\u001b[1m414/414\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step\n",
      "✅ Done with wheat_Koppal_daily.csv | MAE=222.08, RMSE=258.54, R2=0.6926, MAPE=13.26%, Accuracy=86.74%\n",
      "Saved updated CSV with Date, Actual & Predicted: tat_mqa_output_csv\\wheat_Koppal_daily_tat_mqa_updated.csv\n",
      "🚀 Processing: wheat_MadikeriKodagu_daily.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_38\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_38\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_query_attention_16      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">17,216</span> │ input_layer_38[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiQueryAttention</span>)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_76 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_query_attention_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                               │                           │                 │ input_layer_38[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_76        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_76[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_233 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ layer_normalization_76[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_234 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dense_233[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_77 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_76[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                               │                           │                 │ dense_234[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_77        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_77[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_38   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_77[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_235 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ global_average_pooling1d_… │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_38 (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_query_attention_16      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │          \u001b[38;5;34m17,216\u001b[0m │ input_layer_38[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mMultiQueryAttention\u001b[0m)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_76 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ multi_query_attention_16[\u001b[38;5;34m…\u001b[0m │\n",
       "│                               │                           │                 │ input_layer_38[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_76        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ add_76[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_233 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │           \u001b[38;5;34m8,320\u001b[0m │ layer_normalization_76[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_234 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │             \u001b[38;5;34m129\u001b[0m │ dense_233[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_77 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_76[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                               │                           │                 │ dense_234[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_77        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ add_77[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_38   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_77[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_235 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │              \u001b[38;5;34m65\u001b[0m │ global_average_pooling1d_… │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,986</span> (101.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25,986\u001b[0m (101.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,986</span> (101.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m25,986\u001b[0m (101.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - loss: 0.2067 - mae: 0.2434 - val_loss: 0.1054 - val_mae: 0.3137\n",
      "Epoch 2/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0348 - mae: 0.1482 - val_loss: 0.0908 - val_mae: 0.2921\n",
      "Epoch 3/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0322 - mae: 0.1428 - val_loss: 0.1465 - val_mae: 0.3724\n",
      "Epoch 4/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0294 - mae: 0.1354 - val_loss: 0.0614 - val_mae: 0.2334\n",
      "Epoch 5/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0268 - mae: 0.1297 - val_loss: 0.0973 - val_mae: 0.3005\n",
      "Epoch 6/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0262 - mae: 0.1293 - val_loss: 0.0267 - val_mae: 0.1527\n",
      "Epoch 7/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0273 - mae: 0.1300 - val_loss: 0.1570 - val_mae: 0.3856\n",
      "Epoch 8/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0242 - mae: 0.1219 - val_loss: 0.1122 - val_mae: 0.3228\n",
      "Epoch 9/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0231 - mae: 0.1199 - val_loss: 0.0305 - val_mae: 0.1614\n",
      "Epoch 10/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0186 - mae: 0.1068 - val_loss: 0.0250 - val_mae: 0.1453\n",
      "Epoch 11/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0170 - mae: 0.1021 - val_loss: 0.0545 - val_mae: 0.2220\n",
      "Epoch 12/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0150 - mae: 0.0952 - val_loss: 0.0265 - val_mae: 0.1479\n",
      "Epoch 13/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0124 - mae: 0.0861 - val_loss: 0.0402 - val_mae: 0.1921\n",
      "Epoch 14/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0089 - mae: 0.0712 - val_loss: 0.0199 - val_mae: 0.1325\n",
      "Epoch 15/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0060 - mae: 0.0559 - val_loss: 0.0017 - val_mae: 0.0385\n",
      "Epoch 16/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0035 - mae: 0.0384 - val_loss: 8.5795e-04 - val_mae: 0.0283\n",
      "Epoch 17/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0026 - mae: 0.0317 - val_loss: 0.0037 - val_mae: 0.0590\n",
      "Epoch 18/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0030 - mae: 0.0348 - val_loss: 2.2329e-04 - val_mae: 0.0122\n",
      "Epoch 19/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0029 - mae: 0.0347 - val_loss: 5.3843e-04 - val_mae: 0.0214\n",
      "Epoch 20/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0020 - mae: 0.0263 - val_loss: 5.8257e-04 - val_mae: 0.0232\n",
      "Epoch 21/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0017 - mae: 0.0244 - val_loss: 4.1284e-04 - val_mae: 0.0200\n",
      "Epoch 22/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0014 - mae: 0.0206 - val_loss: 0.0017 - val_mae: 0.0410\n",
      "Epoch 23/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0016 - mae: 0.0247 - val_loss: 0.0034 - val_mae: 0.0580\n",
      "Epoch 24/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0013 - mae: 0.0198 - val_loss: 8.6813e-04 - val_mae: 0.0293\n",
      "Epoch 25/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0011 - mae: 0.0177 - val_loss: 4.8348e-04 - val_mae: 0.0218\n",
      "Epoch 26/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0012 - mae: 0.0200 - val_loss: 4.1810e-04 - val_mae: 0.0204\n",
      "Epoch 27/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mae: 0.0174 - val_loss: 0.0031 - val_mae: 0.0559\n",
      "Epoch 28/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0013 - mae: 0.0224 - val_loss: 2.1332e-04 - val_mae: 0.0143\n",
      "Epoch 29/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 9.0576e-04 - mae: 0.0155 - val_loss: 2.8321e-04 - val_mae: 0.0167\n",
      "Epoch 30/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0014 - mae: 0.0236 - val_loss: 2.6484e-04 - val_mae: 0.0158\n",
      "Epoch 31/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 8.9864e-04 - mae: 0.0157 - val_loss: 0.0011 - val_mae: 0.0327\n",
      "Epoch 32/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 8.3578e-04 - mae: 0.0150 - val_loss: 3.6551e-04 - val_mae: 0.0188\n",
      "Epoch 33/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 8.2172e-04 - mae: 0.0139 - val_loss: 1.7032e-04 - val_mae: 0.0130\n",
      "Epoch 34/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0011 - mae: 0.0194 - val_loss: 0.0033 - val_mae: 0.0567\n",
      "Epoch 35/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 9.4069e-04 - mae: 0.0164 - val_loss: 5.9928e-04 - val_mae: 0.0234\n",
      "Epoch 36/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0011 - mae: 0.0189 - val_loss: 1.8555e-04 - val_mae: 0.0136\n",
      "Epoch 37/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 9.6525e-04 - mae: 0.0170 - val_loss: 6.1742e-05 - val_mae: 0.0070\n",
      "Epoch 38/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 8.7546e-04 - mae: 0.0159 - val_loss: 9.1128e-04 - val_mae: 0.0299\n",
      "Epoch 39/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 8.8217e-04 - mae: 0.0155 - val_loss: 3.3817e-04 - val_mae: 0.0181\n",
      "Epoch 40/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 8.5840e-04 - mae: 0.0159 - val_loss: 4.6818e-04 - val_mae: 0.0216\n",
      "Epoch 41/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 8.8804e-04 - mae: 0.0158 - val_loss: 0.0010 - val_mae: 0.0321\n",
      "Epoch 42/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 8.2388e-04 - mae: 0.0146 - val_loss: 7.8539e-04 - val_mae: 0.0275\n",
      "Epoch 43/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 7.6693e-04 - mae: 0.0139 - val_loss: 0.0019 - val_mae: 0.0431\n",
      "Epoch 44/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 7.9960e-04 - mae: 0.0144 - val_loss: 2.3189e-04 - val_mae: 0.0151\n",
      "Epoch 45/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 8.9863e-04 - mae: 0.0158 - val_loss: 7.2120e-04 - val_mae: 0.0264\n",
      "Epoch 46/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 9.6385e-04 - mae: 0.0179 - val_loss: 7.0468e-04 - val_mae: 0.0263\n",
      "Epoch 47/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0010 - mae: 0.0178 - val_loss: 5.5016e-04 - val_mae: 0.0223\n",
      "Epoch 48/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 8.9831e-04 - mae: 0.0158 - val_loss: 1.9501e-04 - val_mae: 0.0137\n",
      "Epoch 49/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 8.2919e-04 - mae: 0.0146 - val_loss: 2.3621e-04 - val_mae: 0.0153\n",
      "Epoch 50/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 7.9918e-04 - mae: 0.0141 - val_loss: 3.8734e-04 - val_mae: 0.0195\n",
      "Epoch 51/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 7.5386e-04 - mae: 0.0132 - val_loss: 0.0012 - val_mae: 0.0337\n",
      "Epoch 52/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 8.0710e-04 - mae: 0.0143 - val_loss: 4.6570e-04 - val_mae: 0.0209\n",
      "Epoch 53/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 8.3667e-04 - mae: 0.0155 - val_loss: 3.2342e-04 - val_mae: 0.0177\n",
      "Epoch 54/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 6.8695e-04 - mae: 0.0119 - val_loss: 3.4899e-04 - val_mae: 0.0185\n",
      "Epoch 55/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 7.3526e-04 - mae: 0.0124 - val_loss: 6.9424e-04 - val_mae: 0.0263\n",
      "Epoch 56/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 9.3817e-04 - mae: 0.0165 - val_loss: 4.3867e-04 - val_mae: 0.0207\n",
      "Epoch 57/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 8.6416e-04 - mae: 0.0146 - val_loss: 7.0379e-04 - val_mae: 0.0262\n",
      "Epoch 58/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 9.2801e-04 - mae: 0.0164 - val_loss: 6.2698e-04 - val_mae: 0.0245\n",
      "Epoch 59/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 7.4735e-04 - mae: 0.0132 - val_loss: 6.2827e-04 - val_mae: 0.0249\n",
      "Epoch 60/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 7.8991e-04 - mae: 0.0137 - val_loss: 7.2659e-04 - val_mae: 0.0266\n",
      "Epoch 61/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0011 - mae: 0.0172 - val_loss: 8.2560e-04 - val_mae: 0.0278\n",
      "Epoch 62/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 9.7026e-04 - mae: 0.0170 - val_loss: 0.0012 - val_mae: 0.0343\n",
      "Epoch 63/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 7.2195e-04 - mae: 0.0121 - val_loss: 5.3241e-04 - val_mae: 0.0230\n",
      "Epoch 64/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 7.7480e-04 - mae: 0.0134 - val_loss: 8.9597e-04 - val_mae: 0.0295\n",
      "Epoch 65/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 7.3928e-04 - mae: 0.0126 - val_loss: 6.4608e-04 - val_mae: 0.0251\n",
      "Epoch 66/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 7.0573e-04 - mae: 0.0123 - val_loss: 1.0517e-04 - val_mae: 0.0091\n",
      "Epoch 67/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 6.9245e-04 - mae: 0.0121 - val_loss: 0.0010 - val_mae: 0.0315\n",
      "Epoch 68/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 6.8164e-04 - mae: 0.0114 - val_loss: 1.4353e-04 - val_mae: 0.0109\n",
      "Epoch 69/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 7.9178e-04 - mae: 0.0145 - val_loss: 3.9409e-04 - val_mae: 0.0194\n",
      "Epoch 70/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 8.3039e-04 - mae: 0.0147 - val_loss: 0.0012 - val_mae: 0.0347\n",
      "Epoch 71/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 9.2346e-04 - mae: 0.0164 - val_loss: 6.8841e-04 - val_mae: 0.0256\n",
      "Epoch 72/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 6.7352e-04 - mae: 0.0116 - val_loss: 1.7861e-04 - val_mae: 0.0123\n",
      "Epoch 73/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 6.8972e-04 - mae: 0.0119 - val_loss: 5.7335e-04 - val_mae: 0.0235\n",
      "Epoch 74/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 7.0627e-04 - mae: 0.0120 - val_loss: 9.2899e-04 - val_mae: 0.0299\n",
      "Epoch 75/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 6.7599e-04 - mae: 0.0110 - val_loss: 2.9924e-05 - val_mae: 0.0048\n",
      "Epoch 76/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 7.2084e-04 - mae: 0.0123 - val_loss: 2.7624e-04 - val_mae: 0.0162\n",
      "Epoch 77/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 7.2631e-04 - mae: 0.0121 - val_loss: 4.1939e-04 - val_mae: 0.0203\n",
      "Epoch 78/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 7.5306e-04 - mae: 0.0127 - val_loss: 0.0013 - val_mae: 0.0360\n",
      "Epoch 79/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 7.8337e-04 - mae: 0.0133 - val_loss: 6.5777e-04 - val_mae: 0.0254\n",
      "Epoch 80/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 7.7115e-04 - mae: 0.0120 - val_loss: 8.4487e-04 - val_mae: 0.0285\n",
      "Epoch 81/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 7.1001e-04 - mae: 0.0121 - val_loss: 0.0011 - val_mae: 0.0327\n",
      "Epoch 82/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 7.4073e-04 - mae: 0.0123 - val_loss: 5.2650e-04 - val_mae: 0.0227\n",
      "Epoch 83/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 6.8879e-04 - mae: 0.0115 - val_loss: 4.1510e-04 - val_mae: 0.0201\n",
      "Epoch 84/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 7.2067e-04 - mae: 0.0120 - val_loss: 4.6408e-05 - val_mae: 0.0054\n",
      "Epoch 85/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 7.4436e-04 - mae: 0.0132 - val_loss: 2.5065e-04 - val_mae: 0.0154\n",
      "Epoch 86/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 6.9145e-04 - mae: 0.0113 - val_loss: 1.7609e-04 - val_mae: 0.0130\n",
      "Epoch 87/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 7.0065e-04 - mae: 0.0119 - val_loss: 0.0023 - val_mae: 0.0476\n",
      "Epoch 88/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 7.5590e-04 - mae: 0.0126 - val_loss: 0.0026 - val_mae: 0.0509\n",
      "Epoch 89/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 7.5090e-04 - mae: 0.0130 - val_loss: 7.1222e-05 - val_mae: 0.0073\n",
      "Epoch 90/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 7.3401e-04 - mae: 0.0129 - val_loss: 6.7698e-05 - val_mae: 0.0065\n",
      "Epoch 91/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 8.1761e-04 - mae: 0.0140 - val_loss: 1.3805e-05 - val_mae: 0.0033\n",
      "Epoch 92/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 7.6591e-04 - mae: 0.0133 - val_loss: 7.1568e-04 - val_mae: 0.0263\n",
      "Epoch 93/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 6.2895e-04 - mae: 0.0101 - val_loss: 6.5079e-04 - val_mae: 0.0254\n",
      "Epoch 94/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 6.5464e-04 - mae: 0.0105 - val_loss: 5.0183e-04 - val_mae: 0.0220\n",
      "Epoch 95/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 6.7402e-04 - mae: 0.0111 - val_loss: 8.5669e-04 - val_mae: 0.0291\n",
      "Epoch 96/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 6.9619e-04 - mae: 0.0114 - val_loss: 1.0754e-04 - val_mae: 0.0089\n",
      "Epoch 97/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 6.6958e-04 - mae: 0.0108 - val_loss: 8.5448e-04 - val_mae: 0.0291\n",
      "Epoch 98/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 8.6181e-04 - mae: 0.0133 - val_loss: 7.2161e-04 - val_mae: 0.0267\n",
      "Epoch 99/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 6.6879e-04 - mae: 0.0114 - val_loss: 2.7779e-04 - val_mae: 0.0163\n",
      "Epoch 100/100\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 8.0694e-04 - mae: 0.0139 - val_loss: 7.9914e-04 - val_mae: 0.0280\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 19ms/step \n",
      "✅ Done with wheat_MadikeriKodagu_daily.csv | MAE=972.98, RMSE=1202.22, R2=0.9601, MAPE=15.29%, Accuracy=84.71%\n",
      "Saved updated CSV with Date, Actual & Predicted: tat_mqa_output_csv\\wheat_MadikeriKodagu_daily_tat_mqa_updated.csv\n",
      "🚀 Processing: wheat_Mandya_daily.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_39\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_39\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_query_attention_17      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">17,216</span> │ input_layer_39[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiQueryAttention</span>)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_78 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_query_attention_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                               │                           │                 │ input_layer_39[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_78        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_78[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_243 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ layer_normalization_78[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_244 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dense_243[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_79 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_78[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                               │                           │                 │ dense_244[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_79        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_79[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_39   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_79[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_245 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ global_average_pooling1d_… │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_39 (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_query_attention_17      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │          \u001b[38;5;34m17,216\u001b[0m │ input_layer_39[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mMultiQueryAttention\u001b[0m)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_78 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ multi_query_attention_17[\u001b[38;5;34m…\u001b[0m │\n",
       "│                               │                           │                 │ input_layer_39[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_78        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ add_78[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_243 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │           \u001b[38;5;34m8,320\u001b[0m │ layer_normalization_78[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_244 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │             \u001b[38;5;34m129\u001b[0m │ dense_243[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_79 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_78[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                               │                           │                 │ dense_244[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_79        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ add_79[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_39   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_79[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_245 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │              \u001b[38;5;34m65\u001b[0m │ global_average_pooling1d_… │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,986</span> (101.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25,986\u001b[0m (101.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,986</span> (101.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m25,986\u001b[0m (101.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 26ms/step - loss: 0.0739 - mae: 0.1950 - val_loss: 0.0082 - val_mae: 0.0690\n",
      "Epoch 2/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - loss: 0.0366 - mae: 0.1519 - val_loss: 0.0083 - val_mae: 0.0720\n",
      "Epoch 3/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - loss: 0.0305 - mae: 0.1403 - val_loss: 0.0325 - val_mae: 0.1660\n",
      "Epoch 4/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - loss: 0.0297 - mae: 0.1382 - val_loss: 0.0293 - val_mae: 0.1578\n",
      "Epoch 5/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - loss: 0.0288 - mae: 0.1364 - val_loss: 0.0105 - val_mae: 0.0771\n",
      "Epoch 6/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 32ms/step - loss: 0.0284 - mae: 0.1344 - val_loss: 0.0185 - val_mae: 0.1222\n",
      "Epoch 7/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - loss: 0.0280 - mae: 0.1326 - val_loss: 0.0110 - val_mae: 0.0877\n",
      "Epoch 8/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 32ms/step - loss: 0.0272 - mae: 0.1297 - val_loss: 0.0090 - val_mae: 0.0748\n",
      "Epoch 9/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - loss: 0.0277 - mae: 0.1329 - val_loss: 0.0088 - val_mae: 0.0697\n",
      "Epoch 10/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 31ms/step - loss: 0.0276 - mae: 0.1315 - val_loss: 0.0112 - val_mae: 0.0919\n",
      "Epoch 11/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - loss: 0.0276 - mae: 0.1321 - val_loss: 0.0081 - val_mae: 0.0728\n",
      "Epoch 12/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - loss: 0.0276 - mae: 0.1318 - val_loss: 0.0113 - val_mae: 0.0919\n",
      "Epoch 13/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - loss: 0.0266 - mae: 0.1278 - val_loss: 0.0106 - val_mae: 0.0897\n",
      "Epoch 14/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 31ms/step - loss: 0.0266 - mae: 0.1264 - val_loss: 0.0108 - val_mae: 0.0930\n",
      "Epoch 15/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 31ms/step - loss: 0.0273 - mae: 0.1301 - val_loss: 0.0134 - val_mae: 0.1074\n",
      "Epoch 16/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - loss: 0.0263 - mae: 0.1253 - val_loss: 0.0089 - val_mae: 0.0836\n",
      "Epoch 17/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - loss: 0.0267 - mae: 0.1273 - val_loss: 0.0058 - val_mae: 0.0571\n",
      "Epoch 18/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 27ms/step - loss: 0.0266 - mae: 0.1267 - val_loss: 0.0054 - val_mae: 0.0579\n",
      "Epoch 19/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 32ms/step - loss: 0.0265 - mae: 0.1272 - val_loss: 0.0251 - val_mae: 0.1481\n",
      "Epoch 20/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - loss: 0.0258 - mae: 0.1242 - val_loss: 0.0063 - val_mae: 0.0679\n",
      "Epoch 21/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - loss: 0.0265 - mae: 0.1264 - val_loss: 0.0033 - val_mae: 0.0453\n",
      "Epoch 22/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - loss: 0.0260 - mae: 0.1242 - val_loss: 0.0178 - val_mae: 0.1273\n",
      "Epoch 23/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - loss: 0.0260 - mae: 0.1246 - val_loss: 0.0034 - val_mae: 0.0501\n",
      "Epoch 24/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - loss: 0.0257 - mae: 0.1233 - val_loss: 0.0059 - val_mae: 0.0726\n",
      "Epoch 25/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - loss: 0.0253 - mae: 0.1210 - val_loss: 0.0037 - val_mae: 0.0484\n",
      "Epoch 26/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 32ms/step - loss: 0.0257 - mae: 0.1222 - val_loss: 0.0031 - val_mae: 0.0528\n",
      "Epoch 27/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 31ms/step - loss: 0.0255 - mae: 0.1209 - val_loss: 0.0112 - val_mae: 0.0996\n",
      "Epoch 28/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 32ms/step - loss: 0.0264 - mae: 0.1258 - val_loss: 0.0060 - val_mae: 0.0740\n",
      "Epoch 29/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 32ms/step - loss: 0.0252 - mae: 0.1189 - val_loss: 0.0059 - val_mae: 0.0731\n",
      "Epoch 30/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 27ms/step - loss: 0.0253 - mae: 0.1197 - val_loss: 0.0011 - val_mae: 0.0226\n",
      "Epoch 31/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 27ms/step - loss: 0.0252 - mae: 0.1207 - val_loss: 0.0041 - val_mae: 0.0607\n",
      "Epoch 32/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 31ms/step - loss: 0.0253 - mae: 0.1193 - val_loss: 0.0073 - val_mae: 0.0840\n",
      "Epoch 33/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - loss: 0.0256 - mae: 0.1203 - val_loss: 0.0050 - val_mae: 0.0689\n",
      "Epoch 34/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 27ms/step - loss: 0.0252 - mae: 0.1193 - val_loss: 0.0061 - val_mae: 0.0765\n",
      "Epoch 35/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - loss: 0.0250 - mae: 0.1187 - val_loss: 0.0011 - val_mae: 0.0291\n",
      "Epoch 36/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 32ms/step - loss: 0.0251 - mae: 0.1188 - val_loss: 0.0110 - val_mae: 0.1029\n",
      "Epoch 37/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 32ms/step - loss: 0.0249 - mae: 0.1174 - val_loss: 0.0078 - val_mae: 0.0869\n",
      "Epoch 38/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - loss: 0.0249 - mae: 0.1169 - val_loss: 0.0020 - val_mae: 0.0413\n",
      "Epoch 39/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - loss: 0.0249 - mae: 0.1179 - val_loss: 0.0079 - val_mae: 0.0864\n",
      "Epoch 40/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - loss: 0.0248 - mae: 0.1167 - val_loss: 0.0099 - val_mae: 0.0964\n",
      "Epoch 41/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 31ms/step - loss: 0.0250 - mae: 0.1185 - val_loss: 0.0033 - val_mae: 0.0539\n",
      "Epoch 42/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - loss: 0.0250 - mae: 0.1181 - val_loss: 0.0031 - val_mae: 0.0528\n",
      "Epoch 43/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 31ms/step - loss: 0.0248 - mae: 0.1160 - val_loss: 0.0055 - val_mae: 0.0678\n",
      "Epoch 44/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 31ms/step - loss: 0.0250 - mae: 0.1191 - val_loss: 0.0063 - val_mae: 0.0776\n",
      "Epoch 45/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - loss: 0.0247 - mae: 0.1162 - val_loss: 0.0054 - val_mae: 0.0705\n",
      "Epoch 46/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - loss: 0.0249 - mae: 0.1178 - val_loss: 0.0029 - val_mae: 0.0513\n",
      "Epoch 47/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - loss: 0.0250 - mae: 0.1190 - val_loss: 0.0065 - val_mae: 0.0782\n",
      "Epoch 48/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - loss: 0.0246 - mae: 0.1160 - val_loss: 0.0033 - val_mae: 0.0545\n",
      "Epoch 49/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 32ms/step - loss: 0.0247 - mae: 0.1160 - val_loss: 0.0107 - val_mae: 0.0965\n",
      "Epoch 50/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - loss: 0.0249 - mae: 0.1183 - val_loss: 3.7163e-04 - val_mae: 0.0126\n",
      "Epoch 51/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - loss: 0.0248 - mae: 0.1170 - val_loss: 0.0039 - val_mae: 0.0596\n",
      "Epoch 52/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - loss: 0.0251 - mae: 0.1200 - val_loss: 0.0038 - val_mae: 0.0588\n",
      "Epoch 53/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - loss: 0.0246 - mae: 0.1158 - val_loss: 0.0111 - val_mae: 0.1039\n",
      "Epoch 54/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - loss: 0.0246 - mae: 0.1152 - val_loss: 0.0078 - val_mae: 0.0834\n",
      "Epoch 55/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - loss: 0.0247 - mae: 0.1166 - val_loss: 0.0049 - val_mae: 0.0680\n",
      "Epoch 56/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - loss: 0.0247 - mae: 0.1160 - val_loss: 0.0025 - val_mae: 0.0461\n",
      "Epoch 57/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.0247 - mae: 0.1161 - val_loss: 0.0084 - val_mae: 0.0894\n",
      "Epoch 58/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - loss: 0.0245 - mae: 0.1127 - val_loss: 0.0088 - val_mae: 0.0906\n",
      "Epoch 59/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - loss: 0.0247 - mae: 0.1170 - val_loss: 0.0105 - val_mae: 0.0987\n",
      "Epoch 60/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - loss: 0.0248 - mae: 0.1165 - val_loss: 0.0069 - val_mae: 0.0812\n",
      "Epoch 61/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - loss: 0.0247 - mae: 0.1163 - val_loss: 0.0027 - val_mae: 0.0443\n",
      "Epoch 62/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - loss: 0.0247 - mae: 0.1166 - val_loss: 0.0022 - val_mae: 0.0434\n",
      "Epoch 63/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - loss: 0.0244 - mae: 0.1142 - val_loss: 0.0110 - val_mae: 0.1032\n",
      "Epoch 64/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - loss: 0.0248 - mae: 0.1178 - val_loss: 0.0041 - val_mae: 0.0610\n",
      "Epoch 65/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - loss: 0.0245 - mae: 0.1147 - val_loss: 0.0019 - val_mae: 0.0391\n",
      "Epoch 66/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - loss: 0.0244 - mae: 0.1139 - val_loss: 0.0031 - val_mae: 0.0531\n",
      "Epoch 67/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - loss: 0.0246 - mae: 0.1154 - val_loss: 0.0017 - val_mae: 0.0383\n",
      "Epoch 68/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - loss: 0.0245 - mae: 0.1146 - val_loss: 0.0022 - val_mae: 0.0438\n",
      "Epoch 69/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - loss: 0.0244 - mae: 0.1127 - val_loss: 0.0016 - val_mae: 0.0373\n",
      "Epoch 70/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - loss: 0.0246 - mae: 0.1171 - val_loss: 0.0055 - val_mae: 0.0690\n",
      "Epoch 71/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - loss: 0.0247 - mae: 0.1163 - val_loss: 0.0083 - val_mae: 0.0886\n",
      "Epoch 72/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - loss: 0.0245 - mae: 0.1139 - val_loss: 0.0069 - val_mae: 0.0799\n",
      "Epoch 73/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - loss: 0.0246 - mae: 0.1150 - val_loss: 0.0097 - val_mae: 0.0961\n",
      "Epoch 74/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - loss: 0.0246 - mae: 0.1148 - val_loss: 0.0080 - val_mae: 0.0874\n",
      "Epoch 75/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - loss: 0.0245 - mae: 0.1142 - val_loss: 0.0043 - val_mae: 0.0629\n",
      "Epoch 76/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - loss: 0.0246 - mae: 0.1155 - val_loss: 0.0087 - val_mae: 0.0883\n",
      "Epoch 77/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - loss: 0.0246 - mae: 0.1153 - val_loss: 0.0078 - val_mae: 0.0797\n",
      "Epoch 78/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - loss: 0.0246 - mae: 0.1154 - val_loss: 0.0022 - val_mae: 0.0441\n",
      "Epoch 79/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - loss: 0.0245 - mae: 0.1142 - val_loss: 0.0017 - val_mae: 0.0390\n",
      "Epoch 80/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - loss: 0.0248 - mae: 0.1165 - val_loss: 0.0129 - val_mae: 0.1082\n",
      "Epoch 81/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - loss: 0.0246 - mae: 0.1155 - val_loss: 0.0072 - val_mae: 0.0826\n",
      "Epoch 82/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - loss: 0.0245 - mae: 0.1143 - val_loss: 0.0046 - val_mae: 0.0647\n",
      "Epoch 83/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - loss: 0.0246 - mae: 0.1151 - val_loss: 0.0026 - val_mae: 0.0486\n",
      "Epoch 84/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - loss: 0.0245 - mae: 0.1144 - val_loss: 0.0020 - val_mae: 0.0401\n",
      "Epoch 85/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - loss: 0.0246 - mae: 0.1164 - val_loss: 0.0049 - val_mae: 0.0613\n",
      "Epoch 86/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 27ms/step - loss: 0.0247 - mae: 0.1161 - val_loss: 0.0079 - val_mae: 0.0843\n",
      "Epoch 87/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - loss: 0.0248 - mae: 0.1167 - val_loss: 0.0078 - val_mae: 0.0857\n",
      "Epoch 88/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - loss: 0.0242 - mae: 0.1119 - val_loss: 0.0047 - val_mae: 0.0654\n",
      "Epoch 89/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - loss: 0.0247 - mae: 0.1152 - val_loss: 0.0186 - val_mae: 0.1318\n",
      "Epoch 90/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.0246 - mae: 0.1150 - val_loss: 0.0053 - val_mae: 0.0697\n",
      "Epoch 91/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.0245 - mae: 0.1149 - val_loss: 0.0051 - val_mae: 0.0665\n",
      "Epoch 92/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - loss: 0.0245 - mae: 0.1142 - val_loss: 0.0021 - val_mae: 0.0423\n",
      "Epoch 93/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.0244 - mae: 0.1141 - val_loss: 0.0048 - val_mae: 0.0656\n",
      "Epoch 94/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - loss: 0.0246 - mae: 0.1162 - val_loss: 0.0051 - val_mae: 0.0660\n",
      "Epoch 95/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - loss: 0.0245 - mae: 0.1148 - val_loss: 0.0034 - val_mae: 0.0529\n",
      "Epoch 96/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - loss: 0.0244 - mae: 0.1140 - val_loss: 0.0138 - val_mae: 0.1150\n",
      "Epoch 97/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - loss: 0.0246 - mae: 0.1162 - val_loss: 0.0131 - val_mae: 0.1108\n",
      "Epoch 98/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - loss: 0.0245 - mae: 0.1137 - val_loss: 0.0035 - val_mae: 0.0568\n",
      "Epoch 99/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - loss: 0.0245 - mae: 0.1144 - val_loss: 0.0065 - val_mae: 0.0789\n",
      "Epoch 100/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - loss: 0.0245 - mae: 0.1140 - val_loss: 0.0100 - val_mae: 0.0974\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step\n",
      "✅ Done with wheat_Mandya_daily.csv | MAE=258.45, RMSE=296.59, R2=0.4825, MAPE=13.43%, Accuracy=86.57%\n",
      "Saved updated CSV with Date, Actual & Predicted: tat_mqa_output_csv\\wheat_Mandya_daily_tat_mqa_updated.csv\n",
      "🚀 Processing: wheat_Mysore_daily.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_40\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_40\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_query_attention_18      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">17,216</span> │ input_layer_40[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiQueryAttention</span>)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_80 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_query_attention_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                               │                           │                 │ input_layer_40[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_80        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_80[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_253 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ layer_normalization_80[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_254 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dense_253[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_81 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_80[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                               │                           │                 │ dense_254[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_81        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_81[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_40   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_81[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_255 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ global_average_pooling1d_… │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_40 (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_query_attention_18      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │          \u001b[38;5;34m17,216\u001b[0m │ input_layer_40[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mMultiQueryAttention\u001b[0m)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_80 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ multi_query_attention_18[\u001b[38;5;34m…\u001b[0m │\n",
       "│                               │                           │                 │ input_layer_40[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_80        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ add_80[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_253 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │           \u001b[38;5;34m8,320\u001b[0m │ layer_normalization_80[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_254 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │             \u001b[38;5;34m129\u001b[0m │ dense_253[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_81 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_80[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                               │                           │                 │ dense_254[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_81        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ add_81[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_40   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_81[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_255 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │              \u001b[38;5;34m65\u001b[0m │ global_average_pooling1d_… │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,986</span> (101.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25,986\u001b[0m (101.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,986</span> (101.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m25,986\u001b[0m (101.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - loss: 0.0289 - mae: 0.0746 - val_loss: 0.0010 - val_mae: 0.0191\n",
      "Epoch 2/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 19ms/step - loss: 0.0016 - mae: 0.0314 - val_loss: 0.0014 - val_mae: 0.0259\n",
      "Epoch 3/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 19ms/step - loss: 7.2115e-04 - mae: 0.0208 - val_loss: 8.8449e-04 - val_mae: 0.0146\n",
      "Epoch 4/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - loss: 3.7988e-04 - mae: 0.0149 - val_loss: 9.0551e-04 - val_mae: 0.0146\n",
      "Epoch 5/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - loss: 2.7642e-04 - mae: 0.0126 - val_loss: 9.3713e-04 - val_mae: 0.0167\n",
      "Epoch 6/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 22ms/step - loss: 2.5063e-04 - mae: 0.0120 - val_loss: 0.0011 - val_mae: 0.0206\n",
      "Epoch 7/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 22ms/step - loss: 2.4178e-04 - mae: 0.0117 - val_loss: 0.0011 - val_mae: 0.0206\n",
      "Epoch 8/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 20ms/step - loss: 2.4903e-04 - mae: 0.0119 - val_loss: 0.0013 - val_mae: 0.0250\n",
      "Epoch 9/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 22ms/step - loss: 2.3384e-04 - mae: 0.0115 - val_loss: 0.0011 - val_mae: 0.0199\n",
      "Epoch 10/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 21ms/step - loss: 2.3608e-04 - mae: 0.0116 - val_loss: 0.0011 - val_mae: 0.0212\n",
      "Epoch 11/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 22ms/step - loss: 2.2809e-04 - mae: 0.0114 - val_loss: 0.0011 - val_mae: 0.0210\n",
      "Epoch 12/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - loss: 2.2897e-04 - mae: 0.0113 - val_loss: 9.2344e-04 - val_mae: 0.0160\n",
      "Epoch 13/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - loss: 2.3103e-04 - mae: 0.0114 - val_loss: 0.0011 - val_mae: 0.0211\n",
      "Epoch 14/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 24ms/step - loss: 2.2479e-04 - mae: 0.0113 - val_loss: 9.9664e-04 - val_mae: 0.0183\n",
      "Epoch 15/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 22ms/step - loss: 2.2098e-04 - mae: 0.0112 - val_loss: 9.3528e-04 - val_mae: 0.0165\n",
      "Epoch 16/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 21ms/step - loss: 2.1733e-04 - mae: 0.0111 - val_loss: 0.0011 - val_mae: 0.0196\n",
      "Epoch 17/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 20ms/step - loss: 2.1958e-04 - mae: 0.0111 - val_loss: 0.0011 - val_mae: 0.0215\n",
      "Epoch 18/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 22ms/step - loss: 2.0862e-04 - mae: 0.0108 - val_loss: 9.9768e-04 - val_mae: 0.0184\n",
      "Epoch 19/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 19ms/step - loss: 2.0888e-04 - mae: 0.0108 - val_loss: 0.0011 - val_mae: 0.0205\n",
      "Epoch 20/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 22ms/step - loss: 2.0960e-04 - mae: 0.0108 - val_loss: 9.6104e-04 - val_mae: 0.0174\n",
      "Epoch 21/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - loss: 2.0643e-04 - mae: 0.0107 - val_loss: 9.5250e-04 - val_mae: 0.0172\n",
      "Epoch 22/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 20ms/step - loss: 2.0964e-04 - mae: 0.0108 - val_loss: 0.0010 - val_mae: 0.0186\n",
      "Epoch 23/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - loss: 2.0242e-04 - mae: 0.0107 - val_loss: 0.0010 - val_mae: 0.0192\n",
      "Epoch 24/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 22ms/step - loss: 1.9960e-04 - mae: 0.0105 - val_loss: 9.2005e-04 - val_mae: 0.0159\n",
      "Epoch 25/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 20ms/step - loss: 2.0117e-04 - mae: 0.0106 - val_loss: 9.9865e-04 - val_mae: 0.0183\n",
      "Epoch 26/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 22ms/step - loss: 1.9840e-04 - mae: 0.0105 - val_loss: 9.8410e-04 - val_mae: 0.0178\n",
      "Epoch 27/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 21ms/step - loss: 1.9866e-04 - mae: 0.0105 - val_loss: 9.3125e-04 - val_mae: 0.0163\n",
      "Epoch 28/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 21ms/step - loss: 1.9757e-04 - mae: 0.0105 - val_loss: 0.0010 - val_mae: 0.0191\n",
      "Epoch 29/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 21ms/step - loss: 1.9705e-04 - mae: 0.0105 - val_loss: 0.0012 - val_mae: 0.0231\n",
      "Epoch 30/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 24ms/step - loss: 1.9757e-04 - mae: 0.0105 - val_loss: 0.0011 - val_mae: 0.0209\n",
      "Epoch 31/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - loss: 1.9662e-04 - mae: 0.0105 - val_loss: 0.0011 - val_mae: 0.0207\n",
      "Epoch 32/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - loss: 1.9540e-04 - mae: 0.0104 - val_loss: 0.0011 - val_mae: 0.0206\n",
      "Epoch 33/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - loss: 1.9634e-04 - mae: 0.0104 - val_loss: 0.0011 - val_mae: 0.0204\n",
      "Epoch 34/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 22ms/step - loss: 1.9609e-04 - mae: 0.0104 - val_loss: 0.0011 - val_mae: 0.0202\n",
      "Epoch 35/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 21ms/step - loss: 1.9340e-04 - mae: 0.0104 - val_loss: 0.0011 - val_mae: 0.0210\n",
      "Epoch 36/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 21ms/step - loss: 1.9343e-04 - mae: 0.0104 - val_loss: 0.0012 - val_mae: 0.0227\n",
      "Epoch 37/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 21ms/step - loss: 1.9339e-04 - mae: 0.0104 - val_loss: 9.1123e-04 - val_mae: 0.0152\n",
      "Epoch 38/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - loss: 1.9383e-04 - mae: 0.0104 - val_loss: 0.0012 - val_mae: 0.0220\n",
      "Epoch 39/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 21ms/step - loss: 1.9274e-04 - mae: 0.0103 - val_loss: 0.0011 - val_mae: 0.0214\n",
      "Epoch 40/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 21ms/step - loss: 1.9213e-04 - mae: 0.0103 - val_loss: 0.0011 - val_mae: 0.0203\n",
      "Epoch 41/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 21ms/step - loss: 1.9376e-04 - mae: 0.0104 - val_loss: 0.0011 - val_mae: 0.0205\n",
      "Epoch 42/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 20ms/step - loss: 1.9167e-04 - mae: 0.0103 - val_loss: 0.0011 - val_mae: 0.0197\n",
      "Epoch 43/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 22ms/step - loss: 1.9300e-04 - mae: 0.0104 - val_loss: 0.0012 - val_mae: 0.0226\n",
      "Epoch 44/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 19ms/step - loss: 1.9331e-04 - mae: 0.0104 - val_loss: 0.0011 - val_mae: 0.0213\n",
      "Epoch 45/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 22ms/step - loss: 1.9138e-04 - mae: 0.0103 - val_loss: 0.0011 - val_mae: 0.0207\n",
      "Epoch 46/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - loss: 1.9189e-04 - mae: 0.0104 - val_loss: 0.0012 - val_mae: 0.0216\n",
      "Epoch 47/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 21ms/step - loss: 1.9270e-04 - mae: 0.0104 - val_loss: 0.0012 - val_mae: 0.0217\n",
      "Epoch 48/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - loss: 1.9099e-04 - mae: 0.0103 - val_loss: 0.0011 - val_mae: 0.0206\n",
      "Epoch 49/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 22ms/step - loss: 1.9079e-04 - mae: 0.0103 - val_loss: 0.0013 - val_mae: 0.0236\n",
      "Epoch 50/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 21ms/step - loss: 1.9283e-04 - mae: 0.0104 - val_loss: 0.0012 - val_mae: 0.0226\n",
      "Epoch 51/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - loss: 1.9221e-04 - mae: 0.0103 - val_loss: 0.0011 - val_mae: 0.0212\n",
      "Epoch 52/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - loss: 1.9130e-04 - mae: 0.0103 - val_loss: 0.0011 - val_mae: 0.0210\n",
      "Epoch 53/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 21ms/step - loss: 1.9114e-04 - mae: 0.0103 - val_loss: 0.0011 - val_mae: 0.0211\n",
      "Epoch 54/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 19ms/step - loss: 1.9158e-04 - mae: 0.0103 - val_loss: 0.0011 - val_mae: 0.0213\n",
      "Epoch 55/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - loss: 1.9237e-04 - mae: 0.0104 - val_loss: 0.0011 - val_mae: 0.0211\n",
      "Epoch 56/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 19ms/step - loss: 1.9198e-04 - mae: 0.0104 - val_loss: 0.0012 - val_mae: 0.0233\n",
      "Epoch 57/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - loss: 1.9200e-04 - mae: 0.0103 - val_loss: 9.9031e-04 - val_mae: 0.0177\n",
      "Epoch 58/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 21ms/step - loss: 1.9238e-04 - mae: 0.0104 - val_loss: 0.0012 - val_mae: 0.0223\n",
      "Epoch 59/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 19ms/step - loss: 1.9191e-04 - mae: 0.0103 - val_loss: 0.0012 - val_mae: 0.0227\n",
      "Epoch 60/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - loss: 1.9092e-04 - mae: 0.0103 - val_loss: 0.0011 - val_mae: 0.0206\n",
      "Epoch 61/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - loss: 1.9090e-04 - mae: 0.0103 - val_loss: 0.0011 - val_mae: 0.0210\n",
      "Epoch 62/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 20ms/step - loss: 1.9189e-04 - mae: 0.0103 - val_loss: 0.0011 - val_mae: 0.0197\n",
      "Epoch 63/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - loss: 1.9251e-04 - mae: 0.0104 - val_loss: 0.0011 - val_mae: 0.0212\n",
      "Epoch 64/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 22ms/step - loss: 1.9095e-04 - mae: 0.0103 - val_loss: 0.0011 - val_mae: 0.0197\n",
      "Epoch 65/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - loss: 1.9179e-04 - mae: 0.0103 - val_loss: 0.0011 - val_mae: 0.0211\n",
      "Epoch 66/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - loss: 1.9130e-04 - mae: 0.0103 - val_loss: 0.0012 - val_mae: 0.0230\n",
      "Epoch 67/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 21ms/step - loss: 1.9149e-04 - mae: 0.0103 - val_loss: 0.0012 - val_mae: 0.0219\n",
      "Epoch 68/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 22ms/step - loss: 1.9108e-04 - mae: 0.0103 - val_loss: 0.0011 - val_mae: 0.0207\n",
      "Epoch 69/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 22ms/step - loss: 1.9040e-04 - mae: 0.0103 - val_loss: 0.0010 - val_mae: 0.0193\n",
      "Epoch 70/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - loss: 1.9135e-04 - mae: 0.0103 - val_loss: 0.0011 - val_mae: 0.0207\n",
      "Epoch 71/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 21ms/step - loss: 1.9129e-04 - mae: 0.0103 - val_loss: 0.0012 - val_mae: 0.0215\n",
      "Epoch 72/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - loss: 1.9046e-04 - mae: 0.0103 - val_loss: 0.0011 - val_mae: 0.0212\n",
      "Epoch 73/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - loss: 1.9129e-04 - mae: 0.0103 - val_loss: 0.0011 - val_mae: 0.0207\n",
      "Epoch 74/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 22ms/step - loss: 1.9054e-04 - mae: 0.0103 - val_loss: 0.0012 - val_mae: 0.0222\n",
      "Epoch 75/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - loss: 1.9089e-04 - mae: 0.0103 - val_loss: 0.0012 - val_mae: 0.0230\n",
      "Epoch 76/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 22ms/step - loss: 1.9114e-04 - mae: 0.0103 - val_loss: 0.0011 - val_mae: 0.0211\n",
      "Epoch 77/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 22ms/step - loss: 1.9125e-04 - mae: 0.0103 - val_loss: 0.0012 - val_mae: 0.0219\n",
      "Epoch 78/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 21ms/step - loss: 1.9075e-04 - mae: 0.0103 - val_loss: 0.0010 - val_mae: 0.0191\n",
      "Epoch 79/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 21ms/step - loss: 1.9076e-04 - mae: 0.0103 - val_loss: 0.0011 - val_mae: 0.0214\n",
      "Epoch 80/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - loss: 1.9135e-04 - mae: 0.0103 - val_loss: 0.0012 - val_mae: 0.0216\n",
      "Epoch 81/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - loss: 1.9121e-04 - mae: 0.0103 - val_loss: 0.0012 - val_mae: 0.0227\n",
      "Epoch 82/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - loss: 1.9036e-04 - mae: 0.0103 - val_loss: 0.0012 - val_mae: 0.0223\n",
      "Epoch 83/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - loss: 1.9060e-04 - mae: 0.0103 - val_loss: 0.0011 - val_mae: 0.0206\n",
      "Epoch 84/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - loss: 1.9051e-04 - mae: 0.0103 - val_loss: 0.0011 - val_mae: 0.0202\n",
      "Epoch 85/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 24ms/step - loss: 1.9183e-04 - mae: 0.0103 - val_loss: 9.8958e-04 - val_mae: 0.0178\n",
      "Epoch 86/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 22ms/step - loss: 1.9115e-04 - mae: 0.0103 - val_loss: 0.0011 - val_mae: 0.0210\n",
      "Epoch 87/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 22ms/step - loss: 1.9099e-04 - mae: 0.0103 - val_loss: 0.0012 - val_mae: 0.0221\n",
      "Epoch 88/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - loss: 1.9084e-04 - mae: 0.0103 - val_loss: 0.0012 - val_mae: 0.0225\n",
      "Epoch 89/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 21ms/step - loss: 1.9132e-04 - mae: 0.0103 - val_loss: 0.0012 - val_mae: 0.0219\n",
      "Epoch 90/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 21ms/step - loss: 1.9035e-04 - mae: 0.0103 - val_loss: 9.8746e-04 - val_mae: 0.0177\n",
      "Epoch 91/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - loss: 1.9124e-04 - mae: 0.0103 - val_loss: 0.0012 - val_mae: 0.0223\n",
      "Epoch 92/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - loss: 1.9121e-04 - mae: 0.0103 - val_loss: 0.0013 - val_mae: 0.0234\n",
      "Epoch 93/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - loss: 1.9104e-04 - mae: 0.0103 - val_loss: 0.0010 - val_mae: 0.0192\n",
      "Epoch 94/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - loss: 1.9030e-04 - mae: 0.0103 - val_loss: 0.0011 - val_mae: 0.0209\n",
      "Epoch 95/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - loss: 1.8991e-04 - mae: 0.0103 - val_loss: 0.0012 - val_mae: 0.0225\n",
      "Epoch 96/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - loss: 1.9066e-04 - mae: 0.0103 - val_loss: 0.0012 - val_mae: 0.0216\n",
      "Epoch 97/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - loss: 1.9173e-04 - mae: 0.0103 - val_loss: 0.0012 - val_mae: 0.0221\n",
      "Epoch 98/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - loss: 1.9183e-04 - mae: 0.0103 - val_loss: 0.0011 - val_mae: 0.0208\n",
      "Epoch 99/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 24ms/step - loss: 1.9031e-04 - mae: 0.0103 - val_loss: 0.0012 - val_mae: 0.0223\n",
      "Epoch 100/100\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 22ms/step - loss: 1.9125e-04 - mae: 0.0103 - val_loss: 0.0011 - val_mae: 0.0207\n",
      "\u001b[1m491/491\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step\n",
      "✅ Done with wheat_Mysore_daily.csv | MAE=461.68, RMSE=693.86, R2=0.3077, MAPE=28.07%, Accuracy=71.93%\n",
      "Saved updated CSV with Date, Actual & Predicted: tat_mqa_output_csv\\wheat_Mysore_daily_tat_mqa_updated.csv\n",
      "🚀 Processing: wheat_Raichur_daily.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_41\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_41\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_query_attention_19      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">17,216</span> │ input_layer_41[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiQueryAttention</span>)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_82 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_query_attention_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                               │                           │                 │ input_layer_41[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_82        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_82[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_263 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ layer_normalization_82[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_264 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dense_263[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_83 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_82[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                               │                           │                 │ dense_264[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_83        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_83[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_41   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_83[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_265 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ global_average_pooling1d_… │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_41 (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_query_attention_19      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │          \u001b[38;5;34m17,216\u001b[0m │ input_layer_41[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mMultiQueryAttention\u001b[0m)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_82 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ multi_query_attention_19[\u001b[38;5;34m…\u001b[0m │\n",
       "│                               │                           │                 │ input_layer_41[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_82        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ add_82[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_263 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │           \u001b[38;5;34m8,320\u001b[0m │ layer_normalization_82[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_264 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │             \u001b[38;5;34m129\u001b[0m │ dense_263[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_83 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_82[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                               │                           │                 │ dense_264[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_83        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ add_83[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_41   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_83[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_265 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │              \u001b[38;5;34m65\u001b[0m │ global_average_pooling1d_… │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,986</span> (101.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25,986\u001b[0m (101.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,986</span> (101.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m25,986\u001b[0m (101.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 20ms/step - loss: 0.0294 - mae: 0.1161 - val_loss: 0.0138 - val_mae: 0.1041\n",
      "Epoch 2/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 23ms/step - loss: 0.0102 - mae: 0.0783 - val_loss: 0.0163 - val_mae: 0.1151\n",
      "Epoch 3/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 18ms/step - loss: 0.0089 - mae: 0.0719 - val_loss: 0.0110 - val_mae: 0.0878\n",
      "Epoch 4/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - loss: 0.0080 - mae: 0.0666 - val_loss: 0.0104 - val_mae: 0.0786\n",
      "Epoch 5/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 0.0080 - mae: 0.0666 - val_loss: 0.0125 - val_mae: 0.1029\n",
      "Epoch 6/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 14ms/step - loss: 0.0077 - mae: 0.0642 - val_loss: 0.0087 - val_mae: 0.0755\n",
      "Epoch 7/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - loss: 0.0076 - mae: 0.0633 - val_loss: 0.0109 - val_mae: 0.0975\n",
      "Epoch 8/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - loss: 0.0077 - mae: 0.0640 - val_loss: 0.0149 - val_mae: 0.1112\n",
      "Epoch 9/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - loss: 0.0075 - mae: 0.0626 - val_loss: 0.0068 - val_mae: 0.0677\n",
      "Epoch 10/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - loss: 0.0076 - mae: 0.0634 - val_loss: 0.0069 - val_mae: 0.0751\n",
      "Epoch 11/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - loss: 0.0074 - mae: 0.0611 - val_loss: 0.0062 - val_mae: 0.0589\n",
      "Epoch 12/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - loss: 0.0076 - mae: 0.0629 - val_loss: 0.0057 - val_mae: 0.0664\n",
      "Epoch 13/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 18ms/step - loss: 0.0074 - mae: 0.0614 - val_loss: 0.0063 - val_mae: 0.0743\n",
      "Epoch 14/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - loss: 0.0073 - mae: 0.0607 - val_loss: 0.0073 - val_mae: 0.0812\n",
      "Epoch 15/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - loss: 0.0073 - mae: 0.0609 - val_loss: 0.0052 - val_mae: 0.0598\n",
      "Epoch 16/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 14ms/step - loss: 0.0073 - mae: 0.0611 - val_loss: 0.0052 - val_mae: 0.0601\n",
      "Epoch 17/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - loss: 0.0072 - mae: 0.0597 - val_loss: 0.0077 - val_mae: 0.0833\n",
      "Epoch 18/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 14ms/step - loss: 0.0073 - mae: 0.0606 - val_loss: 0.0049 - val_mae: 0.0644\n",
      "Epoch 19/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 0.0072 - mae: 0.0602 - val_loss: 0.0050 - val_mae: 0.0637\n",
      "Epoch 20/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - loss: 0.0071 - mae: 0.0589 - val_loss: 0.0043 - val_mae: 0.0517\n",
      "Epoch 21/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 0.0071 - mae: 0.0594 - val_loss: 0.0042 - val_mae: 0.0525\n",
      "Epoch 22/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 14ms/step - loss: 0.0072 - mae: 0.0602 - val_loss: 0.0055 - val_mae: 0.0695\n",
      "Epoch 23/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 14ms/step - loss: 0.0072 - mae: 0.0601 - val_loss: 0.0043 - val_mae: 0.0572\n",
      "Epoch 24/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - loss: 0.0070 - mae: 0.0584 - val_loss: 0.0055 - val_mae: 0.0515\n",
      "Epoch 25/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - loss: 0.0071 - mae: 0.0592 - val_loss: 0.0043 - val_mae: 0.0556\n",
      "Epoch 26/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - loss: 0.0070 - mae: 0.0587 - val_loss: 0.0043 - val_mae: 0.0528\n",
      "Epoch 27/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - loss: 0.0071 - mae: 0.0588 - val_loss: 0.0051 - val_mae: 0.0674\n",
      "Epoch 28/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - loss: 0.0071 - mae: 0.0588 - val_loss: 0.0056 - val_mae: 0.0515\n",
      "Epoch 29/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - loss: 0.0071 - mae: 0.0589 - val_loss: 0.0047 - val_mae: 0.0505\n",
      "Epoch 30/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - loss: 0.0070 - mae: 0.0586 - val_loss: 0.0041 - val_mae: 0.0518\n",
      "Epoch 31/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - loss: 0.0070 - mae: 0.0588 - val_loss: 0.0046 - val_mae: 0.0575\n",
      "Epoch 32/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - loss: 0.0070 - mae: 0.0585 - val_loss: 0.0050 - val_mae: 0.0562\n",
      "Epoch 33/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - loss: 0.0071 - mae: 0.0588 - val_loss: 0.0041 - val_mae: 0.0524\n",
      "Epoch 34/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - loss: 0.0070 - mae: 0.0587 - val_loss: 0.0044 - val_mae: 0.0518\n",
      "Epoch 35/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 14ms/step - loss: 0.0070 - mae: 0.0584 - val_loss: 0.0044 - val_mae: 0.0591\n",
      "Epoch 36/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - loss: 0.0070 - mae: 0.0587 - val_loss: 0.0047 - val_mae: 0.0597\n",
      "Epoch 37/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 18ms/step - loss: 0.0070 - mae: 0.0590 - val_loss: 0.0043 - val_mae: 0.0530\n",
      "Epoch 38/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 18ms/step - loss: 0.0071 - mae: 0.0588 - val_loss: 0.0047 - val_mae: 0.0623\n",
      "Epoch 39/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - loss: 0.0070 - mae: 0.0582 - val_loss: 0.0042 - val_mae: 0.0505\n",
      "Epoch 40/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 18ms/step - loss: 0.0070 - mae: 0.0583 - val_loss: 0.0042 - val_mae: 0.0529\n",
      "Epoch 41/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - loss: 0.0070 - mae: 0.0579 - val_loss: 0.0052 - val_mae: 0.0654\n",
      "Epoch 42/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - loss: 0.0070 - mae: 0.0585 - val_loss: 0.0047 - val_mae: 0.0511\n",
      "Epoch 43/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - loss: 0.0070 - mae: 0.0582 - val_loss: 0.0047 - val_mae: 0.0625\n",
      "Epoch 44/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - loss: 0.0070 - mae: 0.0584 - val_loss: 0.0042 - val_mae: 0.0556\n",
      "Epoch 45/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 18ms/step - loss: 0.0070 - mae: 0.0581 - val_loss: 0.0059 - val_mae: 0.0702\n",
      "Epoch 46/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - loss: 0.0070 - mae: 0.0580 - val_loss: 0.0045 - val_mae: 0.0541\n",
      "Epoch 47/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 18ms/step - loss: 0.0070 - mae: 0.0581 - val_loss: 0.0045 - val_mae: 0.0609\n",
      "Epoch 48/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - loss: 0.0070 - mae: 0.0588 - val_loss: 0.0051 - val_mae: 0.0665\n",
      "Epoch 49/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - loss: 0.0070 - mae: 0.0580 - val_loss: 0.0049 - val_mae: 0.0546\n",
      "Epoch 50/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 18ms/step - loss: 0.0070 - mae: 0.0585 - val_loss: 0.0054 - val_mae: 0.0682\n",
      "Epoch 51/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - loss: 0.0070 - mae: 0.0579 - val_loss: 0.0045 - val_mae: 0.0576\n",
      "Epoch 52/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 18ms/step - loss: 0.0070 - mae: 0.0583 - val_loss: 0.0053 - val_mae: 0.0649\n",
      "Epoch 53/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 18ms/step - loss: 0.0069 - mae: 0.0577 - val_loss: 0.0046 - val_mae: 0.0611\n",
      "Epoch 54/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - loss: 0.0070 - mae: 0.0580 - val_loss: 0.0052 - val_mae: 0.0662\n",
      "Epoch 55/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 18ms/step - loss: 0.0070 - mae: 0.0581 - val_loss: 0.0046 - val_mae: 0.0585\n",
      "Epoch 56/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - loss: 0.0070 - mae: 0.0582 - val_loss: 0.0058 - val_mae: 0.0683\n",
      "Epoch 57/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - loss: 0.0070 - mae: 0.0580 - val_loss: 0.0042 - val_mae: 0.0550\n",
      "Epoch 58/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - loss: 0.0070 - mae: 0.0579 - val_loss: 0.0048 - val_mae: 0.0623\n",
      "Epoch 59/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - loss: 0.0070 - mae: 0.0579 - val_loss: 0.0051 - val_mae: 0.0598\n",
      "Epoch 60/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - loss: 0.0069 - mae: 0.0576 - val_loss: 0.0057 - val_mae: 0.0708\n",
      "Epoch 61/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - loss: 0.0070 - mae: 0.0580 - val_loss: 0.0051 - val_mae: 0.0645\n",
      "Epoch 62/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - loss: 0.0070 - mae: 0.0583 - val_loss: 0.0051 - val_mae: 0.0628\n",
      "Epoch 63/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 18ms/step - loss: 0.0070 - mae: 0.0579 - val_loss: 0.0056 - val_mae: 0.0665\n",
      "Epoch 64/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - loss: 0.0070 - mae: 0.0581 - val_loss: 0.0063 - val_mae: 0.0745\n",
      "Epoch 65/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - loss: 0.0070 - mae: 0.0579 - val_loss: 0.0059 - val_mae: 0.0702\n",
      "Epoch 66/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - loss: 0.0070 - mae: 0.0576 - val_loss: 0.0072 - val_mae: 0.0781\n",
      "Epoch 67/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 18ms/step - loss: 0.0070 - mae: 0.0576 - val_loss: 0.0067 - val_mae: 0.0755\n",
      "Epoch 68/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 18ms/step - loss: 0.0070 - mae: 0.0577 - val_loss: 0.0056 - val_mae: 0.0679\n",
      "Epoch 69/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - loss: 0.0070 - mae: 0.0578 - val_loss: 0.0064 - val_mae: 0.0729\n",
      "Epoch 70/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - loss: 0.0069 - mae: 0.0577 - val_loss: 0.0057 - val_mae: 0.0664\n",
      "Epoch 71/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - loss: 0.0069 - mae: 0.0575 - val_loss: 0.0063 - val_mae: 0.0721\n",
      "Epoch 72/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - loss: 0.0069 - mae: 0.0574 - val_loss: 0.0067 - val_mae: 0.0727\n",
      "Epoch 73/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - loss: 0.0069 - mae: 0.0576 - val_loss: 0.0058 - val_mae: 0.0691\n",
      "Epoch 74/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - loss: 0.0070 - mae: 0.0581 - val_loss: 0.0060 - val_mae: 0.0703\n",
      "Epoch 75/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - loss: 0.0069 - mae: 0.0576 - val_loss: 0.0062 - val_mae: 0.0703\n",
      "Epoch 76/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - loss: 0.0069 - mae: 0.0576 - val_loss: 0.0072 - val_mae: 0.0782\n",
      "Epoch 77/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 18ms/step - loss: 0.0069 - mae: 0.0576 - val_loss: 0.0066 - val_mae: 0.0735\n",
      "Epoch 78/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - loss: 0.0070 - mae: 0.0579 - val_loss: 0.0061 - val_mae: 0.0697\n",
      "Epoch 79/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 18ms/step - loss: 0.0069 - mae: 0.0573 - val_loss: 0.0083 - val_mae: 0.0827\n",
      "Epoch 80/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - loss: 0.0069 - mae: 0.0576 - val_loss: 0.0068 - val_mae: 0.0759\n",
      "Epoch 81/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - loss: 0.0069 - mae: 0.0575 - val_loss: 0.0069 - val_mae: 0.0753\n",
      "Epoch 82/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - loss: 0.0069 - mae: 0.0577 - val_loss: 0.0067 - val_mae: 0.0760\n",
      "Epoch 83/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - loss: 0.0070 - mae: 0.0578 - val_loss: 0.0060 - val_mae: 0.0711\n",
      "Epoch 84/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - loss: 0.0069 - mae: 0.0576 - val_loss: 0.0059 - val_mae: 0.0689\n",
      "Epoch 85/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - loss: 0.0069 - mae: 0.0573 - val_loss: 0.0056 - val_mae: 0.0691\n",
      "Epoch 86/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 18ms/step - loss: 0.0069 - mae: 0.0574 - val_loss: 0.0068 - val_mae: 0.0763\n",
      "Epoch 87/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - loss: 0.0069 - mae: 0.0575 - val_loss: 0.0076 - val_mae: 0.0803\n",
      "Epoch 88/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - loss: 0.0069 - mae: 0.0574 - val_loss: 0.0068 - val_mae: 0.0752\n",
      "Epoch 89/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - loss: 0.0069 - mae: 0.0574 - val_loss: 0.0078 - val_mae: 0.0814\n",
      "Epoch 90/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - loss: 0.0069 - mae: 0.0573 - val_loss: 0.0070 - val_mae: 0.0771\n",
      "Epoch 91/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - loss: 0.0069 - mae: 0.0575 - val_loss: 0.0072 - val_mae: 0.0783\n",
      "Epoch 92/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - loss: 0.0069 - mae: 0.0574 - val_loss: 0.0068 - val_mae: 0.0760\n",
      "Epoch 93/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - loss: 0.0069 - mae: 0.0574 - val_loss: 0.0062 - val_mae: 0.0718\n",
      "Epoch 94/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 18ms/step - loss: 0.0069 - mae: 0.0577 - val_loss: 0.0065 - val_mae: 0.0732\n",
      "Epoch 95/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - loss: 0.0069 - mae: 0.0574 - val_loss: 0.0066 - val_mae: 0.0735\n",
      "Epoch 96/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - loss: 0.0069 - mae: 0.0573 - val_loss: 0.0072 - val_mae: 0.0784\n",
      "Epoch 97/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 18ms/step - loss: 0.0069 - mae: 0.0576 - val_loss: 0.0065 - val_mae: 0.0741\n",
      "Epoch 98/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - loss: 0.0069 - mae: 0.0573 - val_loss: 0.0079 - val_mae: 0.0826\n",
      "Epoch 99/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 18ms/step - loss: 0.0069 - mae: 0.0574 - val_loss: 0.0068 - val_mae: 0.0765\n",
      "Epoch 100/100\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - loss: 0.0069 - mae: 0.0577 - val_loss: 0.0064 - val_mae: 0.0728\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step\n",
      "✅ Done with wheat_Raichur_daily.csv | MAE=178.39, RMSE=237.83, R2=0.5821, MAPE=10.76%, Accuracy=89.24%\n",
      "Saved updated CSV with Date, Actual & Predicted: tat_mqa_output_csv\\wheat_Raichur_daily_tat_mqa_updated.csv\n",
      "🚀 Processing: wheat_Shimoga_daily.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_42\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_42\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_42 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_query_attention_20      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">17,216</span> │ input_layer_42[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiQueryAttention</span>)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_84 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_query_attention_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                               │                           │                 │ input_layer_42[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_84        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_84[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_273 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ layer_normalization_84[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_274 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dense_273[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_85 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_84[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                               │                           │                 │ dense_274[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_85        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_85[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_42   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_85[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_275 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ global_average_pooling1d_… │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_42 (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_query_attention_20      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │          \u001b[38;5;34m17,216\u001b[0m │ input_layer_42[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mMultiQueryAttention\u001b[0m)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_84 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ multi_query_attention_20[\u001b[38;5;34m…\u001b[0m │\n",
       "│                               │                           │                 │ input_layer_42[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_84        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ add_84[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_273 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │           \u001b[38;5;34m8,320\u001b[0m │ layer_normalization_84[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_274 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │             \u001b[38;5;34m129\u001b[0m │ dense_273[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_85 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_84[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                               │                           │                 │ dense_274[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_85        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ add_85[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_42   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_85[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_275 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │              \u001b[38;5;34m65\u001b[0m │ global_average_pooling1d_… │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,986</span> (101.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25,986\u001b[0m (101.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,986</span> (101.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m25,986\u001b[0m (101.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - loss: 0.0643 - mae: 0.0921 - val_loss: 9.9382e-04 - val_mae: 0.0183\n",
      "Epoch 2/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - loss: 0.0028 - mae: 0.0415 - val_loss: 7.2851e-04 - val_mae: 0.0117\n",
      "Epoch 3/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 18ms/step - loss: 0.0012 - mae: 0.0281 - val_loss: 8.1592e-04 - val_mae: 0.0147\n",
      "Epoch 4/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - loss: 6.6147e-04 - mae: 0.0204 - val_loss: 6.8435e-04 - val_mae: 0.0099\n",
      "Epoch 5/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - loss: 3.7340e-04 - mae: 0.0154 - val_loss: 7.1828e-04 - val_mae: 0.0121\n",
      "Epoch 6/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - loss: 2.4352e-04 - mae: 0.0124 - val_loss: 6.7408e-04 - val_mae: 0.0098\n",
      "Epoch 7/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - loss: 1.7361e-04 - mae: 0.0105 - val_loss: 6.7270e-04 - val_mae: 0.0098\n",
      "Epoch 8/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - loss: 1.3478e-04 - mae: 0.0092 - val_loss: 6.8933e-04 - val_mae: 0.0101\n",
      "Epoch 9/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - loss: 1.1442e-04 - mae: 0.0086 - val_loss: 6.7397e-04 - val_mae: 0.0097\n",
      "Epoch 10/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - loss: 1.2303e-04 - mae: 0.0089 - val_loss: 6.9096e-04 - val_mae: 0.0102\n",
      "Epoch 11/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - loss: 1.1204e-04 - mae: 0.0085 - val_loss: 6.9538e-04 - val_mae: 0.0103\n",
      "Epoch 12/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 18ms/step - loss: 1.1524e-04 - mae: 0.0086 - val_loss: 8.0219e-04 - val_mae: 0.0130\n",
      "Epoch 13/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - loss: 1.0871e-04 - mae: 0.0083 - val_loss: 7.1774e-04 - val_mae: 0.0109\n",
      "Epoch 14/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - loss: 1.2653e-04 - mae: 0.0090 - val_loss: 6.8341e-04 - val_mae: 0.0097\n",
      "Epoch 15/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - loss: 9.5260e-05 - mae: 0.0079 - val_loss: 7.3210e-04 - val_mae: 0.0126\n",
      "Epoch 16/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - loss: 1.0589e-04 - mae: 0.0082 - val_loss: 7.0208e-04 - val_mae: 0.0115\n",
      "Epoch 17/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - loss: 8.7765e-05 - mae: 0.0075 - val_loss: 6.7827e-04 - val_mae: 0.0104\n",
      "Epoch 18/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - loss: 8.3810e-05 - mae: 0.0074 - val_loss: 6.7619e-04 - val_mae: 0.0097\n",
      "Epoch 19/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - loss: 8.1847e-05 - mae: 0.0073 - val_loss: 6.7526e-04 - val_mae: 0.0098\n",
      "Epoch 20/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - loss: 8.7973e-05 - mae: 0.0075 - val_loss: 7.1796e-04 - val_mae: 0.0108\n",
      "Epoch 21/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - loss: 7.8947e-05 - mae: 0.0072 - val_loss: 8.0425e-04 - val_mae: 0.0131\n",
      "Epoch 22/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - loss: 8.0717e-05 - mae: 0.0073 - val_loss: 6.9757e-04 - val_mae: 0.0102\n",
      "Epoch 23/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - loss: 7.5904e-05 - mae: 0.0070 - val_loss: 6.8202e-04 - val_mae: 0.0097\n",
      "Epoch 24/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - loss: 7.2384e-05 - mae: 0.0069 - val_loss: 7.7692e-04 - val_mae: 0.0137\n",
      "Epoch 25/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - loss: 7.9004e-05 - mae: 0.0072 - val_loss: 6.8423e-04 - val_mae: 0.0098\n",
      "Epoch 26/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - loss: 7.8318e-05 - mae: 0.0072 - val_loss: 6.8432e-04 - val_mae: 0.0098\n",
      "Epoch 27/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - loss: 7.6458e-05 - mae: 0.0071 - val_loss: 6.7746e-04 - val_mae: 0.0097\n",
      "Epoch 28/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - loss: 7.6832e-05 - mae: 0.0071 - val_loss: 7.1469e-04 - val_mae: 0.0108\n",
      "Epoch 29/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - loss: 7.6715e-05 - mae: 0.0071 - val_loss: 7.4344e-04 - val_mae: 0.0115\n",
      "Epoch 30/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - loss: 7.3117e-05 - mae: 0.0070 - val_loss: 6.9525e-04 - val_mae: 0.0102\n",
      "Epoch 31/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 18ms/step - loss: 7.2583e-05 - mae: 0.0070 - val_loss: 6.8255e-04 - val_mae: 0.0097\n",
      "Epoch 32/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 19ms/step - loss: 7.3193e-05 - mae: 0.0070 - val_loss: 7.1287e-04 - val_mae: 0.0105\n",
      "Epoch 33/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 19ms/step - loss: 7.0991e-05 - mae: 0.0069 - val_loss: 7.2582e-04 - val_mae: 0.0111\n",
      "Epoch 34/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 7.0915e-05 - mae: 0.0069 - val_loss: 7.0949e-04 - val_mae: 0.0106\n",
      "Epoch 35/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 19ms/step - loss: 7.3891e-05 - mae: 0.0070 - val_loss: 6.8307e-04 - val_mae: 0.0104\n",
      "Epoch 36/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 18ms/step - loss: 7.3095e-05 - mae: 0.0070 - val_loss: 7.6894e-04 - val_mae: 0.0123\n",
      "Epoch 37/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 7.2329e-05 - mae: 0.0069 - val_loss: 7.1776e-04 - val_mae: 0.0108\n",
      "Epoch 38/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 17ms/step - loss: 7.0713e-05 - mae: 0.0069 - val_loss: 7.3923e-04 - val_mae: 0.0113\n",
      "Epoch 39/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 19ms/step - loss: 7.1520e-05 - mae: 0.0069 - val_loss: 6.9313e-04 - val_mae: 0.0102\n",
      "Epoch 40/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 18ms/step - loss: 7.1178e-05 - mae: 0.0069 - val_loss: 8.3278e-04 - val_mae: 0.0138\n",
      "Epoch 41/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 18ms/step - loss: 7.0040e-05 - mae: 0.0068 - val_loss: 7.1467e-04 - val_mae: 0.0108\n",
      "Epoch 42/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 7.3110e-05 - mae: 0.0069 - val_loss: 7.0297e-04 - val_mae: 0.0105\n",
      "Epoch 43/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 18ms/step - loss: 7.1989e-05 - mae: 0.0069 - val_loss: 6.7794e-04 - val_mae: 0.0098\n",
      "Epoch 44/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 7.1107e-05 - mae: 0.0069 - val_loss: 6.9576e-04 - val_mae: 0.0102\n",
      "Epoch 45/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 19ms/step - loss: 7.1035e-05 - mae: 0.0069 - val_loss: 6.7749e-04 - val_mae: 0.0100\n",
      "Epoch 46/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 18ms/step - loss: 6.9909e-05 - mae: 0.0068 - val_loss: 6.8416e-04 - val_mae: 0.0098\n",
      "Epoch 47/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 19ms/step - loss: 7.1351e-05 - mae: 0.0069 - val_loss: 6.7830e-04 - val_mae: 0.0098\n",
      "Epoch 48/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 7.1564e-05 - mae: 0.0069 - val_loss: 6.7915e-04 - val_mae: 0.0099\n",
      "Epoch 49/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 7.1967e-05 - mae: 0.0069 - val_loss: 6.7920e-04 - val_mae: 0.0100\n",
      "Epoch 50/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - loss: 6.8046e-05 - mae: 0.0067 - val_loss: 7.5048e-04 - val_mae: 0.0118\n",
      "Epoch 51/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 18ms/step - loss: 6.9484e-05 - mae: 0.0068 - val_loss: 6.8060e-04 - val_mae: 0.0101\n",
      "Epoch 52/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 18ms/step - loss: 6.8792e-05 - mae: 0.0068 - val_loss: 6.8020e-04 - val_mae: 0.0098\n",
      "Epoch 53/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 18ms/step - loss: 6.9915e-05 - mae: 0.0068 - val_loss: 6.8578e-04 - val_mae: 0.0105\n",
      "Epoch 54/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 6.8075e-05 - mae: 0.0067 - val_loss: 6.8904e-04 - val_mae: 0.0108\n",
      "Epoch 55/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 7.0719e-05 - mae: 0.0069 - val_loss: 6.8617e-04 - val_mae: 0.0099\n",
      "Epoch 56/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - loss: 6.7757e-05 - mae: 0.0067 - val_loss: 6.9202e-04 - val_mae: 0.0100\n",
      "Epoch 57/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - loss: 6.8247e-05 - mae: 0.0068 - val_loss: 6.9788e-04 - val_mae: 0.0103\n",
      "Epoch 58/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 17ms/step - loss: 6.9052e-05 - mae: 0.0068 - val_loss: 6.8187e-04 - val_mae: 0.0098\n",
      "Epoch 59/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 18ms/step - loss: 6.7458e-05 - mae: 0.0067 - val_loss: 6.8921e-04 - val_mae: 0.0099\n",
      "Epoch 60/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - loss: 6.8937e-05 - mae: 0.0068 - val_loss: 6.8374e-04 - val_mae: 0.0102\n",
      "Epoch 61/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 20ms/step - loss: 6.6724e-05 - mae: 0.0067 - val_loss: 6.8975e-04 - val_mae: 0.0100\n",
      "Epoch 62/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - loss: 6.7100e-05 - mae: 0.0067 - val_loss: 6.8813e-04 - val_mae: 0.0099\n",
      "Epoch 63/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - loss: 6.8326e-05 - mae: 0.0067 - val_loss: 6.7979e-04 - val_mae: 0.0098\n",
      "Epoch 64/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 18ms/step - loss: 6.7811e-05 - mae: 0.0067 - val_loss: 6.9464e-04 - val_mae: 0.0101\n",
      "Epoch 65/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - loss: 6.7347e-05 - mae: 0.0067 - val_loss: 6.9503e-04 - val_mae: 0.0102\n",
      "Epoch 66/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 18ms/step - loss: 6.6619e-05 - mae: 0.0067 - val_loss: 7.0473e-04 - val_mae: 0.0104\n",
      "Epoch 67/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - loss: 6.7399e-05 - mae: 0.0067 - val_loss: 7.1135e-04 - val_mae: 0.0107\n",
      "Epoch 68/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - loss: 6.6381e-05 - mae: 0.0067 - val_loss: 6.9162e-04 - val_mae: 0.0100\n",
      "Epoch 69/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 18ms/step - loss: 6.5905e-05 - mae: 0.0067 - val_loss: 6.8736e-04 - val_mae: 0.0098\n",
      "Epoch 70/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 6.5942e-05 - mae: 0.0067 - val_loss: 7.0299e-04 - val_mae: 0.0104\n",
      "Epoch 71/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 6.5319e-05 - mae: 0.0066 - val_loss: 6.8360e-04 - val_mae: 0.0105\n",
      "Epoch 72/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 6.5171e-05 - mae: 0.0066 - val_loss: 6.8025e-04 - val_mae: 0.0098\n",
      "Epoch 73/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 19ms/step - loss: 6.4058e-05 - mae: 0.0066 - val_loss: 6.8607e-04 - val_mae: 0.0101\n",
      "Epoch 74/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 18ms/step - loss: 6.4830e-05 - mae: 0.0066 - val_loss: 6.8401e-04 - val_mae: 0.0098\n",
      "Epoch 75/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 6.5611e-05 - mae: 0.0066 - val_loss: 6.9012e-04 - val_mae: 0.0103\n",
      "Epoch 76/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - loss: 6.3868e-05 - mae: 0.0066 - val_loss: 6.8354e-04 - val_mae: 0.0102\n",
      "Epoch 77/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - loss: 6.3131e-05 - mae: 0.0065 - val_loss: 6.8935e-04 - val_mae: 0.0099\n",
      "Epoch 78/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - loss: 6.3681e-05 - mae: 0.0065 - val_loss: 6.8343e-04 - val_mae: 0.0098\n",
      "Epoch 79/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 18ms/step - loss: 6.3037e-05 - mae: 0.0065 - val_loss: 6.8690e-04 - val_mae: 0.0101\n",
      "Epoch 80/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - loss: 6.3656e-05 - mae: 0.0065 - val_loss: 6.9103e-04 - val_mae: 0.0099\n",
      "Epoch 81/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 19ms/step - loss: 6.3865e-05 - mae: 0.0066 - val_loss: 6.8286e-04 - val_mae: 0.0099\n",
      "Epoch 82/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 19ms/step - loss: 6.3587e-05 - mae: 0.0065 - val_loss: 6.8907e-04 - val_mae: 0.0099\n",
      "Epoch 83/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 6.2823e-05 - mae: 0.0065 - val_loss: 6.9179e-04 - val_mae: 0.0100\n",
      "Epoch 84/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 19ms/step - loss: 6.3487e-05 - mae: 0.0065 - val_loss: 6.9017e-04 - val_mae: 0.0099\n",
      "Epoch 85/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - loss: 6.3445e-05 - mae: 0.0065 - val_loss: 6.9243e-04 - val_mae: 0.0100\n",
      "Epoch 86/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - loss: 6.3049e-05 - mae: 0.0065 - val_loss: 6.9161e-04 - val_mae: 0.0100\n",
      "Epoch 87/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - loss: 6.2621e-05 - mae: 0.0065 - val_loss: 6.9217e-04 - val_mae: 0.0099\n",
      "Epoch 88/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - loss: 6.2682e-05 - mae: 0.0065 - val_loss: 6.8904e-04 - val_mae: 0.0099\n",
      "Epoch 89/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - loss: 6.2746e-05 - mae: 0.0065 - val_loss: 6.9107e-04 - val_mae: 0.0100\n",
      "Epoch 90/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - loss: 6.2674e-05 - mae: 0.0065 - val_loss: 6.9226e-04 - val_mae: 0.0100\n",
      "Epoch 91/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 6.2229e-05 - mae: 0.0065 - val_loss: 6.9154e-04 - val_mae: 0.0100\n",
      "Epoch 92/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - loss: 6.2560e-05 - mae: 0.0065 - val_loss: 6.8756e-04 - val_mae: 0.0099\n",
      "Epoch 93/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 18ms/step - loss: 6.2392e-05 - mae: 0.0065 - val_loss: 6.8747e-04 - val_mae: 0.0099\n",
      "Epoch 94/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 18ms/step - loss: 6.2018e-05 - mae: 0.0065 - val_loss: 6.8878e-04 - val_mae: 0.0099\n",
      "Epoch 95/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - loss: 6.2479e-05 - mae: 0.0065 - val_loss: 6.8481e-04 - val_mae: 0.0100\n",
      "Epoch 96/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - loss: 6.2553e-05 - mae: 0.0065 - val_loss: 6.8652e-04 - val_mae: 0.0099\n",
      "Epoch 97/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - loss: 6.2403e-05 - mae: 0.0065 - val_loss: 6.8981e-04 - val_mae: 0.0105\n",
      "Epoch 98/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - loss: 6.2253e-05 - mae: 0.0065 - val_loss: 6.9605e-04 - val_mae: 0.0103\n",
      "Epoch 99/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - loss: 6.2383e-05 - mae: 0.0065 - val_loss: 6.8675e-04 - val_mae: 0.0099\n",
      "Epoch 100/100\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - loss: 6.2149e-05 - mae: 0.0065 - val_loss: 6.8616e-04 - val_mae: 0.0099\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step\n",
      "✅ Done with wheat_Shimoga_daily.csv | MAE=437.04, RMSE=841.02, R2=0.1979, MAPE=19.81%, Accuracy=80.19%\n",
      "Saved updated CSV with Date, Actual & Predicted: tat_mqa_output_csv\\wheat_Shimoga_daily_tat_mqa_updated.csv\n",
      "🚀 Processing: wheat_Tumkur_daily.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_43\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_43\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_43 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_query_attention_21      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">17,216</span> │ input_layer_43[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiQueryAttention</span>)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_86 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_query_attention_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                               │                           │                 │ input_layer_43[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_86        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_86[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_283 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ layer_normalization_86[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_284 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dense_283[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_87 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_86[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                               │                           │                 │ dense_284[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_87        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_87[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_43   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_87[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_285 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ global_average_pooling1d_… │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_43 (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_query_attention_21      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │          \u001b[38;5;34m17,216\u001b[0m │ input_layer_43[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mMultiQueryAttention\u001b[0m)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_86 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ multi_query_attention_21[\u001b[38;5;34m…\u001b[0m │\n",
       "│                               │                           │                 │ input_layer_43[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_86        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ add_86[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_283 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │           \u001b[38;5;34m8,320\u001b[0m │ layer_normalization_86[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_284 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │             \u001b[38;5;34m129\u001b[0m │ dense_283[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_87 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_86[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                               │                           │                 │ dense_284[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_87        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ add_87[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_43   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_87[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_285 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │              \u001b[38;5;34m65\u001b[0m │ global_average_pooling1d_… │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,986</span> (101.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25,986\u001b[0m (101.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,986</span> (101.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m25,986\u001b[0m (101.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 18ms/step - loss: 0.0552 - mae: 0.0936 - val_loss: 0.0070 - val_mae: 0.0335\n",
      "Epoch 2/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - loss: 0.0039 - mae: 0.0474 - val_loss: 0.0070 - val_mae: 0.0416\n",
      "Epoch 3/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - loss: 0.0028 - mae: 0.0388 - val_loss: 0.0055 - val_mae: 0.0334\n",
      "Epoch 4/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0022 - mae: 0.0334 - val_loss: 0.0052 - val_mae: 0.0327\n",
      "Epoch 5/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - loss: 0.0019 - mae: 0.0291 - val_loss: 0.0054 - val_mae: 0.0378\n",
      "Epoch 6/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - loss: 0.0017 - mae: 0.0277 - val_loss: 0.0062 - val_mae: 0.0438\n",
      "Epoch 7/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - loss: 0.0016 - mae: 0.0259 - val_loss: 0.0062 - val_mae: 0.0430\n",
      "Epoch 8/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - loss: 0.0015 - mae: 0.0249 - val_loss: 0.0053 - val_mae: 0.0362\n",
      "Epoch 9/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - loss: 0.0016 - mae: 0.0256 - val_loss: 0.0053 - val_mae: 0.0354\n",
      "Epoch 10/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0015 - mae: 0.0246 - val_loss: 0.0054 - val_mae: 0.0370\n",
      "Epoch 11/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - loss: 0.0015 - mae: 0.0232 - val_loss: 0.0052 - val_mae: 0.0327\n",
      "Epoch 12/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - loss: 0.0015 - mae: 0.0237 - val_loss: 0.0060 - val_mae: 0.0399\n",
      "Epoch 13/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - loss: 0.0014 - mae: 0.0232 - val_loss: 0.0052 - val_mae: 0.0334\n",
      "Epoch 14/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - loss: 0.0014 - mae: 0.0227 - val_loss: 0.0057 - val_mae: 0.0371\n",
      "Epoch 15/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - loss: 0.0014 - mae: 0.0226 - val_loss: 0.0054 - val_mae: 0.0351\n",
      "Epoch 16/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - loss: 0.0014 - mae: 0.0216 - val_loss: 0.0053 - val_mae: 0.0327\n",
      "Epoch 17/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - loss: 0.0014 - mae: 0.0230 - val_loss: 0.0083 - val_mae: 0.0552\n",
      "Epoch 18/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - loss: 0.0014 - mae: 0.0221 - val_loss: 0.0062 - val_mae: 0.0412\n",
      "Epoch 19/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - loss: 0.0014 - mae: 0.0215 - val_loss: 0.0062 - val_mae: 0.0401\n",
      "Epoch 20/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - loss: 0.0014 - mae: 0.0219 - val_loss: 0.0059 - val_mae: 0.0374\n",
      "Epoch 21/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - loss: 0.0013 - mae: 0.0211 - val_loss: 0.0054 - val_mae: 0.0354\n",
      "Epoch 22/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - loss: 0.0013 - mae: 0.0208 - val_loss: 0.0056 - val_mae: 0.0339\n",
      "Epoch 23/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - loss: 0.0013 - mae: 0.0210 - val_loss: 0.0053 - val_mae: 0.0326\n",
      "Epoch 24/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - loss: 0.0013 - mae: 0.0204 - val_loss: 0.0054 - val_mae: 0.0344\n",
      "Epoch 25/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - loss: 0.0013 - mae: 0.0201 - val_loss: 0.0055 - val_mae: 0.0340\n",
      "Epoch 26/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - loss: 0.0013 - mae: 0.0202 - val_loss: 0.0055 - val_mae: 0.0352\n",
      "Epoch 27/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - loss: 0.0013 - mae: 0.0203 - val_loss: 0.0053 - val_mae: 0.0332\n",
      "Epoch 28/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - loss: 0.0013 - mae: 0.0198 - val_loss: 0.0052 - val_mae: 0.0326\n",
      "Epoch 29/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - loss: 0.0013 - mae: 0.0197 - val_loss: 0.0056 - val_mae: 0.0351\n",
      "Epoch 30/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - loss: 0.0013 - mae: 0.0197 - val_loss: 0.0057 - val_mae: 0.0363\n",
      "Epoch 31/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - loss: 0.0013 - mae: 0.0197 - val_loss: 0.0063 - val_mae: 0.0392\n",
      "Epoch 32/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - loss: 0.0013 - mae: 0.0194 - val_loss: 0.0055 - val_mae: 0.0335\n",
      "Epoch 33/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - loss: 0.0013 - mae: 0.0194 - val_loss: 0.0050 - val_mae: 0.0329\n",
      "Epoch 34/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - loss: 0.0013 - mae: 0.0195 - val_loss: 0.0056 - val_mae: 0.0343\n",
      "Epoch 35/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - loss: 0.0013 - mae: 0.0194 - val_loss: 0.0051 - val_mae: 0.0331\n",
      "Epoch 36/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - loss: 0.0013 - mae: 0.0194 - val_loss: 0.0053 - val_mae: 0.0332\n",
      "Epoch 37/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - loss: 0.0013 - mae: 0.0190 - val_loss: 0.0054 - val_mae: 0.0327\n",
      "Epoch 38/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - loss: 0.0013 - mae: 0.0194 - val_loss: 0.0058 - val_mae: 0.0351\n",
      "Epoch 39/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - loss: 0.0013 - mae: 0.0194 - val_loss: 0.0054 - val_mae: 0.0336\n",
      "Epoch 40/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - loss: 0.0013 - mae: 0.0190 - val_loss: 0.0051 - val_mae: 0.0329\n",
      "Epoch 41/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - loss: 0.0013 - mae: 0.0192 - val_loss: 0.0058 - val_mae: 0.0348\n",
      "Epoch 42/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - loss: 0.0013 - mae: 0.0189 - val_loss: 0.0054 - val_mae: 0.0337\n",
      "Epoch 43/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - loss: 0.0013 - mae: 0.0191 - val_loss: 0.0059 - val_mae: 0.0361\n",
      "Epoch 44/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - loss: 0.0013 - mae: 0.0191 - val_loss: 0.0056 - val_mae: 0.0340\n",
      "Epoch 45/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - loss: 0.0013 - mae: 0.0190 - val_loss: 0.0053 - val_mae: 0.0327\n",
      "Epoch 46/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - loss: 0.0012 - mae: 0.0189 - val_loss: 0.0055 - val_mae: 0.0334\n",
      "Epoch 47/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - loss: 0.0012 - mae: 0.0188 - val_loss: 0.0055 - val_mae: 0.0338\n",
      "Epoch 48/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - loss: 0.0013 - mae: 0.0190 - val_loss: 0.0057 - val_mae: 0.0337\n",
      "Epoch 49/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - loss: 0.0012 - mae: 0.0190 - val_loss: 0.0063 - val_mae: 0.0379\n",
      "Epoch 50/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - loss: 0.0012 - mae: 0.0188 - val_loss: 0.0054 - val_mae: 0.0331\n",
      "Epoch 51/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - loss: 0.0012 - mae: 0.0189 - val_loss: 0.0056 - val_mae: 0.0332\n",
      "Epoch 52/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - loss: 0.0012 - mae: 0.0190 - val_loss: 0.0056 - val_mae: 0.0333\n",
      "Epoch 53/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - loss: 0.0012 - mae: 0.0187 - val_loss: 0.0061 - val_mae: 0.0352\n",
      "Epoch 54/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - loss: 0.0013 - mae: 0.0190 - val_loss: 0.0059 - val_mae: 0.0349\n",
      "Epoch 55/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - loss: 0.0012 - mae: 0.0188 - val_loss: 0.0058 - val_mae: 0.0343\n",
      "Epoch 56/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - loss: 0.0012 - mae: 0.0188 - val_loss: 0.0055 - val_mae: 0.0327\n",
      "Epoch 57/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - loss: 0.0012 - mae: 0.0188 - val_loss: 0.0055 - val_mae: 0.0328\n",
      "Epoch 58/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - loss: 0.0012 - mae: 0.0188 - val_loss: 0.0057 - val_mae: 0.0329\n",
      "Epoch 59/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - loss: 0.0012 - mae: 0.0189 - val_loss: 0.0058 - val_mae: 0.0334\n",
      "Epoch 60/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - loss: 0.0012 - mae: 0.0188 - val_loss: 0.0056 - val_mae: 0.0330\n",
      "Epoch 61/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - loss: 0.0012 - mae: 0.0188 - val_loss: 0.0058 - val_mae: 0.0341\n",
      "Epoch 62/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - loss: 0.0012 - mae: 0.0188 - val_loss: 0.0054 - val_mae: 0.0331\n",
      "Epoch 63/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - loss: 0.0012 - mae: 0.0188 - val_loss: 0.0056 - val_mae: 0.0331\n",
      "Epoch 64/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 18ms/step - loss: 0.0012 - mae: 0.0188 - val_loss: 0.0058 - val_mae: 0.0339\n",
      "Epoch 65/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - loss: 0.0012 - mae: 0.0188 - val_loss: 0.0060 - val_mae: 0.0347\n",
      "Epoch 66/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - loss: 0.0012 - mae: 0.0188 - val_loss: 0.0057 - val_mae: 0.0332\n",
      "Epoch 67/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - loss: 0.0012 - mae: 0.0187 - val_loss: 0.0056 - val_mae: 0.0329\n",
      "Epoch 68/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - loss: 0.0012 - mae: 0.0188 - val_loss: 0.0055 - val_mae: 0.0330\n",
      "Epoch 69/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - loss: 0.0012 - mae: 0.0187 - val_loss: 0.0059 - val_mae: 0.0337\n",
      "Epoch 70/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - loss: 0.0012 - mae: 0.0188 - val_loss: 0.0057 - val_mae: 0.0332\n",
      "Epoch 71/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - loss: 0.0012 - mae: 0.0188 - val_loss: 0.0058 - val_mae: 0.0333\n",
      "Epoch 72/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - loss: 0.0012 - mae: 0.0188 - val_loss: 0.0063 - val_mae: 0.0354\n",
      "Epoch 73/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - loss: 0.0012 - mae: 0.0188 - val_loss: 0.0057 - val_mae: 0.0329\n",
      "Epoch 74/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - loss: 0.0012 - mae: 0.0187 - val_loss: 0.0059 - val_mae: 0.0347\n",
      "Epoch 75/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - loss: 0.0012 - mae: 0.0189 - val_loss: 0.0065 - val_mae: 0.0369\n",
      "Epoch 76/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - loss: 0.0012 - mae: 0.0188 - val_loss: 0.0059 - val_mae: 0.0333\n",
      "Epoch 77/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - loss: 0.0012 - mae: 0.0187 - val_loss: 0.0063 - val_mae: 0.0354\n",
      "Epoch 78/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - loss: 0.0012 - mae: 0.0188 - val_loss: 0.0063 - val_mae: 0.0350\n",
      "Epoch 79/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - loss: 0.0012 - mae: 0.0187 - val_loss: 0.0059 - val_mae: 0.0332\n",
      "Epoch 80/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - loss: 0.0012 - mae: 0.0187 - val_loss: 0.0059 - val_mae: 0.0337\n",
      "Epoch 81/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - loss: 0.0012 - mae: 0.0187 - val_loss: 0.0059 - val_mae: 0.0331\n",
      "Epoch 82/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - loss: 0.0012 - mae: 0.0187 - val_loss: 0.0057 - val_mae: 0.0327\n",
      "Epoch 83/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - loss: 0.0012 - mae: 0.0188 - val_loss: 0.0060 - val_mae: 0.0331\n",
      "Epoch 84/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - loss: 0.0012 - mae: 0.0188 - val_loss: 0.0062 - val_mae: 0.0342\n",
      "Epoch 85/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - loss: 0.0012 - mae: 0.0188 - val_loss: 0.0062 - val_mae: 0.0354\n",
      "Epoch 86/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - loss: 0.0012 - mae: 0.0188 - val_loss: 0.0059 - val_mae: 0.0339\n",
      "Epoch 87/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - loss: 0.0012 - mae: 0.0187 - val_loss: 0.0060 - val_mae: 0.0337\n",
      "Epoch 88/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - loss: 0.0012 - mae: 0.0188 - val_loss: 0.0068 - val_mae: 0.0373\n",
      "Epoch 89/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - loss: 0.0012 - mae: 0.0186 - val_loss: 0.0057 - val_mae: 0.0329\n",
      "Epoch 90/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - loss: 0.0012 - mae: 0.0188 - val_loss: 0.0064 - val_mae: 0.0351\n",
      "Epoch 91/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - loss: 0.0012 - mae: 0.0186 - val_loss: 0.0064 - val_mae: 0.0352\n",
      "Epoch 92/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - loss: 0.0012 - mae: 0.0186 - val_loss: 0.0059 - val_mae: 0.0333\n",
      "Epoch 93/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - loss: 0.0012 - mae: 0.0187 - val_loss: 0.0062 - val_mae: 0.0342\n",
      "Epoch 94/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - loss: 0.0012 - mae: 0.0188 - val_loss: 0.0063 - val_mae: 0.0337\n",
      "Epoch 95/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - loss: 0.0012 - mae: 0.0187 - val_loss: 0.0061 - val_mae: 0.0334\n",
      "Epoch 96/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - loss: 0.0012 - mae: 0.0187 - val_loss: 0.0065 - val_mae: 0.0358\n",
      "Epoch 97/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - loss: 0.0012 - mae: 0.0187 - val_loss: 0.0062 - val_mae: 0.0341\n",
      "Epoch 98/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - loss: 0.0012 - mae: 0.0186 - val_loss: 0.0061 - val_mae: 0.0335\n",
      "Epoch 99/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - loss: 0.0012 - mae: 0.0188 - val_loss: 0.0066 - val_mae: 0.0354\n",
      "Epoch 100/100\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - loss: 0.0012 - mae: 0.0187 - val_loss: 0.0062 - val_mae: 0.0333\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step\n",
      "✅ Done with wheat_Tumkur_daily.csv | MAE=382.21, RMSE=834.89, R2=0.4048, MAPE=13.66%, Accuracy=86.34%\n",
      "Saved updated CSV with Date, Actual & Predicted: tat_mqa_output_csv\\wheat_Tumkur_daily_tat_mqa_updated.csv\n",
      "📊 Metrics saved to tat_mqa_metrics.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "import joblib  # for .pkl model saving (best-effort)\n",
    "warnings_imported = False\n",
    "try:\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    warnings_imported = True\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# -----------------------------\n",
    "# Output directories\n",
    "# -----------------------------\n",
    "input_folder = \"dataset\"\n",
    "output_models = \"tat_mqa_output_models\"\n",
    "output_csv = \"tat_mqa_output_csv\"\n",
    "output_graphs = \"tat_mqa_output_graphs\"\n",
    "output_logs = \"tat_mqa_output_logs\"\n",
    "metrics_file = \"tat_mqa_metrics.csv\"\n",
    "\n",
    "os.makedirs(output_models, exist_ok=True)\n",
    "os.makedirs(output_csv, exist_ok=True)\n",
    "os.makedirs(output_graphs, exist_ok=True)\n",
    "os.makedirs(output_logs, exist_ok=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Function to create dataset\n",
    "# -----------------------------\n",
    "def create_dataset(data, look_back=30):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - look_back):\n",
    "        X.append(data[i:i+look_back, 0])\n",
    "        y.append(data[i+look_back, 0])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# -----------------------------\n",
    "# Multi-Query Attention Layer\n",
    "# -----------------------------\n",
    "class MultiQueryAttention(layers.Layer):\n",
    "    def __init__(self, num_heads, key_dim, dropout_rate=0.1, **kwargs):\n",
    "        super(MultiQueryAttention, self).__init__(**kwargs)\n",
    "        self.num_heads = num_heads\n",
    "        self.key_dim = key_dim\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.q_dense = [layers.Dense(key_dim) for _ in range(num_heads)]\n",
    "        self.k_dense = layers.Dense(key_dim)\n",
    "        self.v_dense = layers.Dense(key_dim)\n",
    "        self.dropout = layers.Dropout(dropout_rate)\n",
    "        self.output_dense = layers.Dense(key_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        K = self.k_dense(x)\n",
    "        V = self.v_dense(x)\n",
    "        head_outputs = []\n",
    "\n",
    "        for q_layer in self.q_dense:\n",
    "            Q = q_layer(x)\n",
    "            scores = tf.matmul(Q, K, transpose_b=True) / tf.math.sqrt(tf.cast(self.key_dim, tf.float32))\n",
    "            attention_weights = tf.nn.softmax(scores, axis=-1)\n",
    "            attention_output = tf.matmul(attention_weights, V)\n",
    "            head_outputs.append(attention_output)\n",
    "\n",
    "        concat = tf.concat(head_outputs, axis=-1)\n",
    "        output = self.output_dense(concat)\n",
    "        output = self.dropout(output)\n",
    "        return output\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(MultiQueryAttention, self).get_config()\n",
    "        config.update({\n",
    "            \"num_heads\": self.num_heads,\n",
    "            \"key_dim\": self.key_dim,\n",
    "            \"dropout_rate\": self.dropout_rate\n",
    "        })\n",
    "        return config\n",
    "\n",
    "# -----------------------------\n",
    "# TAT-MQA Model\n",
    "# -----------------------------\n",
    "def build_tat_mqa_model(input_shape, d_model=64, num_heads=4, ff_dim=128, dropout_rate=0.2):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = MultiQueryAttention(num_heads=num_heads, key_dim=d_model, dropout_rate=dropout_rate)(inputs)\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x + inputs)\n",
    "\n",
    "    ff = layers.Dense(ff_dim, activation='relu')(x)\n",
    "    ff = layers.Dense(input_shape[1])(ff)\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x + ff)\n",
    "\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    outputs = layers.Dense(1)(x)\n",
    "\n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=0.001),\n",
    "                  loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# -----------------------------\n",
    "# Function to robustly parse dates\n",
    "# -----------------------------\n",
    "def parse_dates_safe(date_series):\n",
    "    # keep same behavior as you used before: infer_datetime_format True fallback\n",
    "    try:\n",
    "        return pd.to_datetime(date_series, infer_datetime_format=True, errors='coerce')\n",
    "    except:\n",
    "        return pd.to_datetime(date_series, errors='coerce')\n",
    "\n",
    "# -----------------------------\n",
    "# Metrics storage\n",
    "# -----------------------------\n",
    "metrics_list = []\n",
    "\n",
    "# -----------------------------\n",
    "# Process each CSV file\n",
    "# -----------------------------\n",
    "look_back = 30\n",
    "for file in os.listdir(input_folder):\n",
    "    if not file.endswith(\".csv\"):\n",
    "        continue\n",
    "\n",
    "    file_path = os.path.join(input_folder, file)\n",
    "    print(f\"🚀 Processing: {file}\")\n",
    "\n",
    "    # Load CSV\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Robust date parsing\n",
    "    df['Date'] = parse_dates_safe(df['Date'])\n",
    "    df = df.dropna(subset=['Date'])\n",
    "    df = df.sort_values('Date').reset_index(drop=True)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Handle missing Average Price\n",
    "    # -----------------------------\n",
    "    if 'Average Price' not in df.columns:\n",
    "        raise KeyError(\"Input CSV must contain 'Average Price' column.\")\n",
    "    if df['Average Price'].isna().sum() > 0:\n",
    "        mean_val = df['Average Price'].mean()\n",
    "        df['Average Price'].fillna(mean_val, inplace=True)\n",
    "        print(f\"Filled {df['Average Price'].isna().sum()} missing Average Price values with mean {mean_val:.2f}\")\n",
    "\n",
    "    # Round Actual values early\n",
    "    df['Average Price'] = df['Average Price'].astype(float).round(2)\n",
    "\n",
    "    # Moving averages (fill remaining NaNs with column mean to avoid plotting gaps)\n",
    "    df['MA_7'] = df['Average Price'].rolling(window=7).mean()\n",
    "    df['MA_30'] = df['Average Price'].rolling(window=30).mean()\n",
    "    df['MA_7'].fillna(df['MA_7'].mean(), inplace=True)\n",
    "    df['MA_30'].fillna(df['MA_30'].mean(), inplace=True)\n",
    "\n",
    "    # Prepare data\n",
    "    values = df[['Average Price']].values.astype('float32')\n",
    "    if len(values) <= look_back:\n",
    "        # Not enough data for the chosen look_back; skip file with a warning\n",
    "        print(f\"⚠️ Skipping {file} — dataset length ({len(values)}) <= look_back ({look_back})\")\n",
    "        continue\n",
    "\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_values = scaler.fit_transform(values)\n",
    "\n",
    "    X, y = create_dataset(scaled_values, look_back)\n",
    "    X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
    "\n",
    "    # Build and train model\n",
    "    model = build_tat_mqa_model(input_shape=(look_back,1))\n",
    "    model.summary()\n",
    "\n",
    "    history = model.fit(X, y, epochs=100, batch_size=16, validation_split=0.2, verbose=1)\n",
    "\n",
    "    # Save training logs\n",
    "    log_file = os.path.join(output_logs, file.replace(\".csv\", \"_tat_mqa_training.txt\"))\n",
    "    with open(log_file, \"w\") as f:\n",
    "        f.write(\"Training Loss per Epoch:\\n\")\n",
    "        for i, loss in enumerate(history.history['loss']):\n",
    "            val_loss = history.history['val_loss'][i] if 'val_loss' in history.history else None\n",
    "            f.write(f\"Epoch {i+1}: Loss={loss}, Val_Loss={val_loss}\\n\")\n",
    "\n",
    "    # Predictions (rescale)\n",
    "    predictions = model.predict(X)\n",
    "    predictions_rescaled = scaler.inverse_transform(predictions).flatten()\n",
    "    # pad with NaNs at start so predicted series aligns with original df index\n",
    "    padded_preds = np.concatenate([np.full(look_back, np.nan), predictions_rescaled])\n",
    "    df['Predicted'] = np.round(padded_preds, 2)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Compute metrics using only the matched portion (exclude leading NaNs)\n",
    "    # -----------------------------\n",
    "    y_true = df['Average Price'].values[look_back:]\n",
    "    y_pred = predictions_rescaled\n",
    "    mae = round(mean_absolute_error(y_true, y_pred), 2)\n",
    "    rmse = round(np.sqrt(mean_squared_error(y_true, y_pred)), 2)\n",
    "    r2 = round(r2_score(y_true, y_pred), 4)\n",
    "    # MAPE: avoid divide-by-zero by masking zeros\n",
    "    mask = y_true != 0\n",
    "    if mask.sum() == 0:\n",
    "        mape = np.nan\n",
    "        accuracy = np.nan\n",
    "    else:\n",
    "        mape = round(np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100, 2)\n",
    "        accuracy = round(100 - mape, 2)\n",
    "\n",
    "    metrics_list.append([file.replace(\".csv\",\"\"), mae, rmse, r2, mape, accuracy])\n",
    "\n",
    "    print(f\"✅ Done with {file} | MAE={mae}, RMSE={rmse}, R2={r2}, MAPE={mape}%, Accuracy={accuracy}%\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # Save model: native Keras and attempt .pkl (best-effort)\n",
    "    # -----------------------------\n",
    "    keras_model_path = os.path.join(output_models, file.replace(\".csv\", \"_tat_mqa_model.keras\"))\n",
    "    model.save(keras_model_path)\n",
    "    pkl_model_path = os.path.join(output_models, file.replace(\".csv\", \"_tat_mqa_model.pkl\"))\n",
    "    try:\n",
    "        # joblib.dump the Keras model object (may fail on some TF versions)\n",
    "        joblib.dump(model, pkl_model_path)\n",
    "    except Exception as e:\n",
    "        # fallback: save model architecture + weights dict to pickle (best-effort)\n",
    "        try:\n",
    "            model_info = {\n",
    "                \"config\": model.get_config(),\n",
    "                \"weights\": model.get_weights()\n",
    "            }\n",
    "            joblib.dump(model_info, pkl_model_path)\n",
    "        except Exception as e2:\n",
    "            print(f\"⚠️ Could not save .pkl for {file}: {e}; {e2}\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # Save CSV with only Date, Actual, Predicted (Actual renamed)\n",
    "    # -----------------------------\n",
    "    save_df = pd.DataFrame({\n",
    "        'Date': df['Date'],\n",
    "        'Actual': df['Average Price'].round(2),\n",
    "        'Predicted': df['Predicted']\n",
    "    })\n",
    "    updated_csv_path = os.path.join(output_csv, file.replace(\".csv\", \"_tat_mqa_updated.csv\"))\n",
    "    save_df.to_csv(updated_csv_path, index=False)\n",
    "    print(f\"Saved updated CSV with Date, Actual & Predicted: {updated_csv_path}\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # Save graph with Actual, Predicted, MA7, MA30\n",
    "    # -----------------------------\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.plot(df['Date'], df['Average Price'], label='Actual', color='blue')\n",
    "    plt.plot(df['Date'], df['Predicted'], label='Predicted', color='red', linestyle='dashed')\n",
    "    plt.plot(df['Date'], df['MA_7'], label='MA 7', color='orange')\n",
    "    plt.plot(df['Date'], df['MA_30'], label='MA 30', color='green')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Average Price')\n",
    "    plt.title(f'Price Prediction (TAT-MQA) - {file}')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    graph_file = os.path.join(output_graphs, file.replace(\".csv\", \"_tat_mqa_graph.png\"))\n",
    "    plt.savefig(graph_file, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# -----------------------------\n",
    "# Save all metrics\n",
    "# -----------------------------\n",
    "metrics_df = pd.DataFrame(metrics_list, columns=['District', 'MAE', 'RMSE', 'R2', 'MAPE(%)', 'Accuracy(%)'])\n",
    "metrics_df.to_csv(metrics_file, index=False)\n",
    "print(f\"📊 Metrics saved to {metrics_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f13470c-4e0f-42e1-bd7b-96089a26b96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TAT+GQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af26cba-a053-4055-b2e4-eae9900b6c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Processing: wheat_Bagalkot_daily.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "import joblib  # For saving models as .pkl\n",
    "\n",
    "# -----------------------------\n",
    "# Suppress Warnings\n",
    "# -----------------------------\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "pd.options.mode.chained_assignment = None  # Avoid SettingWithCopyWarning\n",
    "\n",
    "# -----------------------------\n",
    "# Output directories\n",
    "# -----------------------------\n",
    "input_folder = \"dataset\"\n",
    "output_models = \"tat_gqa_output_models\"\n",
    "output_csv = \"tat_gqa_output_csv\"\n",
    "output_graphs = \"tat_gqa_output_graphs\"\n",
    "output_logs = \"tat_gqa_output_logs\"\n",
    "metrics_file = \"tat_gqa_metrics.csv\"\n",
    "\n",
    "for folder in [output_models, output_csv, output_graphs, output_logs]:\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Function to create dataset\n",
    "# -----------------------------\n",
    "def create_dataset(data, look_back=30):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - look_back):\n",
    "        X.append(data[i:i + look_back, 0])\n",
    "        y.append(data[i + look_back, 0])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# -----------------------------\n",
    "# Grouped Query Attention Layer\n",
    "# -----------------------------\n",
    "class GroupedQueryAttention(layers.Layer):\n",
    "    def __init__(self, num_groups=2, key_dim=64, dropout_rate=0.1, **kwargs):\n",
    "        super(GroupedQueryAttention, self).__init__(**kwargs)\n",
    "        self.num_groups = num_groups\n",
    "        self.key_dim = key_dim\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.k_dense = layers.Dense(key_dim)\n",
    "        self.v_dense = layers.Dense(key_dim)\n",
    "        self.q_dense_groups = [layers.Dense(key_dim) for _ in range(num_groups)]\n",
    "        self.dropout = layers.Dropout(dropout_rate)\n",
    "        self.output_dense = layers.Dense(key_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        K = self.k_dense(x)\n",
    "        V = self.v_dense(x)\n",
    "        group_outputs = []\n",
    "        for q_layer in self.q_dense_groups:\n",
    "            Q = q_layer(x)\n",
    "            scores = tf.matmul(Q, K, transpose_b=True) / tf.math.sqrt(tf.cast(self.key_dim, tf.float32))\n",
    "            attention_weights = tf.nn.softmax(scores, axis=-1)\n",
    "            attn_output = tf.matmul(attention_weights, V)\n",
    "            group_outputs.append(attn_output)\n",
    "        concat = tf.concat(group_outputs, axis=-1)\n",
    "        output = self.output_dense(concat)\n",
    "        output = self.dropout(output)\n",
    "        return output\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(GroupedQueryAttention, self).get_config()\n",
    "        config.update({\n",
    "            \"num_groups\": self.num_groups,\n",
    "            \"key_dim\": self.key_dim,\n",
    "            \"dropout_rate\": self.dropout_rate\n",
    "        })\n",
    "        return config\n",
    "\n",
    "# -----------------------------\n",
    "# TAT-GQA Model\n",
    "# -----------------------------\n",
    "def build_tat_gqa_model(input_shape, d_model=64, num_groups=2, ff_dim=128, dropout_rate=0.2):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = GroupedQueryAttention(num_groups=num_groups, key_dim=d_model, dropout_rate=dropout_rate)(inputs)\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x + inputs)\n",
    "    ff = layers.Dense(ff_dim, activation='relu')(x)\n",
    "    ff = layers.Dense(input_shape[1])(ff)\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x + ff)\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    outputs = layers.Dense(1)(x)\n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=0.001),\n",
    "                  loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# -----------------------------\n",
    "# Metrics storage\n",
    "# -----------------------------\n",
    "metrics_list = []\n",
    "\n",
    "# -----------------------------\n",
    "# Training Configuration\n",
    "# -----------------------------\n",
    "look_back = 30\n",
    "epochs = 100\n",
    "batch_size = 16\n",
    "\n",
    "# -----------------------------\n",
    "# Process each CSV file\n",
    "# -----------------------------\n",
    "for file in os.listdir(input_folder):\n",
    "    if not file.endswith(\".csv\"):\n",
    "        continue\n",
    "\n",
    "    file_path = os.path.join(input_folder, file)\n",
    "    print(f\"🚀 Processing: {file}\")\n",
    "\n",
    "    # Load CSV\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to read {file}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Parse dates safely (no infer_datetime_format)\n",
    "    df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "    df = df.dropna(subset=['Date']).sort_values('Date')\n",
    "\n",
    "    # Check if column exists\n",
    "    if 'Average Price' not in df.columns:\n",
    "        print(f\"⚠️ Skipping {file}: 'Average Price' column not found.\")\n",
    "        continue\n",
    "\n",
    "    # Handle missing price values\n",
    "    df['Average Price'] = df['Average Price'].fillna(df['Average Price'].mean())\n",
    "\n",
    "    # Moving averages (for visualization only)\n",
    "    df['MA_7'] = df['Average Price'].rolling(window=7).mean().fillna(df['Average Price'].mean())\n",
    "    df['MA_30'] = df['Average Price'].rolling(window=30).mean().fillna(df['Average Price'].mean())\n",
    "\n",
    "    # Prepare scaled data\n",
    "    values = df[['Average Price']].astype('float32').values\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_values = scaler.fit_transform(values)\n",
    "    X, y = create_dataset(scaled_values, look_back)\n",
    "    X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
    "\n",
    "    # Build and train model\n",
    "    model = build_tat_gqa_model(input_shape=(look_back, 1))\n",
    "    history = model.fit(\n",
    "        X, y,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_split=0.2,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Save training log\n",
    "    log_file = os.path.join(output_logs, file.replace(\".csv\", \"_tat_gqa_training.txt\"))\n",
    "    with open(log_file, \"w\") as f:\n",
    "        f.write(\"Epoch\\tLoss\\tVal_Loss\\n\")\n",
    "        for i in range(len(history.history['loss'])):\n",
    "            f.write(f\"{i+1}\\t{history.history['loss'][i]:.6f}\\t{history.history['val_loss'][i]:.6f}\\n\")\n",
    "\n",
    "    # Predictions\n",
    "    predictions = model.predict(X)\n",
    "    predictions_rescaled = scaler.inverse_transform(predictions)\n",
    "    df['Predicted'] = [np.nan] * look_back + list(predictions_rescaled.flatten())\n",
    "\n",
    "    # Round values for clean output\n",
    "    df['Average Price'] = df['Average Price'].round(2)\n",
    "    df['Predicted'] = df['Predicted'].round(2)\n",
    "\n",
    "    # Metrics Calculation\n",
    "    y_true = df['Average Price'].values[look_back:]\n",
    "    y_pred = predictions_rescaled.flatten()\n",
    "\n",
    "    # Avoid division by zero or NaN in MAPE\n",
    "    mask = y_true != 0\n",
    "    if np.any(mask):\n",
    "        mape = np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100\n",
    "    else:\n",
    "        mape = 0.0\n",
    "\n",
    "    mae = round(mean_absolute_error(y_true, y_pred), 2)\n",
    "    rmse = round(np.sqrt(mean_squared_error(y_true, y_pred)), 2)\n",
    "    r2 = round(r2_score(y_true, y_pred), 2)\n",
    "    mape = round(mape, 2)\n",
    "    accuracy = round(100 - mape, 2)\n",
    "\n",
    "    metrics_list.append([file.replace(\".csv\", \"\"), mae, rmse, r2, mape, accuracy])\n",
    "\n",
    "    # Save model as .pkl\n",
    "    model_file = os.path.join(output_models, file.replace(\".csv\", \"_tat_gqa_model.pkl\"))\n",
    "    joblib.dump(model, model_file)\n",
    "\n",
    "    # Save predictions to CSV\n",
    "    save_df = df[['Date', 'Average Price', 'Predicted']].rename(columns={'Average Price': 'Actual'})\n",
    "    updated_csv_path = os.path.join(output_csv, file.replace(\".csv\", \"_tat_gqa_updated.csv\"))\n",
    "    save_df.to_csv(updated_csv_path, index=False)\n",
    "\n",
    "    # Plot Graph\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(df['Date'], df['Average Price'], label='Actual', color='blue')\n",
    "    plt.plot(df['Date'], df['MA_7'], label='MA 7', color='orange')\n",
    "    plt.plot(df['Date'], df['MA_30'], label='MA 30', color='green')\n",
    "    plt.plot(df['Date'], df['Predicted'], label='Predicted (TAT-GQA)', color='red', linestyle='dashed')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Price')\n",
    "    plt.title(f'Price Prediction (TAT-GQA) - {file}')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    graph_file = os.path.join(output_graphs, file.replace(\".csv\", \"_tat_gqa_graph.png\"))\n",
    "    plt.savefig(graph_file)\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"✅ Done: {file} | MAE={mae}, RMSE={rmse}, R2={r2}, MAPE={mape}%, Accuracy={accuracy}%\")\n",
    "\n",
    "# -----------------------------\n",
    "# Save Metrics\n",
    "# -----------------------------\n",
    "metrics_df = pd.DataFrame(metrics_list, columns=['District', 'MAE', 'RMSE', 'R2', 'MAPE(%)', 'Accuracy(%)'])\n",
    "metrics_df.to_csv(metrics_file, index=False)\n",
    "print(f\"📊 All metrics saved to: {metrics_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffce5097-846f-4556-b20f-d9063b6d30fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TAT+HA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405e678a-32e4-47a6-bc87-7d12b15ddf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import joblib\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "\n",
    "# =========================================================\n",
    "# CLEAN STARTUP – suppress all unnecessary warnings/logs\n",
    "# =========================================================\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # Disable TensorFlow INFO/WARNING logs\n",
    "tf.get_logger().setLevel(\"ERROR\")\n",
    "\n",
    "# =========================================================\n",
    "# Output directories\n",
    "# =========================================================\n",
    "input_folder = \"dataset\"\n",
    "output_models = \"tat_ha_output_models\"\n",
    "output_csv = \"tat_ha_output_csv\"\n",
    "output_graphs = \"tat_ha_output_graphs\"\n",
    "output_logs = \"tat_ha_output_logs\"\n",
    "metrics_file = \"tat_ha_metrics.csv\"\n",
    "\n",
    "os.makedirs(output_models, exist_ok=True)\n",
    "os.makedirs(output_csv, exist_ok=True)\n",
    "os.makedirs(output_graphs, exist_ok=True)\n",
    "os.makedirs(output_logs, exist_ok=True)\n",
    "\n",
    "# =========================================================\n",
    "# Dataset creation\n",
    "# =========================================================\n",
    "def create_dataset(data, look_back=30):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - look_back):\n",
    "        X.append(data[i:i + look_back, 0])\n",
    "        y.append(data[i + look_back, 0])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# =========================================================\n",
    "# Local Attention Layer\n",
    "# =========================================================\n",
    "class LocalAttention(layers.Layer):\n",
    "    def __init__(self, key_dim=64, dropout_rate=0.1, **kwargs):\n",
    "        super(LocalAttention, self).__init__(**kwargs)\n",
    "        self.key_dim = key_dim\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.q_dense = layers.Dense(key_dim)\n",
    "        self.k_dense = layers.Dense(key_dim)\n",
    "        self.v_dense = layers.Dense(key_dim)\n",
    "        self.dropout = layers.Dropout(dropout_rate)\n",
    "\n",
    "    def call(self, x):\n",
    "        Q = self.q_dense(x)\n",
    "        K = self.k_dense(x)\n",
    "        V = self.v_dense(x)\n",
    "        scores = tf.matmul(Q, K, transpose_b=True) / tf.math.sqrt(\n",
    "            tf.cast(tf.shape(K)[-1], tf.float32))\n",
    "        weights = tf.nn.softmax(scores, axis=-1)\n",
    "        output = tf.matmul(weights, V)\n",
    "        return self.dropout(output)\n",
    "\n",
    "# =========================================================\n",
    "# Hierarchical Attention Model\n",
    "# =========================================================\n",
    "def build_tat_ha_model(input_shape, d_model=64, ff_dim=128, dropout_rate=0.2):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    local_attn = LocalAttention(key_dim=d_model, dropout_rate=dropout_rate)(inputs)\n",
    "    local_attn = layers.LayerNormalization(epsilon=1e-6)(local_attn + inputs)\n",
    "\n",
    "    global_attn = layers.MultiHeadAttention(num_heads=4, key_dim=d_model)(local_attn, local_attn)\n",
    "    global_attn = layers.Dropout(dropout_rate)(global_attn)\n",
    "    global_attn = layers.LayerNormalization(epsilon=1e-6)(global_attn + local_attn)\n",
    "\n",
    "    ff = layers.Dense(ff_dim, activation='relu')(global_attn)\n",
    "    ff = layers.Dense(input_shape[1])(ff)\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(ff + global_attn)\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "\n",
    "    outputs = layers.Dense(1)(x)\n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=0.001),\n",
    "                  loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# =========================================================\n",
    "# Metrics list\n",
    "# =========================================================\n",
    "metrics_list = []\n",
    "\n",
    "# =========================================================\n",
    "# Process each CSV file\n",
    "# =========================================================\n",
    "look_back = 30\n",
    "for file in os.listdir(input_folder):\n",
    "    if not file.endswith(\".csv\"):\n",
    "        continue\n",
    "\n",
    "    file_path = os.path.join(input_folder, file)\n",
    "    print(f\"\\n🚀 Processing: {file}\")\n",
    "\n",
    "    # Load CSV\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Safe datetime conversion\n",
    "    df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "    df = df.dropna(subset=['Date']).sort_values('Date')\n",
    "\n",
    "    # Ensure target column exists\n",
    "    if 'Average Price' not in df.columns:\n",
    "        print(f\"⚠️ Skipping {file}: 'Average Price' missing.\")\n",
    "        continue\n",
    "\n",
    "    # Replace inplace warnings (no inplace=True used)\n",
    "    df['Average Price'] = df['Average Price'].fillna(df['Average Price'].mean())\n",
    "    df['MA_7'] = df['Average Price'].rolling(window=7).mean()\n",
    "    df['MA_30'] = df['Average Price'].rolling(window=30).mean()\n",
    "    df['MA_7'] = df['MA_7'].fillna(df['MA_7'].mean())\n",
    "    df['MA_30'] = df['MA_30'].fillna(df['MA_30'].mean())\n",
    "\n",
    "    # Prepare training data\n",
    "    values = df[['Average Price']].values.astype('float32')\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_values = scaler.fit_transform(values)\n",
    "    if len(scaled_values) <= look_back:\n",
    "        print(f\"⚠️ Skipping {file}: not enough data points.\")\n",
    "        continue\n",
    "\n",
    "    X, y = create_dataset(scaled_values, look_back)\n",
    "    X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
    "\n",
    "    # Build and train model (show epochs cleanly)\n",
    "    model = build_tat_ha_model(input_shape=(look_back, 1))\n",
    "    history = model.fit(X, y, epochs=50, batch_size=16, validation_split=0.2, verbose=2)\n",
    "\n",
    "    # Save logs\n",
    "    log_file = os.path.join(output_logs, file.replace(\".csv\", \"_tat_ha_training.txt\"))\n",
    "    with open(log_file, \"w\") as f:\n",
    "        f.write(\"Training Loss per Epoch:\\n\")\n",
    "        for i, loss in enumerate(history.history['loss']):\n",
    "            f.write(f\"Epoch {i + 1}: Loss={loss}, Val_Loss={history.history['val_loss'][i]}\\n\")\n",
    "\n",
    "    # Predictions\n",
    "    predictions = model.predict(X, verbose=0)\n",
    "    predictions_rescaled = scaler.inverse_transform(predictions)\n",
    "    df['Predicted'] = [np.nan] * look_back + list(predictions_rescaled.flatten())\n",
    "\n",
    "    # Round results\n",
    "    df['Average Price'] = df['Average Price'].round(2)\n",
    "    df['Predicted'] = df['Predicted'].round(2)\n",
    "\n",
    "    # Evaluate\n",
    "    y_true = df['Average Price'].values[look_back:]\n",
    "    y_pred = predictions_rescaled.flatten()\n",
    "    valid_idx = ~np.isnan(y_true) & ~np.isnan(y_pred) & (y_true != 0)\n",
    "\n",
    "    if not np.any(valid_idx):\n",
    "        print(f\"⚠️ Skipping metrics for {file}: invalid or zero values.\")\n",
    "        continue\n",
    "\n",
    "    y_true, y_pred = y_true[valid_idx], y_pred[valid_idx]\n",
    "    mae = round(mean_absolute_error(y_true, y_pred), 2)\n",
    "    rmse = round(np.sqrt(mean_squared_error(y_true, y_pred)), 2)\n",
    "    r2 = round(r2_score(y_true, y_pred), 2)\n",
    "    mape = round(np.mean(np.abs((y_true - y_pred) / np.maximum(y_true, 1e-10))) * 100, 2)\n",
    "    accuracy = round(max(0, min(100, 100 - mape)), 2)\n",
    "\n",
    "    metrics_list.append([file.replace(\".csv\", \"\"), mae, rmse, r2, mape, accuracy])\n",
    "\n",
    "    # Save model\n",
    "    model_file = os.path.join(output_models, file.replace(\".csv\", \"_tat_ha_model.pkl\"))\n",
    "    joblib.dump(model, model_file)\n",
    "\n",
    "    # Save updated CSV\n",
    "    save_df = df[['Date', 'Average Price', 'Predicted']].rename(columns={'Average Price': 'Actual'})\n",
    "    updated_csv_path = os.path.join(output_csv, file.replace(\".csv\", \"_tat_ha_updated.csv\"))\n",
    "    save_df.to_csv(updated_csv_path, index=False)\n",
    "\n",
    "    # Plot graph\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(df['Date'], df['Average Price'], label='Actual', color='blue')\n",
    "    plt.plot(df['Date'], df['MA_7'], label='MA 7', color='orange')\n",
    "    plt.plot(df['Date'], df['MA_30'], label='MA 30', color='green')\n",
    "    plt.plot(df['Date'], df['Predicted'], label='Predicted (TAT-HA)', color='red', linestyle='dashed')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Price')\n",
    "    plt.title(f'Price Prediction (TAT-HA) - {file}')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    graph_file = os.path.join(output_graphs, file.replace(\".csv\", \"_tat_ha_graph.png\"))\n",
    "    plt.savefig(graph_file)\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"✅ Done with {file} | MAE={mae}, RMSE={rmse}, R2={r2}, MAPE={mape}%, Accuracy={accuracy}%\")\n",
    "\n",
    "# Save metrics\n",
    "if metrics_list:\n",
    "    metrics_df = pd.DataFrame(metrics_list, columns=['District', 'MAE', 'RMSE', 'R2', 'MAPE(%)', 'Accuracy(%)'])\n",
    "    metrics_df.to_csv(metrics_file, index=False)\n",
    "    print(f\"\\n📊 Metrics saved to {metrics_file}\")\n",
    "else:\n",
    "    print(\"\\n⚠️ No valid data found to save metrics.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2694d47e-4660-4464-b8be-37509338d130",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bd72854-07bb-45ca-85b1-1b82ef08f679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== Processing: wheat_Bagalkot_daily.csv ==========\n",
      "Epoch 1/20\n",
      "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 0.0011 - mae: 0.0234 - val_loss: 0.0021 - val_mae: 0.0360\n",
      "Epoch 2/20\n",
      "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0010 - mae: 0.0224 - val_loss: 0.0023 - val_mae: 0.0372\n",
      "Epoch 3/20\n",
      "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 9.9486e-04 - mae: 0.0222 - val_loss: 0.0026 - val_mae: 0.0389\n",
      "Epoch 4/20\n",
      "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 9.9817e-04 - mae: 0.0222 - val_loss: 0.0022 - val_mae: 0.0365\n",
      "Epoch 5/20\n",
      "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 9.9193e-04 - mae: 0.0221 - val_loss: 0.0022 - val_mae: 0.0365\n",
      "Epoch 6/20\n",
      "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 9.9065e-04 - mae: 0.0221 - val_loss: 0.0025 - val_mae: 0.0380\n",
      "Epoch 7/20\n",
      "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 9.9442e-04 - mae: 0.0221 - val_loss: 0.0021 - val_mae: 0.0362\n",
      "Epoch 8/20\n",
      "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 9.9362e-04 - mae: 0.0221 - val_loss: 0.0021 - val_mae: 0.0361\n",
      "Epoch 9/20\n",
      "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 9.8918e-04 - mae: 0.0221 - val_loss: 0.0023 - val_mae: 0.0373\n",
      "Epoch 10/20\n",
      "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 9.8994e-04 - mae: 0.0220 - val_loss: 0.0021 - val_mae: 0.0359\n",
      "Epoch 11/20\n",
      "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 9.9112e-04 - mae: 0.0221 - val_loss: 0.0022 - val_mae: 0.0368\n",
      "Epoch 12/20\n",
      "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 9.8790e-04 - mae: 0.0221 - val_loss: 0.0023 - val_mae: 0.0369\n",
      "Epoch 13/20\n",
      "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 9.8879e-04 - mae: 0.0221 - val_loss: 0.0022 - val_mae: 0.0365\n",
      "Epoch 14/20\n",
      "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 9.8677e-04 - mae: 0.0220 - val_loss: 0.0020 - val_mae: 0.0355\n",
      "Epoch 15/20\n",
      "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 9.8819e-04 - mae: 0.0221 - val_loss: 0.0024 - val_mae: 0.0375\n",
      "Epoch 16/20\n",
      "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 9.8224e-04 - mae: 0.0220 - val_loss: 0.0026 - val_mae: 0.0383\n",
      "Epoch 17/20\n",
      "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 9.8858e-04 - mae: 0.0220 - val_loss: 0.0023 - val_mae: 0.0373\n",
      "Epoch 18/20\n",
      "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 9.8452e-04 - mae: 0.0220 - val_loss: 0.0024 - val_mae: 0.0377\n",
      "Epoch 19/20\n",
      "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 9.8969e-04 - mae: 0.0221 - val_loss: 0.0022 - val_mae: 0.0367\n",
      "Epoch 20/20\n",
      "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 9.8548e-04 - mae: 0.0220 - val_loss: 0.0023 - val_mae: 0.0371\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step   \n",
      "✅ Done with wheat_Bagalkot_daily.csv | MAE=645.3, RMSE=839.25, R2=0.07, MAPE=22.5%, Accuracy=77.5%\n",
      "\n",
      "========== Processing: wheat_Bangalore_daily.csv ==========\n",
      "Epoch 1/20\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 7.5226e-04 - mae: 0.0218 - val_loss: 0.0015 - val_mae: 0.0292\n",
      "Epoch 2/20\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 6.7200e-04 - mae: 0.0208 - val_loss: 0.0016 - val_mae: 0.0287\n",
      "Epoch 3/20\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 6.3660e-04 - mae: 0.0201 - val_loss: 0.0017 - val_mae: 0.0280\n",
      "Epoch 4/20\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 6.0126e-04 - mae: 0.0193 - val_loss: 0.0021 - val_mae: 0.0305\n",
      "Epoch 5/20\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 5.7820e-04 - mae: 0.0186 - val_loss: 0.0018 - val_mae: 0.0279\n",
      "Epoch 6/20\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 5.7179e-04 - mae: 0.0183 - val_loss: 0.0018 - val_mae: 0.0279\n",
      "Epoch 7/20\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 5.6730e-04 - mae: 0.0181 - val_loss: 0.0030 - val_mae: 0.0414\n",
      "Epoch 8/20\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 5.6989e-04 - mae: 0.0181 - val_loss: 0.0018 - val_mae: 0.0278\n",
      "Epoch 9/20\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 5.6415e-04 - mae: 0.0180 - val_loss: 0.0014 - val_mae: 0.0241\n",
      "Epoch 10/20\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 5.6372e-04 - mae: 0.0180 - val_loss: 0.0016 - val_mae: 0.0258\n",
      "Epoch 11/20\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 5.6192e-04 - mae: 0.0179 - val_loss: 0.0015 - val_mae: 0.0250\n",
      "Epoch 12/20\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 5.5772e-04 - mae: 0.0179 - val_loss: 0.0022 - val_mae: 0.0324\n",
      "Epoch 13/20\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 5.6348e-04 - mae: 0.0179 - val_loss: 0.0017 - val_mae: 0.0275\n",
      "Epoch 14/20\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 5.5924e-04 - mae: 0.0179 - val_loss: 0.0017 - val_mae: 0.0275\n",
      "Epoch 15/20\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 5.5934e-04 - mae: 0.0179 - val_loss: 0.0018 - val_mae: 0.0275\n",
      "Epoch 16/20\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 5.5618e-04 - mae: 0.0178 - val_loss: 0.0014 - val_mae: 0.0243\n",
      "Epoch 17/20\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 5.5926e-04 - mae: 0.0179 - val_loss: 0.0022 - val_mae: 0.0328\n",
      "Epoch 18/20\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 5.5429e-04 - mae: 0.0178 - val_loss: 0.0016 - val_mae: 0.0259\n",
      "Epoch 19/20\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 5.5289e-04 - mae: 0.0177 - val_loss: 0.0021 - val_mae: 0.0311\n",
      "Epoch 20/20\n",
      "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 5.5028e-04 - mae: 0.0176 - val_loss: 0.0016 - val_mae: 0.0255\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step   \n",
      "✅ Done with wheat_Bangalore_daily.csv | MAE=445.04, RMSE=689.28, R2=0.13, MAPE=12.91%, Accuracy=87.09%\n",
      "\n",
      "========== Processing: wheat_Belgaum_daily.csv ==========\n",
      "Epoch 1/20\n",
      "\u001b[1m825/825\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 0.0077 - mae: 0.0650 - val_loss: 0.0061 - val_mae: 0.0598\n",
      "Epoch 2/20\n",
      "\u001b[1m825/825\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0064 - mae: 0.0600 - val_loss: 0.0061 - val_mae: 0.0596\n",
      "Epoch 3/20\n",
      "\u001b[1m825/825\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0063 - mae: 0.0594 - val_loss: 0.0077 - val_mae: 0.0698\n",
      "Epoch 4/20\n",
      "\u001b[1m825/825\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0063 - mae: 0.0592 - val_loss: 0.0119 - val_mae: 0.0922\n",
      "Epoch 5/20\n",
      "\u001b[1m825/825\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0063 - mae: 0.0590 - val_loss: 0.0070 - val_mae: 0.0657\n",
      "Epoch 6/20\n",
      "\u001b[1m825/825\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0062 - mae: 0.0589 - val_loss: 0.0123 - val_mae: 0.0932\n",
      "Epoch 7/20\n",
      "\u001b[1m825/825\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0063 - mae: 0.0590 - val_loss: 0.0112 - val_mae: 0.0877\n",
      "Epoch 8/20\n",
      "\u001b[1m825/825\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0062 - mae: 0.0589 - val_loss: 0.0116 - val_mae: 0.0898\n",
      "Epoch 9/20\n",
      "\u001b[1m825/825\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0062 - mae: 0.0588 - val_loss: 0.0109 - val_mae: 0.0870\n",
      "Epoch 10/20\n",
      "\u001b[1m825/825\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0062 - mae: 0.0588 - val_loss: 0.0096 - val_mae: 0.0792\n",
      "Epoch 11/20\n",
      "\u001b[1m825/825\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0062 - mae: 0.0589 - val_loss: 0.0101 - val_mae: 0.0820\n",
      "Epoch 12/20\n",
      "\u001b[1m825/825\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0062 - mae: 0.0588 - val_loss: 0.0120 - val_mae: 0.0908\n",
      "Epoch 13/20\n",
      "\u001b[1m825/825\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0062 - mae: 0.0587 - val_loss: 0.0108 - val_mae: 0.0859\n",
      "Epoch 14/20\n",
      "\u001b[1m825/825\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0062 - mae: 0.0588 - val_loss: 0.0107 - val_mae: 0.0851\n",
      "Epoch 15/20\n",
      "\u001b[1m825/825\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0062 - mae: 0.0588 - val_loss: 0.0105 - val_mae: 0.0841\n",
      "Epoch 16/20\n",
      "\u001b[1m825/825\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0062 - mae: 0.0588 - val_loss: 0.0091 - val_mae: 0.0769\n",
      "Epoch 17/20\n",
      "\u001b[1m825/825\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0062 - mae: 0.0586 - val_loss: 0.0081 - val_mae: 0.0718\n",
      "Epoch 18/20\n",
      "\u001b[1m825/825\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0062 - mae: 0.0588 - val_loss: 0.0081 - val_mae: 0.0715\n",
      "Epoch 19/20\n",
      "\u001b[1m825/825\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0062 - mae: 0.0587 - val_loss: 0.0107 - val_mae: 0.0855\n",
      "Epoch 20/20\n",
      "\u001b[1m825/825\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0062 - mae: 0.0587 - val_loss: 0.0135 - val_mae: 0.0981\n",
      "\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step   \n",
      "✅ Done with wheat_Belgaum_daily.csv | MAE=557.23, RMSE=659.06, R2=-0.95, MAPE=18.82%, Accuracy=81.18%\n",
      "\n",
      "========== Processing: wheat_Bellary_daily.csv ==========\n",
      "Epoch 1/20\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0039 - mae: 0.0484 - val_loss: 0.0134 - val_mae: 0.0879\n",
      "Epoch 2/20\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0033 - mae: 0.0452 - val_loss: 0.0099 - val_mae: 0.0792\n",
      "Epoch 3/20\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0033 - mae: 0.0443 - val_loss: 0.0111 - val_mae: 0.0808\n",
      "Epoch 4/20\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0032 - mae: 0.0438 - val_loss: 0.0118 - val_mae: 0.0825\n",
      "Epoch 5/20\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0032 - mae: 0.0434 - val_loss: 0.0121 - val_mae: 0.0828\n",
      "Epoch 6/20\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0032 - mae: 0.0433 - val_loss: 0.0104 - val_mae: 0.0776\n",
      "Epoch 7/20\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0031 - mae: 0.0430 - val_loss: 0.0115 - val_mae: 0.0813\n",
      "Epoch 8/20\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0031 - mae: 0.0428 - val_loss: 0.0156 - val_mae: 0.0909\n",
      "Epoch 9/20\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0031 - mae: 0.0426 - val_loss: 0.0121 - val_mae: 0.0815\n",
      "Epoch 10/20\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0031 - mae: 0.0424 - val_loss: 0.0114 - val_mae: 0.0786\n",
      "Epoch 11/20\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0031 - mae: 0.0423 - val_loss: 0.0137 - val_mae: 0.0844\n",
      "Epoch 12/20\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0030 - mae: 0.0422 - val_loss: 0.0137 - val_mae: 0.0826\n",
      "Epoch 13/20\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0030 - mae: 0.0420 - val_loss: 0.0119 - val_mae: 0.0791\n",
      "Epoch 14/20\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0030 - mae: 0.0419 - val_loss: 0.0101 - val_mae: 0.0754\n",
      "Epoch 15/20\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0029 - mae: 0.0416 - val_loss: 0.0138 - val_mae: 0.0803\n",
      "Epoch 16/20\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0029 - mae: 0.0412 - val_loss: 0.0212 - val_mae: 0.0991\n",
      "Epoch 17/20\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0029 - mae: 0.0413 - val_loss: 0.0079 - val_mae: 0.0665\n",
      "Epoch 18/20\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0028 - mae: 0.0410 - val_loss: 0.0131 - val_mae: 0.0836\n",
      "Epoch 19/20\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0028 - mae: 0.0410 - val_loss: 0.0121 - val_mae: 0.0749\n",
      "Epoch 20/20\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0028 - mae: 0.0407 - val_loss: 0.0151 - val_mae: 0.0816\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step   \n",
      "✅ Done with wheat_Bellary_daily.csv | MAE=595.96, RMSE=896.83, R2=0.11, MAPE=21.05%, Accuracy=78.95%\n",
      "\n",
      "========== Processing: wheat_Bidar_daily.csv ==========\n",
      "Epoch 1/20\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0074 - mae: 0.0632 - val_loss: 0.0053 - val_mae: 0.0570\n",
      "Epoch 2/20\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0044 - mae: 0.0511 - val_loss: 0.0053 - val_mae: 0.0566\n",
      "Epoch 3/20\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0044 - mae: 0.0509 - val_loss: 0.0057 - val_mae: 0.0577\n",
      "Epoch 4/20\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0043 - mae: 0.0501 - val_loss: 0.0054 - val_mae: 0.0557\n",
      "Epoch 5/20\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0043 - mae: 0.0499 - val_loss: 0.0051 - val_mae: 0.0541\n",
      "Epoch 6/20\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0042 - mae: 0.0495 - val_loss: 0.0055 - val_mae: 0.0551\n",
      "Epoch 7/20\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0042 - mae: 0.0492 - val_loss: 0.0058 - val_mae: 0.0567\n",
      "Epoch 8/20\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0042 - mae: 0.0491 - val_loss: 0.0056 - val_mae: 0.0555\n",
      "Epoch 9/20\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0042 - mae: 0.0493 - val_loss: 0.0050 - val_mae: 0.0530\n",
      "Epoch 10/20\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0042 - mae: 0.0491 - val_loss: 0.0050 - val_mae: 0.0527\n",
      "Epoch 11/20\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0042 - mae: 0.0491 - val_loss: 0.0050 - val_mae: 0.0528\n",
      "Epoch 12/20\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0042 - mae: 0.0491 - val_loss: 0.0050 - val_mae: 0.0526\n",
      "Epoch 13/20\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0042 - mae: 0.0489 - val_loss: 0.0049 - val_mae: 0.0527\n",
      "Epoch 14/20\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0042 - mae: 0.0491 - val_loss: 0.0049 - val_mae: 0.0523\n",
      "Epoch 15/20\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0042 - mae: 0.0491 - val_loss: 0.0061 - val_mae: 0.0577\n",
      "Epoch 16/20\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0042 - mae: 0.0490 - val_loss: 0.0051 - val_mae: 0.0526\n",
      "Epoch 17/20\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0041 - mae: 0.0488 - val_loss: 0.0057 - val_mae: 0.0553\n",
      "Epoch 18/20\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0041 - mae: 0.0489 - val_loss: 0.0050 - val_mae: 0.0526\n",
      "Epoch 19/20\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0041 - mae: 0.0486 - val_loss: 0.0050 - val_mae: 0.0524\n",
      "Epoch 20/20\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0041 - mae: 0.0486 - val_loss: 0.0051 - val_mae: 0.0526\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step   \n",
      "✅ Done with wheat_Bidar_daily.csv | MAE=276.24, RMSE=375.56, R2=0.36, MAPE=10.02%, Accuracy=89.98%\n",
      "\n",
      "========== Processing: wheat_Bijapur_daily.csv ==========\n",
      "Epoch 1/20\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.0083 - mae: 0.0674 - val_loss: 0.0019 - val_mae: 0.0336\n",
      "Epoch 2/20\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0053 - mae: 0.0552 - val_loss: 0.0017 - val_mae: 0.0307\n",
      "Epoch 3/20\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0052 - mae: 0.0541 - val_loss: 0.0014 - val_mae: 0.0263\n",
      "Epoch 4/20\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0050 - mae: 0.0532 - val_loss: 0.0014 - val_mae: 0.0257\n",
      "Epoch 5/20\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0050 - mae: 0.0527 - val_loss: 0.0015 - val_mae: 0.0274\n",
      "Epoch 6/20\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0049 - mae: 0.0521 - val_loss: 0.0017 - val_mae: 0.0318\n",
      "Epoch 7/20\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0049 - mae: 0.0522 - val_loss: 0.0020 - val_mae: 0.0355\n",
      "Epoch 8/20\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0049 - mae: 0.0523 - val_loss: 0.0018 - val_mae: 0.0332\n",
      "Epoch 9/20\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0049 - mae: 0.0520 - val_loss: 0.0016 - val_mae: 0.0297\n",
      "Epoch 10/20\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0048 - mae: 0.0517 - val_loss: 0.0016 - val_mae: 0.0300\n",
      "Epoch 11/20\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0048 - mae: 0.0518 - val_loss: 0.0025 - val_mae: 0.0420\n",
      "Epoch 12/20\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0048 - mae: 0.0514 - val_loss: 0.0013 - val_mae: 0.0257\n",
      "Epoch 13/20\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0048 - mae: 0.0517 - val_loss: 0.0014 - val_mae: 0.0262\n",
      "Epoch 14/20\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0048 - mae: 0.0519 - val_loss: 0.0021 - val_mae: 0.0374\n",
      "Epoch 15/20\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0048 - mae: 0.0513 - val_loss: 0.0014 - val_mae: 0.0257\n",
      "Epoch 16/20\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0048 - mae: 0.0512 - val_loss: 0.0013 - val_mae: 0.0249\n",
      "Epoch 17/20\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0048 - mae: 0.0517 - val_loss: 0.0017 - val_mae: 0.0318\n",
      "Epoch 18/20\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0048 - mae: 0.0513 - val_loss: 0.0019 - val_mae: 0.0349\n",
      "Epoch 19/20\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0048 - mae: 0.0512 - val_loss: 0.0013 - val_mae: 0.0263\n",
      "Epoch 20/20\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0048 - mae: 0.0516 - val_loss: 0.0015 - val_mae: 0.0299\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step   \n",
      "✅ Done with wheat_Bijapur_daily.csv | MAE=239.21, RMSE=314.43, R2=0.56, MAPE=8.05%, Accuracy=91.95%\n",
      "\n",
      "========== Processing: wheat_Chikmagalur_daily.csv ==========\n",
      "Epoch 1/20\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0294 - mae: 0.1173 - val_loss: 0.0084 - val_mae: 0.0677\n",
      "Epoch 2/20\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0180 - mae: 0.0929 - val_loss: 0.0086 - val_mae: 0.0618\n",
      "Epoch 3/20\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0168 - mae: 0.0886 - val_loss: 0.0074 - val_mae: 0.0670\n",
      "Epoch 4/20\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0158 - mae: 0.0853 - val_loss: 0.0070 - val_mae: 0.0621\n",
      "Epoch 5/20\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0146 - mae: 0.0823 - val_loss: 0.0075 - val_mae: 0.0652\n",
      "Epoch 6/20\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0135 - mae: 0.0798 - val_loss: 0.0098 - val_mae: 0.0788\n",
      "Epoch 7/20\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0128 - mae: 0.0768 - val_loss: 0.0111 - val_mae: 0.0831\n",
      "Epoch 8/20\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0128 - mae: 0.0760 - val_loss: 0.0086 - val_mae: 0.0716\n",
      "Epoch 9/20\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0124 - mae: 0.0739 - val_loss: 0.0080 - val_mae: 0.0696\n",
      "Epoch 10/20\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0122 - mae: 0.0731 - val_loss: 0.0109 - val_mae: 0.0833\n",
      "Epoch 11/20\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0120 - mae: 0.0721 - val_loss: 0.0102 - val_mae: 0.0797\n",
      "Epoch 12/20\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0120 - mae: 0.0717 - val_loss: 0.0086 - val_mae: 0.0696\n",
      "Epoch 13/20\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0119 - mae: 0.0715 - val_loss: 0.0073 - val_mae: 0.0601\n",
      "Epoch 14/20\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0118 - mae: 0.0709 - val_loss: 0.0087 - val_mae: 0.0672\n",
      "Epoch 15/20\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0117 - mae: 0.0709 - val_loss: 0.0083 - val_mae: 0.0684\n",
      "Epoch 16/20\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0117 - mae: 0.0703 - val_loss: 0.0085 - val_mae: 0.0709\n",
      "Epoch 17/20\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0117 - mae: 0.0701 - val_loss: 0.0089 - val_mae: 0.0734\n",
      "Epoch 18/20\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0117 - mae: 0.0704 - val_loss: 0.0065 - val_mae: 0.0543\n",
      "Epoch 19/20\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0117 - mae: 0.0703 - val_loss: 0.0103 - val_mae: 0.0801\n",
      "Epoch 20/20\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0116 - mae: 0.0695 - val_loss: 0.0078 - val_mae: 0.0690\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step   \n",
      "✅ Done with wheat_Chikmagalur_daily.csv | MAE=344.88, RMSE=441.45, R2=0.04, MAPE=13.58%, Accuracy=86.42%\n",
      "\n",
      "========== Processing: wheat_Chitradurga_daily.csv ==========\n",
      "Epoch 1/20\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0637 - mae: 0.2111 - val_loss: 7.1611e-04 - val_mae: 0.0265\n",
      "Epoch 2/20\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0382 - mae: 0.1627 - val_loss: 4.8886e-04 - val_mae: 0.0217\n",
      "Epoch 3/20\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0359 - mae: 0.1559 - val_loss: 0.0031 - val_mae: 0.0545\n",
      "Epoch 4/20\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0327 - mae: 0.1459 - val_loss: 0.0047 - val_mae: 0.0678\n",
      "Epoch 5/20\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0295 - mae: 0.1322 - val_loss: 0.0081 - val_mae: 0.0860\n",
      "Epoch 6/20\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0288 - mae: 0.1254 - val_loss: 3.8855e-04 - val_mae: 0.0164\n",
      "Epoch 7/20\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0282 - mae: 0.1223 - val_loss: 0.0041 - val_mae: 0.0621\n",
      "Epoch 8/20\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0279 - mae: 0.1216 - val_loss: 0.0024 - val_mae: 0.0417\n",
      "Epoch 9/20\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0277 - mae: 0.1198 - val_loss: 6.5468e-04 - val_mae: 0.0206\n",
      "Epoch 10/20\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0275 - mae: 0.1180 - val_loss: 0.0026 - val_mae: 0.0454\n",
      "Epoch 11/20\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0270 - mae: 0.1170 - val_loss: 0.0083 - val_mae: 0.0832\n",
      "Epoch 12/20\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0266 - mae: 0.1148 - val_loss: 0.0022 - val_mae: 0.0379\n",
      "Epoch 13/20\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0265 - mae: 0.1161 - val_loss: 0.0059 - val_mae: 0.0727\n",
      "Epoch 14/20\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0259 - mae: 0.1147 - val_loss: 0.0055 - val_mae: 0.0671\n",
      "Epoch 15/20\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0249 - mae: 0.1123 - val_loss: 0.0018 - val_mae: 0.0334\n",
      "Epoch 16/20\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0245 - mae: 0.1117 - val_loss: 0.0071 - val_mae: 0.0725\n",
      "Epoch 17/20\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0241 - mae: 0.1108 - val_loss: 0.0312 - val_mae: 0.1682\n",
      "Epoch 18/20\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0231 - mae: 0.1066 - val_loss: 0.0148 - val_mae: 0.1108\n",
      "Epoch 19/20\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0227 - mae: 0.1049 - val_loss: 0.0246 - val_mae: 0.1429\n",
      "Epoch 20/20\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0225 - mae: 0.1047 - val_loss: 0.0142 - val_mae: 0.1051\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step \n",
      "✅ Done with wheat_Chitradurga_daily.csv | MAE=196.39, RMSE=222.48, R2=-8.57, MAPE=6.5%, Accuracy=93.5%\n",
      "\n",
      "========== Processing: wheat_Davangere_daily.csv ==========\n",
      "Epoch 1/20\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0213 - mae: 0.1187 - val_loss: 0.0210 - val_mae: 0.1290\n",
      "Epoch 2/20\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0142 - mae: 0.1028 - val_loss: 0.0268 - val_mae: 0.1471\n",
      "Epoch 3/20\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0138 - mae: 0.1011 - val_loss: 0.0287 - val_mae: 0.1515\n",
      "Epoch 4/20\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0131 - mae: 0.0973 - val_loss: 0.0395 - val_mae: 0.1792\n",
      "Epoch 5/20\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0127 - mae: 0.0940 - val_loss: 0.0454 - val_mae: 0.1937\n",
      "Epoch 6/20\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0124 - mae: 0.0915 - val_loss: 0.0456 - val_mae: 0.1932\n",
      "Epoch 7/20\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0124 - mae: 0.0911 - val_loss: 0.0479 - val_mae: 0.1980\n",
      "Epoch 8/20\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0122 - mae: 0.0901 - val_loss: 0.0432 - val_mae: 0.1869\n",
      "Epoch 9/20\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0121 - mae: 0.0898 - val_loss: 0.0521 - val_mae: 0.2074\n",
      "Epoch 10/20\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0123 - mae: 0.0906 - val_loss: 0.0497 - val_mae: 0.2020\n",
      "Epoch 11/20\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0120 - mae: 0.0895 - val_loss: 0.0404 - val_mae: 0.1815\n",
      "Epoch 12/20\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0119 - mae: 0.0892 - val_loss: 0.0450 - val_mae: 0.1923\n",
      "Epoch 13/20\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0117 - mae: 0.0882 - val_loss: 0.0338 - val_mae: 0.1666\n",
      "Epoch 14/20\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0114 - mae: 0.0871 - val_loss: 0.0601 - val_mae: 0.2249\n",
      "Epoch 15/20\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0112 - mae: 0.0867 - val_loss: 0.0401 - val_mae: 0.1839\n",
      "Epoch 16/20\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0110 - mae: 0.0858 - val_loss: 0.0540 - val_mae: 0.2143\n",
      "Epoch 17/20\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0107 - mae: 0.0847 - val_loss: 0.0815 - val_mae: 0.2645\n",
      "Epoch 18/20\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0107 - mae: 0.0840 - val_loss: 0.0867 - val_mae: 0.2755\n",
      "Epoch 19/20\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0104 - mae: 0.0832 - val_loss: 0.1010 - val_mae: 0.2978\n",
      "Epoch 20/20\n",
      "\u001b[1m261/261\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0104 - mae: 0.0827 - val_loss: 0.0956 - val_mae: 0.2878\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step  \n",
      "✅ Done with wheat_Davangere_daily.csv | MAE=877.39, RMSE=942.96, R2=-6.16, MAPE=32.12%, Accuracy=67.88%\n",
      "\n",
      "========== Processing: wheat_Dharwad_daily.csv ==========\n",
      "Epoch 1/20\n",
      "\u001b[1m550/550\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0077 - mae: 0.0607 - val_loss: 0.0120 - val_mae: 0.0833\n",
      "Epoch 2/20\n",
      "\u001b[1m550/550\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0060 - mae: 0.0529 - val_loss: 0.0119 - val_mae: 0.0828\n",
      "Epoch 3/20\n",
      "\u001b[1m550/550\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0059 - mae: 0.0524 - val_loss: 0.0125 - val_mae: 0.0832\n",
      "Epoch 4/20\n",
      "\u001b[1m550/550\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0059 - mae: 0.0520 - val_loss: 0.0138 - val_mae: 0.0858\n",
      "Epoch 5/20\n",
      "\u001b[1m550/550\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0058 - mae: 0.0519 - val_loss: 0.0140 - val_mae: 0.0857\n",
      "Epoch 6/20\n",
      "\u001b[1m550/550\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0058 - mae: 0.0520 - val_loss: 0.0215 - val_mae: 0.1090\n",
      "Epoch 7/20\n",
      "\u001b[1m550/550\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0058 - mae: 0.0518 - val_loss: 0.0259 - val_mae: 0.1217\n",
      "Epoch 8/20\n",
      "\u001b[1m550/550\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0057 - mae: 0.0516 - val_loss: 0.0264 - val_mae: 0.1215\n",
      "Epoch 9/20\n",
      "\u001b[1m550/550\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0057 - mae: 0.0516 - val_loss: 0.0222 - val_mae: 0.1085\n",
      "Epoch 10/20\n",
      "\u001b[1m550/550\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0057 - mae: 0.0517 - val_loss: 0.0306 - val_mae: 0.1302\n",
      "Epoch 11/20\n",
      "\u001b[1m550/550\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0057 - mae: 0.0515 - val_loss: 0.0350 - val_mae: 0.1398\n",
      "Epoch 12/20\n",
      "\u001b[1m550/550\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0057 - mae: 0.0517 - val_loss: 0.0397 - val_mae: 0.1502\n",
      "Epoch 13/20\n",
      "\u001b[1m550/550\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0056 - mae: 0.0514 - val_loss: 0.0307 - val_mae: 0.1289\n",
      "Epoch 14/20\n",
      "\u001b[1m550/550\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0056 - mae: 0.0516 - val_loss: 0.0228 - val_mae: 0.1097\n",
      "Epoch 15/20\n",
      "\u001b[1m550/550\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0056 - mae: 0.0516 - val_loss: 0.0390 - val_mae: 0.1476\n",
      "Epoch 16/20\n",
      "\u001b[1m550/550\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0056 - mae: 0.0515 - val_loss: 0.0380 - val_mae: 0.1434\n",
      "Epoch 17/20\n",
      "\u001b[1m550/550\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0056 - mae: 0.0515 - val_loss: 0.0322 - val_mae: 0.1317\n",
      "Epoch 18/20\n",
      "\u001b[1m550/550\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0056 - mae: 0.0515 - val_loss: 0.0284 - val_mae: 0.1223\n",
      "Epoch 19/20\n",
      "\u001b[1m550/550\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0057 - mae: 0.0518 - val_loss: 0.0406 - val_mae: 0.1500\n",
      "Epoch 20/20\n",
      "\u001b[1m550/550\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0056 - mae: 0.0515 - val_loss: 0.0439 - val_mae: 0.1561\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step   \n",
      "✅ Done with wheat_Dharwad_daily.csv | MAE=642.97, RMSE=863.48, R2=-1.3, MAPE=24.67%, Accuracy=75.33%\n",
      "\n",
      "========== Processing: wheat_Gadag_daily.csv ==========\n",
      "Epoch 1/20\n",
      "\u001b[1m503/503\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 7.5101e-04 - mae: 0.0189 - val_loss: 0.0017 - val_mae: 0.0291\n",
      "Epoch 2/20\n",
      "\u001b[1m503/503\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 6.9645e-04 - mae: 0.0180 - val_loss: 0.0015 - val_mae: 0.0276\n",
      "Epoch 3/20\n",
      "\u001b[1m503/503\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 6.8854e-04 - mae: 0.0179 - val_loss: 0.0018 - val_mae: 0.0305\n",
      "Epoch 4/20\n",
      "\u001b[1m503/503\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 6.8276e-04 - mae: 0.0177 - val_loss: 0.0019 - val_mae: 0.0313\n",
      "Epoch 5/20\n",
      "\u001b[1m503/503\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 6.8030e-04 - mae: 0.0177 - val_loss: 0.0018 - val_mae: 0.0309\n",
      "Epoch 6/20\n",
      "\u001b[1m503/503\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 6.8232e-04 - mae: 0.0178 - val_loss: 0.0019 - val_mae: 0.0311\n",
      "Epoch 7/20\n",
      "\u001b[1m503/503\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 6.7409e-04 - mae: 0.0176 - val_loss: 0.0018 - val_mae: 0.0301\n",
      "Epoch 8/20\n",
      "\u001b[1m503/503\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 6.7787e-04 - mae: 0.0176 - val_loss: 0.0020 - val_mae: 0.0322\n",
      "Epoch 9/20\n",
      "\u001b[1m503/503\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 6.7613e-04 - mae: 0.0176 - val_loss: 0.0019 - val_mae: 0.0318\n",
      "Epoch 10/20\n",
      "\u001b[1m503/503\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 6.7272e-04 - mae: 0.0175 - val_loss: 0.0022 - val_mae: 0.0349\n",
      "Epoch 11/20\n",
      "\u001b[1m503/503\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 6.7482e-04 - mae: 0.0176 - val_loss: 0.0021 - val_mae: 0.0334\n",
      "Epoch 12/20\n",
      "\u001b[1m503/503\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 6.7667e-04 - mae: 0.0176 - val_loss: 0.0024 - val_mae: 0.0359\n",
      "Epoch 13/20\n",
      "\u001b[1m503/503\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 6.7439e-04 - mae: 0.0176 - val_loss: 0.0024 - val_mae: 0.0360\n",
      "Epoch 14/20\n",
      "\u001b[1m503/503\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 6.7248e-04 - mae: 0.0176 - val_loss: 0.0024 - val_mae: 0.0364\n",
      "Epoch 15/20\n",
      "\u001b[1m503/503\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 6.7491e-04 - mae: 0.0176 - val_loss: 0.0024 - val_mae: 0.0366\n",
      "Epoch 16/20\n",
      "\u001b[1m503/503\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 6.7255e-04 - mae: 0.0176 - val_loss: 0.0020 - val_mae: 0.0323\n",
      "Epoch 17/20\n",
      "\u001b[1m503/503\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 6.7321e-04 - mae: 0.0175 - val_loss: 0.0026 - val_mae: 0.0378\n",
      "Epoch 18/20\n",
      "\u001b[1m503/503\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 6.7175e-04 - mae: 0.0175 - val_loss: 0.0026 - val_mae: 0.0378\n",
      "Epoch 19/20\n",
      "\u001b[1m503/503\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 6.7299e-04 - mae: 0.0175 - val_loss: 0.0026 - val_mae: 0.0376\n",
      "Epoch 20/20\n",
      "\u001b[1m503/503\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 6.7457e-04 - mae: 0.0176 - val_loss: 0.0028 - val_mae: 0.0394\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step   \n",
      "✅ Done with wheat_Gadag_daily.csv | MAE=573.54, RMSE=766.13, R2=-0.27, MAPE=20.51%, Accuracy=79.49%\n",
      "\n",
      "========== Processing: wheat_Hassan_daily.csv ==========\n",
      "Epoch 1/20\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0018 - mae: 0.0248 - val_loss: 7.1888e-04 - val_mae: 0.0213\n",
      "Epoch 2/20\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 9.2769e-04 - mae: 0.0168 - val_loss: 2.8833e-04 - val_mae: 0.0143\n",
      "Epoch 3/20\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 9.1769e-04 - mae: 0.0167 - val_loss: 3.4955e-04 - val_mae: 0.0150\n",
      "Epoch 4/20\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 8.9488e-04 - mae: 0.0163 - val_loss: 3.0242e-04 - val_mae: 0.0143\n",
      "Epoch 5/20\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 8.6851e-04 - mae: 0.0161 - val_loss: 2.8205e-04 - val_mae: 0.0140\n",
      "Epoch 6/20\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 8.5749e-04 - mae: 0.0163 - val_loss: 2.8013e-04 - val_mae: 0.0138\n",
      "Epoch 7/20\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 8.1818e-04 - mae: 0.0157 - val_loss: 3.1119e-04 - val_mae: 0.0141\n",
      "Epoch 8/20\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 7.8069e-04 - mae: 0.0158 - val_loss: 2.9167e-04 - val_mae: 0.0138\n",
      "Epoch 9/20\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 7.5129e-04 - mae: 0.0157 - val_loss: 2.3376e-04 - val_mae: 0.0122\n",
      "Epoch 10/20\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 7.1830e-04 - mae: 0.0154 - val_loss: 2.2236e-04 - val_mae: 0.0118\n",
      "Epoch 11/20\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 7.1599e-04 - mae: 0.0152 - val_loss: 2.2998e-04 - val_mae: 0.0120\n",
      "Epoch 12/20\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 7.2062e-04 - mae: 0.0153 - val_loss: 2.7361e-04 - val_mae: 0.0128\n",
      "Epoch 13/20\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 7.0324e-04 - mae: 0.0152 - val_loss: 4.4615e-04 - val_mae: 0.0171\n",
      "Epoch 14/20\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 7.1202e-04 - mae: 0.0154 - val_loss: 3.2125e-04 - val_mae: 0.0139\n",
      "Epoch 15/20\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 6.9614e-04 - mae: 0.0150 - val_loss: 2.6862e-04 - val_mae: 0.0125\n",
      "Epoch 16/20\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 6.7402e-04 - mae: 0.0147 - val_loss: 3.1655e-04 - val_mae: 0.0139\n",
      "Epoch 17/20\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 6.5926e-04 - mae: 0.0147 - val_loss: 2.3073e-04 - val_mae: 0.0119\n",
      "Epoch 18/20\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 6.7101e-04 - mae: 0.0148 - val_loss: 3.1578e-04 - val_mae: 0.0138\n",
      "Epoch 19/20\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 6.7030e-04 - mae: 0.0149 - val_loss: 2.1978e-04 - val_mae: 0.0118\n",
      "Epoch 20/20\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 6.7123e-04 - mae: 0.0147 - val_loss: 2.3759e-04 - val_mae: 0.0120\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step   \n",
      "✅ Done with wheat_Hassan_daily.csv | MAE=156.04, RMSE=200.38, R2=0.77, MAPE=5.03%, Accuracy=94.97%\n",
      "\n",
      "========== Processing: wheat_Haveri_daily.csv ==========\n",
      "Epoch 1/20\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0194 - mae: 0.0999 - val_loss: 0.0195 - val_mae: 0.1104\n",
      "Epoch 2/20\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0131 - mae: 0.0843 - val_loss: 0.0175 - val_mae: 0.1034\n",
      "Epoch 3/20\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0127 - mae: 0.0827 - val_loss: 0.0206 - val_mae: 0.1161\n",
      "Epoch 4/20\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0124 - mae: 0.0818 - val_loss: 0.0245 - val_mae: 0.1262\n",
      "Epoch 5/20\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0123 - mae: 0.0816 - val_loss: 0.0230 - val_mae: 0.1229\n",
      "Epoch 6/20\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0122 - mae: 0.0811 - val_loss: 0.0241 - val_mae: 0.1258\n",
      "Epoch 7/20\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0120 - mae: 0.0807 - val_loss: 0.0238 - val_mae: 0.1250\n",
      "Epoch 8/20\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0120 - mae: 0.0808 - val_loss: 0.0246 - val_mae: 0.1274\n",
      "Epoch 9/20\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0119 - mae: 0.0803 - val_loss: 0.0307 - val_mae: 0.1440\n",
      "Epoch 10/20\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0119 - mae: 0.0806 - val_loss: 0.0269 - val_mae: 0.1329\n",
      "Epoch 11/20\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0120 - mae: 0.0809 - val_loss: 0.0252 - val_mae: 0.1289\n",
      "Epoch 12/20\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0118 - mae: 0.0806 - val_loss: 0.0297 - val_mae: 0.1399\n",
      "Epoch 13/20\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0118 - mae: 0.0804 - val_loss: 0.0261 - val_mae: 0.1300\n",
      "Epoch 14/20\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0118 - mae: 0.0807 - val_loss: 0.0291 - val_mae: 0.1371\n",
      "Epoch 15/20\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0117 - mae: 0.0802 - val_loss: 0.0304 - val_mae: 0.1396\n",
      "Epoch 16/20\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0117 - mae: 0.0804 - val_loss: 0.0327 - val_mae: 0.1450\n",
      "Epoch 17/20\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0117 - mae: 0.0803 - val_loss: 0.0330 - val_mae: 0.1429\n",
      "Epoch 18/20\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0116 - mae: 0.0801 - val_loss: 0.0412 - val_mae: 0.1604\n",
      "Epoch 19/20\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0116 - mae: 0.0800 - val_loss: 0.0392 - val_mae: 0.1573\n",
      "Epoch 20/20\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0116 - mae: 0.0799 - val_loss: 0.0485 - val_mae: 0.1754\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step   \n",
      "✅ Done with wheat_Haveri_daily.csv | MAE=423.07, RMSE=531.47, R2=-1.18, MAPE=19.14%, Accuracy=80.86%\n",
      "\n",
      "========== Processing: wheat_Kalburgi_daily.csv ==========\n",
      "Epoch 1/20\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0271 - mae: 0.1299 - val_loss: 0.0168 - val_mae: 0.1013\n",
      "Epoch 2/20\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0163 - mae: 0.1079 - val_loss: 0.0119 - val_mae: 0.0778\n",
      "Epoch 3/20\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0147 - mae: 0.1013 - val_loss: 0.0111 - val_mae: 0.0680\n",
      "Epoch 4/20\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0137 - mae: 0.0941 - val_loss: 0.0129 - val_mae: 0.0887\n",
      "Epoch 5/20\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0134 - mae: 0.0905 - val_loss: 0.0117 - val_mae: 0.0784\n",
      "Epoch 6/20\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0133 - mae: 0.0892 - val_loss: 0.0106 - val_mae: 0.0693\n",
      "Epoch 7/20\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0132 - mae: 0.0884 - val_loss: 0.0131 - val_mae: 0.0909\n",
      "Epoch 8/20\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0132 - mae: 0.0877 - val_loss: 0.0127 - val_mae: 0.0893\n",
      "Epoch 9/20\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0131 - mae: 0.0871 - val_loss: 0.0103 - val_mae: 0.0614\n",
      "Epoch 10/20\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0130 - mae: 0.0865 - val_loss: 0.0117 - val_mae: 0.0825\n",
      "Epoch 11/20\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0130 - mae: 0.0863 - val_loss: 0.0098 - val_mae: 0.0659\n",
      "Epoch 12/20\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0129 - mae: 0.0855 - val_loss: 0.0110 - val_mae: 0.0781\n",
      "Epoch 13/20\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0129 - mae: 0.0859 - val_loss: 0.0096 - val_mae: 0.0594\n",
      "Epoch 14/20\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0128 - mae: 0.0856 - val_loss: 0.0133 - val_mae: 0.0922\n",
      "Epoch 15/20\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0128 - mae: 0.0857 - val_loss: 0.0123 - val_mae: 0.0864\n",
      "Epoch 16/20\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0127 - mae: 0.0849 - val_loss: 0.0115 - val_mae: 0.0828\n",
      "Epoch 17/20\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0127 - mae: 0.0849 - val_loss: 0.0097 - val_mae: 0.0673\n",
      "Epoch 18/20\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0126 - mae: 0.0848 - val_loss: 0.0108 - val_mae: 0.0768\n",
      "Epoch 19/20\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0126 - mae: 0.0849 - val_loss: 0.0092 - val_mae: 0.0610\n",
      "Epoch 20/20\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0124 - mae: 0.0842 - val_loss: 0.0093 - val_mae: 0.0625\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step   \n",
      "✅ Done with wheat_Kalburgi_daily.csv | MAE=226.04, RMSE=348.67, R2=0.55, MAPE=8.31%, Accuracy=91.69%\n",
      "\n",
      "========== Processing: wheat_Kolar_daily.csv ==========\n",
      "Epoch 1/20\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0142 - mae: 0.0925 - val_loss: 0.0230 - val_mae: 0.1333\n",
      "Epoch 2/20\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0058 - mae: 0.0606 - val_loss: 0.0228 - val_mae: 0.1320\n",
      "Epoch 3/20\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0055 - mae: 0.0580 - val_loss: 0.0218 - val_mae: 0.1263\n",
      "Epoch 4/20\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0052 - mae: 0.0561 - val_loss: 0.0201 - val_mae: 0.1261\n",
      "Epoch 5/20\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0047 - mae: 0.0516 - val_loss: 0.0185 - val_mae: 0.1131\n",
      "Epoch 6/20\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0044 - mae: 0.0488 - val_loss: 0.0192 - val_mae: 0.1155\n",
      "Epoch 7/20\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0043 - mae: 0.0465 - val_loss: 0.0180 - val_mae: 0.0977\n",
      "Epoch 8/20\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0043 - mae: 0.0461 - val_loss: 0.0179 - val_mae: 0.0975\n",
      "Epoch 9/20\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0042 - mae: 0.0440 - val_loss: 0.0176 - val_mae: 0.0995\n",
      "Epoch 10/20\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0041 - mae: 0.0434 - val_loss: 0.0178 - val_mae: 0.0963\n",
      "Epoch 11/20\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0041 - mae: 0.0439 - val_loss: 0.0190 - val_mae: 0.1029\n",
      "Epoch 12/20\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0042 - mae: 0.0438 - val_loss: 0.0179 - val_mae: 0.0975\n",
      "Epoch 13/20\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0042 - mae: 0.0436 - val_loss: 0.0189 - val_mae: 0.1063\n",
      "Epoch 14/20\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0041 - mae: 0.0443 - val_loss: 0.0171 - val_mae: 0.0957\n",
      "Epoch 15/20\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0041 - mae: 0.0433 - val_loss: 0.0168 - val_mae: 0.0947\n",
      "Epoch 16/20\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0041 - mae: 0.0435 - val_loss: 0.0171 - val_mae: 0.1001\n",
      "Epoch 17/20\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0041 - mae: 0.0438 - val_loss: 0.0183 - val_mae: 0.1041\n",
      "Epoch 18/20\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0040 - mae: 0.0429 - val_loss: 0.0192 - val_mae: 0.1092\n",
      "Epoch 19/20\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0040 - mae: 0.0429 - val_loss: 0.0171 - val_mae: 0.0980\n",
      "Epoch 20/20\n",
      "\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0040 - mae: 0.0430 - val_loss: 0.0165 - val_mae: 0.0955\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step  \n",
      "✅ Done with wheat_Kolar_daily.csv | MAE=315.18, RMSE=424.03, R2=0.44, MAPE=12.12%, Accuracy=87.88%\n",
      "\n",
      "========== Processing: wheat_Koppal_daily.csv ==========\n",
      "Epoch 1/20\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0164 - mae: 0.1010 - val_loss: 0.0182 - val_mae: 0.1030\n",
      "Epoch 2/20\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0106 - mae: 0.0869 - val_loss: 0.0148 - val_mae: 0.0956\n",
      "Epoch 3/20\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0099 - mae: 0.0824 - val_loss: 0.0141 - val_mae: 0.0959\n",
      "Epoch 4/20\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0096 - mae: 0.0805 - val_loss: 0.0133 - val_mae: 0.0908\n",
      "Epoch 5/20\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0095 - mae: 0.0792 - val_loss: 0.0136 - val_mae: 0.0916\n",
      "Epoch 6/20\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0095 - mae: 0.0791 - val_loss: 0.0137 - val_mae: 0.0886\n",
      "Epoch 7/20\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0094 - mae: 0.0787 - val_loss: 0.0131 - val_mae: 0.0876\n",
      "Epoch 8/20\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0094 - mae: 0.0788 - val_loss: 0.0137 - val_mae: 0.0871\n",
      "Epoch 9/20\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0092 - mae: 0.0779 - val_loss: 0.0132 - val_mae: 0.0865\n",
      "Epoch 10/20\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0092 - mae: 0.0779 - val_loss: 0.0127 - val_mae: 0.0860\n",
      "Epoch 11/20\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0092 - mae: 0.0779 - val_loss: 0.0126 - val_mae: 0.0869\n",
      "Epoch 12/20\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0091 - mae: 0.0774 - val_loss: 0.0172 - val_mae: 0.0937\n",
      "Epoch 13/20\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0091 - mae: 0.0777 - val_loss: 0.0135 - val_mae: 0.0859\n",
      "Epoch 14/20\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0090 - mae: 0.0772 - val_loss: 0.0132 - val_mae: 0.0906\n",
      "Epoch 15/20\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0090 - mae: 0.0772 - val_loss: 0.0128 - val_mae: 0.0875\n",
      "Epoch 16/20\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0090 - mae: 0.0771 - val_loss: 0.0167 - val_mae: 0.0914\n",
      "Epoch 17/20\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0089 - mae: 0.0770 - val_loss: 0.0127 - val_mae: 0.0862\n",
      "Epoch 18/20\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0088 - mae: 0.0764 - val_loss: 0.0137 - val_mae: 0.0857\n",
      "Epoch 19/20\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0088 - mae: 0.0761 - val_loss: 0.0142 - val_mae: 0.0878\n",
      "Epoch 20/20\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0088 - mae: 0.0763 - val_loss: 0.0132 - val_mae: 0.0840\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step   \n",
      "✅ Done with wheat_Koppal_daily.csv | MAE=201.55, RMSE=276.0, R2=0.3, MAPE=8.54%, Accuracy=91.46%\n",
      "\n",
      "========== Processing: wheat_MadikeriKodagu_daily.csv ==========\n",
      "Epoch 1/20\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.1302 - mae: 0.2671 - val_loss: 0.0112 - val_mae: 0.1038\n",
      "Epoch 2/20\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0022 - mae: 0.0264 - val_loss: 1.0108e-04 - val_mae: 0.0088\n",
      "Epoch 3/20\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0012 - mae: 0.0095 - val_loss: 2.4081e-05 - val_mae: 0.0038\n",
      "Epoch 4/20\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0011 - mae: 0.0054 - val_loss: 1.9393e-05 - val_mae: 0.0040\n",
      "Epoch 5/20\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0011 - mae: 0.0049 - val_loss: 4.5655e-05 - val_mae: 0.0062\n",
      "Epoch 6/20\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0011 - mae: 0.0047 - val_loss: 7.8162e-05 - val_mae: 0.0084\n",
      "Epoch 7/20\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0011 - mae: 0.0063 - val_loss: 4.7272e-05 - val_mae: 0.0062\n",
      "Epoch 8/20\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0011 - mae: 0.0049 - val_loss: 7.4161e-06 - val_mae: 0.0025\n",
      "Epoch 9/20\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0011 - mae: 0.0049 - val_loss: 5.1561e-06 - val_mae: 0.0021\n",
      "Epoch 10/20\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0011 - mae: 0.0041 - val_loss: 1.9332e-05 - val_mae: 0.0039\n",
      "Epoch 11/20\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0011 - mae: 0.0060 - val_loss: 1.3808e-05 - val_mae: 0.0033\n",
      "Epoch 12/20\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0010 - mae: 0.0049 - val_loss: 1.6047e-05 - val_mae: 0.0037\n",
      "Epoch 13/20\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0010 - mae: 0.0052 - val_loss: 1.6413e-05 - val_mae: 0.0032\n",
      "Epoch 14/20\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0010 - mae: 0.0055 - val_loss: 5.4763e-06 - val_mae: 0.0018\n",
      "Epoch 15/20\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.9124e-04 - mae: 0.0045 - val_loss: 7.6313e-06 - val_mae: 0.0024\n",
      "Epoch 16/20\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.7099e-04 - mae: 0.0044 - val_loss: 9.3952e-07 - val_mae: 6.8231e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.4571e-04 - mae: 0.0040 - val_loss: 8.7751e-05 - val_mae: 0.0090\n",
      "Epoch 18/20\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 9.5744e-04 - mae: 0.0056 - val_loss: 3.1232e-05 - val_mae: 0.0050\n",
      "Epoch 19/20\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.3052e-04 - mae: 0.0048 - val_loss: 3.0121e-05 - val_mae: 0.0049\n",
      "Epoch 20/20\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 9.3030e-04 - mae: 0.0056 - val_loss: 2.4018e-06 - val_mae: 0.0014\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step \n",
      "✅ Done with wheat_MadikeriKodagu_daily.csv | MAE=26.99, RMSE=28.87, R2=1.0, MAPE=1.11%, Accuracy=98.89%\n",
      "\n",
      "========== Processing: wheat_Mandya_daily.csv ==========\n",
      "Epoch 1/20\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0806 - mae: 0.2146 - val_loss: 3.1679e-04 - val_mae: 0.0145\n",
      "Epoch 2/20\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0272 - mae: 0.1168 - val_loss: 9.1088e-05 - val_mae: 0.0091\n",
      "Epoch 3/20\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0267 - mae: 0.1152 - val_loss: 2.6770e-04 - val_mae: 0.0155\n",
      "Epoch 4/20\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0258 - mae: 0.1127 - val_loss: 4.7812e-04 - val_mae: 0.0211\n",
      "Epoch 5/20\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0248 - mae: 0.1128 - val_loss: 7.2774e-04 - val_mae: 0.0260\n",
      "Epoch 6/20\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0232 - mae: 0.1069 - val_loss: 7.4226e-04 - val_mae: 0.0168\n",
      "Epoch 7/20\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0214 - mae: 0.0993 - val_loss: 0.0018 - val_mae: 0.0326\n",
      "Epoch 8/20\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0208 - mae: 0.0982 - val_loss: 0.0020 - val_mae: 0.0259\n",
      "Epoch 9/20\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0207 - mae: 0.0978 - val_loss: 0.0016 - val_mae: 0.0199\n",
      "Epoch 10/20\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0202 - mae: 0.0931 - val_loss: 5.2448e-04 - val_mae: 0.0208\n",
      "Epoch 11/20\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0200 - mae: 0.0915 - val_loss: 0.0011 - val_mae: 0.0188\n",
      "Epoch 12/20\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0199 - mae: 0.0910 - val_loss: 0.0026 - val_mae: 0.0324\n",
      "Epoch 13/20\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0198 - mae: 0.0914 - val_loss: 0.0029 - val_mae: 0.0287\n",
      "Epoch 14/20\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0196 - mae: 0.0888 - val_loss: 0.0013 - val_mae: 0.0237\n",
      "Epoch 15/20\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0195 - mae: 0.0911 - val_loss: 0.0018 - val_mae: 0.0226\n",
      "Epoch 16/20\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0197 - mae: 0.0923 - val_loss: 0.0017 - val_mae: 0.0227\n",
      "Epoch 17/20\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0189 - mae: 0.0868 - val_loss: 0.0020 - val_mae: 0.0328\n",
      "Epoch 18/20\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0189 - mae: 0.0879 - val_loss: 0.0020 - val_mae: 0.0216\n",
      "Epoch 19/20\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0186 - mae: 0.0885 - val_loss: 0.0060 - val_mae: 0.0530\n",
      "Epoch 20/20\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0181 - mae: 0.0870 - val_loss: 0.0040 - val_mae: 0.0297\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step \n",
      "✅ Done with wheat_Mandya_daily.csv | MAE=55.06, RMSE=117.02, R2=0.79, MAPE=1.93%, Accuracy=98.07%\n",
      "\n",
      "========== Processing: wheat_Mysore_daily.csv ==========\n",
      "Epoch 1/20\n",
      "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 2.3543e-04 - mae: 0.0112 - val_loss: 0.0013 - val_mae: 0.0250\n",
      "Epoch 2/20\n",
      "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 2.1497e-04 - mae: 0.0108 - val_loss: 0.0013 - val_mae: 0.0259\n",
      "Epoch 3/20\n",
      "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 2.1387e-04 - mae: 0.0108 - val_loss: 0.0012 - val_mae: 0.0232\n",
      "Epoch 4/20\n",
      "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 2.1143e-04 - mae: 0.0107 - val_loss: 0.0012 - val_mae: 0.0228\n",
      "Epoch 5/20\n",
      "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 2.0528e-04 - mae: 0.0106 - val_loss: 0.0012 - val_mae: 0.0225\n",
      "Epoch 6/20\n",
      "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 2.0225e-04 - mae: 0.0105 - val_loss: 0.0013 - val_mae: 0.0244\n",
      "Epoch 7/20\n",
      "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.9885e-04 - mae: 0.0104 - val_loss: 0.0014 - val_mae: 0.0259\n",
      "Epoch 8/20\n",
      "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.9725e-04 - mae: 0.0104 - val_loss: 0.0017 - val_mae: 0.0301\n",
      "Epoch 9/20\n",
      "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 1.9545e-04 - mae: 0.0103 - val_loss: 0.0017 - val_mae: 0.0291\n",
      "Epoch 10/20\n",
      "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 1.9351e-04 - mae: 0.0103 - val_loss: 0.0019 - val_mae: 0.0314\n",
      "Epoch 11/20\n",
      "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 1.9262e-04 - mae: 0.0102 - val_loss: 0.0021 - val_mae: 0.0338\n",
      "Epoch 12/20\n",
      "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.9261e-04 - mae: 0.0102 - val_loss: 0.0020 - val_mae: 0.0329\n",
      "Epoch 13/20\n",
      "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.9261e-04 - mae: 0.0102 - val_loss: 0.0020 - val_mae: 0.0326\n",
      "Epoch 14/20\n",
      "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.9088e-04 - mae: 0.0102 - val_loss: 0.0019 - val_mae: 0.0318\n",
      "Epoch 15/20\n",
      "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.9246e-04 - mae: 0.0102 - val_loss: 0.0024 - val_mae: 0.0365\n",
      "Epoch 16/20\n",
      "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 1.9210e-04 - mae: 0.0102 - val_loss: 0.0023 - val_mae: 0.0357\n",
      "Epoch 17/20\n",
      "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.9132e-04 - mae: 0.0102 - val_loss: 0.0025 - val_mae: 0.0375\n",
      "Epoch 18/20\n",
      "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 1.9222e-04 - mae: 0.0102 - val_loss: 0.0027 - val_mae: 0.0393\n",
      "Epoch 19/20\n",
      "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.9034e-04 - mae: 0.0102 - val_loss: 0.0026 - val_mae: 0.0377\n",
      "Epoch 20/20\n",
      "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 1.9219e-04 - mae: 0.0102 - val_loss: 0.0022 - val_mae: 0.0340\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step   \n",
      "✅ Done with wheat_Mysore_daily.csv | MAE=1219.99, RMSE=1670.19, R2=-0.69, MAPE=63.64%, Accuracy=36.36%\n",
      "\n",
      "========== Processing: wheat_Raichur_daily.csv ==========\n",
      "Epoch 1/20\n",
      "\u001b[1m275/275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0116 - mae: 0.0788 - val_loss: 0.0041 - val_mae: 0.0536\n",
      "Epoch 2/20\n",
      "\u001b[1m275/275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0076 - mae: 0.0616 - val_loss: 0.0039 - val_mae: 0.0491\n",
      "Epoch 3/20\n",
      "\u001b[1m275/275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0073 - mae: 0.0598 - val_loss: 0.0034 - val_mae: 0.0430\n",
      "Epoch 4/20\n",
      "\u001b[1m275/275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0071 - mae: 0.0583 - val_loss: 0.0035 - val_mae: 0.0477\n",
      "Epoch 5/20\n",
      "\u001b[1m275/275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0070 - mae: 0.0578 - val_loss: 0.0055 - val_mae: 0.0694\n",
      "Epoch 6/20\n",
      "\u001b[1m275/275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0069 - mae: 0.0569 - val_loss: 0.0085 - val_mae: 0.0835\n",
      "Epoch 7/20\n",
      "\u001b[1m275/275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0066 - mae: 0.0556 - val_loss: 0.0176 - val_mae: 0.1129\n",
      "Epoch 8/20\n",
      "\u001b[1m275/275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0066 - mae: 0.0552 - val_loss: 0.0330 - val_mae: 0.1455\n",
      "Epoch 9/20\n",
      "\u001b[1m275/275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0065 - mae: 0.0550 - val_loss: 0.0386 - val_mae: 0.1505\n",
      "Epoch 10/20\n",
      "\u001b[1m275/275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0064 - mae: 0.0544 - val_loss: 0.0403 - val_mae: 0.1538\n",
      "Epoch 11/20\n",
      "\u001b[1m275/275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0064 - mae: 0.0543 - val_loss: 0.0522 - val_mae: 0.1737\n",
      "Epoch 12/20\n",
      "\u001b[1m275/275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0063 - mae: 0.0537 - val_loss: 0.0463 - val_mae: 0.1608\n",
      "Epoch 13/20\n",
      "\u001b[1m275/275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0063 - mae: 0.0536 - val_loss: 0.0591 - val_mae: 0.1805\n",
      "Epoch 14/20\n",
      "\u001b[1m275/275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0063 - mae: 0.0536 - val_loss: 0.0564 - val_mae: 0.1773\n",
      "Epoch 15/20\n",
      "\u001b[1m275/275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0062 - mae: 0.0532 - val_loss: 0.0624 - val_mae: 0.1845\n",
      "Epoch 16/20\n",
      "\u001b[1m275/275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0062 - mae: 0.0529 - val_loss: 0.0600 - val_mae: 0.1803\n",
      "Epoch 17/20\n",
      "\u001b[1m275/275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0063 - mae: 0.0536 - val_loss: 0.0541 - val_mae: 0.1716\n",
      "Epoch 18/20\n",
      "\u001b[1m275/275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0062 - mae: 0.0531 - val_loss: 0.0696 - val_mae: 0.1975\n",
      "Epoch 19/20\n",
      "\u001b[1m275/275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0062 - mae: 0.0538 - val_loss: 0.0570 - val_mae: 0.1776\n",
      "Epoch 20/20\n",
      "\u001b[1m275/275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0062 - mae: 0.0531 - val_loss: 0.0453 - val_mae: 0.1603\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step   \n",
      "✅ Done with wheat_Raichur_daily.csv | MAE=456.82, RMSE=606.45, R2=-1.0, MAPE=21.73%, Accuracy=78.27%\n",
      "\n",
      "========== Processing: wheat_Shimoga_daily.csv ==========\n",
      "Epoch 1/20\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 8.4229e-05 - mae: 0.0077 - val_loss: 7.1000e-04 - val_mae: 0.0111\n",
      "Epoch 2/20\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 7.1983e-05 - mae: 0.0070 - val_loss: 6.9160e-04 - val_mae: 0.0109\n",
      "Epoch 3/20\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 6.9303e-05 - mae: 0.0068 - val_loss: 6.6474e-04 - val_mae: 0.0100\n",
      "Epoch 4/20\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 6.8300e-05 - mae: 0.0068 - val_loss: 6.4942e-04 - val_mae: 0.0099\n",
      "Epoch 5/20\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 6.8188e-05 - mae: 0.0067 - val_loss: 6.9794e-04 - val_mae: 0.0110\n",
      "Epoch 6/20\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 6.6510e-05 - mae: 0.0066 - val_loss: 6.4862e-04 - val_mae: 0.0096\n",
      "Epoch 7/20\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 6.6447e-05 - mae: 0.0066 - val_loss: 6.7232e-04 - val_mae: 0.0102\n",
      "Epoch 8/20\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 6.5920e-05 - mae: 0.0066 - val_loss: 6.4401e-04 - val_mae: 0.0094\n",
      "Epoch 9/20\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 6.4777e-05 - mae: 0.0065 - val_loss: 6.6107e-04 - val_mae: 0.0099\n",
      "Epoch 10/20\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 6.2587e-05 - mae: 0.0063 - val_loss: 6.2580e-04 - val_mae: 0.0089\n",
      "Epoch 11/20\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 6.0607e-05 - mae: 0.0062 - val_loss: 6.0979e-04 - val_mae: 0.0089\n",
      "Epoch 12/20\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 5.9410e-05 - mae: 0.0061 - val_loss: 6.3920e-04 - val_mae: 0.0097\n",
      "Epoch 13/20\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 6.0257e-05 - mae: 0.0061 - val_loss: 6.4443e-04 - val_mae: 0.0100\n",
      "Epoch 14/20\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 5.8975e-05 - mae: 0.0060 - val_loss: 6.0538e-04 - val_mae: 0.0085\n",
      "Epoch 15/20\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 5.9161e-05 - mae: 0.0060 - val_loss: 6.2604e-04 - val_mae: 0.0094\n",
      "Epoch 16/20\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 5.9175e-05 - mae: 0.0060 - val_loss: 6.1514e-04 - val_mae: 0.0089\n",
      "Epoch 17/20\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 5.8672e-05 - mae: 0.0060 - val_loss: 6.0093e-04 - val_mae: 0.0084\n",
      "Epoch 18/20\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 5.9468e-05 - mae: 0.0060 - val_loss: 6.1474e-04 - val_mae: 0.0090\n",
      "Epoch 19/20\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 5.8812e-05 - mae: 0.0060 - val_loss: 6.1989e-04 - val_mae: 0.0094\n",
      "Epoch 20/20\n",
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 5.8753e-05 - mae: 0.0060 - val_loss: 6.0422e-04 - val_mae: 0.0085\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step   \n",
      "✅ Done with wheat_Shimoga_daily.csv | MAE=527.56, RMSE=1519.41, R2=0.11, MAPE=16.19%, Accuracy=83.81%\n",
      "\n",
      "========== Processing: wheat_Tumkur_daily.csv ==========\n",
      "Epoch 1/20\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0016 - mae: 0.0211 - val_loss: 0.0049 - val_mae: 0.0334\n",
      "Epoch 2/20\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0013 - mae: 0.0190 - val_loss: 0.0050 - val_mae: 0.0319\n",
      "Epoch 3/20\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0013 - mae: 0.0184 - val_loss: 0.0053 - val_mae: 0.0302\n",
      "Epoch 4/20\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0013 - mae: 0.0185 - val_loss: 0.0060 - val_mae: 0.0303\n",
      "Epoch 5/20\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0012 - mae: 0.0178 - val_loss: 0.0094 - val_mae: 0.0335\n",
      "Epoch 6/20\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0012 - mae: 0.0171 - val_loss: 0.0169 - val_mae: 0.0399\n",
      "Epoch 7/20\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0011 - mae: 0.0171 - val_loss: 0.0288 - val_mae: 0.0474\n",
      "Epoch 8/20\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0011 - mae: 0.0167 - val_loss: 0.0307 - val_mae: 0.0485\n",
      "Epoch 9/20\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0011 - mae: 0.0169 - val_loss: 0.0374 - val_mae: 0.0514\n",
      "Epoch 10/20\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0011 - mae: 0.0165 - val_loss: 0.0381 - val_mae: 0.0513\n",
      "Epoch 11/20\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0010 - mae: 0.0163 - val_loss: 0.0436 - val_mae: 0.0529\n",
      "Epoch 12/20\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0011 - mae: 0.0166 - val_loss: 0.0475 - val_mae: 0.0595\n",
      "Epoch 13/20\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0010 - mae: 0.0164 - val_loss: 0.0506 - val_mae: 0.0593\n",
      "Epoch 14/20\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0010 - mae: 0.0164 - val_loss: 0.0586 - val_mae: 0.0680\n",
      "Epoch 15/20\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 9.9333e-04 - mae: 0.0161 - val_loss: 0.0453 - val_mae: 0.0593\n",
      "Epoch 16/20\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 9.8366e-04 - mae: 0.0161 - val_loss: 0.0573 - val_mae: 0.0725\n",
      "Epoch 17/20\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 9.7322e-04 - mae: 0.0160 - val_loss: 0.0412 - val_mae: 0.0651\n",
      "Epoch 18/20\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 9.5929e-04 - mae: 0.0160 - val_loss: 0.0466 - val_mae: 0.0682\n",
      "Epoch 19/20\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 9.4876e-04 - mae: 0.0157 - val_loss: 0.0426 - val_mae: 0.0678\n",
      "Epoch 20/20\n",
      "\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 9.4471e-04 - mae: 0.0157 - val_loss: 0.0523 - val_mae: 0.0738\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step   \n",
      "✅ Done with wheat_Tumkur_daily.csv | MAE=1307.83, RMSE=4051.57, R2=-5.33, MAPE=32.28%, Accuracy=67.72%\n",
      "\n",
      "📊 Metrics saved to output_lstm_csv\\lstm_metrics.csv\n",
      "\n",
      "🎉 All districts processed successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "# -----------------------------\n",
    "# 🧹 Clean console output\n",
    "# -----------------------------\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "tf.get_logger().setLevel(\"ERROR\")\n",
    "\n",
    "# -----------------------------\n",
    "# Paths\n",
    "# -----------------------------\n",
    "input_folder = \"dataset\"\n",
    "output_models = \"output_lstm_models\"\n",
    "output_csv = \"output_lstm_csv\"\n",
    "output_graphs = \"output_lstm_graphs\"\n",
    "output_logs = \"output_lstm_logs\"\n",
    "metrics_file = os.path.join(output_csv, \"lstm_metrics.csv\")\n",
    "\n",
    "os.makedirs(output_models, exist_ok=True)\n",
    "os.makedirs(output_csv, exist_ok=True)\n",
    "os.makedirs(output_graphs, exist_ok=True)\n",
    "os.makedirs(output_logs, exist_ok=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Function to create sequences\n",
    "# -----------------------------\n",
    "def create_sequences(data, seq_length=5):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i+seq_length])\n",
    "        y.append(data[i+seq_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# -----------------------------\n",
    "# Metrics storage\n",
    "# -----------------------------\n",
    "metrics_list = []\n",
    "\n",
    "# -----------------------------\n",
    "# Process each CSV\n",
    "# -----------------------------\n",
    "seq_length = 5\n",
    "for file in os.listdir(input_folder):\n",
    "    if file.endswith(\".csv\"):\n",
    "        district_name = file.split(\".\")[0]\n",
    "        print(f\"\\n========== Processing: {file} ==========\")\n",
    "\n",
    "        df = pd.read_csv(os.path.join(input_folder, file))\n",
    "\n",
    "        df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "        df = df.dropna(subset=['Date'])\n",
    "        df = df.sort_values('Date')\n",
    "\n",
    "        df['Average Price'] = df['Average Price'].fillna(df['Average Price'].mean())\n",
    "\n",
    "        df['MA_7'] = df['Average Price'].rolling(7).mean().fillna(df['Average Price'].mean())\n",
    "        df['MA_30'] = df['Average Price'].rolling(30).mean().fillna(df['Average Price'].mean())\n",
    "\n",
    "        scaler = MinMaxScaler()\n",
    "        prices_scaled = scaler.fit_transform(df['Average Price'].values.reshape(-1, 1))\n",
    "\n",
    "        X, y = create_sequences(prices_scaled, seq_length)\n",
    "\n",
    "        split = int(0.8 * len(X))\n",
    "        X_train, X_test = X[:split], X[split:]\n",
    "        y_train, y_test = y[:split], y[split:]\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(50, activation='relu', input_shape=(seq_length, 1)))\n",
    "        model.add(Dense(1))\n",
    "        model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            epochs=20,\n",
    "            batch_size=32,\n",
    "            validation_data=(X_test, y_test),\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        y_pred_scaled = model.predict(X_test)\n",
    "        y_pred = scaler.inverse_transform(y_pred_scaled)\n",
    "        y_true = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "        y_true_round = np.round(y_true, 2)\n",
    "        y_pred_round = np.round(y_pred, 2)\n",
    "\n",
    "        df_pred = df.iloc[seq_length + split:].copy()\n",
    "        df_pred = df_pred[['Date']].copy()\n",
    "        df_pred['Actual'] = y_true_round.flatten()\n",
    "        df_pred['Predicted'] = y_pred_round.flatten()\n",
    "        df_pred.to_csv(os.path.join(output_csv, f\"{district_name}_lstm_updated.csv\"), index=False)\n",
    "\n",
    "        # -----------------------------\n",
    "        # FIXED METRICS SECTION\n",
    "        # -----------------------------\n",
    "        mae_val = round(mean_absolute_error(y_true, y_pred), 2)\n",
    "        rmse_val = round(np.sqrt(mean_squared_error(y_true, y_pred)), 2)   # FIXED ✔\n",
    "        r2_val = round(r2_score(y_true, y_pred), 2)\n",
    "        mape_val = round(np.mean(np.abs((y_true - y_pred) / y_true)) * 100, 2)\n",
    "        accuracy_val = round(100 - mape_val, 2)\n",
    "\n",
    "        metrics_list.append([district_name, mae_val, rmse_val, r2_val, mape_val, accuracy_val])\n",
    "\n",
    "        print(f\"✅ Done with {file} | MAE={mae_val}, RMSE={rmse_val}, R2={r2_val}, \"\n",
    "              f\"MAPE={mape_val}%, Accuracy={accuracy_val}%\")\n",
    "\n",
    "        joblib.dump(model, os.path.join(output_models, f\"{district_name}_lstm_model.pkl\"))\n",
    "\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(df['Date'], df['Average Price'], label='Actual', color='blue')\n",
    "        plt.plot(df['Date'], df['MA_7'], label='MA 7', color='orange')\n",
    "        plt.plot(df['Date'], df['MA_30'], label='MA 30', color='green')\n",
    "        plt.plot(df_pred['Date'], df_pred['Predicted'], label='Predicted', color='red', linestyle='dashed')\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Average Price')\n",
    "        plt.title(f\"LSTM Predictions for {district_name}\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.savefig(os.path.join(output_graphs, f\"{district_name}_lstm_graph.png\"))\n",
    "        plt.close()\n",
    "\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        plt.plot(history.history['loss'], label='Train Loss')\n",
    "        plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "        plt.title(f\"Training Loss for {district_name}\")\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        plt.savefig(os.path.join(output_graphs, f\"{district_name}_lstm_training_loss.png\"))\n",
    "        plt.close()\n",
    "\n",
    "# Save metrics CSV\n",
    "metrics_df = pd.DataFrame(metrics_list, columns=['District', 'MAE', 'RMSE', 'R2', 'MAPE(%)', 'Accuracy(%)'])\n",
    "metrics_df.to_csv(metrics_file, index=False)\n",
    "\n",
    "print(f\"\\n📊 Metrics saved to {metrics_file}\")\n",
    "print(\"\\n🎉 All districts processed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7470849-23f3-4f8f-b642-09b851325c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06358772-a024-49f6-a863-23d43b5973c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Processing: wheat_Bagalkot_daily.csv\n",
      "Epoch 1/20\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 41ms/step - loss: 9.8727e-04 - mae: 0.0225 - val_loss: 0.0015 - val_mae: 0.0297\n",
      "Epoch 2/20\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 39ms/step - loss: 8.9480e-04 - mae: 0.0212 - val_loss: 0.0014 - val_mae: 0.0284\n",
      "Epoch 3/20\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 38ms/step - loss: 8.6191e-04 - mae: 0.0208 - val_loss: 0.0015 - val_mae: 0.0301\n",
      "Epoch 4/20\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 39ms/step - loss: 8.5912e-04 - mae: 0.0207 - val_loss: 0.0015 - val_mae: 0.0302\n",
      "Epoch 5/20\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 39ms/step - loss: 8.4648e-04 - mae: 0.0204 - val_loss: 0.0016 - val_mae: 0.0318\n",
      "Epoch 6/20\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 38ms/step - loss: 8.3047e-04 - mae: 0.0205 - val_loss: 0.0016 - val_mae: 0.0310\n",
      "Epoch 7/20\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 37ms/step - loss: 8.4359e-04 - mae: 0.0205 - val_loss: 0.0016 - val_mae: 0.0308\n",
      "Epoch 8/20\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 38ms/step - loss: 8.3009e-04 - mae: 0.0203 - val_loss: 0.0014 - val_mae: 0.0297\n",
      "Epoch 9/20\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 38ms/step - loss: 8.2753e-04 - mae: 0.0202 - val_loss: 0.0014 - val_mae: 0.0291\n",
      "Epoch 10/20\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 37ms/step - loss: 8.1438e-04 - mae: 0.0201 - val_loss: 0.0015 - val_mae: 0.0307\n",
      "Epoch 11/20\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 38ms/step - loss: 8.1270e-04 - mae: 0.0200 - val_loss: 0.0014 - val_mae: 0.0293\n",
      "Epoch 12/20\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 38ms/step - loss: 8.1486e-04 - mae: 0.0199 - val_loss: 0.0015 - val_mae: 0.0300\n",
      "Epoch 13/20\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 38ms/step - loss: 8.0476e-04 - mae: 0.0198 - val_loss: 0.0015 - val_mae: 0.0301\n",
      "Epoch 14/20\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 37ms/step - loss: 8.1017e-04 - mae: 0.0199 - val_loss: 0.0019 - val_mae: 0.0330\n",
      "Epoch 15/20\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 35ms/step - loss: 8.0150e-04 - mae: 0.0198 - val_loss: 0.0015 - val_mae: 0.0299\n",
      "Epoch 16/20\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 36ms/step - loss: 8.0296e-04 - mae: 0.0197 - val_loss: 0.0014 - val_mae: 0.0291\n",
      "Epoch 17/20\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 36ms/step - loss: 7.9698e-04 - mae: 0.0197 - val_loss: 0.0014 - val_mae: 0.0293\n",
      "Epoch 18/20\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 37ms/step - loss: 7.9505e-04 - mae: 0.0197 - val_loss: 0.0014 - val_mae: 0.0294\n",
      "Epoch 19/20\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 36ms/step - loss: 7.9843e-04 - mae: 0.0198 - val_loss: 0.0016 - val_mae: 0.0302\n",
      "Epoch 20/20\n",
      "\u001b[1m1129/1129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 37ms/step - loss: 8.0499e-04 - mae: 0.0197 - val_loss: 0.0016 - val_mae: 0.0310\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step\n",
      "✅ Done with wheat_Bagalkot_daily.csv | MAE=538.02, RMSE=684.86, R2=0.38, MAPE=21.18%, Accuracy=78.82%\n",
      "\n",
      "🚀 Processing: wheat_Bangalore_daily.csv\n",
      "Epoch 1/20\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 31ms/step - loss: 6.5202e-04 - mae: 0.0198 - val_loss: 0.0015 - val_mae: 0.0266\n",
      "Epoch 2/20\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 28ms/step - loss: 5.9459e-04 - mae: 0.0184 - val_loss: 0.0011 - val_mae: 0.0237\n",
      "Epoch 3/20\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 29ms/step - loss: 5.7429e-04 - mae: 0.0180 - val_loss: 0.0014 - val_mae: 0.0248\n",
      "Epoch 4/20\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 29ms/step - loss: 5.5459e-04 - mae: 0.0180 - val_loss: 0.0015 - val_mae: 0.0258\n",
      "Epoch 5/20\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 28ms/step - loss: 5.3597e-04 - mae: 0.0173 - val_loss: 0.0019 - val_mae: 0.0282\n",
      "Epoch 6/20\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 29ms/step - loss: 5.3209e-04 - mae: 0.0174 - val_loss: 0.0014 - val_mae: 0.0236\n",
      "Epoch 7/20\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 29ms/step - loss: 5.2204e-04 - mae: 0.0171 - val_loss: 0.0021 - val_mae: 0.0297\n",
      "Epoch 8/20\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 27ms/step - loss: 5.0851e-04 - mae: 0.0167 - val_loss: 0.0016 - val_mae: 0.0251\n",
      "Epoch 9/20\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 27ms/step - loss: 5.0353e-04 - mae: 0.0167 - val_loss: 0.0025 - val_mae: 0.0344\n",
      "Epoch 10/20\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 24ms/step - loss: 4.9747e-04 - mae: 0.0165 - val_loss: 0.0016 - val_mae: 0.0247\n",
      "Epoch 11/20\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 28ms/step - loss: 4.8980e-04 - mae: 0.0163 - val_loss: 0.0023 - val_mae: 0.0308\n",
      "Epoch 12/20\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 29ms/step - loss: 4.8654e-04 - mae: 0.0163 - val_loss: 0.0021 - val_mae: 0.0281\n",
      "Epoch 13/20\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 28ms/step - loss: 4.8879e-04 - mae: 0.0163 - val_loss: 0.0018 - val_mae: 0.0256\n",
      "Epoch 14/20\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 31ms/step - loss: 4.8168e-04 - mae: 0.0161 - val_loss: 0.0022 - val_mae: 0.0305\n",
      "Epoch 15/20\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 24ms/step - loss: 4.8480e-04 - mae: 0.0162 - val_loss: 0.0027 - val_mae: 0.0349\n",
      "Epoch 16/20\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 27ms/step - loss: 4.7424e-04 - mae: 0.0160 - val_loss: 0.0021 - val_mae: 0.0283\n",
      "Epoch 17/20\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 25ms/step - loss: 4.7884e-04 - mae: 0.0160 - val_loss: 0.0018 - val_mae: 0.0259\n",
      "Epoch 18/20\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 26ms/step - loss: 4.7917e-04 - mae: 0.0160 - val_loss: 0.0018 - val_mae: 0.0266\n",
      "Epoch 19/20\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 26ms/step - loss: 4.8115e-04 - mae: 0.0161 - val_loss: 0.0018 - val_mae: 0.0261\n",
      "Epoch 20/20\n",
      "\u001b[1m645/645\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 26ms/step - loss: 4.7498e-04 - mae: 0.0159 - val_loss: 0.0015 - val_mae: 0.0235\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step  \n",
      "✅ Done with wheat_Bangalore_daily.csv | MAE=411.4, RMSE=675.95, R2=0.16, MAPE=12.3%, Accuracy=87.7%\n",
      "\n",
      "🚀 Processing: wheat_Belgaum_daily.csv\n",
      "Epoch 1/20\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 29ms/step - loss: 0.0062 - mae: 0.0586 - val_loss: 0.0061 - val_mae: 0.0615\n",
      "Epoch 2/20\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 25ms/step - loss: 0.0052 - mae: 0.0540 - val_loss: 0.0039 - val_mae: 0.0475\n",
      "Epoch 3/20\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 24ms/step - loss: 0.0051 - mae: 0.0534 - val_loss: 0.0098 - val_mae: 0.0829\n",
      "Epoch 4/20\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 24ms/step - loss: 0.0050 - mae: 0.0529 - val_loss: 0.0041 - val_mae: 0.0478\n",
      "Epoch 5/20\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 26ms/step - loss: 0.0050 - mae: 0.0529 - val_loss: 0.0039 - val_mae: 0.0484\n",
      "Epoch 6/20\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 26ms/step - loss: 0.0050 - mae: 0.0526 - val_loss: 0.0054 - val_mae: 0.0565\n",
      "Epoch 7/20\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 22ms/step - loss: 0.0050 - mae: 0.0527 - val_loss: 0.0043 - val_mae: 0.0490\n",
      "Epoch 8/20\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 22ms/step - loss: 0.0049 - mae: 0.0526 - val_loss: 0.0046 - val_mae: 0.0512\n",
      "Epoch 9/20\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 22ms/step - loss: 0.0050 - mae: 0.0526 - val_loss: 0.0050 - val_mae: 0.0543\n",
      "Epoch 10/20\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 23ms/step - loss: 0.0049 - mae: 0.0526 - val_loss: 0.0055 - val_mae: 0.0571\n",
      "Epoch 11/20\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 28ms/step - loss: 0.0049 - mae: 0.0524 - val_loss: 0.0045 - val_mae: 0.0494\n",
      "Epoch 12/20\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 27ms/step - loss: 0.0049 - mae: 0.0524 - val_loss: 0.0058 - val_mae: 0.0595\n",
      "Epoch 13/20\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 26ms/step - loss: 0.0049 - mae: 0.0523 - val_loss: 0.0046 - val_mae: 0.0506\n",
      "Epoch 14/20\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 24ms/step - loss: 0.0049 - mae: 0.0524 - val_loss: 0.0055 - val_mae: 0.0564\n",
      "Epoch 15/20\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 23ms/step - loss: 0.0049 - mae: 0.0523 - val_loss: 0.0040 - val_mae: 0.0473\n",
      "Epoch 16/20\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 26ms/step - loss: 0.0049 - mae: 0.0522 - val_loss: 0.0052 - val_mae: 0.0550\n",
      "Epoch 17/20\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 23ms/step - loss: 0.0049 - mae: 0.0524 - val_loss: 0.0065 - val_mae: 0.0642\n",
      "Epoch 18/20\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 24ms/step - loss: 0.0049 - mae: 0.0523 - val_loss: 0.0069 - val_mae: 0.0654\n",
      "Epoch 19/20\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 25ms/step - loss: 0.0049 - mae: 0.0522 - val_loss: 0.0058 - val_mae: 0.0590\n",
      "Epoch 20/20\n",
      "\u001b[1m1648/1648\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 25ms/step - loss: 0.0049 - mae: 0.0521 - val_loss: 0.0049 - val_mae: 0.0522\n",
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step \n",
      "✅ Done with wheat_Belgaum_daily.csv | MAE=296.59, RMSE=397.28, R2=0.29, MAPE=10.76%, Accuracy=89.24%\n",
      "\n",
      "🚀 Processing: wheat_Bellary_daily.csv\n",
      "Epoch 1/20\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 25ms/step - loss: 0.0034 - mae: 0.0452 - val_loss: 0.0081 - val_mae: 0.0724\n",
      "Epoch 2/20\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - loss: 0.0029 - mae: 0.0414 - val_loss: 0.0074 - val_mae: 0.0675\n",
      "Epoch 3/20\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - loss: 0.0028 - mae: 0.0401 - val_loss: 0.0066 - val_mae: 0.0626\n",
      "Epoch 4/20\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 26ms/step - loss: 0.0027 - mae: 0.0397 - val_loss: 0.0120 - val_mae: 0.0816\n",
      "Epoch 5/20\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 25ms/step - loss: 0.0027 - mae: 0.0393 - val_loss: 0.0066 - val_mae: 0.0617\n",
      "Epoch 6/20\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 24ms/step - loss: 0.0026 - mae: 0.0392 - val_loss: 0.0079 - val_mae: 0.0652\n",
      "Epoch 7/20\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 26ms/step - loss: 0.0026 - mae: 0.0390 - val_loss: 0.0079 - val_mae: 0.0658\n",
      "Epoch 8/20\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 24ms/step - loss: 0.0026 - mae: 0.0387 - val_loss: 0.0098 - val_mae: 0.0728\n",
      "Epoch 9/20\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 24ms/step - loss: 0.0026 - mae: 0.0386 - val_loss: 0.0099 - val_mae: 0.0672\n",
      "Epoch 10/20\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 26ms/step - loss: 0.0025 - mae: 0.0382 - val_loss: 0.0107 - val_mae: 0.0745\n",
      "Epoch 11/20\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 24ms/step - loss: 0.0026 - mae: 0.0383 - val_loss: 0.0143 - val_mae: 0.0821\n",
      "Epoch 12/20\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 24ms/step - loss: 0.0026 - mae: 0.0384 - val_loss: 0.0128 - val_mae: 0.0734\n",
      "Epoch 13/20\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 26ms/step - loss: 0.0025 - mae: 0.0380 - val_loss: 0.0193 - val_mae: 0.0915\n",
      "Epoch 14/20\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - loss: 0.0025 - mae: 0.0379 - val_loss: 0.0131 - val_mae: 0.0730\n",
      "Epoch 15/20\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 24ms/step - loss: 0.0025 - mae: 0.0377 - val_loss: 0.0151 - val_mae: 0.0768\n",
      "Epoch 16/20\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 26ms/step - loss: 0.0025 - mae: 0.0377 - val_loss: 0.0205 - val_mae: 0.0855\n",
      "Epoch 17/20\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 24ms/step - loss: 0.0025 - mae: 0.0375 - val_loss: 0.0212 - val_mae: 0.0887\n",
      "Epoch 18/20\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 24ms/step - loss: 0.0024 - mae: 0.0374 - val_loss: 0.0259 - val_mae: 0.0956\n",
      "Epoch 19/20\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 26ms/step - loss: 0.0024 - mae: 0.0374 - val_loss: 0.0161 - val_mae: 0.0780\n",
      "Epoch 20/20\n",
      "\u001b[1m775/775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 24ms/step - loss: 0.0024 - mae: 0.0374 - val_loss: 0.0167 - val_mae: 0.0784\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step   \n",
      "✅ Done with wheat_Bellary_daily.csv | MAE=572.03, RMSE=943.94, R2=0.02, MAPE=21.17%, Accuracy=78.83%\n",
      "\n",
      "🚀 Processing: wheat_Bidar_daily.csv\n",
      "Epoch 1/20\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 33ms/step - loss: 0.0050 - mae: 0.0544 - val_loss: 0.0056 - val_mae: 0.0562\n",
      "Epoch 2/20\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 28ms/step - loss: 0.0041 - mae: 0.0492 - val_loss: 0.0054 - val_mae: 0.0542\n",
      "Epoch 3/20\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 27ms/step - loss: 0.0039 - mae: 0.0477 - val_loss: 0.0053 - val_mae: 0.0536\n",
      "Epoch 4/20\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 27ms/step - loss: 0.0038 - mae: 0.0469 - val_loss: 0.0053 - val_mae: 0.0533\n",
      "Epoch 5/20\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 28ms/step - loss: 0.0037 - mae: 0.0466 - val_loss: 0.0054 - val_mae: 0.0535\n",
      "Epoch 6/20\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 28ms/step - loss: 0.0037 - mae: 0.0463 - val_loss: 0.0055 - val_mae: 0.0543\n",
      "Epoch 7/20\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 29ms/step - loss: 0.0036 - mae: 0.0459 - val_loss: 0.0051 - val_mae: 0.0521\n",
      "Epoch 8/20\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 28ms/step - loss: 0.0036 - mae: 0.0457 - val_loss: 0.0053 - val_mae: 0.0539\n",
      "Epoch 9/20\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 28ms/step - loss: 0.0036 - mae: 0.0456 - val_loss: 0.0050 - val_mae: 0.0519\n",
      "Epoch 10/20\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 27ms/step - loss: 0.0036 - mae: 0.0456 - val_loss: 0.0050 - val_mae: 0.0524\n",
      "Epoch 11/20\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 27ms/step - loss: 0.0035 - mae: 0.0453 - val_loss: 0.0059 - val_mae: 0.0572\n",
      "Epoch 12/20\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 29ms/step - loss: 0.0035 - mae: 0.0455 - val_loss: 0.0051 - val_mae: 0.0524\n",
      "Epoch 13/20\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 26ms/step - loss: 0.0035 - mae: 0.0453 - val_loss: 0.0053 - val_mae: 0.0542\n",
      "Epoch 14/20\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 28ms/step - loss: 0.0035 - mae: 0.0452 - val_loss: 0.0050 - val_mae: 0.0521\n",
      "Epoch 15/20\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 29ms/step - loss: 0.0035 - mae: 0.0453 - val_loss: 0.0057 - val_mae: 0.0563\n",
      "Epoch 16/20\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 28ms/step - loss: 0.0035 - mae: 0.0451 - val_loss: 0.0052 - val_mae: 0.0534\n",
      "Epoch 17/20\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 27ms/step - loss: 0.0035 - mae: 0.0450 - val_loss: 0.0054 - val_mae: 0.0537\n",
      "Epoch 18/20\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 27ms/step - loss: 0.0035 - mae: 0.0450 - val_loss: 0.0051 - val_mae: 0.0528\n",
      "Epoch 19/20\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 29ms/step - loss: 0.0035 - mae: 0.0450 - val_loss: 0.0057 - val_mae: 0.0561\n",
      "Epoch 20/20\n",
      "\u001b[1m812/812\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 27ms/step - loss: 0.0035 - mae: 0.0449 - val_loss: 0.0053 - val_mae: 0.0541\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step\n",
      "✅ Done with wheat_Bidar_daily.csv | MAE=283.78, RMSE=382.01, R2=0.33, MAPE=10.32%, Accuracy=89.68%\n",
      "\n",
      "🚀 Processing: wheat_Bijapur_daily.csv\n",
      "Epoch 1/20\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 25ms/step - loss: 0.0064 - mae: 0.0606 - val_loss: 0.0021 - val_mae: 0.0365\n",
      "Epoch 2/20\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 27ms/step - loss: 0.0052 - mae: 0.0541 - val_loss: 0.0029 - val_mae: 0.0459\n",
      "Epoch 3/20\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 24ms/step - loss: 0.0049 - mae: 0.0519 - val_loss: 0.0012 - val_mae: 0.0245\n",
      "Epoch 4/20\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 24ms/step - loss: 0.0047 - mae: 0.0507 - val_loss: 0.0012 - val_mae: 0.0253\n",
      "Epoch 5/20\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 24ms/step - loss: 0.0045 - mae: 0.0497 - val_loss: 0.0012 - val_mae: 0.0240\n",
      "Epoch 6/20\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 26ms/step - loss: 0.0045 - mae: 0.0497 - val_loss: 0.0032 - val_mae: 0.0480\n",
      "Epoch 7/20\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 24ms/step - loss: 0.0045 - mae: 0.0495 - val_loss: 0.0012 - val_mae: 0.0248\n",
      "Epoch 8/20\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 25ms/step - loss: 0.0045 - mae: 0.0495 - val_loss: 0.0012 - val_mae: 0.0248\n",
      "Epoch 9/20\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 26ms/step - loss: 0.0044 - mae: 0.0492 - val_loss: 0.0012 - val_mae: 0.0244\n",
      "Epoch 10/20\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 24ms/step - loss: 0.0044 - mae: 0.0487 - val_loss: 0.0012 - val_mae: 0.0247\n",
      "Epoch 11/20\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 24ms/step - loss: 0.0044 - mae: 0.0486 - val_loss: 0.0013 - val_mae: 0.0272\n",
      "Epoch 12/20\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 24ms/step - loss: 0.0043 - mae: 0.0485 - val_loss: 0.0012 - val_mae: 0.0250\n",
      "Epoch 13/20\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 25ms/step - loss: 0.0044 - mae: 0.0486 - val_loss: 0.0012 - val_mae: 0.0244\n",
      "Epoch 14/20\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 25ms/step - loss: 0.0043 - mae: 0.0479 - val_loss: 0.0012 - val_mae: 0.0245\n",
      "Epoch 15/20\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 24ms/step - loss: 0.0043 - mae: 0.0477 - val_loss: 0.0014 - val_mae: 0.0282\n",
      "Epoch 16/20\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 25ms/step - loss: 0.0043 - mae: 0.0479 - val_loss: 0.0012 - val_mae: 0.0252\n",
      "Epoch 17/20\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 26ms/step - loss: 0.0043 - mae: 0.0483 - val_loss: 0.0012 - val_mae: 0.0245\n",
      "Epoch 18/20\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 42ms/step - loss: 0.0043 - mae: 0.0481 - val_loss: 0.0012 - val_mae: 0.0255\n",
      "Epoch 19/20\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 26ms/step - loss: 0.0043 - mae: 0.0483 - val_loss: 0.0012 - val_mae: 0.0237\n",
      "Epoch 20/20\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 26ms/step - loss: 0.0043 - mae: 0.0479 - val_loss: 0.0012 - val_mae: 0.0239\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step   \n",
      "✅ Done with wheat_Bijapur_daily.csv | MAE=191.34, RMSE=273.81, R2=0.66, MAPE=6.81%, Accuracy=93.19%\n",
      "\n",
      "🚀 Processing: wheat_Chikmagalur_daily.csv\n",
      "Epoch 1/20\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 23ms/step - loss: 0.0188 - mae: 0.0959 - val_loss: 0.0060 - val_mae: 0.0530\n",
      "Epoch 2/20\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 22ms/step - loss: 0.0144 - mae: 0.0832 - val_loss: 0.0070 - val_mae: 0.0679\n",
      "Epoch 3/20\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 24ms/step - loss: 0.0137 - mae: 0.0796 - val_loss: 0.0078 - val_mae: 0.0700\n",
      "Epoch 4/20\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - loss: 0.0131 - mae: 0.0769 - val_loss: 0.0056 - val_mae: 0.0527\n",
      "Epoch 5/20\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - loss: 0.0128 - mae: 0.0759 - val_loss: 0.0059 - val_mae: 0.0545\n",
      "Epoch 6/20\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 24ms/step - loss: 0.0128 - mae: 0.0749 - val_loss: 0.0058 - val_mae: 0.0542\n",
      "Epoch 7/20\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 26ms/step - loss: 0.0126 - mae: 0.0743 - val_loss: 0.0058 - val_mae: 0.0543\n",
      "Epoch 8/20\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 23ms/step - loss: 0.0123 - mae: 0.0732 - val_loss: 0.0057 - val_mae: 0.0555\n",
      "Epoch 9/20\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 22ms/step - loss: 0.0122 - mae: 0.0729 - val_loss: 0.0068 - val_mae: 0.0607\n",
      "Epoch 10/20\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 27ms/step - loss: 0.0122 - mae: 0.0724 - val_loss: 0.0059 - val_mae: 0.0550\n",
      "Epoch 11/20\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 24ms/step - loss: 0.0122 - mae: 0.0722 - val_loss: 0.0056 - val_mae: 0.0517\n",
      "Epoch 12/20\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 24ms/step - loss: 0.0121 - mae: 0.0717 - val_loss: 0.0056 - val_mae: 0.0514\n",
      "Epoch 13/20\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 24ms/step - loss: 0.0120 - mae: 0.0714 - val_loss: 0.0055 - val_mae: 0.0503\n",
      "Epoch 14/20\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 26ms/step - loss: 0.0119 - mae: 0.0703 - val_loss: 0.0071 - val_mae: 0.0599\n",
      "Epoch 15/20\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 24ms/step - loss: 0.0119 - mae: 0.0705 - val_loss: 0.0054 - val_mae: 0.0503\n",
      "Epoch 16/20\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - loss: 0.0118 - mae: 0.0704 - val_loss: 0.0058 - val_mae: 0.0524\n",
      "Epoch 17/20\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 26ms/step - loss: 0.0118 - mae: 0.0701 - val_loss: 0.0058 - val_mae: 0.0513\n",
      "Epoch 18/20\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - loss: 0.0118 - mae: 0.0702 - val_loss: 0.0056 - val_mae: 0.0527\n",
      "Epoch 19/20\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 24ms/step - loss: 0.0116 - mae: 0.0697 - val_loss: 0.0060 - val_mae: 0.0527\n",
      "Epoch 20/20\n",
      "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 26ms/step - loss: 0.0116 - mae: 0.0697 - val_loss: 0.0055 - val_mae: 0.0503\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step  \n",
      "✅ Done with wheat_Chikmagalur_daily.csv | MAE=251.71, RMSE=370.2, R2=0.32, MAPE=10.25%, Accuracy=89.75%\n",
      "\n",
      "🚀 Processing: wheat_Chitradurga_daily.csv\n",
      "Epoch 1/20\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 29ms/step - loss: 0.0401 - mae: 0.1660 - val_loss: 0.0248 - val_mae: 0.1571\n",
      "Epoch 2/20\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - loss: 0.0279 - mae: 0.1279 - val_loss: 0.0033 - val_mae: 0.0575\n",
      "Epoch 3/20\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - loss: 0.0256 - mae: 0.1193 - val_loss: 0.0053 - val_mae: 0.0725\n",
      "Epoch 4/20\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - loss: 0.0252 - mae: 0.1168 - val_loss: 0.0073 - val_mae: 0.0840\n",
      "Epoch 5/20\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - loss: 0.0241 - mae: 0.1131 - val_loss: 2.2281e-04 - val_mae: 0.0114\n",
      "Epoch 6/20\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - loss: 0.0244 - mae: 0.1134 - val_loss: 0.0021 - val_mae: 0.0444\n",
      "Epoch 7/20\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - loss: 0.0243 - mae: 0.1137 - val_loss: 0.0226 - val_mae: 0.1499\n",
      "Epoch 8/20\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - loss: 0.0235 - mae: 0.1122 - val_loss: 0.0018 - val_mae: 0.0417\n",
      "Epoch 9/20\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - loss: 0.0231 - mae: 0.1095 - val_loss: 0.0056 - val_mae: 0.0745\n",
      "Epoch 10/20\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - loss: 0.0226 - mae: 0.1087 - val_loss: 0.0028 - val_mae: 0.0531\n",
      "Epoch 11/20\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - loss: 0.0225 - mae: 0.1079 - val_loss: 0.0038 - val_mae: 0.0603\n",
      "Epoch 12/20\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - loss: 0.0223 - mae: 0.1057 - val_loss: 0.0050 - val_mae: 0.0698\n",
      "Epoch 13/20\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - loss: 0.0223 - mae: 0.1069 - val_loss: 5.7580e-04 - val_mae: 0.0222\n",
      "Epoch 14/20\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - loss: 0.0223 - mae: 0.1070 - val_loss: 0.0014 - val_mae: 0.0369\n",
      "Epoch 15/20\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - loss: 0.0222 - mae: 0.1071 - val_loss: 4.5226e-04 - val_mae: 0.0184\n",
      "Epoch 16/20\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - loss: 0.0218 - mae: 0.1061 - val_loss: 0.0019 - val_mae: 0.0430\n",
      "Epoch 17/20\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - loss: 0.0213 - mae: 0.1040 - val_loss: 0.0101 - val_mae: 0.1001\n",
      "Epoch 18/20\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - loss: 0.0215 - mae: 0.1052 - val_loss: 0.0055 - val_mae: 0.0736\n",
      "Epoch 19/20\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0211 - mae: 0.1042 - val_loss: 2.1642e-05 - val_mae: 0.0029\n",
      "Epoch 20/20\n",
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - loss: 0.0214 - mae: 0.1048 - val_loss: 0.0020 - val_mae: 0.0449\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step  \n",
      "✅ Done with wheat_Chitradurga_daily.csv | MAE=83.83, RMSE=84.38, R2=-0.39, MAPE=2.8%, Accuracy=97.2%\n",
      "\n",
      "🚀 Processing: wheat_Davangere_daily.csv\n",
      "Epoch 1/20\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 24ms/step - loss: 0.0143 - mae: 0.0988 - val_loss: 0.0093 - val_mae: 0.0574\n",
      "Epoch 2/20\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 22ms/step - loss: 0.0113 - mae: 0.0857 - val_loss: 0.0173 - val_mae: 0.0982\n",
      "Epoch 3/20\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 23ms/step - loss: 0.0109 - mae: 0.0839 - val_loss: 0.0352 - val_mae: 0.1481\n",
      "Epoch 4/20\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 25ms/step - loss: 0.0107 - mae: 0.0828 - val_loss: 0.0263 - val_mae: 0.1232\n",
      "Epoch 5/20\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 24ms/step - loss: 0.0104 - mae: 0.0814 - val_loss: 0.0223 - val_mae: 0.1124\n",
      "Epoch 6/20\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 24ms/step - loss: 0.0103 - mae: 0.0810 - val_loss: 0.0240 - val_mae: 0.1243\n",
      "Epoch 7/20\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 24ms/step - loss: 0.0102 - mae: 0.0803 - val_loss: 0.0340 - val_mae: 0.1547\n",
      "Epoch 8/20\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 25ms/step - loss: 0.0101 - mae: 0.0804 - val_loss: 0.0221 - val_mae: 0.1075\n",
      "Epoch 9/20\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 25ms/step - loss: 0.0100 - mae: 0.0793 - val_loss: 0.0192 - val_mae: 0.0951\n",
      "Epoch 10/20\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 25ms/step - loss: 0.0099 - mae: 0.0791 - val_loss: 0.0225 - val_mae: 0.1129\n",
      "Epoch 11/20\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 24ms/step - loss: 0.0099 - mae: 0.0786 - val_loss: 0.0372 - val_mae: 0.1609\n",
      "Epoch 12/20\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 26ms/step - loss: 0.0098 - mae: 0.0783 - val_loss: 0.0393 - val_mae: 0.1671\n",
      "Epoch 13/20\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 25ms/step - loss: 0.0097 - mae: 0.0776 - val_loss: 0.0442 - val_mae: 0.1767\n",
      "Epoch 14/20\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 24ms/step - loss: 0.0097 - mae: 0.0777 - val_loss: 0.0539 - val_mae: 0.1936\n",
      "Epoch 15/20\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 23ms/step - loss: 0.0096 - mae: 0.0774 - val_loss: 0.0873 - val_mae: 0.2589\n",
      "Epoch 16/20\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 24ms/step - loss: 0.0096 - mae: 0.0771 - val_loss: 0.0714 - val_mae: 0.2298\n",
      "Epoch 17/20\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 26ms/step - loss: 0.0095 - mae: 0.0764 - val_loss: 0.0674 - val_mae: 0.2165\n",
      "Epoch 18/20\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 25ms/step - loss: 0.0094 - mae: 0.0763 - val_loss: 0.0585 - val_mae: 0.2038\n",
      "Epoch 19/20\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 23ms/step - loss: 0.0094 - mae: 0.0760 - val_loss: 0.0543 - val_mae: 0.1969\n",
      "Epoch 20/20\n",
      "\u001b[1m519/519\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 23ms/step - loss: 0.0094 - mae: 0.0759 - val_loss: 0.0646 - val_mae: 0.2127\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step  \n",
      "✅ Done with wheat_Davangere_daily.csv | MAE=648.46, RMSE=775.15, R2=-3.88, MAPE=23.32%, Accuracy=76.68%\n",
      "\n",
      "🚀 Processing: wheat_Dharwad_daily.csv\n",
      "Epoch 1/20\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 25ms/step - loss: 0.0062 - mae: 0.0552 - val_loss: 0.0127 - val_mae: 0.0812\n",
      "Epoch 2/20\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 23ms/step - loss: 0.0053 - mae: 0.0507 - val_loss: 0.0142 - val_mae: 0.0829\n",
      "Epoch 3/20\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 25ms/step - loss: 0.0051 - mae: 0.0491 - val_loss: 0.0136 - val_mae: 0.0816\n",
      "Epoch 4/20\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 23ms/step - loss: 0.0050 - mae: 0.0490 - val_loss: 0.0146 - val_mae: 0.0842\n",
      "Epoch 5/20\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 23ms/step - loss: 0.0049 - mae: 0.0485 - val_loss: 0.0144 - val_mae: 0.0839\n",
      "Epoch 6/20\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 23ms/step - loss: 0.0049 - mae: 0.0484 - val_loss: 0.0160 - val_mae: 0.0881\n",
      "Epoch 7/20\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 24ms/step - loss: 0.0049 - mae: 0.0481 - val_loss: 0.0145 - val_mae: 0.0844\n",
      "Epoch 8/20\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 23ms/step - loss: 0.0049 - mae: 0.0481 - val_loss: 0.0185 - val_mae: 0.0956\n",
      "Epoch 9/20\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 22ms/step - loss: 0.0049 - mae: 0.0483 - val_loss: 0.0136 - val_mae: 0.0825\n",
      "Epoch 10/20\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 24ms/step - loss: 0.0049 - mae: 0.0480 - val_loss: 0.0143 - val_mae: 0.0838\n",
      "Epoch 11/20\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 22ms/step - loss: 0.0049 - mae: 0.0480 - val_loss: 0.0161 - val_mae: 0.0883\n",
      "Epoch 12/20\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 23ms/step - loss: 0.0048 - mae: 0.0478 - val_loss: 0.0129 - val_mae: 0.0808\n",
      "Epoch 13/20\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 26ms/step - loss: 0.0049 - mae: 0.0478 - val_loss: 0.0153 - val_mae: 0.0862\n",
      "Epoch 14/20\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 23ms/step - loss: 0.0049 - mae: 0.0479 - val_loss: 0.0170 - val_mae: 0.0911\n",
      "Epoch 15/20\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 23ms/step - loss: 0.0049 - mae: 0.0480 - val_loss: 0.0174 - val_mae: 0.0924\n",
      "Epoch 16/20\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 24ms/step - loss: 0.0049 - mae: 0.0479 - val_loss: 0.0151 - val_mae: 0.0855\n",
      "Epoch 17/20\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 25ms/step - loss: 0.0049 - mae: 0.0477 - val_loss: 0.0148 - val_mae: 0.0842\n",
      "Epoch 18/20\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 27ms/step - loss: 0.0048 - mae: 0.0477 - val_loss: 0.0139 - val_mae: 0.0829\n",
      "Epoch 19/20\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 26ms/step - loss: 0.0048 - mae: 0.0476 - val_loss: 0.0154 - val_mae: 0.0869\n",
      "Epoch 20/20\n",
      "\u001b[1m1099/1099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 25ms/step - loss: 0.0048 - mae: 0.0476 - val_loss: 0.0176 - val_mae: 0.0935\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step   \n",
      "✅ Done with wheat_Dharwad_daily.csv | MAE=385.37, RMSE=546.81, R2=0.08, MAPE=15.13%, Accuracy=84.87%\n",
      "\n",
      "🚀 Processing: wheat_Gadag_daily.csv\n",
      "Epoch 1/20\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 28ms/step - loss: 7.4634e-04 - mae: 0.0191 - val_loss: 0.0019 - val_mae: 0.0315\n",
      "Epoch 2/20\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 26ms/step - loss: 6.1855e-04 - mae: 0.0172 - val_loss: 0.0012 - val_mae: 0.0245\n",
      "Epoch 3/20\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - loss: 6.0334e-04 - mae: 0.0169 - val_loss: 0.0018 - val_mae: 0.0306\n",
      "Epoch 4/20\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - loss: 5.8876e-04 - mae: 0.0167 - val_loss: 0.0013 - val_mae: 0.0263\n",
      "Epoch 5/20\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - loss: 5.8371e-04 - mae: 0.0165 - val_loss: 0.0016 - val_mae: 0.0281\n",
      "Epoch 6/20\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - loss: 5.8154e-04 - mae: 0.0164 - val_loss: 0.0013 - val_mae: 0.0269\n",
      "Epoch 7/20\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - loss: 5.8413e-04 - mae: 0.0165 - val_loss: 0.0013 - val_mae: 0.0256\n",
      "Epoch 8/20\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 26ms/step - loss: 5.8482e-04 - mae: 0.0165 - val_loss: 0.0017 - val_mae: 0.0294\n",
      "Epoch 9/20\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 26ms/step - loss: 5.8016e-04 - mae: 0.0164 - val_loss: 0.0016 - val_mae: 0.0282\n",
      "Epoch 10/20\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - loss: 5.7932e-04 - mae: 0.0164 - val_loss: 0.0013 - val_mae: 0.0257\n",
      "Epoch 11/20\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - loss: 5.8189e-04 - mae: 0.0165 - val_loss: 0.0014 - val_mae: 0.0268\n",
      "Epoch 12/20\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - loss: 5.7611e-04 - mae: 0.0163 - val_loss: 0.0014 - val_mae: 0.0261\n",
      "Epoch 13/20\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - loss: 5.8073e-04 - mae: 0.0164 - val_loss: 0.0014 - val_mae: 0.0267\n",
      "Epoch 14/20\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 27ms/step - loss: 5.7459e-04 - mae: 0.0163 - val_loss: 0.0015 - val_mae: 0.0275\n",
      "Epoch 15/20\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 27ms/step - loss: 5.7622e-04 - mae: 0.0163 - val_loss: 0.0018 - val_mae: 0.0300\n",
      "Epoch 16/20\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 30ms/step - loss: 5.7282e-04 - mae: 0.0163 - val_loss: 0.0015 - val_mae: 0.0274\n",
      "Epoch 17/20\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - loss: 5.7273e-04 - mae: 0.0163 - val_loss: 0.0018 - val_mae: 0.0303\n",
      "Epoch 18/20\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 24ms/step - loss: 5.7633e-04 - mae: 0.0163 - val_loss: 0.0014 - val_mae: 0.0265\n",
      "Epoch 19/20\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - loss: 5.7166e-04 - mae: 0.0163 - val_loss: 0.0015 - val_mae: 0.0277\n",
      "Epoch 20/20\n",
      "\u001b[1m1004/1004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 26ms/step - loss: 5.6840e-04 - mae: 0.0162 - val_loss: 0.0018 - val_mae: 0.0303\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step\n",
      "✅ Done with wheat_Gadag_daily.csv | MAE=440.26, RMSE=617.31, R2=0.18, MAPE=16.2%, Accuracy=83.8%\n",
      "\n",
      "🚀 Processing: wheat_Hassan_daily.csv\n",
      "Epoch 1/20\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 31ms/step - loss: 0.0013 - mae: 0.0232 - val_loss: 0.0012 - val_mae: 0.0296\n",
      "Epoch 2/20\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 24ms/step - loss: 9.6920e-04 - mae: 0.0194 - val_loss: 6.5741e-04 - val_mae: 0.0212\n",
      "Epoch 3/20\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 23ms/step - loss: 8.0457e-04 - mae: 0.0181 - val_loss: 4.6888e-04 - val_mae: 0.0170\n",
      "Epoch 4/20\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 24ms/step - loss: 7.6425e-04 - mae: 0.0174 - val_loss: 0.0014 - val_mae: 0.0339\n",
      "Epoch 5/20\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 25ms/step - loss: 7.2292e-04 - mae: 0.0168 - val_loss: 0.0020 - val_mae: 0.0404\n",
      "Epoch 6/20\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 23ms/step - loss: 7.4301e-04 - mae: 0.0171 - val_loss: 5.5131e-04 - val_mae: 0.0191\n",
      "Epoch 7/20\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 21ms/step - loss: 7.1560e-04 - mae: 0.0165 - val_loss: 4.5086e-04 - val_mae: 0.0168\n",
      "Epoch 8/20\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 21ms/step - loss: 7.0995e-04 - mae: 0.0162 - val_loss: 1.9922e-04 - val_mae: 0.0113\n",
      "Epoch 9/20\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 22ms/step - loss: 7.0768e-04 - mae: 0.0163 - val_loss: 2.2563e-04 - val_mae: 0.0120\n",
      "Epoch 10/20\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 21ms/step - loss: 7.0223e-04 - mae: 0.0160 - val_loss: 2.7463e-04 - val_mae: 0.0130\n",
      "Epoch 11/20\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20ms/step - loss: 6.0173e-04 - mae: 0.0156 - val_loss: 6.3306e-04 - val_mae: 0.0207\n",
      "Epoch 12/20\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 22ms/step - loss: 6.3157e-04 - mae: 0.0157 - val_loss: 3.6272e-04 - val_mae: 0.0152\n",
      "Epoch 13/20\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 22ms/step - loss: 6.5249e-04 - mae: 0.0156 - val_loss: 4.6049e-04 - val_mae: 0.0173\n",
      "Epoch 14/20\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 21ms/step - loss: 6.2999e-04 - mae: 0.0152 - val_loss: 2.3673e-04 - val_mae: 0.0117\n",
      "Epoch 15/20\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 21ms/step - loss: 6.1993e-04 - mae: 0.0153 - val_loss: 6.6356e-04 - val_mae: 0.0218\n",
      "Epoch 16/20\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 23ms/step - loss: 7.5078e-04 - mae: 0.0163 - val_loss: 7.1510e-04 - val_mae: 0.0229\n",
      "Epoch 17/20\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 21ms/step - loss: 5.9382e-04 - mae: 0.0150 - val_loss: 3.5667e-04 - val_mae: 0.0150\n",
      "Epoch 18/20\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 23ms/step - loss: 5.9474e-04 - mae: 0.0150 - val_loss: 2.2653e-04 - val_mae: 0.0119\n",
      "Epoch 19/20\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 23ms/step - loss: 6.4930e-04 - mae: 0.0153 - val_loss: 1.9904e-04 - val_mae: 0.0110\n",
      "Epoch 20/20\n",
      "\u001b[1m623/623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 23ms/step - loss: 6.0779e-04 - mae: 0.0151 - val_loss: 6.0511e-04 - val_mae: 0.0202\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step   \n",
      "✅ Done with wheat_Hassan_daily.csv | MAE=263.18, RMSE=319.79, R2=0.41, MAPE=8.18%, Accuracy=91.82%\n",
      "\n",
      "🚀 Processing: wheat_Haveri_daily.csv\n",
      "Epoch 1/20\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 23ms/step - loss: 0.0137 - mae: 0.0866 - val_loss: 0.0140 - val_mae: 0.0940\n",
      "Epoch 2/20\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 22ms/step - loss: 0.0111 - mae: 0.0768 - val_loss: 0.0171 - val_mae: 0.1008\n",
      "Epoch 3/20\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 24ms/step - loss: 0.0105 - mae: 0.0747 - val_loss: 0.0180 - val_mae: 0.1021\n",
      "Epoch 4/20\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 25ms/step - loss: 0.0102 - mae: 0.0736 - val_loss: 0.0166 - val_mae: 0.0988\n",
      "Epoch 5/20\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 23ms/step - loss: 0.0100 - mae: 0.0728 - val_loss: 0.0196 - val_mae: 0.1087\n",
      "Epoch 6/20\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 25ms/step - loss: 0.0099 - mae: 0.0727 - val_loss: 0.0153 - val_mae: 0.0964\n",
      "Epoch 7/20\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 28ms/step - loss: 0.0097 - mae: 0.0719 - val_loss: 0.0147 - val_mae: 0.0949\n",
      "Epoch 8/20\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 23ms/step - loss: 0.0097 - mae: 0.0717 - val_loss: 0.0217 - val_mae: 0.1190\n",
      "Epoch 9/20\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 26ms/step - loss: 0.0097 - mae: 0.0716 - val_loss: 0.0150 - val_mae: 0.0949\n",
      "Epoch 10/20\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - loss: 0.0096 - mae: 0.0711 - val_loss: 0.0164 - val_mae: 0.1022\n",
      "Epoch 11/20\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 22ms/step - loss: 0.0096 - mae: 0.0710 - val_loss: 0.0203 - val_mae: 0.1130\n",
      "Epoch 12/20\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 25ms/step - loss: 0.0095 - mae: 0.0707 - val_loss: 0.0186 - val_mae: 0.1076\n",
      "Epoch 13/20\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - loss: 0.0096 - mae: 0.0715 - val_loss: 0.0151 - val_mae: 0.0933\n",
      "Epoch 14/20\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 29ms/step - loss: 0.0094 - mae: 0.0705 - val_loss: 0.0218 - val_mae: 0.1173\n",
      "Epoch 15/20\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 34ms/step - loss: 0.0095 - mae: 0.0709 - val_loss: 0.0156 - val_mae: 0.0965\n",
      "Epoch 16/20\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - loss: 0.0095 - mae: 0.0705 - val_loss: 0.0187 - val_mae: 0.1089\n",
      "Epoch 17/20\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 33ms/step - loss: 0.0095 - mae: 0.0705 - val_loss: 0.0220 - val_mae: 0.1182\n",
      "Epoch 18/20\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 30ms/step - loss: 0.0094 - mae: 0.0702 - val_loss: 0.0169 - val_mae: 0.0994\n",
      "Epoch 19/20\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 28ms/step - loss: 0.0094 - mae: 0.0702 - val_loss: 0.0161 - val_mae: 0.1010\n",
      "Epoch 20/20\n",
      "\u001b[1m794/794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 31ms/step - loss: 0.0094 - mae: 0.0703 - val_loss: 0.0206 - val_mae: 0.1121\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step\n",
      "✅ Done with wheat_Haveri_daily.csv | MAE=270.36, RMSE=346.62, R2=0.07, MAPE=12.45%, Accuracy=87.55%\n",
      "\n",
      "🚀 Processing: wheat_Kalburgi_daily.csv\n",
      "Epoch 1/20\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 26ms/step - loss: 0.0163 - mae: 0.1033 - val_loss: 0.0107 - val_mae: 0.0622\n",
      "Epoch 2/20\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 28ms/step - loss: 0.0119 - mae: 0.0847 - val_loss: 0.0217 - val_mae: 0.0690\n",
      "Epoch 3/20\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 35ms/step - loss: 0.0112 - mae: 0.0814 - val_loss: 0.0235 - val_mae: 0.0909\n",
      "Epoch 4/20\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 30ms/step - loss: 0.0109 - mae: 0.0802 - val_loss: 0.0287 - val_mae: 0.0991\n",
      "Epoch 5/20\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 28ms/step - loss: 0.0108 - mae: 0.0794 - val_loss: 0.0263 - val_mae: 0.0770\n",
      "Epoch 6/20\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 29ms/step - loss: 0.0107 - mae: 0.0791 - val_loss: 0.0279 - val_mae: 0.0846\n",
      "Epoch 7/20\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 28ms/step - loss: 0.0105 - mae: 0.0782 - val_loss: 0.0265 - val_mae: 0.0976\n",
      "Epoch 8/20\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 30ms/step - loss: 0.0104 - mae: 0.0780 - val_loss: 0.0286 - val_mae: 0.0744\n",
      "Epoch 9/20\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 26ms/step - loss: 0.0104 - mae: 0.0776 - val_loss: 0.0259 - val_mae: 0.0685\n",
      "Epoch 10/20\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 27ms/step - loss: 0.0103 - mae: 0.0775 - val_loss: 0.0321 - val_mae: 0.0821\n",
      "Epoch 11/20\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 30ms/step - loss: 0.0102 - mae: 0.0770 - val_loss: 0.0298 - val_mae: 0.0708\n",
      "Epoch 12/20\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 28ms/step - loss: 0.0102 - mae: 0.0770 - val_loss: 0.0271 - val_mae: 0.0729\n",
      "Epoch 13/20\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 27ms/step - loss: 0.0101 - mae: 0.0767 - val_loss: 0.0316 - val_mae: 0.0839\n",
      "Epoch 14/20\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 26ms/step - loss: 0.0101 - mae: 0.0764 - val_loss: 0.0332 - val_mae: 0.0795\n",
      "Epoch 15/20\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 27ms/step - loss: 0.0101 - mae: 0.0764 - val_loss: 0.0298 - val_mae: 0.0791\n",
      "Epoch 16/20\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 34ms/step - loss: 0.0101 - mae: 0.0765 - val_loss: 0.0331 - val_mae: 0.0807\n",
      "Epoch 17/20\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 39ms/step - loss: 0.0100 - mae: 0.0761 - val_loss: 0.0306 - val_mae: 0.0808\n",
      "Epoch 18/20\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 36ms/step - loss: 0.0101 - mae: 0.0766 - val_loss: 0.0356 - val_mae: 0.0919\n",
      "Epoch 19/20\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 27ms/step - loss: 0.0099 - mae: 0.0756 - val_loss: 0.0380 - val_mae: 0.1070\n",
      "Epoch 20/20\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - loss: 0.0100 - mae: 0.0760 - val_loss: 0.0324 - val_mae: 0.0918\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step\n",
      "✅ Done with wheat_Kalburgi_daily.csv | MAE=331.85, RMSE=650.21, R2=-0.56, MAPE=11.18%, Accuracy=88.82%\n",
      "\n",
      "🚀 Processing: wheat_Kolar_daily.csv\n",
      "Epoch 1/20\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 26ms/step - loss: 0.0077 - mae: 0.0688 - val_loss: 0.0183 - val_mae: 0.1204\n",
      "Epoch 2/20\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - loss: 0.0053 - mae: 0.0570 - val_loss: 0.0163 - val_mae: 0.1085\n",
      "Epoch 3/20\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 23ms/step - loss: 0.0044 - mae: 0.0497 - val_loss: 0.0151 - val_mae: 0.0956\n",
      "Epoch 4/20\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 23ms/step - loss: 0.0041 - mae: 0.0470 - val_loss: 0.0192 - val_mae: 0.1050\n",
      "Epoch 5/20\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 23ms/step - loss: 0.0036 - mae: 0.0435 - val_loss: 0.0194 - val_mae: 0.1056\n",
      "Epoch 6/20\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - loss: 0.0037 - mae: 0.0433 - val_loss: 0.0179 - val_mae: 0.1002\n",
      "Epoch 7/20\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - loss: 0.0036 - mae: 0.0433 - val_loss: 0.0185 - val_mae: 0.1059\n",
      "Epoch 8/20\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - loss: 0.0035 - mae: 0.0416 - val_loss: 0.0197 - val_mae: 0.1091\n",
      "Epoch 9/20\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 28ms/step - loss: 0.0035 - mae: 0.0424 - val_loss: 0.0232 - val_mae: 0.1171\n",
      "Epoch 10/20\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 26ms/step - loss: 0.0034 - mae: 0.0415 - val_loss: 0.0212 - val_mae: 0.1131\n",
      "Epoch 11/20\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - loss: 0.0034 - mae: 0.0412 - val_loss: 0.0255 - val_mae: 0.1244\n",
      "Epoch 12/20\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 26ms/step - loss: 0.0034 - mae: 0.0410 - val_loss: 0.0202 - val_mae: 0.1101\n",
      "Epoch 13/20\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - loss: 0.0033 - mae: 0.0407 - val_loss: 0.0201 - val_mae: 0.1087\n",
      "Epoch 14/20\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - loss: 0.0033 - mae: 0.0409 - val_loss: 0.0193 - val_mae: 0.1120\n",
      "Epoch 15/20\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 30ms/step - loss: 0.0033 - mae: 0.0408 - val_loss: 0.0217 - val_mae: 0.1146\n",
      "Epoch 16/20\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 28ms/step - loss: 0.0033 - mae: 0.0409 - val_loss: 0.0208 - val_mae: 0.1141\n",
      "Epoch 17/20\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 25ms/step - loss: 0.0033 - mae: 0.0406 - val_loss: 0.0182 - val_mae: 0.1026\n",
      "Epoch 18/20\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 23ms/step - loss: 0.0033 - mae: 0.0404 - val_loss: 0.0218 - val_mae: 0.1133\n",
      "Epoch 19/20\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - loss: 0.0032 - mae: 0.0399 - val_loss: 0.0274 - val_mae: 0.1288\n",
      "Epoch 20/20\n",
      "\u001b[1m402/402\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 23ms/step - loss: 0.0033 - mae: 0.0400 - val_loss: 0.0209 - val_mae: 0.1132\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step  \n",
      "✅ Done with wheat_Kolar_daily.csv | MAE=373.64, RMSE=476.86, R2=0.29, MAPE=13.14%, Accuracy=86.86%\n",
      "\n",
      "🚀 Processing: wheat_Koppal_daily.csv\n",
      "Epoch 1/20\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - loss: 0.0116 - mae: 0.0877 - val_loss: 0.0152 - val_mae: 0.0927\n",
      "Epoch 2/20\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 23ms/step - loss: 0.0087 - mae: 0.0747 - val_loss: 0.0101 - val_mae: 0.0814\n",
      "Epoch 3/20\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 27ms/step - loss: 0.0082 - mae: 0.0725 - val_loss: 0.0106 - val_mae: 0.0816\n",
      "Epoch 4/20\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 27ms/step - loss: 0.0081 - mae: 0.0717 - val_loss: 0.0111 - val_mae: 0.0782\n",
      "Epoch 5/20\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 25ms/step - loss: 0.0078 - mae: 0.0703 - val_loss: 0.0097 - val_mae: 0.0749\n",
      "Epoch 6/20\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 24ms/step - loss: 0.0079 - mae: 0.0705 - val_loss: 0.0098 - val_mae: 0.0775\n",
      "Epoch 7/20\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 23ms/step - loss: 0.0077 - mae: 0.0699 - val_loss: 0.0103 - val_mae: 0.0766\n",
      "Epoch 8/20\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 25ms/step - loss: 0.0077 - mae: 0.0698 - val_loss: 0.0102 - val_mae: 0.0771\n",
      "Epoch 9/20\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 27ms/step - loss: 0.0077 - mae: 0.0697 - val_loss: 0.0097 - val_mae: 0.0745\n",
      "Epoch 10/20\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 25ms/step - loss: 0.0076 - mae: 0.0692 - val_loss: 0.0095 - val_mae: 0.0754\n",
      "Epoch 11/20\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 25ms/step - loss: 0.0076 - mae: 0.0691 - val_loss: 0.0105 - val_mae: 0.0767\n",
      "Epoch 12/20\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 23ms/step - loss: 0.0076 - mae: 0.0691 - val_loss: 0.0103 - val_mae: 0.0814\n",
      "Epoch 13/20\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 23ms/step - loss: 0.0076 - mae: 0.0693 - val_loss: 0.0098 - val_mae: 0.0749\n",
      "Epoch 14/20\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 25ms/step - loss: 0.0076 - mae: 0.0691 - val_loss: 0.0119 - val_mae: 0.0891\n",
      "Epoch 15/20\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 29ms/step - loss: 0.0075 - mae: 0.0690 - val_loss: 0.0109 - val_mae: 0.0765\n",
      "Epoch 16/20\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 32ms/step - loss: 0.0075 - mae: 0.0688 - val_loss: 0.0102 - val_mae: 0.0800\n",
      "Epoch 17/20\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 29ms/step - loss: 0.0075 - mae: 0.0683 - val_loss: 0.0103 - val_mae: 0.0768\n",
      "Epoch 18/20\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 31ms/step - loss: 0.0075 - mae: 0.0685 - val_loss: 0.0100 - val_mae: 0.0787\n",
      "Epoch 19/20\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 23ms/step - loss: 0.0074 - mae: 0.0683 - val_loss: 0.0106 - val_mae: 0.0830\n",
      "Epoch 20/20\n",
      "\u001b[1m662/662\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 36ms/step - loss: 0.0074 - mae: 0.0685 - val_loss: 0.0107 - val_mae: 0.0765\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step\n",
      "✅ Done with wheat_Koppal_daily.csv | MAE=183.53, RMSE=248.13, R2=0.43, MAPE=7.77%, Accuracy=92.23%\n",
      "\n",
      "🚀 Processing: wheat_MadikeriKodagu_daily.csv\n",
      "Epoch 1/20\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 41ms/step - loss: 0.0133 - mae: 0.0706 - val_loss: 1.2560e-06 - val_mae: 9.4754e-04\n",
      "Epoch 2/20\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - loss: 0.0054 - mae: 0.0456 - val_loss: 3.8668e-05 - val_mae: 0.0057\n",
      "Epoch 3/20\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - loss: 0.0046 - mae: 0.0416 - val_loss: 2.3241e-05 - val_mae: 0.0046\n",
      "Epoch 4/20\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - loss: 0.0041 - mae: 0.0407 - val_loss: 9.1192e-05 - val_mae: 0.0087\n",
      "Epoch 5/20\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - loss: 0.0038 - mae: 0.0385 - val_loss: 6.3534e-05 - val_mae: 0.0080\n",
      "Epoch 6/20\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - loss: 0.0034 - mae: 0.0355 - val_loss: 1.1577e-04 - val_mae: 0.0105\n",
      "Epoch 7/20\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - loss: 0.0032 - mae: 0.0349 - val_loss: 5.1746e-05 - val_mae: 0.0072\n",
      "Epoch 8/20\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - loss: 0.0034 - mae: 0.0367 - val_loss: 4.5152e-05 - val_mae: 0.0064\n",
      "Epoch 9/20\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - loss: 0.0032 - mae: 0.0361 - val_loss: 5.4397e-06 - val_mae: 0.0020\n",
      "Epoch 10/20\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - loss: 0.0032 - mae: 0.0351 - val_loss: 3.0628e-04 - val_mae: 0.0167\n",
      "Epoch 11/20\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - loss: 0.0027 - mae: 0.0329 - val_loss: 9.3138e-06 - val_mae: 0.0025\n",
      "Epoch 12/20\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - loss: 0.0026 - mae: 0.0327 - val_loss: 1.2624e-05 - val_mae: 0.0036\n",
      "Epoch 13/20\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - loss: 0.0026 - mae: 0.0323 - val_loss: 1.4547e-04 - val_mae: 0.0120\n",
      "Epoch 14/20\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - loss: 0.0028 - mae: 0.0342 - val_loss: 4.3648e-05 - val_mae: 0.0062\n",
      "Epoch 15/20\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - loss: 0.0022 - mae: 0.0305 - val_loss: 2.8113e-04 - val_mae: 0.0167\n",
      "Epoch 16/20\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - loss: 0.0026 - mae: 0.0326 - val_loss: 5.1065e-07 - val_mae: 6.2795e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - loss: 0.0023 - mae: 0.0313 - val_loss: 6.4654e-06 - val_mae: 0.0025\n",
      "Epoch 18/20\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - loss: 0.0022 - mae: 0.0307 - val_loss: 1.7185e-04 - val_mae: 0.0130\n",
      "Epoch 19/20\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - loss: 0.0022 - mae: 0.0304 - val_loss: 1.5389e-05 - val_mae: 0.0038\n",
      "Epoch 20/20\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - loss: 0.0021 - mae: 0.0290 - val_loss: 1.2930e-04 - val_mae: 0.0113\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step\n",
      "✅ Done with wheat_MadikeriKodagu_daily.csv | MAE=209.61, RMSE=211.84, R2=0.98, MAPE=6.75%, Accuracy=93.25%\n",
      "\n",
      "🚀 Processing: wheat_Mandya_daily.csv\n",
      "Epoch 1/20\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 43ms/step - loss: 0.0382 - mae: 0.1565 - val_loss: 0.0058 - val_mae: 0.0726\n",
      "Epoch 2/20\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 32ms/step - loss: 0.0271 - mae: 0.1354 - val_loss: 9.9246e-04 - val_mae: 0.0300\n",
      "Epoch 3/20\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 35ms/step - loss: 0.0227 - mae: 0.1192 - val_loss: 7.0435e-04 - val_mae: 0.0228\n",
      "Epoch 4/20\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 0.0199 - mae: 0.1059 - val_loss: 5.6326e-04 - val_mae: 0.0151\n",
      "Epoch 5/20\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 35ms/step - loss: 0.0198 - mae: 0.1054 - val_loss: 5.3801e-04 - val_mae: 0.0102\n",
      "Epoch 6/20\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 35ms/step - loss: 0.0195 - mae: 0.1034 - val_loss: 0.0013 - val_mae: 0.0319\n",
      "Epoch 7/20\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 34ms/step - loss: 0.0187 - mae: 0.1004 - val_loss: 0.0028 - val_mae: 0.0354\n",
      "Epoch 8/20\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 38ms/step - loss: 0.0187 - mae: 0.0987 - val_loss: 0.0014 - val_mae: 0.0238\n",
      "Epoch 9/20\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 35ms/step - loss: 0.0180 - mae: 0.0956 - val_loss: 0.0011 - val_mae: 0.0256\n",
      "Epoch 10/20\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 35ms/step - loss: 0.0179 - mae: 0.0957 - val_loss: 0.0010 - val_mae: 0.0131\n",
      "Epoch 11/20\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 37ms/step - loss: 0.0179 - mae: 0.0948 - val_loss: 0.0034 - val_mae: 0.0497\n",
      "Epoch 12/20\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 36ms/step - loss: 0.0174 - mae: 0.0926 - val_loss: 6.1014e-04 - val_mae: 0.0133\n",
      "Epoch 13/20\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 39ms/step - loss: 0.0171 - mae: 0.0918 - val_loss: 0.0013 - val_mae: 0.0256\n",
      "Epoch 14/20\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 37ms/step - loss: 0.0175 - mae: 0.0932 - val_loss: 0.0020 - val_mae: 0.0357\n",
      "Epoch 15/20\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 36ms/step - loss: 0.0171 - mae: 0.0904 - val_loss: 0.0012 - val_mae: 0.0201\n",
      "Epoch 16/20\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 37ms/step - loss: 0.0162 - mae: 0.0881 - val_loss: 0.0012 - val_mae: 0.0212\n",
      "Epoch 17/20\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 36ms/step - loss: 0.0164 - mae: 0.0877 - val_loss: 6.1545e-04 - val_mae: 0.0149\n",
      "Epoch 18/20\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 37ms/step - loss: 0.0172 - mae: 0.0906 - val_loss: 0.0014 - val_mae: 0.0246\n",
      "Epoch 19/20\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 36ms/step - loss: 0.0167 - mae: 0.0900 - val_loss: 0.0014 - val_mae: 0.0285\n",
      "Epoch 20/20\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 37ms/step - loss: 0.0162 - mae: 0.0870 - val_loss: 0.0018 - val_mae: 0.0319\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 81ms/step\n",
      "✅ Done with wheat_Mandya_daily.csv | MAE=59.23, RMSE=79.35, R2=0.9, MAPE=2.24%, Accuracy=97.76%\n",
      "\n",
      "🚀 Processing: wheat_Mysore_daily.csv\n",
      "Epoch 1/20\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 52ms/step - loss: 2.4320e-04 - mae: 0.0115 - val_loss: 0.0017 - val_mae: 0.0289\n",
      "Epoch 2/20\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 34ms/step - loss: 2.0040e-04 - mae: 0.0104 - val_loss: 0.0012 - val_mae: 0.0166\n",
      "Epoch 3/20\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 28ms/step - loss: 1.9275e-04 - mae: 0.0103 - val_loss: 0.0014 - val_mae: 0.0198\n",
      "Epoch 4/20\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 29ms/step - loss: 1.8684e-04 - mae: 0.0102 - val_loss: 0.0014 - val_mae: 0.0201\n",
      "Epoch 5/20\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 31ms/step - loss: 1.7991e-04 - mae: 0.0100 - val_loss: 0.0014 - val_mae: 0.0182\n",
      "Epoch 6/20\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 28ms/step - loss: 1.8123e-04 - mae: 0.0100 - val_loss: 0.0013 - val_mae: 0.0166\n",
      "Epoch 7/20\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 29ms/step - loss: 1.7893e-04 - mae: 0.0099 - val_loss: 0.0013 - val_mae: 0.0200\n",
      "Epoch 8/20\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 31ms/step - loss: 1.7689e-04 - mae: 0.0098 - val_loss: 0.0013 - val_mae: 0.0176\n",
      "Epoch 9/20\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 38ms/step - loss: 1.7436e-04 - mae: 0.0098 - val_loss: 0.0016 - val_mae: 0.0176\n",
      "Epoch 10/20\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 34ms/step - loss: 1.7473e-04 - mae: 0.0098 - val_loss: 0.0019 - val_mae: 0.0248\n",
      "Epoch 11/20\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 32ms/step - loss: 1.7474e-04 - mae: 0.0097 - val_loss: 0.0015 - val_mae: 0.0215\n",
      "Epoch 12/20\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 31ms/step - loss: 1.7242e-04 - mae: 0.0097 - val_loss: 0.0017 - val_mae: 0.0207\n",
      "Epoch 13/20\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 29ms/step - loss: 1.6984e-04 - mae: 0.0097 - val_loss: 0.0017 - val_mae: 0.0218\n",
      "Epoch 14/20\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 29ms/step - loss: 1.7184e-04 - mae: 0.0097 - val_loss: 0.0039 - val_mae: 0.0278\n",
      "Epoch 15/20\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 29ms/step - loss: 1.6981e-04 - mae: 0.0097 - val_loss: 0.0029 - val_mae: 0.0257\n",
      "Epoch 16/20\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 35ms/step - loss: 1.6948e-04 - mae: 0.0097 - val_loss: 0.0058 - val_mae: 0.0278\n",
      "Epoch 17/20\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 34ms/step - loss: 1.7089e-04 - mae: 0.0097 - val_loss: 0.0022 - val_mae: 0.0230\n",
      "Epoch 18/20\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 34ms/step - loss: 1.6847e-04 - mae: 0.0096 - val_loss: 0.0051 - val_mae: 0.0259\n",
      "Epoch 19/20\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 31ms/step - loss: 1.6995e-04 - mae: 0.0097 - val_loss: 0.0076 - val_mae: 0.0347\n",
      "Epoch 20/20\n",
      "\u001b[1m785/785\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 29ms/step - loss: 1.6398e-04 - mae: 0.0096 - val_loss: 0.0100 - val_mae: 0.0383\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step\n",
      "✅ Done with wheat_Mysore_daily.csv | MAE=1375.98, RMSE=3592.03, R2=-6.83, MAPE=64.92%, Accuracy=35.08%\n",
      "\n",
      "🚀 Processing: wheat_Raichur_daily.csv\n",
      "Epoch 1/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 31ms/step - loss: 0.0080 - mae: 0.0643 - val_loss: 0.0041 - val_mae: 0.0587\n",
      "Epoch 2/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 32ms/step - loss: 0.0065 - mae: 0.0574 - val_loss: 0.0054 - val_mae: 0.0668\n",
      "Epoch 3/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 34ms/step - loss: 0.0062 - mae: 0.0552 - val_loss: 0.0049 - val_mae: 0.0631\n",
      "Epoch 4/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 36ms/step - loss: 0.0060 - mae: 0.0541 - val_loss: 0.0086 - val_mae: 0.0813\n",
      "Epoch 5/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 38ms/step - loss: 0.0059 - mae: 0.0533 - val_loss: 0.0127 - val_mae: 0.0949\n",
      "Epoch 6/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 36ms/step - loss: 0.0058 - mae: 0.0526 - val_loss: 0.0237 - val_mae: 0.1220\n",
      "Epoch 7/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 41ms/step - loss: 0.0057 - mae: 0.0519 - val_loss: 0.0234 - val_mae: 0.1222\n",
      "Epoch 8/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 37ms/step - loss: 0.0057 - mae: 0.0522 - val_loss: 0.0130 - val_mae: 0.0957\n",
      "Epoch 9/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 35ms/step - loss: 0.0057 - mae: 0.0518 - val_loss: 0.0293 - val_mae: 0.1330\n",
      "Epoch 10/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 39ms/step - loss: 0.0057 - mae: 0.0520 - val_loss: 0.0204 - val_mae: 0.1129\n",
      "Epoch 11/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 34ms/step - loss: 0.0056 - mae: 0.0515 - val_loss: 0.0241 - val_mae: 0.1223\n",
      "Epoch 12/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 30ms/step - loss: 0.0057 - mae: 0.0519 - val_loss: 0.0262 - val_mae: 0.1278\n",
      "Epoch 13/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 29ms/step - loss: 0.0056 - mae: 0.0517 - val_loss: 0.0159 - val_mae: 0.1029\n",
      "Epoch 14/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 34ms/step - loss: 0.0056 - mae: 0.0518 - val_loss: 0.0166 - val_mae: 0.1057\n",
      "Epoch 15/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 37ms/step - loss: 0.0055 - mae: 0.0514 - val_loss: 0.0209 - val_mae: 0.1151\n",
      "Epoch 16/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 34ms/step - loss: 0.0056 - mae: 0.0518 - val_loss: 0.0193 - val_mae: 0.1121\n",
      "Epoch 17/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 39ms/step - loss: 0.0055 - mae: 0.0513 - val_loss: 0.0134 - val_mae: 0.0959\n",
      "Epoch 18/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 46ms/step - loss: 0.0056 - mae: 0.0517 - val_loss: 0.0174 - val_mae: 0.1073\n",
      "Epoch 19/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 41ms/step - loss: 0.0054 - mae: 0.0509 - val_loss: 0.0158 - val_mae: 0.1039\n",
      "Epoch 20/20\n",
      "\u001b[1m548/548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 32ms/step - loss: 0.0054 - mae: 0.0508 - val_loss: 0.0158 - val_mae: 0.1042\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step\n",
      "✅ Done with wheat_Raichur_daily.csv | MAE=297.07, RMSE=357.87, R2=0.3, MAPE=14.6%, Accuracy=85.4%\n",
      "\n",
      "🚀 Processing: wheat_Shimoga_daily.csv\n",
      "Epoch 1/20\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 34ms/step - loss: 8.0998e-05 - mae: 0.0073 - val_loss: 7.2154e-04 - val_mae: 0.0093\n",
      "Epoch 2/20\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 38ms/step - loss: 6.5213e-05 - mae: 0.0065 - val_loss: 8.0458e-04 - val_mae: 0.0092\n",
      "Epoch 3/20\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 35ms/step - loss: 6.3426e-05 - mae: 0.0063 - val_loss: 8.4666e-04 - val_mae: 0.0092\n",
      "Epoch 4/20\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 34ms/step - loss: 5.9619e-05 - mae: 0.0061 - val_loss: 8.3738e-04 - val_mae: 0.0096\n",
      "Epoch 5/20\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 35ms/step - loss: 5.9523e-05 - mae: 0.0061 - val_loss: 8.0293e-04 - val_mae: 0.0102\n",
      "Epoch 6/20\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 35ms/step - loss: 5.7473e-05 - mae: 0.0060 - val_loss: 7.6050e-04 - val_mae: 0.0091\n",
      "Epoch 7/20\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 31ms/step - loss: 5.6311e-05 - mae: 0.0060 - val_loss: 7.9056e-04 - val_mae: 0.0095\n",
      "Epoch 8/20\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 38ms/step - loss: 5.6998e-05 - mae: 0.0060 - val_loss: 8.3256e-04 - val_mae: 0.0092\n",
      "Epoch 9/20\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 32ms/step - loss: 5.6673e-05 - mae: 0.0060 - val_loss: 7.6826e-04 - val_mae: 0.0089\n",
      "Epoch 10/20\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 36ms/step - loss: 5.5693e-05 - mae: 0.0059 - val_loss: 7.8366e-04 - val_mae: 0.0089\n",
      "Epoch 11/20\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 33ms/step - loss: 5.5458e-05 - mae: 0.0059 - val_loss: 7.4633e-04 - val_mae: 0.0090\n",
      "Epoch 12/20\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 38ms/step - loss: 5.5361e-05 - mae: 0.0058 - val_loss: 7.6415e-04 - val_mae: 0.0090\n",
      "Epoch 13/20\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 37ms/step - loss: 5.5436e-05 - mae: 0.0059 - val_loss: 8.0142e-04 - val_mae: 0.0089\n",
      "Epoch 14/20\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 40ms/step - loss: 5.5157e-05 - mae: 0.0058 - val_loss: 7.8790e-04 - val_mae: 0.0094\n",
      "Epoch 15/20\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 45ms/step - loss: 5.4663e-05 - mae: 0.0058 - val_loss: 7.8789e-04 - val_mae: 0.0089\n",
      "Epoch 16/20\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 39ms/step - loss: 5.3934e-05 - mae: 0.0058 - val_loss: 7.3996e-04 - val_mae: 0.0086\n",
      "Epoch 17/20\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 43ms/step - loss: 5.4800e-05 - mae: 0.0058 - val_loss: 7.1160e-04 - val_mae: 0.0085\n",
      "Epoch 18/20\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 41ms/step - loss: 5.4233e-05 - mae: 0.0058 - val_loss: 7.7849e-04 - val_mae: 0.0083\n",
      "Epoch 19/20\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 33ms/step - loss: 5.5067e-05 - mae: 0.0058 - val_loss: 7.3768e-04 - val_mae: 0.0083\n",
      "Epoch 20/20\n",
      "\u001b[1m660/660\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 34ms/step - loss: 5.3399e-05 - mae: 0.0057 - val_loss: 7.5507e-04 - val_mae: 0.0084\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step\n",
      "✅ Done with wheat_Shimoga_daily.csv | MAE=520.19, RMSE=1698.52, R2=-0.11, MAPE=15.74%, Accuracy=84.26%\n",
      "\n",
      "🚀 Processing: wheat_Tumkur_daily.csv\n",
      "Epoch 1/20\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 37ms/step - loss: 0.0014 - mae: 0.0213 - val_loss: 0.0047 - val_mae: 0.0362\n",
      "Epoch 2/20\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 42ms/step - loss: 0.0012 - mae: 0.0192 - val_loss: 0.0039 - val_mae: 0.0281\n",
      "Epoch 3/20\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - loss: 0.0011 - mae: 0.0182 - val_loss: 0.0050 - val_mae: 0.0305\n",
      "Epoch 4/20\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 35ms/step - loss: 0.0011 - mae: 0.0178 - val_loss: 0.0060 - val_mae: 0.0305\n",
      "Epoch 5/20\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 37ms/step - loss: 0.0011 - mae: 0.0174 - val_loss: 0.0070 - val_mae: 0.0297\n",
      "Epoch 6/20\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 44ms/step - loss: 0.0011 - mae: 0.0172 - val_loss: 0.0061 - val_mae: 0.0289\n",
      "Epoch 7/20\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - loss: 0.0011 - mae: 0.0174 - val_loss: 0.0088 - val_mae: 0.0313\n",
      "Epoch 8/20\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 36ms/step - loss: 0.0010 - mae: 0.0169 - val_loss: 0.0139 - val_mae: 0.0355\n",
      "Epoch 9/20\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 42ms/step - loss: 9.9688e-04 - mae: 0.0165 - val_loss: 0.0301 - val_mae: 0.0519\n",
      "Epoch 10/20\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 41ms/step - loss: 0.0010 - mae: 0.0168 - val_loss: 0.0133 - val_mae: 0.0347\n",
      "Epoch 11/20\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 34ms/step - loss: 0.0010 - mae: 0.0162 - val_loss: 0.0258 - val_mae: 0.0439\n",
      "Epoch 12/20\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 9.7904e-04 - mae: 0.0161 - val_loss: 0.0248 - val_mae: 0.0438\n",
      "Epoch 13/20\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 25ms/step - loss: 9.8306e-04 - mae: 0.0161 - val_loss: 0.0328 - val_mae: 0.0496\n",
      "Epoch 14/20\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 25ms/step - loss: 9.7949e-04 - mae: 0.0160 - val_loss: 0.0208 - val_mae: 0.0411\n",
      "Epoch 15/20\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 25ms/step - loss: 9.9350e-04 - mae: 0.0163 - val_loss: 0.0208 - val_mae: 0.0418\n",
      "Epoch 16/20\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 25ms/step - loss: 9.7659e-04 - mae: 0.0162 - val_loss: 0.0229 - val_mae: 0.0433\n",
      "Epoch 17/20\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 25ms/step - loss: 9.9763e-04 - mae: 0.0160 - val_loss: 0.0242 - val_mae: 0.0443\n",
      "Epoch 18/20\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 24ms/step - loss: 9.8087e-04 - mae: 0.0158 - val_loss: 0.0228 - val_mae: 0.0452\n",
      "Epoch 19/20\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - loss: 9.7797e-04 - mae: 0.0160 - val_loss: 0.0230 - val_mae: 0.0431\n",
      "Epoch 20/20\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 20ms/step - loss: 9.8891e-04 - mae: 0.0162 - val_loss: 0.0248 - val_mae: 0.0447\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step\n",
      "✅ Done with wheat_Tumkur_daily.csv | MAE=791.42, RMSE=2787.91, R2=-1.99, MAPE=17.88%, Accuracy=82.12%\n",
      "\n",
      "📊 Metrics saved to gru_output_csv\\gru_metrics.csv\n",
      "\n",
      "🎉 All districts processed successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import joblib\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Dense, Dropout\n",
    "\n",
    "# -----------------------------\n",
    "# Output paths\n",
    "# -----------------------------\n",
    "input_folder = \"dataset\"\n",
    "output_models = \"gru_output_models\"\n",
    "output_csv = \"gru_output_csv\"\n",
    "output_graphs = \"gru_output_graphs\"\n",
    "output_logs = \"gru_output_logs\"\n",
    "metrics_file = os.path.join(output_csv, \"gru_metrics.csv\")\n",
    "\n",
    "os.makedirs(output_models, exist_ok=True)\n",
    "os.makedirs(output_csv, exist_ok=True)\n",
    "os.makedirs(output_graphs, exist_ok=True)\n",
    "os.makedirs(output_logs, exist_ok=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Function to create dataset\n",
    "# -----------------------------\n",
    "def create_dataset(data, look_back=30):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - look_back):\n",
    "        X.append(data[i:i + look_back, 0])\n",
    "        y.append(data[i + look_back, 0])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# -----------------------------\n",
    "# Metrics storage\n",
    "# -----------------------------\n",
    "metrics_list = []\n",
    "\n",
    "# -----------------------------\n",
    "# Process each CSV file\n",
    "# -----------------------------\n",
    "look_back = 30\n",
    "for file in os.listdir(input_folder):\n",
    "    if file.endswith(\".csv\"):\n",
    "        district_name = file.split(\".\")[0]\n",
    "        print(f\"\\n🚀 Processing: {file}\")\n",
    "\n",
    "        df = pd.read_csv(os.path.join(input_folder, file))\n",
    "\n",
    "        df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "        df = df.dropna(subset=['Date'])\n",
    "        df = df.sort_values('Date')\n",
    "\n",
    "        df['Average Price'] = df['Average Price'].fillna(df['Average Price'].mean())\n",
    "\n",
    "        df['MA_7'] = df['Average Price'].rolling(7).mean().fillna(df['Average Price'].mean())\n",
    "        df['MA_30'] = df['Average Price'].rolling(30).mean().fillna(df['Average Price'].mean())\n",
    "\n",
    "        values = df[['Average Price']].values\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        scaled_values = scaler.fit_transform(values)\n",
    "\n",
    "        X, y = create_dataset(scaled_values, look_back)\n",
    "        X = X.reshape((X.shape[0], X.shape[1], 1))\n",
    "\n",
    "        split = int(len(X) * 0.8)\n",
    "        X_train, X_test = X[:split], X[split:]\n",
    "        y_train, y_test = y[:split], y[split:]\n",
    "\n",
    "        model = Sequential([\n",
    "            GRU(64, return_sequences=True, input_shape=(look_back, 1)),\n",
    "            Dropout(0.2),\n",
    "            GRU(32),\n",
    "            Dropout(0.2),\n",
    "            Dense(1)\n",
    "        ])\n",
    "\n",
    "        model.compile(optimizer=\"adam\", loss=\"mse\", metrics=['mae'])\n",
    "\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            epochs=20,\n",
    "            batch_size=16,\n",
    "            validation_data=(X_test, y_test),\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        # Save training log\n",
    "        log_file = os.path.join(output_logs, f\"{district_name}_gru_training.txt\")\n",
    "        with open(log_file, \"w\") as f:\n",
    "            f.write(\"Epoch\\tTrain_Loss\\tVal_Loss\\n\")\n",
    "            for i, (loss, val_loss) in enumerate(zip(history.history['loss'], history.history['val_loss'])):\n",
    "                f.write(f\"{i+1}\\t{loss:.6f}\\t{val_loss:.6f}\\n\")\n",
    "\n",
    "        # Prediction\n",
    "        y_pred_scaled = model.predict(X_test)\n",
    "        y_pred = scaler.inverse_transform(y_pred_scaled)\n",
    "        y_true = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "        y_true_round = np.round(y_true, 2)\n",
    "        y_pred_round = np.round(y_pred, 2)\n",
    "\n",
    "        df_pred = df.iloc[-len(y_true):].copy()\n",
    "        df_pred = df_pred[['Date']].reset_index(drop=True)\n",
    "        df_pred['Actual'] = y_true_round.flatten()\n",
    "        df_pred['Predicted'] = y_pred_round.flatten()\n",
    "        df_pred.to_csv(os.path.join(output_csv, f\"{district_name}_gru_updated.csv\"), index=False)\n",
    "\n",
    "        # -----------------------------\n",
    "        # FIXED METRICS SECTION\n",
    "        # -----------------------------\n",
    "        mae_val = round(mean_absolute_error(y_true, y_pred), 2)\n",
    "        rmse_val = round(np.sqrt(mean_squared_error(y_true, y_pred)), 2)  # FIXED\n",
    "        r2_val = round(r2_score(y_true, y_pred), 2)\n",
    "        mape_val = round(np.mean(np.abs((y_true - y_pred) / y_true)) * 100, 2)\n",
    "        accuracy_val = round(100 - mape_val, 2)\n",
    "\n",
    "        metrics_list.append([district_name, mae_val, rmse_val, r2_val, mape_val, accuracy_val])\n",
    "\n",
    "        print(f\"✅ Done with {file} | MAE={mae_val}, RMSE={rmse_val}, R2={r2_val}, \"\n",
    "              f\"MAPE={mape_val}%, Accuracy={accuracy_val}%\")\n",
    "\n",
    "        joblib.dump(model, os.path.join(output_models, f\"{district_name}_gru_model.pkl\"))\n",
    "\n",
    "        # -----------------------------\n",
    "        # Graph\n",
    "        # -----------------------------\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(df_pred['Date'], df_pred['Actual'], label=\"Actual\", color=\"blue\")\n",
    "        plt.plot(df_pred['Date'], df_pred['Predicted'], label=\"Predicted (GRU)\", color=\"red\", linestyle=\"dashed\")\n",
    "        plt.plot(df['Date'], df['MA_7'], label=\"MA_7\", color=\"orange\")\n",
    "        plt.plot(df['Date'], df['MA_30'], label=\"MA_30\", color=\"green\")\n",
    "        plt.xlabel(\"Date\")\n",
    "        plt.ylabel(\"Average Price\")\n",
    "        plt.title(f\"GRU Predictions - {district_name}\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.savefig(os.path.join(output_graphs, f\"{district_name}_gru_graph.png\"))\n",
    "        plt.close()\n",
    "\n",
    "        # Loss graph\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        plt.plot(history.history['loss'], label='Train Loss')\n",
    "        plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "        plt.title(f\"GRU Training Loss - {district_name}\")\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        plt.savefig(os.path.join(output_graphs, f\"{district_name}_gru_loss.png\"))\n",
    "        plt.close()\n",
    "\n",
    "# Save metrics CSV\n",
    "metrics_df = pd.DataFrame(metrics_list, columns=['District', 'MAE', 'RMSE', 'R2', 'MAPE(%)', 'Accuracy(%)'])\n",
    "metrics_df.to_csv(metrics_file, index=False)\n",
    "\n",
    "print(\"\\n📊 Metrics saved to\", metrics_file)\n",
    "print(\"\\n🎉 All districts processed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96bf9cf-370a-49d4-a78e-00f53e2d60b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
