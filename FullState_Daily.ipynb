{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e2b709-d7b0-4719-b3b2-b5bead9ae4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52362a9a-09f0-409e-8754-f6aeec61b7ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: prophet in c:\\users\\ravik\\appdata\\roaming\\python\\python313\\site-packages (1.2.1)\n",
      "Requirement already satisfied: cmdstanpy>=1.0.4 in c:\\users\\ravik\\appdata\\roaming\\python\\python313\\site-packages (from prophet) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.15.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from prophet) (2.1.3)\n",
      "Requirement already satisfied: matplotlib>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from prophet) (3.10.0)\n",
      "Requirement already satisfied: pandas>=1.0.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from prophet) (2.2.3)\n",
      "Requirement already satisfied: holidays<1,>=0.25 in c:\\users\\ravik\\appdata\\roaming\\python\\python313\\site-packages (from prophet) (0.85)\n",
      "Requirement already satisfied: tqdm>=4.36.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from prophet) (4.67.1)\n",
      "Requirement already satisfied: importlib_resources in c:\\users\\ravik\\appdata\\roaming\\python\\python313\\site-packages (from prophet) (6.5.2)\n",
      "Requirement already satisfied: python-dateutil in c:\\programdata\\anaconda3\\lib\\site-packages (from holidays<1,>=0.25->prophet) (2.9.0.post0)\n",
      "Requirement already satisfied: stanio<2.0.0,>=0.4.0 in c:\\users\\ravik\\appdata\\roaming\\python\\python313\\site-packages (from cmdstanpy>=1.0.4->prophet) (0.5.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (3.2.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=1.0.4->prophet) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=1.0.4->prophet) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil->holidays<1,>=0.25->prophet) (1.17.0)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm>=4.36.1->prophet) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02a43c8a-b02c-4c54-9346-9be64a4bf5fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Loading dataset: dataset/Crop_price_forecast_Daily.xlsx\n",
      "\n",
      "ğŸš€ Processing: District = All Districts | Crop = full_state\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:18:54 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:19:02 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All Districts - full_state | MAE=148.73, RMSE=199.35, RÂ²=0.8766, MAPE=7.89%, Accuracy=92.11%\n",
      "\n",
      "ğŸš€ Processing: District = Bagalkot | Crop = onion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:19:07 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:19:13 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Bagalkot - onion | MAE=378.66, RMSE=550.26, RÂ²=0.4212, MAPE=36.42%, Accuracy=63.58%\n",
      "\n",
      "ğŸš€ Processing: District = Bagalkot | Crop = wheat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:19:18 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:19:21 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Bagalkot - wheat | MAE=150.28, RMSE=275.75, RÂ²=0.7021, MAPE=6.67%, Accuracy=93.33%\n",
      "\n",
      "ğŸš€ Processing: District = Bangalore | Crop = capsicum\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:19:27 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:19:30 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Bangalore - capsicum | MAE=551.75, RMSE=749.05, RÂ²=0.4753, MAPE=22.02%, Accuracy=77.98%\n",
      "\n",
      "ğŸš€ Processing: District = Bangalore | Crop = onion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:19:36 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:19:41 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Bangalore - onion | MAE=400.05, RMSE=576.98, RÂ²=0.5775, MAPE=23.64%, Accuracy=76.36%\n",
      "\n",
      "ğŸš€ Processing: District = Bangalore | Crop = tomato\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:19:47 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:19:50 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Bangalore - tomato | MAE=669.81, RMSE=992.52, RÂ²=0.3106, MAPE=52.76%, Accuracy=47.24%\n",
      "\n",
      "ğŸš€ Processing: District = Bangalore | Crop = wheat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:19:55 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:20:02 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Bangalore - wheat | MAE=84.09, RMSE=187.41, RÂ²=0.8934, MAPE=3.31%, Accuracy=96.69%\n",
      "\n",
      "ğŸš€ Processing: District = Belgaum | Crop = capsicum\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:20:08 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:20:08 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Belgaum - capsicum | MAE=440.84, RMSE=603.17, RÂ²=0.4214, MAPE=15.35%, Accuracy=84.65%\n",
      "\n",
      "ğŸš€ Processing: District = Belgaum | Crop = onion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:20:11 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:20:19 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Belgaum - onion | MAE=431.06, RMSE=689.9, RÂ²=0.5469, MAPE=31.56%, Accuracy=68.44%\n",
      "\n",
      "ğŸš€ Processing: District = Belgaum | Crop = tomato\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:20:25 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:20:28 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Belgaum - tomato | MAE=378.82, RMSE=717.06, RÂ²=0.5929, MAPE=21.3%, Accuracy=78.7%\n",
      "\n",
      "ğŸš€ Processing: District = Belgaum | Crop = wheat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:20:34 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:20:42 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Belgaum - wheat | MAE=63.57, RMSE=82.51, RÂ²=0.9746, MAPE=2.99%, Accuracy=97.01%\n",
      "\n",
      "ğŸš€ Processing: District = Bellary | Crop = capsicum\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:20:48 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:20:52 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Bellary - capsicum | MAE=45.8, RMSE=118.68, RÂ²=0.4521, MAPE=2.32%, Accuracy=97.68%\n",
      "\n",
      "ğŸš€ Processing: District = Bellary | Crop = onion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:20:56 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:21:02 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Bellary - onion | MAE=237.41, RMSE=363.13, RÂ²=0.5648, MAPE=19.37%, Accuracy=80.63%\n",
      "\n",
      "ğŸš€ Processing: District = Bellary | Crop = tomato\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:21:08 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:21:09 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Bellary - tomato | MAE=326.94, RMSE=548.41, RÂ²=0.2286, MAPE=43.6%, Accuracy=56.4%\n",
      "\n",
      "ğŸš€ Processing: District = Bellary | Crop = wheat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:21:15 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:21:18 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Bellary - wheat | MAE=184.07, RMSE=359.21, RÂ²=0.6576, MAPE=8.34%, Accuracy=91.66%\n",
      "\n",
      "ğŸš€ Processing: District = Bidar | Crop = onion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:21:23 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:21:26 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Bidar - onion | MAE=97.57, RMSE=198.92, RÂ²=0.7085, MAPE=7.58%, Accuracy=92.42%\n",
      "\n",
      "ğŸš€ Processing: District = Bidar | Crop = wheat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:21:32 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:21:39 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Bidar - wheat | MAE=115.18, RMSE=163.88, RÂ²=0.9005, MAPE=5.25%, Accuracy=94.75%\n",
      "\n",
      "ğŸš€ Processing: District = Bijapur | Crop = onion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:21:45 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:21:52 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Bijapur - onion | MAE=296.21, RMSE=478.88, RÂ²=0.521, MAPE=24.55%, Accuracy=75.45%\n",
      "\n",
      "ğŸš€ Processing: District = Bijapur | Crop = wheat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:21:57 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:22:05 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Bijapur - wheat | MAE=165.38, RMSE=225.42, RÂ²=0.8927, MAPE=7.42%, Accuracy=92.58%\n",
      "\n",
      "ğŸš€ Processing: District = Chamrajnagar | Crop = onion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:22:11 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:22:15 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Chamrajnagar - onion | MAE=346.38, RMSE=537.59, RÂ²=0.7603, MAPE=22.36%, Accuracy=77.64%\n",
      "\n",
      "ğŸš€ Processing: District = Chamrajnagar | Crop = tomato\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:22:20 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:22:26 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Chamrajnagar - tomato | MAE=328.88, RMSE=603.65, RÂ²=0.6823, MAPE=25.26%, Accuracy=74.74%\n",
      "\n",
      "ğŸš€ Processing: District = Chamrajnagar | Crop = wheat\n",
      "âš ï¸ Chamrajnagar - wheat: Not enough data. Using crop-level average instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:22:32 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:22:41 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Chamrajnagar - wheat | MAE=29.46, RMSE=50.09, RÂ²=0.9902, MAPE=1.32%, Accuracy=98.68%\n",
      "\n",
      "ğŸš€ Processing: District = Chikmagalur | Crop = capsicum\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:22:47 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:22:48 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Chikmagalur - capsicum | MAE=164.32, RMSE=243.45, RÂ²=0.837, MAPE=9.84%, Accuracy=90.16%\n",
      "\n",
      "ğŸš€ Processing: District = Chikmagalur | Crop = onion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:22:51 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:22:57 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Chikmagalur - onion | MAE=282.02, RMSE=370.75, RÂ²=0.7299, MAPE=18.08%, Accuracy=81.92%\n",
      "\n",
      "ğŸš€ Processing: District = Chikmagalur | Crop = tomato\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:23:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:23:06 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Chikmagalur - tomato | MAE=324.25, RMSE=485.11, RÂ²=0.5427, MAPE=32.46%, Accuracy=67.54%\n",
      "\n",
      "ğŸš€ Processing: District = Chikmagalur | Crop = wheat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:23:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:23:22 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Chikmagalur - wheat | MAE=45.24, RMSE=68.23, RÂ²=0.9804, MAPE=2.42%, Accuracy=97.58%\n",
      "\n",
      "ğŸš€ Processing: District = Chitradurga | Crop = onion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:23:28 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:23:38 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Chitradurga - onion | MAE=84.14, RMSE=150.27, RÂ²=0.8945, MAPE=5.95%, Accuracy=94.05%\n",
      "\n",
      "ğŸš€ Processing: District = Chitradurga | Crop = tomato\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:23:44 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:23:53 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Chitradurga - tomato | MAE=41.91, RMSE=71.53, RÂ²=0.9951, MAPE=4.34%, Accuracy=95.66%\n",
      "\n",
      "ğŸš€ Processing: District = Chitradurga | Crop = wheat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:23:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:24:08 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Chitradurga - wheat | MAE=27.55, RMSE=47.33, RÂ²=0.9933, MAPE=1.26%, Accuracy=98.74%\n",
      "\n",
      "ğŸš€ Processing: District = Davangere | Crop = capsicum\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:24:13 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:24:17 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Davangere - capsicum | MAE=795.86, RMSE=1130.34, RÂ²=0.5776, MAPE=26.11%, Accuracy=73.89%\n",
      "\n",
      "ğŸš€ Processing: District = Davangere | Crop = onion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:24:22 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:24:34 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Davangere - onion | MAE=279.47, RMSE=453.81, RÂ²=0.607, MAPE=25.46%, Accuracy=74.54%\n",
      "\n",
      "ğŸš€ Processing: District = Davangere | Crop = tomato\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:24:40 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:24:42 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Davangere - tomato | MAE=509.04, RMSE=783.97, RÂ²=0.3766, MAPE=56.56%, Accuracy=43.44%\n",
      "\n",
      "ğŸš€ Processing: District = Davangere | Crop = wheat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:24:48 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:25:00 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Davangere - wheat | MAE=47.99, RMSE=90.84, RÂ²=0.9698, MAPE=2.31%, Accuracy=97.69%\n",
      "\n",
      "ğŸš€ Processing: District = Dharwad | Crop = capsicum\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:25:05 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:25:05 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Dharwad - capsicum | MAE=224.53, RMSE=350.04, RÂ²=0.9015, MAPE=9.33%, Accuracy=90.67%\n",
      "\n",
      "ğŸš€ Processing: District = Dharwad | Crop = onion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:25:07 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:25:11 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Dharwad - onion | MAE=341.3, RMSE=494.87, RÂ²=0.5821, MAPE=30.24%, Accuracy=69.76%\n",
      "\n",
      "ğŸš€ Processing: District = Dharwad | Crop = tomato\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:25:14 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:25:15 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Dharwad - tomato | MAE=340.21, RMSE=574.57, RÂ²=0.5191, MAPE=19.48%, Accuracy=80.52%\n",
      "\n",
      "ğŸš€ Processing: District = Dharwad | Crop = wheat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:25:16 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:25:21 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Dharwad - wheat | MAE=100.06, RMSE=140.08, RÂ²=0.9106, MAPE=5.06%, Accuracy=94.94%\n",
      "\n",
      "ğŸš€ Processing: District = Gadag | Crop = onion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:25:24 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:25:29 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Gadag - onion | MAE=256.71, RMSE=366.67, RÂ²=0.6704, MAPE=22.92%, Accuracy=77.08%\n",
      "\n",
      "ğŸš€ Processing: District = Gadag | Crop = tomato\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:25:32 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:25:33 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Gadag - tomato | MAE=265.44, RMSE=463.17, RÂ²=0.9541, MAPE=7.07%, Accuracy=92.93%\n",
      "\n",
      "ğŸš€ Processing: District = Gadag | Crop = wheat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:25:34 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:25:37 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Gadag - wheat | MAE=119.87, RMSE=184.81, RÂ²=0.8816, MAPE=5.8%, Accuracy=94.2%\n",
      "\n",
      "ğŸš€ Processing: District = Hassan | Crop = capsicum\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:25:40 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:25:44 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Hassan - capsicum | MAE=294.4, RMSE=392.06, RÂ²=0.805, MAPE=17.28%, Accuracy=82.72%\n",
      "\n",
      "ğŸš€ Processing: District = Hassan | Crop = onion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:25:47 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:25:51 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Hassan - onion | MAE=280.06, RMSE=415.29, RÂ²=0.5912, MAPE=19.46%, Accuracy=80.54%\n",
      "\n",
      "ğŸš€ Processing: District = Hassan | Crop = tomato\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:25:54 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:25:56 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Hassan - tomato | MAE=303.29, RMSE=505.12, RÂ²=0.5976, MAPE=23.09%, Accuracy=76.91%\n",
      "\n",
      "ğŸš€ Processing: District = Hassan | Crop = wheat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:25:59 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:26:03 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Hassan - wheat | MAE=111.31, RMSE=241.9, RÂ²=0.8507, MAPE=5.09%, Accuracy=94.91%\n",
      "\n",
      "ğŸš€ Processing: District = Haveri | Crop = capsicum\n",
      "âš ï¸ Haveri - capsicum: Not enough data. Using crop-level average instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:26:06 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:26:09 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Haveri - capsicum | MAE=296.63, RMSE=380.2, RÂ²=0.7287, MAPE=12.78%, Accuracy=87.22%\n",
      "\n",
      "ğŸš€ Processing: District = Haveri | Crop = onion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:26:13 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:26:15 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Haveri - onion | MAE=248.7, RMSE=362.6, RÂ²=0.6478, MAPE=18.51%, Accuracy=81.49%\n",
      "\n",
      "ğŸš€ Processing: District = Haveri | Crop = tomato\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:26:18 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:26:19 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Haveri - tomato | MAE=367.24, RMSE=523.9, RÂ²=0.9506, MAPE=30.28%, Accuracy=69.72%\n",
      "\n",
      "ğŸš€ Processing: District = Haveri | Crop = wheat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:26:21 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:26:27 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Haveri - wheat | MAE=60.81, RMSE=85.14, RÂ²=0.9438, MAPE=3.12%, Accuracy=96.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:26:30 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ Processing: District = Kalburgi | Crop = capsicum\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:26:30 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Kalburgi - capsicum | MAE=429.49, RMSE=610.32, RÂ²=0.7662, MAPE=27.29%, Accuracy=72.71%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:26:31 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ Processing: District = Kalburgi | Crop = onion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:26:32 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Kalburgi - onion | MAE=300.09, RMSE=424.97, RÂ²=0.6371, MAPE=20.35%, Accuracy=79.65%\n",
      "\n",
      "ğŸš€ Processing: District = Kalburgi | Crop = tomato\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:26:33 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:26:33 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Kalburgi - tomato | MAE=873.24, RMSE=1248.12, RÂ²=0.5061, MAPE=72.34%, Accuracy=27.66%\n",
      "\n",
      "ğŸš€ Processing: District = Kalburgi | Crop = wheat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:26:35 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:26:41 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Kalburgi - wheat | MAE=72.12, RMSE=135.08, RÂ²=0.9023, MAPE=2.95%, Accuracy=97.05%\n",
      "\n",
      "ğŸš€ Processing: District = Karwar(Uttar Kannad) | Crop = onion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:26:44 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:26:45 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Karwar(Uttar Kannad) - onion | MAE=172.38, RMSE=224.8, RÂ²=0.9679, MAPE=12.38%, Accuracy=87.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:26:46 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ Processing: District = Karwar(Uttar Kannad) | Crop = tomato\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:26:46 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Karwar(Uttar Kannad) - tomato | MAE=153.8, RMSE=217.55, RÂ²=0.9187, MAPE=14.75%, Accuracy=85.25%\n",
      "\n",
      "ğŸš€ Processing: District = Karwar(Uttar Kannad) | Crop = wheat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:26:47 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:26:48 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Karwar(Uttar Kannad) - wheat | MAE=29.48, RMSE=42.91, RÂ²=0.9297, MAPE=1.85%, Accuracy=98.15%\n",
      "\n",
      "ğŸš€ Processing: District = Kolar | Crop = capsicum\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:26:50 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:26:52 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Kolar - capsicum | MAE=437.68, RMSE=586.51, RÂ²=0.6395, MAPE=20.9%, Accuracy=79.1%\n",
      "\n",
      "ğŸš€ Processing: District = Kolar | Crop = onion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:26:56 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:26:58 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Kolar - onion | MAE=335.35, RMSE=470.3, RÂ²=0.7231, MAPE=20.83%, Accuracy=79.17%\n",
      "\n",
      "ğŸš€ Processing: District = Kolar | Crop = tomato\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:27:01 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:27:04 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Kolar - tomato | MAE=411.5, RMSE=608.31, RÂ²=0.3732, MAPE=42.78%, Accuracy=57.22%\n",
      "\n",
      "ğŸš€ Processing: District = Kolar | Crop = wheat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:27:07 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:27:14 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Kolar - wheat | MAE=60.46, RMSE=94.18, RÂ²=0.9687, MAPE=2.78%, Accuracy=97.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:27:16 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ Processing: District = Koppal | Crop = onion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:27:17 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Koppal - onion | MAE=246.96, RMSE=379.37, RÂ²=0.8991, MAPE=16.64%, Accuracy=83.36%\n",
      "\n",
      "ğŸš€ Processing: District = Koppal | Crop = tomato\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:27:18 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:27:18 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Koppal - tomato | MAE=306.59, RMSE=565.61, RÂ²=0.9118, MAPE=18.69%, Accuracy=81.31%\n",
      "\n",
      "ğŸš€ Processing: District = Koppal | Crop = wheat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:27:19 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:27:24 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Koppal - wheat | MAE=54.51, RMSE=84.92, RÂ²=0.956, MAPE=3.02%, Accuracy=96.98%\n",
      "\n",
      "ğŸš€ Processing: District = Madikeri(Kodagu) | Crop = onion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:27:27 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:27:32 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Madikeri(Kodagu) - onion | MAE=48.72, RMSE=86.22, RÂ²=0.969, MAPE=4.25%, Accuracy=95.75%\n",
      "\n",
      "ğŸš€ Processing: District = Madikeri(Kodagu) | Crop = tomato\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:27:35 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:27:38 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Madikeri(Kodagu) - tomato | MAE=34.66, RMSE=53.19, RÂ²=0.968, MAPE=3.93%, Accuracy=96.07%\n",
      "\n",
      "ğŸš€ Processing: District = Madikeri(Kodagu) | Crop = wheat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:27:41 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:27:44 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Madikeri(Kodagu) - wheat | MAE=539.72, RMSE=1257.4, RÂ²=0.9514, MAPE=31.01%, Accuracy=68.99%\n",
      "\n",
      "ğŸš€ Processing: District = Mandya | Crop = capsicum\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:27:47 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:27:52 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Mandya - capsicum | MAE=212.76, RMSE=306.8, RÂ²=0.913, MAPE=15.09%, Accuracy=84.91%\n",
      "\n",
      "ğŸš€ Processing: District = Mandya | Crop = onion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:27:55 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:28:00 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Mandya - onion | MAE=157.01, RMSE=247.18, RÂ²=0.7547, MAPE=10.71%, Accuracy=89.29%\n",
      "\n",
      "ğŸš€ Processing: District = Mandya | Crop = tomato\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:28:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:28:04 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Mandya - tomato | MAE=277.07, RMSE=566.79, RÂ²=0.4829, MAPE=29.57%, Accuracy=70.43%\n",
      "\n",
      "ğŸš€ Processing: District = Mandya | Crop = wheat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:28:08 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:28:12 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Mandya - wheat | MAE=24.12, RMSE=40.25, RÂ²=0.9839, MAPE=1.08%, Accuracy=98.92%\n",
      "\n",
      "ğŸš€ Processing: District = Mangalore(Dakshin Kannad) | Crop = onion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:28:14 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:28:17 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Mangalore(Dakshin Kannad) - onion | MAE=270.76, RMSE=412.31, RÂ²=0.7879, MAPE=14.69%, Accuracy=85.31%\n",
      "\n",
      "ğŸš€ Processing: District = Mangalore(Dakshin Kannad) | Crop = tomato\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:28:20 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:28:20 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Mangalore(Dakshin Kannad) - tomato | MAE=580.25, RMSE=716.43, RÂ²=0.6503, MAPE=32.23%, Accuracy=67.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:28:21 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ Processing: District = Mangalore(Dakshin Kannad) | Crop = wheat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:28:22 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Mangalore(Dakshin Kannad) - wheat | MAE=32.8, RMSE=70.38, RÂ²=0.9879, MAPE=1.37%, Accuracy=98.63%\n",
      "\n",
      "ğŸš€ Processing: District = Mysore | Crop = capsicum\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:28:23 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:28:26 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Mysore - capsicum | MAE=446.55, RMSE=585.89, RÂ²=0.699, MAPE=18.41%, Accuracy=81.59%\n",
      "\n",
      "ğŸš€ Processing: District = Mysore | Crop = onion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:28:28 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:28:31 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Mysore - onion | MAE=230.73, RMSE=345.57, RÂ²=0.7323, MAPE=13.41%, Accuracy=86.59%\n",
      "\n",
      "ğŸš€ Processing: District = Mysore | Crop = tomato\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:28:34 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:28:36 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Mysore - tomato | MAE=259.8, RMSE=378.21, RÂ²=0.593, MAPE=21.34%, Accuracy=78.66%\n",
      "\n",
      "ğŸš€ Processing: District = Mysore | Crop = wheat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:28:39 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:28:42 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Mysore - wheat | MAE=144.37, RMSE=673.33, RÂ²=0.5611, MAPE=5.44%, Accuracy=94.56%\n",
      "\n",
      "ğŸš€ Processing: District = Raichur | Crop = onion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:28:45 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:28:50 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Raichur - onion | MAE=327.33, RMSE=481.9, RÂ²=0.6305, MAPE=30.31%, Accuracy=69.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:28:53 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ Processing: District = Raichur | Crop = tomato\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:28:53 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Raichur - tomato | MAE=2.94, RMSE=4.86, RÂ²=0.9999, MAPE=0.54%, Accuracy=99.46%\n",
      "\n",
      "ğŸš€ Processing: District = Raichur | Crop = wheat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:28:55 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:28:59 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Raichur - wheat | MAE=56.02, RMSE=84.58, RÂ²=0.9484, MAPE=3.09%, Accuracy=96.91%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:29:02 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ Processing: District = Shimoga | Crop = capsicum\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:29:02 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Shimoga - capsicum | MAE=0.25, RMSE=0.43, RÂ²=1.0, MAPE=0.02%, Accuracy=99.98%\n",
      "\n",
      "ğŸš€ Processing: District = Shimoga | Crop = onion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:29:04 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:29:06 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Shimoga - onion | MAE=339.75, RMSE=516.96, RÂ²=0.6895, MAPE=70.82%, Accuracy=29.18%\n",
      "\n",
      "ğŸš€ Processing: District = Shimoga | Crop = tomato\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:29:10 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:29:12 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Shimoga - tomato | MAE=490.67, RMSE=840.33, RÂ²=0.33, MAPE=86.3%, Accuracy=13.7%\n",
      "\n",
      "ğŸš€ Processing: District = Shimoga | Crop = wheat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:29:15 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:29:17 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Shimoga - wheat | MAE=123.16, RMSE=531.28, RÂ²=0.4148, MAPE=4.71%, Accuracy=95.29%\n",
      "\n",
      "ğŸš€ Processing: District = Tumkur | Crop = onion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:29:20 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:29:24 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Tumkur - onion | MAE=338.99, RMSE=575.53, RÂ²=0.8989, MAPE=12.38%, Accuracy=87.62%\n",
      "\n",
      "ğŸš€ Processing: District = Tumkur | Crop = tomato\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:29:27 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:29:32 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Tumkur - tomato | MAE=251.28, RMSE=416.54, RÂ²=0.9198, MAPE=27.15%, Accuracy=72.85%\n",
      "\n",
      "ğŸš€ Processing: District = Tumkur | Crop = wheat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:29:35 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:29:38 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Tumkur - wheat | MAE=196.96, RMSE=471.28, RÂ²=0.6466, MAPE=6.92%, Accuracy=93.08%\n",
      "\n",
      "ğŸš€ Processing: District = Udupi | Crop = capsicum\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:29:41 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:29:43 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Udupi - capsicum | MAE=495.26, RMSE=734.73, RÂ²=0.7585, MAPE=14.58%, Accuracy=85.42%\n",
      "\n",
      "ğŸš€ Processing: District = Udupi | Crop = onion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:29:46 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:29:49 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Udupi - onion | MAE=581.35, RMSE=870.86, RÂ²=0.549, MAPE=28.82%, Accuracy=71.18%\n",
      "\n",
      "ğŸš€ Processing: District = Udupi | Crop = tomato\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:29:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "00:29:54 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Udupi - tomato | MAE=697.79, RMSE=1052.64, RÂ²=0.3508, MAPE=42.36%, Accuracy=57.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:29:57 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ Processing: District = Udupi | Crop = wheat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:29:58 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Udupi - wheat | MAE=0.37, RMSE=0.84, RÂ²=1.0, MAPE=0.02%, Accuracy=99.98%\n",
      "\n",
      "ğŸ“Š All combinations processed successfully!\n",
      "âœ… Metrics saved to: prophet_state_all_output\\prophet_all_metrics.csv\n",
      "         District        Crop     MAE     RMSE    R2  MAPE(%)  Accuracy(%)\n",
      "0   All Districts  full_state  148.73   199.35  0.88     7.89        92.11\n",
      "1        Bagalkot       onion  378.66   550.26  0.42    36.42        63.58\n",
      "2        Bagalkot       wheat  150.28   275.75  0.70     6.67        93.33\n",
      "3       Bangalore    capsicum  551.75   749.05  0.48    22.02        77.98\n",
      "4       Bangalore       onion  400.05   576.98  0.58    23.64        76.36\n",
      "..            ...         ...     ...      ...   ...      ...          ...\n",
      "85         Tumkur       wheat  196.96   471.28  0.65     6.92        93.08\n",
      "86          Udupi    capsicum  495.26   734.73  0.76    14.58        85.42\n",
      "87          Udupi       onion  581.35   870.86  0.55    28.82        71.18\n",
      "88          Udupi      tomato  697.79  1052.64  0.35    42.36        57.64\n",
      "89          Udupi       wheat    0.37     0.84  1.00     0.02        99.98\n",
      "\n",
      "[90 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from prophet import Prophet\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# ==========================================================\n",
    "# ğŸ“‚ Paths and Setup\n",
    "# ==========================================================\n",
    "input_file = \"dataset/Crop_price_forecast_Daily.xlsx\"\n",
    "output_folder = \"prophet_state_all_output\"\n",
    "output_csv = os.path.join(output_folder, \"prophet_all_predictions\")\n",
    "output_graphs = os.path.join(output_folder, \"prophet_all_graphs\")\n",
    "future_forecast_csv = os.path.join(output_folder, \"prophet_future_forecasts\")\n",
    "metrics_file = os.path.join(output_folder, \"prophet_all_metrics.csv\")\n",
    "\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "os.makedirs(output_csv, exist_ok=True)\n",
    "os.makedirs(output_graphs, exist_ok=True)\n",
    "os.makedirs(future_forecast_csv, exist_ok=True)\n",
    "\n",
    "# ==========================================================\n",
    "# ğŸ§® Helper Functions\n",
    "# ==========================================================\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    mask = y_true != 0\n",
    "    return np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100 if np.any(mask) else np.nan\n",
    "\n",
    "def parse_dates_safe(series):\n",
    "    try:\n",
    "        return pd.to_datetime(series, dayfirst=True)\n",
    "    except:\n",
    "        return pd.to_datetime(series, dayfirst=False)\n",
    "\n",
    "# ==========================================================\n",
    "# ğŸ“˜ Load Dataset\n",
    "# ==========================================================\n",
    "print(f\"ğŸ“˜ Loading dataset: {input_file}\")\n",
    "df = pd.read_excel(input_file)\n",
    "df.columns = [col.strip().lower() for col in df.columns]\n",
    "\n",
    "required_cols = ['date', 'district', 'crop_type', 'average']\n",
    "if not all(col in df.columns for col in required_cols):\n",
    "    raise ValueError(f\"âŒ Missing required columns: {required_cols}\")\n",
    "\n",
    "df['date'] = parse_dates_safe(df['date'])\n",
    "df = df.sort_values('date')\n",
    "df = df.dropna(subset=['average'])\n",
    "\n",
    "# ==========================================================\n",
    "# ğŸ“Š Metrics Storage\n",
    "# ==========================================================\n",
    "metrics_list = []\n",
    "\n",
    "# ==========================================================\n",
    "# ğŸ” Prophet per (District Ã— Crop)\n",
    "# ==========================================================\n",
    "groups = df.groupby(['district', 'crop_type'])\n",
    "\n",
    "for (district, crop), group in groups:\n",
    "    print(f\"\\nğŸš€ Processing: District = {district} | Crop = {crop}\")\n",
    "\n",
    "    data = group.copy().sort_values('date')\n",
    "    data = data.groupby('date', as_index=False).mean(numeric_only=True)\n",
    "    data.set_index('date', inplace=True)\n",
    "    data = data.asfreq('D')\n",
    "\n",
    "    # Fill missing values\n",
    "    data['average'] = data['average'].ffill().bfill().fillna(data['average'].mean())\n",
    "\n",
    "    # âœ… If too few data points, replace with crop-level average across districts\n",
    "    if data['average'].count() < 2:\n",
    "        print(f\"âš ï¸ {district} - {crop}: Not enough data. Using crop-level average instead.\")\n",
    "        crop_level = df[df['crop_type'] == crop].groupby('date', as_index=False)['average'].mean()\n",
    "        if crop_level.empty:\n",
    "            print(f\"âš ï¸ {district} - {crop}: No crop-level data found. Using overall average instead.\")\n",
    "            crop_level = df.groupby('date', as_index=False)['average'].mean()\n",
    "        crop_level.set_index('date', inplace=True)\n",
    "        crop_level = crop_level.asfreq('D')\n",
    "        crop_level['average'] = crop_level['average'].ffill().bfill().fillna(crop_level['average'].mean())\n",
    "        data = crop_level.copy()\n",
    "\n",
    "    # ==========================================================\n",
    "    # ğŸ§© Feature Engineering\n",
    "    # ==========================================================\n",
    "    data['Lag_1'] = data['average'].shift(1)\n",
    "    data['Lag_7'] = data['average'].shift(7)\n",
    "    data['MA_7'] = data['average'].rolling(window=7).mean()\n",
    "    data['MA_30'] = data['average'].rolling(window=30).mean()\n",
    "    data[['Lag_1', 'Lag_7', 'MA_7', 'MA_30']] = data[['Lag_1', 'Lag_7', 'MA_7', 'MA_30']].bfill().ffill()\n",
    "\n",
    "    # ==========================================================\n",
    "    # ğŸ¤– Prophet Model Preparation\n",
    "    # ==========================================================\n",
    "    prophet_df = data.reset_index()[['date', 'average']].rename(columns={'date': 'ds', 'average': 'y'})\n",
    "\n",
    "    model = Prophet(\n",
    "        yearly_seasonality=True,\n",
    "        weekly_seasonality=True,\n",
    "        daily_seasonality=False,\n",
    "        seasonality_mode='additive'\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        model.fit(prophet_df)\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Skipping {district} - {crop} due to Prophet fit error: {e}\")\n",
    "        continue\n",
    "\n",
    "    # ==========================================================\n",
    "    # ğŸ“… Forecast (Historical + Future)\n",
    "    # ==========================================================\n",
    "    forecast = model.predict(model.make_future_dataframe(periods=0, freq='D'))\n",
    "\n",
    "    merged = prophet_df.merge(forecast[['ds', 'yhat']], on='ds', how='left')\n",
    "    merged.rename(columns={'y': 'Actual', 'yhat': 'Predicted'}, inplace=True)\n",
    "    merged['District'] = district\n",
    "    merged['Crop'] = crop\n",
    "    merged[['Actual', 'Predicted']] = merged[['Actual', 'Predicted']].round(2)\n",
    "\n",
    "    # ==========================================================\n",
    "    # ğŸ“ˆ Metrics Calculation\n",
    "    # ==========================================================\n",
    "    y_true = merged['Actual'].values\n",
    "    y_pred = merged['Predicted'].values\n",
    "    mae = round(mean_absolute_error(y_true, y_pred), 2)\n",
    "    rmse = round(np.sqrt(mean_squared_error(y_true, y_pred)), 2)\n",
    "    r2 = round(r2_score(y_true, y_pred), 4)\n",
    "    mape = round(mean_absolute_percentage_error(y_true, y_pred), 2)\n",
    "    accuracy = round(100 - mape, 2)\n",
    "\n",
    "    metrics_list.append({\n",
    "        'District': district,\n",
    "        'Crop': crop,\n",
    "        'MAE': mae,\n",
    "        'RMSE': rmse,\n",
    "        'R2': r2,\n",
    "        'MAPE(%)': mape,\n",
    "        'Accuracy(%)': accuracy\n",
    "    })\n",
    "\n",
    "    print(f\"âœ… {district} - {crop} | MAE={mae}, RMSE={rmse}, RÂ²={r2}, MAPE={mape}%, Accuracy={accuracy}%\")\n",
    "\n",
    "    # ==========================================================\n",
    "    # ğŸ’¾ Save Historical Predictions\n",
    "    # ==========================================================\n",
    "    merged.to_csv(os.path.join(output_csv, f\"{district}_{crop}_prophet_daily.csv\"), index=False, float_format='%.2f')\n",
    "\n",
    "    # ==========================================================\n",
    "    # ğŸ”® Generate Future Forecast (30 Days)\n",
    "    # ==========================================================\n",
    "    future_periods = 30\n",
    "    future_df = model.make_future_dataframe(periods=future_periods, freq='D')\n",
    "    future_forecast = model.predict(future_df)\n",
    "\n",
    "    future_forecast = future_forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail(future_periods)\n",
    "    future_forecast[['yhat', 'yhat_lower', 'yhat_upper']] = future_forecast[['yhat', 'yhat_lower', 'yhat_upper']].round(2)\n",
    "    future_forecast['District'] = district\n",
    "    future_forecast['Crop'] = crop\n",
    "\n",
    "    future_forecast.to_csv(os.path.join(future_forecast_csv, f\"{district}_{crop}_future_forecast.csv\"), index=False)\n",
    "\n",
    "    # ==========================================================\n",
    "    # ğŸ“Š Save Graph (Historical + Future)\n",
    "    # ==========================================================\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.plot(merged['ds'], merged['Actual'], label='Actual', color='blue')\n",
    "    plt.plot(merged['ds'], merged['Predicted'], label='Predicted (Prophet)', color='red', linestyle='dashed')\n",
    "    plt.plot(future_forecast['ds'], future_forecast['yhat'], label='Future Forecast (30 days)', color='green', linestyle='dotted')\n",
    "    plt.title(f\"Prophet Forecast - {district} | {crop}\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Average Price\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_graphs, f\"{district}_{crop}_prophet_graph.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    del data, prophet_df, merged, model, forecast\n",
    "    gc.collect()\n",
    "\n",
    "# ==========================================================\n",
    "# ğŸ§¾ Save Metrics Summary\n",
    "# ==========================================================\n",
    "metrics_df = pd.DataFrame(metrics_list).round(2)\n",
    "metrics_df.to_csv(metrics_file, index=False)\n",
    "print(f\"\\nğŸ“Š All combinations processed successfully!\")\n",
    "print(f\"âœ… Metrics saved to: {metrics_file}\")\n",
    "print(metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd44c2f0-7cef-44da-9b66-1433cfb6a287",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "350c9378-6f4a-43ab-85da-952635ae6fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Loading dataset: dataset/Crop_price_forecast_Daily.xlsx\n",
      "\n",
      "ğŸš€ Processing: District = All Districts | Crop = full_state\n",
      "âœ… All Districts - full_state | MAE=14.15, RMSE=28.28, RÂ²=0.9975, MAPE=0.73%, Accuracy=99.27%\n",
      "\n",
      "ğŸš€ Processing: District = Bagalkot | Crop = onion\n",
      "âœ… Bagalkot - onion | MAE=13.61, RMSE=51.73, RÂ²=0.9949, MAPE=1.06%, Accuracy=98.94%\n",
      "\n",
      "ğŸš€ Processing: District = Bagalkot | Crop = wheat\n",
      "âœ… Bagalkot - wheat | MAE=10.82, RMSE=56.97, RÂ²=0.9873, MAPE=0.51%, Accuracy=99.49%\n",
      "\n",
      "ğŸš€ Processing: District = Bangalore | Crop = capsicum\n",
      "âœ… Bangalore - capsicum | MAE=117.4, RMSE=214.75, RÂ²=0.9569, MAPE=4.14%, Accuracy=95.86%\n",
      "\n",
      "ğŸš€ Processing: District = Bangalore | Crop = onion\n",
      "âœ… Bangalore - onion | MAE=33.52, RMSE=93.61, RÂ²=0.9889, MAPE=1.71%, Accuracy=98.29%\n",
      "\n",
      "ğŸš€ Processing: District = Bangalore | Crop = tomato\n",
      "âœ… Bangalore - tomato | MAE=76.43, RMSE=165.0, RÂ²=0.9809, MAPE=4.82%, Accuracy=95.18%\n",
      "\n",
      "ğŸš€ Processing: District = Bangalore | Crop = wheat\n",
      "âœ… Bangalore - wheat | MAE=13.46, RMSE=107.32, RÂ²=0.9651, MAPE=0.55%, Accuracy=99.45%\n",
      "\n",
      "ğŸš€ Processing: District = Belgaum | Crop = capsicum\n",
      "âœ… Belgaum - capsicum | MAE=82.23, RMSE=250.34, RÂ²=0.9003, MAPE=2.88%, Accuracy=97.12%\n",
      "\n",
      "ğŸš€ Processing: District = Belgaum | Crop = onion\n",
      "âœ… Belgaum - onion | MAE=45.84, RMSE=153.93, RÂ²=0.9774, MAPE=2.81%, Accuracy=97.19%\n",
      "\n",
      "ğŸš€ Processing: District = Belgaum | Crop = tomato\n",
      "âœ… Belgaum - tomato | MAE=35.0, RMSE=152.83, RÂ²=0.9815, MAPE=1.35%, Accuracy=98.65%\n",
      "\n",
      "ğŸš€ Processing: District = Belgaum | Crop = wheat\n",
      "âœ… Belgaum - wheat | MAE=6.95, RMSE=27.19, RÂ²=0.9972, MAPE=0.35%, Accuracy=99.65%\n",
      "\n",
      "ğŸš€ Processing: District = Bellary | Crop = capsicum\n",
      "âœ… Bellary - capsicum | MAE=6.35, RMSE=68.72, RÂ²=0.8163, MAPE=0.25%, Accuracy=99.75%\n",
      "\n",
      "ğŸš€ Processing: District = Bellary | Crop = onion\n",
      "âœ… Bellary - onion | MAE=64.16, RMSE=132.63, RÂ²=0.9419, MAPE=5.23%, Accuracy=94.77%\n",
      "\n",
      "ğŸš€ Processing: District = Bellary | Crop = tomato\n",
      "âœ… Bellary - tomato | MAE=44.41, RMSE=119.98, RÂ²=0.9631, MAPE=4.84%, Accuracy=95.16%\n",
      "\n",
      "ğŸš€ Processing: District = Bellary | Crop = wheat\n",
      "âœ… Bellary - wheat | MAE=4.55, RMSE=31.73, RÂ²=0.9973, MAPE=0.25%, Accuracy=99.75%\n",
      "\n",
      "ğŸš€ Processing: District = Bidar | Crop = onion\n",
      "âœ… Bidar - onion | MAE=1.82, RMSE=22.1, RÂ²=0.9964, MAPE=0.14%, Accuracy=99.86%\n",
      "\n",
      "ğŸš€ Processing: District = Bidar | Crop = wheat\n",
      "âœ… Bidar - wheat | MAE=39.73, RMSE=88.38, RÂ²=0.971, MAPE=1.65%, Accuracy=98.35%\n",
      "\n",
      "ğŸš€ Processing: District = Bijapur | Crop = onion\n",
      "âœ… Bijapur - onion | MAE=18.3, RMSE=66.58, RÂ²=0.9907, MAPE=1.2%, Accuracy=98.8%\n",
      "\n",
      "ğŸš€ Processing: District = Bijapur | Crop = wheat\n",
      "âœ… Bijapur - wheat | MAE=39.98, RMSE=97.25, RÂ²=0.98, MAPE=1.77%, Accuracy=98.23%\n",
      "\n",
      "ğŸš€ Processing: District = Chamrajnagar | Crop = onion\n",
      "âœ… Chamrajnagar - onion | MAE=18.48, RMSE=55.94, RÂ²=0.9974, MAPE=1.48%, Accuracy=98.52%\n",
      "\n",
      "ğŸš€ Processing: District = Chamrajnagar | Crop = tomato\n",
      "âœ… Chamrajnagar - tomato | MAE=60.84, RMSE=241.84, RÂ²=0.949, MAPE=3.63%, Accuracy=96.37%\n",
      "\n",
      "ğŸš€ Processing: District = Chamrajnagar | Crop = wheat\n",
      "âš ï¸ Chamrajnagar - wheat: Not enough data, using crop-level or global average.\n",
      "âœ… Chamrajnagar - wheat | MAE=9.72, RMSE=35.39, RÂ²=0.9951, MAPE=0.43%, Accuracy=99.57%\n",
      "\n",
      "ğŸš€ Processing: District = Chikmagalur | Crop = capsicum\n",
      "âœ… Chikmagalur - capsicum | MAE=28.73, RMSE=133.46, RÂ²=0.951, MAPE=1.53%, Accuracy=98.47%\n",
      "\n",
      "ğŸš€ Processing: District = Chikmagalur | Crop = onion\n",
      "âœ… Chikmagalur - onion | MAE=31.98, RMSE=68.94, RÂ²=0.9907, MAPE=2.01%, Accuracy=97.99%\n",
      "\n",
      "ğŸš€ Processing: District = Chikmagalur | Crop = tomato\n",
      "âœ… Chikmagalur - tomato | MAE=52.72, RMSE=115.64, RÂ²=0.974, MAPE=4.71%, Accuracy=95.29%\n",
      "\n",
      "ğŸš€ Processing: District = Chikmagalur | Crop = wheat\n",
      "âœ… Chikmagalur - wheat | MAE=3.87, RMSE=23.23, RÂ²=0.9977, MAPE=0.22%, Accuracy=99.78%\n",
      "\n",
      "ğŸš€ Processing: District = Chitradurga | Crop = onion\n",
      "âœ… Chitradurga - onion | MAE=7.42, RMSE=39.86, RÂ²=0.9926, MAPE=0.52%, Accuracy=99.48%\n",
      "\n",
      "ğŸš€ Processing: District = Chitradurga | Crop = tomato\n",
      "âœ… Chitradurga - tomato | MAE=4.89, RMSE=24.09, RÂ²=0.9994, MAPE=0.54%, Accuracy=99.46%\n",
      "\n",
      "ğŸš€ Processing: District = Chitradurga | Crop = wheat\n",
      "âœ… Chitradurga - wheat | MAE=1.27, RMSE=26.71, RÂ²=0.9979, MAPE=0.06%, Accuracy=99.94%\n",
      "\n",
      "ğŸš€ Processing: District = Davangere | Crop = capsicum\n",
      "âœ… Davangere - capsicum | MAE=101.32, RMSE=249.99, RÂ²=0.9793, MAPE=2.81%, Accuracy=97.19%\n",
      "\n",
      "ğŸš€ Processing: District = Davangere | Crop = onion\n",
      "âœ… Davangere - onion | MAE=60.16, RMSE=252.59, RÂ²=0.8783, MAPE=4.72%, Accuracy=95.28%\n",
      "\n",
      "ğŸš€ Processing: District = Davangere | Crop = tomato\n",
      "âœ… Davangere - tomato | MAE=72.75, RMSE=186.04, RÂ²=0.9649, MAPE=6.51%, Accuracy=93.49%\n",
      "\n",
      "ğŸš€ Processing: District = Davangere | Crop = wheat\n",
      "âœ… Davangere - wheat | MAE=4.83, RMSE=41.78, RÂ²=0.9936, MAPE=0.21%, Accuracy=99.79%\n",
      "\n",
      "ğŸš€ Processing: District = Dharwad | Crop = capsicum\n",
      "âœ… Dharwad - capsicum | MAE=150.66, RMSE=307.51, RÂ²=0.924, MAPE=6.67%, Accuracy=93.33%\n",
      "\n",
      "ğŸš€ Processing: District = Dharwad | Crop = onion\n",
      "âœ… Dharwad - onion | MAE=68.59, RMSE=134.26, RÂ²=0.9692, MAPE=5.43%, Accuracy=94.57%\n",
      "\n",
      "ğŸš€ Processing: District = Dharwad | Crop = tomato\n",
      "âœ… Dharwad - tomato | MAE=28.09, RMSE=142.14, RÂ²=0.9706, MAPE=2.0%, Accuracy=98.0%\n",
      "\n",
      "ğŸš€ Processing: District = Dharwad | Crop = wheat\n",
      "âœ… Dharwad - wheat | MAE=26.67, RMSE=58.99, RÂ²=0.9842, MAPE=1.35%, Accuracy=98.65%\n",
      "\n",
      "ğŸš€ Processing: District = Gadag | Crop = onion\n",
      "âœ… Gadag - onion | MAE=22.92, RMSE=71.25, RÂ²=0.9876, MAPE=1.77%, Accuracy=98.23%\n",
      "\n",
      "ğŸš€ Processing: District = Gadag | Crop = tomato\n",
      "âœ… Gadag - tomato | MAE=37.29, RMSE=135.32, RÂ²=0.9961, MAPE=1.39%, Accuracy=98.61%\n",
      "\n",
      "ğŸš€ Processing: District = Gadag | Crop = wheat\n",
      "âœ… Gadag - wheat | MAE=56.9, RMSE=116.97, RÂ²=0.9526, MAPE=2.71%, Accuracy=97.29%\n",
      "\n",
      "ğŸš€ Processing: District = Hassan | Crop = capsicum\n",
      "âœ… Hassan - capsicum | MAE=8.73, RMSE=44.01, RÂ²=0.9975, MAPE=0.49%, Accuracy=99.51%\n",
      "\n",
      "ğŸš€ Processing: District = Hassan | Crop = onion\n",
      "âœ… Hassan - onion | MAE=34.78, RMSE=74.35, RÂ²=0.9869, MAPE=2.49%, Accuracy=97.51%\n",
      "\n",
      "ğŸš€ Processing: District = Hassan | Crop = tomato\n",
      "âœ… Hassan - tomato | MAE=26.1, RMSE=61.96, RÂ²=0.9939, MAPE=2.09%, Accuracy=97.91%\n",
      "\n",
      "ğŸš€ Processing: District = Hassan | Crop = wheat\n",
      "âœ… Hassan - wheat | MAE=6.17, RMSE=42.73, RÂ²=0.9953, MAPE=0.29%, Accuracy=99.71%\n",
      "\n",
      "ğŸš€ Processing: District = Haveri | Crop = capsicum\n",
      "âš ï¸ Haveri - capsicum: Not enough data, using crop-level or global average.\n",
      "âœ… Haveri - capsicum | MAE=41.75, RMSE=71.23, RÂ²=0.9905, MAPE=1.63%, Accuracy=98.37%\n",
      "\n",
      "ğŸš€ Processing: District = Haveri | Crop = onion\n",
      "âœ… Haveri - onion | MAE=19.43, RMSE=61.61, RÂ²=0.9898, MAPE=1.2%, Accuracy=98.8%\n",
      "\n",
      "ğŸš€ Processing: District = Haveri | Crop = tomato\n",
      "âœ… Haveri - tomato | MAE=9.75, RMSE=42.21, RÂ²=0.9997, MAPE=1.37%, Accuracy=98.63%\n",
      "\n",
      "ğŸš€ Processing: District = Haveri | Crop = wheat\n",
      "âœ… Haveri - wheat | MAE=3.01, RMSE=18.39, RÂ²=0.9974, MAPE=0.18%, Accuracy=99.82%\n",
      "\n",
      "ğŸš€ Processing: District = Kalburgi | Crop = capsicum\n",
      "âœ… Kalburgi - capsicum | MAE=176.85, RMSE=338.18, RÂ²=0.9282, MAPE=7.58%, Accuracy=92.42%\n",
      "\n",
      "ğŸš€ Processing: District = Kalburgi | Crop = onion\n",
      "âœ… Kalburgi - onion | MAE=40.44, RMSE=115.43, RÂ²=0.9732, MAPE=2.53%, Accuracy=97.47%\n",
      "\n",
      "ğŸš€ Processing: District = Kalburgi | Crop = tomato\n",
      "âœ… Kalburgi - tomato | MAE=303.32, RMSE=627.59, RÂ²=0.8751, MAPE=18.0%, Accuracy=82.0%\n",
      "\n",
      "ğŸš€ Processing: District = Kalburgi | Crop = wheat\n",
      "âœ… Kalburgi - wheat | MAE=4.73, RMSE=40.2, RÂ²=0.9913, MAPE=0.21%, Accuracy=99.79%\n",
      "\n",
      "ğŸš€ Processing: District = Karwar(Uttar Kannad) | Crop = onion\n",
      "âœ… Karwar(Uttar Kannad) - onion | MAE=21.35, RMSE=74.98, RÂ²=0.9964, MAPE=2.72%, Accuracy=97.28%\n",
      "\n",
      "ğŸš€ Processing: District = Karwar(Uttar Kannad) | Crop = tomato\n",
      "âœ… Karwar(Uttar Kannad) - tomato | MAE=113.25, RMSE=189.05, RÂ²=0.9386, MAPE=9.53%, Accuracy=90.47%\n",
      "\n",
      "ğŸš€ Processing: District = Karwar(Uttar Kannad) | Crop = wheat\n",
      "âœ… Karwar(Uttar Kannad) - wheat | MAE=13.83, RMSE=44.35, RÂ²=0.9249, MAPE=0.92%, Accuracy=99.08%\n",
      "\n",
      "ğŸš€ Processing: District = Kolar | Crop = capsicum\n",
      "âœ… Kolar - capsicum | MAE=74.68, RMSE=141.93, RÂ²=0.9789, MAPE=3.0%, Accuracy=97.0%\n",
      "\n",
      "ğŸš€ Processing: District = Kolar | Crop = onion\n",
      "âœ… Kolar - onion | MAE=25.43, RMSE=67.98, RÂ²=0.9942, MAPE=1.45%, Accuracy=98.55%\n",
      "\n",
      "ğŸš€ Processing: District = Kolar | Crop = tomato\n",
      "âœ… Kolar - tomato | MAE=55.45, RMSE=99.85, RÂ²=0.9831, MAPE=5.03%, Accuracy=94.97%\n",
      "\n",
      "ğŸš€ Processing: District = Kolar | Crop = wheat\n",
      "âœ… Kolar - wheat | MAE=1.96, RMSE=26.53, RÂ²=0.9975, MAPE=0.09%, Accuracy=99.91%\n",
      "\n",
      "ğŸš€ Processing: District = Koppal | Crop = onion\n",
      "âœ… Koppal - onion | MAE=48.31, RMSE=164.46, RÂ²=0.981, MAPE=2.45%, Accuracy=97.55%\n",
      "\n",
      "ğŸš€ Processing: District = Koppal | Crop = tomato\n",
      "âœ… Koppal - tomato | MAE=180.29, RMSE=513.2, RÂ²=0.9274, MAPE=6.76%, Accuracy=93.24%\n",
      "\n",
      "ğŸš€ Processing: District = Koppal | Crop = wheat\n",
      "âœ… Koppal - wheat | MAE=4.54, RMSE=24.26, RÂ²=0.9964, MAPE=0.29%, Accuracy=99.71%\n",
      "\n",
      "ğŸš€ Processing: District = Madikeri(Kodagu) | Crop = onion\n",
      "âœ… Madikeri(Kodagu) - onion | MAE=1.72, RMSE=15.84, RÂ²=0.999, MAPE=0.16%, Accuracy=99.84%\n",
      "\n",
      "ğŸš€ Processing: District = Madikeri(Kodagu) | Crop = tomato\n",
      "âœ… Madikeri(Kodagu) - tomato | MAE=1.3, RMSE=8.04, RÂ²=0.9993, MAPE=0.19%, Accuracy=99.81%\n",
      "\n",
      "ğŸš€ Processing: District = Madikeri(Kodagu) | Crop = wheat\n",
      "âœ… Madikeri(Kodagu) - wheat | MAE=8.8, RMSE=274.25, RÂ²=0.9977, MAPE=0.14%, Accuracy=99.86%\n",
      "\n",
      "ğŸš€ Processing: District = Mandya | Crop = capsicum\n",
      "âœ… Mandya - capsicum | MAE=12.9, RMSE=52.93, RÂ²=0.9974, MAPE=0.73%, Accuracy=99.27%\n",
      "\n",
      "ğŸš€ Processing: District = Mandya | Crop = onion\n",
      "âœ… Mandya - onion | MAE=4.99, RMSE=27.57, RÂ²=0.9969, MAPE=0.31%, Accuracy=99.69%\n",
      "\n",
      "ğŸš€ Processing: District = Mandya | Crop = tomato\n",
      "âœ… Mandya - tomato | MAE=38.48, RMSE=137.06, RÂ²=0.9698, MAPE=4.43%, Accuracy=95.57%\n",
      "\n",
      "ğŸš€ Processing: District = Mandya | Crop = wheat\n",
      "âœ… Mandya - wheat | MAE=1.33, RMSE=23.85, RÂ²=0.9943, MAPE=0.07%, Accuracy=99.93%\n",
      "\n",
      "ğŸš€ Processing: District = Mangalore(Dakshin Kannad) | Crop = onion\n",
      "âœ… Mangalore(Dakshin Kannad) - onion | MAE=11.98, RMSE=58.84, RÂ²=0.9957, MAPE=0.61%, Accuracy=99.39%\n",
      "\n",
      "ğŸš€ Processing: District = Mangalore(Dakshin Kannad) | Crop = tomato\n",
      "âœ… Mangalore(Dakshin Kannad) - tomato | MAE=65.83, RMSE=169.27, RÂ²=0.9805, MAPE=3.13%, Accuracy=96.87%\n",
      "\n",
      "ğŸš€ Processing: District = Mangalore(Dakshin Kannad) | Crop = wheat\n",
      "âœ… Mangalore(Dakshin Kannad) - wheat | MAE=5.28, RMSE=67.6, RÂ²=0.9889, MAPE=0.25%, Accuracy=99.75%\n",
      "\n",
      "ğŸš€ Processing: District = Mysore | Crop = capsicum\n",
      "âœ… Mysore - capsicum | MAE=90.8, RMSE=210.05, RÂ²=0.9613, MAPE=3.99%, Accuracy=96.01%\n",
      "\n",
      "ğŸš€ Processing: District = Mysore | Crop = onion\n",
      "âœ… Mysore - onion | MAE=36.94, RMSE=123.99, RÂ²=0.9655, MAPE=2.06%, Accuracy=97.94%\n",
      "\n",
      "ğŸš€ Processing: District = Mysore | Crop = tomato\n",
      "âœ… Mysore - tomato | MAE=43.79, RMSE=92.24, RÂ²=0.9758, MAPE=3.36%, Accuracy=96.64%\n",
      "\n",
      "ğŸš€ Processing: District = Mysore | Crop = wheat\n",
      "âœ… Mysore - wheat | MAE=67.91, RMSE=539.27, RÂ²=0.7185, MAPE=2.16%, Accuracy=97.84%\n",
      "\n",
      "ğŸš€ Processing: District = Raichur | Crop = onion\n",
      "âœ… Raichur - onion | MAE=65.09, RMSE=125.23, RÂ²=0.975, MAPE=5.85%, Accuracy=94.15%\n",
      "\n",
      "ğŸš€ Processing: District = Raichur | Crop = tomato\n",
      "âœ… Raichur - tomato | MAE=3.16, RMSE=76.07, RÂ²=0.974, MAPE=0.18%, Accuracy=99.82%\n",
      "\n",
      "ğŸš€ Processing: District = Raichur | Crop = wheat\n",
      "âœ… Raichur - wheat | MAE=3.42, RMSE=22.88, RÂ²=0.9962, MAPE=0.21%, Accuracy=99.79%\n",
      "\n",
      "ğŸš€ Processing: District = Shimoga | Crop = capsicum\n",
      "âœ… Shimoga - capsicum | MAE=15.3, RMSE=138.81, RÂ²=0.4701, MAPE=1.1%, Accuracy=98.9%\n",
      "\n",
      "ğŸš€ Processing: District = Shimoga | Crop = onion\n",
      "âœ… Shimoga - onion | MAE=57.71, RMSE=247.52, RÂ²=0.9288, MAPE=23.44%, Accuracy=76.56%\n",
      "\n",
      "ğŸš€ Processing: District = Shimoga | Crop = tomato\n",
      "âœ… Shimoga - tomato | MAE=101.91, RMSE=365.21, RÂ²=0.8735, MAPE=23.01%, Accuracy=76.99%\n",
      "\n",
      "ğŸš€ Processing: District = Shimoga | Crop = wheat\n",
      "âœ… Shimoga - wheat | MAE=63.6, RMSE=433.79, RÂ²=0.6098, MAPE=2.27%, Accuracy=97.73%\n",
      "\n",
      "ğŸš€ Processing: District = Tumkur | Crop = onion\n",
      "âœ… Tumkur - onion | MAE=14.11, RMSE=49.8, RÂ²=0.9992, MAPE=0.64%, Accuracy=99.36%\n",
      "\n",
      "ğŸš€ Processing: District = Tumkur | Crop = tomato\n",
      "âœ… Tumkur - tomato | MAE=19.11, RMSE=81.81, RÂ²=0.9969, MAPE=1.64%, Accuracy=98.36%\n",
      "\n",
      "ğŸš€ Processing: District = Tumkur | Crop = wheat\n",
      "âœ… Tumkur - wheat | MAE=2.95, RMSE=38.13, RÂ²=0.9977, MAPE=0.1%, Accuracy=99.9%\n",
      "\n",
      "ğŸš€ Processing: District = Udupi | Crop = capsicum\n",
      "âœ… Udupi - capsicum | MAE=39.29, RMSE=175.13, RÂ²=0.9863, MAPE=0.92%, Accuracy=99.08%\n",
      "\n",
      "ğŸš€ Processing: District = Udupi | Crop = onion\n",
      "âœ… Udupi - onion | MAE=34.25, RMSE=140.03, RÂ²=0.9883, MAPE=1.42%, Accuracy=98.58%\n",
      "\n",
      "ğŸš€ Processing: District = Udupi | Crop = tomato\n",
      "âœ… Udupi - tomato | MAE=44.37, RMSE=161.2, RÂ²=0.9848, MAPE=2.12%, Accuracy=97.88%\n",
      "\n",
      "ğŸš€ Processing: District = Udupi | Crop = wheat\n",
      "âœ… Udupi - wheat | MAE=1.33, RMSE=39.82, RÂ²=0.9666, MAPE=0.11%, Accuracy=99.89%\n",
      "\n",
      "ğŸ“Š All combinations processed successfully!\n",
      "âœ… Metrics saved to: arima_state_all_output\\arima_all_metrics.csv\n",
      "         District        Crop     MAE    RMSE    R2  MAPE(%)  Accuracy(%)\n",
      "0   All Districts  full_state   14.15   28.28  1.00     0.73        99.27\n",
      "1        Bagalkot       onion   13.61   51.73  0.99     1.06        98.94\n",
      "2        Bagalkot       wheat   10.82   56.97  0.99     0.51        99.49\n",
      "3       Bangalore    capsicum  117.40  214.75  0.96     4.14        95.86\n",
      "4       Bangalore       onion   33.52   93.61  0.99     1.71        98.29\n",
      "..            ...         ...     ...     ...   ...      ...          ...\n",
      "85         Tumkur       wheat    2.95   38.13  1.00     0.10        99.90\n",
      "86          Udupi    capsicum   39.29  175.13  0.99     0.92        99.08\n",
      "87          Udupi       onion   34.25  140.03  0.99     1.42        98.58\n",
      "88          Udupi      tomato   44.37  161.20  0.98     2.12        97.88\n",
      "89          Udupi       wheat    1.33   39.82  0.97     0.11        99.89\n",
      "\n",
      "[90 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ==========================================================\n",
    "# ğŸ“‚ Paths and Setup\n",
    "# ==========================================================\n",
    "input_file = \"dataset/Crop_price_forecast_Daily.xlsx\"\n",
    "output_folder = \"arima_state_all_output\"\n",
    "output_csv = os.path.join(output_folder, \"arima_all_predictions\")\n",
    "output_graphs = os.path.join(output_folder, \"arima_all_graphs\")\n",
    "metrics_file = os.path.join(output_folder, \"arima_all_metrics.csv\")\n",
    "\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "os.makedirs(output_csv, exist_ok=True)\n",
    "os.makedirs(output_graphs, exist_ok=True)\n",
    "\n",
    "# ==========================================================\n",
    "# ğŸ§® Helper Functions\n",
    "# ==========================================================\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    mask = y_true != 0\n",
    "    return np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100 if np.any(mask) else np.nan\n",
    "\n",
    "def parse_dates_safe(series):\n",
    "    try:\n",
    "        return pd.to_datetime(series, dayfirst=True)\n",
    "    except:\n",
    "        return pd.to_datetime(series, dayfirst=False)\n",
    "\n",
    "# ==========================================================\n",
    "# ğŸ“˜ Load Dataset\n",
    "# ==========================================================\n",
    "print(f\"ğŸ“˜ Loading dataset: {input_file}\")\n",
    "df = pd.read_excel(input_file)\n",
    "df.columns = [col.strip().lower() for col in df.columns]\n",
    "\n",
    "required_cols = ['date', 'district', 'crop_type', 'average']\n",
    "if not all(col in df.columns for col in required_cols):\n",
    "    raise ValueError(f\"âŒ Missing required columns: {required_cols}\")\n",
    "\n",
    "df['date'] = parse_dates_safe(df['date'])\n",
    "df = df.sort_values('date')\n",
    "df = df.dropna(subset=['average'])\n",
    "\n",
    "# ==========================================================\n",
    "# ğŸ“Š Metrics Storage\n",
    "# ==========================================================\n",
    "metrics_list = []\n",
    "\n",
    "# ==========================================================\n",
    "# ğŸ” ARIMA per (District Ã— Crop)\n",
    "# ==========================================================\n",
    "groups = df.groupby(['district', 'crop_type'])\n",
    "\n",
    "for (district, crop), group in groups:\n",
    "    print(f\"\\nğŸš€ Processing: District = {district} | Crop = {crop}\")\n",
    "\n",
    "    data = group.copy().sort_values('date')\n",
    "    data = data.groupby('date', as_index=False).mean(numeric_only=True)\n",
    "    data.set_index('date', inplace=True)\n",
    "    data = data.asfreq('D')\n",
    "\n",
    "    # Fill missing values\n",
    "    data['average'] = data['average'].ffill().bfill().fillna(data['average'].mean())\n",
    "\n",
    "    # âœ… Handle sparse data by using crop-level or global averages\n",
    "    if data['average'].count() < 5:\n",
    "        print(f\"âš ï¸ {district} - {crop}: Not enough data, using crop-level or global average.\")\n",
    "        crop_level = df[df['crop_type'] == crop].groupby('date', as_index=False)['average'].mean()\n",
    "        if crop_level.empty:\n",
    "            print(f\"âš ï¸ {district} - {crop}: No crop-level data found. Using overall average.\")\n",
    "            crop_level = df.groupby('date', as_index=False)['average'].mean()\n",
    "        crop_level.set_index('date', inplace=True)\n",
    "        crop_level = crop_level.asfreq('D')\n",
    "        crop_level['average'] = crop_level['average'].ffill().bfill().fillna(crop_level['average'].mean())\n",
    "        data = crop_level.copy()\n",
    "\n",
    "    # ==========================================================\n",
    "    # ğŸ§© Feature Engineering\n",
    "    # ==========================================================\n",
    "    data['Lag_1'] = data['average'].shift(1)\n",
    "    data['Lag_7'] = data['average'].shift(7)\n",
    "    data['MA_7'] = data['average'].rolling(window=7).mean()\n",
    "    data['MA_30'] = data['average'].rolling(window=30).mean()\n",
    "    data[['Lag_1', 'Lag_7', 'MA_7', 'MA_30']] = data[['Lag_1', 'Lag_7', 'MA_7', 'MA_30']].bfill().ffill()\n",
    "\n",
    "    # ==========================================================\n",
    "    # âš™ï¸ ARIMA Model (Simple Order)\n",
    "    # ==========================================================\n",
    "    y = data['average'].values\n",
    "    try:\n",
    "        model = ARIMA(y, order=(1,1,1))\n",
    "        model_fit = model.fit()\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Skipping {district} - {crop} due to ARIMA fit error: {e}\")\n",
    "        continue\n",
    "\n",
    "    # ==========================================================\n",
    "    # ğŸ”¢ Forecast same length\n",
    "    # ==========================================================\n",
    "    predictions = model_fit.predict(start=0, end=len(y)-1)\n",
    "    predictions = predictions[:len(y)]  # Ensure same length\n",
    "\n",
    "    data['Predicted'] = predictions.round(2)\n",
    "\n",
    "    # ==========================================================\n",
    "    # ğŸ“ˆ Metrics Calculation\n",
    "    # ==========================================================\n",
    "    y_true = data['average'].values\n",
    "    y_pred = data['Predicted'].values\n",
    "\n",
    "    mae = round(mean_absolute_error(y_true, y_pred), 2)\n",
    "    rmse = round(np.sqrt(mean_squared_error(y_true, y_pred)), 2)\n",
    "    r2 = round(r2_score(y_true, y_pred), 4)\n",
    "    mape = round(mean_absolute_percentage_error(y_true, y_pred), 2)\n",
    "    accuracy = round(100 - mape, 2)\n",
    "\n",
    "    metrics_list.append({\n",
    "        'District': district,\n",
    "        'Crop': crop,\n",
    "        'MAE': mae,\n",
    "        'RMSE': rmse,\n",
    "        'R2': r2,\n",
    "        'MAPE(%)': mape,\n",
    "        'Accuracy(%)': accuracy\n",
    "    })\n",
    "\n",
    "    print(f\"âœ… {district} - {crop} | MAE={mae}, RMSE={rmse}, RÂ²={r2}, MAPE={mape}%, Accuracy={accuracy}%\")\n",
    "\n",
    "    # ==========================================================\n",
    "    # ğŸ’¾ Save Predictions\n",
    "    # ==========================================================\n",
    "    data.reset_index().to_csv(os.path.join(output_csv, f\"{district}_{crop}_arima_daily.csv\"), index=False, float_format='%.2f')\n",
    "\n",
    "    # ==========================================================\n",
    "    # ğŸ”® Future Forecast (30 days)\n",
    "    # ==========================================================\n",
    "    try:\n",
    "        forecast = model_fit.forecast(steps=30)\n",
    "        future_dates = pd.date_range(start=data.index[-1] + pd.Timedelta(days=1), periods=30, freq='D')\n",
    "        forecast_df = pd.DataFrame({'Date': future_dates, 'Forecast': forecast.round(2)})\n",
    "        forecast_df['District'] = district\n",
    "        forecast_df['Crop'] = crop\n",
    "        forecast_df.to_csv(os.path.join(output_csv, f\"{district}_{crop}_arima_future.csv\"), index=False, float_format='%.2f')\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Could not generate future forecast for {district}-{crop}: {e}\")\n",
    "\n",
    "    # ==========================================================\n",
    "    # ğŸ“Š Save Graph\n",
    "    # ==========================================================\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.plot(data.index, data['average'], label='Actual', color='blue')\n",
    "    plt.plot(data.index, data['Predicted'], label='Predicted (ARIMA)', color='red', linestyle='dashed')\n",
    "    if 'forecast_df' in locals():\n",
    "        plt.plot(forecast_df['Date'], forecast_df['Forecast'], label='Future Forecast (30 days)', color='green', linestyle='dotted')\n",
    "    plt.title(f\"ARIMA Forecast - {district} | {crop}\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Average Price\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_graphs, f\"{district}_{crop}_arima_graph.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    del data, y, model, model_fit\n",
    "    gc.collect()\n",
    "\n",
    "# ==========================================================\n",
    "# ğŸ§¾ Save Metrics Summary\n",
    "# ==========================================================\n",
    "metrics_df = pd.DataFrame(metrics_list).round(2)\n",
    "metrics_df.to_csv(metrics_file, index=False)\n",
    "print(f\"\\nğŸ“Š All combinations processed successfully!\")\n",
    "print(f\"âœ… Metrics saved to: {metrics_file}\")\n",
    "print(metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e83188-09fa-42c1-9af2-7cf267f80a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SARIMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2397a57-114f-48ad-9e2b-3d21cc81799d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Loading dataset: dataset/Crop_price_forecast_Daily.xlsx\n",
      "\n",
      "ğŸš€ Processing: District = All Districts | Crop = full_state\n",
      "âœ… All Districts - full_state | MAE=13.1, RMSE=109.58, RÂ²=0.9627, MAPE=0.76%, Accuracy=99.24%\n",
      "\n",
      "ğŸš€ Processing: District = Bagalkot | Crop = onion\n",
      "âœ… Bagalkot - onion | MAE=15.74, RMSE=133.68, RÂ²=0.9658, MAPE=1.2%, Accuracy=98.8%\n",
      "\n",
      "ğŸš€ Processing: District = Bagalkot | Crop = wheat\n",
      "âœ… Bagalkot - wheat | MAE=11.79, RMSE=99.16, RÂ²=0.9615, MAPE=0.6%, Accuracy=99.4%\n",
      "\n",
      "ğŸš€ Processing: District = Bangalore | Crop = capsicum\n",
      "âœ… Bangalore - capsicum | MAE=95.55, RMSE=252.73, RÂ²=0.9403, MAPE=3.45%, Accuracy=96.55%\n",
      "\n",
      "ğŸš€ Processing: District = Bangalore | Crop = onion\n",
      "âœ… Bangalore - onion | MAE=29.46, RMSE=115.47, RÂ²=0.9831, MAPE=1.66%, Accuracy=98.34%\n",
      "\n",
      "ğŸš€ Processing: District = Bangalore | Crop = tomato\n",
      "âœ… Bangalore - tomato | MAE=58.93, RMSE=146.43, RÂ²=0.985, MAPE=3.99%, Accuracy=96.01%\n",
      "\n",
      "ğŸš€ Processing: District = Bangalore | Crop = wheat\n",
      "âœ… Bangalore - wheat | MAE=18.66, RMSE=186.91, RÂ²=0.894, MAPE=0.86%, Accuracy=99.14%\n",
      "\n",
      "ğŸš€ Processing: District = Belgaum | Crop = capsicum\n",
      "âœ… Belgaum - capsicum | MAE=99.05, RMSE=489.7, RÂ²=0.6186, MAPE=3.51%, Accuracy=96.49%\n",
      "\n",
      "ğŸš€ Processing: District = Belgaum | Crop = onion\n",
      "âœ… Belgaum - onion | MAE=49.08, RMSE=156.42, RÂ²=0.9767, MAPE=3.14%, Accuracy=96.86%\n",
      "\n",
      "ğŸš€ Processing: District = Belgaum | Crop = tomato\n",
      "âœ… Belgaum - tomato | MAE=31.28, RMSE=115.7, RÂ²=0.9894, MAPE=1.48%, Accuracy=98.52%\n",
      "\n",
      "ğŸš€ Processing: District = Belgaum | Crop = wheat\n",
      "âœ… Belgaum - wheat | MAE=9.02, RMSE=128.82, RÂ²=0.938, MAPE=0.5%, Accuracy=99.5%\n",
      "\n",
      "ğŸš€ Processing: District = Bellary | Crop = capsicum\n",
      "âœ… Bellary - capsicum | MAE=17.19, RMSE=338.12, RÂ²=-3.4474, MAPE=0.72%, Accuracy=99.28%\n",
      "\n",
      "ğŸš€ Processing: District = Bellary | Crop = onion\n",
      "âœ… Bellary - onion | MAE=50.59, RMSE=122.34, RÂ²=0.9506, MAPE=4.31%, Accuracy=95.69%\n",
      "\n",
      "ğŸš€ Processing: District = Bellary | Crop = tomato\n",
      "âœ… Bellary - tomato | MAE=37.86, RMSE=106.65, RÂ²=0.9708, MAPE=4.53%, Accuracy=95.47%\n",
      "\n",
      "ğŸš€ Processing: District = Bellary | Crop = wheat\n",
      "âœ… Bellary - wheat | MAE=6.58, RMSE=126.26, RÂ²=0.9577, MAPE=0.46%, Accuracy=99.54%\n",
      "\n",
      "ğŸš€ Processing: District = Bidar | Crop = onion\n",
      "âœ… Bidar - onion | MAE=3.71, RMSE=67.3, RÂ²=0.9666, MAPE=0.34%, Accuracy=99.66%\n",
      "\n",
      "ğŸš€ Processing: District = Bidar | Crop = wheat\n",
      "âœ… Bidar - wheat | MAE=32.84, RMSE=144.91, RÂ²=0.9222, MAPE=1.47%, Accuracy=98.53%\n",
      "\n",
      "ğŸš€ Processing: District = Bijapur | Crop = onion\n",
      "âœ… Bijapur - onion | MAE=18.08, RMSE=54.74, RÂ²=0.9937, MAPE=1.25%, Accuracy=98.75%\n",
      "\n",
      "ğŸš€ Processing: District = Bijapur | Crop = wheat\n",
      "âœ… Bijapur - wheat | MAE=35.38, RMSE=175.13, RÂ²=0.9352, MAPE=1.66%, Accuracy=98.34%\n",
      "\n",
      "ğŸš€ Processing: District = Chamrajnagar | Crop = onion\n",
      "âœ… Chamrajnagar - onion | MAE=16.6, RMSE=73.73, RÂ²=0.9955, MAPE=1.53%, Accuracy=98.47%\n",
      "\n",
      "ğŸš€ Processing: District = Chamrajnagar | Crop = tomato\n",
      "âœ… Chamrajnagar - tomato | MAE=47.72, RMSE=191.92, RÂ²=0.9679, MAPE=3.18%, Accuracy=96.82%\n",
      "\n",
      "ğŸš€ Processing: District = Chamrajnagar | Crop = wheat\n",
      "âš ï¸ Chamrajnagar - wheat: Not enough data, using crop-level or global average.\n",
      "âœ… Chamrajnagar - wheat | MAE=11.24, RMSE=170.06, RÂ²=0.8866, MAPE=0.56%, Accuracy=99.44%\n",
      "\n",
      "ğŸš€ Processing: District = Chikmagalur | Crop = capsicum\n",
      "âœ… Chikmagalur - capsicum | MAE=41.6, RMSE=408.65, RÂ²=0.5408, MAPE=1.95%, Accuracy=98.05%\n",
      "\n",
      "ğŸš€ Processing: District = Chikmagalur | Crop = onion\n",
      "âœ… Chikmagalur - onion | MAE=30.52, RMSE=130.44, RÂ²=0.9666, MAPE=2.11%, Accuracy=97.89%\n",
      "\n",
      "ğŸš€ Processing: District = Chikmagalur | Crop = tomato\n",
      "âœ… Chikmagalur - tomato | MAE=40.84, RMSE=101.71, RÂ²=0.9799, MAPE=4.02%, Accuracy=95.98%\n",
      "\n",
      "ğŸš€ Processing: District = Chikmagalur | Crop = wheat\n",
      "âœ… Chikmagalur - wheat | MAE=6.14, RMSE=135.1, RÂ²=0.9233, MAPE=0.39%, Accuracy=99.61%\n",
      "\n",
      "ğŸš€ Processing: District = Chitradurga | Crop = onion\n",
      "âœ… Chitradurga - onion | MAE=8.51, RMSE=68.15, RÂ²=0.9783, MAPE=0.81%, Accuracy=99.19%\n",
      "\n",
      "ğŸš€ Processing: District = Chitradurga | Crop = tomato\n",
      "âœ… Chitradurga - tomato | MAE=6.24, RMSE=74.3, RÂ²=0.9947, MAPE=0.94%, Accuracy=99.06%\n",
      "\n",
      "ğŸš€ Processing: District = Chitradurga | Crop = wheat\n",
      "âœ… Chitradurga - wheat | MAE=6.45, RMSE=181.7, RÂ²=0.9018, MAPE=0.41%, Accuracy=99.59%\n",
      "\n",
      "ğŸš€ Processing: District = Davangere | Crop = capsicum\n",
      "âœ… Davangere - capsicum | MAE=85.18, RMSE=214.82, RÂ²=0.9847, MAPE=2.52%, Accuracy=97.48%\n",
      "\n",
      "ğŸš€ Processing: District = Davangere | Crop = onion\n",
      "âœ… Davangere - onion | MAE=47.18, RMSE=202.53, RÂ²=0.9217, MAPE=4.15%, Accuracy=95.85%\n",
      "\n",
      "ğŸš€ Processing: District = Davangere | Crop = tomato\n",
      "âœ… Davangere - tomato | MAE=59.11, RMSE=134.27, RÂ²=0.9817, MAPE=5.88%, Accuracy=94.12%\n",
      "\n",
      "ğŸš€ Processing: District = Davangere | Crop = wheat\n",
      "âœ… Davangere - wheat | MAE=10.11, RMSE=215.95, RÂ²=0.8292, MAPE=0.47%, Accuracy=99.53%\n",
      "\n",
      "ğŸš€ Processing: District = Dharwad | Crop = capsicum\n",
      "âœ… Dharwad - capsicum | MAE=149.67, RMSE=280.0, RÂ²=0.937, MAPE=6.28%, Accuracy=93.72%\n",
      "\n",
      "ğŸš€ Processing: District = Dharwad | Crop = onion\n",
      "âœ… Dharwad - onion | MAE=52.79, RMSE=143.84, RÂ²=0.9647, MAPE=4.28%, Accuracy=95.72%\n",
      "\n",
      "ğŸš€ Processing: District = Dharwad | Crop = tomato\n",
      "âœ… Dharwad - tomato | MAE=35.64, RMSE=138.19, RÂ²=0.9722, MAPE=3.04%, Accuracy=96.96%\n",
      "\n",
      "ğŸš€ Processing: District = Dharwad | Crop = wheat\n",
      "âœ… Dharwad - wheat | MAE=26.25, RMSE=176.75, RÂ²=0.8577, MAPE=1.41%, Accuracy=98.59%\n",
      "\n",
      "ğŸš€ Processing: District = Gadag | Crop = onion\n",
      "âœ… Gadag - onion | MAE=22.47, RMSE=141.75, RÂ²=0.9507, MAPE=1.92%, Accuracy=98.08%\n",
      "\n",
      "ğŸš€ Processing: District = Gadag | Crop = tomato\n",
      "âœ… Gadag - tomato | MAE=63.28, RMSE=644.89, RÂ²=0.911, MAPE=5.45%, Accuracy=94.55%\n",
      "\n",
      "ğŸš€ Processing: District = Gadag | Crop = wheat\n",
      "âœ… Gadag - wheat | MAE=43.27, RMSE=158.99, RÂ²=0.9124, MAPE=2.17%, Accuracy=97.83%\n",
      "\n",
      "ğŸš€ Processing: District = Hassan | Crop = capsicum\n",
      "âœ… Hassan - capsicum | MAE=10.88, RMSE=115.38, RÂ²=0.9831, MAPE=0.7%, Accuracy=99.3%\n",
      "\n",
      "ğŸš€ Processing: District = Hassan | Crop = onion\n",
      "âœ… Hassan - onion | MAE=29.26, RMSE=118.87, RÂ²=0.9665, MAPE=2.17%, Accuracy=97.83%\n",
      "\n",
      "ğŸš€ Processing: District = Hassan | Crop = tomato\n",
      "âœ… Hassan - tomato | MAE=22.2, RMSE=81.02, RÂ²=0.9896, MAPE=1.9%, Accuracy=98.1%\n",
      "\n",
      "ğŸš€ Processing: District = Hassan | Crop = wheat\n",
      "âœ… Hassan - wheat | MAE=8.47, RMSE=105.53, RÂ²=0.9716, MAPE=0.42%, Accuracy=99.58%\n",
      "\n",
      "ğŸš€ Processing: District = Haveri | Crop = capsicum\n",
      "âš ï¸ Haveri - capsicum: Not enough data, using crop-level or global average.\n",
      "âœ… Haveri - capsicum | MAE=33.09, RMSE=125.59, RÂ²=0.9704, MAPE=1.48%, Accuracy=98.52%\n",
      "\n",
      "ğŸš€ Processing: District = Haveri | Crop = onion\n",
      "âœ… Haveri - onion | MAE=17.25, RMSE=95.38, RÂ²=0.9756, MAPE=1.24%, Accuracy=98.76%\n",
      "\n",
      "ğŸš€ Processing: District = Haveri | Crop = tomato\n",
      "âœ… Haveri - tomato | MAE=10.15, RMSE=30.55, RÂ²=0.9998, MAPE=1.31%, Accuracy=98.69%\n",
      "\n",
      "ğŸš€ Processing: District = Haveri | Crop = wheat\n",
      "âœ… Haveri - wheat | MAE=5.12, RMSE=99.86, RÂ²=0.9227, MAPE=0.36%, Accuracy=99.64%\n",
      "\n",
      "ğŸš€ Processing: District = Kalburgi | Crop = capsicum\n",
      "âœ… Kalburgi - capsicum | MAE=132.39, RMSE=234.84, RÂ²=0.9654, MAPE=6.74%, Accuracy=93.26%\n",
      "\n",
      "ğŸš€ Processing: District = Kalburgi | Crop = onion\n",
      "âœ… Kalburgi - onion | MAE=51.82, RMSE=248.28, RÂ²=0.8761, MAPE=3.37%, Accuracy=96.63%\n",
      "\n",
      "ğŸš€ Processing: District = Kalburgi | Crop = tomato\n",
      "âœ… Kalburgi - tomato | MAE=228.06, RMSE=418.7, RÂ²=0.9444, MAPE=15.18%, Accuracy=84.82%\n",
      "\n",
      "ğŸš€ Processing: District = Kalburgi | Crop = wheat\n",
      "âœ… Kalburgi - wheat | MAE=7.89, RMSE=145.0, RÂ²=0.8874, MAPE=0.38%, Accuracy=99.62%\n",
      "\n",
      "ğŸš€ Processing: District = Karwar(Uttar Kannad) | Crop = onion\n",
      "âœ… Karwar(Uttar Kannad) - onion | MAE=22.15, RMSE=88.44, RÂ²=0.995, MAPE=3.02%, Accuracy=96.98%\n",
      "\n",
      "ğŸš€ Processing: District = Karwar(Uttar Kannad) | Crop = tomato\n",
      "âœ… Karwar(Uttar Kannad) - tomato | MAE=97.91, RMSE=237.54, RÂ²=0.903, MAPE=10.15%, Accuracy=89.85%\n",
      "\n",
      "ğŸš€ Processing: District = Karwar(Uttar Kannad) | Crop = wheat\n",
      "âœ… Karwar(Uttar Kannad) - wheat | MAE=18.6, RMSE=197.41, RÂ²=-0.4872, MAPE=1.39%, Accuracy=98.61%\n",
      "\n",
      "ğŸš€ Processing: District = Kolar | Crop = capsicum\n",
      "âœ… Kolar - capsicum | MAE=56.29, RMSE=152.81, RÂ²=0.9755, MAPE=2.43%, Accuracy=97.57%\n",
      "\n",
      "ğŸš€ Processing: District = Kolar | Crop = onion\n",
      "âœ… Kolar - onion | MAE=22.91, RMSE=133.88, RÂ²=0.9776, MAPE=1.4%, Accuracy=98.6%\n",
      "\n",
      "ğŸš€ Processing: District = Kolar | Crop = tomato\n",
      "âœ… Kolar - tomato | MAE=40.35, RMSE=100.79, RÂ²=0.9828, MAPE=3.89%, Accuracy=96.11%\n",
      "\n",
      "ğŸš€ Processing: District = Kolar | Crop = wheat\n",
      "âœ… Kolar - wheat | MAE=1.76, RMSE=12.99, RÂ²=0.9994, MAPE=0.08%, Accuracy=99.92%\n",
      "\n",
      "ğŸš€ Processing: District = Koppal | Crop = onion\n",
      "âœ… Koppal - onion | MAE=45.43, RMSE=101.69, RÂ²=0.9927, MAPE=2.16%, Accuracy=97.84%\n",
      "\n",
      "ğŸš€ Processing: District = Koppal | Crop = tomato\n",
      "âœ… Koppal - tomato | MAE=263.53, RMSE=901.22, RÂ²=0.776, MAPE=10.16%, Accuracy=89.84%\n",
      "\n",
      "ğŸš€ Processing: District = Koppal | Crop = wheat\n",
      "âœ… Koppal - wheat | MAE=7.66, RMSE=158.33, RÂ²=0.847, MAPE=0.52%, Accuracy=99.48%\n",
      "\n",
      "ğŸš€ Processing: District = Madikeri(Kodagu) | Crop = onion\n",
      "âœ… Madikeri(Kodagu) - onion | MAE=3.04, RMSE=53.03, RÂ²=0.9883, MAPE=0.47%, Accuracy=99.53%\n",
      "\n",
      "ğŸš€ Processing: District = Madikeri(Kodagu) | Crop = tomato\n",
      "âœ… Madikeri(Kodagu) - tomato | MAE=1.93, RMSE=25.14, RÂ²=0.9929, MAPE=0.39%, Accuracy=99.61%\n",
      "\n",
      "ğŸš€ Processing: District = Madikeri(Kodagu) | Crop = wheat\n",
      "âœ… Madikeri(Kodagu) - wheat | MAE=20.79, RMSE=254.57, RÂ²=0.998, MAPE=0.51%, Accuracy=99.49%\n",
      "\n",
      "ğŸš€ Processing: District = Mandya | Crop = capsicum\n",
      "âœ… Mandya - capsicum | MAE=14.72, RMSE=119.48, RÂ²=0.9868, MAPE=0.93%, Accuracy=99.07%\n",
      "\n",
      "ğŸš€ Processing: District = Mandya | Crop = onion\n",
      "âœ… Mandya - onion | MAE=6.3, RMSE=48.69, RÂ²=0.9905, MAPE=0.51%, Accuracy=99.49%\n",
      "\n",
      "ğŸš€ Processing: District = Mandya | Crop = tomato\n",
      "âœ… Mandya - tomato | MAE=34.98, RMSE=129.76, RÂ²=0.9729, MAPE=4.71%, Accuracy=95.29%\n",
      "\n",
      "ğŸš€ Processing: District = Mandya | Crop = wheat\n",
      "âœ… Mandya - wheat | MAE=5.68, RMSE=132.23, RÂ²=0.8261, MAPE=0.41%, Accuracy=99.59%\n",
      "\n",
      "ğŸš€ Processing: District = Mangalore(Dakshin Kannad) | Crop = onion\n",
      "âœ… Mangalore(Dakshin Kannad) - onion | MAE=15.95, RMSE=188.25, RÂ²=0.9558, MAPE=0.85%, Accuracy=99.15%\n",
      "\n",
      "ğŸš€ Processing: District = Mangalore(Dakshin Kannad) | Crop = tomato\n",
      "âœ… Mangalore(Dakshin Kannad) - tomato | MAE=88.28, RMSE=451.06, RÂ²=0.8614, MAPE=4.74%, Accuracy=95.26%\n",
      "\n",
      "ğŸš€ Processing: District = Mangalore(Dakshin Kannad) | Crop = wheat\n",
      "âœ… Mangalore(Dakshin Kannad) - wheat | MAE=13.08, RMSE=148.81, RÂ²=0.946, MAPE=0.67%, Accuracy=99.33%\n",
      "\n",
      "ğŸš€ Processing: District = Mysore | Crop = capsicum\n",
      "âœ… Mysore - capsicum | MAE=75.94, RMSE=193.24, RÂ²=0.9673, MAPE=3.36%, Accuracy=96.64%\n",
      "\n",
      "ğŸš€ Processing: District = Mysore | Crop = onion\n",
      "âœ… Mysore - onion | MAE=31.36, RMSE=140.53, RÂ²=0.9557, MAPE=1.95%, Accuracy=98.05%\n",
      "\n",
      "ğŸš€ Processing: District = Mysore | Crop = tomato\n",
      "âœ… Mysore - tomato | MAE=33.02, RMSE=83.52, RÂ²=0.9802, MAPE=2.7%, Accuracy=97.3%\n",
      "\n",
      "ğŸš€ Processing: District = Mysore | Crop = wheat\n",
      "âœ… Mysore - wheat | MAE=51.95, RMSE=417.43, RÂ²=0.8313, MAPE=1.83%, Accuracy=98.17%\n",
      "\n",
      "ğŸš€ Processing: District = Raichur | Crop = onion\n",
      "âœ… Raichur - onion | MAE=51.65, RMSE=136.68, RÂ²=0.9703, MAPE=4.66%, Accuracy=95.34%\n",
      "\n",
      "ğŸš€ Processing: District = Raichur | Crop = tomato\n",
      "âœ… Raichur - tomato | MAE=0.42, RMSE=2.24, RÂ²=1.0, MAPE=0.04%, Accuracy=99.96%\n",
      "\n",
      "ğŸš€ Processing: District = Raichur | Crop = wheat\n",
      "âœ… Raichur - wheat | MAE=5.76, RMSE=100.28, RÂ²=0.9274, MAPE=0.41%, Accuracy=99.59%\n",
      "\n",
      "ğŸš€ Processing: District = Shimoga | Crop = capsicum\n",
      "âœ… Shimoga - capsicum | MAE=18.68, RMSE=103.48, RÂ²=0.7055, MAPE=1.4%, Accuracy=98.6%\n",
      "\n",
      "ğŸš€ Processing: District = Shimoga | Crop = onion\n",
      "âœ… Shimoga - onion | MAE=46.21, RMSE=200.18, RÂ²=0.9534, MAPE=9.65%, Accuracy=90.35%\n",
      "\n",
      "ğŸš€ Processing: District = Shimoga | Crop = tomato\n",
      "âœ… Shimoga - tomato | MAE=76.36, RMSE=250.61, RÂ²=0.9404, MAPE=10.6%, Accuracy=89.4%\n",
      "\n",
      "ğŸš€ Processing: District = Shimoga | Crop = wheat\n",
      "âœ… Shimoga - wheat | MAE=44.56, RMSE=367.57, RÂ²=0.7199, MAPE=1.76%, Accuracy=98.24%\n",
      "\n",
      "ğŸš€ Processing: District = Tumkur | Crop = onion\n",
      "âœ… Tumkur - onion | MAE=14.99, RMSE=89.97, RÂ²=0.9975, MAPE=0.74%, Accuracy=99.26%\n",
      "\n",
      "ğŸš€ Processing: District = Tumkur | Crop = tomato\n",
      "âœ… Tumkur - tomato | MAE=16.58, RMSE=109.28, RÂ²=0.9945, MAPE=1.66%, Accuracy=98.34%\n",
      "\n",
      "ğŸš€ Processing: District = Tumkur | Crop = wheat\n",
      "âœ… Tumkur - wheat | MAE=2.93, RMSE=24.99, RÂ²=0.999, MAPE=0.11%, Accuracy=99.89%\n",
      "\n",
      "ğŸš€ Processing: District = Udupi | Crop = capsicum\n",
      "âœ… Udupi - capsicum | MAE=46.53, RMSE=237.94, RÂ²=0.9747, MAPE=1.2%, Accuracy=98.8%\n",
      "\n",
      "ğŸš€ Processing: District = Udupi | Crop = onion\n",
      "âœ… Udupi - onion | MAE=35.05, RMSE=202.5, RÂ²=0.9756, MAPE=1.54%, Accuracy=98.46%\n",
      "\n",
      "ğŸš€ Processing: District = Udupi | Crop = tomato\n",
      "âœ… Udupi - tomato | MAE=44.31, RMSE=156.96, RÂ²=0.9856, MAPE=2.13%, Accuracy=97.87%\n",
      "\n",
      "ğŸš€ Processing: District = Udupi | Crop = wheat\n",
      "âœ… Udupi - wheat | MAE=0.03, RMSE=0.25, RÂ²=1.0, MAPE=0.0%, Accuracy=100.0%\n",
      "\n",
      "ğŸ“Š All combinations processed successfully!\n",
      "âœ… Metrics saved to: sarimax_state_all_output\\sarimax_all_metrics.csv\n",
      "         District        Crop    MAE    RMSE    R2  MAPE(%)  Accuracy(%)\n",
      "0   All Districts  full_state  13.10  109.58  0.96     0.76        99.24\n",
      "1        Bagalkot       onion  15.74  133.68  0.97     1.20        98.80\n",
      "2        Bagalkot       wheat  11.79   99.16  0.96     0.60        99.40\n",
      "3       Bangalore    capsicum  95.55  252.73  0.94     3.45        96.55\n",
      "4       Bangalore       onion  29.46  115.47  0.98     1.66        98.34\n",
      "..            ...         ...    ...     ...   ...      ...          ...\n",
      "85         Tumkur       wheat   2.93   24.99  1.00     0.11        99.89\n",
      "86          Udupi    capsicum  46.53  237.94  0.97     1.20        98.80\n",
      "87          Udupi       onion  35.05  202.50  0.98     1.54        98.46\n",
      "88          Udupi      tomato  44.31  156.96  0.99     2.13        97.87\n",
      "89          Udupi       wheat   0.03    0.25  1.00     0.00       100.00\n",
      "\n",
      "[90 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ==========================================================\n",
    "# ğŸ“‚ Paths and Setup\n",
    "# ==========================================================\n",
    "input_file = \"dataset/Crop_price_forecast_Daily.xlsx\"\n",
    "output_folder = \"sarimax_state_all_output\"\n",
    "output_csv = os.path.join(output_folder, \"sarimax_all_predictions\")\n",
    "output_graphs = os.path.join(output_folder, \"sarimax_all_graphs\")\n",
    "metrics_file = os.path.join(output_folder, \"sarimax_all_metrics.csv\")\n",
    "\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "os.makedirs(output_csv, exist_ok=True)\n",
    "os.makedirs(output_graphs, exist_ok=True)\n",
    "\n",
    "# ==========================================================\n",
    "# ğŸ§® Helper Functions\n",
    "# ==========================================================\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    mask = y_true != 0\n",
    "    return np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100 if np.any(mask) else np.nan\n",
    "\n",
    "def parse_dates_safe(series):\n",
    "    try:\n",
    "        return pd.to_datetime(series, dayfirst=True)\n",
    "    except:\n",
    "        return pd.to_datetime(series, dayfirst=False)\n",
    "\n",
    "# ==========================================================\n",
    "# ğŸ“˜ Load Dataset\n",
    "# ==========================================================\n",
    "print(f\"ğŸ“˜ Loading dataset: {input_file}\")\n",
    "df = pd.read_excel(input_file)\n",
    "df.columns = [col.strip().lower() for col in df.columns]\n",
    "\n",
    "required_cols = ['date', 'district', 'crop_type', 'average']\n",
    "if not all(col in df.columns for col in required_cols):\n",
    "    raise ValueError(f\"âŒ Missing required columns: {required_cols}\")\n",
    "\n",
    "df['date'] = parse_dates_safe(df['date'])\n",
    "df = df.sort_values('date')\n",
    "df = df.dropna(subset=['average'])\n",
    "\n",
    "# ==========================================================\n",
    "# ğŸ“Š Metrics Storage\n",
    "# ==========================================================\n",
    "metrics_list = []\n",
    "\n",
    "# ==========================================================\n",
    "# ğŸ” SARIMAX per (District Ã— Crop)\n",
    "# ==========================================================\n",
    "groups = df.groupby(['district', 'crop_type'])\n",
    "\n",
    "for (district, crop), group in groups:\n",
    "    print(f\"\\nğŸš€ Processing: District = {district} | Crop = {crop}\")\n",
    "\n",
    "    data = group.copy().sort_values('date')\n",
    "    data = data.groupby('date', as_index=False).mean(numeric_only=True)\n",
    "    data.set_index('date', inplace=True)\n",
    "    data = data.asfreq('D')\n",
    "\n",
    "    # Fill missing values\n",
    "    data['average'] = data['average'].ffill().bfill().fillna(data['average'].mean())\n",
    "\n",
    "    # âœ… Handle sparse data (less than 10 valid points)\n",
    "    if data['average'].count() < 10:\n",
    "        print(f\"âš ï¸ {district} - {crop}: Not enough data, using crop-level or global average.\")\n",
    "        crop_level = df[df['crop_type'] == crop].groupby('date', as_index=False)['average'].mean()\n",
    "        if crop_level.empty:\n",
    "            print(f\"âš ï¸ {district} - {crop}: No crop-level data found. Using overall average.\")\n",
    "            crop_level = df.groupby('date', as_index=False)['average'].mean()\n",
    "        crop_level.set_index('date', inplace=True)\n",
    "        crop_level = crop_level.asfreq('D')\n",
    "        crop_level['average'] = crop_level['average'].ffill().bfill().fillna(crop_level['average'].mean())\n",
    "        data = crop_level.copy()\n",
    "\n",
    "    # ==========================================================\n",
    "    # ğŸ§© Feature Engineering\n",
    "    # ==========================================================\n",
    "    data['Lag_1'] = data['average'].shift(1)\n",
    "    data['Lag_7'] = data['average'].shift(7)\n",
    "    data['MA_7'] = data['average'].rolling(window=7).mean()\n",
    "    data['MA_30'] = data['average'].rolling(window=30).mean()\n",
    "    data[['Lag_1', 'Lag_7', 'MA_7', 'MA_30']] = data[['Lag_1', 'Lag_7', 'MA_7', 'MA_30']].bfill().ffill()\n",
    "\n",
    "    # Exogenous regressors\n",
    "    exog = data[['Lag_1', 'Lag_7', 'MA_7', 'MA_30']]\n",
    "\n",
    "    # ==========================================================\n",
    "    # âš™ï¸ SARIMAX Model\n",
    "    # ==========================================================\n",
    "    y = data['average'].values\n",
    "    try:\n",
    "        model = SARIMAX(y, exog=exog, order=(1, 1, 1), seasonal_order=(0, 1, 1, 7), enforce_stationarity=False, enforce_invertibility=False)\n",
    "        model_fit = model.fit(disp=False)\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Skipping {district} - {crop} due to SARIMAX fit error: {e}\")\n",
    "        continue\n",
    "\n",
    "    # ==========================================================\n",
    "    # ğŸ”¢ Predictions\n",
    "    # ==========================================================\n",
    "    predictions = model_fit.predict(start=0, end=len(y)-1, exog=exog)\n",
    "    predictions = predictions[:len(y)]\n",
    "\n",
    "    data['Predicted'] = predictions.round(2)\n",
    "\n",
    "    # ==========================================================\n",
    "    # ğŸ“ˆ Metrics\n",
    "    # ==========================================================\n",
    "    y_true = data['average'].values\n",
    "    y_pred = data['Predicted'].values\n",
    "\n",
    "    mae = round(mean_absolute_error(y_true, y_pred), 2)\n",
    "    rmse = round(np.sqrt(mean_squared_error(y_true, y_pred)), 2)\n",
    "    r2 = round(r2_score(y_true, y_pred), 4)\n",
    "    mape = round(mean_absolute_percentage_error(y_true, y_pred), 2)\n",
    "    accuracy = round(100 - mape, 2)\n",
    "\n",
    "    metrics_list.append({\n",
    "        'District': district,\n",
    "        'Crop': crop,\n",
    "        'MAE': mae,\n",
    "        'RMSE': rmse,\n",
    "        'R2': r2,\n",
    "        'MAPE(%)': mape,\n",
    "        'Accuracy(%)': accuracy\n",
    "    })\n",
    "\n",
    "    print(f\"âœ… {district} - {crop} | MAE={mae}, RMSE={rmse}, RÂ²={r2}, MAPE={mape}%, Accuracy={accuracy}%\")\n",
    "\n",
    "    # ==========================================================\n",
    "    # ğŸ’¾ Save Predictions\n",
    "    # ==========================================================\n",
    "    data.reset_index().to_csv(os.path.join(output_csv, f\"{district}_{crop}_sarimax_daily.csv\"), index=False, float_format='%.2f')\n",
    "\n",
    "    # ==========================================================\n",
    "    # ğŸ”® Future Forecast (30 days)\n",
    "    # ==========================================================\n",
    "    try:\n",
    "        future_exog = exog.tail(30).copy()\n",
    "        future_exog = pd.concat([future_exog]*2, ignore_index=True).iloc[:30]  # reuse recent pattern\n",
    "        forecast = model_fit.forecast(steps=30, exog=future_exog)\n",
    "        future_dates = pd.date_range(start=data.index[-1] + pd.Timedelta(days=1), periods=30, freq='D')\n",
    "        forecast_df = pd.DataFrame({'Date': future_dates, 'Forecast': forecast.round(2)})\n",
    "        forecast_df['District'] = district\n",
    "        forecast_df['Crop'] = crop\n",
    "        forecast_df.to_csv(os.path.join(output_csv, f\"{district}_{crop}_sarimax_future.csv\"), index=False, float_format='%.2f')\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Could not generate future forecast for {district}-{crop}: {e}\")\n",
    "\n",
    "    # ==========================================================\n",
    "    # ğŸ“Š Plot Graph\n",
    "    # ==========================================================\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.plot(data.index, data['average'], label='Actual', color='blue')\n",
    "    plt.plot(data.index, data['Predicted'], label='Predicted (SARIMAX)', color='red', linestyle='dashed')\n",
    "    if 'forecast_df' in locals():\n",
    "        plt.plot(forecast_df['Date'], forecast_df['Forecast'], label='Future Forecast (30 days)', color='green', linestyle='dotted')\n",
    "    plt.title(f\"SARIMAX Forecast - {district} | {crop}\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Average Price\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_graphs, f\"{district}_{crop}_sarimax_graph.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    del data, y, model, model_fit, exog\n",
    "    gc.collect()\n",
    "\n",
    "# ==========================================================\n",
    "# ğŸ§¾ Save Metrics\n",
    "# ==========================================================\n",
    "metrics_df = pd.DataFrame(metrics_list).round(2)\n",
    "metrics_df.to_csv(metrics_file, index=False)\n",
    "print(f\"\\nğŸ“Š All combinations processed successfully!\")\n",
    "print(f\"âœ… Metrics saved to: {metrics_file}\")\n",
    "print(metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b7aa63-27da-45fc-8a4b-b703e4381524",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TAT+MHA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "495e9c8f-2c7e-479a-a6fc-8b3aba2684c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Loading dataset: dataset/Crop_price_forecast_Daily.xlsx\n",
      "\n",
      "ğŸš€ Processing: All Districts | full_state\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 0.0543 - mae: 0.1353 - val_loss: 0.0222 - val_mae: 0.1139 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0056 - mae: 0.0581 - val_loss: 0.0141 - val_mae: 0.0918 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0043 - mae: 0.0517 - val_loss: 0.0135 - val_mae: 0.0924 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0029 - mae: 0.0429 - val_loss: 0.0100 - val_mae: 0.0800 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - loss: 0.0020 - mae: 0.0350 - val_loss: 0.0074 - val_mae: 0.0687 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0014 - mae: 0.0298 - val_loss: 0.0042 - val_mae: 0.0455 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0012 - mae: 0.0276 - val_loss: 0.0027 - val_mae: 0.0372 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0012 - mae: 0.0271 - val_loss: 0.0040 - val_mae: 0.0484 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0011 - mae: 0.0260 - val_loss: 0.0057 - val_mae: 0.0622 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 9.0996e-04 - mae: 0.0238 - val_loss: 0.0052 - val_mae: 0.0605 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 7.8823e-04 - mae: 0.0221 - val_loss: 0.0023 - val_mae: 0.0353 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 7.8243e-04 - mae: 0.0219 - val_loss: 0.0037 - val_mae: 0.0494 - learning_rate: 0.0010\n",
      "Epoch 13/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 7.3432e-04 - mae: 0.0212 - val_loss: 0.0017 - val_mae: 0.0312 - learning_rate: 0.0010\n",
      "Epoch 14/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 7.1028e-04 - mae: 0.0208 - val_loss: 0.0018 - val_mae: 0.0326 - learning_rate: 0.0010\n",
      "Epoch 15/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6.1309e-04 - mae: 0.0194 - val_loss: 0.0027 - val_mae: 0.0418 - learning_rate: 0.0010\n",
      "Epoch 16/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 5.3376e-04 - mae: 0.0179 - val_loss: 0.0013 - val_mae: 0.0282 - learning_rate: 0.0010\n",
      "Epoch 17/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 6.8968e-04 - mae: 0.0205 - val_loss: 0.0014 - val_mae: 0.0286 - learning_rate: 0.0010\n",
      "Epoch 18/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 5.3435e-04 - mae: 0.0179 - val_loss: 0.0011 - val_mae: 0.0267 - learning_rate: 0.0010\n",
      "Epoch 19/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 5.3215e-04 - mae: 0.0179 - val_loss: 0.0012 - val_mae: 0.0262 - learning_rate: 0.0010\n",
      "Epoch 20/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 4.6189e-04 - mae: 0.0166 - val_loss: 0.0011 - val_mae: 0.0260 - learning_rate: 0.0010\n",
      "Epoch 21/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 4.9208e-04 - mae: 0.0172 - val_loss: 0.0016 - val_mae: 0.0319 - learning_rate: 0.0010\n",
      "Epoch 22/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 4.8779e-04 - mae: 0.0172 - val_loss: 0.0032 - val_mae: 0.0484 - learning_rate: 0.0010\n",
      "Epoch 23/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 4.2423e-04 - mae: 0.0159 - val_loss: 0.0010 - val_mae: 0.0248 - learning_rate: 5.0000e-04\n",
      "Epoch 24/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 3.6540e-04 - mae: 0.0148 - val_loss: 9.8147e-04 - val_mae: 0.0244 - learning_rate: 5.0000e-04\n",
      "Epoch 25/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 3.5870e-04 - mae: 0.0145 - val_loss: 0.0011 - val_mae: 0.0257 - learning_rate: 5.0000e-04\n",
      "Epoch 26/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 3.9395e-04 - mae: 0.0153 - val_loss: 0.0012 - val_mae: 0.0261 - learning_rate: 5.0000e-04\n",
      "Epoch 27/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 4.1869e-04 - mae: 0.0158 - val_loss: 0.0018 - val_mae: 0.0348 - learning_rate: 5.0000e-04\n",
      "Epoch 28/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 3.0588e-04 - mae: 0.0134 - val_loss: 9.2627e-04 - val_mae: 0.0236 - learning_rate: 2.5000e-04\n",
      "Epoch 29/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 2.7847e-04 - mae: 0.0127 - val_loss: 9.1598e-04 - val_mae: 0.0233 - learning_rate: 2.5000e-04\n",
      "Epoch 30/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 2.8959e-04 - mae: 0.0130 - val_loss: 0.0010 - val_mae: 0.0241 - learning_rate: 2.5000e-04\n",
      "Epoch 31/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 2.9167e-04 - mae: 0.0131 - val_loss: 8.9786e-04 - val_mae: 0.0233 - learning_rate: 2.5000e-04\n",
      "Epoch 32/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 2.8563e-04 - mae: 0.0130 - val_loss: 9.0393e-04 - val_mae: 0.0233 - learning_rate: 2.5000e-04\n",
      "Epoch 33/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 3.0316e-04 - mae: 0.0134 - val_loss: 8.8747e-04 - val_mae: 0.0231 - learning_rate: 2.5000e-04\n",
      "Epoch 34/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 2.5313e-04 - mae: 0.0121 - val_loss: 8.9407e-04 - val_mae: 0.0229 - learning_rate: 1.2500e-04\n",
      "Epoch 35/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 2.4992e-04 - mae: 0.0121 - val_loss: 9.3338e-04 - val_mae: 0.0232 - learning_rate: 1.2500e-04\n",
      "Epoch 36/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 2.5078e-04 - mae: 0.0121 - val_loss: 9.4436e-04 - val_mae: 0.0234 - learning_rate: 1.2500e-04\n",
      "Epoch 37/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 2.6063e-04 - mae: 0.0123 - val_loss: 9.0263e-04 - val_mae: 0.0229 - learning_rate: 1.2500e-04\n",
      "Epoch 38/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 2.5795e-04 - mae: 0.0123 - val_loss: 8.9197e-04 - val_mae: 0.0228 - learning_rate: 6.2500e-05\n",
      "Epoch 39/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 2.4444e-04 - mae: 0.0120 - val_loss: 9.1191e-04 - val_mae: 0.0229 - learning_rate: 6.2500e-05\n",
      "Epoch 40/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 2.5535e-04 - mae: 0.0123 - val_loss: 8.9998e-04 - val_mae: 0.0228 - learning_rate: 6.2500e-05\n",
      "Epoch 41/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 2.4494e-04 - mae: 0.0120 - val_loss: 8.8720e-04 - val_mae: 0.0227 - learning_rate: 6.2500e-05\n",
      "Epoch 42/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 2.3772e-04 - mae: 0.0119 - val_loss: 8.8618e-04 - val_mae: 0.0230 - learning_rate: 3.1250e-05\n",
      "Epoch 43/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 2.3756e-04 - mae: 0.0118 - val_loss: 8.8283e-04 - val_mae: 0.0229 - learning_rate: 3.1250e-05\n",
      "Epoch 44/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 2.3819e-04 - mae: 0.0117 - val_loss: 8.8283e-04 - val_mae: 0.0229 - learning_rate: 3.1250e-05\n",
      "Epoch 45/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 2.3880e-04 - mae: 0.0117 - val_loss: 9.0105e-04 - val_mae: 0.0228 - learning_rate: 3.1250e-05\n",
      "Epoch 46/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 2.3311e-04 - mae: 0.0117 - val_loss: 8.9539e-04 - val_mae: 0.0231 - learning_rate: 1.5625e-05\n",
      "Epoch 47/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 2.3446e-04 - mae: 0.0117 - val_loss: 9.2430e-04 - val_mae: 0.0237 - learning_rate: 1.5625e-05\n",
      "Epoch 48/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 2.3584e-04 - mae: 0.0116 - val_loss: 9.1237e-04 - val_mae: 0.0235 - learning_rate: 1.5625e-05\n",
      "Epoch 49/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 2.3353e-04 - mae: 0.0116 - val_loss: 9.0386e-04 - val_mae: 0.0233 - learning_rate: 1.5625e-05\n",
      "Epoch 50/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 2.3076e-04 - mae: 0.0115 - val_loss: 8.9291e-04 - val_mae: 0.0229 - learning_rate: 7.8125e-06\n",
      "Epoch 51/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 2.2996e-04 - mae: 0.0117 - val_loss: 8.9097e-04 - val_mae: 0.0229 - learning_rate: 7.8125e-06\n",
      "Epoch 52/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 2.3022e-04 - mae: 0.0116 - val_loss: 8.8990e-04 - val_mae: 0.0229 - learning_rate: 7.8125e-06\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step   \n",
      "âœ… All Districts - full_state | MAE=48.85, RMSE=64.51, RÂ²=0.987, MAPE=2.57%, Acc=97.43%\n",
      "\n",
      "ğŸš€ Processing: Bagalkot | onion\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 0.1177 - mae: 0.1621 - val_loss: 0.0015 - val_mae: 0.0283 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0064 - mae: 0.0617 - val_loss: 0.0011 - val_mae: 0.0206 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0052 - mae: 0.0555 - val_loss: 0.0026 - val_mae: 0.0461 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0044 - mae: 0.0520 - val_loss: 8.8303e-04 - val_mae: 0.0206 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0041 - mae: 0.0502 - val_loss: 0.0064 - val_mae: 0.0759 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0034 - mae: 0.0450 - val_loss: 0.0043 - val_mae: 0.0613 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0028 - mae: 0.0413 - val_loss: 7.9213e-04 - val_mae: 0.0217 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0025 - mae: 0.0387 - val_loss: 7.9619e-04 - val_mae: 0.0216 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0019 - mae: 0.0340 - val_loss: 9.8446e-04 - val_mae: 0.0262 - learning_rate: 5.0000e-04\n",
      "Epoch 10/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0330 - val_loss: 8.5670e-04 - val_mae: 0.0231 - learning_rate: 5.0000e-04\n",
      "Epoch 11/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0017 - mae: 0.0321 - val_loss: 0.0021 - val_mae: 0.0422 - learning_rate: 5.0000e-04\n",
      "Epoch 12/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0017 - mae: 0.0316 - val_loss: 5.3477e-04 - val_mae: 0.0126 - learning_rate: 5.0000e-04\n",
      "Epoch 13/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0015 - mae: 0.0302 - val_loss: 4.8398e-04 - val_mae: 0.0141 - learning_rate: 5.0000e-04\n",
      "Epoch 14/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0014 - mae: 0.0288 - val_loss: 4.8561e-04 - val_mae: 0.0123 - learning_rate: 5.0000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0015 - mae: 0.0297 - val_loss: 0.0016 - val_mae: 0.0377 - learning_rate: 5.0000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0017 - mae: 0.0318 - val_loss: 0.0013 - val_mae: 0.0294 - learning_rate: 5.0000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0267 - val_loss: 3.9469e-04 - val_mae: 0.0116 - learning_rate: 2.5000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0012 - mae: 0.0267 - val_loss: 4.0114e-04 - val_mae: 0.0120 - learning_rate: 2.5000e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0012 - mae: 0.0264 - val_loss: 0.0019 - val_mae: 0.0406 - learning_rate: 2.5000e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0012 - mae: 0.0261 - val_loss: 0.0011 - val_mae: 0.0287 - learning_rate: 2.5000e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0011 - mae: 0.0251 - val_loss: 5.9226e-04 - val_mae: 0.0166 - learning_rate: 2.5000e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0010 - mae: 0.0242 - val_loss: 3.9334e-04 - val_mae: 0.0124 - learning_rate: 1.2500e-04\n",
      "Epoch 23/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 9.4493e-04 - mae: 0.0233 - val_loss: 3.6962e-04 - val_mae: 0.0112 - learning_rate: 1.2500e-04\n",
      "Epoch 24/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 9.3222e-04 - mae: 0.0231 - val_loss: 6.8644e-04 - val_mae: 0.0209 - learning_rate: 1.2500e-04\n",
      "Epoch 25/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 9.7910e-04 - mae: 0.0236 - val_loss: 3.5529e-04 - val_mae: 0.0119 - learning_rate: 1.2500e-04\n",
      "Epoch 26/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 9.0737e-04 - mae: 0.0224 - val_loss: 4.1869e-04 - val_mae: 0.0152 - learning_rate: 6.2500e-05\n",
      "Epoch 27/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 8.6549e-04 - mae: 0.0221 - val_loss: 3.9548e-04 - val_mae: 0.0139 - learning_rate: 6.2500e-05\n",
      "Epoch 28/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 8.5660e-04 - mae: 0.0219 - val_loss: 4.4160e-04 - val_mae: 0.0164 - learning_rate: 6.2500e-05\n",
      "Epoch 29/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 8.7539e-04 - mae: 0.0222 - val_loss: 3.4796e-04 - val_mae: 0.0109 - learning_rate: 6.2500e-05\n",
      "Epoch 30/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 8.4890e-04 - mae: 0.0218 - val_loss: 3.4792e-04 - val_mae: 0.0114 - learning_rate: 3.1250e-05\n",
      "Epoch 31/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 8.8009e-04 - mae: 0.0219 - val_loss: 3.4658e-04 - val_mae: 0.0110 - learning_rate: 3.1250e-05\n",
      "Epoch 32/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.3640e-04 - mae: 0.0214 - val_loss: 3.5369e-04 - val_mae: 0.0111 - learning_rate: 3.1250e-05\n",
      "Epoch 33/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 8.1478e-04 - mae: 0.0216 - val_loss: 3.8763e-04 - val_mae: 0.0143 - learning_rate: 3.1250e-05\n",
      "Epoch 34/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 8.0581e-04 - mae: 0.0214 - val_loss: 3.5328e-04 - val_mae: 0.0122 - learning_rate: 1.5625e-05\n",
      "Epoch 35/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 8.2747e-04 - mae: 0.0212 - val_loss: 3.5510e-04 - val_mae: 0.0110 - learning_rate: 1.5625e-05\n",
      "Epoch 36/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 7.9790e-04 - mae: 0.0209 - val_loss: 3.4340e-04 - val_mae: 0.0113 - learning_rate: 1.5625e-05\n",
      "Epoch 37/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 8.3592e-04 - mae: 0.0216 - val_loss: 3.4565e-04 - val_mae: 0.0107 - learning_rate: 1.5625e-05\n",
      "Epoch 38/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 8.0533e-04 - mae: 0.0211 - val_loss: 3.6356e-04 - val_mae: 0.0129 - learning_rate: 7.8125e-06\n",
      "Epoch 39/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 7.8692e-04 - mae: 0.0209 - val_loss: 3.4600e-04 - val_mae: 0.0110 - learning_rate: 7.8125e-06\n",
      "Epoch 40/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 7.9716e-04 - mae: 0.0209 - val_loss: 3.4958e-04 - val_mae: 0.0119 - learning_rate: 7.8125e-06\n",
      "Epoch 41/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 7.8791e-04 - mae: 0.0208 - val_loss: 3.4821e-04 - val_mae: 0.0119 - learning_rate: 7.8125e-06\n",
      "Epoch 42/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 7.9352e-04 - mae: 0.0209 - val_loss: 3.4609e-04 - val_mae: 0.0115 - learning_rate: 3.9063e-06\n",
      "Epoch 43/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 7.9563e-04 - mae: 0.0208 - val_loss: 3.5055e-04 - val_mae: 0.0117 - learning_rate: 3.9063e-06\n",
      "Epoch 44/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 7.9032e-04 - mae: 0.0208 - val_loss: 3.4957e-04 - val_mae: 0.0114 - learning_rate: 3.9063e-06\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step   \n",
      "âœ… Bagalkot - onion | MAE=85.96, RMSE=142.76, RÂ²=0.9611, MAPE=7.47%, Acc=92.53%\n",
      "\n",
      "ğŸš€ Processing: Bagalkot | wheat\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0592 - mae: 0.1373 - val_loss: 0.0182 - val_mae: 0.0796 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0039 - mae: 0.0467 - val_loss: 0.0109 - val_mae: 0.0727 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0028 - mae: 0.0383 - val_loss: 0.0090 - val_mae: 0.0570 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0024 - mae: 0.0355 - val_loss: 0.0072 - val_mae: 0.0598 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0019 - mae: 0.0315 - val_loss: 0.0074 - val_mae: 0.0500 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0018 - mae: 0.0299 - val_loss: 0.0064 - val_mae: 0.0472 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0015 - mae: 0.0265 - val_loss: 0.0049 - val_mae: 0.0433 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0013 - mae: 0.0243 - val_loss: 0.0049 - val_mae: 0.0417 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mae: 0.0263 - val_loss: 0.0050 - val_mae: 0.0373 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0012 - mae: 0.0229 - val_loss: 0.0036 - val_mae: 0.0364 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mae: 0.0233 - val_loss: 0.0043 - val_mae: 0.0353 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0011 - mae: 0.0220 - val_loss: 0.0036 - val_mae: 0.0325 - learning_rate: 0.0010\n",
      "Epoch 13/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 9.4497e-04 - mae: 0.0192 - val_loss: 0.0039 - val_mae: 0.0358 - learning_rate: 0.0010\n",
      "Epoch 14/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 9.3043e-04 - mae: 0.0189 - val_loss: 0.0029 - val_mae: 0.0282 - learning_rate: 0.0010\n",
      "Epoch 15/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0010 - mae: 0.0210 - val_loss: 0.0026 - val_mae: 0.0283 - learning_rate: 0.0010\n",
      "Epoch 16/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 9.8074e-04 - mae: 0.0198 - val_loss: 0.0025 - val_mae: 0.0283 - learning_rate: 0.0010\n",
      "Epoch 17/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0010 - mae: 0.0204 - val_loss: 0.0022 - val_mae: 0.0326 - learning_rate: 0.0010\n",
      "Epoch 18/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.8991e-04 - mae: 0.0198 - val_loss: 0.0024 - val_mae: 0.0243 - learning_rate: 0.0010\n",
      "Epoch 19/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.3576e-04 - mae: 0.0173 - val_loss: 0.0020 - val_mae: 0.0257 - learning_rate: 0.0010\n",
      "Epoch 20/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 9.1579e-04 - mae: 0.0189 - val_loss: 0.0020 - val_mae: 0.0231 - learning_rate: 0.0010\n",
      "Epoch 21/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 8.4068e-04 - mae: 0.0174 - val_loss: 0.0018 - val_mae: 0.0255 - learning_rate: 0.0010\n",
      "Epoch 22/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 9.0204e-04 - mae: 0.0183 - val_loss: 0.0019 - val_mae: 0.0239 - learning_rate: 0.0010\n",
      "Epoch 23/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.1711e-04 - mae: 0.0168 - val_loss: 0.0017 - val_mae: 0.0239 - learning_rate: 0.0010\n",
      "Epoch 24/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 8.1991e-04 - mae: 0.0171 - val_loss: 0.0016 - val_mae: 0.0237 - learning_rate: 0.0010\n",
      "Epoch 25/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 7.4065e-04 - mae: 0.0158 - val_loss: 0.0015 - val_mae: 0.0255 - learning_rate: 0.0010\n",
      "Epoch 26/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 8.9673e-04 - mae: 0.0185 - val_loss: 0.0017 - val_mae: 0.0200 - learning_rate: 0.0010\n",
      "Epoch 27/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 8.3196e-04 - mae: 0.0174 - val_loss: 0.0016 - val_mae: 0.0206 - learning_rate: 0.0010\n",
      "Epoch 28/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 8.1734e-04 - mae: 0.0165 - val_loss: 0.0014 - val_mae: 0.0209 - learning_rate: 0.0010\n",
      "Epoch 29/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 7.4361e-04 - mae: 0.0158 - val_loss: 0.0012 - val_mae: 0.0235 - learning_rate: 0.0010\n",
      "Epoch 30/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 7.0975e-04 - mae: 0.0150 - val_loss: 0.0012 - val_mae: 0.0198 - learning_rate: 0.0010\n",
      "Epoch 31/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 6.8049e-04 - mae: 0.0149 - val_loss: 0.0011 - val_mae: 0.0178 - learning_rate: 0.0010\n",
      "Epoch 32/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 7.5688e-04 - mae: 0.0159 - val_loss: 0.0011 - val_mae: 0.0168 - learning_rate: 0.0010\n",
      "Epoch 33/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 6.6943e-04 - mae: 0.0144 - val_loss: 0.0012 - val_mae: 0.0183 - learning_rate: 0.0010\n",
      "Epoch 34/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 7.2233e-04 - mae: 0.0154 - val_loss: 0.0010 - val_mae: 0.0191 - learning_rate: 0.0010\n",
      "Epoch 35/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 7.4569e-04 - mae: 0.0159 - val_loss: 0.0010 - val_mae: 0.0190 - learning_rate: 0.0010\n",
      "Epoch 36/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 7.4165e-04 - mae: 0.0161 - val_loss: 9.7189e-04 - val_mae: 0.0170 - learning_rate: 0.0010\n",
      "Epoch 37/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 5.2630e-04 - mae: 0.0116 - val_loss: 9.8886e-04 - val_mae: 0.0193 - learning_rate: 5.0000e-04\n",
      "Epoch 38/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 5.4094e-04 - mae: 0.0127 - val_loss: 0.0010 - val_mae: 0.0161 - learning_rate: 5.0000e-04\n",
      "Epoch 39/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 5.1592e-04 - mae: 0.0119 - val_loss: 0.0010 - val_mae: 0.0162 - learning_rate: 5.0000e-04\n",
      "Epoch 40/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 5.1813e-04 - mae: 0.0121 - val_loss: 0.0013 - val_mae: 0.0184 - learning_rate: 5.0000e-04\n",
      "Epoch 41/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 5.0109e-04 - mae: 0.0109 - val_loss: 0.0012 - val_mae: 0.0197 - learning_rate: 2.5000e-04\n",
      "Epoch 42/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 4.9567e-04 - mae: 0.0107 - val_loss: 0.0010 - val_mae: 0.0172 - learning_rate: 2.5000e-04\n",
      "Epoch 43/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 4.5947e-04 - mae: 0.0107 - val_loss: 9.4383e-04 - val_mae: 0.0185 - learning_rate: 2.5000e-04\n",
      "Epoch 44/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.4253e-04 - mae: 0.0106 - val_loss: 9.2593e-04 - val_mae: 0.0184 - learning_rate: 2.5000e-04\n",
      "Epoch 45/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 4.6286e-04 - mae: 0.0111 - val_loss: 9.3371e-04 - val_mae: 0.0196 - learning_rate: 2.5000e-04\n",
      "Epoch 46/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.4643e-04 - mae: 0.0107 - val_loss: 9.5208e-04 - val_mae: 0.0204 - learning_rate: 2.5000e-04\n",
      "Epoch 47/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 4.6138e-04 - mae: 0.0110 - val_loss: 9.6926e-04 - val_mae: 0.0183 - learning_rate: 2.5000e-04\n",
      "Epoch 48/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 4.1948e-04 - mae: 0.0102 - val_loss: 9.2859e-04 - val_mae: 0.0206 - learning_rate: 1.2500e-04\n",
      "Epoch 49/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 3.9974e-04 - mae: 0.0100 - val_loss: 0.0013 - val_mae: 0.0218 - learning_rate: 1.2500e-04\n",
      "Epoch 50/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 4.3097e-04 - mae: 0.0101 - val_loss: 0.0011 - val_mae: 0.0182 - learning_rate: 1.2500e-04\n",
      "Epoch 51/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 4.2538e-04 - mae: 0.0098 - val_loss: 9.4869e-04 - val_mae: 0.0189 - learning_rate: 1.2500e-04\n",
      "Epoch 52/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 4.0577e-04 - mae: 0.0095 - val_loss: 9.0076e-04 - val_mae: 0.0166 - learning_rate: 6.2500e-05\n",
      "Epoch 53/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 3.9378e-04 - mae: 0.0096 - val_loss: 9.2410e-04 - val_mae: 0.0156 - learning_rate: 6.2500e-05\n",
      "Epoch 54/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 3.8512e-04 - mae: 0.0096 - val_loss: 0.0011 - val_mae: 0.0175 - learning_rate: 6.2500e-05\n",
      "Epoch 55/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 4.0692e-04 - mae: 0.0097 - val_loss: 8.9838e-04 - val_mae: 0.0162 - learning_rate: 6.2500e-05\n",
      "Epoch 56/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 4.0349e-04 - mae: 0.0093 - val_loss: 8.7459e-04 - val_mae: 0.0177 - learning_rate: 3.1250e-05\n",
      "Epoch 57/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 3.9192e-04 - mae: 0.0092 - val_loss: 9.6054e-04 - val_mae: 0.0197 - learning_rate: 3.1250e-05\n",
      "Epoch 58/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 3.6507e-04 - mae: 0.0091 - val_loss: 0.0012 - val_mae: 0.0205 - learning_rate: 3.1250e-05\n",
      "Epoch 59/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 3.6367e-04 - mae: 0.0092 - val_loss: 9.8497e-04 - val_mae: 0.0189 - learning_rate: 3.1250e-05\n",
      "Epoch 60/60\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 3.3730e-04 - mae: 0.0089 - val_loss: 0.0012 - val_mae: 0.0197 - learning_rate: 1.5625e-05\n",
      "\u001b[1m76/76\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step   \n",
      "âœ… Bagalkot - wheat | MAE=50.18, RMSE=90.65, RÂ²=0.9678, MAPE=2.39%, Acc=97.61%\n",
      "\n",
      "ğŸš€ Processing: Bangalore | capsicum\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - loss: 0.0473 - mae: 0.1364 - val_loss: 0.0055 - val_mae: 0.0521 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0077 - mae: 0.0666 - val_loss: 0.0064 - val_mae: 0.0641 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0064 - mae: 0.0613 - val_loss: 0.0065 - val_mae: 0.0649 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0057 - mae: 0.0575 - val_loss: 0.0053 - val_mae: 0.0568 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0048 - mae: 0.0528 - val_loss: 0.0055 - val_mae: 0.0583 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0046 - mae: 0.0517 - val_loss: 0.0050 - val_mae: 0.0548 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0042 - mae: 0.0488 - val_loss: 0.0062 - val_mae: 0.0630 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0041 - mae: 0.0487 - val_loss: 0.0049 - val_mae: 0.0549 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0037 - mae: 0.0461 - val_loss: 0.0047 - val_mae: 0.0532 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0035 - mae: 0.0445 - val_loss: 0.0042 - val_mae: 0.0493 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0036 - mae: 0.0457 - val_loss: 0.0041 - val_mae: 0.0486 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0032 - mae: 0.0424 - val_loss: 0.0040 - val_mae: 0.0484 - learning_rate: 0.0010\n",
      "Epoch 13/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0030 - mae: 0.0411 - val_loss: 0.0042 - val_mae: 0.0500 - learning_rate: 0.0010\n",
      "Epoch 14/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0029 - mae: 0.0398 - val_loss: 0.0037 - val_mae: 0.0456 - learning_rate: 0.0010\n",
      "Epoch 15/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0031 - mae: 0.0413 - val_loss: 0.0037 - val_mae: 0.0457 - learning_rate: 0.0010\n",
      "Epoch 16/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0028 - mae: 0.0393 - val_loss: 0.0043 - val_mae: 0.0510 - learning_rate: 0.0010\n",
      "Epoch 17/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0030 - mae: 0.0411 - val_loss: 0.0038 - val_mae: 0.0473 - learning_rate: 0.0010\n",
      "Epoch 18/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0028 - mae: 0.0390 - val_loss: 0.0037 - val_mae: 0.0453 - learning_rate: 0.0010\n",
      "Epoch 19/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0022 - mae: 0.0336 - val_loss: 0.0040 - val_mae: 0.0485 - learning_rate: 5.0000e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0022 - mae: 0.0338 - val_loss: 0.0048 - val_mae: 0.0547 - learning_rate: 5.0000e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0022 - mae: 0.0339 - val_loss: 0.0050 - val_mae: 0.0562 - learning_rate: 5.0000e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0023 - mae: 0.0353 - val_loss: 0.0058 - val_mae: 0.0618 - learning_rate: 5.0000e-04\n",
      "Epoch 23/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0021 - mae: 0.0330 - val_loss: 0.0031 - val_mae: 0.0411 - learning_rate: 2.5000e-04\n",
      "Epoch 24/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0019 - mae: 0.0318 - val_loss: 0.0030 - val_mae: 0.0405 - learning_rate: 2.5000e-04\n",
      "Epoch 25/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0020 - mae: 0.0316 - val_loss: 0.0031 - val_mae: 0.0408 - learning_rate: 2.5000e-04\n",
      "Epoch 26/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0020 - mae: 0.0320 - val_loss: 0.0031 - val_mae: 0.0407 - learning_rate: 2.5000e-04\n",
      "Epoch 27/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0020 - mae: 0.0314 - val_loss: 0.0030 - val_mae: 0.0405 - learning_rate: 2.5000e-04\n",
      "Epoch 28/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0019 - mae: 0.0308 - val_loss: 0.0030 - val_mae: 0.0404 - learning_rate: 1.2500e-04\n",
      "Epoch 29/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0019 - mae: 0.0310 - val_loss: 0.0030 - val_mae: 0.0407 - learning_rate: 1.2500e-04\n",
      "Epoch 30/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0019 - mae: 0.0308 - val_loss: 0.0030 - val_mae: 0.0410 - learning_rate: 1.2500e-04\n",
      "Epoch 31/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0019 - mae: 0.0310 - val_loss: 0.0029 - val_mae: 0.0399 - learning_rate: 1.2500e-04\n",
      "Epoch 32/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0019 - mae: 0.0308 - val_loss: 0.0029 - val_mae: 0.0395 - learning_rate: 1.2500e-04\n",
      "Epoch 33/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0019 - mae: 0.0308 - val_loss: 0.0029 - val_mae: 0.0396 - learning_rate: 1.2500e-04\n",
      "Epoch 34/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0019 - mae: 0.0310 - val_loss: 0.0028 - val_mae: 0.0389 - learning_rate: 1.2500e-04\n",
      "Epoch 35/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0018 - mae: 0.0307 - val_loss: 0.0029 - val_mae: 0.0394 - learning_rate: 1.2500e-04\n",
      "Epoch 36/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0029 - val_mae: 0.0394 - learning_rate: 1.2500e-04\n",
      "Epoch 37/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0018 - mae: 0.0296 - val_loss: 0.0029 - val_mae: 0.0392 - learning_rate: 6.2500e-05\n",
      "Epoch 38/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0018 - mae: 0.0298 - val_loss: 0.0028 - val_mae: 0.0386 - learning_rate: 6.2500e-05\n",
      "Epoch 39/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0018 - mae: 0.0297 - val_loss: 0.0028 - val_mae: 0.0390 - learning_rate: 6.2500e-05\n",
      "Epoch 40/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0300 - val_loss: 0.0028 - val_mae: 0.0387 - learning_rate: 6.2500e-05\n",
      "Epoch 41/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0017 - mae: 0.0294 - val_loss: 0.0028 - val_mae: 0.0389 - learning_rate: 3.1250e-05\n",
      "Epoch 42/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0017 - mae: 0.0292 - val_loss: 0.0028 - val_mae: 0.0386 - learning_rate: 3.1250e-05\n",
      "Epoch 43/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0017 - mae: 0.0294 - val_loss: 0.0028 - val_mae: 0.0387 - learning_rate: 3.1250e-05\n",
      "Epoch 44/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0017 - mae: 0.0293 - val_loss: 0.0028 - val_mae: 0.0387 - learning_rate: 3.1250e-05\n",
      "Epoch 45/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0017 - mae: 0.0294 - val_loss: 0.0028 - val_mae: 0.0387 - learning_rate: 1.5625e-05\n",
      "Epoch 46/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0017 - mae: 0.0290 - val_loss: 0.0028 - val_mae: 0.0388 - learning_rate: 1.5625e-05\n",
      "\u001b[1m83/83\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step   \n",
      "âœ… Bangalore - capsicum | MAE=221.93, RMSE=308.94, RÂ²=0.9107, MAPE=8.38%, Acc=91.62%\n",
      "\n",
      "ğŸš€ Processing: Bangalore | onion\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - loss: 0.0462 - mae: 0.1225 - val_loss: 0.0096 - val_mae: 0.0755 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0045 - mae: 0.0497 - val_loss: 0.0051 - val_mae: 0.0452 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0026 - mae: 0.0395 - val_loss: 0.0051 - val_mae: 0.0452 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0022 - mae: 0.0350 - val_loss: 0.0041 - val_mae: 0.0436 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0016 - mae: 0.0300 - val_loss: 0.0040 - val_mae: 0.0390 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0015 - mae: 0.0280 - val_loss: 0.0041 - val_mae: 0.0416 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0013 - mae: 0.0269 - val_loss: 0.0038 - val_mae: 0.0455 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0012 - mae: 0.0245 - val_loss: 0.0037 - val_mae: 0.0370 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0010 - mae: 0.0222 - val_loss: 0.0034 - val_mae: 0.0369 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0010 - mae: 0.0227 - val_loss: 0.0034 - val_mae: 0.0358 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 9.8437e-04 - mae: 0.0216 - val_loss: 0.0033 - val_mae: 0.0349 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 9.9474e-04 - mae: 0.0220 - val_loss: 0.0035 - val_mae: 0.0341 - learning_rate: 0.0010\n",
      "Epoch 13/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.4940e-04 - mae: 0.0211 - val_loss: 0.0034 - val_mae: 0.0332 - learning_rate: 0.0010\n",
      "Epoch 14/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.0088e-04 - mae: 0.0205 - val_loss: 0.0039 - val_mae: 0.0358 - learning_rate: 0.0010\n",
      "Epoch 15/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 8.7412e-04 - mae: 0.0199 - val_loss: 0.0035 - val_mae: 0.0330 - learning_rate: 0.0010\n",
      "Epoch 16/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 6.9195e-04 - mae: 0.0172 - val_loss: 0.0035 - val_mae: 0.0323 - learning_rate: 5.0000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 6.8572e-04 - mae: 0.0172 - val_loss: 0.0033 - val_mae: 0.0320 - learning_rate: 5.0000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 6.9736e-04 - mae: 0.0173 - val_loss: 0.0032 - val_mae: 0.0309 - learning_rate: 5.0000e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 6.9062e-04 - mae: 0.0174 - val_loss: 0.0032 - val_mae: 0.0313 - learning_rate: 5.0000e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 6.8572e-04 - mae: 0.0174 - val_loss: 0.0033 - val_mae: 0.0314 - learning_rate: 5.0000e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 7.0187e-04 - mae: 0.0176 - val_loss: 0.0033 - val_mae: 0.0315 - learning_rate: 5.0000e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 7.0194e-04 - mae: 0.0176 - val_loss: 0.0035 - val_mae: 0.0313 - learning_rate: 5.0000e-04\n",
      "Epoch 23/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 6.1967e-04 - mae: 0.0161 - val_loss: 0.0033 - val_mae: 0.0306 - learning_rate: 2.5000e-04\n",
      "Epoch 24/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 6.1155e-04 - mae: 0.0161 - val_loss: 0.0031 - val_mae: 0.0299 - learning_rate: 2.5000e-04\n",
      "Epoch 25/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 6.1280e-04 - mae: 0.0164 - val_loss: 0.0031 - val_mae: 0.0296 - learning_rate: 2.5000e-04\n",
      "Epoch 26/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 6.1870e-04 - mae: 0.0161 - val_loss: 0.0031 - val_mae: 0.0296 - learning_rate: 2.5000e-04\n",
      "Epoch 27/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 5.9047e-04 - mae: 0.0160 - val_loss: 0.0032 - val_mae: 0.0299 - learning_rate: 1.2500e-04\n",
      "Epoch 28/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 5.7218e-04 - mae: 0.0156 - val_loss: 0.0032 - val_mae: 0.0301 - learning_rate: 1.2500e-04\n",
      "Epoch 29/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 5.6306e-04 - mae: 0.0153 - val_loss: 0.0032 - val_mae: 0.0306 - learning_rate: 1.2500e-04\n",
      "Epoch 30/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 5.6793e-04 - mae: 0.0154 - val_loss: 0.0031 - val_mae: 0.0298 - learning_rate: 1.2500e-04\n",
      "Epoch 31/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 5.5237e-04 - mae: 0.0150 - val_loss: 0.0032 - val_mae: 0.0303 - learning_rate: 6.2500e-05\n",
      "Epoch 32/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 5.5021e-04 - mae: 0.0149 - val_loss: 0.0033 - val_mae: 0.0302 - learning_rate: 6.2500e-05\n",
      "Epoch 33/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 5.4572e-04 - mae: 0.0149 - val_loss: 0.0033 - val_mae: 0.0302 - learning_rate: 6.2500e-05\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step   \n",
      "âœ… Bangalore - onion | MAE=98.5, RMSE=192.54, RÂ²=0.9531, MAPE=5.06%, Acc=94.94%\n",
      "\n",
      "ğŸš€ Processing: Bangalore | tomato\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0577 - mae: 0.1290 - val_loss: 0.0131 - val_mae: 0.0664 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0054 - mae: 0.0559 - val_loss: 0.0084 - val_mae: 0.0578 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0045 - mae: 0.0512 - val_loss: 0.0087 - val_mae: 0.0575 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0039 - mae: 0.0474 - val_loss: 0.0079 - val_mae: 0.0578 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0030 - mae: 0.0418 - val_loss: 0.0108 - val_mae: 0.0742 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0030 - mae: 0.0414 - val_loss: 0.0082 - val_mae: 0.0574 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0023 - mae: 0.0364 - val_loss: 0.0085 - val_mae: 0.0601 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0025 - mae: 0.0383 - val_loss: 0.0077 - val_mae: 0.0538 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0022 - mae: 0.0350 - val_loss: 0.0074 - val_mae: 0.0509 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0021 - mae: 0.0348 - val_loss: 0.0083 - val_mae: 0.0593 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0019 - mae: 0.0325 - val_loss: 0.0067 - val_mae: 0.0492 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0017 - mae: 0.0310 - val_loss: 0.0078 - val_mae: 0.0594 - learning_rate: 0.0010\n",
      "Epoch 13/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0016 - mae: 0.0297 - val_loss: 0.0070 - val_mae: 0.0537 - learning_rate: 0.0010\n",
      "Epoch 14/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0016 - mae: 0.0297 - val_loss: 0.0070 - val_mae: 0.0542 - learning_rate: 0.0010\n",
      "Epoch 15/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0015 - mae: 0.0277 - val_loss: 0.0068 - val_mae: 0.0537 - learning_rate: 0.0010\n",
      "Epoch 16/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mae: 0.0258 - val_loss: 0.0062 - val_mae: 0.0471 - learning_rate: 5.0000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0012 - mae: 0.0249 - val_loss: 0.0060 - val_mae: 0.0463 - learning_rate: 5.0000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0012 - mae: 0.0247 - val_loss: 0.0063 - val_mae: 0.0477 - learning_rate: 5.0000e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0012 - mae: 0.0249 - val_loss: 0.0064 - val_mae: 0.0475 - learning_rate: 5.0000e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0012 - mae: 0.0248 - val_loss: 0.0073 - val_mae: 0.0546 - learning_rate: 5.0000e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0012 - mae: 0.0249 - val_loss: 0.0062 - val_mae: 0.0477 - learning_rate: 5.0000e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0011 - mae: 0.0235 - val_loss: 0.0055 - val_mae: 0.0435 - learning_rate: 2.5000e-04\n",
      "Epoch 23/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0010 - mae: 0.0222 - val_loss: 0.0054 - val_mae: 0.0436 - learning_rate: 2.5000e-04\n",
      "Epoch 24/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0010 - mae: 0.0222 - val_loss: 0.0052 - val_mae: 0.0428 - learning_rate: 2.5000e-04\n",
      "Epoch 25/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 9.7327e-04 - mae: 0.0217 - val_loss: 0.0053 - val_mae: 0.0434 - learning_rate: 2.5000e-04\n",
      "Epoch 26/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0010 - mae: 0.0224 - val_loss: 0.0053 - val_mae: 0.0428 - learning_rate: 2.5000e-04\n",
      "Epoch 27/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0011 - mae: 0.0228 - val_loss: 0.0051 - val_mae: 0.0421 - learning_rate: 2.5000e-04\n",
      "Epoch 28/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 9.6693e-04 - mae: 0.0215 - val_loss: 0.0050 - val_mae: 0.0422 - learning_rate: 2.5000e-04\n",
      "Epoch 29/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 9.9002e-04 - mae: 0.0221 - val_loss: 0.0051 - val_mae: 0.0422 - learning_rate: 2.5000e-04\n",
      "Epoch 30/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0011 - mae: 0.0230 - val_loss: 0.0051 - val_mae: 0.0418 - learning_rate: 2.5000e-04\n",
      "Epoch 31/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 9.7223e-04 - mae: 0.0217 - val_loss: 0.0047 - val_mae: 0.0405 - learning_rate: 2.5000e-04\n",
      "Epoch 32/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 9.4792e-04 - mae: 0.0216 - val_loss: 0.0049 - val_mae: 0.0409 - learning_rate: 2.5000e-04\n",
      "Epoch 33/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 9.6215e-04 - mae: 0.0218 - val_loss: 0.0049 - val_mae: 0.0404 - learning_rate: 2.5000e-04\n",
      "Epoch 34/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 9.3136e-04 - mae: 0.0210 - val_loss: 0.0048 - val_mae: 0.0405 - learning_rate: 2.5000e-04\n",
      "Epoch 35/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 8.9959e-04 - mae: 0.0210 - val_loss: 0.0045 - val_mae: 0.0394 - learning_rate: 2.5000e-04\n",
      "Epoch 36/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 9.5211e-04 - mae: 0.0216 - val_loss: 0.0043 - val_mae: 0.0388 - learning_rate: 2.5000e-04\n",
      "Epoch 37/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 9.0951e-04 - mae: 0.0211 - val_loss: 0.0045 - val_mae: 0.0391 - learning_rate: 2.5000e-04\n",
      "Epoch 38/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 8.8021e-04 - mae: 0.0207 - val_loss: 0.0057 - val_mae: 0.0450 - learning_rate: 2.5000e-04\n",
      "Epoch 39/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 9.5097e-04 - mae: 0.0218 - val_loss: 0.0049 - val_mae: 0.0398 - learning_rate: 2.5000e-04\n",
      "Epoch 40/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 8.6831e-04 - mae: 0.0206 - val_loss: 0.0045 - val_mae: 0.0392 - learning_rate: 2.5000e-04\n",
      "Epoch 41/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 8.0314e-04 - mae: 0.0197 - val_loss: 0.0048 - val_mae: 0.0410 - learning_rate: 1.2500e-04\n",
      "Epoch 42/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 7.9408e-04 - mae: 0.0195 - val_loss: 0.0048 - val_mae: 0.0406 - learning_rate: 1.2500e-04\n",
      "Epoch 43/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 7.7519e-04 - mae: 0.0191 - val_loss: 0.0045 - val_mae: 0.0389 - learning_rate: 1.2500e-04\n",
      "Epoch 44/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 7.4030e-04 - mae: 0.0187 - val_loss: 0.0044 - val_mae: 0.0388 - learning_rate: 1.2500e-04\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step   \n",
      "âœ… Bangalore - tomato | MAE=197.09, RMSE=354.7, RÂ²=0.9123, MAPE=13.45%, Acc=86.55%\n",
      "\n",
      "ğŸš€ Processing: Bangalore | wheat\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - loss: 0.2208 - mae: 0.2026 - val_loss: 0.0093 - val_mae: 0.0858 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0062 - mae: 0.0592 - val_loss: 0.0080 - val_mae: 0.0793 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0053 - mae: 0.0553 - val_loss: 0.0080 - val_mae: 0.0793 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0046 - mae: 0.0515 - val_loss: 0.0085 - val_mae: 0.0823 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0038 - mae: 0.0468 - val_loss: 0.0065 - val_mae: 0.0696 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0034 - mae: 0.0437 - val_loss: 0.0065 - val_mae: 0.0699 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0027 - mae: 0.0379 - val_loss: 0.0069 - val_mae: 0.0733 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0021 - mae: 0.0317 - val_loss: 0.0063 - val_mae: 0.0691 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0018 - mae: 0.0289 - val_loss: 0.0033 - val_mae: 0.0481 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0251 - val_loss: 0.0048 - val_mae: 0.0597 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0013 - mae: 0.0226 - val_loss: 0.0041 - val_mae: 0.0542 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0011 - mae: 0.0204 - val_loss: 0.0044 - val_mae: 0.0570 - learning_rate: 0.0010\n",
      "Epoch 13/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0011 - mae: 0.0196 - val_loss: 0.0050 - val_mae: 0.0612 - learning_rate: 0.0010\n",
      "Epoch 14/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 9.3645e-04 - mae: 0.0178 - val_loss: 0.0046 - val_mae: 0.0582 - learning_rate: 5.0000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 9.0590e-04 - mae: 0.0169 - val_loss: 0.0056 - val_mae: 0.0652 - learning_rate: 5.0000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 8.4900e-04 - mae: 0.0165 - val_loss: 0.0045 - val_mae: 0.0575 - learning_rate: 5.0000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 8.1827e-04 - mae: 0.0160 - val_loss: 0.0045 - val_mae: 0.0580 - learning_rate: 5.0000e-04\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step   \n",
      "âœ… Bangalore - wheat | MAE=182.99, RMSE=250.47, RÂ²=0.8095, MAPE=7.45%, Acc=92.55%\n",
      "\n",
      "ğŸš€ Processing: Belgaum | capsicum\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - loss: 0.0744 - mae: 0.2060 - val_loss: 0.0150 - val_mae: 0.1127 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0184 - mae: 0.1058 - val_loss: 0.0041 - val_mae: 0.0454 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0106 - mae: 0.0740 - val_loss: 0.0038 - val_mae: 0.0532 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0108 - mae: 0.0754 - val_loss: 0.0027 - val_mae: 0.0449 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0095 - mae: 0.0711 - val_loss: 0.0029 - val_mae: 0.0466 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0101 - mae: 0.0728 - val_loss: 0.0084 - val_mae: 0.0834 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0117 - mae: 0.0796 - val_loss: 0.0021 - val_mae: 0.0369 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0108 - mae: 0.0764 - val_loss: 0.0041 - val_mae: 0.0569 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0111 - mae: 0.0797 - val_loss: 0.0043 - val_mae: 0.0581 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0098 - mae: 0.0727 - val_loss: 0.0106 - val_mae: 0.0938 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0118 - mae: 0.0805 - val_loss: 0.0041 - val_mae: 0.0566 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0071 - mae: 0.0598 - val_loss: 0.0020 - val_mae: 0.0351 - learning_rate: 5.0000e-04\n",
      "Epoch 13/60\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0063 - mae: 0.0557 - val_loss: 0.0019 - val_mae: 0.0352 - learning_rate: 5.0000e-04\n",
      "Epoch 14/60\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0061 - mae: 0.0525 - val_loss: 0.0021 - val_mae: 0.0381 - learning_rate: 5.0000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0062 - mae: 0.0550 - val_loss: 0.0019 - val_mae: 0.0337 - learning_rate: 5.0000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0052 - mae: 0.0488 - val_loss: 0.0019 - val_mae: 0.0360 - learning_rate: 5.0000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0054 - mae: 0.0512 - val_loss: 0.0017 - val_mae: 0.0324 - learning_rate: 2.5000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0050 - mae: 0.0490 - val_loss: 0.0017 - val_mae: 0.0328 - learning_rate: 2.5000e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0050 - mae: 0.0492 - val_loss: 0.0020 - val_mae: 0.0380 - learning_rate: 2.5000e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0051 - mae: 0.0499 - val_loss: 0.0017 - val_mae: 0.0321 - learning_rate: 2.5000e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0052 - mae: 0.0497 - val_loss: 0.0016 - val_mae: 0.0303 - learning_rate: 2.5000e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0050 - mae: 0.0488 - val_loss: 0.0017 - val_mae: 0.0333 - learning_rate: 2.5000e-04\n",
      "Epoch 23/60\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0048 - mae: 0.0488 - val_loss: 0.0017 - val_mae: 0.0343 - learning_rate: 2.5000e-04\n",
      "Epoch 24/60\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0046 - mae: 0.0483 - val_loss: 0.0021 - val_mae: 0.0391 - learning_rate: 2.5000e-04\n",
      "Epoch 25/60\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0048 - mae: 0.0490 - val_loss: 0.0021 - val_mae: 0.0388 - learning_rate: 2.5000e-04\n",
      "Epoch 26/60\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0044 - mae: 0.0482 - val_loss: 0.0017 - val_mae: 0.0346 - learning_rate: 1.2500e-04\n",
      "Epoch 27/60\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0045 - mae: 0.0468 - val_loss: 0.0017 - val_mae: 0.0346 - learning_rate: 1.2500e-04\n",
      "Epoch 28/60\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0044 - mae: 0.0468 - val_loss: 0.0015 - val_mae: 0.0306 - learning_rate: 1.2500e-04\n",
      "Epoch 29/60\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0044 - mae: 0.0466 - val_loss: 0.0016 - val_mae: 0.0332 - learning_rate: 1.2500e-04\n",
      "Epoch 30/60\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0042 - mae: 0.0455 - val_loss: 0.0015 - val_mae: 0.0294 - learning_rate: 6.2500e-05\n",
      "Epoch 31/60\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0043 - mae: 0.0456 - val_loss: 0.0016 - val_mae: 0.0300 - learning_rate: 6.2500e-05\n",
      "Epoch 32/60\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0045 - mae: 0.0464 - val_loss: 0.0015 - val_mae: 0.0301 - learning_rate: 6.2500e-05\n",
      "Epoch 33/60\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0045 - mae: 0.0464 - val_loss: 0.0017 - val_mae: 0.0306 - learning_rate: 6.2500e-05\n",
      "Epoch 34/60\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0044 - mae: 0.0465 - val_loss: 0.0016 - val_mae: 0.0299 - learning_rate: 3.1250e-05\n",
      "Epoch 35/60\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0042 - mae: 0.0458 - val_loss: 0.0015 - val_mae: 0.0301 - learning_rate: 3.1250e-05\n",
      "Epoch 36/60\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0043 - mae: 0.0468 - val_loss: 0.0015 - val_mae: 0.0299 - learning_rate: 3.1250e-05\n",
      "Epoch 37/60\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0039 - mae: 0.0435 - val_loss: 0.0015 - val_mae: 0.0297 - learning_rate: 3.1250e-05\n",
      "Epoch 38/60\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0040 - mae: 0.0448 - val_loss: 0.0016 - val_mae: 0.0295 - learning_rate: 1.5625e-05\n",
      "Epoch 39/60\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0044 - mae: 0.0462 - val_loss: 0.0017 - val_mae: 0.0299 - learning_rate: 1.5625e-05\n",
      "Epoch 40/60\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0041 - mae: 0.0453 - val_loss: 0.0017 - val_mae: 0.0298 - learning_rate: 1.5625e-05\n",
      "Epoch 41/60\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0045 - mae: 0.0472 - val_loss: 0.0015 - val_mae: 0.0294 - learning_rate: 1.5625e-05\n",
      "Epoch 42/60\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0040 - mae: 0.0442 - val_loss: 0.0016 - val_mae: 0.0297 - learning_rate: 7.8125e-06\n",
      "Epoch 43/60\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0042 - mae: 0.0457 - val_loss: 0.0016 - val_mae: 0.0295 - learning_rate: 7.8125e-06\n",
      "\u001b[1m19/19\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step \n",
      "âœ… Belgaum - capsicum | MAE=260.32, RMSE=379.87, RÂ²=0.7715, MAPE=9.32%, Acc=90.68%\n",
      "\n",
      "ğŸš€ Processing: Belgaum | onion\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0936 - mae: 0.1490 - val_loss: 0.0017 - val_mae: 0.0329 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0057 - mae: 0.0555 - val_loss: 0.0013 - val_mae: 0.0274 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0046 - mae: 0.0527 - val_loss: 0.0011 - val_mae: 0.0232 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0039 - mae: 0.0481 - val_loss: 0.0018 - val_mae: 0.0342 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0033 - mae: 0.0452 - val_loss: 0.0017 - val_mae: 0.0324 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0033 - mae: 0.0446 - val_loss: 0.0014 - val_mae: 0.0292 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0027 - mae: 0.0401 - val_loss: 0.0029 - val_mae: 0.0479 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0021 - mae: 0.0357 - val_loss: 9.3184e-04 - val_mae: 0.0206 - learning_rate: 5.0000e-04\n",
      "Epoch 9/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0019 - mae: 0.0336 - val_loss: 9.1756e-04 - val_mae: 0.0203 - learning_rate: 5.0000e-04\n",
      "Epoch 10/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0020 - mae: 0.0337 - val_loss: 0.0016 - val_mae: 0.0321 - learning_rate: 5.0000e-04\n",
      "Epoch 11/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0017 - mae: 0.0317 - val_loss: 0.0013 - val_mae: 0.0277 - learning_rate: 5.0000e-04\n",
      "Epoch 12/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0017 - mae: 0.0315 - val_loss: 0.0019 - val_mae: 0.0357 - learning_rate: 5.0000e-04\n",
      "Epoch 13/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0015 - mae: 0.0289 - val_loss: 8.8772e-04 - val_mae: 0.0204 - learning_rate: 2.5000e-04\n",
      "Epoch 14/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0013 - mae: 0.0273 - val_loss: 9.3674e-04 - val_mae: 0.0218 - learning_rate: 2.5000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0014 - mae: 0.0274 - val_loss: 8.7027e-04 - val_mae: 0.0203 - learning_rate: 2.5000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0014 - mae: 0.0273 - val_loss: 8.3577e-04 - val_mae: 0.0195 - learning_rate: 2.5000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mae: 0.0269 - val_loss: 8.3820e-04 - val_mae: 0.0197 - learning_rate: 1.2500e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mae: 0.0265 - val_loss: 9.4429e-04 - val_mae: 0.0222 - learning_rate: 1.2500e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0266 - val_loss: 9.8251e-04 - val_mae: 0.0226 - learning_rate: 1.2500e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0012 - mae: 0.0256 - val_loss: 9.4433e-04 - val_mae: 0.0219 - learning_rate: 1.2500e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0011 - mae: 0.0248 - val_loss: 8.6243e-04 - val_mae: 0.0208 - learning_rate: 6.2500e-05\n",
      "Epoch 22/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0011 - mae: 0.0244 - val_loss: 8.1066e-04 - val_mae: 0.0193 - learning_rate: 6.2500e-05\n",
      "Epoch 23/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0011 - mae: 0.0243 - val_loss: 8.0180e-04 - val_mae: 0.0190 - learning_rate: 6.2500e-05\n",
      "Epoch 24/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0011 - mae: 0.0243 - val_loss: 8.0012e-04 - val_mae: 0.0190 - learning_rate: 6.2500e-05\n",
      "Epoch 25/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0011 - mae: 0.0240 - val_loss: 8.5087e-04 - val_mae: 0.0205 - learning_rate: 6.2500e-05\n",
      "Epoch 26/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0011 - mae: 0.0243 - val_loss: 7.9602e-04 - val_mae: 0.0190 - learning_rate: 6.2500e-05\n",
      "Epoch 27/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0011 - mae: 0.0237 - val_loss: 8.0468e-04 - val_mae: 0.0191 - learning_rate: 3.1250e-05\n",
      "Epoch 28/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0011 - mae: 0.0240 - val_loss: 7.9816e-04 - val_mae: 0.0190 - learning_rate: 3.1250e-05\n",
      "Epoch 29/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0010 - mae: 0.0230 - val_loss: 7.9311e-04 - val_mae: 0.0189 - learning_rate: 3.1250e-05\n",
      "Epoch 30/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0011 - mae: 0.0236 - val_loss: 7.8636e-04 - val_mae: 0.0189 - learning_rate: 3.1250e-05\n",
      "Epoch 31/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 9.6788e-04 - mae: 0.0227 - val_loss: 7.8962e-04 - val_mae: 0.0190 - learning_rate: 1.5625e-05\n",
      "Epoch 32/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.7254e-04 - mae: 0.0226 - val_loss: 7.9888e-04 - val_mae: 0.0193 - learning_rate: 1.5625e-05\n",
      "Epoch 33/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0010 - mae: 0.0230 - val_loss: 7.8175e-04 - val_mae: 0.0188 - learning_rate: 1.5625e-05\n",
      "Epoch 34/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 9.8201e-04 - mae: 0.0229 - val_loss: 7.9260e-04 - val_mae: 0.0191 - learning_rate: 1.5625e-05\n",
      "Epoch 35/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0010 - mae: 0.0231 - val_loss: 7.8555e-04 - val_mae: 0.0190 - learning_rate: 7.8125e-06\n",
      "Epoch 36/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 9.8972e-04 - mae: 0.0231 - val_loss: 7.8842e-04 - val_mae: 0.0190 - learning_rate: 7.8125e-06\n",
      "Epoch 37/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 9.6024e-04 - mae: 0.0224 - val_loss: 7.8167e-04 - val_mae: 0.0189 - learning_rate: 7.8125e-06\n",
      "Epoch 38/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 9.3910e-04 - mae: 0.0221 - val_loss: 7.8828e-04 - val_mae: 0.0191 - learning_rate: 7.8125e-06\n",
      "Epoch 39/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 9.9119e-04 - mae: 0.0228 - val_loss: 7.8391e-04 - val_mae: 0.0189 - learning_rate: 3.9063e-06\n",
      "Epoch 40/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0010 - mae: 0.0229 - val_loss: 7.8987e-04 - val_mae: 0.0191 - learning_rate: 3.9063e-06\n",
      "Epoch 41/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 9.4821e-04 - mae: 0.0222 - val_loss: 7.7859e-04 - val_mae: 0.0187 - learning_rate: 3.9063e-06\n",
      "Epoch 42/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 9.5769e-04 - mae: 0.0223 - val_loss: 7.8026e-04 - val_mae: 0.0188 - learning_rate: 3.9063e-06\n",
      "Epoch 43/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 9.6928e-04 - mae: 0.0224 - val_loss: 7.7954e-04 - val_mae: 0.0187 - learning_rate: 1.9531e-06\n",
      "Epoch 44/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 9.5274e-04 - mae: 0.0224 - val_loss: 7.7887e-04 - val_mae: 0.0188 - learning_rate: 1.9531e-06\n",
      "Epoch 45/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 9.1630e-04 - mae: 0.0218 - val_loss: 7.7740e-04 - val_mae: 0.0187 - learning_rate: 1.9531e-06\n",
      "Epoch 46/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 9.5091e-04 - mae: 0.0224 - val_loss: 7.7759e-04 - val_mae: 0.0187 - learning_rate: 1.9531e-06\n",
      "Epoch 47/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 9.5177e-04 - mae: 0.0222 - val_loss: 7.7794e-04 - val_mae: 0.0186 - learning_rate: 1.0000e-06\n",
      "Epoch 48/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 9.6545e-04 - mae: 0.0225 - val_loss: 7.7914e-04 - val_mae: 0.0188 - learning_rate: 1.0000e-06\n",
      "Epoch 49/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 9.3687e-04 - mae: 0.0221 - val_loss: 7.7716e-04 - val_mae: 0.0187 - learning_rate: 1.0000e-06\n",
      "Epoch 50/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 9.9593e-04 - mae: 0.0224 - val_loss: 7.7765e-04 - val_mae: 0.0187 - learning_rate: 1.0000e-06\n",
      "Epoch 51/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 9.2095e-04 - mae: 0.0220 - val_loss: 7.7860e-04 - val_mae: 0.0187 - learning_rate: 1.0000e-06\n",
      "Epoch 52/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 9.6548e-04 - mae: 0.0223 - val_loss: 7.7799e-04 - val_mae: 0.0187 - learning_rate: 1.0000e-06\n",
      "Epoch 53/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 9.5691e-04 - mae: 0.0225 - val_loss: 7.7780e-04 - val_mae: 0.0187 - learning_rate: 1.0000e-06\n",
      "Epoch 54/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 9.9513e-04 - mae: 0.0228 - val_loss: 7.7690e-04 - val_mae: 0.0187 - learning_rate: 1.0000e-06\n",
      "Epoch 55/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 9.7498e-04 - mae: 0.0223 - val_loss: 7.8036e-04 - val_mae: 0.0187 - learning_rate: 1.0000e-06\n",
      "Epoch 56/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 9.6143e-04 - mae: 0.0224 - val_loss: 7.7718e-04 - val_mae: 0.0187 - learning_rate: 1.0000e-06\n",
      "Epoch 57/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 9.7643e-04 - mae: 0.0227 - val_loss: 7.7797e-04 - val_mae: 0.0187 - learning_rate: 1.0000e-06\n",
      "Epoch 58/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 9.6740e-04 - mae: 0.0222 - val_loss: 7.7665e-04 - val_mae: 0.0187 - learning_rate: 1.0000e-06\n",
      "Epoch 59/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 9.6034e-04 - mae: 0.0221 - val_loss: 7.7693e-04 - val_mae: 0.0187 - learning_rate: 1.0000e-06\n",
      "Epoch 60/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 9.7498e-04 - mae: 0.0225 - val_loss: 7.7691e-04 - val_mae: 0.0186 - learning_rate: 1.0000e-06\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step   \n",
      "âœ… Belgaum - onion | MAE=164.59, RMSE=273.83, RÂ²=0.9289, MAPE=11.08%, Acc=88.92%\n",
      "\n",
      "ğŸš€ Processing: Belgaum | tomato\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m130/130\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - loss: 0.0571 - mae: 0.1169 - val_loss: 0.0158 - val_mae: 0.0799 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m130/130\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0041 - mae: 0.0511 - val_loss: 0.0149 - val_mae: 0.0750 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m130/130\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0031 - mae: 0.0437 - val_loss: 0.0150 - val_mae: 0.0747 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m130/130\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0024 - mae: 0.0388 - val_loss: 0.0140 - val_mae: 0.0735 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m130/130\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0016 - mae: 0.0320 - val_loss: 0.0125 - val_mae: 0.0708 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m130/130\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0014 - mae: 0.0298 - val_loss: 0.0133 - val_mae: 0.0768 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m130/130\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0012 - mae: 0.0273 - val_loss: 0.0142 - val_mae: 0.0850 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m130/130\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0010 - mae: 0.0250 - val_loss: 0.0124 - val_mae: 0.0780 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m130/130\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.9323e-04 - mae: 0.0235 - val_loss: 0.0091 - val_mae: 0.0640 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m130/130\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 8.3845e-04 - mae: 0.0225 - val_loss: 0.0092 - val_mae: 0.0639 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m130/130\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 6.5165e-04 - mae: 0.0198 - val_loss: 0.0090 - val_mae: 0.0637 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m130/130\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 6.7323e-04 - mae: 0.0199 - val_loss: 0.0088 - val_mae: 0.0642 - learning_rate: 0.0010\n",
      "Epoch 13/60\n",
      "\u001b[1m130/130\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 6.7307e-04 - mae: 0.0200 - val_loss: 0.0091 - val_mae: 0.0639 - learning_rate: 0.0010\n",
      "Epoch 14/60\n",
      "\u001b[1m130/130\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 5.5196e-04 - mae: 0.0181 - val_loss: 0.0090 - val_mae: 0.0673 - learning_rate: 0.0010\n",
      "Epoch 15/60\n",
      "\u001b[1m130/130\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 5.1068e-04 - mae: 0.0173 - val_loss: 0.0090 - val_mae: 0.0615 - learning_rate: 0.0010\n",
      "Epoch 16/60\n",
      "\u001b[1m130/130\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 4.7762e-04 - mae: 0.0169 - val_loss: 0.0090 - val_mae: 0.0630 - learning_rate: 0.0010\n",
      "Epoch 17/60\n",
      "\u001b[1m130/130\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 3.3958e-04 - mae: 0.0137 - val_loss: 0.0089 - val_mae: 0.0611 - learning_rate: 5.0000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m130/130\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 3.1766e-04 - mae: 0.0132 - val_loss: 0.0088 - val_mae: 0.0608 - learning_rate: 5.0000e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m130/130\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 3.1076e-04 - mae: 0.0129 - val_loss: 0.0086 - val_mae: 0.0607 - learning_rate: 5.0000e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m130/130\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 2.7979e-04 - mae: 0.0122 - val_loss: 0.0087 - val_mae: 0.0605 - learning_rate: 5.0000e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m130/130\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 2.6186e-04 - mae: 0.0118 - val_loss: 0.0082 - val_mae: 0.0603 - learning_rate: 5.0000e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m130/130\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 2.6796e-04 - mae: 0.0120 - val_loss: 0.0086 - val_mae: 0.0597 - learning_rate: 5.0000e-04\n",
      "Epoch 23/60\n",
      "\u001b[1m130/130\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 2.4866e-04 - mae: 0.0114 - val_loss: 0.0080 - val_mae: 0.0596 - learning_rate: 5.0000e-04\n",
      "Epoch 24/60\n",
      "\u001b[1m130/130\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 2.5704e-04 - mae: 0.0119 - val_loss: 0.0089 - val_mae: 0.0602 - learning_rate: 5.0000e-04\n",
      "Epoch 25/60\n",
      "\u001b[1m130/130\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 2.5803e-04 - mae: 0.0119 - val_loss: 0.0100 - val_mae: 0.0652 - learning_rate: 5.0000e-04\n",
      "Epoch 26/60\n",
      "\u001b[1m130/130\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 2.3538e-04 - mae: 0.0111 - val_loss: 0.0087 - val_mae: 0.0600 - learning_rate: 5.0000e-04\n",
      "Epoch 27/60\n",
      "\u001b[1m130/130\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 2.3665e-04 - mae: 0.0111 - val_loss: 0.0083 - val_mae: 0.0589 - learning_rate: 5.0000e-04\n",
      "Epoch 28/60\n",
      "\u001b[1m130/130\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 2.0556e-04 - mae: 0.0102 - val_loss: 0.0081 - val_mae: 0.0587 - learning_rate: 2.5000e-04\n",
      "Epoch 29/60\n",
      "\u001b[1m130/130\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 1.8621e-04 - mae: 0.0095 - val_loss: 0.0083 - val_mae: 0.0588 - learning_rate: 2.5000e-04\n",
      "Epoch 30/60\n",
      "\u001b[1m130/130\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 1.7829e-04 - mae: 0.0092 - val_loss: 0.0081 - val_mae: 0.0581 - learning_rate: 2.5000e-04\n",
      "Epoch 31/60\n",
      "\u001b[1m130/130\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 1.7244e-04 - mae: 0.0091 - val_loss: 0.0084 - val_mae: 0.0579 - learning_rate: 2.5000e-04\n",
      "\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step   \n",
      "âœ… Belgaum - tomato | MAE=165.9, RMSE=400.15, RÂ²=0.8729, MAPE=8.95%, Acc=91.05%\n",
      "\n",
      "ğŸš€ Processing: Belgaum | wheat\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0433 - mae: 0.1328 - val_loss: 0.0520 - val_mae: 0.2081 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0050 - mae: 0.0561 - val_loss: 0.0217 - val_mae: 0.1228 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0039 - mae: 0.0494 - val_loss: 0.0179 - val_mae: 0.1104 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0028 - mae: 0.0419 - val_loss: 0.0063 - val_mae: 0.0637 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0028 - mae: 0.0417 - val_loss: 0.0111 - val_mae: 0.0844 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0021 - mae: 0.0358 - val_loss: 0.0156 - val_mae: 0.1030 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0308 - val_loss: 0.0106 - val_mae: 0.0824 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0013 - mae: 0.0282 - val_loss: 0.0070 - val_mae: 0.0667 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0012 - mae: 0.0273 - val_loss: 0.0125 - val_mae: 0.0906 - learning_rate: 5.0000e-04\n",
      "Epoch 10/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0011 - mae: 0.0252 - val_loss: 0.0101 - val_mae: 0.0805 - learning_rate: 5.0000e-04\n",
      "Epoch 11/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 9.5359e-04 - mae: 0.0237 - val_loss: 0.0073 - val_mae: 0.0675 - learning_rate: 5.0000e-04\n",
      "Epoch 12/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 9.9280e-04 - mae: 0.0243 - val_loss: 0.0090 - val_mae: 0.0755 - learning_rate: 5.0000e-04\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step   \n",
      "âœ… Belgaum - wheat | MAE=234.05, RMSE=248.34, RÂ²=0.7686, MAPE=11.66%, Acc=88.34%\n",
      "\n",
      "ğŸš€ Processing: Bellary | capsicum\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m75/75\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.1540 - mae: 0.2319 - val_loss: 0.0087 - val_mae: 0.0389 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m75/75\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0055 - mae: 0.0575 - val_loss: 0.0081 - val_mae: 0.0269 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m75/75\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0046 - mae: 0.0532 - val_loss: 0.0075 - val_mae: 0.0290 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m75/75\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0040 - mae: 0.0493 - val_loss: 0.0073 - val_mae: 0.0340 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m75/75\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0036 - mae: 0.0462 - val_loss: 0.0057 - val_mae: 0.0249 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m75/75\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0028 - mae: 0.0413 - val_loss: 0.0060 - val_mae: 0.0334 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m75/75\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0023 - mae: 0.0358 - val_loss: 0.0050 - val_mae: 0.0169 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m75/75\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0015 - mae: 0.0288 - val_loss: 0.0047 - val_mae: 0.0190 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m75/75\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0010 - mae: 0.0231 - val_loss: 0.0037 - val_mae: 0.0209 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m75/75\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 8.5717e-04 - mae: 0.0212 - val_loss: 0.0039 - val_mae: 0.0227 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m75/75\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 6.9098e-04 - mae: 0.0183 - val_loss: 0.0041 - val_mae: 0.0188 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m75/75\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 6.2417e-04 - mae: 0.0170 - val_loss: 0.0044 - val_mae: 0.0178 - learning_rate: 0.0010\n",
      "Epoch 13/60\n",
      "\u001b[1m75/75\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 6.4583e-04 - mae: 0.0170 - val_loss: 0.0038 - val_mae: 0.0181 - learning_rate: 0.0010\n",
      "Epoch 14/60\n",
      "\u001b[1m75/75\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 4.7962e-04 - mae: 0.0141 - val_loss: 0.0031 - val_mae: 0.0151 - learning_rate: 5.0000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m75/75\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 4.5798e-04 - mae: 0.0141 - val_loss: 0.0031 - val_mae: 0.0209 - learning_rate: 5.0000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m75/75\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.9568e-04 - mae: 0.0140 - val_loss: 0.0031 - val_mae: 0.0172 - learning_rate: 5.0000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m75/75\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.3589e-04 - mae: 0.0132 - val_loss: 0.0031 - val_mae: 0.0127 - learning_rate: 5.0000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m75/75\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 3.8395e-04 - mae: 0.0123 - val_loss: 0.0031 - val_mae: 0.0156 - learning_rate: 5.0000e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m75/75\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 3.5557e-04 - mae: 0.0116 - val_loss: 0.0031 - val_mae: 0.0129 - learning_rate: 2.5000e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m75/75\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 3.4754e-04 - mae: 0.0116 - val_loss: 0.0031 - val_mae: 0.0149 - learning_rate: 2.5000e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m75/75\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 3.6763e-04 - mae: 0.0117 - val_loss: 0.0031 - val_mae: 0.0135 - learning_rate: 2.5000e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m75/75\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 3.2098e-04 - mae: 0.0111 - val_loss: 0.0031 - val_mae: 0.0127 - learning_rate: 2.5000e-04\n",
      "Epoch 23/60\n",
      "\u001b[1m75/75\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 2.9845e-04 - mae: 0.0106 - val_loss: 0.0031 - val_mae: 0.0138 - learning_rate: 1.2500e-04\n",
      "Epoch 24/60\n",
      "\u001b[1m75/75\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 3.0496e-04 - mae: 0.0105 - val_loss: 0.0031 - val_mae: 0.0145 - learning_rate: 1.2500e-04\n",
      "Epoch 25/60\n",
      "\u001b[1m75/75\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 3.2156e-04 - mae: 0.0106 - val_loss: 0.0031 - val_mae: 0.0168 - learning_rate: 1.2500e-04\n",
      "Epoch 26/60\n",
      "\u001b[1m75/75\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 3.0416e-04 - mae: 0.0102 - val_loss: 0.0031 - val_mae: 0.0146 - learning_rate: 1.2500e-04\n",
      "Epoch 27/60\n",
      "\u001b[1m75/75\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 2.9174e-04 - mae: 0.0103 - val_loss: 0.0031 - val_mae: 0.0134 - learning_rate: 6.2500e-05\n",
      "Epoch 28/60\n",
      "\u001b[1m75/75\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 2.7689e-04 - mae: 0.0101 - val_loss: 0.0031 - val_mae: 0.0125 - learning_rate: 6.2500e-05\n",
      "Epoch 29/60\n",
      "\u001b[1m75/75\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 2.6831e-04 - mae: 0.0100 - val_loss: 0.0031 - val_mae: 0.0128 - learning_rate: 6.2500e-05\n",
      "Epoch 30/60\n",
      "\u001b[1m75/75\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 2.9807e-04 - mae: 0.0102 - val_loss: 0.0031 - val_mae: 0.0150 - learning_rate: 6.2500e-05\n",
      "Epoch 31/60\n",
      "\u001b[1m75/75\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 2.8093e-04 - mae: 0.0100 - val_loss: 0.0031 - val_mae: 0.0136 - learning_rate: 3.1250e-05\n",
      "\u001b[1m47/47\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step   \n",
      "âœ… Bellary - capsicum | MAE=11.39, RMSE=57.57, RÂ²=0.8352, MAPE=0.55%, Acc=99.45%\n",
      "\n",
      "ğŸš€ Processing: Bellary | onion\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 0.0801 - mae: 0.1431 - val_loss: 0.0018 - val_mae: 0.0265 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0056 - mae: 0.0557 - val_loss: 0.0026 - val_mae: 0.0436 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0047 - mae: 0.0522 - val_loss: 0.0012 - val_mae: 0.0268 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0040 - mae: 0.0481 - val_loss: 7.7710e-04 - val_mae: 0.0177 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0034 - mae: 0.0441 - val_loss: 0.0015 - val_mae: 0.0315 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0031 - mae: 0.0422 - val_loss: 0.0010 - val_mae: 0.0243 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0027 - mae: 0.0384 - val_loss: 8.3829e-04 - val_mae: 0.0182 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0025 - mae: 0.0364 - val_loss: 7.8583e-04 - val_mae: 0.0182 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0019 - mae: 0.0311 - val_loss: 0.0011 - val_mae: 0.0255 - learning_rate: 5.0000e-04\n",
      "Epoch 10/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0019 - mae: 0.0309 - val_loss: 7.8600e-04 - val_mae: 0.0184 - learning_rate: 5.0000e-04\n",
      "Epoch 11/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0017 - mae: 0.0290 - val_loss: 7.7473e-04 - val_mae: 0.0185 - learning_rate: 5.0000e-04\n",
      "Epoch 12/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0017 - mae: 0.0295 - val_loss: 8.9430e-04 - val_mae: 0.0221 - learning_rate: 5.0000e-04\n",
      "Epoch 13/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0016 - mae: 0.0280 - val_loss: 9.5346e-04 - val_mae: 0.0236 - learning_rate: 2.5000e-04\n",
      "Epoch 14/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0015 - mae: 0.0270 - val_loss: 7.5924e-04 - val_mae: 0.0189 - learning_rate: 2.5000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0016 - mae: 0.0270 - val_loss: 7.8944e-04 - val_mae: 0.0201 - learning_rate: 2.5000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0015 - mae: 0.0262 - val_loss: 7.4460e-04 - val_mae: 0.0188 - learning_rate: 2.5000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0014 - mae: 0.0255 - val_loss: 7.0670e-04 - val_mae: 0.0176 - learning_rate: 1.2500e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0014 - mae: 0.0251 - val_loss: 7.0979e-04 - val_mae: 0.0180 - learning_rate: 1.2500e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0014 - mae: 0.0254 - val_loss: 6.7994e-04 - val_mae: 0.0170 - learning_rate: 1.2500e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0014 - mae: 0.0253 - val_loss: 6.7196e-04 - val_mae: 0.0166 - learning_rate: 1.2500e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0014 - mae: 0.0249 - val_loss: 7.3952e-04 - val_mae: 0.0190 - learning_rate: 1.2500e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0014 - mae: 0.0249 - val_loss: 7.6660e-04 - val_mae: 0.0195 - learning_rate: 1.2500e-04\n",
      "Epoch 23/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0014 - mae: 0.0248 - val_loss: 6.8759e-04 - val_mae: 0.0170 - learning_rate: 1.2500e-04\n",
      "Epoch 24/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0014 - mae: 0.0247 - val_loss: 7.4115e-04 - val_mae: 0.0190 - learning_rate: 1.2500e-04\n",
      "Epoch 25/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0013 - mae: 0.0243 - val_loss: 7.5515e-04 - val_mae: 0.0192 - learning_rate: 6.2500e-05\n",
      "Epoch 26/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0014 - mae: 0.0246 - val_loss: 7.3683e-04 - val_mae: 0.0188 - learning_rate: 6.2500e-05\n",
      "Epoch 27/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0013 - mae: 0.0240 - val_loss: 7.2920e-04 - val_mae: 0.0184 - learning_rate: 6.2500e-05\n",
      "Epoch 28/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0013 - mae: 0.0240 - val_loss: 6.9073e-04 - val_mae: 0.0173 - learning_rate: 6.2500e-05\n",
      "\u001b[1m80/80\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step   \n",
      "âœ… Bellary - onion | MAE=117.71, RMSE=193.83, RÂ²=0.8762, MAPE=9.36%, Acc=90.64%\n",
      "\n",
      "ğŸš€ Processing: Bellary | tomato\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0810 - mae: 0.1413 - val_loss: 0.0189 - val_mae: 0.0490 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0041 - mae: 0.0496 - val_loss: 0.0183 - val_mae: 0.0527 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0034 - mae: 0.0444 - val_loss: 0.0163 - val_mae: 0.0506 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0028 - mae: 0.0400 - val_loss: 0.0145 - val_mae: 0.0444 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0023 - mae: 0.0360 - val_loss: 0.0142 - val_mae: 0.0456 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0019 - mae: 0.0326 - val_loss: 0.0133 - val_mae: 0.0446 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0016 - mae: 0.0288 - val_loss: 0.0132 - val_mae: 0.0451 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0016 - mae: 0.0289 - val_loss: 0.0141 - val_mae: 0.0537 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0015 - mae: 0.0278 - val_loss: 0.0129 - val_mae: 0.0427 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0013 - mae: 0.0261 - val_loss: 0.0128 - val_mae: 0.0395 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0013 - mae: 0.0257 - val_loss: 0.0131 - val_mae: 0.0434 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mae: 0.0257 - val_loss: 0.0149 - val_mae: 0.0587 - learning_rate: 0.0010\n",
      "Epoch 13/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0012 - mae: 0.0243 - val_loss: 0.0127 - val_mae: 0.0406 - learning_rate: 0.0010\n",
      "Epoch 14/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0011 - mae: 0.0226 - val_loss: 0.0134 - val_mae: 0.0481 - learning_rate: 0.0010\n",
      "Epoch 15/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0010 - mae: 0.0220 - val_loss: 0.0124 - val_mae: 0.0379 - learning_rate: 5.0000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0010 - mae: 0.0215 - val_loss: 0.0125 - val_mae: 0.0393 - learning_rate: 5.0000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 9.5952e-04 - mae: 0.0207 - val_loss: 0.0120 - val_mae: 0.0381 - learning_rate: 5.0000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.3136e-04 - mae: 0.0201 - val_loss: 0.0123 - val_mae: 0.0386 - learning_rate: 5.0000e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 9.0354e-04 - mae: 0.0197 - val_loss: 0.0120 - val_mae: 0.0383 - learning_rate: 5.0000e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 9.1310e-04 - mae: 0.0198 - val_loss: 0.0119 - val_mae: 0.0379 - learning_rate: 5.0000e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 9.4047e-04 - mae: 0.0202 - val_loss: 0.0134 - val_mae: 0.0468 - learning_rate: 5.0000e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 8.9517e-04 - mae: 0.0197 - val_loss: 0.0127 - val_mae: 0.0418 - learning_rate: 5.0000e-04\n",
      "Epoch 23/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 8.5764e-04 - mae: 0.0190 - val_loss: 0.0123 - val_mae: 0.0388 - learning_rate: 5.0000e-04\n",
      "Epoch 24/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 8.9746e-04 - mae: 0.0198 - val_loss: 0.0119 - val_mae: 0.0402 - learning_rate: 5.0000e-04\n",
      "Epoch 25/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 8.4502e-04 - mae: 0.0188 - val_loss: 0.0119 - val_mae: 0.0388 - learning_rate: 2.5000e-04\n",
      "Epoch 26/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 8.8111e-04 - mae: 0.0197 - val_loss: 0.0123 - val_mae: 0.0387 - learning_rate: 2.5000e-04\n",
      "Epoch 27/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 8.3966e-04 - mae: 0.0188 - val_loss: 0.0117 - val_mae: 0.0369 - learning_rate: 2.5000e-04\n",
      "Epoch 28/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.5057e-04 - mae: 0.0191 - val_loss: 0.0118 - val_mae: 0.0374 - learning_rate: 2.5000e-04\n",
      "Epoch 29/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.3388e-04 - mae: 0.0190 - val_loss: 0.0117 - val_mae: 0.0375 - learning_rate: 2.5000e-04\n",
      "Epoch 30/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 8.5148e-04 - mae: 0.0195 - val_loss: 0.0118 - val_mae: 0.0368 - learning_rate: 2.5000e-04\n",
      "Epoch 31/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 8.5706e-04 - mae: 0.0195 - val_loss: 0.0119 - val_mae: 0.0366 - learning_rate: 2.5000e-04\n",
      "Epoch 32/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 7.4562e-04 - mae: 0.0173 - val_loss: 0.0117 - val_mae: 0.0368 - learning_rate: 1.2500e-04\n",
      "Epoch 33/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 7.4050e-04 - mae: 0.0174 - val_loss: 0.0120 - val_mae: 0.0377 - learning_rate: 1.2500e-04\n",
      "Epoch 34/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 7.2868e-04 - mae: 0.0170 - val_loss: 0.0120 - val_mae: 0.0375 - learning_rate: 1.2500e-04\n",
      "Epoch 35/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 7.5351e-04 - mae: 0.0175 - val_loss: 0.0115 - val_mae: 0.0364 - learning_rate: 1.2500e-04\n",
      "Epoch 36/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 7.2986e-04 - mae: 0.0172 - val_loss: 0.0119 - val_mae: 0.0372 - learning_rate: 1.2500e-04\n",
      "Epoch 37/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 7.5045e-04 - mae: 0.0175 - val_loss: 0.0121 - val_mae: 0.0394 - learning_rate: 1.2500e-04\n",
      "Epoch 38/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 7.3330e-04 - mae: 0.0174 - val_loss: 0.0120 - val_mae: 0.0371 - learning_rate: 1.2500e-04\n",
      "Epoch 39/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 7.4304e-04 - mae: 0.0174 - val_loss: 0.0118 - val_mae: 0.0366 - learning_rate: 1.2500e-04\n",
      "Epoch 40/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6.9110e-04 - mae: 0.0166 - val_loss: 0.0118 - val_mae: 0.0371 - learning_rate: 6.2500e-05\n",
      "Epoch 41/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 6.7084e-04 - mae: 0.0165 - val_loss: 0.0117 - val_mae: 0.0382 - learning_rate: 6.2500e-05\n",
      "Epoch 42/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 6.9831e-04 - mae: 0.0167 - val_loss: 0.0119 - val_mae: 0.0398 - learning_rate: 6.2500e-05\n",
      "Epoch 43/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 6.8757e-04 - mae: 0.0166 - val_loss: 0.0119 - val_mae: 0.0384 - learning_rate: 6.2500e-05\n",
      "\u001b[1m80/80\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step   \n",
      "âœ… Bellary - tomato | MAE=128.45, RMSE=358.91, RÂ²=0.6711, MAPE=12.91%, Acc=87.09%\n",
      "\n",
      "ğŸš€ Processing: Bellary | wheat\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 0.1298 - mae: 0.1571 - val_loss: 0.0506 - val_mae: 0.1437 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0026 - mae: 0.0399 - val_loss: 0.0363 - val_mae: 0.1044 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0023 - mae: 0.0371 - val_loss: 0.0373 - val_mae: 0.1115 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0020 - mae: 0.0342 - val_loss: 0.0295 - val_mae: 0.0908 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0017 - mae: 0.0321 - val_loss: 0.0290 - val_mae: 0.0897 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0014 - mae: 0.0283 - val_loss: 0.0255 - val_mae: 0.0830 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0012 - mae: 0.0261 - val_loss: 0.0259 - val_mae: 0.0832 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 9.5216e-04 - mae: 0.0228 - val_loss: 0.0246 - val_mae: 0.0804 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 7.2782e-04 - mae: 0.0196 - val_loss: 0.0209 - val_mae: 0.0781 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 6.4406e-04 - mae: 0.0182 - val_loss: 0.0230 - val_mae: 0.0770 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 5.1974e-04 - mae: 0.0158 - val_loss: 0.0200 - val_mae: 0.0731 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 4.4202e-04 - mae: 0.0144 - val_loss: 0.0211 - val_mae: 0.0725 - learning_rate: 0.0010\n",
      "Epoch 13/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 4.2718e-04 - mae: 0.0143 - val_loss: 0.0206 - val_mae: 0.0714 - learning_rate: 0.0010\n",
      "Epoch 14/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 3.9306e-04 - mae: 0.0137 - val_loss: 0.0189 - val_mae: 0.0698 - learning_rate: 0.0010\n",
      "Epoch 15/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 3.1566e-04 - mae: 0.0121 - val_loss: 0.0199 - val_mae: 0.0715 - learning_rate: 0.0010\n",
      "Epoch 16/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 2.9307e-04 - mae: 0.0120 - val_loss: 0.0180 - val_mae: 0.0673 - learning_rate: 0.0010\n",
      "Epoch 17/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 2.6296e-04 - mae: 0.0112 - val_loss: 0.0175 - val_mae: 0.0654 - learning_rate: 0.0010\n",
      "Epoch 18/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 2.7074e-04 - mae: 0.0116 - val_loss: 0.0173 - val_mae: 0.0652 - learning_rate: 0.0010\n",
      "Epoch 19/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 2.5137e-04 - mae: 0.0109 - val_loss: 0.0174 - val_mae: 0.0638 - learning_rate: 0.0010\n",
      "Epoch 20/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 2.3576e-04 - mae: 0.0108 - val_loss: 0.0149 - val_mae: 0.0647 - learning_rate: 0.0010\n",
      "Epoch 21/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 2.4301e-04 - mae: 0.0108 - val_loss: 0.0158 - val_mae: 0.0612 - learning_rate: 0.0010\n",
      "Epoch 22/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 2.1237e-04 - mae: 0.0099 - val_loss: 0.0169 - val_mae: 0.0659 - learning_rate: 0.0010\n",
      "Epoch 23/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 2.4027e-04 - mae: 0.0109 - val_loss: 0.0167 - val_mae: 0.0644 - learning_rate: 0.0010\n",
      "Epoch 24/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 2.0363e-04 - mae: 0.0099 - val_loss: 0.0161 - val_mae: 0.0614 - learning_rate: 0.0010\n",
      "Epoch 25/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 1.6325e-04 - mae: 0.0085 - val_loss: 0.0135 - val_mae: 0.0637 - learning_rate: 5.0000e-04\n",
      "Epoch 26/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 1.6701e-04 - mae: 0.0086 - val_loss: 0.0144 - val_mae: 0.0586 - learning_rate: 5.0000e-04\n",
      "Epoch 27/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 1.6011e-04 - mae: 0.0084 - val_loss: 0.0138 - val_mae: 0.0597 - learning_rate: 5.0000e-04\n",
      "Epoch 28/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 1.5934e-04 - mae: 0.0083 - val_loss: 0.0134 - val_mae: 0.0624 - learning_rate: 5.0000e-04\n",
      "Epoch 29/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.7615e-04 - mae: 0.0090 - val_loss: 0.0129 - val_mae: 0.0614 - learning_rate: 5.0000e-04\n",
      "Epoch 30/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 1.5474e-04 - mae: 0.0082 - val_loss: 0.0142 - val_mae: 0.0563 - learning_rate: 5.0000e-04\n",
      "Epoch 31/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 1.6785e-04 - mae: 0.0087 - val_loss: 0.0129 - val_mae: 0.0607 - learning_rate: 5.0000e-04\n",
      "Epoch 32/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 1.4684e-04 - mae: 0.0079 - val_loss: 0.0131 - val_mae: 0.0576 - learning_rate: 5.0000e-04\n",
      "Epoch 33/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 1.4519e-04 - mae: 0.0078 - val_loss: 0.0135 - val_mae: 0.0576 - learning_rate: 5.0000e-04\n",
      "Epoch 34/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 1.3413e-04 - mae: 0.0073 - val_loss: 0.0137 - val_mae: 0.0558 - learning_rate: 2.5000e-04\n",
      "Epoch 35/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 1.3097e-04 - mae: 0.0073 - val_loss: 0.0124 - val_mae: 0.0607 - learning_rate: 2.5000e-04\n",
      "Epoch 36/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 1.3746e-04 - mae: 0.0074 - val_loss: 0.0126 - val_mae: 0.0609 - learning_rate: 2.5000e-04\n",
      "Epoch 37/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 1.3629e-04 - mae: 0.0075 - val_loss: 0.0121 - val_mae: 0.0615 - learning_rate: 2.5000e-04\n",
      "Epoch 38/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 1.2970e-04 - mae: 0.0073 - val_loss: 0.0121 - val_mae: 0.0619 - learning_rate: 2.5000e-04\n",
      "Epoch 39/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.2860e-04 - mae: 0.0072 - val_loss: 0.0122 - val_mae: 0.0603 - learning_rate: 2.5000e-04\n",
      "Epoch 40/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 1.3041e-04 - mae: 0.0074 - val_loss: 0.0124 - val_mae: 0.0581 - learning_rate: 2.5000e-04\n",
      "Epoch 41/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.3088e-04 - mae: 0.0074 - val_loss: 0.0129 - val_mae: 0.0570 - learning_rate: 2.5000e-04\n",
      "Epoch 42/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 1.1696e-04 - mae: 0.0066 - val_loss: 0.0131 - val_mae: 0.0548 - learning_rate: 1.2500e-04\n",
      "Epoch 43/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 1.2119e-04 - mae: 0.0069 - val_loss: 0.0129 - val_mae: 0.0561 - learning_rate: 1.2500e-04\n",
      "Epoch 44/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 1.1957e-04 - mae: 0.0068 - val_loss: 0.0126 - val_mae: 0.0558 - learning_rate: 1.2500e-04\n",
      "Epoch 45/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 1.1819e-04 - mae: 0.0066 - val_loss: 0.0125 - val_mae: 0.0560 - learning_rate: 1.2500e-04\n",
      "Epoch 46/60\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 1.1610e-04 - mae: 0.0065 - val_loss: 0.0126 - val_mae: 0.0557 - learning_rate: 6.2500e-05\n",
      "\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step   \n",
      "âœ… Bellary - wheat | MAE=94.02, RMSE=207.39, RÂ²=0.8858, MAPE=4.09%, Acc=95.91%\n",
      "\n",
      "ğŸš€ Processing: Bidar | onion\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 0.1607 - mae: 0.1819 - val_loss: 0.0217 - val_mae: 0.0496 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0052 - mae: 0.0562 - val_loss: 0.0197 - val_mae: 0.0501 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0043 - mae: 0.0512 - val_loss: 0.0164 - val_mae: 0.0423 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0035 - mae: 0.0460 - val_loss: 0.0137 - val_mae: 0.0489 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0031 - mae: 0.0425 - val_loss: 0.0137 - val_mae: 0.0415 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0027 - mae: 0.0393 - val_loss: 0.0118 - val_mae: 0.0551 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0023 - mae: 0.0355 - val_loss: 0.0119 - val_mae: 0.0588 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0020 - mae: 0.0336 - val_loss: 0.0128 - val_mae: 0.0357 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0016 - mae: 0.0295 - val_loss: 0.0127 - val_mae: 0.0684 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0014 - mae: 0.0274 - val_loss: 0.0138 - val_mae: 0.0401 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0011 - mae: 0.0238 - val_loss: 0.0122 - val_mae: 0.0380 - learning_rate: 5.0000e-04\n",
      "Epoch 12/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0011 - mae: 0.0237 - val_loss: 0.0124 - val_mae: 0.0413 - learning_rate: 5.0000e-04\n",
      "Epoch 13/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 9.7917e-04 - mae: 0.0217 - val_loss: 0.0114 - val_mae: 0.0578 - learning_rate: 5.0000e-04\n",
      "Epoch 14/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 9.7935e-04 - mae: 0.0217 - val_loss: 0.0127 - val_mae: 0.0392 - learning_rate: 5.0000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 9.2707e-04 - mae: 0.0206 - val_loss: 0.0113 - val_mae: 0.0503 - learning_rate: 5.0000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 8.4101e-04 - mae: 0.0196 - val_loss: 0.0113 - val_mae: 0.0540 - learning_rate: 5.0000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 8.8145e-04 - mae: 0.0200 - val_loss: 0.0119 - val_mae: 0.0383 - learning_rate: 5.0000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 7.8042e-04 - mae: 0.0186 - val_loss: 0.0128 - val_mae: 0.0373 - learning_rate: 5.0000e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 7.2548e-04 - mae: 0.0174 - val_loss: 0.0118 - val_mae: 0.0459 - learning_rate: 5.0000e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 6.6041e-04 - mae: 0.0168 - val_loss: 0.0114 - val_mae: 0.0465 - learning_rate: 2.5000e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 6.6018e-04 - mae: 0.0166 - val_loss: 0.0115 - val_mae: 0.0399 - learning_rate: 2.5000e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 6.5505e-04 - mae: 0.0166 - val_loss: 0.0115 - val_mae: 0.0379 - learning_rate: 2.5000e-04\n",
      "Epoch 23/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 6.5656e-04 - mae: 0.0165 - val_loss: 0.0122 - val_mae: 0.0337 - learning_rate: 2.5000e-04\n",
      "\u001b[1m81/81\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step   \n",
      "âœ… Bidar - onion | MAE=73.08, RMSE=158.38, RÂ²=0.8157, MAPE=5.72%, Acc=94.28%\n",
      "\n",
      "ğŸš€ Processing: Bidar | wheat\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.0866 - mae: 0.1488 - val_loss: 0.0099 - val_mae: 0.0855 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0085 - mae: 0.0708 - val_loss: 0.0131 - val_mae: 0.1020 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0062 - mae: 0.0596 - val_loss: 0.0324 - val_mae: 0.1699 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0065 - mae: 0.0585 - val_loss: 0.0371 - val_mae: 0.1831 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0065 - mae: 0.0580 - val_loss: 0.0393 - val_mae: 0.1896 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0058 - mae: 0.0536 - val_loss: 0.0086 - val_mae: 0.0800 - learning_rate: 5.0000e-04\n",
      "Epoch 7/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0038 - mae: 0.0451 - val_loss: 0.0092 - val_mae: 0.0838 - learning_rate: 5.0000e-04\n",
      "Epoch 8/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0038 - mae: 0.0446 - val_loss: 0.0137 - val_mae: 0.1062 - learning_rate: 5.0000e-04\n",
      "Epoch 9/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0040 - mae: 0.0448 - val_loss: 0.0242 - val_mae: 0.1462 - learning_rate: 5.0000e-04\n",
      "Epoch 10/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0046 - mae: 0.0463 - val_loss: 0.0113 - val_mae: 0.0951 - learning_rate: 5.0000e-04\n",
      "Epoch 11/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0031 - mae: 0.0395 - val_loss: 0.0051 - val_mae: 0.0592 - learning_rate: 2.5000e-04\n",
      "Epoch 12/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0029 - mae: 0.0378 - val_loss: 0.0063 - val_mae: 0.0677 - learning_rate: 2.5000e-04\n",
      "Epoch 13/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0029 - mae: 0.0384 - val_loss: 0.0055 - val_mae: 0.0623 - learning_rate: 2.5000e-04\n",
      "Epoch 14/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0029 - mae: 0.0377 - val_loss: 0.0073 - val_mae: 0.0743 - learning_rate: 2.5000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0029 - mae: 0.0372 - val_loss: 0.0075 - val_mae: 0.0759 - learning_rate: 2.5000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0027 - mae: 0.0362 - val_loss: 0.0039 - val_mae: 0.0498 - learning_rate: 1.2500e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0025 - mae: 0.0351 - val_loss: 0.0040 - val_mae: 0.0513 - learning_rate: 1.2500e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0024 - mae: 0.0343 - val_loss: 0.0040 - val_mae: 0.0510 - learning_rate: 1.2500e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0025 - mae: 0.0348 - val_loss: 0.0047 - val_mae: 0.0570 - learning_rate: 1.2500e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0026 - mae: 0.0357 - val_loss: 0.0042 - val_mae: 0.0532 - learning_rate: 1.2500e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0022 - mae: 0.0320 - val_loss: 0.0030 - val_mae: 0.0414 - learning_rate: 6.2500e-05\n",
      "Epoch 22/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0021 - mae: 0.0314 - val_loss: 0.0032 - val_mae: 0.0434 - learning_rate: 6.2500e-05\n",
      "Epoch 23/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0022 - mae: 0.0322 - val_loss: 0.0028 - val_mae: 0.0401 - learning_rate: 6.2500e-05\n",
      "Epoch 24/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0021 - mae: 0.0316 - val_loss: 0.0030 - val_mae: 0.0420 - learning_rate: 6.2500e-05\n",
      "Epoch 25/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0022 - mae: 0.0318 - val_loss: 0.0030 - val_mae: 0.0420 - learning_rate: 6.2500e-05\n",
      "Epoch 26/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0022 - mae: 0.0315 - val_loss: 0.0030 - val_mae: 0.0418 - learning_rate: 6.2500e-05\n",
      "Epoch 27/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0022 - mae: 0.0318 - val_loss: 0.0029 - val_mae: 0.0407 - learning_rate: 6.2500e-05\n",
      "Epoch 28/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0020 - mae: 0.0296 - val_loss: 0.0025 - val_mae: 0.0364 - learning_rate: 3.1250e-05\n",
      "Epoch 29/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0019 - mae: 0.0290 - val_loss: 0.0027 - val_mae: 0.0385 - learning_rate: 3.1250e-05\n",
      "Epoch 30/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0020 - mae: 0.0296 - val_loss: 0.0026 - val_mae: 0.0372 - learning_rate: 3.1250e-05\n",
      "Epoch 31/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0019 - mae: 0.0288 - val_loss: 0.0026 - val_mae: 0.0378 - learning_rate: 3.1250e-05\n",
      "Epoch 32/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0020 - mae: 0.0294 - val_loss: 0.0027 - val_mae: 0.0391 - learning_rate: 3.1250e-05\n",
      "Epoch 33/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0019 - mae: 0.0285 - val_loss: 0.0024 - val_mae: 0.0355 - learning_rate: 1.5625e-05\n",
      "Epoch 34/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0018 - mae: 0.0283 - val_loss: 0.0024 - val_mae: 0.0356 - learning_rate: 1.5625e-05\n",
      "Epoch 35/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0018 - mae: 0.0278 - val_loss: 0.0025 - val_mae: 0.0364 - learning_rate: 1.5625e-05\n",
      "Epoch 36/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0019 - mae: 0.0286 - val_loss: 0.0025 - val_mae: 0.0363 - learning_rate: 1.5625e-05\n",
      "Epoch 37/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0018 - mae: 0.0282 - val_loss: 0.0024 - val_mae: 0.0352 - learning_rate: 7.8125e-06\n",
      "Epoch 38/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0018 - mae: 0.0276 - val_loss: 0.0024 - val_mae: 0.0349 - learning_rate: 7.8125e-06\n",
      "Epoch 39/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0018 - mae: 0.0274 - val_loss: 0.0024 - val_mae: 0.0348 - learning_rate: 7.8125e-06\n",
      "Epoch 40/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0018 - mae: 0.0277 - val_loss: 0.0024 - val_mae: 0.0350 - learning_rate: 7.8125e-06\n",
      "Epoch 41/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0018 - mae: 0.0277 - val_loss: 0.0024 - val_mae: 0.0349 - learning_rate: 7.8125e-06\n",
      "Epoch 42/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0018 - mae: 0.0271 - val_loss: 0.0024 - val_mae: 0.0347 - learning_rate: 3.9063e-06\n",
      "Epoch 43/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0018 - mae: 0.0271 - val_loss: 0.0024 - val_mae: 0.0346 - learning_rate: 3.9063e-06\n",
      "Epoch 44/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0017 - mae: 0.0273 - val_loss: 0.0024 - val_mae: 0.0345 - learning_rate: 3.9063e-06\n",
      "Epoch 45/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0017 - mae: 0.0274 - val_loss: 0.0024 - val_mae: 0.0346 - learning_rate: 3.9063e-06\n",
      "Epoch 46/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0018 - mae: 0.0272 - val_loss: 0.0024 - val_mae: 0.0345 - learning_rate: 1.9531e-06\n",
      "Epoch 47/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0017 - mae: 0.0273 - val_loss: 0.0024 - val_mae: 0.0346 - learning_rate: 1.9531e-06\n",
      "Epoch 48/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0018 - mae: 0.0273 - val_loss: 0.0024 - val_mae: 0.0346 - learning_rate: 1.9531e-06\n",
      "Epoch 49/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0018 - mae: 0.0277 - val_loss: 0.0024 - val_mae: 0.0345 - learning_rate: 1.9531e-06\n",
      "Epoch 50/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0017 - mae: 0.0274 - val_loss: 0.0023 - val_mae: 0.0344 - learning_rate: 1.0000e-06\n",
      "Epoch 51/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0017 - mae: 0.0268 - val_loss: 0.0023 - val_mae: 0.0344 - learning_rate: 1.0000e-06\n",
      "Epoch 52/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0018 - mae: 0.0275 - val_loss: 0.0023 - val_mae: 0.0344 - learning_rate: 1.0000e-06\n",
      "Epoch 53/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0017 - mae: 0.0271 - val_loss: 0.0023 - val_mae: 0.0344 - learning_rate: 1.0000e-06\n",
      "Epoch 54/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0017 - mae: 0.0270 - val_loss: 0.0023 - val_mae: 0.0345 - learning_rate: 1.0000e-06\n",
      "Epoch 55/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0018 - mae: 0.0278 - val_loss: 0.0023 - val_mae: 0.0345 - learning_rate: 1.0000e-06\n",
      "Epoch 56/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0017 - mae: 0.0269 - val_loss: 0.0023 - val_mae: 0.0345 - learning_rate: 1.0000e-06\n",
      "Epoch 57/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0017 - mae: 0.0270 - val_loss: 0.0023 - val_mae: 0.0344 - learning_rate: 1.0000e-06\n",
      "Epoch 58/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0017 - mae: 0.0269 - val_loss: 0.0023 - val_mae: 0.0344 - learning_rate: 1.0000e-06\n",
      "Epoch 59/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0018 - mae: 0.0276 - val_loss: 0.0023 - val_mae: 0.0344 - learning_rate: 1.0000e-06\n",
      "Epoch 60/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0017 - mae: 0.0266 - val_loss: 0.0023 - val_mae: 0.0345 - learning_rate: 1.0000e-06\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step   \n",
      "âœ… Bidar - wheat | MAE=79.64, RMSE=131.9, RÂ²=0.9351, MAPE=3.36%, Acc=96.64%\n",
      "\n",
      "ğŸš€ Processing: Bijapur | onion\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0765 - mae: 0.1351 - val_loss: 9.8340e-04 - val_mae: 0.0213 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0048 - mae: 0.0527 - val_loss: 9.0166e-04 - val_mae: 0.0202 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0038 - mae: 0.0474 - val_loss: 0.0012 - val_mae: 0.0261 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0030 - mae: 0.0417 - val_loss: 0.0017 - val_mae: 0.0340 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0026 - mae: 0.0383 - val_loss: 9.9665e-04 - val_mae: 0.0218 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0020 - mae: 0.0329 - val_loss: 0.0016 - val_mae: 0.0332 - learning_rate: 5.0000e-04\n",
      "Epoch 7/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0019 - mae: 0.0328 - val_loss: 9.3839e-04 - val_mae: 0.0210 - learning_rate: 5.0000e-04\n",
      "Epoch 8/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0016 - mae: 0.0293 - val_loss: 8.4346e-04 - val_mae: 0.0191 - learning_rate: 5.0000e-04\n",
      "Epoch 9/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0014 - mae: 0.0272 - val_loss: 8.5404e-04 - val_mae: 0.0197 - learning_rate: 5.0000e-04\n",
      "Epoch 10/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0013 - mae: 0.0260 - val_loss: 8.4088e-04 - val_mae: 0.0198 - learning_rate: 5.0000e-04\n",
      "Epoch 11/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0246 - val_loss: 8.3214e-04 - val_mae: 0.0193 - learning_rate: 5.0000e-04\n",
      "Epoch 12/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0011 - mae: 0.0226 - val_loss: 8.7887e-04 - val_mae: 0.0206 - learning_rate: 5.0000e-04\n",
      "Epoch 13/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 9.9489e-04 - mae: 0.0221 - val_loss: 8.1839e-04 - val_mae: 0.0196 - learning_rate: 2.5000e-04\n",
      "Epoch 14/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 9.5313e-04 - mae: 0.0212 - val_loss: 8.1258e-04 - val_mae: 0.0192 - learning_rate: 2.5000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 9.4034e-04 - mae: 0.0212 - val_loss: 9.9238e-04 - val_mae: 0.0234 - learning_rate: 2.5000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 8.9486e-04 - mae: 0.0202 - val_loss: 9.0137e-04 - val_mae: 0.0218 - learning_rate: 2.5000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 8.1559e-04 - mae: 0.0191 - val_loss: 7.5636e-04 - val_mae: 0.0183 - learning_rate: 1.2500e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 7.4948e-04 - mae: 0.0182 - val_loss: 7.6542e-04 - val_mae: 0.0187 - learning_rate: 1.2500e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 7.7304e-04 - mae: 0.0182 - val_loss: 7.8115e-04 - val_mae: 0.0194 - learning_rate: 1.2500e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 7.6435e-04 - mae: 0.0181 - val_loss: 7.3917e-04 - val_mae: 0.0184 - learning_rate: 1.2500e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 7.3559e-04 - mae: 0.0178 - val_loss: 7.2206e-04 - val_mae: 0.0178 - learning_rate: 1.2500e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 7.1138e-04 - mae: 0.0177 - val_loss: 7.8973e-04 - val_mae: 0.0200 - learning_rate: 1.2500e-04\n",
      "Epoch 23/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 7.1701e-04 - mae: 0.0179 - val_loss: 6.9010e-04 - val_mae: 0.0174 - learning_rate: 1.2500e-04\n",
      "Epoch 24/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 6.9048e-04 - mae: 0.0172 - val_loss: 6.7223e-04 - val_mae: 0.0168 - learning_rate: 1.2500e-04\n",
      "Epoch 25/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 6.7212e-04 - mae: 0.0169 - val_loss: 6.8413e-04 - val_mae: 0.0176 - learning_rate: 6.2500e-05\n",
      "Epoch 26/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 6.5759e-04 - mae: 0.0163 - val_loss: 6.6185e-04 - val_mae: 0.0167 - learning_rate: 6.2500e-05\n",
      "Epoch 27/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 6.4985e-04 - mae: 0.0165 - val_loss: 6.3466e-04 - val_mae: 0.0165 - learning_rate: 6.2500e-05\n",
      "Epoch 28/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 6.5576e-04 - mae: 0.0165 - val_loss: 6.6673e-04 - val_mae: 0.0171 - learning_rate: 6.2500e-05\n",
      "Epoch 29/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 6.4266e-04 - mae: 0.0161 - val_loss: 6.3016e-04 - val_mae: 0.0164 - learning_rate: 6.2500e-05\n",
      "Epoch 30/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 6.2714e-04 - mae: 0.0162 - val_loss: 6.3352e-04 - val_mae: 0.0165 - learning_rate: 6.2500e-05\n",
      "Epoch 31/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 6.2447e-04 - mae: 0.0161 - val_loss: 6.2497e-04 - val_mae: 0.0164 - learning_rate: 6.2500e-05\n",
      "Epoch 32/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 6.0063e-04 - mae: 0.0156 - val_loss: 6.2674e-04 - val_mae: 0.0165 - learning_rate: 3.1250e-05\n",
      "Epoch 33/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 6.0406e-04 - mae: 0.0155 - val_loss: 6.1538e-04 - val_mae: 0.0161 - learning_rate: 3.1250e-05\n",
      "Epoch 34/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 6.1897e-04 - mae: 0.0158 - val_loss: 6.1574e-04 - val_mae: 0.0162 - learning_rate: 3.1250e-05\n",
      "Epoch 35/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 5.9481e-04 - mae: 0.0156 - val_loss: 6.1502e-04 - val_mae: 0.0163 - learning_rate: 3.1250e-05\n",
      "Epoch 36/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 6.1211e-04 - mae: 0.0157 - val_loss: 5.9967e-04 - val_mae: 0.0160 - learning_rate: 1.5625e-05\n",
      "Epoch 37/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 5.9350e-04 - mae: 0.0154 - val_loss: 6.0209e-04 - val_mae: 0.0160 - learning_rate: 1.5625e-05\n",
      "Epoch 38/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 5.8902e-04 - mae: 0.0152 - val_loss: 5.9924e-04 - val_mae: 0.0160 - learning_rate: 1.5625e-05\n",
      "Epoch 39/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 5.9466e-04 - mae: 0.0152 - val_loss: 5.9948e-04 - val_mae: 0.0160 - learning_rate: 1.5625e-05\n",
      "Epoch 40/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 5.9644e-04 - mae: 0.0154 - val_loss: 5.9204e-04 - val_mae: 0.0159 - learning_rate: 7.8125e-06\n",
      "Epoch 41/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5.7160e-04 - mae: 0.0148 - val_loss: 5.9074e-04 - val_mae: 0.0158 - learning_rate: 7.8125e-06\n",
      "Epoch 42/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 5.7367e-04 - mae: 0.0149 - val_loss: 5.9600e-04 - val_mae: 0.0160 - learning_rate: 7.8125e-06\n",
      "Epoch 43/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5.6541e-04 - mae: 0.0147 - val_loss: 5.9072e-04 - val_mae: 0.0159 - learning_rate: 7.8125e-06\n",
      "Epoch 44/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 5.8223e-04 - mae: 0.0150 - val_loss: 6.0509e-04 - val_mae: 0.0161 - learning_rate: 3.9063e-06\n",
      "Epoch 45/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 5.8175e-04 - mae: 0.0150 - val_loss: 5.9915e-04 - val_mae: 0.0161 - learning_rate: 3.9063e-06\n",
      "Epoch 46/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 5.8315e-04 - mae: 0.0151 - val_loss: 5.8989e-04 - val_mae: 0.0158 - learning_rate: 3.9063e-06\n",
      "Epoch 47/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 5.8643e-04 - mae: 0.0151 - val_loss: 5.9563e-04 - val_mae: 0.0159 - learning_rate: 3.9063e-06\n",
      "Epoch 48/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 5.8182e-04 - mae: 0.0149 - val_loss: 5.8705e-04 - val_mae: 0.0158 - learning_rate: 1.9531e-06\n",
      "Epoch 49/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 5.6784e-04 - mae: 0.0149 - val_loss: 5.8620e-04 - val_mae: 0.0158 - learning_rate: 1.9531e-06\n",
      "Epoch 50/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 5.6145e-04 - mae: 0.0147 - val_loss: 5.8767e-04 - val_mae: 0.0158 - learning_rate: 1.9531e-06\n",
      "Epoch 51/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 5.6744e-04 - mae: 0.0146 - val_loss: 5.8461e-04 - val_mae: 0.0158 - learning_rate: 1.9531e-06\n",
      "Epoch 52/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 5.6059e-04 - mae: 0.0145 - val_loss: 5.8396e-04 - val_mae: 0.0158 - learning_rate: 1.0000e-06\n",
      "Epoch 53/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 5.8245e-04 - mae: 0.0149 - val_loss: 5.8565e-04 - val_mae: 0.0158 - learning_rate: 1.0000e-06\n",
      "Epoch 54/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 5.5036e-04 - mae: 0.0145 - val_loss: 5.8412e-04 - val_mae: 0.0158 - learning_rate: 1.0000e-06\n",
      "Epoch 55/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 5.8103e-04 - mae: 0.0147 - val_loss: 5.8414e-04 - val_mae: 0.0158 - learning_rate: 1.0000e-06\n",
      "Epoch 56/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 5.5471e-04 - mae: 0.0148 - val_loss: 5.8191e-04 - val_mae: 0.0157 - learning_rate: 1.0000e-06\n",
      "Epoch 57/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 5.5288e-04 - mae: 0.0146 - val_loss: 5.8056e-04 - val_mae: 0.0157 - learning_rate: 1.0000e-06\n",
      "Epoch 58/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 5.7277e-04 - mae: 0.0148 - val_loss: 5.7924e-04 - val_mae: 0.0157 - learning_rate: 1.0000e-06\n",
      "Epoch 59/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 5.5363e-04 - mae: 0.0146 - val_loss: 5.8277e-04 - val_mae: 0.0157 - learning_rate: 1.0000e-06\n",
      "Epoch 60/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 5.5747e-04 - mae: 0.0149 - val_loss: 5.7990e-04 - val_mae: 0.0157 - learning_rate: 1.0000e-06\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step   \n",
      "âœ… Bijapur - onion | MAE=105.11, RMSE=212.35, RÂ²=0.9061, MAPE=7.65%, Acc=92.35%\n",
      "\n",
      "ğŸš€ Processing: Bijapur | wheat\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - loss: 0.0339 - mae: 0.1115 - val_loss: 0.0024 - val_mae: 0.0412 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0046 - mae: 0.0498 - val_loss: 0.0038 - val_mae: 0.0526 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0032 - mae: 0.0415 - val_loss: 0.0012 - val_mae: 0.0265 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0029 - mae: 0.0393 - val_loss: 6.7055e-04 - val_mae: 0.0201 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0026 - mae: 0.0365 - val_loss: 5.8948e-04 - val_mae: 0.0188 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0024 - mae: 0.0356 - val_loss: 6.7156e-04 - val_mae: 0.0203 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0021 - mae: 0.0318 - val_loss: 4.9242e-04 - val_mae: 0.0168 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0021 - mae: 0.0322 - val_loss: 4.6726e-04 - val_mae: 0.0164 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0020 - mae: 0.0319 - val_loss: 9.5141e-04 - val_mae: 0.0259 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0021 - mae: 0.0333 - val_loss: 8.0060e-04 - val_mae: 0.0235 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0019 - mae: 0.0306 - val_loss: 6.9556e-04 - val_mae: 0.0217 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0016 - mae: 0.0267 - val_loss: 7.5244e-04 - val_mae: 0.0217 - learning_rate: 5.0000e-04\n",
      "Epoch 13/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0017 - mae: 0.0274 - val_loss: 7.9113e-04 - val_mae: 0.0225 - learning_rate: 5.0000e-04\n",
      "Epoch 14/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0017 - mae: 0.0277 - val_loss: 6.4188e-04 - val_mae: 0.0194 - learning_rate: 5.0000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0016 - mae: 0.0264 - val_loss: 4.3325e-04 - val_mae: 0.0151 - learning_rate: 5.0000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mae: 0.0252 - val_loss: 0.0011 - val_mae: 0.0287 - learning_rate: 2.5000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0014 - mae: 0.0239 - val_loss: 0.0012 - val_mae: 0.0305 - learning_rate: 2.5000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0014 - mae: 0.0244 - val_loss: 0.0013 - val_mae: 0.0315 - learning_rate: 2.5000e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - mae: 0.0243 - val_loss: 0.0014 - val_mae: 0.0337 - learning_rate: 2.5000e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0013 - mae: 0.0229 - val_loss: 6.1755e-04 - val_mae: 0.0197 - learning_rate: 1.2500e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mae: 0.0225 - val_loss: 7.2110e-04 - val_mae: 0.0219 - learning_rate: 1.2500e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0013 - mae: 0.0223 - val_loss: 6.6985e-04 - val_mae: 0.0209 - learning_rate: 1.2500e-04\n",
      "Epoch 23/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mae: 0.0227 - val_loss: 7.4212e-04 - val_mae: 0.0224 - learning_rate: 1.2500e-04\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step   \n",
      "âœ… Bijapur - wheat | MAE=97.87, RMSE=159.47, RÂ²=0.9459, MAPE=4.26%, Acc=95.74%\n",
      "\n",
      "ğŸš€ Processing: Chamrajnagar | onion\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0938 - mae: 0.1562 - val_loss: 0.0220 - val_mae: 0.1057 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0055 - mae: 0.0498 - val_loss: 0.0089 - val_mae: 0.0792 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0044 - mae: 0.0476 - val_loss: 0.0053 - val_mae: 0.0615 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0031 - mae: 0.0405 - val_loss: 0.0037 - val_mae: 0.0474 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0023 - mae: 0.0351 - val_loss: 0.0027 - val_mae: 0.0368 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0019 - mae: 0.0329 - val_loss: 0.0051 - val_mae: 0.0543 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0016 - mae: 0.0297 - val_loss: 0.0088 - val_mae: 0.0748 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0013 - mae: 0.0263 - val_loss: 0.0083 - val_mae: 0.0723 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0264 - val_loss: 0.0059 - val_mae: 0.0612 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0010 - mae: 0.0230 - val_loss: 0.0023 - val_mae: 0.0279 - learning_rate: 5.0000e-04\n",
      "Epoch 11/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 8.6606e-04 - mae: 0.0213 - val_loss: 0.0061 - val_mae: 0.0597 - learning_rate: 5.0000e-04\n",
      "Epoch 12/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 8.2876e-04 - mae: 0.0206 - val_loss: 0.0032 - val_mae: 0.0355 - learning_rate: 5.0000e-04\n",
      "Epoch 13/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 7.9597e-04 - mae: 0.0203 - val_loss: 0.0031 - val_mae: 0.0334 - learning_rate: 5.0000e-04\n",
      "Epoch 14/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 7.8395e-04 - mae: 0.0197 - val_loss: 0.0066 - val_mae: 0.0571 - learning_rate: 5.0000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 7.0212e-04 - mae: 0.0187 - val_loss: 0.0020 - val_mae: 0.0253 - learning_rate: 2.5000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 7.0145e-04 - mae: 0.0187 - val_loss: 0.0022 - val_mae: 0.0250 - learning_rate: 2.5000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 6.4330e-04 - mae: 0.0179 - val_loss: 0.0019 - val_mae: 0.0255 - learning_rate: 2.5000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 6.2580e-04 - mae: 0.0174 - val_loss: 0.0020 - val_mae: 0.0244 - learning_rate: 2.5000e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6.2403e-04 - mae: 0.0172 - val_loss: 0.0025 - val_mae: 0.0281 - learning_rate: 2.5000e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 5.3478e-04 - mae: 0.0160 - val_loss: 0.0023 - val_mae: 0.0271 - learning_rate: 1.2500e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 5.7462e-04 - mae: 0.0163 - val_loss: 0.0032 - val_mae: 0.0365 - learning_rate: 1.2500e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 5.5448e-04 - mae: 0.0159 - val_loss: 0.0024 - val_mae: 0.0273 - learning_rate: 1.2500e-04\n",
      "Epoch 23/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5.4602e-04 - mae: 0.0158 - val_loss: 0.0023 - val_mae: 0.0261 - learning_rate: 1.2500e-04\n",
      "Epoch 24/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 5.1112e-04 - mae: 0.0156 - val_loss: 0.0019 - val_mae: 0.0249 - learning_rate: 6.2500e-05\n",
      "Epoch 25/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 5.0168e-04 - mae: 0.0152 - val_loss: 0.0021 - val_mae: 0.0255 - learning_rate: 6.2500e-05\n",
      "Epoch 26/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 4.9519e-04 - mae: 0.0151 - val_loss: 0.0024 - val_mae: 0.0279 - learning_rate: 6.2500e-05\n",
      "Epoch 27/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 4.9633e-04 - mae: 0.0151 - val_loss: 0.0022 - val_mae: 0.0261 - learning_rate: 6.2500e-05\n",
      "Epoch 28/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 5.0157e-04 - mae: 0.0154 - val_loss: 0.0025 - val_mae: 0.0303 - learning_rate: 6.2500e-05\n",
      "Epoch 29/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 4.8281e-04 - mae: 0.0150 - val_loss: 0.0018 - val_mae: 0.0237 - learning_rate: 3.1250e-05\n",
      "Epoch 30/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 4.9158e-04 - mae: 0.0149 - val_loss: 0.0018 - val_mae: 0.0239 - learning_rate: 3.1250e-05\n",
      "Epoch 31/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.6451e-04 - mae: 0.0147 - val_loss: 0.0018 - val_mae: 0.0240 - learning_rate: 3.1250e-05\n",
      "Epoch 32/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 4.7108e-04 - mae: 0.0148 - val_loss: 0.0018 - val_mae: 0.0241 - learning_rate: 3.1250e-05\n",
      "Epoch 33/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 4.6574e-04 - mae: 0.0147 - val_loss: 0.0018 - val_mae: 0.0237 - learning_rate: 1.5625e-05\n",
      "Epoch 34/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 4.5984e-04 - mae: 0.0144 - val_loss: 0.0017 - val_mae: 0.0241 - learning_rate: 1.5625e-05\n",
      "Epoch 35/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.7357e-04 - mae: 0.0146 - val_loss: 0.0017 - val_mae: 0.0236 - learning_rate: 1.5625e-05\n",
      "Epoch 36/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 4.6966e-04 - mae: 0.0146 - val_loss: 0.0018 - val_mae: 0.0235 - learning_rate: 1.5625e-05\n",
      "Epoch 37/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 4.8059e-04 - mae: 0.0147 - val_loss: 0.0017 - val_mae: 0.0235 - learning_rate: 1.5625e-05\n",
      "Epoch 38/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 4.6422e-04 - mae: 0.0147 - val_loss: 0.0017 - val_mae: 0.0236 - learning_rate: 1.5625e-05\n",
      "Epoch 39/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4.5788e-04 - mae: 0.0144 - val_loss: 0.0017 - val_mae: 0.0238 - learning_rate: 7.8125e-06\n",
      "Epoch 40/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 4.5977e-04 - mae: 0.0145 - val_loss: 0.0017 - val_mae: 0.0238 - learning_rate: 7.8125e-06\n",
      "Epoch 41/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 4.6406e-04 - mae: 0.0144 - val_loss: 0.0017 - val_mae: 0.0236 - learning_rate: 7.8125e-06\n",
      "Epoch 42/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 4.5172e-04 - mae: 0.0144 - val_loss: 0.0017 - val_mae: 0.0237 - learning_rate: 7.8125e-06\n",
      "Epoch 43/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 4.4419e-04 - mae: 0.0142 - val_loss: 0.0017 - val_mae: 0.0238 - learning_rate: 3.9063e-06\n",
      "Epoch 44/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.5504e-04 - mae: 0.0143 - val_loss: 0.0017 - val_mae: 0.0236 - learning_rate: 3.9063e-06\n",
      "Epoch 45/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 4.4258e-04 - mae: 0.0142 - val_loss: 0.0017 - val_mae: 0.0241 - learning_rate: 3.9063e-06\n",
      "Epoch 46/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 4.4570e-04 - mae: 0.0143 - val_loss: 0.0017 - val_mae: 0.0239 - learning_rate: 3.9063e-06\n",
      "Epoch 47/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 4.5942e-04 - mae: 0.0142 - val_loss: 0.0017 - val_mae: 0.0238 - learning_rate: 1.9531e-06\n",
      "Epoch 48/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 4.5408e-04 - mae: 0.0143 - val_loss: 0.0017 - val_mae: 0.0240 - learning_rate: 1.9531e-06\n",
      "Epoch 49/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 4.5643e-04 - mae: 0.0143 - val_loss: 0.0017 - val_mae: 0.0239 - learning_rate: 1.9531e-06\n",
      "Epoch 50/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 4.4824e-04 - mae: 0.0143 - val_loss: 0.0017 - val_mae: 0.0239 - learning_rate: 1.9531e-06\n",
      "Epoch 51/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 4.4928e-04 - mae: 0.0145 - val_loss: 0.0017 - val_mae: 0.0241 - learning_rate: 1.0000e-06\n",
      "Epoch 52/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 4.6198e-04 - mae: 0.0143 - val_loss: 0.0017 - val_mae: 0.0240 - learning_rate: 1.0000e-06\n",
      "Epoch 53/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 4.4224e-04 - mae: 0.0144 - val_loss: 0.0017 - val_mae: 0.0241 - learning_rate: 1.0000e-06\n",
      "\u001b[1m84/84\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step   \n",
      "âœ… Chamrajnagar - onion | MAE=72.3, RMSE=146.13, RÂ²=0.9823, MAPE=4.44%, Acc=95.56%\n",
      "\n",
      "ğŸš€ Processing: Chamrajnagar | tomato\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 0.1145 - mae: 0.1655 - val_loss: 0.0037 - val_mae: 0.0474 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0051 - mae: 0.0563 - val_loss: 0.0025 - val_mae: 0.0348 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0041 - mae: 0.0506 - val_loss: 0.0024 - val_mae: 0.0333 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0036 - mae: 0.0477 - val_loss: 0.0021 - val_mae: 0.0305 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0028 - mae: 0.0414 - val_loss: 0.0019 - val_mae: 0.0268 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0019 - mae: 0.0350 - val_loss: 0.0023 - val_mae: 0.0332 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0014 - mae: 0.0289 - val_loss: 0.0021 - val_mae: 0.0300 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.1400e-04 - mae: 0.0237 - val_loss: 0.0029 - val_mae: 0.0400 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 7.9962e-04 - mae: 0.0223 - val_loss: 0.0018 - val_mae: 0.0261 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 6.2340e-04 - mae: 0.0195 - val_loss: 0.0018 - val_mae: 0.0258 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 5.4569e-04 - mae: 0.0183 - val_loss: 0.0018 - val_mae: 0.0265 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4.6692e-04 - mae: 0.0168 - val_loss: 0.0017 - val_mae: 0.0248 - learning_rate: 0.0010\n",
      "Epoch 13/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4.2857e-04 - mae: 0.0161 - val_loss: 0.0017 - val_mae: 0.0250 - learning_rate: 0.0010\n",
      "Epoch 14/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 3.3670e-04 - mae: 0.0141 - val_loss: 0.0017 - val_mae: 0.0253 - learning_rate: 5.0000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 3.0897e-04 - mae: 0.0135 - val_loss: 0.0018 - val_mae: 0.0261 - learning_rate: 5.0000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 3.1219e-04 - mae: 0.0138 - val_loss: 0.0018 - val_mae: 0.0257 - learning_rate: 5.0000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 2.8749e-04 - mae: 0.0130 - val_loss: 0.0017 - val_mae: 0.0254 - learning_rate: 5.0000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 2.7169e-04 - mae: 0.0127 - val_loss: 0.0017 - val_mae: 0.0260 - learning_rate: 2.5000e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 2.7663e-04 - mae: 0.0127 - val_loss: 0.0018 - val_mae: 0.0262 - learning_rate: 2.5000e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 2.4294e-04 - mae: 0.0119 - val_loss: 0.0017 - val_mae: 0.0254 - learning_rate: 2.5000e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 2.4225e-04 - mae: 0.0119 - val_loss: 0.0018 - val_mae: 0.0269 - learning_rate: 2.5000e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 2.4452e-04 - mae: 0.0120 - val_loss: 0.0018 - val_mae: 0.0257 - learning_rate: 2.5000e-04\n",
      "Epoch 23/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 2.3360e-04 - mae: 0.0116 - val_loss: 0.0018 - val_mae: 0.0261 - learning_rate: 2.5000e-04\n",
      "Epoch 24/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 2.3398e-04 - mae: 0.0118 - val_loss: 0.0018 - val_mae: 0.0264 - learning_rate: 2.5000e-04\n",
      "Epoch 25/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 2.1241e-04 - mae: 0.0112 - val_loss: 0.0018 - val_mae: 0.0262 - learning_rate: 1.2500e-04\n",
      "Epoch 26/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 2.0731e-04 - mae: 0.0110 - val_loss: 0.0017 - val_mae: 0.0270 - learning_rate: 1.2500e-04\n",
      "Epoch 27/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 2.0694e-04 - mae: 0.0110 - val_loss: 0.0017 - val_mae: 0.0262 - learning_rate: 1.2500e-04\n",
      "Epoch 28/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 2.0638e-04 - mae: 0.0110 - val_loss: 0.0018 - val_mae: 0.0263 - learning_rate: 1.2500e-04\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step   \n",
      "âœ… Chamrajnagar - tomato | MAE=231.41, RMSE=423.16, RÂ²=0.8443, MAPE=17.58%, Acc=82.42%\n",
      "\n",
      "ğŸš€ Processing: Chamrajnagar | wheat\n",
      "âš ï¸ Not enough data for Chamrajnagar-wheat (len=1). Attempting crop-level fallback.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0635 - mae: 0.1469 - val_loss: 0.0444 - val_mae: 0.1823 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0067 - mae: 0.0650 - val_loss: 0.0311 - val_mae: 0.1496 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0049 - mae: 0.0552 - val_loss: 0.0229 - val_mae: 0.1240 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0031 - mae: 0.0443 - val_loss: 0.0234 - val_mae: 0.1281 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0026 - mae: 0.0403 - val_loss: 0.0141 - val_mae: 0.0927 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0023 - mae: 0.0369 - val_loss: 0.0120 - val_mae: 0.0849 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0018 - mae: 0.0326 - val_loss: 0.0088 - val_mae: 0.0730 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0016 - mae: 0.0306 - val_loss: 0.0139 - val_mae: 0.0933 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0012 - mae: 0.0265 - val_loss: 0.0119 - val_mae: 0.0848 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0011 - mae: 0.0254 - val_loss: 0.0132 - val_mae: 0.0920 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0011 - mae: 0.0254 - val_loss: 0.0100 - val_mae: 0.0765 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 8.6627e-04 - mae: 0.0218 - val_loss: 0.0114 - val_mae: 0.0834 - learning_rate: 5.0000e-04\n",
      "Epoch 13/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 8.5077e-04 - mae: 0.0213 - val_loss: 0.0064 - val_mae: 0.0609 - learning_rate: 5.0000e-04\n",
      "Epoch 14/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 7.1370e-04 - mae: 0.0193 - val_loss: 0.0078 - val_mae: 0.0662 - learning_rate: 5.0000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 7.2996e-04 - mae: 0.0196 - val_loss: 0.0100 - val_mae: 0.0771 - learning_rate: 5.0000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 6.8577e-04 - mae: 0.0189 - val_loss: 0.0059 - val_mae: 0.0577 - learning_rate: 5.0000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 6.4490e-04 - mae: 0.0180 - val_loss: 0.0062 - val_mae: 0.0581 - learning_rate: 5.0000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 6.6119e-04 - mae: 0.0185 - val_loss: 0.0062 - val_mae: 0.0582 - learning_rate: 5.0000e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 6.6093e-04 - mae: 0.0184 - val_loss: 0.0080 - val_mae: 0.0674 - learning_rate: 5.0000e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6.5378e-04 - mae: 0.0182 - val_loss: 0.0072 - val_mae: 0.0629 - learning_rate: 5.0000e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 5.6343e-04 - mae: 0.0167 - val_loss: 0.0053 - val_mae: 0.0533 - learning_rate: 2.5000e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 5.6565e-04 - mae: 0.0167 - val_loss: 0.0048 - val_mae: 0.0509 - learning_rate: 2.5000e-04\n",
      "Epoch 23/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 5.3716e-04 - mae: 0.0161 - val_loss: 0.0048 - val_mae: 0.0506 - learning_rate: 2.5000e-04\n",
      "Epoch 24/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 5.4003e-04 - mae: 0.0164 - val_loss: 0.0056 - val_mae: 0.0546 - learning_rate: 2.5000e-04\n",
      "Epoch 25/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5.1572e-04 - mae: 0.0156 - val_loss: 0.0055 - val_mae: 0.0542 - learning_rate: 2.5000e-04\n",
      "Epoch 26/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 5.0215e-04 - mae: 0.0152 - val_loss: 0.0047 - val_mae: 0.0499 - learning_rate: 2.5000e-04\n",
      "Epoch 27/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 4.6650e-04 - mae: 0.0148 - val_loss: 0.0051 - val_mae: 0.0517 - learning_rate: 1.2500e-04\n",
      "Epoch 28/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 4.6196e-04 - mae: 0.0146 - val_loss: 0.0049 - val_mae: 0.0511 - learning_rate: 1.2500e-04\n",
      "Epoch 29/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 4.6750e-04 - mae: 0.0148 - val_loss: 0.0049 - val_mae: 0.0507 - learning_rate: 1.2500e-04\n",
      "Epoch 30/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.4856e-04 - mae: 0.0144 - val_loss: 0.0052 - val_mae: 0.0524 - learning_rate: 1.2500e-04\n",
      "Epoch 31/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 4.5821e-04 - mae: 0.0146 - val_loss: 0.0045 - val_mae: 0.0486 - learning_rate: 6.2500e-05\n",
      "Epoch 32/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 4.4674e-04 - mae: 0.0143 - val_loss: 0.0039 - val_mae: 0.0458 - learning_rate: 6.2500e-05\n",
      "Epoch 33/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 4.7605e-04 - mae: 0.0148 - val_loss: 0.0039 - val_mae: 0.0457 - learning_rate: 6.2500e-05\n",
      "Epoch 34/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 4.5598e-04 - mae: 0.0141 - val_loss: 0.0036 - val_mae: 0.0443 - learning_rate: 6.2500e-05\n",
      "Epoch 35/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 4.4545e-04 - mae: 0.0142 - val_loss: 0.0045 - val_mae: 0.0484 - learning_rate: 6.2500e-05\n",
      "Epoch 36/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 4.4001e-04 - mae: 0.0141 - val_loss: 0.0050 - val_mae: 0.0511 - learning_rate: 6.2500e-05\n",
      "Epoch 37/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 4.3009e-04 - mae: 0.0138 - val_loss: 0.0041 - val_mae: 0.0466 - learning_rate: 6.2500e-05\n",
      "Epoch 38/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 4.2001e-04 - mae: 0.0137 - val_loss: 0.0044 - val_mae: 0.0483 - learning_rate: 6.2500e-05\n",
      "Epoch 39/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4.2174e-04 - mae: 0.0138 - val_loss: 0.0046 - val_mae: 0.0490 - learning_rate: 3.1250e-05\n",
      "Epoch 40/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 4.0954e-04 - mae: 0.0136 - val_loss: 0.0043 - val_mae: 0.0477 - learning_rate: 3.1250e-05\n",
      "Epoch 41/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 4.2469e-04 - mae: 0.0138 - val_loss: 0.0047 - val_mae: 0.0495 - learning_rate: 3.1250e-05\n",
      "Epoch 42/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 4.3102e-04 - mae: 0.0137 - val_loss: 0.0047 - val_mae: 0.0497 - learning_rate: 3.1250e-05\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step   \n",
      "âœ… Chamrajnagar - wheat | MAE=65.11, RMSE=83.74, RÂ²=0.9725, MAPE=2.9%, Acc=97.1%\n",
      "\n",
      "ğŸš€ Processing: Chikmagalur | capsicum\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1167 - mae: 0.2350 - val_loss: 0.0643 - val_mae: 0.2067 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0086 - mae: 0.0737 - val_loss: 0.0349 - val_mae: 0.1569 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0080 - mae: 0.0704 - val_loss: 0.0268 - val_mae: 0.1355 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0070 - mae: 0.0667 - val_loss: 0.0250 - val_mae: 0.1310 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0057 - mae: 0.0603 - val_loss: 0.0240 - val_mae: 0.1258 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0055 - mae: 0.0589 - val_loss: 0.0250 - val_mae: 0.1293 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0049 - mae: 0.0555 - val_loss: 0.0338 - val_mae: 0.1455 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0057 - mae: 0.0603 - val_loss: 0.0209 - val_mae: 0.1086 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0046 - mae: 0.0535 - val_loss: 0.0300 - val_mae: 0.1402 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0037 - mae: 0.0481 - val_loss: 0.0265 - val_mae: 0.1242 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0040 - mae: 0.0502 - val_loss: 0.0337 - val_mae: 0.1503 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0039 - mae: 0.0503 - val_loss: 0.0295 - val_mae: 0.1401 - learning_rate: 0.0010\n",
      "Epoch 13/60\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0031 - mae: 0.0444 - val_loss: 0.0219 - val_mae: 0.1112 - learning_rate: 5.0000e-04\n",
      "Epoch 14/60\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0027 - mae: 0.0403 - val_loss: 0.0210 - val_mae: 0.1135 - learning_rate: 5.0000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0026 - mae: 0.0393 - val_loss: 0.0204 - val_mae: 0.1110 - learning_rate: 5.0000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0024 - mae: 0.0382 - val_loss: 0.0200 - val_mae: 0.1087 - learning_rate: 5.0000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0022 - mae: 0.0365 - val_loss: 0.0186 - val_mae: 0.1054 - learning_rate: 5.0000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0021 - mae: 0.0360 - val_loss: 0.0196 - val_mae: 0.1013 - learning_rate: 5.0000e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0020 - mae: 0.0346 - val_loss: 0.0181 - val_mae: 0.1076 - learning_rate: 5.0000e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0019 - mae: 0.0336 - val_loss: 0.0183 - val_mae: 0.1102 - learning_rate: 5.0000e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0021 - mae: 0.0355 - val_loss: 0.0177 - val_mae: 0.1007 - learning_rate: 5.0000e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0018 - mae: 0.0324 - val_loss: 0.0185 - val_mae: 0.1066 - learning_rate: 5.0000e-04\n",
      "Epoch 23/60\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0015 - mae: 0.0305 - val_loss: 0.0186 - val_mae: 0.1034 - learning_rate: 5.0000e-04\n",
      "Epoch 24/60\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0017 - mae: 0.0325 - val_loss: 0.0167 - val_mae: 0.1013 - learning_rate: 5.0000e-04\n",
      "Epoch 25/60\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0018 - mae: 0.0324 - val_loss: 0.0166 - val_mae: 0.1022 - learning_rate: 5.0000e-04\n",
      "Epoch 26/60\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0016 - mae: 0.0314 - val_loss: 0.0206 - val_mae: 0.1205 - learning_rate: 5.0000e-04\n",
      "Epoch 27/60\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0026 - mae: 0.0406 - val_loss: 0.0189 - val_mae: 0.1117 - learning_rate: 5.0000e-04\n",
      "Epoch 28/60\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0016 - mae: 0.0307 - val_loss: 0.0170 - val_mae: 0.1041 - learning_rate: 5.0000e-04\n",
      "Epoch 29/60\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0014 - mae: 0.0285 - val_loss: 0.0176 - val_mae: 0.1068 - learning_rate: 5.0000e-04\n",
      "Epoch 30/60\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0014 - mae: 0.0294 - val_loss: 0.0156 - val_mae: 0.0927 - learning_rate: 2.5000e-04\n",
      "Epoch 31/60\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0011 - mae: 0.0257 - val_loss: 0.0155 - val_mae: 0.0920 - learning_rate: 2.5000e-04\n",
      "Epoch 32/60\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mae: 0.0249 - val_loss: 0.0153 - val_mae: 0.0918 - learning_rate: 2.5000e-04\n",
      "Epoch 33/60\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mae: 0.0253 - val_loss: 0.0157 - val_mae: 0.0925 - learning_rate: 2.5000e-04\n",
      "Epoch 34/60\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0011 - mae: 0.0256 - val_loss: 0.0161 - val_mae: 0.0974 - learning_rate: 2.5000e-04\n",
      "Epoch 35/60\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0269 - val_loss: 0.0160 - val_mae: 0.0953 - learning_rate: 2.5000e-04\n",
      "Epoch 36/60\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mae: 0.0255 - val_loss: 0.0168 - val_mae: 0.1008 - learning_rate: 2.5000e-04\n",
      "Epoch 37/60\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0011 - mae: 0.0248 - val_loss: 0.0151 - val_mae: 0.0886 - learning_rate: 1.2500e-04\n",
      "Epoch 38/60\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 9.4502e-04 - mae: 0.0229 - val_loss: 0.0150 - val_mae: 0.0870 - learning_rate: 1.2500e-04\n",
      "Epoch 39/60\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.9573e-04 - mae: 0.0235 - val_loss: 0.0151 - val_mae: 0.0870 - learning_rate: 1.2500e-04\n",
      "Epoch 40/60\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 9.6996e-04 - mae: 0.0234 - val_loss: 0.0150 - val_mae: 0.0882 - learning_rate: 1.2500e-04\n",
      "Epoch 41/60\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 9.2768e-04 - mae: 0.0226 - val_loss: 0.0151 - val_mae: 0.0882 - learning_rate: 1.2500e-04\n",
      "Epoch 42/60\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 9.5203e-04 - mae: 0.0237 - val_loss: 0.0145 - val_mae: 0.0857 - learning_rate: 1.2500e-04\n",
      "Epoch 43/60\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 8.7976e-04 - mae: 0.0221 - val_loss: 0.0148 - val_mae: 0.0875 - learning_rate: 1.2500e-04\n",
      "Epoch 44/60\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.4494e-04 - mae: 0.0232 - val_loss: 0.0150 - val_mae: 0.0871 - learning_rate: 1.2500e-04\n",
      "Epoch 45/60\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 8.3873e-04 - mae: 0.0216 - val_loss: 0.0149 - val_mae: 0.0882 - learning_rate: 1.2500e-04\n",
      "Epoch 46/60\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 8.8753e-04 - mae: 0.0225 - val_loss: 0.0151 - val_mae: 0.0879 - learning_rate: 1.2500e-04\n",
      "Epoch 47/60\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 8.0477e-04 - mae: 0.0211 - val_loss: 0.0148 - val_mae: 0.0877 - learning_rate: 6.2500e-05\n",
      "Epoch 48/60\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.0113e-04 - mae: 0.0212 - val_loss: 0.0146 - val_mae: 0.0849 - learning_rate: 6.2500e-05\n",
      "Epoch 49/60\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 8.0467e-04 - mae: 0.0209 - val_loss: 0.0151 - val_mae: 0.0883 - learning_rate: 6.2500e-05\n",
      "Epoch 50/60\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 7.9040e-04 - mae: 0.0207 - val_loss: 0.0148 - val_mae: 0.0867 - learning_rate: 6.2500e-05\n",
      "\u001b[1m32/32\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step  \n",
      "âœ… Chikmagalur - capsicum | MAE=96.79, RMSE=199.66, RÂ²=0.891, MAPE=5.41%, Acc=94.59%\n",
      "\n",
      "ğŸš€ Processing: Chikmagalur | onion\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.1513 - mae: 0.1767 - val_loss: 0.0104 - val_mae: 0.0704 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0055 - mae: 0.0559 - val_loss: 0.0067 - val_mae: 0.0516 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0039 - mae: 0.0485 - val_loss: 0.0037 - val_mae: 0.0400 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0032 - mae: 0.0441 - val_loss: 0.0031 - val_mae: 0.0382 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0027 - mae: 0.0402 - val_loss: 0.0027 - val_mae: 0.0346 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0023 - mae: 0.0370 - val_loss: 0.0021 - val_mae: 0.0302 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0020 - mae: 0.0345 - val_loss: 0.0019 - val_mae: 0.0288 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0019 - mae: 0.0330 - val_loss: 0.0023 - val_mae: 0.0346 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0020 - mae: 0.0342 - val_loss: 0.0020 - val_mae: 0.0338 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0015 - mae: 0.0300 - val_loss: 0.0015 - val_mae: 0.0269 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0013 - mae: 0.0267 - val_loss: 0.0015 - val_mae: 0.0267 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0013 - mae: 0.0277 - val_loss: 0.0015 - val_mae: 0.0274 - learning_rate: 0.0010\n",
      "Epoch 13/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0011 - mae: 0.0249 - val_loss: 0.0014 - val_mae: 0.0267 - learning_rate: 0.0010\n",
      "Epoch 14/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0011 - mae: 0.0244 - val_loss: 0.0014 - val_mae: 0.0264 - learning_rate: 0.0010\n",
      "Epoch 15/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0011 - mae: 0.0247 - val_loss: 0.0015 - val_mae: 0.0290 - learning_rate: 0.0010\n",
      "Epoch 16/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0011 - mae: 0.0254 - val_loss: 0.0025 - val_mae: 0.0416 - learning_rate: 0.0010\n",
      "Epoch 17/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 9.5627e-04 - mae: 0.0231 - val_loss: 0.0014 - val_mae: 0.0263 - learning_rate: 0.0010\n",
      "Epoch 18/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 7.3386e-04 - mae: 0.0198 - val_loss: 0.0013 - val_mae: 0.0244 - learning_rate: 5.0000e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 7.5933e-04 - mae: 0.0200 - val_loss: 0.0013 - val_mae: 0.0244 - learning_rate: 5.0000e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 7.4186e-04 - mae: 0.0200 - val_loss: 0.0013 - val_mae: 0.0244 - learning_rate: 5.0000e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 7.2826e-04 - mae: 0.0196 - val_loss: 0.0013 - val_mae: 0.0245 - learning_rate: 5.0000e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 6.9818e-04 - mae: 0.0191 - val_loss: 0.0012 - val_mae: 0.0241 - learning_rate: 5.0000e-04\n",
      "Epoch 23/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 6.9832e-04 - mae: 0.0191 - val_loss: 0.0013 - val_mae: 0.0257 - learning_rate: 2.5000e-04\n",
      "Epoch 24/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 6.5522e-04 - mae: 0.0185 - val_loss: 0.0013 - val_mae: 0.0248 - learning_rate: 2.5000e-04\n",
      "Epoch 25/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 6.5043e-04 - mae: 0.0185 - val_loss: 0.0013 - val_mae: 0.0245 - learning_rate: 2.5000e-04\n",
      "Epoch 26/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 6.4272e-04 - mae: 0.0184 - val_loss: 0.0012 - val_mae: 0.0237 - learning_rate: 2.5000e-04\n",
      "Epoch 27/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 6.0759e-04 - mae: 0.0179 - val_loss: 0.0012 - val_mae: 0.0237 - learning_rate: 1.2500e-04\n",
      "Epoch 28/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 6.4063e-04 - mae: 0.0183 - val_loss: 0.0012 - val_mae: 0.0240 - learning_rate: 1.2500e-04\n",
      "Epoch 29/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 6.2260e-04 - mae: 0.0180 - val_loss: 0.0012 - val_mae: 0.0239 - learning_rate: 1.2500e-04\n",
      "Epoch 30/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 6.4517e-04 - mae: 0.0184 - val_loss: 0.0012 - val_mae: 0.0235 - learning_rate: 1.2500e-04\n",
      "Epoch 31/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 5.8784e-04 - mae: 0.0174 - val_loss: 0.0012 - val_mae: 0.0236 - learning_rate: 6.2500e-05\n",
      "Epoch 32/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 5.8653e-04 - mae: 0.0173 - val_loss: 0.0013 - val_mae: 0.0246 - learning_rate: 6.2500e-05\n",
      "Epoch 33/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 5.8462e-04 - mae: 0.0173 - val_loss: 0.0012 - val_mae: 0.0241 - learning_rate: 6.2500e-05\n",
      "Epoch 34/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 5.8677e-04 - mae: 0.0172 - val_loss: 0.0012 - val_mae: 0.0242 - learning_rate: 6.2500e-05\n",
      "Epoch 35/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 5.6918e-04 - mae: 0.0170 - val_loss: 0.0012 - val_mae: 0.0236 - learning_rate: 3.1250e-05\n",
      "Epoch 36/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 5.6692e-04 - mae: 0.0169 - val_loss: 0.0013 - val_mae: 0.0246 - learning_rate: 3.1250e-05\n",
      "Epoch 37/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 5.7936e-04 - mae: 0.0171 - val_loss: 0.0012 - val_mae: 0.0235 - learning_rate: 3.1250e-05\n",
      "Epoch 38/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 5.7793e-04 - mae: 0.0172 - val_loss: 0.0012 - val_mae: 0.0233 - learning_rate: 3.1250e-05\n",
      "Epoch 39/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 5.5728e-04 - mae: 0.0166 - val_loss: 0.0013 - val_mae: 0.0246 - learning_rate: 1.5625e-05\n",
      "Epoch 40/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 5.5736e-04 - mae: 0.0167 - val_loss: 0.0012 - val_mae: 0.0242 - learning_rate: 1.5625e-05\n",
      "Epoch 41/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 5.5899e-04 - mae: 0.0168 - val_loss: 0.0012 - val_mae: 0.0239 - learning_rate: 1.5625e-05\n",
      "Epoch 42/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 5.5876e-04 - mae: 0.0169 - val_loss: 0.0012 - val_mae: 0.0241 - learning_rate: 1.5625e-05\n",
      "Epoch 43/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 5.6363e-04 - mae: 0.0169 - val_loss: 0.0013 - val_mae: 0.0256 - learning_rate: 7.8125e-06\n",
      "Epoch 44/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 5.4518e-04 - mae: 0.0166 - val_loss: 0.0013 - val_mae: 0.0252 - learning_rate: 7.8125e-06\n",
      "Epoch 45/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5.5100e-04 - mae: 0.0166 - val_loss: 0.0013 - val_mae: 0.0257 - learning_rate: 7.8125e-06\n",
      "Epoch 46/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 5.4958e-04 - mae: 0.0167 - val_loss: 0.0013 - val_mae: 0.0245 - learning_rate: 7.8125e-06\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step   \n",
      "âœ… Chikmagalur - onion | MAE=71.85, RMSE=110.62, RÂ²=0.9759, MAPE=4.61%, Acc=95.39%\n",
      "\n",
      "ğŸš€ Processing: Chikmagalur | tomato\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.1053 - mae: 0.1543 - val_loss: 0.0245 - val_mae: 0.1081 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0039 - mae: 0.0464 - val_loss: 0.0147 - val_mae: 0.0762 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0033 - mae: 0.0429 - val_loss: 0.0107 - val_mae: 0.0652 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0026 - mae: 0.0384 - val_loss: 0.0087 - val_mae: 0.0609 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0024 - mae: 0.0373 - val_loss: 0.0085 - val_mae: 0.0615 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0019 - mae: 0.0335 - val_loss: 0.0067 - val_mae: 0.0541 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0018 - mae: 0.0318 - val_loss: 0.0070 - val_mae: 0.0589 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0016 - mae: 0.0297 - val_loss: 0.0058 - val_mae: 0.0507 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0013 - mae: 0.0271 - val_loss: 0.0054 - val_mae: 0.0488 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0012 - mae: 0.0257 - val_loss: 0.0055 - val_mae: 0.0491 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0012 - mae: 0.0254 - val_loss: 0.0059 - val_mae: 0.0522 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0011 - mae: 0.0240 - val_loss: 0.0054 - val_mae: 0.0474 - learning_rate: 0.0010\n",
      "Epoch 13/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 9.5104e-04 - mae: 0.0225 - val_loss: 0.0058 - val_mae: 0.0497 - learning_rate: 0.0010\n",
      "Epoch 14/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.5534e-04 - mae: 0.0212 - val_loss: 0.0053 - val_mae: 0.0464 - learning_rate: 5.0000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 8.2217e-04 - mae: 0.0206 - val_loss: 0.0056 - val_mae: 0.0477 - learning_rate: 5.0000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 8.3363e-04 - mae: 0.0210 - val_loss: 0.0056 - val_mae: 0.0478 - learning_rate: 5.0000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 7.8817e-04 - mae: 0.0202 - val_loss: 0.0056 - val_mae: 0.0469 - learning_rate: 5.0000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 7.2185e-04 - mae: 0.0192 - val_loss: 0.0057 - val_mae: 0.0475 - learning_rate: 2.5000e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 7.2014e-04 - mae: 0.0190 - val_loss: 0.0057 - val_mae: 0.0478 - learning_rate: 2.5000e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 7.0520e-04 - mae: 0.0191 - val_loss: 0.0056 - val_mae: 0.0465 - learning_rate: 2.5000e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 6.7985e-04 - mae: 0.0186 - val_loss: 0.0056 - val_mae: 0.0458 - learning_rate: 2.5000e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 6.7663e-04 - mae: 0.0186 - val_loss: 0.0056 - val_mae: 0.0457 - learning_rate: 1.2500e-04\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step   \n",
      "âœ… Chikmagalur - tomato | MAE=135.7, RMSE=228.73, RÂ²=0.8984, MAPE=12.96%, Acc=87.04%\n",
      "\n",
      "ğŸš€ Processing: Chikmagalur | wheat\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0397 - mae: 0.1297 - val_loss: 0.0126 - val_mae: 0.1103 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0037 - mae: 0.0482 - val_loss: 3.2631e-04 - val_mae: 0.0125 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0022 - mae: 0.0366 - val_loss: 3.9946e-04 - val_mae: 0.0148 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0306 - val_loss: 7.9898e-04 - val_mae: 0.0244 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0269 - val_loss: 0.0015 - val_mae: 0.0341 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0011 - mae: 0.0265 - val_loss: 6.6416e-04 - val_mae: 0.0218 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 8.8997e-04 - mae: 0.0232 - val_loss: 2.4061e-04 - val_mae: 0.0121 - learning_rate: 5.0000e-04\n",
      "Epoch 8/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 7.9102e-04 - mae: 0.0216 - val_loss: 2.4834e-04 - val_mae: 0.0114 - learning_rate: 5.0000e-04\n",
      "Epoch 9/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 8.5530e-04 - mae: 0.0224 - val_loss: 4.0398e-04 - val_mae: 0.0146 - learning_rate: 5.0000e-04\n",
      "Epoch 10/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 7.9863e-04 - mae: 0.0217 - val_loss: 0.0026 - val_mae: 0.0485 - learning_rate: 5.0000e-04\n",
      "Epoch 11/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6.5470e-04 - mae: 0.0196 - val_loss: 2.0634e-04 - val_mae: 0.0111 - learning_rate: 2.5000e-04\n",
      "Epoch 12/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 6.1625e-04 - mae: 0.0191 - val_loss: 2.8945e-04 - val_mae: 0.0126 - learning_rate: 2.5000e-04\n",
      "Epoch 13/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 6.2334e-04 - mae: 0.0192 - val_loss: 2.0402e-04 - val_mae: 0.0111 - learning_rate: 2.5000e-04\n",
      "Epoch 14/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 6.3018e-04 - mae: 0.0192 - val_loss: 3.4582e-04 - val_mae: 0.0148 - learning_rate: 2.5000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 5.3440e-04 - mae: 0.0176 - val_loss: 1.7393e-04 - val_mae: 0.0094 - learning_rate: 2.5000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 5.3313e-04 - mae: 0.0175 - val_loss: 2.0670e-04 - val_mae: 0.0105 - learning_rate: 1.2500e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 4.8215e-04 - mae: 0.0167 - val_loss: 1.6225e-04 - val_mae: 0.0090 - learning_rate: 1.2500e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5.1503e-04 - mae: 0.0171 - val_loss: 5.3634e-04 - val_mae: 0.0192 - learning_rate: 1.2500e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.9620e-04 - mae: 0.0167 - val_loss: 3.0552e-04 - val_mae: 0.0136 - learning_rate: 1.2500e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 4.4825e-04 - mae: 0.0158 - val_loss: 1.9801e-04 - val_mae: 0.0099 - learning_rate: 6.2500e-05\n",
      "Epoch 21/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 4.5475e-04 - mae: 0.0158 - val_loss: 3.3228e-04 - val_mae: 0.0147 - learning_rate: 6.2500e-05\n",
      "Epoch 22/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 4.5647e-04 - mae: 0.0158 - val_loss: 1.2678e-04 - val_mae: 0.0066 - learning_rate: 6.2500e-05\n",
      "Epoch 23/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 4.4287e-04 - mae: 0.0155 - val_loss: 1.3422e-04 - val_mae: 0.0071 - learning_rate: 6.2500e-05\n",
      "Epoch 24/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 4.2268e-04 - mae: 0.0154 - val_loss: 1.9314e-04 - val_mae: 0.0097 - learning_rate: 3.1250e-05\n",
      "Epoch 25/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 4.2925e-04 - mae: 0.0154 - val_loss: 2.1102e-04 - val_mae: 0.0100 - learning_rate: 3.1250e-05\n",
      "Epoch 26/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.1719e-04 - mae: 0.0151 - val_loss: 1.5041e-04 - val_mae: 0.0079 - learning_rate: 3.1250e-05\n",
      "Epoch 27/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.1736e-04 - mae: 0.0152 - val_loss: 1.4594e-04 - val_mae: 0.0074 - learning_rate: 3.1250e-05\n",
      "Epoch 28/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 4.0439e-04 - mae: 0.0149 - val_loss: 1.7040e-04 - val_mae: 0.0085 - learning_rate: 1.5625e-05\n",
      "Epoch 29/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4.0019e-04 - mae: 0.0147 - val_loss: 2.1143e-04 - val_mae: 0.0103 - learning_rate: 1.5625e-05\n",
      "Epoch 30/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 3.9300e-04 - mae: 0.0146 - val_loss: 1.9028e-04 - val_mae: 0.0094 - learning_rate: 1.5625e-05\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step   \n",
      "âœ… Chikmagalur - wheat | MAE=17.18, RMSE=28.02, RÂ²=0.9967, MAPE=0.93%, Acc=99.07%\n",
      "\n",
      "ğŸš€ Processing: Chitradurga | onion\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.1444 - mae: 0.2105 - val_loss: 0.0138 - val_mae: 0.1080 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0105 - mae: 0.0793 - val_loss: 0.0040 - val_mae: 0.0612 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0067 - mae: 0.0615 - val_loss: 0.0024 - val_mae: 0.0480 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0055 - mae: 0.0560 - val_loss: 2.2598e-04 - val_mae: 0.0102 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0043 - mae: 0.0476 - val_loss: 4.8953e-04 - val_mae: 0.0181 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0037 - mae: 0.0445 - val_loss: 0.0026 - val_mae: 0.0496 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0034 - mae: 0.0429 - val_loss: 0.0042 - val_mae: 0.0635 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0029 - mae: 0.0392 - val_loss: 0.0010 - val_mae: 0.0291 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0022 - mae: 0.0324 - val_loss: 6.7787e-04 - val_mae: 0.0229 - learning_rate: 5.0000e-04\n",
      "Epoch 10/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0021 - mae: 0.0315 - val_loss: 3.9473e-04 - val_mae: 0.0149 - learning_rate: 5.0000e-04\n",
      "Epoch 11/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0020 - mae: 0.0303 - val_loss: 3.8488e-04 - val_mae: 0.0158 - learning_rate: 5.0000e-04\n",
      "Epoch 12/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0019 - mae: 0.0300 - val_loss: 2.6274e-04 - val_mae: 0.0122 - learning_rate: 5.0000e-04\n",
      "\u001b[1m81/81\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step   \n",
      "âœ… Chitradurga - onion | MAE=51.37, RMSE=91.86, RÂ²=0.9595, MAPE=3.49%, Acc=96.51%\n",
      "\n",
      "ğŸš€ Processing: Chitradurga | tomato\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.1405 - mae: 0.2262 - val_loss: 0.0049 - val_mae: 0.0701 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0099 - mae: 0.0693 - val_loss: 0.0016 - val_mae: 0.0396 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0073 - mae: 0.0604 - val_loss: 6.5904e-05 - val_mae: 0.0081 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0065 - mae: 0.0593 - val_loss: 0.0024 - val_mae: 0.0487 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0051 - mae: 0.0523 - val_loss: 0.0032 - val_mae: 0.0564 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0040 - mae: 0.0468 - val_loss: 2.7413e-04 - val_mae: 0.0166 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0037 - mae: 0.0454 - val_loss: 7.7146e-04 - val_mae: 0.0278 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0024 - mae: 0.0362 - val_loss: 9.7151e-06 - val_mae: 0.0031 - learning_rate: 5.0000e-04\n",
      "Epoch 9/60\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0023 - mae: 0.0359 - val_loss: 2.1900e-05 - val_mae: 0.0047 - learning_rate: 5.0000e-04\n",
      "Epoch 10/60\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0019 - mae: 0.0333 - val_loss: 2.2540e-04 - val_mae: 0.0150 - learning_rate: 5.0000e-04\n",
      "Epoch 11/60\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0018 - mae: 0.0323 - val_loss: 1.5745e-04 - val_mae: 0.0125 - learning_rate: 5.0000e-04\n",
      "Epoch 12/60\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - mae: 0.0290 - val_loss: 7.9766e-04 - val_mae: 0.0282 - learning_rate: 2.5000e-04\n",
      "Epoch 13/60\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - mae: 0.0292 - val_loss: 7.9245e-09 - val_mae: 8.9019e-05 - learning_rate: 2.5000e-04\n",
      "Epoch 14/60\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0014 - mae: 0.0285 - val_loss: 7.0804e-05 - val_mae: 0.0084 - learning_rate: 2.5000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0274 - val_loss: 3.5430e-05 - val_mae: 0.0060 - learning_rate: 2.5000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mae: 0.0264 - val_loss: 1.1005e-04 - val_mae: 0.0105 - learning_rate: 1.2500e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0011 - mae: 0.0257 - val_loss: 1.2783e-05 - val_mae: 0.0036 - learning_rate: 1.2500e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mae: 0.0256 - val_loss: 2.8401e-04 - val_mae: 0.0169 - learning_rate: 1.2500e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0011 - mae: 0.0253 - val_loss: 7.0974e-06 - val_mae: 0.0027 - learning_rate: 1.2500e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.5525e-04 - mae: 0.0242 - val_loss: 6.5103e-05 - val_mae: 0.0081 - learning_rate: 6.2500e-05\n",
      "Epoch 21/60\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 9.7998e-04 - mae: 0.0246 - val_loss: 4.8351e-07 - val_mae: 6.9535e-04 - learning_rate: 6.2500e-05\n",
      "\u001b[1m69/69\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step   \n",
      "âœ… Chitradurga - tomato | MAE=45.74, RMSE=92.03, RÂ²=0.9919, MAPE=4.09%, Acc=95.91%\n",
      "\n",
      "ğŸš€ Processing: Chitradurga | wheat\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - loss: 0.1188 - mae: 0.2121 - val_loss: 0.0591 - val_mae: 0.2419 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0173 - mae: 0.1086 - val_loss: 0.0367 - val_mae: 0.1904 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0066 - mae: 0.0646 - val_loss: 7.3663e-04 - val_mae: 0.0223 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0046 - mae: 0.0530 - val_loss: 7.8337e-04 - val_mae: 0.0238 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0037 - mae: 0.0483 - val_loss: 0.0064 - val_mae: 0.0791 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0030 - mae: 0.0438 - val_loss: 0.0030 - val_mae: 0.0530 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0022 - mae: 0.0367 - val_loss: 6.9623e-04 - val_mae: 0.0230 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0018 - mae: 0.0331 - val_loss: 1.6240e-04 - val_mae: 0.0107 - learning_rate: 5.0000e-04\n",
      "Epoch 9/60\n",
      "\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0017 - mae: 0.0315 - val_loss: 0.0028 - val_mae: 0.0512 - learning_rate: 5.0000e-04\n",
      "Epoch 10/60\n",
      "\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0016 - mae: 0.0313 - val_loss: 4.0634e-04 - val_mae: 0.0162 - learning_rate: 5.0000e-04\n",
      "Epoch 11/60\n",
      "\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0014 - mae: 0.0291 - val_loss: 3.5905e-04 - val_mae: 0.0152 - learning_rate: 5.0000e-04\n",
      "Epoch 12/60\n",
      "\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - mae: 0.0284 - val_loss: 1.5755e-04 - val_mae: 0.0105 - learning_rate: 5.0000e-04\n",
      "Epoch 13/60\n",
      "\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0011 - mae: 0.0252 - val_loss: 1.5610e-04 - val_mae: 0.0104 - learning_rate: 2.5000e-04\n",
      "Epoch 14/60\n",
      "\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0012 - mae: 0.0262 - val_loss: 0.0016 - val_mae: 0.0380 - learning_rate: 2.5000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0011 - mae: 0.0249 - val_loss: 2.7516e-04 - val_mae: 0.0131 - learning_rate: 2.5000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0010 - mae: 0.0240 - val_loss: 5.7785e-04 - val_mae: 0.0207 - learning_rate: 2.5000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.6203e-04 - mae: 0.0237 - val_loss: 1.4925e-04 - val_mae: 0.0102 - learning_rate: 1.2500e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.9811e-04 - mae: 0.0227 - val_loss: 2.1066e-04 - val_mae: 0.0116 - learning_rate: 1.2500e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 9.0906e-04 - mae: 0.0225 - val_loss: 1.6181e-04 - val_mae: 0.0104 - learning_rate: 1.2500e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 9.0432e-04 - mae: 0.0228 - val_loss: 1.7413e-04 - val_mae: 0.0107 - learning_rate: 1.2500e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.4859e-04 - mae: 0.0222 - val_loss: 1.5478e-04 - val_mae: 0.0103 - learning_rate: 6.2500e-05\n",
      "Epoch 22/60\n",
      "\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 9.0169e-04 - mae: 0.0227 - val_loss: 2.1238e-04 - val_mae: 0.0118 - learning_rate: 6.2500e-05\n",
      "Epoch 23/60\n",
      "\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 8.3587e-04 - mae: 0.0216 - val_loss: 1.7200e-04 - val_mae: 0.0107 - learning_rate: 6.2500e-05\n",
      "Epoch 24/60\n",
      "\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 8.6498e-04 - mae: 0.0220 - val_loss: 1.5976e-04 - val_mae: 0.0104 - learning_rate: 6.2500e-05\n",
      "Epoch 25/60\n",
      "\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 7.9388e-04 - mae: 0.0210 - val_loss: 2.6091e-04 - val_mae: 0.0128 - learning_rate: 3.1250e-05\n",
      "\u001b[1m62/62\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step   \n",
      "âœ… Chitradurga - wheat | MAE=27.54, RMSE=39.37, RÂ²=0.9954, MAPE=1.16%, Acc=98.84%\n",
      "\n",
      "ğŸš€ Processing: Davangere | capsicum\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 0.0950 - mae: 0.1659 - val_loss: 0.0139 - val_mae: 0.0844 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0053 - mae: 0.0571 - val_loss: 0.0081 - val_mae: 0.0559 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0043 - mae: 0.0522 - val_loss: 0.0082 - val_mae: 0.0570 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0039 - mae: 0.0486 - val_loss: 0.0061 - val_mae: 0.0474 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0034 - mae: 0.0454 - val_loss: 0.0063 - val_mae: 0.0469 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0027 - mae: 0.0409 - val_loss: 0.0055 - val_mae: 0.0440 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0026 - mae: 0.0402 - val_loss: 0.0062 - val_mae: 0.0482 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0021 - mae: 0.0363 - val_loss: 0.0062 - val_mae: 0.0490 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0022 - mae: 0.0368 - val_loss: 0.0067 - val_mae: 0.0534 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0021 - mae: 0.0358 - val_loss: 0.0059 - val_mae: 0.0471 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0016 - mae: 0.0310 - val_loss: 0.0048 - val_mae: 0.0456 - learning_rate: 5.0000e-04\n",
      "Epoch 12/60\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0015 - mae: 0.0294 - val_loss: 0.0046 - val_mae: 0.0405 - learning_rate: 5.0000e-04\n",
      "Epoch 13/60\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0015 - mae: 0.0296 - val_loss: 0.0046 - val_mae: 0.0405 - learning_rate: 5.0000e-04\n",
      "Epoch 14/60\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - mae: 0.0279 - val_loss: 0.0046 - val_mae: 0.0403 - learning_rate: 5.0000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0013 - mae: 0.0270 - val_loss: 0.0048 - val_mae: 0.0409 - learning_rate: 5.0000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0266 - val_loss: 0.0044 - val_mae: 0.0404 - learning_rate: 5.0000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0013 - mae: 0.0278 - val_loss: 0.0049 - val_mae: 0.0418 - learning_rate: 5.0000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0012 - mae: 0.0264 - val_loss: 0.0048 - val_mae: 0.0411 - learning_rate: 5.0000e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0263 - val_loss: 0.0049 - val_mae: 0.0422 - learning_rate: 5.0000e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0012 - mae: 0.0256 - val_loss: 0.0045 - val_mae: 0.0402 - learning_rate: 5.0000e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0011 - mae: 0.0248 - val_loss: 0.0043 - val_mae: 0.0405 - learning_rate: 2.5000e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0011 - mae: 0.0245 - val_loss: 0.0043 - val_mae: 0.0395 - learning_rate: 2.5000e-04\n",
      "Epoch 23/60\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0011 - mae: 0.0243 - val_loss: 0.0043 - val_mae: 0.0403 - learning_rate: 2.5000e-04\n",
      "Epoch 24/60\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0010 - mae: 0.0241 - val_loss: 0.0043 - val_mae: 0.0430 - learning_rate: 2.5000e-04\n",
      "Epoch 25/60\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0010 - mae: 0.0242 - val_loss: 0.0043 - val_mae: 0.0429 - learning_rate: 2.5000e-04\n",
      "Epoch 26/60\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.7756e-04 - mae: 0.0231 - val_loss: 0.0043 - val_mae: 0.0417 - learning_rate: 1.2500e-04\n",
      "Epoch 27/60\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 9.6621e-04 - mae: 0.0229 - val_loss: 0.0044 - val_mae: 0.0395 - learning_rate: 1.2500e-04\n",
      "Epoch 28/60\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 9.6244e-04 - mae: 0.0228 - val_loss: 0.0042 - val_mae: 0.0420 - learning_rate: 1.2500e-04\n",
      "Epoch 29/60\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0010 - mae: 0.0234 - val_loss: 0.0042 - val_mae: 0.0402 - learning_rate: 1.2500e-04\n",
      "Epoch 30/60\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 9.3812e-04 - mae: 0.0227 - val_loss: 0.0043 - val_mae: 0.0441 - learning_rate: 1.2500e-04\n",
      "Epoch 31/60\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.6267e-04 - mae: 0.0231 - val_loss: 0.0042 - val_mae: 0.0402 - learning_rate: 1.2500e-04\n",
      "Epoch 32/60\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 9.5199e-04 - mae: 0.0228 - val_loss: 0.0042 - val_mae: 0.0412 - learning_rate: 1.2500e-04\n",
      "Epoch 33/60\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 9.4316e-04 - mae: 0.0227 - val_loss: 0.0042 - val_mae: 0.0431 - learning_rate: 1.2500e-04\n",
      "Epoch 34/60\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 9.0034e-04 - mae: 0.0219 - val_loss: 0.0041 - val_mae: 0.0395 - learning_rate: 6.2500e-05\n",
      "Epoch 35/60\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.8541e-04 - mae: 0.0218 - val_loss: 0.0042 - val_mae: 0.0388 - learning_rate: 6.2500e-05\n",
      "Epoch 36/60\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.6924e-04 - mae: 0.0215 - val_loss: 0.0041 - val_mae: 0.0399 - learning_rate: 6.2500e-05\n",
      "Epoch 37/60\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 8.9309e-04 - mae: 0.0221 - val_loss: 0.0042 - val_mae: 0.0391 - learning_rate: 6.2500e-05\n",
      "Epoch 38/60\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 8.3554e-04 - mae: 0.0210 - val_loss: 0.0043 - val_mae: 0.0389 - learning_rate: 3.1250e-05\n",
      "Epoch 39/60\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 8.2401e-04 - mae: 0.0208 - val_loss: 0.0043 - val_mae: 0.0391 - learning_rate: 3.1250e-05\n",
      "Epoch 40/60\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 8.4033e-04 - mae: 0.0212 - val_loss: 0.0044 - val_mae: 0.0393 - learning_rate: 3.1250e-05\n",
      "Epoch 41/60\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 8.5736e-04 - mae: 0.0214 - val_loss: 0.0044 - val_mae: 0.0399 - learning_rate: 3.1250e-05\n",
      "Epoch 42/60\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 8.6963e-04 - mae: 0.0213 - val_loss: 0.0042 - val_mae: 0.0390 - learning_rate: 1.5625e-05\n",
      "Epoch 43/60\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 8.3506e-04 - mae: 0.0209 - val_loss: 0.0043 - val_mae: 0.0392 - learning_rate: 1.5625e-05\n",
      "Epoch 44/60\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.1442e-04 - mae: 0.0207 - val_loss: 0.0042 - val_mae: 0.0391 - learning_rate: 1.5625e-05\n",
      "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step   \n",
      "âœ… Davangere - capsicum | MAE=395.85, RMSE=601.78, RÂ²=0.8797, MAPE=13.17%, Acc=86.83%\n",
      "\n",
      "ğŸš€ Processing: Davangere | onion\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 0.0914 - mae: 0.1440 - val_loss: 0.0012 - val_mae: 0.0220 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0032 - mae: 0.0411 - val_loss: 0.0014 - val_mae: 0.0279 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0028 - mae: 0.0382 - val_loss: 6.2948e-04 - val_mae: 0.0195 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0025 - mae: 0.0356 - val_loss: 5.9944e-04 - val_mae: 0.0154 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0020 - mae: 0.0311 - val_loss: 5.4077e-04 - val_mae: 0.0149 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0019 - mae: 0.0301 - val_loss: 0.0014 - val_mae: 0.0319 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0252 - val_loss: 4.4654e-04 - val_mae: 0.0141 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0014 - mae: 0.0246 - val_loss: 8.8434e-04 - val_mae: 0.0242 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0013 - mae: 0.0231 - val_loss: 0.0010 - val_mae: 0.0278 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0208 - val_loss: 0.0022 - val_mae: 0.0433 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0204 - val_loss: 0.0011 - val_mae: 0.0297 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0010 - mae: 0.0183 - val_loss: 4.6579e-04 - val_mae: 0.0150 - learning_rate: 5.0000e-04\n",
      "Epoch 13/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.9059e-04 - mae: 0.0174 - val_loss: 3.1119e-04 - val_mae: 0.0114 - learning_rate: 5.0000e-04\n",
      "Epoch 14/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 9.9702e-04 - mae: 0.0177 - val_loss: 2.7443e-04 - val_mae: 0.0111 - learning_rate: 5.0000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 9.6115e-04 - mae: 0.0168 - val_loss: 2.7683e-04 - val_mae: 0.0109 - learning_rate: 5.0000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 9.1864e-04 - mae: 0.0164 - val_loss: 3.0374e-04 - val_mae: 0.0113 - learning_rate: 5.0000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 9.1464e-04 - mae: 0.0161 - val_loss: 2.3727e-04 - val_mae: 0.0107 - learning_rate: 5.0000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 8.3952e-04 - mae: 0.0145 - val_loss: 3.1551e-04 - val_mae: 0.0128 - learning_rate: 2.5000e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 8.3434e-04 - mae: 0.0144 - val_loss: 3.0075e-04 - val_mae: 0.0115 - learning_rate: 2.5000e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.0992e-04 - mae: 0.0142 - val_loss: 3.0007e-04 - val_mae: 0.0127 - learning_rate: 2.5000e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 8.2585e-04 - mae: 0.0142 - val_loss: 2.1857e-04 - val_mae: 0.0099 - learning_rate: 2.5000e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 7.9217e-04 - mae: 0.0134 - val_loss: 3.7253e-04 - val_mae: 0.0141 - learning_rate: 1.2500e-04\n",
      "Epoch 23/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 7.7645e-04 - mae: 0.0134 - val_loss: 3.1518e-04 - val_mae: 0.0124 - learning_rate: 1.2500e-04\n",
      "Epoch 24/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 7.9060e-04 - mae: 0.0135 - val_loss: 3.7262e-04 - val_mae: 0.0136 - learning_rate: 1.2500e-04\n",
      "Epoch 25/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 7.8069e-04 - mae: 0.0135 - val_loss: 3.2569e-04 - val_mae: 0.0137 - learning_rate: 1.2500e-04\n",
      "Epoch 26/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 7.5798e-04 - mae: 0.0129 - val_loss: 2.4376e-04 - val_mae: 0.0103 - learning_rate: 6.2500e-05\n",
      "Epoch 27/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 7.8080e-04 - mae: 0.0130 - val_loss: 2.3632e-04 - val_mae: 0.0102 - learning_rate: 6.2500e-05\n",
      "Epoch 28/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 7.4733e-04 - mae: 0.0129 - val_loss: 2.6168e-04 - val_mae: 0.0105 - learning_rate: 6.2500e-05\n",
      "Epoch 29/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 7.5530e-04 - mae: 0.0129 - val_loss: 2.6763e-04 - val_mae: 0.0111 - learning_rate: 6.2500e-05\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step   \n",
      "âœ… Davangere - onion | MAE=127.72, RMSE=308.56, RÂ²=0.8193, MAPE=10.53%, Acc=89.47%\n",
      "\n",
      "ğŸš€ Processing: Davangere | tomato\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 0.1166 - mae: 0.1757 - val_loss: 0.0238 - val_mae: 0.1083 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0054 - mae: 0.0578 - val_loss: 0.0154 - val_mae: 0.0803 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0043 - mae: 0.0518 - val_loss: 0.0141 - val_mae: 0.0753 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0035 - mae: 0.0460 - val_loss: 0.0108 - val_mae: 0.0665 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0029 - mae: 0.0422 - val_loss: 0.0137 - val_mae: 0.0773 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0028 - mae: 0.0417 - val_loss: 0.0114 - val_mae: 0.0662 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0022 - mae: 0.0369 - val_loss: 0.0092 - val_mae: 0.0579 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0019 - mae: 0.0338 - val_loss: 0.0098 - val_mae: 0.0569 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0019 - mae: 0.0343 - val_loss: 0.0117 - val_mae: 0.0701 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0017 - mae: 0.0322 - val_loss: 0.0124 - val_mae: 0.0716 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0015 - mae: 0.0294 - val_loss: 0.0089 - val_mae: 0.0557 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0014 - mae: 0.0285 - val_loss: 0.0091 - val_mae: 0.0596 - learning_rate: 0.0010\n",
      "Epoch 13/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0013 - mae: 0.0273 - val_loss: 0.0079 - val_mae: 0.0545 - learning_rate: 0.0010\n",
      "Epoch 14/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0013 - mae: 0.0277 - val_loss: 0.0070 - val_mae: 0.0534 - learning_rate: 0.0010\n",
      "Epoch 15/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0011 - mae: 0.0253 - val_loss: 0.0087 - val_mae: 0.0625 - learning_rate: 0.0010\n",
      "Epoch 16/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0011 - mae: 0.0245 - val_loss: 0.0067 - val_mae: 0.0529 - learning_rate: 0.0010\n",
      "Epoch 17/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0010 - mae: 0.0242 - val_loss: 0.0064 - val_mae: 0.0503 - learning_rate: 0.0010\n",
      "Epoch 18/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0012 - mae: 0.0262 - val_loss: 0.0082 - val_mae: 0.0620 - learning_rate: 0.0010\n",
      "Epoch 19/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0011 - mae: 0.0252 - val_loss: 0.0080 - val_mae: 0.0593 - learning_rate: 0.0010\n",
      "Epoch 20/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0010 - mae: 0.0238 - val_loss: 0.0071 - val_mae: 0.0560 - learning_rate: 0.0010\n",
      "Epoch 21/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0011 - mae: 0.0245 - val_loss: 0.0075 - val_mae: 0.0572 - learning_rate: 0.0010\n",
      "Epoch 22/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 7.9150e-04 - mae: 0.0210 - val_loss: 0.0068 - val_mae: 0.0520 - learning_rate: 5.0000e-04\n",
      "Epoch 23/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 7.6822e-04 - mae: 0.0203 - val_loss: 0.0070 - val_mae: 0.0530 - learning_rate: 5.0000e-04\n",
      "Epoch 24/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 7.6295e-04 - mae: 0.0204 - val_loss: 0.0084 - val_mae: 0.0618 - learning_rate: 5.0000e-04\n",
      "Epoch 25/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 7.7642e-04 - mae: 0.0205 - val_loss: 0.0072 - val_mae: 0.0538 - learning_rate: 5.0000e-04\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step   \n",
      "âœ… Davangere - tomato | MAE=232.24, RMSE=365.1, RÂ²=0.865, MAPE=32.09%, Acc=67.91%\n",
      "\n",
      "ğŸš€ Processing: Davangere | wheat\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 0.0808 - mae: 0.1661 - val_loss: 0.0062 - val_mae: 0.0563 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0100 - mae: 0.0784 - val_loss: 0.0031 - val_mae: 0.0281 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0041 - mae: 0.0511 - val_loss: 0.0077 - val_mae: 0.0797 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0028 - mae: 0.0413 - val_loss: 0.0032 - val_mae: 0.0307 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0027 - mae: 0.0409 - val_loss: 0.0047 - val_mae: 0.0544 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0019 - mae: 0.0340 - val_loss: 0.0043 - val_mae: 0.0482 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0014 - mae: 0.0284 - val_loss: 0.0032 - val_mae: 0.0305 - learning_rate: 5.0000e-04\n",
      "Epoch 8/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0265 - val_loss: 0.0031 - val_mae: 0.0288 - learning_rate: 5.0000e-04\n",
      "Epoch 9/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0011 - mae: 0.0253 - val_loss: 0.0033 - val_mae: 0.0328 - learning_rate: 5.0000e-04\n",
      "Epoch 10/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 9.3073e-04 - mae: 0.0232 - val_loss: 0.0034 - val_mae: 0.0366 - learning_rate: 5.0000e-04\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step   \n",
      "âœ… Davangere - wheat | MAE=99.86, RMSE=148.06, RÂ²=0.9202, MAPE=4.94%, Acc=95.06%\n",
      "\n",
      "ğŸš€ Processing: Dharwad | capsicum\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 241ms/step - loss: 1.1220 - mae: 0.8905 - val_loss: 0.6544 - val_mae: 0.7956 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.5478 - mae: 0.6144 - val_loss: 0.2312 - val_mae: 0.4616 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3843 - mae: 0.5727 - val_loss: 0.4769 - val_mae: 0.6783 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.1944 - mae: 0.3800 - val_loss: 0.0213 - val_mae: 0.1176 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.1273 - mae: 0.3092 - val_loss: 0.0527 - val_mae: 0.2025 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.1663 - mae: 0.3613 - val_loss: 0.0462 - val_mae: 0.1702 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0490 - mae: 0.1801 - val_loss: 0.2871 - val_mae: 0.5188 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.1074 - mae: 0.2987 - val_loss: 0.2109 - val_mae: 0.4397 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0444 - mae: 0.1825 - val_loss: 0.1024 - val_mae: 0.2917 - learning_rate: 5.0000e-04\n",
      "Epoch 10/60\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0282 - mae: 0.1282 - val_loss: 0.0453 - val_mae: 0.1699 - learning_rate: 5.0000e-04\n",
      "Epoch 11/60\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0446 - mae: 0.1641 - val_loss: 0.0395 - val_mae: 0.1542 - learning_rate: 5.0000e-04\n",
      "Epoch 12/60\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0392 - mae: 0.1434 - val_loss: 0.0686 - val_mae: 0.2272 - learning_rate: 5.0000e-04\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step\n",
      "âœ… Dharwad - capsicum | MAE=502.26, RMSE=683.9, RÂ²=0.6309, MAPE=17.52%, Acc=82.48%\n",
      "\n",
      "ğŸš€ Processing: Dharwad | onion\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0752 - mae: 0.1392 - val_loss: 0.0027 - val_mae: 0.0363 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0054 - mae: 0.0552 - val_loss: 0.0018 - val_mae: 0.0306 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0047 - mae: 0.0518 - val_loss: 0.0017 - val_mae: 0.0299 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0041 - mae: 0.0487 - val_loss: 0.0026 - val_mae: 0.0410 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0039 - mae: 0.0480 - val_loss: 0.0017 - val_mae: 0.0276 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0028 - mae: 0.0398 - val_loss: 0.0023 - val_mae: 0.0355 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0023 - mae: 0.0357 - val_loss: 0.0018 - val_mae: 0.0306 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0022 - mae: 0.0355 - val_loss: 0.0019 - val_mae: 0.0278 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0018 - mae: 0.0307 - val_loss: 0.0018 - val_mae: 0.0298 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0017 - mae: 0.0293 - val_loss: 0.0015 - val_mae: 0.0265 - learning_rate: 5.0000e-04\n",
      "Epoch 11/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0281 - val_loss: 0.0013 - val_mae: 0.0237 - learning_rate: 5.0000e-04\n",
      "Epoch 12/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0015 - mae: 0.0281 - val_loss: 0.0013 - val_mae: 0.0237 - learning_rate: 5.0000e-04\n",
      "Epoch 13/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mae: 0.0275 - val_loss: 0.0012 - val_mae: 0.0234 - learning_rate: 5.0000e-04\n",
      "Epoch 14/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0014 - mae: 0.0265 - val_loss: 0.0012 - val_mae: 0.0237 - learning_rate: 5.0000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0013 - mae: 0.0251 - val_loss: 0.0012 - val_mae: 0.0235 - learning_rate: 5.0000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mae: 0.0254 - val_loss: 0.0012 - val_mae: 0.0234 - learning_rate: 2.5000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0012 - mae: 0.0248 - val_loss: 0.0013 - val_mae: 0.0242 - learning_rate: 2.5000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0013 - mae: 0.0250 - val_loss: 0.0012 - val_mae: 0.0230 - learning_rate: 2.5000e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0012 - mae: 0.0240 - val_loss: 0.0012 - val_mae: 0.0233 - learning_rate: 2.5000e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0012 - mae: 0.0238 - val_loss: 0.0012 - val_mae: 0.0230 - learning_rate: 2.5000e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mae: 0.0238 - val_loss: 0.0012 - val_mae: 0.0239 - learning_rate: 2.5000e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0012 - mae: 0.0243 - val_loss: 0.0012 - val_mae: 0.0241 - learning_rate: 2.5000e-04\n",
      "Epoch 23/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0011 - mae: 0.0228 - val_loss: 0.0011 - val_mae: 0.0224 - learning_rate: 1.2500e-04\n",
      "Epoch 24/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0011 - mae: 0.0227 - val_loss: 0.0012 - val_mae: 0.0241 - learning_rate: 1.2500e-04\n",
      "Epoch 25/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0011 - mae: 0.0226 - val_loss: 0.0012 - val_mae: 0.0235 - learning_rate: 1.2500e-04\n",
      "Epoch 26/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0011 - mae: 0.0227 - val_loss: 0.0012 - val_mae: 0.0234 - learning_rate: 1.2500e-04\n",
      "Epoch 27/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0010 - mae: 0.0215 - val_loss: 0.0011 - val_mae: 0.0226 - learning_rate: 6.2500e-05\n",
      "Epoch 28/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0010 - mae: 0.0215 - val_loss: 0.0011 - val_mae: 0.0223 - learning_rate: 6.2500e-05\n",
      "Epoch 29/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0010 - mae: 0.0217 - val_loss: 0.0011 - val_mae: 0.0223 - learning_rate: 6.2500e-05\n",
      "Epoch 30/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0010 - mae: 0.0217 - val_loss: 0.0011 - val_mae: 0.0221 - learning_rate: 6.2500e-05\n",
      "Epoch 31/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0010 - mae: 0.0215 - val_loss: 0.0011 - val_mae: 0.0226 - learning_rate: 3.1250e-05\n",
      "Epoch 32/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0010 - mae: 0.0214 - val_loss: 0.0011 - val_mae: 0.0226 - learning_rate: 3.1250e-05\n",
      "Epoch 33/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 9.9848e-04 - mae: 0.0212 - val_loss: 0.0011 - val_mae: 0.0222 - learning_rate: 3.1250e-05\n",
      "Epoch 34/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 9.8089e-04 - mae: 0.0210 - val_loss: 0.0011 - val_mae: 0.0221 - learning_rate: 3.1250e-05\n",
      "Epoch 35/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 9.8368e-04 - mae: 0.0209 - val_loss: 0.0011 - val_mae: 0.0223 - learning_rate: 1.5625e-05\n",
      "Epoch 36/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 9.8625e-04 - mae: 0.0209 - val_loss: 0.0011 - val_mae: 0.0225 - learning_rate: 1.5625e-05\n",
      "Epoch 37/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 9.8139e-04 - mae: 0.0209 - val_loss: 0.0011 - val_mae: 0.0222 - learning_rate: 1.5625e-05\n",
      "Epoch 38/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 9.7068e-04 - mae: 0.0207 - val_loss: 0.0011 - val_mae: 0.0223 - learning_rate: 1.5625e-05\n",
      "Epoch 39/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 9.8634e-04 - mae: 0.0208 - val_loss: 0.0011 - val_mae: 0.0227 - learning_rate: 7.8125e-06\n",
      "Epoch 40/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 9.6000e-04 - mae: 0.0207 - val_loss: 0.0011 - val_mae: 0.0230 - learning_rate: 7.8125e-06\n",
      "Epoch 41/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 9.6259e-04 - mae: 0.0206 - val_loss: 0.0011 - val_mae: 0.0229 - learning_rate: 7.8125e-06\n",
      "Epoch 42/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 9.5837e-04 - mae: 0.0208 - val_loss: 0.0011 - val_mae: 0.0230 - learning_rate: 7.8125e-06\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step   \n",
      "âœ… Dharwad - onion | MAE=133.74, RMSE=216.53, RÂ²=0.9204, MAPE=11.14%, Acc=88.86%\n",
      "\n",
      "ğŸš€ Processing: Dharwad | tomato\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - loss: 0.1292 - mae: 0.2786 - val_loss: 0.0464 - val_mae: 0.1681 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0083 - mae: 0.0706 - val_loss: 0.0450 - val_mae: 0.0858 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0047 - mae: 0.0535 - val_loss: 0.0426 - val_mae: 0.0787 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0042 - mae: 0.0502 - val_loss: 0.0407 - val_mae: 0.1065 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0051 - mae: 0.0542 - val_loss: 0.0487 - val_mae: 0.1072 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0037 - mae: 0.0472 - val_loss: 0.0403 - val_mae: 0.0951 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0040 - mae: 0.0489 - val_loss: 0.0450 - val_mae: 0.1036 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0034 - mae: 0.0443 - val_loss: 0.0406 - val_mae: 0.0778 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0028 - mae: 0.0393 - val_loss: 0.0363 - val_mae: 0.1008 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0027 - mae: 0.0400 - val_loss: 0.0394 - val_mae: 0.0776 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0026 - mae: 0.0390 - val_loss: 0.0362 - val_mae: 0.0767 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0023 - mae: 0.0368 - val_loss: 0.0344 - val_mae: 0.0922 - learning_rate: 0.0010\n",
      "Epoch 13/60\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0024 - mae: 0.0370 - val_loss: 0.0355 - val_mae: 0.0885 - learning_rate: 0.0010\n",
      "Epoch 14/60\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0027 - mae: 0.0396 - val_loss: 0.0353 - val_mae: 0.0703 - learning_rate: 0.0010\n",
      "Epoch 15/60\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0018 - mae: 0.0304 - val_loss: 0.0274 - val_mae: 0.1002 - learning_rate: 0.0010\n",
      "Epoch 16/60\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0022 - mae: 0.0343 - val_loss: 0.0326 - val_mae: 0.0781 - learning_rate: 0.0010\n",
      "Epoch 17/60\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0016 - mae: 0.0295 - val_loss: 0.0336 - val_mae: 0.0821 - learning_rate: 0.0010\n",
      "Epoch 18/60\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0020 - mae: 0.0343 - val_loss: 0.0334 - val_mae: 0.0780 - learning_rate: 0.0010\n",
      "Epoch 19/60\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0016 - mae: 0.0291 - val_loss: 0.0348 - val_mae: 0.0977 - learning_rate: 0.0010\n",
      "Epoch 20/60\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0017 - mae: 0.0294 - val_loss: 0.0274 - val_mae: 0.0896 - learning_rate: 5.0000e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0014 - mae: 0.0279 - val_loss: 0.0292 - val_mae: 0.0670 - learning_rate: 5.0000e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0015 - mae: 0.0282 - val_loss: 0.0293 - val_mae: 0.0652 - learning_rate: 5.0000e-04\n",
      "Epoch 23/60\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0012 - mae: 0.0246 - val_loss: 0.0304 - val_mae: 0.0713 - learning_rate: 5.0000e-04\n",
      "\u001b[1m19/19\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step \n",
      "âœ… Dharwad - tomato | MAE=429.65, RMSE=644.0, RÂ²=0.3688, MAPE=23.13%, Acc=76.87%\n",
      "\n",
      "ğŸš€ Processing: Dharwad | wheat\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 0.0351 - mae: 0.1141 - val_loss: 0.0462 - val_mae: 0.1844 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0046 - mae: 0.0533 - val_loss: 0.0220 - val_mae: 0.1135 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0034 - mae: 0.0459 - val_loss: 0.0242 - val_mae: 0.1220 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0024 - mae: 0.0383 - val_loss: 0.0220 - val_mae: 0.1148 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0023 - mae: 0.0373 - val_loss: 0.0242 - val_mae: 0.1236 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0017 - mae: 0.0320 - val_loss: 0.0230 - val_mae: 0.1201 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0015 - mae: 0.0295 - val_loss: 0.0188 - val_mae: 0.1040 - learning_rate: 5.0000e-04\n",
      "Epoch 8/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0013 - mae: 0.0274 - val_loss: 0.0197 - val_mae: 0.1077 - learning_rate: 5.0000e-04\n",
      "Epoch 9/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0265 - val_loss: 0.0178 - val_mae: 0.1004 - learning_rate: 5.0000e-04\n",
      "Epoch 10/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0012 - mae: 0.0257 - val_loss: 0.0171 - val_mae: 0.0976 - learning_rate: 5.0000e-04\n",
      "Epoch 11/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0013 - mae: 0.0274 - val_loss: 0.0149 - val_mae: 0.0890 - learning_rate: 5.0000e-04\n",
      "Epoch 12/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mae: 0.0260 - val_loss: 0.0158 - val_mae: 0.0927 - learning_rate: 5.0000e-04\n",
      "Epoch 13/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0010 - mae: 0.0242 - val_loss: 0.0181 - val_mae: 0.1021 - learning_rate: 5.0000e-04\n",
      "Epoch 14/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 9.5674e-04 - mae: 0.0232 - val_loss: 0.0142 - val_mae: 0.0868 - learning_rate: 5.0000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.5457e-04 - mae: 0.0233 - val_loss: 0.0183 - val_mae: 0.1034 - learning_rate: 5.0000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0010 - mae: 0.0243 - val_loss: 0.0165 - val_mae: 0.0960 - learning_rate: 5.0000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0010 - mae: 0.0239 - val_loss: 0.0191 - val_mae: 0.1067 - learning_rate: 5.0000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 9.0799e-04 - mae: 0.0225 - val_loss: 0.0142 - val_mae: 0.0872 - learning_rate: 5.0000e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 8.4573e-04 - mae: 0.0214 - val_loss: 0.0144 - val_mae: 0.0876 - learning_rate: 2.5000e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 8.4019e-04 - mae: 0.0213 - val_loss: 0.0153 - val_mae: 0.0914 - learning_rate: 2.5000e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 8.8236e-04 - mae: 0.0219 - val_loss: 0.0158 - val_mae: 0.0934 - learning_rate: 2.5000e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.4007e-04 - mae: 0.0214 - val_loss: 0.0150 - val_mae: 0.0902 - learning_rate: 2.5000e-04\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step   \n",
      "âœ… Dharwad - wheat | MAE=98.43, RMSE=163.38, RÂ²=0.8781, MAPE=4.63%, Acc=95.37%\n",
      "\n",
      "ğŸš€ Processing: Gadag | onion\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 0.1277 - mae: 0.1874 - val_loss: 0.0105 - val_mae: 0.0851 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0092 - mae: 0.0731 - val_loss: 0.0039 - val_mae: 0.0442 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0065 - mae: 0.0615 - val_loss: 0.0027 - val_mae: 0.0379 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0053 - mae: 0.0552 - val_loss: 0.0028 - val_mae: 0.0351 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0043 - mae: 0.0496 - val_loss: 0.0024 - val_mae: 0.0398 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0036 - mae: 0.0446 - val_loss: 0.0024 - val_mae: 0.0430 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0032 - mae: 0.0411 - val_loss: 0.0016 - val_mae: 0.0253 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0026 - mae: 0.0372 - val_loss: 0.0022 - val_mae: 0.0407 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0028 - mae: 0.0381 - val_loss: 0.0019 - val_mae: 0.0360 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0025 - mae: 0.0362 - val_loss: 0.0017 - val_mae: 0.0277 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0022 - mae: 0.0334 - val_loss: 0.0021 - val_mae: 0.0370 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0020 - mae: 0.0308 - val_loss: 0.0014 - val_mae: 0.0188 - learning_rate: 5.0000e-04\n",
      "Epoch 13/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0019 - mae: 0.0291 - val_loss: 0.0014 - val_mae: 0.0213 - learning_rate: 5.0000e-04\n",
      "Epoch 14/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0018 - mae: 0.0290 - val_loss: 0.0017 - val_mae: 0.0293 - learning_rate: 5.0000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0019 - mae: 0.0303 - val_loss: 0.0014 - val_mae: 0.0175 - learning_rate: 5.0000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0288 - val_loss: 0.0015 - val_mae: 0.0196 - learning_rate: 5.0000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0016 - mae: 0.0261 - val_loss: 0.0014 - val_mae: 0.0204 - learning_rate: 2.5000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0015 - mae: 0.0257 - val_loss: 0.0014 - val_mae: 0.0196 - learning_rate: 2.5000e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0016 - mae: 0.0262 - val_loss: 0.0020 - val_mae: 0.0353 - learning_rate: 2.5000e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0253 - val_loss: 0.0015 - val_mae: 0.0227 - learning_rate: 2.5000e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0014 - mae: 0.0241 - val_loss: 0.0014 - val_mae: 0.0180 - learning_rate: 1.2500e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0014 - mae: 0.0239 - val_loss: 0.0014 - val_mae: 0.0152 - learning_rate: 1.2500e-04\n",
      "Epoch 23/60\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0014 - mae: 0.0239 - val_loss: 0.0016 - val_mae: 0.0256 - learning_rate: 1.2500e-04\n",
      "\u001b[1m80/80\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step   \n",
      "âœ… Gadag - onion | MAE=71.67, RMSE=122.84, RÂ²=0.9632, MAPE=6.95%, Acc=93.05%\n",
      "\n",
      "ğŸš€ Processing: Gadag | tomato\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - loss: 0.9220 - mae: 0.6668 - val_loss: 0.0224 - val_mae: 0.1362 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0412 - mae: 0.1650 - val_loss: 0.1319 - val_mae: 0.3486 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0257 - mae: 0.1342 - val_loss: 0.0749 - val_mae: 0.2634 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0213 - mae: 0.1211 - val_loss: 0.0717 - val_mae: 0.2580 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0154 - mae: 0.0979 - val_loss: 0.0584 - val_mae: 0.2337 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0120 - mae: 0.0832 - val_loss: 0.0412 - val_mae: 0.1965 - learning_rate: 5.0000e-04\n",
      "Epoch 7/60\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0102 - mae: 0.0771 - val_loss: 0.0356 - val_mae: 0.1823 - learning_rate: 5.0000e-04\n",
      "Epoch 8/60\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0087 - mae: 0.0712 - val_loss: 0.0274 - val_mae: 0.1592 - learning_rate: 5.0000e-04\n",
      "Epoch 9/60\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0068 - mae: 0.0639 - val_loss: 0.0202 - val_mae: 0.1353 - learning_rate: 5.0000e-04\n",
      "Epoch 10/60\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0052 - mae: 0.0565 - val_loss: 0.0209 - val_mae: 0.1385 - learning_rate: 5.0000e-04\n",
      "Epoch 11/60\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0045 - mae: 0.0528 - val_loss: 0.0200 - val_mae: 0.1351 - learning_rate: 5.0000e-04\n",
      "Epoch 12/60\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0037 - mae: 0.0474 - val_loss: 0.0159 - val_mae: 0.1194 - learning_rate: 5.0000e-04\n",
      "Epoch 13/60\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0035 - mae: 0.0460 - val_loss: 0.0125 - val_mae: 0.1034 - learning_rate: 5.0000e-04\n",
      "Epoch 14/60\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0032 - mae: 0.0442 - val_loss: 0.0097 - val_mae: 0.0864 - learning_rate: 5.0000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0032 - mae: 0.0438 - val_loss: 0.0091 - val_mae: 0.0810 - learning_rate: 5.0000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0028 - mae: 0.0406 - val_loss: 0.0104 - val_mae: 0.0913 - learning_rate: 5.0000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0028 - mae: 0.0406 - val_loss: 0.0070 - val_mae: 0.0620 - learning_rate: 5.0000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0028 - mae: 0.0416 - val_loss: 0.0073 - val_mae: 0.0614 - learning_rate: 5.0000e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0027 - mae: 0.0413 - val_loss: 0.0083 - val_mae: 0.0749 - learning_rate: 5.0000e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0027 - mae: 0.0393 - val_loss: 0.0077 - val_mae: 0.0727 - learning_rate: 5.0000e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0023 - mae: 0.0374 - val_loss: 0.0090 - val_mae: 0.0839 - learning_rate: 5.0000e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0023 - mae: 0.0368 - val_loss: 0.0085 - val_mae: 0.0797 - learning_rate: 2.5000e-04\n",
      "Epoch 23/60\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0021 - mae: 0.0359 - val_loss: 0.0086 - val_mae: 0.0814 - learning_rate: 2.5000e-04\n",
      "Epoch 24/60\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0022 - mae: 0.0362 - val_loss: 0.0071 - val_mae: 0.0677 - learning_rate: 2.5000e-04\n",
      "Epoch 25/60\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0022 - mae: 0.0364 - val_loss: 0.0072 - val_mae: 0.0695 - learning_rate: 2.5000e-04\n",
      "\u001b[1m19/19\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step \n",
      "âœ… Gadag - tomato | MAE=404.82, RMSE=517.08, RÂ²=0.9391, MAPE=8.62%, Acc=91.38%\n",
      "\n",
      "ğŸš€ Processing: Gadag | wheat\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - loss: 0.0337 - mae: 0.1081 - val_loss: 0.0104 - val_mae: 0.0843 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0039 - mae: 0.0483 - val_loss: 0.0087 - val_mae: 0.0764 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0029 - mae: 0.0420 - val_loss: 0.0102 - val_mae: 0.0841 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0021 - mae: 0.0350 - val_loss: 0.0078 - val_mae: 0.0721 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0018 - mae: 0.0322 - val_loss: 0.0057 - val_mae: 0.0611 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0016 - mae: 0.0299 - val_loss: 0.0052 - val_mae: 0.0589 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0014 - mae: 0.0276 - val_loss: 0.0099 - val_mae: 0.0829 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0012 - mae: 0.0248 - val_loss: 0.0076 - val_mae: 0.0715 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 9.5200e-04 - mae: 0.0221 - val_loss: 0.0093 - val_mae: 0.0798 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0010 - mae: 0.0227 - val_loss: 0.0070 - val_mae: 0.0680 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 8.5377e-04 - mae: 0.0204 - val_loss: 0.0079 - val_mae: 0.0728 - learning_rate: 5.0000e-04\n",
      "Epoch 12/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 8.7324e-04 - mae: 0.0204 - val_loss: 0.0085 - val_mae: 0.0763 - learning_rate: 5.0000e-04\n",
      "Epoch 13/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 7.9141e-04 - mae: 0.0191 - val_loss: 0.0080 - val_mae: 0.0734 - learning_rate: 5.0000e-04\n",
      "Epoch 14/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 8.1457e-04 - mae: 0.0194 - val_loss: 0.0071 - val_mae: 0.0690 - learning_rate: 5.0000e-04\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step   \n",
      "âœ… Gadag - wheat | MAE=262.06, RMSE=297.5, RÂ²=0.693, MAPE=14.23%, Acc=85.77%\n",
      "\n",
      "ğŸš€ Processing: Hassan | capsicum\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - loss: 0.0638 - mae: 0.1291 - val_loss: 0.0317 - val_mae: 0.1473 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0049 - mae: 0.0543 - val_loss: 0.0293 - val_mae: 0.1471 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0037 - mae: 0.0472 - val_loss: 0.0228 - val_mae: 0.1297 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0028 - mae: 0.0412 - val_loss: 0.0145 - val_mae: 0.0988 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0027 - mae: 0.0401 - val_loss: 0.0216 - val_mae: 0.1285 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0024 - mae: 0.0375 - val_loss: 0.0160 - val_mae: 0.1089 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0018 - mae: 0.0324 - val_loss: 0.0150 - val_mae: 0.1060 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0015 - mae: 0.0292 - val_loss: 0.0111 - val_mae: 0.0882 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0014 - mae: 0.0273 - val_loss: 0.0133 - val_mae: 0.1001 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0013 - mae: 0.0264 - val_loss: 0.0088 - val_mae: 0.0764 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0011 - mae: 0.0247 - val_loss: 0.0081 - val_mae: 0.0724 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0012 - mae: 0.0264 - val_loss: 0.0070 - val_mae: 0.0680 - learning_rate: 0.0010\n",
      "Epoch 13/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0011 - mae: 0.0242 - val_loss: 0.0066 - val_mae: 0.0659 - learning_rate: 0.0010\n",
      "Epoch 14/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 9.6022e-04 - mae: 0.0232 - val_loss: 0.0059 - val_mae: 0.0606 - learning_rate: 0.0010\n",
      "Epoch 15/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 8.3984e-04 - mae: 0.0214 - val_loss: 0.0064 - val_mae: 0.0627 - learning_rate: 0.0010\n",
      "Epoch 16/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 8.1496e-04 - mae: 0.0208 - val_loss: 0.0079 - val_mae: 0.0699 - learning_rate: 0.0010\n",
      "Epoch 17/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 7.9019e-04 - mae: 0.0209 - val_loss: 0.0074 - val_mae: 0.0672 - learning_rate: 0.0010\n",
      "Epoch 18/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 7.6422e-04 - mae: 0.0207 - val_loss: 0.0099 - val_mae: 0.0828 - learning_rate: 0.0010\n",
      "Epoch 19/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 5.1800e-04 - mae: 0.0161 - val_loss: 0.0074 - val_mae: 0.0661 - learning_rate: 5.0000e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 5.0629e-04 - mae: 0.0161 - val_loss: 0.0074 - val_mae: 0.0654 - learning_rate: 5.0000e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 5.0646e-04 - mae: 0.0159 - val_loss: 0.0066 - val_mae: 0.0608 - learning_rate: 5.0000e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 4.6784e-04 - mae: 0.0154 - val_loss: 0.0061 - val_mae: 0.0577 - learning_rate: 5.0000e-04\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step   \n",
      "âœ… Hassan - capsicum | MAE=121.4, RMSE=188.07, RÂ²=0.9552, MAPE=6.15%, Acc=93.85%\n",
      "\n",
      "ğŸš€ Processing: Hassan | onion\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0662 - mae: 0.1436 - val_loss: 0.0032 - val_mae: 0.0411 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0059 - mae: 0.0577 - val_loss: 0.0028 - val_mae: 0.0400 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0044 - mae: 0.0506 - val_loss: 0.0075 - val_mae: 0.0763 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0033 - mae: 0.0433 - val_loss: 0.0025 - val_mae: 0.0337 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0026 - mae: 0.0390 - val_loss: 0.0062 - val_mae: 0.0699 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0020 - mae: 0.0340 - val_loss: 0.0041 - val_mae: 0.0541 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0017 - mae: 0.0312 - val_loss: 0.0044 - val_mae: 0.0561 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0019 - mae: 0.0336 - val_loss: 0.0037 - val_mae: 0.0492 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - mae: 0.0276 - val_loss: 0.0045 - val_mae: 0.0572 - learning_rate: 5.0000e-04\n",
      "Epoch 10/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0013 - mae: 0.0279 - val_loss: 0.0025 - val_mae: 0.0375 - learning_rate: 5.0000e-04\n",
      "Epoch 11/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0011 - mae: 0.0253 - val_loss: 0.0030 - val_mae: 0.0433 - learning_rate: 5.0000e-04\n",
      "Epoch 12/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0011 - mae: 0.0254 - val_loss: 0.0029 - val_mae: 0.0422 - learning_rate: 5.0000e-04\n",
      "Epoch 13/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0010 - mae: 0.0242 - val_loss: 0.0020 - val_mae: 0.0298 - learning_rate: 2.5000e-04\n",
      "Epoch 14/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0010 - mae: 0.0240 - val_loss: 0.0018 - val_mae: 0.0278 - learning_rate: 2.5000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 9.8457e-04 - mae: 0.0236 - val_loss: 0.0018 - val_mae: 0.0281 - learning_rate: 2.5000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 9.5036e-04 - mae: 0.0229 - val_loss: 0.0017 - val_mae: 0.0275 - learning_rate: 2.5000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 9.8892e-04 - mae: 0.0236 - val_loss: 0.0019 - val_mae: 0.0289 - learning_rate: 2.5000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 9.2913e-04 - mae: 0.0227 - val_loss: 0.0020 - val_mae: 0.0316 - learning_rate: 2.5000e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 8.4485e-04 - mae: 0.0216 - val_loss: 0.0018 - val_mae: 0.0279 - learning_rate: 1.2500e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 8.1286e-04 - mae: 0.0209 - val_loss: 0.0020 - val_mae: 0.0306 - learning_rate: 1.2500e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.2538e-04 - mae: 0.0212 - val_loss: 0.0019 - val_mae: 0.0288 - learning_rate: 1.2500e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 8.4989e-04 - mae: 0.0217 - val_loss: 0.0019 - val_mae: 0.0291 - learning_rate: 1.2500e-04\n",
      "Epoch 23/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 8.3068e-04 - mae: 0.0212 - val_loss: 0.0020 - val_mae: 0.0310 - learning_rate: 6.2500e-05\n",
      "Epoch 24/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 8.0752e-04 - mae: 0.0211 - val_loss: 0.0018 - val_mae: 0.0277 - learning_rate: 6.2500e-05\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step   \n",
      "âœ… Hassan - onion | MAE=100.38, RMSE=148.95, RÂ²=0.9475, MAPE=7.43%, Acc=92.57%\n",
      "\n",
      "ğŸš€ Processing: Hassan | tomato\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.1388 - mae: 0.1720 - val_loss: 0.0190 - val_mae: 0.0820 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0046 - mae: 0.0518 - val_loss: 0.0150 - val_mae: 0.0679 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0039 - mae: 0.0486 - val_loss: 0.0138 - val_mae: 0.0645 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0033 - mae: 0.0443 - val_loss: 0.0116 - val_mae: 0.0767 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0027 - mae: 0.0402 - val_loss: 0.0094 - val_mae: 0.0647 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0022 - mae: 0.0367 - val_loss: 0.0078 - val_mae: 0.0567 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0019 - mae: 0.0332 - val_loss: 0.0070 - val_mae: 0.0554 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0016 - mae: 0.0311 - val_loss: 0.0063 - val_mae: 0.0505 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0012 - mae: 0.0268 - val_loss: 0.0056 - val_mae: 0.0483 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0011 - mae: 0.0249 - val_loss: 0.0059 - val_mae: 0.0558 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0011 - mae: 0.0255 - val_loss: 0.0050 - val_mae: 0.0455 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 8.9769e-04 - mae: 0.0228 - val_loss: 0.0048 - val_mae: 0.0462 - learning_rate: 0.0010\n",
      "Epoch 13/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 8.1536e-04 - mae: 0.0218 - val_loss: 0.0045 - val_mae: 0.0444 - learning_rate: 0.0010\n",
      "Epoch 14/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 7.1089e-04 - mae: 0.0200 - val_loss: 0.0043 - val_mae: 0.0453 - learning_rate: 0.0010\n",
      "Epoch 15/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 7.5958e-04 - mae: 0.0212 - val_loss: 0.0043 - val_mae: 0.0444 - learning_rate: 0.0010\n",
      "Epoch 16/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 6.3946e-04 - mae: 0.0191 - val_loss: 0.0044 - val_mae: 0.0456 - learning_rate: 0.0010\n",
      "Epoch 17/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 5.6484e-04 - mae: 0.0178 - val_loss: 0.0041 - val_mae: 0.0432 - learning_rate: 0.0010\n",
      "Epoch 18/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 5.2850e-04 - mae: 0.0173 - val_loss: 0.0044 - val_mae: 0.0455 - learning_rate: 0.0010\n",
      "Epoch 19/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4.8942e-04 - mae: 0.0167 - val_loss: 0.0039 - val_mae: 0.0422 - learning_rate: 0.0010\n",
      "Epoch 20/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5.0977e-04 - mae: 0.0170 - val_loss: 0.0039 - val_mae: 0.0422 - learning_rate: 0.0010\n",
      "Epoch 21/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 4.6445e-04 - mae: 0.0163 - val_loss: 0.0039 - val_mae: 0.0449 - learning_rate: 0.0010\n",
      "Epoch 22/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 4.6346e-04 - mae: 0.0163 - val_loss: 0.0042 - val_mae: 0.0436 - learning_rate: 0.0010\n",
      "Epoch 23/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 4.2171e-04 - mae: 0.0153 - val_loss: 0.0038 - val_mae: 0.0421 - learning_rate: 0.0010\n",
      "Epoch 24/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4.1215e-04 - mae: 0.0153 - val_loss: 0.0045 - val_mae: 0.0447 - learning_rate: 0.0010\n",
      "Epoch 25/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4.2703e-04 - mae: 0.0157 - val_loss: 0.0042 - val_mae: 0.0434 - learning_rate: 0.0010\n",
      "Epoch 26/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4.2399e-04 - mae: 0.0155 - val_loss: 0.0042 - val_mae: 0.0432 - learning_rate: 0.0010\n",
      "Epoch 27/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.2261e-04 - mae: 0.0155 - val_loss: 0.0041 - val_mae: 0.0427 - learning_rate: 0.0010\n",
      "Epoch 28/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 3.0419e-04 - mae: 0.0128 - val_loss: 0.0039 - val_mae: 0.0408 - learning_rate: 5.0000e-04\n",
      "Epoch 29/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 3.0872e-04 - mae: 0.0130 - val_loss: 0.0039 - val_mae: 0.0409 - learning_rate: 5.0000e-04\n",
      "Epoch 30/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 2.9028e-04 - mae: 0.0124 - val_loss: 0.0041 - val_mae: 0.0415 - learning_rate: 5.0000e-04\n",
      "Epoch 31/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 3.1568e-04 - mae: 0.0131 - val_loss: 0.0037 - val_mae: 0.0412 - learning_rate: 5.0000e-04\n",
      "Epoch 32/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 2.6987e-04 - mae: 0.0117 - val_loss: 0.0038 - val_mae: 0.0403 - learning_rate: 2.5000e-04\n",
      "Epoch 33/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 2.6238e-04 - mae: 0.0117 - val_loss: 0.0037 - val_mae: 0.0390 - learning_rate: 2.5000e-04\n",
      "Epoch 34/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 2.6176e-04 - mae: 0.0118 - val_loss: 0.0039 - val_mae: 0.0403 - learning_rate: 2.5000e-04\n",
      "Epoch 35/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 2.6019e-04 - mae: 0.0117 - val_loss: 0.0038 - val_mae: 0.0398 - learning_rate: 2.5000e-04\n",
      "Epoch 36/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 2.4525e-04 - mae: 0.0112 - val_loss: 0.0038 - val_mae: 0.0401 - learning_rate: 1.2500e-04\n",
      "Epoch 37/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 2.5003e-04 - mae: 0.0114 - val_loss: 0.0038 - val_mae: 0.0400 - learning_rate: 1.2500e-04\n",
      "Epoch 38/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 2.4400e-04 - mae: 0.0111 - val_loss: 0.0037 - val_mae: 0.0396 - learning_rate: 1.2500e-04\n",
      "Epoch 39/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 2.4852e-04 - mae: 0.0113 - val_loss: 0.0038 - val_mae: 0.0399 - learning_rate: 1.2500e-04\n",
      "Epoch 40/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 2.2321e-04 - mae: 0.0107 - val_loss: 0.0038 - val_mae: 0.0402 - learning_rate: 6.2500e-05\n",
      "Epoch 41/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 2.3977e-04 - mae: 0.0110 - val_loss: 0.0039 - val_mae: 0.0404 - learning_rate: 6.2500e-05\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step   \n",
      "âœ… Hassan - tomato | MAE=117.52, RMSE=192.32, RÂ²=0.9419, MAPE=10.26%, Acc=89.74%\n",
      "\n",
      "ğŸš€ Processing: Hassan | wheat\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.0285 - mae: 0.0995 - val_loss: 0.0045 - val_mae: 0.0597 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0036 - mae: 0.0443 - val_loss: 0.0017 - val_mae: 0.0339 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0029 - mae: 0.0395 - val_loss: 0.0024 - val_mae: 0.0422 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0021 - mae: 0.0326 - val_loss: 0.0019 - val_mae: 0.0364 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0016 - mae: 0.0287 - val_loss: 0.0037 - val_mae: 0.0550 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0013 - mae: 0.0256 - val_loss: 0.0024 - val_mae: 0.0425 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0011 - mae: 0.0251 - val_loss: 0.0030 - val_mae: 0.0489 - learning_rate: 5.0000e-04\n",
      "Epoch 8/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 8.0733e-04 - mae: 0.0204 - val_loss: 0.0019 - val_mae: 0.0369 - learning_rate: 5.0000e-04\n",
      "Epoch 9/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 6.7098e-04 - mae: 0.0188 - val_loss: 0.0014 - val_mae: 0.0314 - learning_rate: 5.0000e-04\n",
      "Epoch 10/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 6.4851e-04 - mae: 0.0183 - val_loss: 0.0015 - val_mae: 0.0328 - learning_rate: 5.0000e-04\n",
      "Epoch 11/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5.7113e-04 - mae: 0.0173 - val_loss: 0.0026 - val_mae: 0.0457 - learning_rate: 5.0000e-04\n",
      "Epoch 12/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 6.1754e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mae: 0.0289 - learning_rate: 5.0000e-04\n",
      "Epoch 13/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 5.2812e-04 - mae: 0.0167 - val_loss: 0.0015 - val_mae: 0.0333 - learning_rate: 5.0000e-04\n",
      "Epoch 14/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5.1374e-04 - mae: 0.0163 - val_loss: 0.0013 - val_mae: 0.0296 - learning_rate: 5.0000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 4.5825e-04 - mae: 0.0156 - val_loss: 8.9239e-04 - val_mae: 0.0242 - learning_rate: 5.0000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4.5702e-04 - mae: 0.0157 - val_loss: 8.7426e-04 - val_mae: 0.0239 - learning_rate: 5.0000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 4.3017e-04 - mae: 0.0152 - val_loss: 9.9599e-04 - val_mae: 0.0257 - learning_rate: 5.0000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 3.8703e-04 - mae: 0.0143 - val_loss: 0.0019 - val_mae: 0.0375 - learning_rate: 5.0000e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 3.5406e-04 - mae: 0.0137 - val_loss: 0.0011 - val_mae: 0.0278 - learning_rate: 5.0000e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 3.0768e-04 - mae: 0.0122 - val_loss: 0.0015 - val_mae: 0.0326 - learning_rate: 2.5000e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 2.9404e-04 - mae: 0.0120 - val_loss: 9.1839e-04 - val_mae: 0.0246 - learning_rate: 2.5000e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 2.7236e-04 - mae: 0.0115 - val_loss: 0.0012 - val_mae: 0.0295 - learning_rate: 2.5000e-04\n",
      "Epoch 23/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 2.7906e-04 - mae: 0.0117 - val_loss: 8.9184e-04 - val_mae: 0.0243 - learning_rate: 2.5000e-04\n",
      "Epoch 24/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 2.4505e-04 - mae: 0.0109 - val_loss: 0.0013 - val_mae: 0.0303 - learning_rate: 1.2500e-04\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step   \n",
      "âœ… Hassan - wheat | MAE=119.37, RMSE=150.96, RÂ²=0.942, MAPE=5.44%, Acc=94.56%\n",
      "\n",
      "ğŸš€ Processing: Haveri | capsicum\n",
      "âš ï¸ Not enough data for Haveri-capsicum (len=1). Attempting crop-level fallback.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0375 - mae: 0.1193 - val_loss: 0.0124 - val_mae: 0.0822 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0058 - mae: 0.0598 - val_loss: 0.0074 - val_mae: 0.0640 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0045 - mae: 0.0524 - val_loss: 0.0061 - val_mae: 0.0592 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0033 - mae: 0.0449 - val_loss: 0.0069 - val_mae: 0.0635 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0028 - mae: 0.0419 - val_loss: 0.0086 - val_mae: 0.0727 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0030 - mae: 0.0426 - val_loss: 0.0056 - val_mae: 0.0570 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0023 - mae: 0.0374 - val_loss: 0.0061 - val_mae: 0.0598 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0022 - mae: 0.0364 - val_loss: 0.0049 - val_mae: 0.0536 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0019 - mae: 0.0338 - val_loss: 0.0064 - val_mae: 0.0619 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0333 - val_loss: 0.0057 - val_mae: 0.0576 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0015 - mae: 0.0303 - val_loss: 0.0050 - val_mae: 0.0533 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0303 - val_loss: 0.0126 - val_mae: 0.0947 - learning_rate: 0.0010\n",
      "Epoch 13/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0014 - mae: 0.0292 - val_loss: 0.0042 - val_mae: 0.0492 - learning_rate: 5.0000e-04\n",
      "Epoch 14/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0013 - mae: 0.0277 - val_loss: 0.0041 - val_mae: 0.0488 - learning_rate: 5.0000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0014 - mae: 0.0288 - val_loss: 0.0040 - val_mae: 0.0485 - learning_rate: 5.0000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mae: 0.0271 - val_loss: 0.0044 - val_mae: 0.0497 - learning_rate: 5.0000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0011 - mae: 0.0258 - val_loss: 0.0052 - val_mae: 0.0535 - learning_rate: 5.0000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0012 - mae: 0.0268 - val_loss: 0.0051 - val_mae: 0.0533 - learning_rate: 5.0000e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 9.7497e-04 - mae: 0.0239 - val_loss: 0.0043 - val_mae: 0.0483 - learning_rate: 2.5000e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 9.5336e-04 - mae: 0.0236 - val_loss: 0.0045 - val_mae: 0.0493 - learning_rate: 2.5000e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 9.6197e-04 - mae: 0.0235 - val_loss: 0.0044 - val_mae: 0.0489 - learning_rate: 2.5000e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 9.7377e-04 - mae: 0.0239 - val_loss: 0.0047 - val_mae: 0.0504 - learning_rate: 2.5000e-04\n",
      "Epoch 23/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 8.7893e-04 - mae: 0.0226 - val_loss: 0.0043 - val_mae: 0.0481 - learning_rate: 1.2500e-04\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step   \n",
      "âœ… Haveri - capsicum | MAE=142.35, RMSE=184.37, RÂ²=0.9351, MAPE=5.91%, Acc=94.09%\n",
      "\n",
      "ğŸš€ Processing: Haveri | onion\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.0850 - mae: 0.1578 - val_loss: 0.0041 - val_mae: 0.0460 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0081 - mae: 0.0671 - val_loss: 0.0033 - val_mae: 0.0433 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0056 - mae: 0.0558 - val_loss: 0.0032 - val_mae: 0.0440 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0051 - mae: 0.0543 - val_loss: 0.0044 - val_mae: 0.0519 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0041 - mae: 0.0481 - val_loss: 0.0021 - val_mae: 0.0327 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0028 - mae: 0.0390 - val_loss: 0.0020 - val_mae: 0.0330 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0025 - mae: 0.0368 - val_loss: 0.0017 - val_mae: 0.0276 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0024 - mae: 0.0365 - val_loss: 0.0020 - val_mae: 0.0307 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0020 - mae: 0.0332 - val_loss: 0.0016 - val_mae: 0.0253 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0019 - mae: 0.0328 - val_loss: 0.0015 - val_mae: 0.0270 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0019 - mae: 0.0322 - val_loss: 0.0013 - val_mae: 0.0239 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0019 - mae: 0.0321 - val_loss: 0.0016 - val_mae: 0.0284 - learning_rate: 0.0010\n",
      "Epoch 13/60\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0019 - mae: 0.0327 - val_loss: 0.0013 - val_mae: 0.0248 - learning_rate: 0.0010\n",
      "Epoch 14/60\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0016 - mae: 0.0296 - val_loss: 0.0019 - val_mae: 0.0346 - learning_rate: 0.0010\n",
      "Epoch 15/60\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0015 - mae: 0.0286 - val_loss: 0.0013 - val_mae: 0.0256 - learning_rate: 0.0010\n",
      "Epoch 16/60\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0013 - mae: 0.0250 - val_loss: 0.0013 - val_mae: 0.0244 - learning_rate: 5.0000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mae: 0.0249 - val_loss: 0.0013 - val_mae: 0.0245 - learning_rate: 5.0000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mae: 0.0248 - val_loss: 0.0012 - val_mae: 0.0246 - learning_rate: 5.0000e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0250 - val_loss: 0.0012 - val_mae: 0.0243 - learning_rate: 5.0000e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mae: 0.0240 - val_loss: 0.0017 - val_mae: 0.0325 - learning_rate: 5.0000e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0012 - mae: 0.0241 - val_loss: 0.0016 - val_mae: 0.0320 - learning_rate: 5.0000e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0012 - mae: 0.0243 - val_loss: 0.0014 - val_mae: 0.0282 - learning_rate: 5.0000e-04\n",
      "Epoch 23/60\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0011 - mae: 0.0235 - val_loss: 0.0010 - val_mae: 0.0211 - learning_rate: 5.0000e-04\n",
      "Epoch 24/60\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0010 - mae: 0.0221 - val_loss: 0.0013 - val_mae: 0.0274 - learning_rate: 5.0000e-04\n",
      "Epoch 25/60\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0011 - mae: 0.0235 - val_loss: 0.0012 - val_mae: 0.0253 - learning_rate: 5.0000e-04\n",
      "Epoch 26/60\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0011 - mae: 0.0232 - val_loss: 9.7579e-04 - val_mae: 0.0209 - learning_rate: 5.0000e-04\n",
      "Epoch 27/60\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0011 - mae: 0.0232 - val_loss: 0.0010 - val_mae: 0.0222 - learning_rate: 5.0000e-04\n",
      "Epoch 28/60\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 9.1263e-04 - mae: 0.0201 - val_loss: 9.5442e-04 - val_mae: 0.0208 - learning_rate: 2.5000e-04\n",
      "Epoch 29/60\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 8.8216e-04 - mae: 0.0198 - val_loss: 9.9002e-04 - val_mae: 0.0221 - learning_rate: 2.5000e-04\n",
      "Epoch 30/60\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 9.7673e-04 - mae: 0.0212 - val_loss: 9.7339e-04 - val_mae: 0.0215 - learning_rate: 2.5000e-04\n",
      "Epoch 31/60\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 9.4574e-04 - mae: 0.0209 - val_loss: 0.0012 - val_mae: 0.0261 - learning_rate: 2.5000e-04\n",
      "Epoch 32/60\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 8.6718e-04 - mae: 0.0196 - val_loss: 0.0015 - val_mae: 0.0298 - learning_rate: 1.2500e-04\n",
      "Epoch 33/60\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.6331e-04 - mae: 0.0193 - val_loss: 0.0011 - val_mae: 0.0247 - learning_rate: 1.2500e-04\n",
      "Epoch 34/60\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.2995e-04 - mae: 0.0189 - val_loss: 0.0011 - val_mae: 0.0241 - learning_rate: 1.2500e-04\n",
      "Epoch 35/60\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 8.1591e-04 - mae: 0.0188 - val_loss: 0.0010 - val_mae: 0.0231 - learning_rate: 1.2500e-04\n",
      "Epoch 36/60\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 8.1978e-04 - mae: 0.0190 - val_loss: 0.0013 - val_mae: 0.0273 - learning_rate: 6.2500e-05\n",
      "\u001b[1m76/76\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step   \n",
      "âœ… Haveri - onion | MAE=62.16, RMSE=103.02, RÂ²=0.9716, MAPE=4.25%, Acc=95.75%\n",
      "\n",
      "ğŸš€ Processing: Haveri | tomato\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - loss: 0.1179 - mae: 0.2523 - val_loss: 1.2897 - val_mae: 0.9674 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0200 - mae: 0.1120 - val_loss: 0.0630 - val_mae: 0.1839 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0106 - mae: 0.0808 - val_loss: 0.0595 - val_mae: 0.1850 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0065 - mae: 0.0647 - val_loss: 0.1123 - val_mae: 0.3061 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0050 - mae: 0.0556 - val_loss: 0.0610 - val_mae: 0.2153 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0039 - mae: 0.0498 - val_loss: 0.0422 - val_mae: 0.1643 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0036 - mae: 0.0481 - val_loss: 0.0557 - val_mae: 0.2146 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0032 - mae: 0.0449 - val_loss: 0.0465 - val_mae: 0.1775 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0027 - mae: 0.0412 - val_loss: 0.0748 - val_mae: 0.2460 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0031 - mae: 0.0436 - val_loss: 0.0415 - val_mae: 0.1649 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0024 - mae: 0.0392 - val_loss: 0.0435 - val_mae: 0.1586 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0025 - mae: 0.0402 - val_loss: 0.0342 - val_mae: 0.1583 - learning_rate: 0.0010\n",
      "Epoch 13/60\n",
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0019 - mae: 0.0332 - val_loss: 0.0262 - val_mae: 0.0930 - learning_rate: 0.0010\n",
      "Epoch 14/60\n",
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0017 - mae: 0.0329 - val_loss: 0.0377 - val_mae: 0.1354 - learning_rate: 0.0010\n",
      "Epoch 15/60\n",
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0017 - mae: 0.0330 - val_loss: 0.0458 - val_mae: 0.1691 - learning_rate: 0.0010\n",
      "Epoch 16/60\n",
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0016 - mae: 0.0317 - val_loss: 0.0377 - val_mae: 0.1516 - learning_rate: 0.0010\n",
      "Epoch 17/60\n",
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0016 - mae: 0.0312 - val_loss: 0.0380 - val_mae: 0.1357 - learning_rate: 0.0010\n",
      "Epoch 18/60\n",
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0011 - mae: 0.0263 - val_loss: 0.0302 - val_mae: 0.1230 - learning_rate: 5.0000e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0010 - mae: 0.0256 - val_loss: 0.0292 - val_mae: 0.1089 - learning_rate: 5.0000e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 9.7290e-04 - mae: 0.0248 - val_loss: 0.0380 - val_mae: 0.1554 - learning_rate: 5.0000e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 9.3763e-04 - mae: 0.0242 - val_loss: 0.0360 - val_mae: 0.1446 - learning_rate: 5.0000e-04\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step \n",
      "âœ… Haveri - tomato | MAE=346.66, RMSE=631.02, RÂ²=0.9276, MAPE=21.79%, Acc=78.21%\n",
      "\n",
      "ğŸš€ Processing: Haveri | wheat\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0272 - mae: 0.1015 - val_loss: 0.0164 - val_mae: 0.0975 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0036 - mae: 0.0474 - val_loss: 0.0053 - val_mae: 0.0462 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0031 - mae: 0.0437 - val_loss: 0.0048 - val_mae: 0.0511 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0022 - mae: 0.0375 - val_loss: 0.0041 - val_mae: 0.0386 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0018 - mae: 0.0337 - val_loss: 0.0045 - val_mae: 0.0364 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0286 - val_loss: 0.0033 - val_mae: 0.0387 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0011 - mae: 0.0262 - val_loss: 0.0032 - val_mae: 0.0325 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 9.9047e-04 - mae: 0.0246 - val_loss: 0.0031 - val_mae: 0.0430 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 8.8604e-04 - mae: 0.0231 - val_loss: 0.0028 - val_mae: 0.0378 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 9.1465e-04 - mae: 0.0240 - val_loss: 0.0029 - val_mae: 0.0377 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 7.1886e-04 - mae: 0.0208 - val_loss: 0.0028 - val_mae: 0.0361 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 8.1227e-04 - mae: 0.0225 - val_loss: 0.0033 - val_mae: 0.0295 - learning_rate: 0.0010\n",
      "Epoch 13/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 8.1074e-04 - mae: 0.0225 - val_loss: 0.0026 - val_mae: 0.0334 - learning_rate: 0.0010\n",
      "Epoch 14/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 6.0794e-04 - mae: 0.0192 - val_loss: 0.0024 - val_mae: 0.0318 - learning_rate: 0.0010\n",
      "Epoch 15/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 6.1014e-04 - mae: 0.0193 - val_loss: 0.0028 - val_mae: 0.0266 - learning_rate: 0.0010\n",
      "Epoch 16/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5.6009e-04 - mae: 0.0184 - val_loss: 0.0026 - val_mae: 0.0411 - learning_rate: 0.0010\n",
      "Epoch 17/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.9213e-04 - mae: 0.0172 - val_loss: 0.0022 - val_mae: 0.0273 - learning_rate: 0.0010\n",
      "Epoch 18/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 4.3342e-04 - mae: 0.0158 - val_loss: 0.0028 - val_mae: 0.0456 - learning_rate: 0.0010\n",
      "Epoch 19/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5.6154e-04 - mae: 0.0186 - val_loss: 0.0023 - val_mae: 0.0249 - learning_rate: 0.0010\n",
      "Epoch 20/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 3.7528e-04 - mae: 0.0148 - val_loss: 0.0020 - val_mae: 0.0314 - learning_rate: 0.0010\n",
      "Epoch 21/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 3.5521e-04 - mae: 0.0145 - val_loss: 0.0020 - val_mae: 0.0329 - learning_rate: 0.0010\n",
      "Epoch 22/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 3.5623e-04 - mae: 0.0145 - val_loss: 0.0020 - val_mae: 0.0229 - learning_rate: 0.0010\n",
      "Epoch 23/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.6543e-04 - mae: 0.0169 - val_loss: 0.0023 - val_mae: 0.0227 - learning_rate: 0.0010\n",
      "Epoch 24/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 3.6754e-04 - mae: 0.0147 - val_loss: 0.0018 - val_mae: 0.0270 - learning_rate: 0.0010\n",
      "Epoch 25/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 3.5654e-04 - mae: 0.0147 - val_loss: 0.0019 - val_mae: 0.0341 - learning_rate: 0.0010\n",
      "Epoch 26/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 3.4151e-04 - mae: 0.0143 - val_loss: 0.0019 - val_mae: 0.0360 - learning_rate: 0.0010\n",
      "Epoch 27/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 3.4162e-04 - mae: 0.0141 - val_loss: 0.0018 - val_mae: 0.0293 - learning_rate: 0.0010\n",
      "Epoch 28/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 2.8840e-04 - mae: 0.0129 - val_loss: 0.0019 - val_mae: 0.0370 - learning_rate: 0.0010\n",
      "Epoch 29/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 2.8667e-04 - mae: 0.0130 - val_loss: 0.0018 - val_mae: 0.0314 - learning_rate: 5.0000e-04\n",
      "Epoch 30/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 3.3412e-04 - mae: 0.0142 - val_loss: 0.0017 - val_mae: 0.0286 - learning_rate: 5.0000e-04\n",
      "Epoch 31/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 3.4307e-04 - mae: 0.0143 - val_loss: 0.0017 - val_mae: 0.0307 - learning_rate: 5.0000e-04\n",
      "Epoch 32/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 3.0279e-04 - mae: 0.0133 - val_loss: 0.0017 - val_mae: 0.0327 - learning_rate: 5.0000e-04\n",
      "Epoch 33/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 2.2374e-04 - mae: 0.0109 - val_loss: 0.0015 - val_mae: 0.0297 - learning_rate: 2.5000e-04\n",
      "Epoch 34/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 2.0300e-04 - mae: 0.0104 - val_loss: 0.0016 - val_mae: 0.0312 - learning_rate: 2.5000e-04\n",
      "Epoch 35/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 2.2050e-04 - mae: 0.0110 - val_loss: 0.0015 - val_mae: 0.0254 - learning_rate: 2.5000e-04\n",
      "Epoch 36/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 2.2645e-04 - mae: 0.0113 - val_loss: 0.0015 - val_mae: 0.0229 - learning_rate: 2.5000e-04\n",
      "Epoch 37/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 2.1373e-04 - mae: 0.0108 - val_loss: 0.0015 - val_mae: 0.0227 - learning_rate: 2.5000e-04\n",
      "Epoch 38/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 1.8467e-04 - mae: 0.0099 - val_loss: 0.0015 - val_mae: 0.0228 - learning_rate: 1.2500e-04\n",
      "Epoch 39/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 1.7962e-04 - mae: 0.0097 - val_loss: 0.0015 - val_mae: 0.0250 - learning_rate: 1.2500e-04\n",
      "Epoch 40/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 1.7773e-04 - mae: 0.0097 - val_loss: 0.0015 - val_mae: 0.0265 - learning_rate: 1.2500e-04\n",
      "Epoch 41/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 1.7886e-04 - mae: 0.0097 - val_loss: 0.0015 - val_mae: 0.0264 - learning_rate: 1.2500e-04\n",
      "Epoch 42/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.6002e-04 - mae: 0.0091 - val_loss: 0.0015 - val_mae: 0.0275 - learning_rate: 6.2500e-05\n",
      "Epoch 43/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 1.6249e-04 - mae: 0.0092 - val_loss: 0.0015 - val_mae: 0.0253 - learning_rate: 6.2500e-05\n",
      "Epoch 44/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.6911e-04 - mae: 0.0094 - val_loss: 0.0015 - val_mae: 0.0278 - learning_rate: 6.2500e-05\n",
      "Epoch 45/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 1.6105e-04 - mae: 0.0091 - val_loss: 0.0015 - val_mae: 0.0266 - learning_rate: 6.2500e-05\n",
      "Epoch 46/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 1.5705e-04 - mae: 0.0090 - val_loss: 0.0015 - val_mae: 0.0251 - learning_rate: 3.1250e-05\n",
      "Epoch 47/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 1.5631e-04 - mae: 0.0090 - val_loss: 0.0015 - val_mae: 0.0267 - learning_rate: 3.1250e-05\n",
      "Epoch 48/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.5528e-04 - mae: 0.0089 - val_loss: 0.0015 - val_mae: 0.0268 - learning_rate: 3.1250e-05\n",
      "Epoch 49/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.5664e-04 - mae: 0.0090 - val_loss: 0.0014 - val_mae: 0.0265 - learning_rate: 3.1250e-05\n",
      "Epoch 50/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 1.5511e-04 - mae: 0.0090 - val_loss: 0.0015 - val_mae: 0.0277 - learning_rate: 3.1250e-05\n",
      "Epoch 51/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.5419e-04 - mae: 0.0089 - val_loss: 0.0014 - val_mae: 0.0268 - learning_rate: 3.1250e-05\n",
      "Epoch 52/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.5859e-04 - mae: 0.0091 - val_loss: 0.0014 - val_mae: 0.0250 - learning_rate: 3.1250e-05\n",
      "Epoch 53/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.5637e-04 - mae: 0.0090 - val_loss: 0.0015 - val_mae: 0.0280 - learning_rate: 3.1250e-05\n",
      "Epoch 54/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 1.5126e-04 - mae: 0.0088 - val_loss: 0.0014 - val_mae: 0.0241 - learning_rate: 1.5625e-05\n",
      "Epoch 55/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 1.5387e-04 - mae: 0.0089 - val_loss: 0.0014 - val_mae: 0.0233 - learning_rate: 1.5625e-05\n",
      "Epoch 56/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 1.5031e-04 - mae: 0.0088 - val_loss: 0.0014 - val_mae: 0.0233 - learning_rate: 1.5625e-05\n",
      "Epoch 57/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.5634e-04 - mae: 0.0090 - val_loss: 0.0014 - val_mae: 0.0222 - learning_rate: 1.5625e-05\n",
      "Epoch 58/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.4977e-04 - mae: 0.0088 - val_loss: 0.0014 - val_mae: 0.0252 - learning_rate: 7.8125e-06\n",
      "Epoch 59/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.4898e-04 - mae: 0.0087 - val_loss: 0.0014 - val_mae: 0.0241 - learning_rate: 7.8125e-06\n",
      "Epoch 60/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 1.4916e-04 - mae: 0.0088 - val_loss: 0.0014 - val_mae: 0.0247 - learning_rate: 7.8125e-06\n",
      "\u001b[1m83/83\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step   \n",
      "âœ… Haveri - wheat | MAE=27.62, RMSE=41.15, RÂ²=0.9867, MAPE=1.43%, Acc=98.57%\n",
      "\n",
      "ğŸš€ Processing: Kalburgi | capsicum\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - loss: 0.1255 - mae: 0.2582 - val_loss: 0.0251 - val_mae: 0.1186 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0175 - mae: 0.1033 - val_loss: 0.0292 - val_mae: 0.1348 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0178 - mae: 0.1032 - val_loss: 0.0281 - val_mae: 0.1320 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0156 - mae: 0.0969 - val_loss: 0.0356 - val_mae: 0.1587 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0153 - mae: 0.0957 - val_loss: 0.0329 - val_mae: 0.1512 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0143 - mae: 0.0929 - val_loss: 0.0107 - val_mae: 0.0689 - learning_rate: 5.0000e-04\n",
      "Epoch 7/60\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0122 - mae: 0.0838 - val_loss: 0.0119 - val_mae: 0.0672 - learning_rate: 5.0000e-04\n",
      "Epoch 8/60\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0122 - mae: 0.0826 - val_loss: 0.0156 - val_mae: 0.0849 - learning_rate: 5.0000e-04\n",
      "Epoch 9/60\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0114 - mae: 0.0812 - val_loss: 0.0171 - val_mae: 0.0930 - learning_rate: 5.0000e-04\n",
      "Epoch 10/60\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0124 - mae: 0.0851 - val_loss: 0.0198 - val_mae: 0.1063 - learning_rate: 5.0000e-04\n",
      "Epoch 11/60\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0118 - mae: 0.0824 - val_loss: 0.0109 - val_mae: 0.0655 - learning_rate: 2.5000e-04\n",
      "Epoch 12/60\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0104 - mae: 0.0769 - val_loss: 0.0095 - val_mae: 0.0641 - learning_rate: 2.5000e-04\n",
      "Epoch 13/60\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0106 - mae: 0.0769 - val_loss: 0.0111 - val_mae: 0.0672 - learning_rate: 2.5000e-04\n",
      "Epoch 14/60\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0104 - mae: 0.0759 - val_loss: 0.0113 - val_mae: 0.0691 - learning_rate: 2.5000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0099 - mae: 0.0745 - val_loss: 0.0106 - val_mae: 0.0665 - learning_rate: 2.5000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0101 - mae: 0.0750 - val_loss: 0.0108 - val_mae: 0.0682 - learning_rate: 2.5000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0093 - mae: 0.0726 - val_loss: 0.0080 - val_mae: 0.0657 - learning_rate: 1.2500e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0098 - mae: 0.0736 - val_loss: 0.0079 - val_mae: 0.0667 - learning_rate: 1.2500e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0096 - mae: 0.0727 - val_loss: 0.0080 - val_mae: 0.0641 - learning_rate: 1.2500e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0090 - mae: 0.0704 - val_loss: 0.0079 - val_mae: 0.0634 - learning_rate: 1.2500e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0095 - mae: 0.0733 - val_loss: 0.0083 - val_mae: 0.0612 - learning_rate: 1.2500e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0096 - mae: 0.0736 - val_loss: 0.0077 - val_mae: 0.0637 - learning_rate: 1.2500e-04\n",
      "Epoch 23/60\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0094 - mae: 0.0724 - val_loss: 0.0075 - val_mae: 0.0665 - learning_rate: 1.2500e-04\n",
      "Epoch 24/60\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0088 - mae: 0.0693 - val_loss: 0.0074 - val_mae: 0.0655 - learning_rate: 1.2500e-04\n",
      "Epoch 25/60\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0092 - mae: 0.0717 - val_loss: 0.0079 - val_mae: 0.0605 - learning_rate: 1.2500e-04\n",
      "Epoch 26/60\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0092 - mae: 0.0705 - val_loss: 0.0075 - val_mae: 0.0621 - learning_rate: 1.2500e-04\n",
      "Epoch 27/60\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0087 - mae: 0.0693 - val_loss: 0.0078 - val_mae: 0.0597 - learning_rate: 1.2500e-04\n",
      "Epoch 28/60\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0083 - mae: 0.0664 - val_loss: 0.0077 - val_mae: 0.0596 - learning_rate: 6.2500e-05\n",
      "Epoch 29/60\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0083 - mae: 0.0673 - val_loss: 0.0074 - val_mae: 0.0610 - learning_rate: 6.2500e-05\n",
      "Epoch 30/60\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0080 - mae: 0.0657 - val_loss: 0.0077 - val_mae: 0.0593 - learning_rate: 6.2500e-05\n",
      "Epoch 31/60\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0084 - mae: 0.0671 - val_loss: 0.0073 - val_mae: 0.0612 - learning_rate: 6.2500e-05\n",
      "Epoch 32/60\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0086 - mae: 0.0672 - val_loss: 0.0076 - val_mae: 0.0592 - learning_rate: 6.2500e-05\n",
      "Epoch 33/60\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0083 - mae: 0.0678 - val_loss: 0.0071 - val_mae: 0.0615 - learning_rate: 6.2500e-05\n",
      "Epoch 34/60\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0083 - mae: 0.0676 - val_loss: 0.0073 - val_mae: 0.0595 - learning_rate: 6.2500e-05\n",
      "Epoch 35/60\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0075 - mae: 0.0631 - val_loss: 0.0075 - val_mae: 0.0586 - learning_rate: 6.2500e-05\n",
      "Epoch 36/60\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0078 - mae: 0.0642 - val_loss: 0.0069 - val_mae: 0.0616 - learning_rate: 6.2500e-05\n",
      "Epoch 37/60\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0084 - mae: 0.0668 - val_loss: 0.0068 - val_mae: 0.0622 - learning_rate: 6.2500e-05\n",
      "Epoch 38/60\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0083 - mae: 0.0676 - val_loss: 0.0068 - val_mae: 0.0613 - learning_rate: 6.2500e-05\n",
      "Epoch 39/60\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0080 - mae: 0.0655 - val_loss: 0.0068 - val_mae: 0.0610 - learning_rate: 6.2500e-05\n",
      "Epoch 40/60\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0081 - mae: 0.0666 - val_loss: 0.0068 - val_mae: 0.0615 - learning_rate: 6.2500e-05\n",
      "Epoch 41/60\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0076 - mae: 0.0639 - val_loss: 0.0069 - val_mae: 0.0610 - learning_rate: 6.2500e-05\n",
      "Epoch 42/60\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0075 - mae: 0.0637 - val_loss: 0.0069 - val_mae: 0.0610 - learning_rate: 3.1250e-05\n",
      "Epoch 43/60\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0079 - mae: 0.0659 - val_loss: 0.0073 - val_mae: 0.0587 - learning_rate: 3.1250e-05\n",
      "Epoch 44/60\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0073 - mae: 0.0640 - val_loss: 0.0067 - val_mae: 0.0620 - learning_rate: 3.1250e-05\n",
      "Epoch 45/60\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0081 - mae: 0.0664 - val_loss: 0.0068 - val_mae: 0.0619 - learning_rate: 3.1250e-05\n",
      "Epoch 46/60\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0078 - mae: 0.0636 - val_loss: 0.0068 - val_mae: 0.0619 - learning_rate: 1.5625e-05\n",
      "Epoch 47/60\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0076 - mae: 0.0643 - val_loss: 0.0068 - val_mae: 0.0613 - learning_rate: 1.5625e-05\n",
      "Epoch 48/60\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0075 - mae: 0.0621 - val_loss: 0.0068 - val_mae: 0.0611 - learning_rate: 1.5625e-05\n",
      "Epoch 49/60\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0078 - mae: 0.0638 - val_loss: 0.0068 - val_mae: 0.0614 - learning_rate: 1.5625e-05\n",
      "Epoch 50/60\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0076 - mae: 0.0632 - val_loss: 0.0068 - val_mae: 0.0617 - learning_rate: 7.8125e-06\n",
      "Epoch 51/60\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0080 - mae: 0.0658 - val_loss: 0.0068 - val_mae: 0.0612 - learning_rate: 7.8125e-06\n",
      "Epoch 52/60\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0078 - mae: 0.0645 - val_loss: 0.0069 - val_mae: 0.0606 - learning_rate: 7.8125e-06\n",
      "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step \n",
      "âœ… Kalburgi - capsicum | MAE=359.54, RMSE=535.13, RÂ²=0.806, MAPE=15.99%, Acc=84.01%\n",
      "\n",
      "ğŸš€ Processing: Kalburgi | onion\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - loss: 0.2744 - mae: 0.3772 - val_loss: 0.0214 - val_mae: 0.1279 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0143 - mae: 0.0937 - val_loss: 0.0027 - val_mae: 0.0443 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0089 - mae: 0.0696 - val_loss: 0.0020 - val_mae: 0.0370 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0087 - mae: 0.0708 - val_loss: 0.0018 - val_mae: 0.0343 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0085 - mae: 0.0685 - val_loss: 0.0026 - val_mae: 0.0415 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0084 - mae: 0.0697 - val_loss: 0.0034 - val_mae: 0.0482 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0067 - mae: 0.0607 - val_loss: 0.0016 - val_mae: 0.0311 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0076 - mae: 0.0637 - val_loss: 0.0037 - val_mae: 0.0501 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0070 - mae: 0.0610 - val_loss: 0.0020 - val_mae: 0.0347 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0066 - mae: 0.0599 - val_loss: 0.0020 - val_mae: 0.0355 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0062 - mae: 0.0566 - val_loss: 0.0021 - val_mae: 0.0338 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0060 - mae: 0.0563 - val_loss: 0.0032 - val_mae: 0.0462 - learning_rate: 5.0000e-04\n",
      "Epoch 13/60\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0060 - mae: 0.0563 - val_loss: 0.0016 - val_mae: 0.0303 - learning_rate: 5.0000e-04\n",
      "Epoch 14/60\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0061 - mae: 0.0568 - val_loss: 0.0024 - val_mae: 0.0381 - learning_rate: 5.0000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0059 - mae: 0.0567 - val_loss: 0.0020 - val_mae: 0.0336 - learning_rate: 5.0000e-04\n",
      "\u001b[1m19/19\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step \n",
      "âœ… Kalburgi - onion | MAE=244.38, RMSE=368.54, RÂ²=0.7336, MAPE=16.58%, Acc=83.42%\n",
      "\n",
      "ğŸš€ Processing: Kalburgi | tomato\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - loss: 0.3385 - mae: 0.3748 - val_loss: 0.0140 - val_mae: 0.1066 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0268 - mae: 0.1255 - val_loss: 0.0058 - val_mae: 0.0630 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0184 - mae: 0.1002 - val_loss: 0.0080 - val_mae: 0.0703 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0168 - mae: 0.0957 - val_loss: 0.0070 - val_mae: 0.0662 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0145 - mae: 0.0884 - val_loss: 0.0112 - val_mae: 0.0826 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0146 - mae: 0.0897 - val_loss: 0.0069 - val_mae: 0.0641 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0135 - mae: 0.0849 - val_loss: 0.0075 - val_mae: 0.0699 - learning_rate: 5.0000e-04\n",
      "Epoch 8/60\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0129 - mae: 0.0822 - val_loss: 0.0080 - val_mae: 0.0678 - learning_rate: 5.0000e-04\n",
      "Epoch 9/60\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0120 - mae: 0.0796 - val_loss: 0.0082 - val_mae: 0.0712 - learning_rate: 5.0000e-04\n",
      "Epoch 10/60\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0127 - mae: 0.0834 - val_loss: 0.0080 - val_mae: 0.0698 - learning_rate: 5.0000e-04\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step \n",
      "âœ… Kalburgi - tomato | MAE=834.9, RMSE=1152.25, RÂ²=0.5797, MAPE=75.85%, Acc=24.15%\n",
      "\n",
      "ğŸš€ Processing: Kalburgi | wheat\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0357 - mae: 0.1099 - val_loss: 0.0152 - val_mae: 0.0606 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0031 - mae: 0.0440 - val_loss: 0.0117 - val_mae: 0.0504 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0026 - mae: 0.0395 - val_loss: 0.0113 - val_mae: 0.0435 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0019 - mae: 0.0341 - val_loss: 0.0121 - val_mae: 0.0466 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0017 - mae: 0.0313 - val_loss: 0.0126 - val_mae: 0.0529 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0258 - val_loss: 0.0106 - val_mae: 0.0400 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 9.4141e-04 - mae: 0.0227 - val_loss: 0.0100 - val_mae: 0.0387 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 8.4371e-04 - mae: 0.0214 - val_loss: 0.0098 - val_mae: 0.0389 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 7.1725e-04 - mae: 0.0194 - val_loss: 0.0097 - val_mae: 0.0356 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 6.2294e-04 - mae: 0.0181 - val_loss: 0.0102 - val_mae: 0.0359 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 7.2337e-04 - mae: 0.0201 - val_loss: 0.0114 - val_mae: 0.0398 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 5.2485e-04 - mae: 0.0163 - val_loss: 0.0108 - val_mae: 0.0356 - learning_rate: 0.0010\n",
      "Epoch 13/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4.5592e-04 - mae: 0.0153 - val_loss: 0.0109 - val_mae: 0.0375 - learning_rate: 0.0010\n",
      "Epoch 14/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 3.6421e-04 - mae: 0.0130 - val_loss: 0.0112 - val_mae: 0.0361 - learning_rate: 5.0000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 3.4641e-04 - mae: 0.0127 - val_loss: 0.0123 - val_mae: 0.0386 - learning_rate: 5.0000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 3.5751e-04 - mae: 0.0133 - val_loss: 0.0120 - val_mae: 0.0348 - learning_rate: 5.0000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 3.2411e-04 - mae: 0.0124 - val_loss: 0.0121 - val_mae: 0.0347 - learning_rate: 5.0000e-04\n",
      "\u001b[1m84/84\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step   \n",
      "âœ… Kalburgi - wheat | MAE=42.55, RMSE=145.08, RÂ²=0.8876, MAPE=1.58%, Acc=98.42%\n",
      "\n",
      "ğŸš€ Processing: Karwar(Uttar Kannad) | onion\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - loss: 0.5760 - mae: 0.5017 - val_loss: 0.1740 - val_mae: 0.3712 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0168 - mae: 0.0964 - val_loss: 0.0793 - val_mae: 0.2260 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0086 - mae: 0.0703 - val_loss: 0.0653 - val_mae: 0.2007 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0077 - mae: 0.0681 - val_loss: 0.0484 - val_mae: 0.1574 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0062 - mae: 0.0603 - val_loss: 0.0464 - val_mae: 0.1530 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0059 - mae: 0.0602 - val_loss: 0.0398 - val_mae: 0.1313 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0058 - mae: 0.0594 - val_loss: 0.0509 - val_mae: 0.1581 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0052 - mae: 0.0569 - val_loss: 0.0485 - val_mae: 0.1458 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0050 - mae: 0.0552 - val_loss: 0.0449 - val_mae: 0.1309 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0050 - mae: 0.0555 - val_loss: 0.0517 - val_mae: 0.1482 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0042 - mae: 0.0506 - val_loss: 0.0443 - val_mae: 0.1246 - learning_rate: 5.0000e-04\n",
      "Epoch 12/60\n",
      "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0041 - mae: 0.0509 - val_loss: 0.0439 - val_mae: 0.1244 - learning_rate: 5.0000e-04\n",
      "Epoch 13/60\n",
      "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0040 - mae: 0.0482 - val_loss: 0.0432 - val_mae: 0.1214 - learning_rate: 5.0000e-04\n",
      "Epoch 14/60\n",
      "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0040 - mae: 0.0496 - val_loss: 0.0432 - val_mae: 0.1202 - learning_rate: 5.0000e-04\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step \n",
      "âœ… Karwar(Uttar Kannad) - onion | MAE=155.18, RMSE=320.64, RÂ²=0.9333, MAPE=12.05%, Acc=87.95%\n",
      "\n",
      "ğŸš€ Processing: Karwar(Uttar Kannad) | tomato\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - loss: 0.5143 - mae: 0.4930 - val_loss: 0.0242 - val_mae: 0.1176 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0488 - mae: 0.1719 - val_loss: 0.1666 - val_mae: 0.3633 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0234 - mae: 0.1223 - val_loss: 0.0733 - val_mae: 0.2135 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0141 - mae: 0.0948 - val_loss: 0.0436 - val_mae: 0.1512 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0118 - mae: 0.0851 - val_loss: 0.0591 - val_mae: 0.1872 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0113 - mae: 0.0849 - val_loss: 0.0575 - val_mae: 0.1835 - learning_rate: 5.0000e-04\n",
      "Epoch 7/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0121 - mae: 0.0842 - val_loss: 0.0527 - val_mae: 0.1727 - learning_rate: 5.0000e-04\n",
      "Epoch 8/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0111 - mae: 0.0815 - val_loss: 0.0453 - val_mae: 0.1577 - learning_rate: 5.0000e-04\n",
      "Epoch 9/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0108 - mae: 0.0813 - val_loss: 0.0534 - val_mae: 0.1765 - learning_rate: 5.0000e-04\n",
      "\u001b[1m9/9\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step \n",
      "âœ… Karwar(Uttar Kannad) - tomato | MAE=770.9, RMSE=972.94, RÂ²=-0.5963, MAPE=123.53%, Acc=-23.53%\n",
      "\n",
      "ğŸš€ Processing: Karwar(Uttar Kannad) | wheat\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - loss: 0.1423 - mae: 0.2765 - val_loss: 0.0015 - val_mae: 0.0263 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0129 - mae: 0.0872 - val_loss: 0.0015 - val_mae: 0.0258 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0074 - mae: 0.0650 - val_loss: 8.1807e-04 - val_mae: 0.0033 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0064 - mae: 0.0615 - val_loss: 8.5853e-04 - val_mae: 0.0072 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0053 - mae: 0.0568 - val_loss: 8.1378e-04 - val_mae: 0.0026 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0051 - mae: 0.0540 - val_loss: 8.8902e-04 - val_mae: 0.0124 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0048 - mae: 0.0527 - val_loss: 0.0015 - val_mae: 0.0295 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0046 - mae: 0.0512 - val_loss: 0.0011 - val_mae: 0.0197 - learning_rate: 5.0000e-04\n",
      "Epoch 9/60\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0044 - mae: 0.0507 - val_loss: 0.0021 - val_mae: 0.0385 - learning_rate: 5.0000e-04\n",
      "Epoch 10/60\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0046 - mae: 0.0521 - val_loss: 0.0011 - val_mae: 0.0195 - learning_rate: 5.0000e-04\n",
      "Epoch 11/60\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0042 - mae: 0.0496 - val_loss: 0.0013 - val_mae: 0.0258 - learning_rate: 5.0000e-04\n",
      "Epoch 12/60\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0043 - mae: 0.0493 - val_loss: 0.0013 - val_mae: 0.0260 - learning_rate: 2.5000e-04\n",
      "Epoch 13/60\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0042 - mae: 0.0492 - val_loss: 0.0010 - val_mae: 0.0179 - learning_rate: 2.5000e-04\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step \n",
      "âœ… Karwar(Uttar Kannad) - wheat | MAE=29.68, RMSE=56.77, RÂ²=0.8568, MAPE=1.93%, Acc=98.07%\n",
      "\n",
      "ğŸš€ Processing: Kolar | capsicum\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0273 - mae: 0.1106 - val_loss: 0.0117 - val_mae: 0.0898 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0055 - mae: 0.0568 - val_loss: 0.0162 - val_mae: 0.1065 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0051 - mae: 0.0547 - val_loss: 0.0129 - val_mae: 0.0935 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0044 - mae: 0.0506 - val_loss: 0.0074 - val_mae: 0.0677 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0038 - mae: 0.0463 - val_loss: 0.0089 - val_mae: 0.0770 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0032 - mae: 0.0420 - val_loss: 0.0085 - val_mae: 0.0758 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0034 - mae: 0.0438 - val_loss: 0.0091 - val_mae: 0.0790 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0029 - mae: 0.0399 - val_loss: 0.0116 - val_mae: 0.0914 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0024 - mae: 0.0352 - val_loss: 0.0050 - val_mae: 0.0559 - learning_rate: 5.0000e-04\n",
      "Epoch 10/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0022 - mae: 0.0337 - val_loss: 0.0050 - val_mae: 0.0554 - learning_rate: 5.0000e-04\n",
      "Epoch 11/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0021 - mae: 0.0330 - val_loss: 0.0048 - val_mae: 0.0534 - learning_rate: 5.0000e-04\n",
      "Epoch 12/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0020 - mae: 0.0328 - val_loss: 0.0045 - val_mae: 0.0517 - learning_rate: 5.0000e-04\n",
      "Epoch 13/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0020 - mae: 0.0325 - val_loss: 0.0049 - val_mae: 0.0561 - learning_rate: 5.0000e-04\n",
      "Epoch 14/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0020 - mae: 0.0326 - val_loss: 0.0054 - val_mae: 0.0601 - learning_rate: 5.0000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0020 - mae: 0.0326 - val_loss: 0.0067 - val_mae: 0.0681 - learning_rate: 5.0000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0021 - mae: 0.0330 - val_loss: 0.0053 - val_mae: 0.0592 - learning_rate: 5.0000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0018 - mae: 0.0300 - val_loss: 0.0043 - val_mae: 0.0517 - learning_rate: 2.5000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0018 - mae: 0.0301 - val_loss: 0.0043 - val_mae: 0.0517 - learning_rate: 2.5000e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0302 - val_loss: 0.0043 - val_mae: 0.0508 - learning_rate: 2.5000e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0018 - mae: 0.0299 - val_loss: 0.0042 - val_mae: 0.0509 - learning_rate: 2.5000e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0018 - mae: 0.0304 - val_loss: 0.0042 - val_mae: 0.0499 - learning_rate: 2.5000e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0018 - mae: 0.0301 - val_loss: 0.0042 - val_mae: 0.0497 - learning_rate: 2.5000e-04\n",
      "Epoch 23/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0018 - mae: 0.0302 - val_loss: 0.0041 - val_mae: 0.0496 - learning_rate: 2.5000e-04\n",
      "Epoch 24/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0017 - mae: 0.0297 - val_loss: 0.0042 - val_mae: 0.0509 - learning_rate: 2.5000e-04\n",
      "Epoch 25/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0017 - mae: 0.0296 - val_loss: 0.0042 - val_mae: 0.0494 - learning_rate: 2.5000e-04\n",
      "Epoch 26/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0016 - mae: 0.0286 - val_loss: 0.0041 - val_mae: 0.0500 - learning_rate: 1.2500e-04\n",
      "Epoch 27/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0016 - mae: 0.0284 - val_loss: 0.0042 - val_mae: 0.0512 - learning_rate: 1.2500e-04\n",
      "Epoch 28/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0016 - mae: 0.0285 - val_loss: 0.0043 - val_mae: 0.0521 - learning_rate: 1.2500e-04\n",
      "Epoch 29/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0016 - mae: 0.0280 - val_loss: 0.0040 - val_mae: 0.0496 - learning_rate: 1.2500e-04\n",
      "Epoch 30/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0016 - mae: 0.0283 - val_loss: 0.0041 - val_mae: 0.0504 - learning_rate: 1.2500e-04\n",
      "Epoch 31/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0016 - mae: 0.0282 - val_loss: 0.0041 - val_mae: 0.0511 - learning_rate: 1.2500e-04\n",
      "Epoch 32/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0016 - mae: 0.0284 - val_loss: 0.0040 - val_mae: 0.0498 - learning_rate: 1.2500e-04\n",
      "Epoch 33/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0016 - mae: 0.0281 - val_loss: 0.0042 - val_mae: 0.0517 - learning_rate: 1.2500e-04\n",
      "Epoch 34/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0016 - mae: 0.0280 - val_loss: 0.0044 - val_mae: 0.0530 - learning_rate: 6.2500e-05\n",
      "Epoch 35/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0016 - mae: 0.0282 - val_loss: 0.0042 - val_mae: 0.0516 - learning_rate: 6.2500e-05\n",
      "Epoch 36/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mae: 0.0275 - val_loss: 0.0042 - val_mae: 0.0516 - learning_rate: 6.2500e-05\n",
      "Epoch 37/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0015 - mae: 0.0274 - val_loss: 0.0041 - val_mae: 0.0504 - learning_rate: 6.2500e-05\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step   \n",
      "âœ… Kolar - capsicum | MAE=168.56, RMSE=233.44, RÂ²=0.9424, MAPE=7.22%, Acc=92.78%\n",
      "\n",
      "ğŸš€ Processing: Kolar | onion\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0779 - mae: 0.1346 - val_loss: 0.0101 - val_mae: 0.0716 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0065 - mae: 0.0608 - val_loss: 0.0074 - val_mae: 0.0684 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0051 - mae: 0.0551 - val_loss: 0.0096 - val_mae: 0.0740 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0050 - mae: 0.0548 - val_loss: 0.0061 - val_mae: 0.0530 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0034 - mae: 0.0440 - val_loss: 0.0061 - val_mae: 0.0548 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0028 - mae: 0.0400 - val_loss: 0.0053 - val_mae: 0.0505 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0026 - mae: 0.0382 - val_loss: 0.0039 - val_mae: 0.0452 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0024 - mae: 0.0367 - val_loss: 0.0041 - val_mae: 0.0496 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0023 - mae: 0.0357 - val_loss: 0.0037 - val_mae: 0.0464 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0020 - mae: 0.0337 - val_loss: 0.0035 - val_mae: 0.0401 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0018 - mae: 0.0319 - val_loss: 0.0030 - val_mae: 0.0369 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0017 - mae: 0.0310 - val_loss: 0.0026 - val_mae: 0.0337 - learning_rate: 0.0010\n",
      "Epoch 13/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0017 - mae: 0.0308 - val_loss: 0.0036 - val_mae: 0.0404 - learning_rate: 0.0010\n",
      "Epoch 14/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0018 - mae: 0.0319 - val_loss: 0.0028 - val_mae: 0.0351 - learning_rate: 0.0010\n",
      "Epoch 15/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0014 - mae: 0.0275 - val_loss: 0.0035 - val_mae: 0.0431 - learning_rate: 0.0010\n",
      "Epoch 16/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0013 - mae: 0.0264 - val_loss: 0.0020 - val_mae: 0.0327 - learning_rate: 0.0010\n",
      "Epoch 17/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0013 - mae: 0.0259 - val_loss: 0.0021 - val_mae: 0.0315 - learning_rate: 0.0010\n",
      "Epoch 18/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0013 - mae: 0.0263 - val_loss: 0.0045 - val_mae: 0.0532 - learning_rate: 0.0010\n",
      "Epoch 19/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0011 - mae: 0.0243 - val_loss: 0.0022 - val_mae: 0.0319 - learning_rate: 0.0010\n",
      "Epoch 20/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0013 - mae: 0.0271 - val_loss: 0.0046 - val_mae: 0.0562 - learning_rate: 0.0010\n",
      "Epoch 21/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 8.9702e-04 - mae: 0.0219 - val_loss: 0.0017 - val_mae: 0.0265 - learning_rate: 5.0000e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 8.8976e-04 - mae: 0.0217 - val_loss: 0.0023 - val_mae: 0.0336 - learning_rate: 5.0000e-04\n",
      "Epoch 23/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 7.8905e-04 - mae: 0.0204 - val_loss: 0.0027 - val_mae: 0.0347 - learning_rate: 5.0000e-04\n",
      "Epoch 24/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 8.3940e-04 - mae: 0.0213 - val_loss: 0.0020 - val_mae: 0.0297 - learning_rate: 5.0000e-04\n",
      "Epoch 25/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 8.0377e-04 - mae: 0.0206 - val_loss: 0.0026 - val_mae: 0.0337 - learning_rate: 5.0000e-04\n",
      "Epoch 26/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 6.3108e-04 - mae: 0.0179 - val_loss: 0.0016 - val_mae: 0.0255 - learning_rate: 2.5000e-04\n",
      "Epoch 27/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 6.2708e-04 - mae: 0.0177 - val_loss: 0.0018 - val_mae: 0.0274 - learning_rate: 2.5000e-04\n",
      "Epoch 28/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 6.5278e-04 - mae: 0.0184 - val_loss: 0.0016 - val_mae: 0.0257 - learning_rate: 2.5000e-04\n",
      "Epoch 29/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 6.2228e-04 - mae: 0.0177 - val_loss: 0.0015 - val_mae: 0.0249 - learning_rate: 2.5000e-04\n",
      "Epoch 30/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 6.3205e-04 - mae: 0.0181 - val_loss: 0.0016 - val_mae: 0.0258 - learning_rate: 2.5000e-04\n",
      "Epoch 31/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 5.7556e-04 - mae: 0.0171 - val_loss: 0.0020 - val_mae: 0.0288 - learning_rate: 1.2500e-04\n",
      "Epoch 32/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 5.9369e-04 - mae: 0.0174 - val_loss: 0.0017 - val_mae: 0.0260 - learning_rate: 1.2500e-04\n",
      "Epoch 33/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 5.6299e-04 - mae: 0.0169 - val_loss: 0.0015 - val_mae: 0.0248 - learning_rate: 1.2500e-04\n",
      "Epoch 34/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5.9366e-04 - mae: 0.0174 - val_loss: 0.0015 - val_mae: 0.0252 - learning_rate: 1.2500e-04\n",
      "Epoch 35/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 5.1291e-04 - mae: 0.0159 - val_loss: 0.0015 - val_mae: 0.0248 - learning_rate: 6.2500e-05\n",
      "Epoch 36/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5.1398e-04 - mae: 0.0160 - val_loss: 0.0015 - val_mae: 0.0248 - learning_rate: 6.2500e-05\n",
      "Epoch 37/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 5.0426e-04 - mae: 0.0157 - val_loss: 0.0016 - val_mae: 0.0248 - learning_rate: 6.2500e-05\n",
      "Epoch 38/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 5.0580e-04 - mae: 0.0158 - val_loss: 0.0017 - val_mae: 0.0258 - learning_rate: 6.2500e-05\n",
      "Epoch 39/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 5.0051e-04 - mae: 0.0157 - val_loss: 0.0016 - val_mae: 0.0248 - learning_rate: 3.1250e-05\n",
      "Epoch 40/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 4.9260e-04 - mae: 0.0153 - val_loss: 0.0016 - val_mae: 0.0250 - learning_rate: 3.1250e-05\n",
      "Epoch 41/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 5.0075e-04 - mae: 0.0157 - val_loss: 0.0015 - val_mae: 0.0244 - learning_rate: 3.1250e-05\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step   \n",
      "âœ… Kolar - onion | MAE=75.81, RMSE=128.81, RÂ²=0.9793, MAPE=4.27%, Acc=95.73%\n",
      "\n",
      "ğŸš€ Processing: Kolar | tomato\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 0.0754 - mae: 0.1447 - val_loss: 0.0123 - val_mae: 0.0563 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0049 - mae: 0.0553 - val_loss: 0.0090 - val_mae: 0.0463 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0040 - mae: 0.0506 - val_loss: 0.0071 - val_mae: 0.0578 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0030 - mae: 0.0431 - val_loss: 0.0055 - val_mae: 0.0369 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0023 - mae: 0.0377 - val_loss: 0.0046 - val_mae: 0.0349 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0017 - mae: 0.0324 - val_loss: 0.0050 - val_mae: 0.0346 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0014 - mae: 0.0287 - val_loss: 0.0040 - val_mae: 0.0345 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mae: 0.0257 - val_loss: 0.0038 - val_mae: 0.0339 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0010 - mae: 0.0245 - val_loss: 0.0036 - val_mae: 0.0347 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 9.3913e-04 - mae: 0.0232 - val_loss: 0.0036 - val_mae: 0.0317 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 8.6008e-04 - mae: 0.0221 - val_loss: 0.0037 - val_mae: 0.0307 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 8.6487e-04 - mae: 0.0221 - val_loss: 0.0035 - val_mae: 0.0355 - learning_rate: 0.0010\n",
      "Epoch 13/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.0889e-04 - mae: 0.0215 - val_loss: 0.0031 - val_mae: 0.0310 - learning_rate: 0.0010\n",
      "Epoch 14/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 7.5478e-04 - mae: 0.0208 - val_loss: 0.0033 - val_mae: 0.0288 - learning_rate: 0.0010\n",
      "Epoch 15/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 7.0384e-04 - mae: 0.0199 - val_loss: 0.0030 - val_mae: 0.0298 - learning_rate: 0.0010\n",
      "Epoch 16/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 6.6589e-04 - mae: 0.0193 - val_loss: 0.0029 - val_mae: 0.0303 - learning_rate: 0.0010\n",
      "Epoch 17/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 7.0314e-04 - mae: 0.0199 - val_loss: 0.0031 - val_mae: 0.0351 - learning_rate: 0.0010\n",
      "Epoch 18/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 6.9433e-04 - mae: 0.0198 - val_loss: 0.0031 - val_mae: 0.0357 - learning_rate: 0.0010\n",
      "Epoch 19/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 7.1116e-04 - mae: 0.0202 - val_loss: 0.0031 - val_mae: 0.0373 - learning_rate: 0.0010\n",
      "Epoch 20/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 5.3548e-04 - mae: 0.0166 - val_loss: 0.0026 - val_mae: 0.0276 - learning_rate: 5.0000e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5.3745e-04 - mae: 0.0171 - val_loss: 0.0027 - val_mae: 0.0260 - learning_rate: 5.0000e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 5.4420e-04 - mae: 0.0172 - val_loss: 0.0026 - val_mae: 0.0278 - learning_rate: 5.0000e-04\n",
      "Epoch 23/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 5.7780e-04 - mae: 0.0179 - val_loss: 0.0026 - val_mae: 0.0286 - learning_rate: 5.0000e-04\n",
      "Epoch 24/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 5.5548e-04 - mae: 0.0175 - val_loss: 0.0025 - val_mae: 0.0275 - learning_rate: 5.0000e-04\n",
      "Epoch 25/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 5.4515e-04 - mae: 0.0172 - val_loss: 0.0025 - val_mae: 0.0265 - learning_rate: 5.0000e-04\n",
      "Epoch 26/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5.2119e-04 - mae: 0.0169 - val_loss: 0.0024 - val_mae: 0.0270 - learning_rate: 5.0000e-04\n",
      "Epoch 27/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 5.0997e-04 - mae: 0.0168 - val_loss: 0.0023 - val_mae: 0.0275 - learning_rate: 5.0000e-04\n",
      "Epoch 28/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 5.4680e-04 - mae: 0.0174 - val_loss: 0.0024 - val_mae: 0.0321 - learning_rate: 5.0000e-04\n",
      "Epoch 29/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 5.2666e-04 - mae: 0.0172 - val_loss: 0.0025 - val_mae: 0.0330 - learning_rate: 5.0000e-04\n",
      "Epoch 30/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 4.7103e-04 - mae: 0.0161 - val_loss: 0.0024 - val_mae: 0.0329 - learning_rate: 5.0000e-04\n",
      "Epoch 31/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 4.7518e-04 - mae: 0.0159 - val_loss: 0.0025 - val_mae: 0.0338 - learning_rate: 5.0000e-04\n",
      "Epoch 32/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.2420e-04 - mae: 0.0149 - val_loss: 0.0022 - val_mae: 0.0244 - learning_rate: 2.5000e-04\n",
      "Epoch 33/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 4.2660e-04 - mae: 0.0149 - val_loss: 0.0022 - val_mae: 0.0241 - learning_rate: 2.5000e-04\n",
      "Epoch 34/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 4.1532e-04 - mae: 0.0147 - val_loss: 0.0022 - val_mae: 0.0248 - learning_rate: 2.5000e-04\n",
      "Epoch 35/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 4.2891e-04 - mae: 0.0151 - val_loss: 0.0021 - val_mae: 0.0239 - learning_rate: 2.5000e-04\n",
      "Epoch 36/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 4.1232e-04 - mae: 0.0148 - val_loss: 0.0021 - val_mae: 0.0252 - learning_rate: 2.5000e-04\n",
      "Epoch 37/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4.1830e-04 - mae: 0.0150 - val_loss: 0.0020 - val_mae: 0.0250 - learning_rate: 2.5000e-04\n",
      "Epoch 38/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 4.2326e-04 - mae: 0.0150 - val_loss: 0.0021 - val_mae: 0.0259 - learning_rate: 2.5000e-04\n",
      "Epoch 39/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 4.1936e-04 - mae: 0.0150 - val_loss: 0.0021 - val_mae: 0.0261 - learning_rate: 2.5000e-04\n",
      "Epoch 40/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.3053e-04 - mae: 0.0152 - val_loss: 0.0019 - val_mae: 0.0294 - learning_rate: 2.5000e-04\n",
      "Epoch 41/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4.3255e-04 - mae: 0.0154 - val_loss: 0.0018 - val_mae: 0.0245 - learning_rate: 2.5000e-04\n",
      "Epoch 42/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 4.2452e-04 - mae: 0.0153 - val_loss: 0.0019 - val_mae: 0.0282 - learning_rate: 2.5000e-04\n",
      "Epoch 43/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4.1657e-04 - mae: 0.0151 - val_loss: 0.0019 - val_mae: 0.0266 - learning_rate: 2.5000e-04\n",
      "Epoch 44/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.1771e-04 - mae: 0.0152 - val_loss: 0.0018 - val_mae: 0.0243 - learning_rate: 2.5000e-04\n",
      "Epoch 45/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.2857e-04 - mae: 0.0153 - val_loss: 0.0019 - val_mae: 0.0269 - learning_rate: 2.5000e-04\n",
      "Epoch 46/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 3.5229e-04 - mae: 0.0134 - val_loss: 0.0019 - val_mae: 0.0226 - learning_rate: 1.2500e-04\n",
      "Epoch 47/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 3.4344e-04 - mae: 0.0132 - val_loss: 0.0019 - val_mae: 0.0225 - learning_rate: 1.2500e-04\n",
      "Epoch 48/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 3.3879e-04 - mae: 0.0132 - val_loss: 0.0019 - val_mae: 0.0224 - learning_rate: 1.2500e-04\n",
      "Epoch 49/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 3.4794e-04 - mae: 0.0133 - val_loss: 0.0018 - val_mae: 0.0225 - learning_rate: 1.2500e-04\n",
      "Epoch 50/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 3.4476e-04 - mae: 0.0133 - val_loss: 0.0019 - val_mae: 0.0222 - learning_rate: 6.2500e-05\n",
      "Epoch 51/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 3.3819e-04 - mae: 0.0131 - val_loss: 0.0018 - val_mae: 0.0223 - learning_rate: 6.2500e-05\n",
      "Epoch 52/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 3.3450e-04 - mae: 0.0131 - val_loss: 0.0019 - val_mae: 0.0221 - learning_rate: 6.2500e-05\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step   \n",
      "âœ… Kolar - tomato | MAE=137.72, RMSE=214.99, RÂ²=0.922, MAPE=13.77%, Acc=86.23%\n",
      "\n",
      "ğŸš€ Processing: Kolar | wheat\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - loss: 0.0450 - mae: 0.1200 - val_loss: 0.0459 - val_mae: 0.1812 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0042 - mae: 0.0516 - val_loss: 0.0287 - val_mae: 0.1344 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0028 - mae: 0.0422 - val_loss: 0.0184 - val_mae: 0.0964 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0021 - mae: 0.0364 - val_loss: 0.0200 - val_mae: 0.1085 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0017 - mae: 0.0330 - val_loss: 0.0142 - val_mae: 0.0810 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0013 - mae: 0.0285 - val_loss: 0.0181 - val_mae: 0.1050 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0012 - mae: 0.0274 - val_loss: 0.0221 - val_mae: 0.1234 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 9.0859e-04 - mae: 0.0235 - val_loss: 0.0165 - val_mae: 0.0990 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 7.2119e-04 - mae: 0.0214 - val_loss: 0.0144 - val_mae: 0.0900 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 5.0374e-04 - mae: 0.0177 - val_loss: 0.0113 - val_mae: 0.0719 - learning_rate: 5.0000e-04\n",
      "Epoch 11/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 4.8401e-04 - mae: 0.0175 - val_loss: 0.0095 - val_mae: 0.0617 - learning_rate: 5.0000e-04\n",
      "Epoch 12/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 4.1187e-04 - mae: 0.0160 - val_loss: 0.0124 - val_mae: 0.0810 - learning_rate: 5.0000e-04\n",
      "Epoch 13/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 3.9167e-04 - mae: 0.0157 - val_loss: 0.0088 - val_mae: 0.0589 - learning_rate: 5.0000e-04\n",
      "Epoch 14/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 3.9798e-04 - mae: 0.0157 - val_loss: 0.0100 - val_mae: 0.0661 - learning_rate: 5.0000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 3.4384e-04 - mae: 0.0146 - val_loss: 0.0087 - val_mae: 0.0585 - learning_rate: 5.0000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 3.0193e-04 - mae: 0.0137 - val_loss: 0.0089 - val_mae: 0.0595 - learning_rate: 5.0000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 2.7638e-04 - mae: 0.0130 - val_loss: 0.0101 - val_mae: 0.0683 - learning_rate: 5.0000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 2.7007e-04 - mae: 0.0127 - val_loss: 0.0090 - val_mae: 0.0607 - learning_rate: 2.5000e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 2.4358e-04 - mae: 0.0122 - val_loss: 0.0090 - val_mae: 0.0612 - learning_rate: 2.5000e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 2.3578e-04 - mae: 0.0120 - val_loss: 0.0090 - val_mae: 0.0616 - learning_rate: 2.5000e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 2.2758e-04 - mae: 0.0118 - val_loss: 0.0092 - val_mae: 0.0634 - learning_rate: 2.5000e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 1.9414e-04 - mae: 0.0108 - val_loss: 0.0084 - val_mae: 0.0577 - learning_rate: 1.2500e-04\n",
      "Epoch 23/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 2.0160e-04 - mae: 0.0109 - val_loss: 0.0078 - val_mae: 0.0542 - learning_rate: 1.2500e-04\n",
      "Epoch 24/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.9943e-04 - mae: 0.0108 - val_loss: 0.0091 - val_mae: 0.0625 - learning_rate: 1.2500e-04\n",
      "Epoch 25/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 1.8634e-04 - mae: 0.0105 - val_loss: 0.0077 - val_mae: 0.0534 - learning_rate: 1.2500e-04\n",
      "Epoch 26/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.8634e-04 - mae: 0.0105 - val_loss: 0.0072 - val_mae: 0.0517 - learning_rate: 1.2500e-04\n",
      "Epoch 27/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 1.7723e-04 - mae: 0.0102 - val_loss: 0.0080 - val_mae: 0.0549 - learning_rate: 1.2500e-04\n",
      "Epoch 28/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 1.8104e-04 - mae: 0.0103 - val_loss: 0.0073 - val_mae: 0.0519 - learning_rate: 1.2500e-04\n",
      "Epoch 29/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 1.8531e-04 - mae: 0.0104 - val_loss: 0.0083 - val_mae: 0.0567 - learning_rate: 1.2500e-04\n",
      "Epoch 30/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 1.6922e-04 - mae: 0.0099 - val_loss: 0.0079 - val_mae: 0.0543 - learning_rate: 1.2500e-04\n",
      "Epoch 31/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.5649e-04 - mae: 0.0096 - val_loss: 0.0074 - val_mae: 0.0524 - learning_rate: 6.2500e-05\n",
      "Epoch 32/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 1.6494e-04 - mae: 0.0099 - val_loss: 0.0073 - val_mae: 0.0517 - learning_rate: 6.2500e-05\n",
      "Epoch 33/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.5392e-04 - mae: 0.0094 - val_loss: 0.0075 - val_mae: 0.0527 - learning_rate: 6.2500e-05\n",
      "Epoch 34/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 1.6253e-04 - mae: 0.0096 - val_loss: 0.0071 - val_mae: 0.0513 - learning_rate: 6.2500e-05\n",
      "Epoch 35/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 1.4825e-04 - mae: 0.0092 - val_loss: 0.0075 - val_mae: 0.0526 - learning_rate: 3.1250e-05\n",
      "Epoch 36/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.4685e-04 - mae: 0.0092 - val_loss: 0.0073 - val_mae: 0.0517 - learning_rate: 3.1250e-05\n",
      "Epoch 37/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 1.4896e-04 - mae: 0.0092 - val_loss: 0.0070 - val_mae: 0.0509 - learning_rate: 3.1250e-05\n",
      "Epoch 38/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 1.4598e-04 - mae: 0.0091 - val_loss: 0.0071 - val_mae: 0.0511 - learning_rate: 3.1250e-05\n",
      "Epoch 39/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 1.4313e-04 - mae: 0.0090 - val_loss: 0.0073 - val_mae: 0.0518 - learning_rate: 3.1250e-05\n",
      "Epoch 40/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.4704e-04 - mae: 0.0092 - val_loss: 0.0072 - val_mae: 0.0513 - learning_rate: 3.1250e-05\n",
      "Epoch 41/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 1.4193e-04 - mae: 0.0090 - val_loss: 0.0075 - val_mae: 0.0526 - learning_rate: 3.1250e-05\n",
      "Epoch 42/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.4017e-04 - mae: 0.0089 - val_loss: 0.0070 - val_mae: 0.0507 - learning_rate: 1.5625e-05\n",
      "Epoch 43/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 1.3618e-04 - mae: 0.0088 - val_loss: 0.0072 - val_mae: 0.0514 - learning_rate: 1.5625e-05\n",
      "Epoch 44/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.3805e-04 - mae: 0.0087 - val_loss: 0.0073 - val_mae: 0.0517 - learning_rate: 1.5625e-05\n",
      "Epoch 45/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.3850e-04 - mae: 0.0089 - val_loss: 0.0072 - val_mae: 0.0514 - learning_rate: 1.5625e-05\n",
      "\u001b[1m84/84\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step   \n",
      "âœ… Kolar - wheat | MAE=49.52, RMSE=118.11, RÂ²=0.9509, MAPE=1.85%, Acc=98.15%\n",
      "\n",
      "ğŸš€ Processing: Koppal | onion\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 196ms/step - loss: 0.6205 - mae: 0.6407 - val_loss: 1.1796 - val_mae: 1.0859 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.4969 - mae: 0.5952 - val_loss: 0.0038 - val_mae: 0.0546 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.2420 - mae: 0.4577 - val_loss: 0.0045 - val_mae: 0.0585 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0716 - mae: 0.2194 - val_loss: 0.4347 - val_mae: 0.6583 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.1301 - mae: 0.3226 - val_loss: 0.1971 - val_mae: 0.4421 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0339 - mae: 0.1517 - val_loss: 0.0133 - val_mae: 0.1074 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0779 - mae: 0.2574 - val_loss: 0.0477 - val_mae: 0.2145 - learning_rate: 5.0000e-04\n",
      "Epoch 8/60\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0326 - mae: 0.1533 - val_loss: 0.1840 - val_mae: 0.4269 - learning_rate: 5.0000e-04\n",
      "Epoch 9/60\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0341 - mae: 0.1332 - val_loss: 0.2331 - val_mae: 0.4811 - learning_rate: 5.0000e-04\n",
      "Epoch 10/60\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0348 - mae: 0.1305 - val_loss: 0.1412 - val_mae: 0.3734 - learning_rate: 5.0000e-04\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step\n",
      "âœ… Koppal - onion | MAE=1563.44, RMSE=1810.37, RÂ²=-1.0414, MAPE=88.68%, Acc=11.32%\n",
      "\n",
      "ğŸš€ Processing: Koppal | tomato\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 175ms/step - loss: 2.3603 - mae: 1.0329 - val_loss: 0.3708 - val_mae: 0.6063 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.6048 - mae: 0.7105 - val_loss: 0.0125 - val_mae: 0.1082 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.1622 - mae: 0.3459 - val_loss: 0.3527 - val_mae: 0.5937 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.1793 - mae: 0.3844 - val_loss: 4.9244e-04 - val_mae: 0.0198 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0645 - mae: 0.2154 - val_loss: 0.1109 - val_mae: 0.3325 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0851 - mae: 0.2659 - val_loss: 5.6496e-04 - val_mae: 0.0214 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0233 - mae: 0.1283 - val_loss: 0.0431 - val_mae: 0.2064 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0445 - mae: 0.1850 - val_loss: 6.8219e-04 - val_mae: 0.0185 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0078 - mae: 0.0713 - val_loss: 0.0077 - val_mae: 0.0854 - learning_rate: 5.0000e-04\n",
      "Epoch 10/60\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0134 - mae: 0.0992 - val_loss: 0.0090 - val_mae: 0.0926 - learning_rate: 5.0000e-04\n",
      "Epoch 11/60\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0117 - mae: 0.0890 - val_loss: 6.4020e-04 - val_mae: 0.0228 - learning_rate: 5.0000e-04\n",
      "Epoch 12/60\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0054 - mae: 0.0590 - val_loss: 0.0029 - val_mae: 0.0500 - learning_rate: 5.0000e-04\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step\n",
      "âœ… Koppal - tomato | MAE=584.71, RMSE=829.77, RÂ²=-2.0259, MAPE=79.57%, Acc=20.43%\n",
      "\n",
      "ğŸš€ Processing: Koppal | wheat\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0796 - mae: 0.1566 - val_loss: 0.0126 - val_mae: 0.0814 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0049 - mae: 0.0553 - val_loss: 0.0040 - val_mae: 0.0411 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0035 - mae: 0.0465 - val_loss: 0.0027 - val_mae: 0.0462 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0032 - mae: 0.0449 - val_loss: 0.0023 - val_mae: 0.0363 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0025 - mae: 0.0394 - val_loss: 0.0024 - val_mae: 0.0453 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0021 - mae: 0.0365 - val_loss: 0.0032 - val_mae: 0.0536 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0020 - mae: 0.0352 - val_loss: 0.0017 - val_mae: 0.0359 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0016 - mae: 0.0307 - val_loss: 0.0020 - val_mae: 0.0261 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0013 - mae: 0.0287 - val_loss: 0.0015 - val_mae: 0.0257 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0012 - mae: 0.0275 - val_loss: 0.0021 - val_mae: 0.0269 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0011 - mae: 0.0258 - val_loss: 0.0016 - val_mae: 0.0368 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0011 - mae: 0.0252 - val_loss: 0.0029 - val_mae: 0.0393 - learning_rate: 0.0010\n",
      "Epoch 13/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 8.8469e-04 - mae: 0.0226 - val_loss: 0.0016 - val_mae: 0.0368 - learning_rate: 0.0010\n",
      "Epoch 14/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 7.6959e-04 - mae: 0.0210 - val_loss: 0.0015 - val_mae: 0.0357 - learning_rate: 5.0000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 7.1353e-04 - mae: 0.0199 - val_loss: 0.0013 - val_mae: 0.0234 - learning_rate: 5.0000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6.4274e-04 - mae: 0.0190 - val_loss: 0.0011 - val_mae: 0.0293 - learning_rate: 5.0000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 6.3986e-04 - mae: 0.0189 - val_loss: 0.0015 - val_mae: 0.0359 - learning_rate: 5.0000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 6.1976e-04 - mae: 0.0186 - val_loss: 0.0014 - val_mae: 0.0354 - learning_rate: 5.0000e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 5.7992e-04 - mae: 0.0178 - val_loss: 0.0013 - val_mae: 0.0338 - learning_rate: 5.0000e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 5.8086e-04 - mae: 0.0179 - val_loss: 9.8602e-04 - val_mae: 0.0273 - learning_rate: 5.0000e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 5.3260e-04 - mae: 0.0173 - val_loss: 9.5202e-04 - val_mae: 0.0270 - learning_rate: 5.0000e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 5.8801e-04 - mae: 0.0179 - val_loss: 0.0021 - val_mae: 0.0421 - learning_rate: 5.0000e-04\n",
      "Epoch 23/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 5.7838e-04 - mae: 0.0177 - val_loss: 0.0010 - val_mae: 0.0291 - learning_rate: 5.0000e-04\n",
      "Epoch 24/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 5.7488e-04 - mae: 0.0177 - val_loss: 8.2910e-04 - val_mae: 0.0246 - learning_rate: 5.0000e-04\n",
      "Epoch 25/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5.7467e-04 - mae: 0.0178 - val_loss: 8.6072e-04 - val_mae: 0.0258 - learning_rate: 5.0000e-04\n",
      "Epoch 26/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 5.4595e-04 - mae: 0.0173 - val_loss: 8.3933e-04 - val_mae: 0.0256 - learning_rate: 5.0000e-04\n",
      "Epoch 27/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6.1029e-04 - mae: 0.0185 - val_loss: 8.9798e-04 - val_mae: 0.0273 - learning_rate: 5.0000e-04\n",
      "Epoch 28/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 5.1362e-04 - mae: 0.0166 - val_loss: 0.0011 - val_mae: 0.0305 - learning_rate: 5.0000e-04\n",
      "Epoch 29/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 4.2297e-04 - mae: 0.0148 - val_loss: 8.7124e-04 - val_mae: 0.0270 - learning_rate: 2.5000e-04\n",
      "Epoch 30/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 4.1185e-04 - mae: 0.0145 - val_loss: 7.9543e-04 - val_mae: 0.0254 - learning_rate: 2.5000e-04\n",
      "Epoch 31/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 4.1866e-04 - mae: 0.0145 - val_loss: 6.6024e-04 - val_mae: 0.0210 - learning_rate: 2.5000e-04\n",
      "Epoch 32/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 4.0865e-04 - mae: 0.0143 - val_loss: 7.8604e-04 - val_mae: 0.0253 - learning_rate: 2.5000e-04\n",
      "Epoch 33/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 3.9558e-04 - mae: 0.0141 - val_loss: 6.5070e-04 - val_mae: 0.0183 - learning_rate: 2.5000e-04\n",
      "Epoch 34/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.2025e-04 - mae: 0.0148 - val_loss: 6.3642e-04 - val_mae: 0.0197 - learning_rate: 2.5000e-04\n",
      "Epoch 35/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 3.9681e-04 - mae: 0.0142 - val_loss: 6.6722e-04 - val_mae: 0.0225 - learning_rate: 2.5000e-04\n",
      "Epoch 36/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 3.6069e-04 - mae: 0.0133 - val_loss: 7.1965e-04 - val_mae: 0.0241 - learning_rate: 1.2500e-04\n",
      "Epoch 37/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 3.7413e-04 - mae: 0.0137 - val_loss: 6.9903e-04 - val_mae: 0.0236 - learning_rate: 1.2500e-04\n",
      "Epoch 38/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 3.6473e-04 - mae: 0.0134 - val_loss: 6.2340e-04 - val_mae: 0.0212 - learning_rate: 1.2500e-04\n",
      "Epoch 39/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 3.6560e-04 - mae: 0.0134 - val_loss: 6.9233e-04 - val_mae: 0.0235 - learning_rate: 1.2500e-04\n",
      "Epoch 40/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 3.5944e-04 - mae: 0.0132 - val_loss: 8.0856e-04 - val_mae: 0.0261 - learning_rate: 6.2500e-05\n",
      "Epoch 41/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 3.7468e-04 - mae: 0.0136 - val_loss: 7.3733e-04 - val_mae: 0.0246 - learning_rate: 6.2500e-05\n",
      "Epoch 42/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 3.7168e-04 - mae: 0.0135 - val_loss: 6.8312e-04 - val_mae: 0.0234 - learning_rate: 6.2500e-05\n",
      "Epoch 43/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 3.5904e-04 - mae: 0.0133 - val_loss: 7.2541e-04 - val_mae: 0.0244 - learning_rate: 6.2500e-05\n",
      "Epoch 44/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 3.3083e-04 - mae: 0.0126 - val_loss: 7.8482e-04 - val_mae: 0.0257 - learning_rate: 3.1250e-05\n",
      "Epoch 45/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 3.4188e-04 - mae: 0.0128 - val_loss: 5.6045e-04 - val_mae: 0.0192 - learning_rate: 3.1250e-05\n",
      "Epoch 46/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 3.4095e-04 - mae: 0.0129 - val_loss: 6.5396e-04 - val_mae: 0.0228 - learning_rate: 3.1250e-05\n",
      "Epoch 47/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 3.4050e-04 - mae: 0.0128 - val_loss: 5.6766e-04 - val_mae: 0.0198 - learning_rate: 3.1250e-05\n",
      "Epoch 48/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 3.2602e-04 - mae: 0.0126 - val_loss: 5.5491e-04 - val_mae: 0.0192 - learning_rate: 1.5625e-05\n",
      "Epoch 49/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 3.3041e-04 - mae: 0.0125 - val_loss: 5.4839e-04 - val_mae: 0.0188 - learning_rate: 1.5625e-05\n",
      "Epoch 50/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 3.2616e-04 - mae: 0.0126 - val_loss: 6.3310e-04 - val_mae: 0.0223 - learning_rate: 1.5625e-05\n",
      "Epoch 51/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 3.2601e-04 - mae: 0.0124 - val_loss: 5.6333e-04 - val_mae: 0.0197 - learning_rate: 1.5625e-05\n",
      "Epoch 52/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 3.2367e-04 - mae: 0.0124 - val_loss: 6.1046e-04 - val_mae: 0.0216 - learning_rate: 1.5625e-05\n",
      "Epoch 53/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 3.2991e-04 - mae: 0.0125 - val_loss: 5.6831e-04 - val_mae: 0.0201 - learning_rate: 7.8125e-06\n",
      "Epoch 54/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 3.2319e-04 - mae: 0.0124 - val_loss: 5.9378e-04 - val_mae: 0.0211 - learning_rate: 7.8125e-06\n",
      "Epoch 55/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 3.2529e-04 - mae: 0.0123 - val_loss: 6.1378e-04 - val_mae: 0.0217 - learning_rate: 7.8125e-06\n",
      "Epoch 56/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 3.2475e-04 - mae: 0.0124 - val_loss: 5.7150e-04 - val_mae: 0.0202 - learning_rate: 7.8125e-06\n",
      "Epoch 57/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 3.2002e-04 - mae: 0.0124 - val_loss: 6.0512e-04 - val_mae: 0.0215 - learning_rate: 3.9063e-06\n",
      "\u001b[1m81/81\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step   \n",
      "âœ… Koppal - wheat | MAE=20.41, RMSE=29.77, RÂ²=0.9946, MAPE=1.16%, Acc=98.84%\n",
      "\n",
      "ğŸš€ Processing: Madikeri(Kodagu) | onion\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m123/123\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0781 - mae: 0.1677 - val_loss: 0.0016 - val_mae: 0.0324 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m123/123\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0056 - mae: 0.0577 - val_loss: 0.0011 - val_mae: 0.0319 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m123/123\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0038 - mae: 0.0480 - val_loss: 0.0020 - val_mae: 0.0447 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m123/123\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0030 - mae: 0.0421 - val_loss: 0.0028 - val_mae: 0.0530 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m123/123\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0026 - mae: 0.0385 - val_loss: 0.0013 - val_mae: 0.0360 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m123/123\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0022 - mae: 0.0363 - val_loss: 1.3311e-04 - val_mae: 0.0095 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m123/123\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0020 - mae: 0.0344 - val_loss: 6.1822e-04 - val_mae: 0.0228 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m123/123\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0016 - mae: 0.0302 - val_loss: 2.1635e-04 - val_mae: 0.0132 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m123/123\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mae: 0.0298 - val_loss: 3.7419e-05 - val_mae: 0.0046 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m123/123\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0012 - mae: 0.0260 - val_loss: 2.2338e-04 - val_mae: 0.0119 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m123/123\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 8.0345e-04 - mae: 0.0208 - val_loss: 1.2985e-04 - val_mae: 0.0098 - learning_rate: 5.0000e-04\n",
      "Epoch 12/60\n",
      "\u001b[1m123/123\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 8.1082e-04 - mae: 0.0213 - val_loss: 5.1894e-04 - val_mae: 0.0198 - learning_rate: 5.0000e-04\n",
      "Epoch 13/60\n",
      "\u001b[1m123/123\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 7.0661e-04 - mae: 0.0196 - val_loss: 2.5947e-04 - val_mae: 0.0147 - learning_rate: 5.0000e-04\n",
      "Epoch 14/60\n",
      "\u001b[1m123/123\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 6.2381e-04 - mae: 0.0184 - val_loss: 2.2200e-04 - val_mae: 0.0135 - learning_rate: 5.0000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m123/123\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5.5320e-04 - mae: 0.0173 - val_loss: 1.0423e-04 - val_mae: 0.0085 - learning_rate: 2.5000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m123/123\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5.2521e-04 - mae: 0.0169 - val_loss: 1.9347e-04 - val_mae: 0.0115 - learning_rate: 2.5000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m123/123\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 4.9240e-04 - mae: 0.0163 - val_loss: 2.7142e-04 - val_mae: 0.0129 - learning_rate: 2.5000e-04\n",
      "\u001b[1m77/77\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step   \n",
      "âœ… Madikeri(Kodagu) - onion | MAE=31.72, RMSE=47.21, RÂ²=0.9906, MAPE=2.41%, Acc=97.59%\n",
      "\n",
      "ğŸš€ Processing: Madikeri(Kodagu) | tomato\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - loss: 0.0345 - mae: 0.1279 - val_loss: 0.0101 - val_mae: 0.0865 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0073 - mae: 0.0655 - val_loss: 0.0031 - val_mae: 0.0437 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0044 - mae: 0.0509 - val_loss: 0.0020 - val_mae: 0.0339 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0030 - mae: 0.0414 - val_loss: 0.0283 - val_mae: 0.1667 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0046 - mae: 0.0510 - val_loss: 0.0063 - val_mae: 0.0768 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0024 - mae: 0.0373 - val_loss: 0.0028 - val_mae: 0.0499 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0020 - mae: 0.0344 - val_loss: 6.1405e-04 - val_mae: 0.0221 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0013 - mae: 0.0269 - val_loss: 0.0010 - val_mae: 0.0298 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0011 - mae: 0.0254 - val_loss: 1.8141e-04 - val_mae: 0.0122 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0270 - val_loss: 1.0178e-04 - val_mae: 0.0069 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0012 - mae: 0.0269 - val_loss: 3.4258e-04 - val_mae: 0.0169 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0013 - mae: 0.0279 - val_loss: 0.0022 - val_mae: 0.0456 - learning_rate: 0.0010\n",
      "Epoch 13/60\n",
      "\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0011 - mae: 0.0246 - val_loss: 0.0013 - val_mae: 0.0347 - learning_rate: 0.0010\n",
      "Epoch 14/60\n",
      "\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 7.3164e-04 - mae: 0.0197 - val_loss: 0.0021 - val_mae: 0.0456 - learning_rate: 5.0000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.0444e-04 - mae: 0.0213 - val_loss: 1.0541e-04 - val_mae: 0.0093 - learning_rate: 5.0000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 7.1462e-04 - mae: 0.0196 - val_loss: 0.0013 - val_mae: 0.0353 - learning_rate: 5.0000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 7.1092e-04 - mae: 0.0198 - val_loss: 2.1787e-04 - val_mae: 0.0133 - learning_rate: 5.0000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6.2463e-04 - mae: 0.0179 - val_loss: 1.7680e-04 - val_mae: 0.0119 - learning_rate: 2.5000e-04\n",
      "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step   \n",
      "âœ… Madikeri(Kodagu) - tomato | MAE=18.92, RMSE=27.94, RÂ²=0.9909, MAPE=2.41%, Acc=97.59%\n",
      "\n",
      "ğŸš€ Processing: Madikeri(Kodagu) | wheat\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m113/113\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 0.2160 - mae: 0.2148 - val_loss: 0.0970 - val_mae: 0.3001 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m113/113\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0093 - mae: 0.0703 - val_loss: 0.0730 - val_mae: 0.2583 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m113/113\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0092 - mae: 0.0698 - val_loss: 0.0844 - val_mae: 0.2777 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m113/113\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0087 - mae: 0.0684 - val_loss: 0.0602 - val_mae: 0.2328 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m113/113\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0085 - mae: 0.0672 - val_loss: 0.0693 - val_mae: 0.2507 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m113/113\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0081 - mae: 0.0662 - val_loss: 0.0345 - val_mae: 0.1742 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m113/113\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0073 - mae: 0.0618 - val_loss: 0.0329 - val_mae: 0.1692 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m113/113\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0065 - mae: 0.0572 - val_loss: 0.0263 - val_mae: 0.1503 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m113/113\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0061 - mae: 0.0558 - val_loss: 0.0246 - val_mae: 0.1458 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m113/113\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0060 - mae: 0.0560 - val_loss: 0.0191 - val_mae: 0.1269 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m113/113\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0050 - mae: 0.0499 - val_loss: 0.0170 - val_mae: 0.1150 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m113/113\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0043 - mae: 0.0460 - val_loss: 0.0094 - val_mae: 0.0777 - learning_rate: 0.0010\n",
      "Epoch 13/60\n",
      "\u001b[1m113/113\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0040 - mae: 0.0432 - val_loss: 0.0041 - val_mae: 0.0512 - learning_rate: 0.0010\n",
      "Epoch 14/60\n",
      "\u001b[1m113/113\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0032 - mae: 0.0389 - val_loss: 0.0011 - val_mae: 0.0281 - learning_rate: 0.0010\n",
      "Epoch 15/60\n",
      "\u001b[1m113/113\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0030 - mae: 0.0378 - val_loss: 0.0027 - val_mae: 0.0475 - learning_rate: 0.0010\n",
      "Epoch 16/60\n",
      "\u001b[1m113/113\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0019 - mae: 0.0306 - val_loss: 0.0093 - val_mae: 0.0952 - learning_rate: 0.0010\n",
      "Epoch 17/60\n",
      "\u001b[1m113/113\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0015 - mae: 0.0267 - val_loss: 0.0044 - val_mae: 0.0639 - learning_rate: 0.0010\n",
      "Epoch 18/60\n",
      "\u001b[1m113/113\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0015 - mae: 0.0259 - val_loss: 0.0025 - val_mae: 0.0461 - learning_rate: 0.0010\n",
      "Epoch 19/60\n",
      "\u001b[1m113/113\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 9.7550e-04 - mae: 0.0206 - val_loss: 0.0042 - val_mae: 0.0624 - learning_rate: 5.0000e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m113/113\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0010 - mae: 0.0212 - val_loss: 0.0022 - val_mae: 0.0424 - learning_rate: 5.0000e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m113/113\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 9.4342e-04 - mae: 0.0205 - val_loss: 0.0025 - val_mae: 0.0453 - learning_rate: 5.0000e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m113/113\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 8.8441e-04 - mae: 0.0193 - val_loss: 0.0044 - val_mae: 0.0620 - learning_rate: 5.0000e-04\n",
      "\u001b[1m71/71\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step  \n",
      "âœ… Madikeri(Kodagu) - wheat | MAE=400.35, RMSE=706.63, RÂ²=0.9847, MAPE=8.73%, Acc=91.27%\n",
      "\n",
      "ğŸš€ Processing: Mandya | capsicum\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 20ms/step - loss: 0.2819 - mae: 0.2571 - val_loss: 0.1372 - val_mae: 0.3475 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0103 - mae: 0.0713 - val_loss: 0.0876 - val_mae: 0.2744 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0071 - mae: 0.0613 - val_loss: 0.0395 - val_mae: 0.1730 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0055 - mae: 0.0548 - val_loss: 0.0299 - val_mae: 0.1478 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0052 - mae: 0.0541 - val_loss: 0.0215 - val_mae: 0.1218 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0045 - mae: 0.0502 - val_loss: 0.0145 - val_mae: 0.0982 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0042 - mae: 0.0492 - val_loss: 0.0204 - val_mae: 0.1194 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0033 - mae: 0.0432 - val_loss: 0.0188 - val_mae: 0.1147 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0034 - mae: 0.0443 - val_loss: 0.0118 - val_mae: 0.0887 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0030 - mae: 0.0421 - val_loss: 0.0145 - val_mae: 0.0994 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0027 - mae: 0.0393 - val_loss: 0.0163 - val_mae: 0.1077 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0026 - mae: 0.0388 - val_loss: 0.0109 - val_mae: 0.0851 - learning_rate: 0.0010\n",
      "Epoch 13/60\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0024 - mae: 0.0369 - val_loss: 0.0067 - val_mae: 0.0653 - learning_rate: 0.0010\n",
      "Epoch 14/60\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0022 - mae: 0.0350 - val_loss: 0.0077 - val_mae: 0.0702 - learning_rate: 0.0010\n",
      "Epoch 15/60\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0021 - mae: 0.0350 - val_loss: 0.0108 - val_mae: 0.0850 - learning_rate: 0.0010\n",
      "Epoch 16/60\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0317 - val_loss: 0.0093 - val_mae: 0.0780 - learning_rate: 0.0010\n",
      "Epoch 17/60\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0018 - mae: 0.0318 - val_loss: 0.0060 - val_mae: 0.0596 - learning_rate: 0.0010\n",
      "Epoch 18/60\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0015 - mae: 0.0282 - val_loss: 0.0065 - val_mae: 0.0624 - learning_rate: 0.0010\n",
      "Epoch 19/60\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0283 - val_loss: 0.0090 - val_mae: 0.0765 - learning_rate: 0.0010\n",
      "Epoch 20/60\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0014 - mae: 0.0273 - val_loss: 0.0098 - val_mae: 0.0802 - learning_rate: 0.0010\n",
      "Epoch 21/60\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0019 - mae: 0.0320 - val_loss: 0.0128 - val_mae: 0.0955 - learning_rate: 0.0010\n",
      "Epoch 22/60\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0242 - val_loss: 0.0066 - val_mae: 0.0620 - learning_rate: 5.0000e-04\n",
      "Epoch 23/60\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0011 - mae: 0.0242 - val_loss: 0.0070 - val_mae: 0.0658 - learning_rate: 5.0000e-04\n",
      "Epoch 24/60\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0011 - mae: 0.0236 - val_loss: 0.0065 - val_mae: 0.0615 - learning_rate: 5.0000e-04\n",
      "Epoch 25/60\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0011 - mae: 0.0231 - val_loss: 0.0064 - val_mae: 0.0615 - learning_rate: 5.0000e-04\n",
      "\u001b[1m78/78\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step   \n",
      "âœ… Mandya - capsicum | MAE=93.05, RMSE=163.23, RÂ²=0.9755, MAPE=5.53%, Acc=94.47%\n",
      "\n",
      "ğŸš€ Processing: Mandya | onion\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0873 - mae: 0.1530 - val_loss: 0.0292 - val_mae: 0.1387 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0059 - mae: 0.0563 - val_loss: 0.0184 - val_mae: 0.1038 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0048 - mae: 0.0516 - val_loss: 0.0096 - val_mae: 0.0671 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0039 - mae: 0.0457 - val_loss: 0.0076 - val_mae: 0.0600 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0033 - mae: 0.0426 - val_loss: 0.0079 - val_mae: 0.0583 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0028 - mae: 0.0388 - val_loss: 0.0057 - val_mae: 0.0537 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0025 - mae: 0.0360 - val_loss: 0.0052 - val_mae: 0.0504 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0023 - mae: 0.0347 - val_loss: 0.0049 - val_mae: 0.0475 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0020 - mae: 0.0317 - val_loss: 0.0051 - val_mae: 0.0626 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0017 - mae: 0.0294 - val_loss: 0.0036 - val_mae: 0.0434 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0013 - mae: 0.0258 - val_loss: 0.0031 - val_mae: 0.0430 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - mae: 0.0271 - val_loss: 0.0037 - val_mae: 0.0513 - learning_rate: 0.0010\n",
      "Epoch 13/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0011 - mae: 0.0243 - val_loss: 0.0041 - val_mae: 0.0529 - learning_rate: 0.0010\n",
      "Epoch 14/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mae: 0.0233 - val_loss: 0.0035 - val_mae: 0.0459 - learning_rate: 0.0010\n",
      "Epoch 15/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 9.1911e-04 - mae: 0.0212 - val_loss: 0.0038 - val_mae: 0.0515 - learning_rate: 0.0010\n",
      "Epoch 16/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 8.1411e-04 - mae: 0.0204 - val_loss: 0.0036 - val_mae: 0.0437 - learning_rate: 5.0000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 6.5482e-04 - mae: 0.0176 - val_loss: 0.0035 - val_mae: 0.0412 - learning_rate: 5.0000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 6.2429e-04 - mae: 0.0175 - val_loss: 0.0031 - val_mae: 0.0379 - learning_rate: 5.0000e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6.3591e-04 - mae: 0.0176 - val_loss: 0.0038 - val_mae: 0.0411 - learning_rate: 5.0000e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 5.2893e-04 - mae: 0.0160 - val_loss: 0.0038 - val_mae: 0.0391 - learning_rate: 2.5000e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 5.2159e-04 - mae: 0.0156 - val_loss: 0.0042 - val_mae: 0.0392 - learning_rate: 2.5000e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4.8762e-04 - mae: 0.0153 - val_loss: 0.0041 - val_mae: 0.0402 - learning_rate: 2.5000e-04\n",
      "Epoch 23/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 4.7660e-04 - mae: 0.0153 - val_loss: 0.0043 - val_mae: 0.0388 - learning_rate: 2.5000e-04\n",
      "Epoch 24/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4.6703e-04 - mae: 0.0150 - val_loss: 0.0043 - val_mae: 0.0386 - learning_rate: 1.2500e-04\n",
      "Epoch 25/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 4.4261e-04 - mae: 0.0145 - val_loss: 0.0040 - val_mae: 0.0380 - learning_rate: 1.2500e-04\n",
      "Epoch 26/60\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4.3067e-04 - mae: 0.0145 - val_loss: 0.0040 - val_mae: 0.0379 - learning_rate: 1.2500e-04\n",
      "\u001b[1m84/84\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step   \n",
      "âœ… Mandya - onion | MAE=71.06, RMSE=122.15, RÂ²=0.9393, MAPE=4.97%, Acc=95.03%\n",
      "\n",
      "ğŸš€ Processing: Mandya | tomato\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0921 - mae: 0.1470 - val_loss: 0.0285 - val_mae: 0.0973 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0041 - mae: 0.0497 - val_loss: 0.0236 - val_mae: 0.0841 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0032 - mae: 0.0439 - val_loss: 0.0250 - val_mae: 0.0845 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0026 - mae: 0.0397 - val_loss: 0.0210 - val_mae: 0.0745 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0020 - mae: 0.0345 - val_loss: 0.0200 - val_mae: 0.0744 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0016 - mae: 0.0306 - val_loss: 0.0210 - val_mae: 0.0746 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0012 - mae: 0.0258 - val_loss: 0.0199 - val_mae: 0.0709 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0011 - mae: 0.0248 - val_loss: 0.0182 - val_mae: 0.0688 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 8.4380e-04 - mae: 0.0216 - val_loss: 0.0170 - val_mae: 0.0707 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 7.5384e-04 - mae: 0.0200 - val_loss: 0.0181 - val_mae: 0.0671 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 6.6763e-04 - mae: 0.0184 - val_loss: 0.0190 - val_mae: 0.0690 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 6.1367e-04 - mae: 0.0174 - val_loss: 0.0181 - val_mae: 0.0672 - learning_rate: 0.0010\n",
      "Epoch 13/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 5.4833e-04 - mae: 0.0164 - val_loss: 0.0179 - val_mae: 0.0667 - learning_rate: 0.0010\n",
      "Epoch 14/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4.6731e-04 - mae: 0.0144 - val_loss: 0.0177 - val_mae: 0.0664 - learning_rate: 5.0000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.5678e-04 - mae: 0.0139 - val_loss: 0.0182 - val_mae: 0.0677 - learning_rate: 5.0000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 4.5787e-04 - mae: 0.0140 - val_loss: 0.0175 - val_mae: 0.0661 - learning_rate: 5.0000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 4.1222e-04 - mae: 0.0133 - val_loss: 0.0181 - val_mae: 0.0672 - learning_rate: 5.0000e-04\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step   \n",
      "âœ… Mandya - tomato | MAE=295.79, RMSE=514.87, RÂ²=0.5754, MAPE=37.62%, Acc=62.38%\n",
      "\n",
      "ğŸš€ Processing: Mandya | wheat\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 0.0960 - mae: 0.1993 - val_loss: 0.0038 - val_mae: 0.0535 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0088 - mae: 0.0711 - val_loss: 0.0093 - val_mae: 0.0915 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0056 - mae: 0.0563 - val_loss: 0.0025 - val_mae: 0.0452 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0040 - mae: 0.0495 - val_loss: 9.6547e-04 - val_mae: 0.0281 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0038 - mae: 0.0473 - val_loss: 0.0024 - val_mae: 0.0475 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0034 - mae: 0.0438 - val_loss: 3.3951e-04 - val_mae: 0.0166 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0027 - mae: 0.0393 - val_loss: 4.5482e-04 - val_mae: 0.0198 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0021 - mae: 0.0348 - val_loss: 4.3405e-04 - val_mae: 0.0149 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0018 - mae: 0.0309 - val_loss: 7.7283e-04 - val_mae: 0.0229 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0018 - mae: 0.0317 - val_loss: 5.1520e-04 - val_mae: 0.0195 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mae: 0.0265 - val_loss: 4.8314e-04 - val_mae: 0.0201 - learning_rate: 5.0000e-04\n",
      "Epoch 12/60\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0011 - mae: 0.0246 - val_loss: 5.1168e-04 - val_mae: 0.0201 - learning_rate: 5.0000e-04\n",
      "Epoch 13/60\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mae: 0.0245 - val_loss: 5.5242e-04 - val_mae: 0.0214 - learning_rate: 5.0000e-04\n",
      "Epoch 14/60\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0012 - mae: 0.0252 - val_loss: 6.4958e-04 - val_mae: 0.0234 - learning_rate: 5.0000e-04\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step  \n",
      "âœ… Mandya - wheat | MAE=43.78, RMSE=58.63, RÂ²=0.9626, MAPE=1.98%, Acc=98.02%\n",
      "\n",
      "ğŸš€ Processing: Mangalore(Dakshin Kannad) | onion\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - loss: 0.1093 - mae: 0.1627 - val_loss: 0.0117 - val_mae: 0.0816 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0042 - mae: 0.0509 - val_loss: 0.0097 - val_mae: 0.0709 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0040 - mae: 0.0491 - val_loss: 0.0094 - val_mae: 0.0713 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0036 - mae: 0.0460 - val_loss: 0.0092 - val_mae: 0.0716 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0033 - mae: 0.0440 - val_loss: 0.0092 - val_mae: 0.0710 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0027 - mae: 0.0403 - val_loss: 0.0081 - val_mae: 0.0555 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0024 - mae: 0.0373 - val_loss: 0.0082 - val_mae: 0.0594 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0022 - mae: 0.0351 - val_loss: 0.0079 - val_mae: 0.0545 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0018 - mae: 0.0319 - val_loss: 0.0079 - val_mae: 0.0603 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0017 - mae: 0.0308 - val_loss: 0.0089 - val_mae: 0.0575 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mae: 0.0280 - val_loss: 0.0076 - val_mae: 0.0586 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0013 - mae: 0.0264 - val_loss: 0.0077 - val_mae: 0.0513 - learning_rate: 0.0010\n",
      "Epoch 13/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mae: 0.0252 - val_loss: 0.0075 - val_mae: 0.0495 - learning_rate: 0.0010\n",
      "Epoch 14/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mae: 0.0245 - val_loss: 0.0068 - val_mae: 0.0504 - learning_rate: 0.0010\n",
      "Epoch 15/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0011 - mae: 0.0242 - val_loss: 0.0066 - val_mae: 0.0490 - learning_rate: 0.0010\n",
      "Epoch 16/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0011 - mae: 0.0239 - val_loss: 0.0062 - val_mae: 0.0491 - learning_rate: 0.0010\n",
      "Epoch 17/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0010 - mae: 0.0232 - val_loss: 0.0062 - val_mae: 0.0443 - learning_rate: 0.0010\n",
      "Epoch 18/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 9.6298e-04 - mae: 0.0232 - val_loss: 0.0061 - val_mae: 0.0459 - learning_rate: 0.0010\n",
      "Epoch 19/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.0566e-04 - mae: 0.0204 - val_loss: 0.0060 - val_mae: 0.0423 - learning_rate: 0.0010\n",
      "Epoch 20/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.0324e-04 - mae: 0.0207 - val_loss: 0.0067 - val_mae: 0.0491 - learning_rate: 0.0010\n",
      "Epoch 21/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 7.4828e-04 - mae: 0.0200 - val_loss: 0.0055 - val_mae: 0.0423 - learning_rate: 0.0010\n",
      "Epoch 22/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6.4085e-04 - mae: 0.0176 - val_loss: 0.0050 - val_mae: 0.0396 - learning_rate: 0.0010\n",
      "Epoch 23/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 7.9623e-04 - mae: 0.0209 - val_loss: 0.0050 - val_mae: 0.0405 - learning_rate: 0.0010\n",
      "Epoch 24/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6.7247e-04 - mae: 0.0185 - val_loss: 0.0048 - val_mae: 0.0419 - learning_rate: 0.0010\n",
      "Epoch 25/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 5.1387e-04 - mae: 0.0156 - val_loss: 0.0045 - val_mae: 0.0386 - learning_rate: 0.0010\n",
      "Epoch 26/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5.5943e-04 - mae: 0.0166 - val_loss: 0.0044 - val_mae: 0.0419 - learning_rate: 0.0010\n",
      "Epoch 27/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.5239e-04 - mae: 0.0146 - val_loss: 0.0046 - val_mae: 0.0406 - learning_rate: 0.0010\n",
      "Epoch 28/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 5.0632e-04 - mae: 0.0158 - val_loss: 0.0043 - val_mae: 0.0390 - learning_rate: 0.0010\n",
      "Epoch 29/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4.9920e-04 - mae: 0.0157 - val_loss: 0.0040 - val_mae: 0.0382 - learning_rate: 0.0010\n",
      "Epoch 30/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4.8826e-04 - mae: 0.0155 - val_loss: 0.0043 - val_mae: 0.0393 - learning_rate: 0.0010\n",
      "Epoch 31/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4.7957e-04 - mae: 0.0153 - val_loss: 0.0038 - val_mae: 0.0371 - learning_rate: 0.0010\n",
      "Epoch 32/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 4.4042e-04 - mae: 0.0142 - val_loss: 0.0036 - val_mae: 0.0378 - learning_rate: 0.0010\n",
      "Epoch 33/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4.7051e-04 - mae: 0.0152 - val_loss: 0.0041 - val_mae: 0.0391 - learning_rate: 0.0010\n",
      "Epoch 34/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 5.2180e-04 - mae: 0.0164 - val_loss: 0.0042 - val_mae: 0.0378 - learning_rate: 0.0010\n",
      "Epoch 35/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 4.5107e-04 - mae: 0.0146 - val_loss: 0.0038 - val_mae: 0.0368 - learning_rate: 0.0010\n",
      "Epoch 36/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4.9492e-04 - mae: 0.0159 - val_loss: 0.0037 - val_mae: 0.0362 - learning_rate: 0.0010\n",
      "Epoch 37/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 3.2931e-04 - mae: 0.0116 - val_loss: 0.0035 - val_mae: 0.0359 - learning_rate: 5.0000e-04\n",
      "Epoch 38/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 3.1082e-04 - mae: 0.0111 - val_loss: 0.0033 - val_mae: 0.0350 - learning_rate: 5.0000e-04\n",
      "Epoch 39/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 3.2814e-04 - mae: 0.0116 - val_loss: 0.0032 - val_mae: 0.0347 - learning_rate: 5.0000e-04\n",
      "Epoch 40/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 3.9360e-04 - mae: 0.0135 - val_loss: 0.0033 - val_mae: 0.0348 - learning_rate: 5.0000e-04\n",
      "Epoch 41/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 3.6551e-04 - mae: 0.0127 - val_loss: 0.0034 - val_mae: 0.0353 - learning_rate: 5.0000e-04\n",
      "Epoch 42/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 3.7052e-04 - mae: 0.0131 - val_loss: 0.0030 - val_mae: 0.0342 - learning_rate: 5.0000e-04\n",
      "Epoch 43/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 3.3138e-04 - mae: 0.0118 - val_loss: 0.0035 - val_mae: 0.0360 - learning_rate: 5.0000e-04\n",
      "Epoch 44/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 3.1782e-04 - mae: 0.0115 - val_loss: 0.0034 - val_mae: 0.0359 - learning_rate: 5.0000e-04\n",
      "Epoch 45/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 3.0824e-04 - mae: 0.0112 - val_loss: 0.0036 - val_mae: 0.0365 - learning_rate: 5.0000e-04\n",
      "Epoch 46/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 3.1037e-04 - mae: 0.0112 - val_loss: 0.0032 - val_mae: 0.0343 - learning_rate: 5.0000e-04\n",
      "Epoch 47/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 2.4581e-04 - mae: 0.0089 - val_loss: 0.0028 - val_mae: 0.0336 - learning_rate: 2.5000e-04\n",
      "Epoch 48/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 2.5840e-04 - mae: 0.0094 - val_loss: 0.0027 - val_mae: 0.0331 - learning_rate: 2.5000e-04\n",
      "Epoch 49/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 2.7240e-04 - mae: 0.0101 - val_loss: 0.0029 - val_mae: 0.0344 - learning_rate: 2.5000e-04\n",
      "Epoch 50/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 2.6042e-04 - mae: 0.0098 - val_loss: 0.0028 - val_mae: 0.0338 - learning_rate: 2.5000e-04\n",
      "Epoch 51/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 2.5614e-04 - mae: 0.0097 - val_loss: 0.0028 - val_mae: 0.0334 - learning_rate: 2.5000e-04\n",
      "Epoch 52/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 2.5990e-04 - mae: 0.0099 - val_loss: 0.0028 - val_mae: 0.0337 - learning_rate: 2.5000e-04\n",
      "Epoch 53/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 2.2658e-04 - mae: 0.0082 - val_loss: 0.0028 - val_mae: 0.0333 - learning_rate: 1.2500e-04\n",
      "Epoch 54/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 2.2385e-04 - mae: 0.0080 - val_loss: 0.0028 - val_mae: 0.0329 - learning_rate: 1.2500e-04\n",
      "Epoch 55/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 2.2466e-04 - mae: 0.0082 - val_loss: 0.0026 - val_mae: 0.0327 - learning_rate: 1.2500e-04\n",
      "Epoch 56/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 2.2616e-04 - mae: 0.0082 - val_loss: 0.0027 - val_mae: 0.0329 - learning_rate: 1.2500e-04\n",
      "Epoch 57/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 2.1702e-04 - mae: 0.0077 - val_loss: 0.0027 - val_mae: 0.0333 - learning_rate: 6.2500e-05\n",
      "Epoch 58/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 2.0752e-04 - mae: 0.0075 - val_loss: 0.0027 - val_mae: 0.0333 - learning_rate: 6.2500e-05\n",
      "Epoch 59/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 2.0870e-04 - mae: 0.0075 - val_loss: 0.0027 - val_mae: 0.0332 - learning_rate: 6.2500e-05\n",
      "Epoch 60/60\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 2.1186e-04 - mae: 0.0075 - val_loss: 0.0027 - val_mae: 0.0329 - learning_rate: 6.2500e-05\n",
      "\u001b[1m81/81\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step   \n",
      "âœ… Mangalore(Dakshin Kannad) - onion | MAE=115.5, RMSE=164.63, RÂ²=0.9663, MAPE=5.7%, Acc=94.3%\n",
      "\n",
      "ğŸš€ Processing: Mangalore(Dakshin Kannad) | tomato\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - loss: 0.2795 - mae: 0.4127 - val_loss: 0.0315 - val_mae: 0.1412 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0285 - mae: 0.1236 - val_loss: 0.0251 - val_mae: 0.1353 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0225 - mae: 0.1148 - val_loss: 0.0479 - val_mae: 0.1887 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0172 - mae: 0.0975 - val_loss: 0.0217 - val_mae: 0.1222 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0134 - mae: 0.0850 - val_loss: 0.0111 - val_mae: 0.0879 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0127 - mae: 0.0843 - val_loss: 0.0106 - val_mae: 0.0868 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0099 - mae: 0.0755 - val_loss: 0.0071 - val_mae: 0.0665 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0089 - mae: 0.0703 - val_loss: 0.0052 - val_mae: 0.0539 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0079 - mae: 0.0694 - val_loss: 0.0055 - val_mae: 0.0584 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0067 - mae: 0.0630 - val_loss: 0.0052 - val_mae: 0.0578 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0061 - mae: 0.0595 - val_loss: 0.0073 - val_mae: 0.0724 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0071 - mae: 0.0667 - val_loss: 0.0053 - val_mae: 0.0587 - learning_rate: 0.0010\n",
      "Epoch 13/60\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0053 - mae: 0.0565 - val_loss: 0.0051 - val_mae: 0.0562 - learning_rate: 5.0000e-04\n",
      "Epoch 14/60\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0055 - mae: 0.0575 - val_loss: 0.0053 - val_mae: 0.0579 - learning_rate: 5.0000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0047 - mae: 0.0526 - val_loss: 0.0042 - val_mae: 0.0473 - learning_rate: 5.0000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0046 - mae: 0.0530 - val_loss: 0.0041 - val_mae: 0.0463 - learning_rate: 5.0000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0044 - mae: 0.0517 - val_loss: 0.0051 - val_mae: 0.0553 - learning_rate: 5.0000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0044 - mae: 0.0511 - val_loss: 0.0047 - val_mae: 0.0503 - learning_rate: 5.0000e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0041 - mae: 0.0485 - val_loss: 0.0047 - val_mae: 0.0504 - learning_rate: 5.0000e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0037 - mae: 0.0473 - val_loss: 0.0053 - val_mae: 0.0561 - learning_rate: 5.0000e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0039 - mae: 0.0480 - val_loss: 0.0053 - val_mae: 0.0539 - learning_rate: 2.5000e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0039 - mae: 0.0484 - val_loss: 0.0051 - val_mae: 0.0529 - learning_rate: 2.5000e-04\n",
      "Epoch 23/60\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0036 - mae: 0.0446 - val_loss: 0.0051 - val_mae: 0.0530 - learning_rate: 2.5000e-04\n",
      "Epoch 24/60\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0034 - mae: 0.0445 - val_loss: 0.0051 - val_mae: 0.0542 - learning_rate: 2.5000e-04\n",
      "\u001b[1m13/13\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step \n",
      "âœ… Mangalore(Dakshin Kannad) - tomato | MAE=196.85, RMSE=294.22, RÂ²=0.9417, MAPE=9.7%, Acc=90.3%\n",
      "\n",
      "ğŸš€ Processing: Mangalore(Dakshin Kannad) | wheat\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - loss: 0.2608 - mae: 0.4040 - val_loss: 0.2159 - val_mae: 0.4627 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0422 - mae: 0.1701 - val_loss: 0.0655 - val_mae: 0.2529 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0130 - mae: 0.0916 - val_loss: 0.0361 - val_mae: 0.1862 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0132 - mae: 0.0910 - val_loss: 0.0228 - val_mae: 0.1467 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0122 - mae: 0.0863 - val_loss: 0.0088 - val_mae: 0.0875 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0125 - mae: 0.0886 - val_loss: 0.0051 - val_mae: 0.0642 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0107 - mae: 0.0820 - val_loss: 0.0025 - val_mae: 0.0424 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0084 - mae: 0.0708 - val_loss: 0.0018 - val_mae: 0.0363 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0070 - mae: 0.0669 - val_loss: 0.0077 - val_mae: 0.0831 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0045 - mae: 0.0514 - val_loss: 0.0044 - val_mae: 0.0600 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0043 - mae: 0.0524 - val_loss: 0.0036 - val_mae: 0.0536 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0041 - mae: 0.0489 - val_loss: 0.0019 - val_mae: 0.0366 - learning_rate: 0.0010\n",
      "Epoch 13/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0043 - mae: 0.0514 - val_loss: 0.0069 - val_mae: 0.0789 - learning_rate: 5.0000e-04\n",
      "Epoch 14/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0046 - mae: 0.0532 - val_loss: 0.0080 - val_mae: 0.0857 - learning_rate: 5.0000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0032 - mae: 0.0442 - val_loss: 0.0040 - val_mae: 0.0581 - learning_rate: 5.0000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m21/21\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0033 - mae: 0.0437 - val_loss: 0.0051 - val_mae: 0.0672 - learning_rate: 5.0000e-04\n",
      "\u001b[1m13/13\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step \n",
      "âœ… Mangalore(Dakshin Kannad) - wheat | MAE=187.13, RMSE=221.59, RÂ²=0.8741, MAPE=7.09%, Acc=92.91%\n",
      "\n",
      "ğŸš€ Processing: Mysore | capsicum\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0529 - mae: 0.1307 - val_loss: 0.0099 - val_mae: 0.0701 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0058 - mae: 0.0601 - val_loss: 0.0074 - val_mae: 0.0611 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0045 - mae: 0.0531 - val_loss: 0.0058 - val_mae: 0.0559 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0032 - mae: 0.0448 - val_loss: 0.0057 - val_mae: 0.0529 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0028 - mae: 0.0412 - val_loss: 0.0054 - val_mae: 0.0568 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0023 - mae: 0.0372 - val_loss: 0.0047 - val_mae: 0.0501 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0020 - mae: 0.0343 - val_loss: 0.0045 - val_mae: 0.0492 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0020 - mae: 0.0352 - val_loss: 0.0050 - val_mae: 0.0492 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0325 - val_loss: 0.0054 - val_mae: 0.0516 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0016 - mae: 0.0308 - val_loss: 0.0056 - val_mae: 0.0527 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mae: 0.0303 - val_loss: 0.0043 - val_mae: 0.0472 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0014 - mae: 0.0290 - val_loss: 0.0043 - val_mae: 0.0486 - learning_rate: 0.0010\n",
      "Epoch 13/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0014 - mae: 0.0286 - val_loss: 0.0045 - val_mae: 0.0474 - learning_rate: 0.0010\n",
      "Epoch 14/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0013 - mae: 0.0279 - val_loss: 0.0042 - val_mae: 0.0463 - learning_rate: 0.0010\n",
      "Epoch 15/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0014 - mae: 0.0290 - val_loss: 0.0045 - val_mae: 0.0475 - learning_rate: 0.0010\n",
      "Epoch 16/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0013 - mae: 0.0274 - val_loss: 0.0042 - val_mae: 0.0456 - learning_rate: 0.0010\n",
      "Epoch 17/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0014 - mae: 0.0296 - val_loss: 0.0044 - val_mae: 0.0478 - learning_rate: 0.0010\n",
      "Epoch 18/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mae: 0.0280 - val_loss: 0.0044 - val_mae: 0.0468 - learning_rate: 0.0010\n",
      "Epoch 19/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 9.4482e-04 - mae: 0.0232 - val_loss: 0.0045 - val_mae: 0.0484 - learning_rate: 5.0000e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 9.6833e-04 - mae: 0.0236 - val_loss: 0.0046 - val_mae: 0.0499 - learning_rate: 5.0000e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 9.3401e-04 - mae: 0.0230 - val_loss: 0.0048 - val_mae: 0.0512 - learning_rate: 5.0000e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 8.7116e-04 - mae: 0.0221 - val_loss: 0.0045 - val_mae: 0.0463 - learning_rate: 5.0000e-04\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step   \n",
      "âœ… Mysore - capsicum | MAE=250.68, RMSE=378.23, RÂ²=0.8737, MAPE=9.87%, Acc=90.13%\n",
      "\n",
      "ğŸš€ Processing: Mysore | onion\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 0.0702 - mae: 0.1345 - val_loss: 0.0161 - val_mae: 0.0715 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0041 - mae: 0.0492 - val_loss: 0.0116 - val_mae: 0.0575 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0033 - mae: 0.0447 - val_loss: 0.0082 - val_mae: 0.0557 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0030 - mae: 0.0420 - val_loss: 0.0077 - val_mae: 0.0600 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0026 - mae: 0.0396 - val_loss: 0.0088 - val_mae: 0.0497 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0023 - mae: 0.0367 - val_loss: 0.0067 - val_mae: 0.0492 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0022 - mae: 0.0358 - val_loss: 0.0064 - val_mae: 0.0527 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0018 - mae: 0.0309 - val_loss: 0.0062 - val_mae: 0.0539 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0017 - mae: 0.0304 - val_loss: 0.0058 - val_mae: 0.0487 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0015 - mae: 0.0286 - val_loss: 0.0063 - val_mae: 0.0597 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0014 - mae: 0.0274 - val_loss: 0.0071 - val_mae: 0.0439 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0012 - mae: 0.0246 - val_loss: 0.0060 - val_mae: 0.0425 - learning_rate: 0.0010\n",
      "Epoch 13/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0011 - mae: 0.0227 - val_loss: 0.0058 - val_mae: 0.0426 - learning_rate: 0.0010\n",
      "Epoch 14/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 9.2754e-04 - mae: 0.0202 - val_loss: 0.0059 - val_mae: 0.0410 - learning_rate: 5.0000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 9.0994e-04 - mae: 0.0201 - val_loss: 0.0058 - val_mae: 0.0408 - learning_rate: 5.0000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 8.9781e-04 - mae: 0.0195 - val_loss: 0.0058 - val_mae: 0.0407 - learning_rate: 5.0000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.6299e-04 - mae: 0.0194 - val_loss: 0.0055 - val_mae: 0.0406 - learning_rate: 5.0000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 7.9199e-04 - mae: 0.0184 - val_loss: 0.0051 - val_mae: 0.0420 - learning_rate: 5.0000e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 7.7881e-04 - mae: 0.0179 - val_loss: 0.0052 - val_mae: 0.0394 - learning_rate: 5.0000e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 7.9581e-04 - mae: 0.0182 - val_loss: 0.0050 - val_mae: 0.0401 - learning_rate: 5.0000e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 7.4362e-04 - mae: 0.0173 - val_loss: 0.0049 - val_mae: 0.0410 - learning_rate: 5.0000e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 7.5979e-04 - mae: 0.0172 - val_loss: 0.0047 - val_mae: 0.0424 - learning_rate: 5.0000e-04\n",
      "Epoch 23/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 7.2554e-04 - mae: 0.0168 - val_loss: 0.0048 - val_mae: 0.0383 - learning_rate: 5.0000e-04\n",
      "Epoch 24/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 7.0466e-04 - mae: 0.0162 - val_loss: 0.0049 - val_mae: 0.0376 - learning_rate: 5.0000e-04\n",
      "Epoch 25/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 7.1385e-04 - mae: 0.0164 - val_loss: 0.0046 - val_mae: 0.0381 - learning_rate: 5.0000e-04\n",
      "Epoch 26/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 7.1171e-04 - mae: 0.0165 - val_loss: 0.0048 - val_mae: 0.0371 - learning_rate: 5.0000e-04\n",
      "Epoch 27/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6.5829e-04 - mae: 0.0154 - val_loss: 0.0049 - val_mae: 0.0369 - learning_rate: 2.5000e-04\n",
      "Epoch 28/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 6.6541e-04 - mae: 0.0156 - val_loss: 0.0050 - val_mae: 0.0379 - learning_rate: 2.5000e-04\n",
      "Epoch 29/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 6.5957e-04 - mae: 0.0154 - val_loss: 0.0048 - val_mae: 0.0370 - learning_rate: 2.5000e-04\n",
      "Epoch 30/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 6.4595e-04 - mae: 0.0151 - val_loss: 0.0045 - val_mae: 0.0359 - learning_rate: 2.5000e-04\n",
      "Epoch 31/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 6.3656e-04 - mae: 0.0150 - val_loss: 0.0046 - val_mae: 0.0361 - learning_rate: 2.5000e-04\n",
      "Epoch 32/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 6.4587e-04 - mae: 0.0153 - val_loss: 0.0042 - val_mae: 0.0365 - learning_rate: 2.5000e-04\n",
      "Epoch 33/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 6.4543e-04 - mae: 0.0153 - val_loss: 0.0041 - val_mae: 0.0371 - learning_rate: 2.5000e-04\n",
      "Epoch 34/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 6.6015e-04 - mae: 0.0156 - val_loss: 0.0041 - val_mae: 0.0369 - learning_rate: 2.5000e-04\n",
      "Epoch 35/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 6.2824e-04 - mae: 0.0148 - val_loss: 0.0043 - val_mae: 0.0352 - learning_rate: 2.5000e-04\n",
      "Epoch 36/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6.1241e-04 - mae: 0.0147 - val_loss: 0.0040 - val_mae: 0.0368 - learning_rate: 2.5000e-04\n",
      "Epoch 37/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 5.9785e-04 - mae: 0.0144 - val_loss: 0.0043 - val_mae: 0.0348 - learning_rate: 2.5000e-04\n",
      "Epoch 38/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 5.8951e-04 - mae: 0.0142 - val_loss: 0.0039 - val_mae: 0.0371 - learning_rate: 2.5000e-04\n",
      "Epoch 39/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 5.8050e-04 - mae: 0.0140 - val_loss: 0.0041 - val_mae: 0.0348 - learning_rate: 2.5000e-04\n",
      "Epoch 40/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 5.8567e-04 - mae: 0.0141 - val_loss: 0.0040 - val_mae: 0.0348 - learning_rate: 2.5000e-04\n",
      "Epoch 41/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 5.5905e-04 - mae: 0.0134 - val_loss: 0.0043 - val_mae: 0.0345 - learning_rate: 1.2500e-04\n",
      "Epoch 42/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 5.7745e-04 - mae: 0.0137 - val_loss: 0.0044 - val_mae: 0.0349 - learning_rate: 1.2500e-04\n",
      "Epoch 43/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 5.6718e-04 - mae: 0.0136 - val_loss: 0.0042 - val_mae: 0.0344 - learning_rate: 1.2500e-04\n",
      "Epoch 44/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 5.6997e-04 - mae: 0.0136 - val_loss: 0.0043 - val_mae: 0.0347 - learning_rate: 1.2500e-04\n",
      "Epoch 45/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5.5546e-04 - mae: 0.0133 - val_loss: 0.0039 - val_mae: 0.0340 - learning_rate: 6.2500e-05\n",
      "Epoch 46/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5.4390e-04 - mae: 0.0128 - val_loss: 0.0039 - val_mae: 0.0337 - learning_rate: 6.2500e-05\n",
      "Epoch 47/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 5.5470e-04 - mae: 0.0132 - val_loss: 0.0038 - val_mae: 0.0340 - learning_rate: 6.2500e-05\n",
      "Epoch 48/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 5.4538e-04 - mae: 0.0130 - val_loss: 0.0038 - val_mae: 0.0336 - learning_rate: 6.2500e-05\n",
      "Epoch 49/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 5.3338e-04 - mae: 0.0129 - val_loss: 0.0039 - val_mae: 0.0333 - learning_rate: 6.2500e-05\n",
      "Epoch 50/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 5.4113e-04 - mae: 0.0131 - val_loss: 0.0039 - val_mae: 0.0332 - learning_rate: 6.2500e-05\n",
      "Epoch 51/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 5.3836e-04 - mae: 0.0130 - val_loss: 0.0038 - val_mae: 0.0336 - learning_rate: 6.2500e-05\n",
      "Epoch 52/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 5.1889e-04 - mae: 0.0124 - val_loss: 0.0038 - val_mae: 0.0348 - learning_rate: 3.1250e-05\n",
      "Epoch 53/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 5.1327e-04 - mae: 0.0123 - val_loss: 0.0038 - val_mae: 0.0339 - learning_rate: 3.1250e-05\n",
      "Epoch 54/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 5.1314e-04 - mae: 0.0125 - val_loss: 0.0038 - val_mae: 0.0342 - learning_rate: 3.1250e-05\n",
      "Epoch 55/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 5.1736e-04 - mae: 0.0125 - val_loss: 0.0037 - val_mae: 0.0351 - learning_rate: 3.1250e-05\n",
      "Epoch 56/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 5.1769e-04 - mae: 0.0124 - val_loss: 0.0038 - val_mae: 0.0337 - learning_rate: 3.1250e-05\n",
      "Epoch 57/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 5.1944e-04 - mae: 0.0123 - val_loss: 0.0038 - val_mae: 0.0339 - learning_rate: 3.1250e-05\n",
      "Epoch 58/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 5.2512e-04 - mae: 0.0126 - val_loss: 0.0037 - val_mae: 0.0340 - learning_rate: 3.1250e-05\n",
      "Epoch 59/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 5.3264e-04 - mae: 0.0127 - val_loss: 0.0038 - val_mae: 0.0333 - learning_rate: 3.1250e-05\n",
      "Epoch 60/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 5.1249e-04 - mae: 0.0124 - val_loss: 0.0038 - val_mae: 0.0338 - learning_rate: 1.5625e-05\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step   \n",
      "âœ… Mysore - onion | MAE=114.46, RMSE=208.11, RÂ²=0.903, MAPE=6.44%, Acc=93.56%\n",
      "\n",
      "ğŸš€ Processing: Mysore | tomato\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.1312 - mae: 0.1791 - val_loss: 0.0261 - val_mae: 0.1257 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0073 - mae: 0.0658 - val_loss: 0.0130 - val_mae: 0.0838 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0055 - mae: 0.0576 - val_loss: 0.0072 - val_mae: 0.0585 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0044 - mae: 0.0506 - val_loss: 0.0074 - val_mae: 0.0632 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0034 - mae: 0.0445 - val_loss: 0.0064 - val_mae: 0.0611 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0027 - mae: 0.0397 - val_loss: 0.0052 - val_mae: 0.0546 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0024 - mae: 0.0373 - val_loss: 0.0047 - val_mae: 0.0500 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0020 - mae: 0.0338 - val_loss: 0.0069 - val_mae: 0.0662 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0019 - mae: 0.0323 - val_loss: 0.0073 - val_mae: 0.0715 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0017 - mae: 0.0311 - val_loss: 0.0034 - val_mae: 0.0417 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0017 - mae: 0.0311 - val_loss: 0.0038 - val_mae: 0.0473 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0312 - val_loss: 0.0044 - val_mae: 0.0529 - learning_rate: 0.0010\n",
      "Epoch 13/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0017 - mae: 0.0309 - val_loss: 0.0108 - val_mae: 0.0929 - learning_rate: 0.0010\n",
      "Epoch 14/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0016 - mae: 0.0292 - val_loss: 0.0035 - val_mae: 0.0452 - learning_rate: 0.0010\n",
      "Epoch 15/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0012 - mae: 0.0253 - val_loss: 0.0034 - val_mae: 0.0447 - learning_rate: 5.0000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0011 - mae: 0.0241 - val_loss: 0.0029 - val_mae: 0.0398 - learning_rate: 5.0000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0012 - mae: 0.0246 - val_loss: 0.0036 - val_mae: 0.0456 - learning_rate: 5.0000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0011 - mae: 0.0242 - val_loss: 0.0035 - val_mae: 0.0454 - learning_rate: 5.0000e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mae: 0.0242 - val_loss: 0.0047 - val_mae: 0.0560 - learning_rate: 5.0000e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0011 - mae: 0.0239 - val_loss: 0.0030 - val_mae: 0.0419 - learning_rate: 5.0000e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 9.7888e-04 - mae: 0.0218 - val_loss: 0.0046 - val_mae: 0.0553 - learning_rate: 2.5000e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0010 - mae: 0.0230 - val_loss: 0.0044 - val_mae: 0.0527 - learning_rate: 2.5000e-04\n",
      "Epoch 23/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0010 - mae: 0.0231 - val_loss: 0.0038 - val_mae: 0.0485 - learning_rate: 2.5000e-04\n",
      "Epoch 24/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0011 - mae: 0.0239 - val_loss: 0.0036 - val_mae: 0.0466 - learning_rate: 2.5000e-04\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step   \n",
      "âœ… Mysore - tomato | MAE=108.0, RMSE=164.06, RÂ²=0.9234, MAPE=8.57%, Acc=91.43%\n",
      "\n",
      "ğŸš€ Processing: Mysore | wheat\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0342 - mae: 0.0975 - val_loss: 0.0036 - val_mae: 0.0410 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0033 - mae: 0.0459 - val_loss: 0.0028 - val_mae: 0.0294 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0025 - mae: 0.0402 - val_loss: 0.0023 - val_mae: 0.0200 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0018 - mae: 0.0340 - val_loss: 0.0020 - val_mae: 0.0144 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0014 - mae: 0.0294 - val_loss: 0.0024 - val_mae: 0.0227 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 9.9408e-04 - mae: 0.0252 - val_loss: 0.0023 - val_mae: 0.0269 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 7.7504e-04 - mae: 0.0222 - val_loss: 0.0022 - val_mae: 0.0182 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 6.1318e-04 - mae: 0.0196 - val_loss: 0.0019 - val_mae: 0.0114 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 4.9279e-04 - mae: 0.0176 - val_loss: 0.0020 - val_mae: 0.0131 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 4.0931e-04 - mae: 0.0161 - val_loss: 0.0019 - val_mae: 0.0118 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 3.6563e-04 - mae: 0.0152 - val_loss: 0.0020 - val_mae: 0.0141 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 3.2020e-04 - mae: 0.0141 - val_loss: 0.0023 - val_mae: 0.0226 - learning_rate: 0.0010\n",
      "Epoch 13/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 2.1243e-04 - mae: 0.0115 - val_loss: 0.0019 - val_mae: 0.0112 - learning_rate: 5.0000e-04\n",
      "Epoch 14/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 2.1891e-04 - mae: 0.0117 - val_loss: 0.0019 - val_mae: 0.0106 - learning_rate: 5.0000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 2.0822e-04 - mae: 0.0114 - val_loss: 0.0019 - val_mae: 0.0106 - learning_rate: 5.0000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 1.7743e-04 - mae: 0.0105 - val_loss: 0.0019 - val_mae: 0.0111 - learning_rate: 5.0000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 1.5319e-04 - mae: 0.0097 - val_loss: 0.0018 - val_mae: 0.0105 - learning_rate: 2.5000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 1.4406e-04 - mae: 0.0093 - val_loss: 0.0020 - val_mae: 0.0136 - learning_rate: 2.5000e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 1.4648e-04 - mae: 0.0094 - val_loss: 0.0018 - val_mae: 0.0103 - learning_rate: 2.5000e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.3000e-04 - mae: 0.0088 - val_loss: 0.0019 - val_mae: 0.0107 - learning_rate: 2.5000e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 1.2690e-04 - mae: 0.0087 - val_loss: 0.0020 - val_mae: 0.0142 - learning_rate: 1.2500e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 1.2109e-04 - mae: 0.0086 - val_loss: 0.0019 - val_mae: 0.0113 - learning_rate: 1.2500e-04\n",
      "Epoch 23/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.1197e-04 - mae: 0.0081 - val_loss: 0.0019 - val_mae: 0.0116 - learning_rate: 1.2500e-04\n",
      "Epoch 24/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 1.2695e-04 - mae: 0.0088 - val_loss: 0.0019 - val_mae: 0.0125 - learning_rate: 1.2500e-04\n",
      "Epoch 25/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.1073e-04 - mae: 0.0081 - val_loss: 0.0019 - val_mae: 0.0125 - learning_rate: 6.2500e-05\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step   \n",
      "âœ… Mysore - wheat | MAE=222.29, RMSE=703.5, RÂ²=0.5221, MAPE=9.13%, Acc=90.87%\n",
      "\n",
      "ğŸš€ Processing: Raichur | onion\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 0.1001 - mae: 0.1545 - val_loss: 0.0020 - val_mae: 0.0386 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0057 - mae: 0.0567 - val_loss: 0.0015 - val_mae: 0.0313 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0046 - mae: 0.0523 - val_loss: 0.0018 - val_mae: 0.0361 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0039 - mae: 0.0484 - val_loss: 7.4670e-04 - val_mae: 0.0199 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0035 - mae: 0.0451 - val_loss: 0.0020 - val_mae: 0.0390 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0032 - mae: 0.0435 - val_loss: 0.0012 - val_mae: 0.0278 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0027 - mae: 0.0395 - val_loss: 7.3206e-04 - val_mae: 0.0201 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0027 - mae: 0.0403 - val_loss: 7.2076e-04 - val_mae: 0.0208 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0020 - mae: 0.0332 - val_loss: 4.9084e-04 - val_mae: 0.0154 - learning_rate: 5.0000e-04\n",
      "Epoch 10/60\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0018 - mae: 0.0321 - val_loss: 5.4837e-04 - val_mae: 0.0170 - learning_rate: 5.0000e-04\n",
      "Epoch 11/60\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0018 - mae: 0.0320 - val_loss: 5.6363e-04 - val_mae: 0.0183 - learning_rate: 5.0000e-04\n",
      "Epoch 12/60\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0017 - mae: 0.0307 - val_loss: 5.0647e-04 - val_mae: 0.0164 - learning_rate: 5.0000e-04\n",
      "Epoch 13/60\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0016 - mae: 0.0303 - val_loss: 4.3859e-04 - val_mae: 0.0141 - learning_rate: 5.0000e-04\n",
      "Epoch 14/60\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0014 - mae: 0.0275 - val_loss: 4.7133e-04 - val_mae: 0.0155 - learning_rate: 2.5000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - mae: 0.0276 - val_loss: 4.1425e-04 - val_mae: 0.0139 - learning_rate: 2.5000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0013 - mae: 0.0267 - val_loss: 7.2996e-04 - val_mae: 0.0215 - learning_rate: 2.5000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0014 - mae: 0.0266 - val_loss: 4.7925e-04 - val_mae: 0.0160 - learning_rate: 2.5000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0252 - val_loss: 4.5227e-04 - val_mae: 0.0156 - learning_rate: 1.2500e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0012 - mae: 0.0255 - val_loss: 4.2958e-04 - val_mae: 0.0149 - learning_rate: 1.2500e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0013 - mae: 0.0257 - val_loss: 4.3463e-04 - val_mae: 0.0151 - learning_rate: 1.2500e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0253 - val_loss: 4.6972e-04 - val_mae: 0.0164 - learning_rate: 1.2500e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0011 - mae: 0.0240 - val_loss: 4.2793e-04 - val_mae: 0.0145 - learning_rate: 6.2500e-05\n",
      "Epoch 23/60\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0012 - mae: 0.0243 - val_loss: 5.4464e-04 - val_mae: 0.0178 - learning_rate: 6.2500e-05\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step   \n",
      "âœ… Raichur - onion | MAE=135.29, RMSE=219.77, RÂ²=0.9235, MAPE=12.07%, Acc=87.93%\n",
      "\n",
      "ğŸš€ Processing: Raichur | tomato\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - loss: 0.8949 - mae: 0.7119 - val_loss: 0.1045 - val_mae: 0.3188 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1018 - mae: 0.2623 - val_loss: 0.0018 - val_mae: 0.0278 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0513 - mae: 0.1847 - val_loss: 0.0585 - val_mae: 0.2388 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0317 - mae: 0.1434 - val_loss: 0.0527 - val_mae: 0.2264 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0276 - mae: 0.1301 - val_loss: 0.0255 - val_mae: 0.1559 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0224 - mae: 0.1186 - val_loss: 0.0124 - val_mae: 0.1069 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0208 - mae: 0.1089 - val_loss: 0.0090 - val_mae: 0.0905 - learning_rate: 5.0000e-04\n",
      "Epoch 8/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0189 - mae: 0.1033 - val_loss: 0.0031 - val_mae: 0.0502 - learning_rate: 5.0000e-04\n",
      "Epoch 9/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0169 - mae: 0.0956 - val_loss: 0.0013 - val_mae: 0.0297 - learning_rate: 5.0000e-04\n",
      "Epoch 10/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0159 - mae: 0.0944 - val_loss: 6.1262e-04 - val_mae: 0.0207 - learning_rate: 5.0000e-04\n",
      "Epoch 11/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0166 - mae: 0.0953 - val_loss: 7.7888e-04 - val_mae: 0.0234 - learning_rate: 5.0000e-04\n",
      "Epoch 12/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0143 - mae: 0.0925 - val_loss: 7.2604e-04 - val_mae: 0.0215 - learning_rate: 5.0000e-04\n",
      "Epoch 13/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0134 - mae: 0.0861 - val_loss: 7.2225e-04 - val_mae: 0.0214 - learning_rate: 5.0000e-04\n",
      "Epoch 14/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0135 - mae: 0.0853 - val_loss: 5.7058e-04 - val_mae: 0.0188 - learning_rate: 5.0000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0122 - mae: 0.0847 - val_loss: 3.4676e-04 - val_mae: 0.0139 - learning_rate: 2.5000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0117 - mae: 0.0821 - val_loss: 4.6885e-04 - val_mae: 0.0165 - learning_rate: 2.5000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0123 - mae: 0.0840 - val_loss: 4.8134e-04 - val_mae: 0.0169 - learning_rate: 2.5000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0114 - mae: 0.0796 - val_loss: 6.5098e-04 - val_mae: 0.0211 - learning_rate: 2.5000e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0121 - mae: 0.0834 - val_loss: 4.4080e-04 - val_mae: 0.0163 - learning_rate: 2.5000e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0110 - mae: 0.0789 - val_loss: 9.1802e-04 - val_mae: 0.0264 - learning_rate: 1.2500e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0103 - mae: 0.0768 - val_loss: 0.0015 - val_mae: 0.0357 - learning_rate: 1.2500e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0108 - mae: 0.0780 - val_loss: 9.0601e-04 - val_mae: 0.0261 - learning_rate: 1.2500e-04\n",
      "Epoch 23/60\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0108 - mae: 0.0809 - val_loss: 0.0010 - val_mae: 0.0285 - learning_rate: 1.2500e-04\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step \n",
      "âœ… Raichur - tomato | MAE=85.35, RMSE=133.46, RÂ²=0.8978, MAPE=11.36%, Acc=88.64%\n",
      "\n",
      "ğŸš€ Processing: Raichur | wheat\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 20ms/step - loss: 0.1412 - mae: 0.1646 - val_loss: 0.0898 - val_mae: 0.2738 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0061 - mae: 0.0616 - val_loss: 0.0613 - val_mae: 0.2229 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0039 - mae: 0.0484 - val_loss: 0.0348 - val_mae: 0.1625 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0032 - mae: 0.0434 - val_loss: 0.0396 - val_mae: 0.1759 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0026 - mae: 0.0386 - val_loss: 0.0326 - val_mae: 0.1582 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0024 - mae: 0.0372 - val_loss: 0.0329 - val_mae: 0.1593 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0021 - mae: 0.0346 - val_loss: 0.0227 - val_mae: 0.1293 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0019 - mae: 0.0322 - val_loss: 0.0201 - val_mae: 0.1213 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0016 - mae: 0.0300 - val_loss: 0.0225 - val_mae: 0.1289 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0016 - mae: 0.0296 - val_loss: 0.0225 - val_mae: 0.1292 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0013 - mae: 0.0262 - val_loss: 0.0203 - val_mae: 0.1222 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0013 - mae: 0.0262 - val_loss: 0.0251 - val_mae: 0.1381 - learning_rate: 0.0010\n",
      "Epoch 13/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0011 - mae: 0.0236 - val_loss: 0.0273 - val_mae: 0.1455 - learning_rate: 5.0000e-04\n",
      "Epoch 14/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0011 - mae: 0.0227 - val_loss: 0.0290 - val_mae: 0.1515 - learning_rate: 5.0000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0011 - mae: 0.0229 - val_loss: 0.0239 - val_mae: 0.1348 - learning_rate: 5.0000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0011 - mae: 0.0227 - val_loss: 0.0220 - val_mae: 0.1284 - learning_rate: 5.0000e-04\n",
      "\u001b[1m84/84\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step   \n",
      "âœ… Raichur - wheat | MAE=72.38, RMSE=114.4, RÂ²=0.9051, MAPE=3.61%, Acc=96.39%\n",
      "\n",
      "ğŸš€ Processing: Shimoga | capsicum\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 526ms/step - loss: 1.3404 - mae: 0.9345 - val_loss: 0.6822 - val_mae: 0.8255 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.9393 - mae: 0.9411 - val_loss: 0.5509 - val_mae: 0.7416 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - loss: 0.3413 - mae: 0.5371 - val_loss: 0.0030 - val_mae: 0.0446 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.1027 - mae: 0.2658 - val_loss: 0.1150 - val_mae: 0.3368 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.3649 - mae: 0.5927 - val_loss: 0.0555 - val_mae: 0.2323 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.1736 - mae: 0.3888 - val_loss: 0.0160 - val_mae: 0.1206 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0203 - mae: 0.1111 - val_loss: 0.2099 - val_mae: 0.4567 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.0838 - mae: 0.2712 - val_loss: 0.2718 - val_mae: 0.5201 - learning_rate: 5.0000e-04\n",
      "Epoch 9/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.1073 - mae: 0.3144 - val_loss: 0.2276 - val_mae: 0.4757 - learning_rate: 5.0000e-04\n",
      "Epoch 10/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0679 - mae: 0.2438 - val_loss: 0.1334 - val_mae: 0.3635 - learning_rate: 5.0000e-04\n",
      "Epoch 11/60\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.0327 - mae: 0.1502 - val_loss: 0.0513 - val_mae: 0.2235 - learning_rate: 5.0000e-04\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step\n",
      "âœ… Shimoga - capsicum | MAE=81.6, RMSE=93.38, RÂ²=0.5411, MAPE=5.07%, Acc=94.93%\n",
      "\n",
      "ğŸš€ Processing: Shimoga | onion\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0235 - mae: 0.0937 - val_loss: 0.0092 - val_mae: 0.0657 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0031 - mae: 0.0432 - val_loss: 0.0099 - val_mae: 0.0619 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0022 - mae: 0.0357 - val_loss: 0.0066 - val_mae: 0.0503 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0015 - mae: 0.0292 - val_loss: 0.0070 - val_mae: 0.0603 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mae: 0.0283 - val_loss: 0.0062 - val_mae: 0.0488 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mae: 0.0253 - val_loss: 0.0063 - val_mae: 0.0472 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0010 - mae: 0.0226 - val_loss: 0.0061 - val_mae: 0.0460 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 9.1246e-04 - mae: 0.0216 - val_loss: 0.0058 - val_mae: 0.0443 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 7.7106e-04 - mae: 0.0190 - val_loss: 0.0054 - val_mae: 0.0433 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 7.3926e-04 - mae: 0.0180 - val_loss: 0.0053 - val_mae: 0.0412 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 7.6829e-04 - mae: 0.0186 - val_loss: 0.0054 - val_mae: 0.0464 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 7.4213e-04 - mae: 0.0184 - val_loss: 0.0062 - val_mae: 0.0509 - learning_rate: 0.0010\n",
      "Epoch 13/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 7.1364e-04 - mae: 0.0178 - val_loss: 0.0057 - val_mae: 0.0454 - learning_rate: 0.0010\n",
      "Epoch 14/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 6.7466e-04 - mae: 0.0168 - val_loss: 0.0052 - val_mae: 0.0406 - learning_rate: 0.0010\n",
      "Epoch 15/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 5.8903e-04 - mae: 0.0147 - val_loss: 0.0054 - val_mae: 0.0411 - learning_rate: 5.0000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 5.8689e-04 - mae: 0.0148 - val_loss: 0.0052 - val_mae: 0.0403 - learning_rate: 5.0000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 5.4398e-04 - mae: 0.0141 - val_loss: 0.0051 - val_mae: 0.0416 - learning_rate: 5.0000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 6.1312e-04 - mae: 0.0154 - val_loss: 0.0051 - val_mae: 0.0405 - learning_rate: 5.0000e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 5.7637e-04 - mae: 0.0147 - val_loss: 0.0051 - val_mae: 0.0399 - learning_rate: 5.0000e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5.3386e-04 - mae: 0.0137 - val_loss: 0.0050 - val_mae: 0.0402 - learning_rate: 5.0000e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5.5324e-04 - mae: 0.0144 - val_loss: 0.0051 - val_mae: 0.0408 - learning_rate: 5.0000e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.6644e-04 - mae: 0.0120 - val_loss: 0.0051 - val_mae: 0.0395 - learning_rate: 2.5000e-04\n",
      "Epoch 23/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 4.8417e-04 - mae: 0.0125 - val_loss: 0.0051 - val_mae: 0.0400 - learning_rate: 2.5000e-04\n",
      "Epoch 24/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4.6935e-04 - mae: 0.0123 - val_loss: 0.0052 - val_mae: 0.0401 - learning_rate: 2.5000e-04\n",
      "Epoch 25/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 4.8683e-04 - mae: 0.0127 - val_loss: 0.0050 - val_mae: 0.0396 - learning_rate: 2.5000e-04\n",
      "Epoch 26/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 4.2124e-04 - mae: 0.0109 - val_loss: 0.0050 - val_mae: 0.0393 - learning_rate: 1.2500e-04\n",
      "Epoch 27/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 4.2897e-04 - mae: 0.0110 - val_loss: 0.0050 - val_mae: 0.0395 - learning_rate: 1.2500e-04\n",
      "Epoch 28/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.2461e-04 - mae: 0.0109 - val_loss: 0.0049 - val_mae: 0.0407 - learning_rate: 1.2500e-04\n",
      "Epoch 29/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 4.1465e-04 - mae: 0.0107 - val_loss: 0.0049 - val_mae: 0.0398 - learning_rate: 1.2500e-04\n",
      "Epoch 30/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.1203e-04 - mae: 0.0108 - val_loss: 0.0049 - val_mae: 0.0397 - learning_rate: 1.2500e-04\n",
      "Epoch 31/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 4.0578e-04 - mae: 0.0102 - val_loss: 0.0049 - val_mae: 0.0388 - learning_rate: 6.2500e-05\n",
      "Epoch 32/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 4.0906e-04 - mae: 0.0104 - val_loss: 0.0049 - val_mae: 0.0387 - learning_rate: 6.2500e-05\n",
      "Epoch 33/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 4.1367e-04 - mae: 0.0104 - val_loss: 0.0049 - val_mae: 0.0388 - learning_rate: 6.2500e-05\n",
      "Epoch 34/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 4.0648e-04 - mae: 0.0103 - val_loss: 0.0049 - val_mae: 0.0388 - learning_rate: 6.2500e-05\n",
      "Epoch 35/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 3.9505e-04 - mae: 0.0098 - val_loss: 0.0049 - val_mae: 0.0387 - learning_rate: 3.1250e-05\n",
      "Epoch 36/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 4.0298e-04 - mae: 0.0100 - val_loss: 0.0049 - val_mae: 0.0387 - learning_rate: 3.1250e-05\n",
      "Epoch 37/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 3.9174e-04 - mae: 0.0097 - val_loss: 0.0049 - val_mae: 0.0386 - learning_rate: 3.1250e-05\n",
      "Epoch 38/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 3.8530e-04 - mae: 0.0097 - val_loss: 0.0049 - val_mae: 0.0386 - learning_rate: 3.1250e-05\n",
      "Epoch 39/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 3.9061e-04 - mae: 0.0094 - val_loss: 0.0049 - val_mae: 0.0386 - learning_rate: 1.5625e-05\n",
      "Epoch 40/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 3.8806e-04 - mae: 0.0095 - val_loss: 0.0049 - val_mae: 0.0386 - learning_rate: 1.5625e-05\n",
      "Epoch 41/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 3.8860e-04 - mae: 0.0096 - val_loss: 0.0050 - val_mae: 0.0388 - learning_rate: 1.5625e-05\n",
      "Epoch 42/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 3.8736e-04 - mae: 0.0096 - val_loss: 0.0050 - val_mae: 0.0387 - learning_rate: 1.5625e-05\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step   \n",
      "âœ… Shimoga - onion | MAE=143.24, RMSE=336.47, RÂ²=0.8689, MAPE=44.25%, Acc=55.75%\n",
      "\n",
      "ğŸš€ Processing: Shimoga | tomato\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 0.1498 - mae: 0.1560 - val_loss: 0.0080 - val_mae: 0.0570 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0030 - mae: 0.0430 - val_loss: 0.0059 - val_mae: 0.0479 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0026 - mae: 0.0400 - val_loss: 0.0071 - val_mae: 0.0557 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0023 - mae: 0.0376 - val_loss: 0.0048 - val_mae: 0.0441 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0019 - mae: 0.0339 - val_loss: 0.0072 - val_mae: 0.0587 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0017 - mae: 0.0314 - val_loss: 0.0049 - val_mae: 0.0447 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0013 - mae: 0.0282 - val_loss: 0.0042 - val_mae: 0.0414 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mae: 0.0263 - val_loss: 0.0040 - val_mae: 0.0405 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0010 - mae: 0.0244 - val_loss: 0.0040 - val_mae: 0.0389 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 8.4914e-04 - mae: 0.0220 - val_loss: 0.0043 - val_mae: 0.0418 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 7.2264e-04 - mae: 0.0200 - val_loss: 0.0039 - val_mae: 0.0390 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6.3324e-04 - mae: 0.0185 - val_loss: 0.0040 - val_mae: 0.0390 - learning_rate: 0.0010\n",
      "Epoch 13/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 5.3363e-04 - mae: 0.0167 - val_loss: 0.0039 - val_mae: 0.0380 - learning_rate: 5.0000e-04\n",
      "Epoch 14/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 5.1602e-04 - mae: 0.0163 - val_loss: 0.0039 - val_mae: 0.0383 - learning_rate: 5.0000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 5.0755e-04 - mae: 0.0161 - val_loss: 0.0038 - val_mae: 0.0373 - learning_rate: 5.0000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 5.0081e-04 - mae: 0.0160 - val_loss: 0.0038 - val_mae: 0.0373 - learning_rate: 5.0000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5.0078e-04 - mae: 0.0160 - val_loss: 0.0039 - val_mae: 0.0367 - learning_rate: 5.0000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 4.1660e-04 - mae: 0.0141 - val_loss: 0.0038 - val_mae: 0.0365 - learning_rate: 2.5000e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 4.0212e-04 - mae: 0.0138 - val_loss: 0.0038 - val_mae: 0.0366 - learning_rate: 2.5000e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 4.1238e-04 - mae: 0.0137 - val_loss: 0.0039 - val_mae: 0.0373 - learning_rate: 2.5000e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 3.8496e-04 - mae: 0.0135 - val_loss: 0.0039 - val_mae: 0.0364 - learning_rate: 2.5000e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 3.8733e-04 - mae: 0.0133 - val_loss: 0.0038 - val_mae: 0.0363 - learning_rate: 1.2500e-04\n",
      "Epoch 23/60\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 3.7509e-04 - mae: 0.0132 - val_loss: 0.0038 - val_mae: 0.0362 - learning_rate: 1.2500e-04\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step   \n",
      "âœ… Shimoga - tomato | MAE=246.37, RMSE=542.08, RÂ²=0.7221, MAPE=37.96%, Acc=62.04%\n",
      "\n",
      "ğŸš€ Processing: Shimoga | wheat\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - loss: 0.0487 - mae: 0.1145 - val_loss: 5.0051e-04 - val_mae: 0.0181 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0030 - mae: 0.0411 - val_loss: 3.5560e-04 - val_mae: 0.0163 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0023 - mae: 0.0358 - val_loss: 3.5574e-04 - val_mae: 0.0176 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0017 - mae: 0.0295 - val_loss: 7.7791e-04 - val_mae: 0.0271 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0014 - mae: 0.0257 - val_loss: 9.6719e-05 - val_mae: 0.0058 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0010 - mae: 0.0214 - val_loss: 9.5478e-05 - val_mae: 0.0060 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.9950e-04 - mae: 0.0191 - val_loss: 1.2137e-04 - val_mae: 0.0065 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 7.1841e-04 - mae: 0.0163 - val_loss: 1.0950e-04 - val_mae: 0.0077 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 6.6229e-04 - mae: 0.0147 - val_loss: 2.7567e-04 - val_mae: 0.0141 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5.6414e-04 - mae: 0.0127 - val_loss: 8.0274e-05 - val_mae: 0.0037 - learning_rate: 5.0000e-04\n",
      "Epoch 11/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 5.3487e-04 - mae: 0.0119 - val_loss: 8.9227e-05 - val_mae: 0.0046 - learning_rate: 5.0000e-04\n",
      "Epoch 12/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 5.2145e-04 - mae: 0.0115 - val_loss: 8.1290e-05 - val_mae: 0.0038 - learning_rate: 5.0000e-04\n",
      "Epoch 13/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 5.0396e-04 - mae: 0.0111 - val_loss: 1.9404e-04 - val_mae: 0.0110 - learning_rate: 5.0000e-04\n",
      "Epoch 14/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4.6234e-04 - mae: 0.0096 - val_loss: 7.7128e-05 - val_mae: 0.0045 - learning_rate: 2.5000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 4.5047e-04 - mae: 0.0094 - val_loss: 7.7969e-05 - val_mae: 0.0048 - learning_rate: 2.5000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 4.6126e-04 - mae: 0.0094 - val_loss: 7.7174e-05 - val_mae: 0.0034 - learning_rate: 2.5000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4.5055e-04 - mae: 0.0093 - val_loss: 8.4694e-05 - val_mae: 0.0043 - learning_rate: 2.5000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 4.2973e-04 - mae: 0.0086 - val_loss: 7.5430e-05 - val_mae: 0.0038 - learning_rate: 1.2500e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 4.4429e-04 - mae: 0.0086 - val_loss: 7.5481e-05 - val_mae: 0.0036 - learning_rate: 1.2500e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 4.2861e-04 - mae: 0.0084 - val_loss: 8.2380e-05 - val_mae: 0.0041 - learning_rate: 1.2500e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.2802e-04 - mae: 0.0082 - val_loss: 7.5070e-05 - val_mae: 0.0036 - learning_rate: 1.2500e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 4.1758e-04 - mae: 0.0081 - val_loss: 7.7951e-05 - val_mae: 0.0036 - learning_rate: 6.2500e-05\n",
      "Epoch 23/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.0871e-04 - mae: 0.0080 - val_loss: 7.4832e-05 - val_mae: 0.0036 - learning_rate: 6.2500e-05\n",
      "Epoch 24/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 4.2191e-04 - mae: 0.0080 - val_loss: 7.5122e-05 - val_mae: 0.0042 - learning_rate: 6.2500e-05\n",
      "Epoch 25/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4.1662e-04 - mae: 0.0082 - val_loss: 7.7505e-05 - val_mae: 0.0035 - learning_rate: 6.2500e-05\n",
      "Epoch 26/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4.0992e-04 - mae: 0.0080 - val_loss: 7.8736e-05 - val_mae: 0.0037 - learning_rate: 3.1250e-05\n",
      "Epoch 27/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 4.1520e-04 - mae: 0.0078 - val_loss: 7.6725e-05 - val_mae: 0.0035 - learning_rate: 3.1250e-05\n",
      "Epoch 28/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 4.1027e-04 - mae: 0.0079 - val_loss: 7.4618e-05 - val_mae: 0.0036 - learning_rate: 3.1250e-05\n",
      "Epoch 29/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.0962e-04 - mae: 0.0077 - val_loss: 7.4555e-05 - val_mae: 0.0037 - learning_rate: 3.1250e-05\n",
      "Epoch 30/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.0988e-04 - mae: 0.0078 - val_loss: 7.4967e-05 - val_mae: 0.0035 - learning_rate: 1.5625e-05\n",
      "Epoch 31/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 4.0952e-04 - mae: 0.0078 - val_loss: 7.5151e-05 - val_mae: 0.0035 - learning_rate: 1.5625e-05\n",
      "Epoch 32/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 4.1796e-04 - mae: 0.0077 - val_loss: 7.6778e-05 - val_mae: 0.0035 - learning_rate: 1.5625e-05\n",
      "Epoch 33/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.0837e-04 - mae: 0.0077 - val_loss: 7.4689e-05 - val_mae: 0.0041 - learning_rate: 1.5625e-05\n",
      "Epoch 34/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 4.0233e-04 - mae: 0.0076 - val_loss: 7.4641e-05 - val_mae: 0.0036 - learning_rate: 7.8125e-06\n",
      "Epoch 35/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4.0760e-04 - mae: 0.0078 - val_loss: 7.4416e-05 - val_mae: 0.0037 - learning_rate: 7.8125e-06\n",
      "Epoch 36/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.0229e-04 - mae: 0.0075 - val_loss: 7.4397e-05 - val_mae: 0.0037 - learning_rate: 7.8125e-06\n",
      "Epoch 37/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 4.0282e-04 - mae: 0.0076 - val_loss: 7.4387e-05 - val_mae: 0.0037 - learning_rate: 7.8125e-06\n",
      "Epoch 38/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4.0857e-04 - mae: 0.0075 - val_loss: 7.4636e-05 - val_mae: 0.0035 - learning_rate: 3.9063e-06\n",
      "Epoch 39/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 4.0872e-04 - mae: 0.0076 - val_loss: 7.4610e-05 - val_mae: 0.0035 - learning_rate: 3.9063e-06\n",
      "Epoch 40/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.0877e-04 - mae: 0.0075 - val_loss: 7.5971e-05 - val_mae: 0.0035 - learning_rate: 3.9063e-06\n",
      "Epoch 41/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 4.0714e-04 - mae: 0.0074 - val_loss: 7.4437e-05 - val_mae: 0.0036 - learning_rate: 3.9063e-06\n",
      "Epoch 42/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.0417e-04 - mae: 0.0075 - val_loss: 7.4912e-05 - val_mae: 0.0035 - learning_rate: 1.9531e-06\n",
      "Epoch 43/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 4.0094e-04 - mae: 0.0073 - val_loss: 7.4919e-05 - val_mae: 0.0035 - learning_rate: 1.9531e-06\n",
      "Epoch 44/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4.0588e-04 - mae: 0.0073 - val_loss: 7.4620e-05 - val_mae: 0.0035 - learning_rate: 1.9531e-06\n",
      "Epoch 45/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 3.9089e-04 - mae: 0.0074 - val_loss: 7.4411e-05 - val_mae: 0.0036 - learning_rate: 1.9531e-06\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step   \n",
      "âœ… Shimoga - wheat | MAE=141.2, RMSE=540.3, RÂ²=0.3963, MAPE=5.58%, Acc=94.42%\n",
      "\n",
      "ğŸš€ Processing: Tumkur | onion\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 0.0354 - mae: 0.1028 - val_loss: 0.0664 - val_mae: 0.2378 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0033 - mae: 0.0455 - val_loss: 0.0326 - val_mae: 0.1574 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0392 - val_loss: 0.0249 - val_mae: 0.1346 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0022 - mae: 0.0368 - val_loss: 0.0215 - val_mae: 0.1236 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0017 - mae: 0.0318 - val_loss: 0.0166 - val_mae: 0.1041 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0011 - mae: 0.0253 - val_loss: 0.0093 - val_mae: 0.0677 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 9.4653e-04 - mae: 0.0234 - val_loss: 0.0105 - val_mae: 0.0747 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 7.8805e-04 - mae: 0.0209 - val_loss: 0.0115 - val_mae: 0.0809 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 6.8197e-04 - mae: 0.0194 - val_loss: 0.0093 - val_mae: 0.0685 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 6.0695e-04 - mae: 0.0184 - val_loss: 0.0075 - val_mae: 0.0597 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 6.0816e-04 - mae: 0.0185 - val_loss: 0.0099 - val_mae: 0.0729 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 4.6174e-04 - mae: 0.0159 - val_loss: 0.0083 - val_mae: 0.0632 - learning_rate: 0.0010\n",
      "Epoch 13/60\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 3.7885e-04 - mae: 0.0143 - val_loss: 0.0067 - val_mae: 0.0560 - learning_rate: 0.0010\n",
      "Epoch 14/60\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 3.3304e-04 - mae: 0.0135 - val_loss: 0.0070 - val_mae: 0.0567 - learning_rate: 0.0010\n",
      "Epoch 15/60\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 3.9406e-04 - mae: 0.0147 - val_loss: 0.0047 - val_mae: 0.0518 - learning_rate: 0.0010\n",
      "Epoch 16/60\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 3.3333e-04 - mae: 0.0135 - val_loss: 0.0058 - val_mae: 0.0525 - learning_rate: 0.0010\n",
      "Epoch 17/60\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 3.1617e-04 - mae: 0.0131 - val_loss: 0.0054 - val_mae: 0.0519 - learning_rate: 0.0010\n",
      "Epoch 18/60\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 3.2854e-04 - mae: 0.0136 - val_loss: 0.0056 - val_mae: 0.0526 - learning_rate: 0.0010\n",
      "Epoch 19/60\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 3.5796e-04 - mae: 0.0143 - val_loss: 0.0052 - val_mae: 0.0521 - learning_rate: 0.0010\n",
      "Epoch 20/60\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 2.2114e-04 - mae: 0.0107 - val_loss: 0.0062 - val_mae: 0.0542 - learning_rate: 5.0000e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 1.9324e-04 - mae: 0.0098 - val_loss: 0.0069 - val_mae: 0.0571 - learning_rate: 5.0000e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 1.9356e-04 - mae: 0.0098 - val_loss: 0.0065 - val_mae: 0.0552 - learning_rate: 5.0000e-04\n",
      "Epoch 23/60\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 1.9137e-04 - mae: 0.0097 - val_loss: 0.0063 - val_mae: 0.0545 - learning_rate: 5.0000e-04\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step   \n",
      "âœ… Tumkur - onion | MAE=332.75, RMSE=426.28, RÂ²=0.9446, MAPE=12.11%, Acc=87.89%\n",
      "\n",
      "ğŸš€ Processing: Tumkur | tomato\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 0.1244 - mae: 0.1785 - val_loss: 0.0564 - val_mae: 0.1858 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0040 - mae: 0.0499 - val_loss: 0.0431 - val_mae: 0.1590 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0033 - mae: 0.0456 - val_loss: 0.0366 - val_mae: 0.1487 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0029 - mae: 0.0426 - val_loss: 0.0418 - val_mae: 0.1550 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0025 - mae: 0.0394 - val_loss: 0.0397 - val_mae: 0.1498 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0022 - mae: 0.0373 - val_loss: 0.0327 - val_mae: 0.1377 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0018 - mae: 0.0335 - val_loss: 0.0334 - val_mae: 0.1367 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0015 - mae: 0.0308 - val_loss: 0.0345 - val_mae: 0.1387 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0015 - mae: 0.0309 - val_loss: 0.0302 - val_mae: 0.1313 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0012 - mae: 0.0268 - val_loss: 0.0280 - val_mae: 0.1272 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0010 - mae: 0.0251 - val_loss: 0.0380 - val_mae: 0.1520 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 9.4356e-04 - mae: 0.0239 - val_loss: 0.0321 - val_mae: 0.1336 - learning_rate: 0.0010\n",
      "Epoch 13/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 8.8277e-04 - mae: 0.0229 - val_loss: 0.0279 - val_mae: 0.1227 - learning_rate: 0.0010\n",
      "Epoch 14/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 8.4391e-04 - mae: 0.0228 - val_loss: 0.0309 - val_mae: 0.1328 - learning_rate: 0.0010\n",
      "Epoch 15/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 6.1830e-04 - mae: 0.0189 - val_loss: 0.0225 - val_mae: 0.1109 - learning_rate: 0.0010\n",
      "Epoch 16/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 6.1050e-04 - mae: 0.0190 - val_loss: 0.0263 - val_mae: 0.1193 - learning_rate: 0.0010\n",
      "Epoch 17/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 5.2558e-04 - mae: 0.0172 - val_loss: 0.0227 - val_mae: 0.1110 - learning_rate: 0.0010\n",
      "Epoch 18/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 4.7719e-04 - mae: 0.0165 - val_loss: 0.0231 - val_mae: 0.1101 - learning_rate: 0.0010\n",
      "Epoch 19/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 4.6197e-04 - mae: 0.0162 - val_loss: 0.0231 - val_mae: 0.1114 - learning_rate: 0.0010\n",
      "Epoch 20/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 4.2461e-04 - mae: 0.0152 - val_loss: 0.0206 - val_mae: 0.1052 - learning_rate: 5.0000e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 3.8266e-04 - mae: 0.0142 - val_loss: 0.0218 - val_mae: 0.1071 - learning_rate: 5.0000e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.1744e-04 - mae: 0.0150 - val_loss: 0.0175 - val_mae: 0.0967 - learning_rate: 5.0000e-04\n",
      "Epoch 23/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.2544e-04 - mae: 0.0153 - val_loss: 0.0185 - val_mae: 0.0975 - learning_rate: 5.0000e-04\n",
      "Epoch 24/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 3.5539e-04 - mae: 0.0138 - val_loss: 0.0177 - val_mae: 0.0966 - learning_rate: 5.0000e-04\n",
      "Epoch 25/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 3.8812e-04 - mae: 0.0144 - val_loss: 0.0170 - val_mae: 0.0934 - learning_rate: 5.0000e-04\n",
      "Epoch 26/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 3.1901e-04 - mae: 0.0128 - val_loss: 0.0183 - val_mae: 0.0968 - learning_rate: 5.0000e-04\n",
      "Epoch 27/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 3.3755e-04 - mae: 0.0136 - val_loss: 0.0158 - val_mae: 0.0898 - learning_rate: 5.0000e-04\n",
      "Epoch 28/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 2.9954e-04 - mae: 0.0125 - val_loss: 0.0142 - val_mae: 0.0846 - learning_rate: 5.0000e-04\n",
      "Epoch 29/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 3.0862e-04 - mae: 0.0126 - val_loss: 0.0169 - val_mae: 0.0919 - learning_rate: 5.0000e-04\n",
      "Epoch 30/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 2.8409e-04 - mae: 0.0119 - val_loss: 0.0162 - val_mae: 0.0894 - learning_rate: 5.0000e-04\n",
      "Epoch 31/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 2.5483e-04 - mae: 0.0111 - val_loss: 0.0176 - val_mae: 0.0943 - learning_rate: 5.0000e-04\n",
      "Epoch 32/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 2.6185e-04 - mae: 0.0114 - val_loss: 0.0165 - val_mae: 0.0902 - learning_rate: 5.0000e-04\n",
      "Epoch 33/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 2.3235e-04 - mae: 0.0104 - val_loss: 0.0167 - val_mae: 0.0912 - learning_rate: 2.5000e-04\n",
      "Epoch 34/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 2.3740e-04 - mae: 0.0103 - val_loss: 0.0151 - val_mae: 0.0860 - learning_rate: 2.5000e-04\n",
      "Epoch 35/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 2.2393e-04 - mae: 0.0100 - val_loss: 0.0149 - val_mae: 0.0862 - learning_rate: 2.5000e-04\n",
      "Epoch 36/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 2.3703e-04 - mae: 0.0106 - val_loss: 0.0147 - val_mae: 0.0854 - learning_rate: 2.5000e-04\n",
      "\u001b[1m78/78\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step   \n",
      "âœ… Tumkur - tomato | MAE=367.19, RMSE=640.6, RÂ²=0.8111, MAPE=28.04%, Acc=71.96%\n",
      "\n",
      "ğŸš€ Processing: Tumkur | wheat\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.0863 - mae: 0.1453 - val_loss: 0.0179 - val_mae: 0.0436 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0052 - mae: 0.0573 - val_loss: 0.0161 - val_mae: 0.0391 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0042 - mae: 0.0514 - val_loss: 0.0150 - val_mae: 0.0365 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0040 - mae: 0.0503 - val_loss: 0.0155 - val_mae: 0.0456 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0030 - mae: 0.0438 - val_loss: 0.0136 - val_mae: 0.0373 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0022 - mae: 0.0368 - val_loss: 0.0134 - val_mae: 0.0361 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0017 - mae: 0.0329 - val_loss: 0.0131 - val_mae: 0.0321 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0012 - mae: 0.0281 - val_loss: 0.0123 - val_mae: 0.0414 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 9.6807e-04 - mae: 0.0245 - val_loss: 0.0124 - val_mae: 0.0290 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 7.9149e-04 - mae: 0.0221 - val_loss: 0.0111 - val_mae: 0.0316 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 6.8599e-04 - mae: 0.0206 - val_loss: 0.0107 - val_mae: 0.0348 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 6.0154e-04 - mae: 0.0191 - val_loss: 0.0106 - val_mae: 0.0307 - learning_rate: 0.0010\n",
      "Epoch 13/60\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 5.4662e-04 - mae: 0.0181 - val_loss: 0.0104 - val_mae: 0.0297 - learning_rate: 0.0010\n",
      "Epoch 14/60\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.5741e-04 - mae: 0.0166 - val_loss: 0.0101 - val_mae: 0.0263 - learning_rate: 0.0010\n",
      "Epoch 15/60\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 4.0700e-04 - mae: 0.0154 - val_loss: 0.0101 - val_mae: 0.0267 - learning_rate: 0.0010\n",
      "Epoch 16/60\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 3.5618e-04 - mae: 0.0145 - val_loss: 0.0092 - val_mae: 0.0350 - learning_rate: 0.0010\n",
      "Epoch 17/60\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 2.7892e-04 - mae: 0.0127 - val_loss: 0.0090 - val_mae: 0.0330 - learning_rate: 0.0010\n",
      "Epoch 18/60\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 3.0554e-04 - mae: 0.0134 - val_loss: 0.0093 - val_mae: 0.0252 - learning_rate: 0.0010\n",
      "Epoch 19/60\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 2.7714e-04 - mae: 0.0126 - val_loss: 0.0087 - val_mae: 0.0318 - learning_rate: 0.0010\n",
      "Epoch 20/60\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 2.2531e-04 - mae: 0.0113 - val_loss: 0.0089 - val_mae: 0.0239 - learning_rate: 0.0010\n",
      "Epoch 21/60\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.9027e-04 - mae: 0.0102 - val_loss: 0.0083 - val_mae: 0.0261 - learning_rate: 0.0010\n",
      "Epoch 22/60\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 2.1464e-04 - mae: 0.0107 - val_loss: 0.0082 - val_mae: 0.0285 - learning_rate: 0.0010\n",
      "Epoch 23/60\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 1.9022e-04 - mae: 0.0101 - val_loss: 0.0085 - val_mae: 0.0301 - learning_rate: 0.0010\n",
      "Epoch 24/60\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.7869e-04 - mae: 0.0097 - val_loss: 0.0090 - val_mae: 0.0261 - learning_rate: 0.0010\n",
      "Epoch 25/60\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 1.7239e-04 - mae: 0.0095 - val_loss: 0.0086 - val_mae: 0.0233 - learning_rate: 0.0010\n",
      "Epoch 26/60\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 1.6177e-04 - mae: 0.0090 - val_loss: 0.0087 - val_mae: 0.0231 - learning_rate: 0.0010\n",
      "Epoch 27/60\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.3033e-04 - mae: 0.0080 - val_loss: 0.0089 - val_mae: 0.0252 - learning_rate: 5.0000e-04\n",
      "Epoch 28/60\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 1.2252e-04 - mae: 0.0077 - val_loss: 0.0092 - val_mae: 0.0248 - learning_rate: 5.0000e-04\n",
      "Epoch 29/60\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 1.1964e-04 - mae: 0.0076 - val_loss: 0.0090 - val_mae: 0.0261 - learning_rate: 5.0000e-04\n",
      "Epoch 30/60\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1.3562e-04 - mae: 0.0081 - val_loss: 0.0085 - val_mae: 0.0285 - learning_rate: 5.0000e-04\n",
      "\u001b[1m76/76\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step   \n",
      "âœ… Tumkur - wheat | MAE=104.93, RMSE=402.23, RÂ²=0.7418, MAPE=3.8%, Acc=96.2%\n",
      "\n",
      "ğŸš€ Processing: Udupi | capsicum\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - loss: 0.0453 - mae: 0.1224 - val_loss: 0.0162 - val_mae: 0.0946 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0048 - mae: 0.0524 - val_loss: 0.0121 - val_mae: 0.0802 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0038 - mae: 0.0468 - val_loss: 0.0130 - val_mae: 0.0846 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0032 - mae: 0.0419 - val_loss: 0.0126 - val_mae: 0.0820 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0028 - mae: 0.0392 - val_loss: 0.0116 - val_mae: 0.0781 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0024 - mae: 0.0364 - val_loss: 0.0115 - val_mae: 0.0771 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0023 - mae: 0.0354 - val_loss: 0.0118 - val_mae: 0.0791 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0023 - mae: 0.0357 - val_loss: 0.0128 - val_mae: 0.0833 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0020 - mae: 0.0324 - val_loss: 0.0112 - val_mae: 0.0770 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0019 - mae: 0.0316 - val_loss: 0.0099 - val_mae: 0.0709 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0016 - mae: 0.0283 - val_loss: 0.0087 - val_mae: 0.0663 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0016 - mae: 0.0285 - val_loss: 0.0091 - val_mae: 0.0676 - learning_rate: 0.0010\n",
      "Epoch 13/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0276 - val_loss: 0.0091 - val_mae: 0.0679 - learning_rate: 0.0010\n",
      "Epoch 14/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0014 - mae: 0.0261 - val_loss: 0.0086 - val_mae: 0.0657 - learning_rate: 0.0010\n",
      "Epoch 15/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0015 - mae: 0.0275 - val_loss: 0.0079 - val_mae: 0.0637 - learning_rate: 0.0010\n",
      "Epoch 16/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mae: 0.0237 - val_loss: 0.0083 - val_mae: 0.0646 - learning_rate: 0.0010\n",
      "Epoch 17/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0011 - mae: 0.0225 - val_loss: 0.0076 - val_mae: 0.0632 - learning_rate: 0.0010\n",
      "Epoch 18/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0011 - mae: 0.0241 - val_loss: 0.0077 - val_mae: 0.0633 - learning_rate: 0.0010\n",
      "Epoch 19/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mae: 0.0236 - val_loss: 0.0077 - val_mae: 0.0635 - learning_rate: 0.0010\n",
      "Epoch 20/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0011 - mae: 0.0227 - val_loss: 0.0081 - val_mae: 0.0656 - learning_rate: 0.0010\n",
      "Epoch 21/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0011 - mae: 0.0231 - val_loss: 0.0077 - val_mae: 0.0639 - learning_rate: 0.0010\n",
      "Epoch 22/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 7.4006e-04 - mae: 0.0177 - val_loss: 0.0077 - val_mae: 0.0639 - learning_rate: 5.0000e-04\n",
      "Epoch 23/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 7.6233e-04 - mae: 0.0177 - val_loss: 0.0078 - val_mae: 0.0645 - learning_rate: 5.0000e-04\n",
      "Epoch 24/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 7.7601e-04 - mae: 0.0185 - val_loss: 0.0078 - val_mae: 0.0651 - learning_rate: 5.0000e-04\n",
      "Epoch 25/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 7.7379e-04 - mae: 0.0184 - val_loss: 0.0072 - val_mae: 0.0622 - learning_rate: 5.0000e-04\n",
      "Epoch 26/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 7.8753e-04 - mae: 0.0188 - val_loss: 0.0071 - val_mae: 0.0615 - learning_rate: 5.0000e-04\n",
      "Epoch 27/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 7.5803e-04 - mae: 0.0186 - val_loss: 0.0072 - val_mae: 0.0617 - learning_rate: 5.0000e-04\n",
      "Epoch 28/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 7.9483e-04 - mae: 0.0194 - val_loss: 0.0070 - val_mae: 0.0611 - learning_rate: 5.0000e-04\n",
      "Epoch 29/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 7.4961e-04 - mae: 0.0184 - val_loss: 0.0069 - val_mae: 0.0604 - learning_rate: 5.0000e-04\n",
      "Epoch 30/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 7.2729e-04 - mae: 0.0181 - val_loss: 0.0069 - val_mae: 0.0601 - learning_rate: 5.0000e-04\n",
      "Epoch 31/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 7.4553e-04 - mae: 0.0186 - val_loss: 0.0070 - val_mae: 0.0606 - learning_rate: 5.0000e-04\n",
      "Epoch 32/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 7.4851e-04 - mae: 0.0187 - val_loss: 0.0072 - val_mae: 0.0618 - learning_rate: 5.0000e-04\n",
      "Epoch 33/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 7.3635e-04 - mae: 0.0182 - val_loss: 0.0069 - val_mae: 0.0603 - learning_rate: 5.0000e-04\n",
      "Epoch 34/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 6.2528e-04 - mae: 0.0159 - val_loss: 0.0070 - val_mae: 0.0608 - learning_rate: 2.5000e-04\n",
      "Epoch 35/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 5.8630e-04 - mae: 0.0154 - val_loss: 0.0070 - val_mae: 0.0608 - learning_rate: 2.5000e-04\n",
      "Epoch 36/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 6.2916e-04 - mae: 0.0164 - val_loss: 0.0071 - val_mae: 0.0613 - learning_rate: 2.5000e-04\n",
      "Epoch 37/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6.1276e-04 - mae: 0.0160 - val_loss: 0.0067 - val_mae: 0.0586 - learning_rate: 2.5000e-04\n",
      "Epoch 38/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 5.9762e-04 - mae: 0.0156 - val_loss: 0.0067 - val_mae: 0.0594 - learning_rate: 2.5000e-04\n",
      "Epoch 39/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 6.0601e-04 - mae: 0.0158 - val_loss: 0.0067 - val_mae: 0.0587 - learning_rate: 2.5000e-04\n",
      "Epoch 40/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6.0078e-04 - mae: 0.0159 - val_loss: 0.0067 - val_mae: 0.0596 - learning_rate: 2.5000e-04\n",
      "Epoch 41/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 6.0437e-04 - mae: 0.0159 - val_loss: 0.0069 - val_mae: 0.0603 - learning_rate: 2.5000e-04\n",
      "Epoch 42/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 5.5145e-04 - mae: 0.0144 - val_loss: 0.0064 - val_mae: 0.0569 - learning_rate: 1.2500e-04\n",
      "Epoch 43/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 5.4408e-04 - mae: 0.0144 - val_loss: 0.0065 - val_mae: 0.0570 - learning_rate: 1.2500e-04\n",
      "Epoch 44/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 5.2653e-04 - mae: 0.0141 - val_loss: 0.0064 - val_mae: 0.0569 - learning_rate: 1.2500e-04\n",
      "Epoch 45/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 5.3182e-04 - mae: 0.0143 - val_loss: 0.0064 - val_mae: 0.0570 - learning_rate: 1.2500e-04\n",
      "Epoch 46/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 5.3039e-04 - mae: 0.0145 - val_loss: 0.0063 - val_mae: 0.0562 - learning_rate: 1.2500e-04\n",
      "Epoch 47/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 5.2135e-04 - mae: 0.0141 - val_loss: 0.0064 - val_mae: 0.0574 - learning_rate: 1.2500e-04\n",
      "Epoch 48/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 5.4707e-04 - mae: 0.0146 - val_loss: 0.0065 - val_mae: 0.0575 - learning_rate: 1.2500e-04\n",
      "Epoch 49/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 5.3993e-04 - mae: 0.0147 - val_loss: 0.0064 - val_mae: 0.0574 - learning_rate: 1.2500e-04\n",
      "Epoch 50/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 5.3985e-04 - mae: 0.0147 - val_loss: 0.0064 - val_mae: 0.0575 - learning_rate: 1.2500e-04\n",
      "Epoch 51/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 5.0258e-04 - mae: 0.0137 - val_loss: 0.0062 - val_mae: 0.0559 - learning_rate: 6.2500e-05\n",
      "Epoch 52/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 4.9314e-04 - mae: 0.0137 - val_loss: 0.0063 - val_mae: 0.0560 - learning_rate: 6.2500e-05\n",
      "Epoch 53/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 4.8881e-04 - mae: 0.0135 - val_loss: 0.0062 - val_mae: 0.0560 - learning_rate: 6.2500e-05\n",
      "Epoch 54/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 4.9523e-04 - mae: 0.0135 - val_loss: 0.0062 - val_mae: 0.0556 - learning_rate: 6.2500e-05\n",
      "Epoch 55/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 4.8859e-04 - mae: 0.0134 - val_loss: 0.0063 - val_mae: 0.0562 - learning_rate: 3.1250e-05\n",
      "Epoch 56/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 4.8685e-04 - mae: 0.0133 - val_loss: 0.0063 - val_mae: 0.0566 - learning_rate: 3.1250e-05\n",
      "Epoch 57/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.8979e-04 - mae: 0.0133 - val_loss: 0.0063 - val_mae: 0.0565 - learning_rate: 3.1250e-05\n",
      "Epoch 58/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 4.9012e-04 - mae: 0.0134 - val_loss: 0.0063 - val_mae: 0.0564 - learning_rate: 3.1250e-05\n",
      "Epoch 59/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 4.6833e-04 - mae: 0.0130 - val_loss: 0.0063 - val_mae: 0.0564 - learning_rate: 1.5625e-05\n",
      "Epoch 60/60\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.6238e-04 - mae: 0.0127 - val_loss: 0.0063 - val_mae: 0.0565 - learning_rate: 1.5625e-05\n",
      "\u001b[1m78/78\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step   \n",
      "âœ… Udupi - capsicum | MAE=177.74, RMSE=350.31, RÂ²=0.9451, MAPE=4.6%, Acc=95.4%\n",
      "\n",
      "ğŸš€ Processing: Udupi | onion\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 0.0770 - mae: 0.1408 - val_loss: 0.0060 - val_mae: 0.0573 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0061 - mae: 0.0570 - val_loss: 0.0058 - val_mae: 0.0538 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0045 - mae: 0.0493 - val_loss: 0.0054 - val_mae: 0.0454 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0033 - mae: 0.0427 - val_loss: 0.0050 - val_mae: 0.0464 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0028 - mae: 0.0394 - val_loss: 0.0051 - val_mae: 0.0470 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0023 - mae: 0.0358 - val_loss: 0.0061 - val_mae: 0.0585 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0019 - mae: 0.0327 - val_loss: 0.0044 - val_mae: 0.0371 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0318 - val_loss: 0.0046 - val_mae: 0.0433 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0016 - mae: 0.0300 - val_loss: 0.0043 - val_mae: 0.0408 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0014 - mae: 0.0275 - val_loss: 0.0041 - val_mae: 0.0374 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0013 - mae: 0.0263 - val_loss: 0.0038 - val_mae: 0.0373 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0013 - mae: 0.0265 - val_loss: 0.0035 - val_mae: 0.0355 - learning_rate: 0.0010\n",
      "Epoch 13/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mae: 0.0251 - val_loss: 0.0040 - val_mae: 0.0351 - learning_rate: 0.0010\n",
      "Epoch 14/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0013 - mae: 0.0261 - val_loss: 0.0037 - val_mae: 0.0338 - learning_rate: 0.0010\n",
      "Epoch 15/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0011 - mae: 0.0238 - val_loss: 0.0036 - val_mae: 0.0358 - learning_rate: 0.0010\n",
      "Epoch 16/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.8841e-04 - mae: 0.0222 - val_loss: 0.0033 - val_mae: 0.0334 - learning_rate: 0.0010\n",
      "Epoch 17/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0010 - mae: 0.0235 - val_loss: 0.0033 - val_mae: 0.0325 - learning_rate: 0.0010\n",
      "Epoch 18/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.6928e-04 - mae: 0.0210 - val_loss: 0.0033 - val_mae: 0.0321 - learning_rate: 0.0010\n",
      "Epoch 19/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 8.9470e-04 - mae: 0.0215 - val_loss: 0.0032 - val_mae: 0.0311 - learning_rate: 0.0010\n",
      "Epoch 20/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 8.4416e-04 - mae: 0.0206 - val_loss: 0.0034 - val_mae: 0.0347 - learning_rate: 0.0010\n",
      "Epoch 21/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 8.7212e-04 - mae: 0.0209 - val_loss: 0.0036 - val_mae: 0.0357 - learning_rate: 0.0010\n",
      "Epoch 22/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.4048e-04 - mae: 0.0206 - val_loss: 0.0032 - val_mae: 0.0317 - learning_rate: 0.0010\n",
      "Epoch 23/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 7.4354e-04 - mae: 0.0194 - val_loss: 0.0036 - val_mae: 0.0372 - learning_rate: 0.0010\n",
      "Epoch 24/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6.2137e-04 - mae: 0.0170 - val_loss: 0.0033 - val_mae: 0.0322 - learning_rate: 5.0000e-04\n",
      "Epoch 25/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 6.1202e-04 - mae: 0.0168 - val_loss: 0.0033 - val_mae: 0.0332 - learning_rate: 5.0000e-04\n",
      "Epoch 26/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 6.2912e-04 - mae: 0.0173 - val_loss: 0.0031 - val_mae: 0.0307 - learning_rate: 5.0000e-04\n",
      "Epoch 27/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 6.2192e-04 - mae: 0.0172 - val_loss: 0.0030 - val_mae: 0.0301 - learning_rate: 5.0000e-04\n",
      "Epoch 28/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6.7608e-04 - mae: 0.0184 - val_loss: 0.0029 - val_mae: 0.0309 - learning_rate: 5.0000e-04\n",
      "Epoch 29/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 5.5866e-04 - mae: 0.0162 - val_loss: 0.0028 - val_mae: 0.0317 - learning_rate: 5.0000e-04\n",
      "Epoch 30/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 5.9642e-04 - mae: 0.0169 - val_loss: 0.0031 - val_mae: 0.0338 - learning_rate: 5.0000e-04\n",
      "Epoch 31/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 6.2498e-04 - mae: 0.0177 - val_loss: 0.0029 - val_mae: 0.0295 - learning_rate: 5.0000e-04\n",
      "Epoch 32/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 5.7291e-04 - mae: 0.0169 - val_loss: 0.0029 - val_mae: 0.0316 - learning_rate: 5.0000e-04\n",
      "Epoch 33/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4.8911e-04 - mae: 0.0149 - val_loss: 0.0028 - val_mae: 0.0309 - learning_rate: 2.5000e-04\n",
      "Epoch 34/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5.0255e-04 - mae: 0.0150 - val_loss: 0.0028 - val_mae: 0.0321 - learning_rate: 2.5000e-04\n",
      "Epoch 35/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.6015e-04 - mae: 0.0144 - val_loss: 0.0027 - val_mae: 0.0316 - learning_rate: 2.5000e-04\n",
      "Epoch 36/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.9799e-04 - mae: 0.0152 - val_loss: 0.0026 - val_mae: 0.0294 - learning_rate: 2.5000e-04\n",
      "Epoch 37/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 4.6575e-04 - mae: 0.0145 - val_loss: 0.0027 - val_mae: 0.0304 - learning_rate: 2.5000e-04\n",
      "Epoch 38/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 4.7937e-04 - mae: 0.0147 - val_loss: 0.0028 - val_mae: 0.0325 - learning_rate: 2.5000e-04\n",
      "Epoch 39/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.8035e-04 - mae: 0.0149 - val_loss: 0.0026 - val_mae: 0.0304 - learning_rate: 2.5000e-04\n",
      "Epoch 40/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 4.5305e-04 - mae: 0.0144 - val_loss: 0.0027 - val_mae: 0.0316 - learning_rate: 2.5000e-04\n",
      "Epoch 41/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.4662e-04 - mae: 0.0140 - val_loss: 0.0025 - val_mae: 0.0307 - learning_rate: 1.2500e-04\n",
      "Epoch 42/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4.4269e-04 - mae: 0.0141 - val_loss: 0.0027 - val_mae: 0.0309 - learning_rate: 1.2500e-04\n",
      "Epoch 43/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4.2264e-04 - mae: 0.0138 - val_loss: 0.0025 - val_mae: 0.0297 - learning_rate: 1.2500e-04\n",
      "Epoch 44/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 4.3528e-04 - mae: 0.0139 - val_loss: 0.0026 - val_mae: 0.0319 - learning_rate: 1.2500e-04\n",
      "Epoch 45/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 4.4276e-04 - mae: 0.0142 - val_loss: 0.0024 - val_mae: 0.0295 - learning_rate: 1.2500e-04\n",
      "Epoch 46/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.2979e-04 - mae: 0.0140 - val_loss: 0.0025 - val_mae: 0.0313 - learning_rate: 1.2500e-04\n",
      "Epoch 47/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 4.3242e-04 - mae: 0.0141 - val_loss: 0.0026 - val_mae: 0.0322 - learning_rate: 1.2500e-04\n",
      "Epoch 48/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 4.3943e-04 - mae: 0.0142 - val_loss: 0.0028 - val_mae: 0.0357 - learning_rate: 1.2500e-04\n",
      "Epoch 49/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 4.1419e-04 - mae: 0.0136 - val_loss: 0.0026 - val_mae: 0.0326 - learning_rate: 1.2500e-04\n",
      "Epoch 50/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 3.8011e-04 - mae: 0.0128 - val_loss: 0.0024 - val_mae: 0.0287 - learning_rate: 6.2500e-05\n",
      "Epoch 51/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 3.8447e-04 - mae: 0.0129 - val_loss: 0.0025 - val_mae: 0.0293 - learning_rate: 6.2500e-05\n",
      "Epoch 52/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 3.7958e-04 - mae: 0.0128 - val_loss: 0.0024 - val_mae: 0.0285 - learning_rate: 6.2500e-05\n",
      "Epoch 53/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 3.8090e-04 - mae: 0.0128 - val_loss: 0.0024 - val_mae: 0.0288 - learning_rate: 6.2500e-05\n",
      "Epoch 54/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 3.6688e-04 - mae: 0.0123 - val_loss: 0.0024 - val_mae: 0.0294 - learning_rate: 3.1250e-05\n",
      "Epoch 55/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 3.6049e-04 - mae: 0.0124 - val_loss: 0.0024 - val_mae: 0.0290 - learning_rate: 3.1250e-05\n",
      "Epoch 56/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 3.6190e-04 - mae: 0.0124 - val_loss: 0.0024 - val_mae: 0.0294 - learning_rate: 3.1250e-05\n",
      "Epoch 57/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 3.6121e-04 - mae: 0.0123 - val_loss: 0.0024 - val_mae: 0.0299 - learning_rate: 3.1250e-05\n",
      "Epoch 58/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 3.4472e-04 - mae: 0.0120 - val_loss: 0.0024 - val_mae: 0.0284 - learning_rate: 1.5625e-05\n",
      "Epoch 59/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 3.5273e-04 - mae: 0.0121 - val_loss: 0.0024 - val_mae: 0.0283 - learning_rate: 1.5625e-05\n",
      "Epoch 60/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 3.5392e-04 - mae: 0.0121 - val_loss: 0.0024 - val_mae: 0.0281 - learning_rate: 1.5625e-05\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step   \n",
      "âœ… Udupi - onion | MAE=137.02, RMSE=260.99, RÂ²=0.9597, MAPE=6.36%, Acc=93.64%\n",
      "\n",
      "ğŸš€ Processing: Udupi | tomato\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - loss: 0.0674 - mae: 0.1338 - val_loss: 0.0214 - val_mae: 0.0859 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0050 - mae: 0.0539 - val_loss: 0.0143 - val_mae: 0.0682 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0040 - mae: 0.0478 - val_loss: 0.0117 - val_mae: 0.0664 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0031 - mae: 0.0419 - val_loss: 0.0100 - val_mae: 0.0598 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0026 - mae: 0.0380 - val_loss: 0.0114 - val_mae: 0.0659 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0022 - mae: 0.0345 - val_loss: 0.0098 - val_mae: 0.0596 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0019 - mae: 0.0314 - val_loss: 0.0101 - val_mae: 0.0639 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0307 - val_loss: 0.0115 - val_mae: 0.0714 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0017 - mae: 0.0291 - val_loss: 0.0089 - val_mae: 0.0578 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0016 - mae: 0.0292 - val_loss: 0.0094 - val_mae: 0.0629 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0015 - mae: 0.0278 - val_loss: 0.0079 - val_mae: 0.0538 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0014 - mae: 0.0261 - val_loss: 0.0089 - val_mae: 0.0620 - learning_rate: 0.0010\n",
      "Epoch 13/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0013 - mae: 0.0256 - val_loss: 0.0079 - val_mae: 0.0543 - learning_rate: 0.0010\n",
      "Epoch 14/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0013 - mae: 0.0256 - val_loss: 0.0082 - val_mae: 0.0571 - learning_rate: 0.0010\n",
      "Epoch 15/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0247 - val_loss: 0.0078 - val_mae: 0.0564 - learning_rate: 0.0010\n",
      "Epoch 16/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0012 - mae: 0.0242 - val_loss: 0.0074 - val_mae: 0.0530 - learning_rate: 0.0010\n",
      "Epoch 17/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0012 - mae: 0.0240 - val_loss: 0.0077 - val_mae: 0.0554 - learning_rate: 0.0010\n",
      "Epoch 18/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0011 - mae: 0.0226 - val_loss: 0.0073 - val_mae: 0.0539 - learning_rate: 0.0010\n",
      "Epoch 19/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0011 - mae: 0.0233 - val_loss: 0.0075 - val_mae: 0.0546 - learning_rate: 0.0010\n",
      "Epoch 20/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0010 - mae: 0.0223 - val_loss: 0.0077 - val_mae: 0.0548 - learning_rate: 0.0010\n",
      "Epoch 21/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.8352e-04 - mae: 0.0218 - val_loss: 0.0073 - val_mae: 0.0545 - learning_rate: 0.0010\n",
      "Epoch 22/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 9.6580e-04 - mae: 0.0216 - val_loss: 0.0076 - val_mae: 0.0549 - learning_rate: 0.0010\n",
      "Epoch 23/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 8.3597e-04 - mae: 0.0197 - val_loss: 0.0064 - val_mae: 0.0500 - learning_rate: 5.0000e-04\n",
      "Epoch 24/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 7.8557e-04 - mae: 0.0190 - val_loss: 0.0065 - val_mae: 0.0517 - learning_rate: 5.0000e-04\n",
      "Epoch 25/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 7.5657e-04 - mae: 0.0183 - val_loss: 0.0065 - val_mae: 0.0491 - learning_rate: 5.0000e-04\n",
      "Epoch 26/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 7.6228e-04 - mae: 0.0186 - val_loss: 0.0065 - val_mae: 0.0487 - learning_rate: 5.0000e-04\n",
      "Epoch 27/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 8.0395e-04 - mae: 0.0194 - val_loss: 0.0065 - val_mae: 0.0485 - learning_rate: 5.0000e-04\n",
      "Epoch 28/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 7.1552e-04 - mae: 0.0180 - val_loss: 0.0065 - val_mae: 0.0493 - learning_rate: 2.5000e-04\n",
      "Epoch 29/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 6.7489e-04 - mae: 0.0174 - val_loss: 0.0067 - val_mae: 0.0495 - learning_rate: 2.5000e-04\n",
      "Epoch 30/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 6.9161e-04 - mae: 0.0176 - val_loss: 0.0067 - val_mae: 0.0492 - learning_rate: 2.5000e-04\n",
      "Epoch 31/60\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 6.6008e-04 - mae: 0.0172 - val_loss: 0.0067 - val_mae: 0.0486 - learning_rate: 2.5000e-04\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step   \n",
      "âœ… Udupi - tomato | MAE=234.43, RMSE=415.59, RÂ²=0.8992, MAPE=12.28%, Acc=87.72%\n",
      "\n",
      "ğŸš€ Processing: Udupi | wheat\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - loss: 0.2665 - mae: 0.3708 - val_loss: 0.0040 - val_mae: 0.0519 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0343 - mae: 0.1503 - val_loss: 0.0430 - val_mae: 0.2029 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0225 - mae: 0.1233 - val_loss: 0.0529 - val_mae: 0.2265 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0170 - mae: 0.1059 - val_loss: 0.0395 - val_mae: 0.1955 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0138 - mae: 0.0956 - val_loss: 0.0286 - val_mae: 0.1664 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0127 - mae: 0.0921 - val_loss: 0.0475 - val_mae: 0.2160 - learning_rate: 5.0000e-04\n",
      "Epoch 7/60\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0111 - mae: 0.0842 - val_loss: 0.0403 - val_mae: 0.1990 - learning_rate: 5.0000e-04\n",
      "Epoch 8/60\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0101 - mae: 0.0806 - val_loss: 0.0508 - val_mae: 0.2240 - learning_rate: 5.0000e-04\n",
      "Epoch 9/60\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0089 - mae: 0.0756 - val_loss: 0.0381 - val_mae: 0.1938 - learning_rate: 5.0000e-04\n",
      "\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step \n",
      "âœ… Udupi - wheat | MAE=114.62, RMSE=151.64, RÂ²=0.4268, MAPE=6.6%, Acc=93.4%\n",
      "\n",
      "ğŸ“Š All combinations processed. Metrics saved to: tat_mha_state_output\\tat_mha_metrics.csv\n",
      "         District        Crop     MAE    RMSE    R2  MAPE(%)  Accuracy(%)\n",
      "0   All Districts  full_state   48.85   64.51  0.99     2.57        97.43\n",
      "1        Bagalkot       onion   85.96  142.76  0.96     7.47        92.53\n",
      "2        Bagalkot       wheat   50.18   90.65  0.97     2.39        97.61\n",
      "3       Bangalore    capsicum  221.93  308.94  0.91     8.38        91.62\n",
      "4       Bangalore       onion   98.50  192.54  0.95     5.06        94.94\n",
      "..            ...         ...     ...     ...   ...      ...          ...\n",
      "85         Tumkur       wheat  104.93  402.23  0.74     3.80        96.20\n",
      "86          Udupi    capsicum  177.74  350.31  0.95     4.60        95.40\n",
      "87          Udupi       onion  137.02  260.99  0.96     6.36        93.64\n",
      "88          Udupi      tomato  234.43  415.59  0.90    12.28        87.72\n",
      "89          Udupi       wheat  114.62  151.64  0.43     6.60        93.40\n",
      "\n",
      "[90 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os, gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks, optimizers\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "# -----------------------------\n",
    "# Config\n",
    "# -----------------------------\n",
    "input_file = \"dataset/Crop_price_forecast_Daily.xlsx\"   # path to all-in-one excel\n",
    "output_folder = \"tat_mha_state_output\"\n",
    "output_models = os.path.join(output_folder, \"models\")\n",
    "output_csv = os.path.join(output_folder, \"predictions\")\n",
    "output_graphs = os.path.join(output_folder, \"graphs\")\n",
    "output_logs = os.path.join(output_folder, \"logs\")\n",
    "metrics_file = os.path.join(output_folder, \"tat_mha_metrics.csv\")\n",
    "look_back = 30\n",
    "epochs = 60\n",
    "batch_size = 32\n",
    "future_steps = 30\n",
    "d_model = 64\n",
    "num_heads = 4\n",
    "ff_dim = 128\n",
    "dropout_rate = 0.15\n",
    "random_seed = 42\n",
    "np.random.seed(random_seed)\n",
    "tf.random.set_seed(random_seed)\n",
    "\n",
    "# Create folders\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "os.makedirs(output_models, exist_ok=True)\n",
    "os.makedirs(output_csv, exist_ok=True)\n",
    "os.makedirs(output_graphs, exist_ok=True)\n",
    "os.makedirs(output_logs, exist_ok=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Helpers\n",
    "# -----------------------------\n",
    "def parse_dates_safe(series):\n",
    "    try:\n",
    "        return pd.to_datetime(series, dayfirst=True)\n",
    "    except:\n",
    "        return pd.to_datetime(series, dayfirst=False)\n",
    "\n",
    "def mape(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    mask = y_true != 0\n",
    "    return np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100 if np.any(mask) else np.nan\n",
    "\n",
    "def create_multifeature_dataset(features, target, look_back):\n",
    "    # features: (N, F), target: (N,)\n",
    "    X, y = [], []\n",
    "    for i in range(len(features) - look_back):\n",
    "        X.append(features[i:i+look_back, :])\n",
    "        y.append(target[i+look_back])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# -----------------------------\n",
    "# TAT + MHA model builder\n",
    "# -----------------------------\n",
    "def build_tat_mha(input_shape, d_model=64, num_heads=4, ff_dim=128, dropout_rate=0.15):\n",
    "    # input_shape = (look_back, num_features)\n",
    "    seq_len, num_features = input_shape\n",
    "\n",
    "    inputs = layers.Input(shape=(seq_len, num_features), name=\"inputs\")  # (B, T, F)\n",
    "    # project features to d_model so attn & residuals align\n",
    "    proj = layers.Dense(d_model, name=\"proj\")(inputs)                     # (B, T, d_model)\n",
    "\n",
    "    # MultiHeadAttention expects (query, value)\n",
    "    attn = layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model//num_heads,\n",
    "                                     name=\"mha\")(proj, proj)\n",
    "    attn = layers.Dropout(dropout_rate)(attn)\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(attn + proj)              # residual 1\n",
    "\n",
    "    # Feed-forward\n",
    "    ff = layers.Dense(ff_dim, activation=\"relu\")(x)\n",
    "    ff = layers.Dense(d_model)(ff)\n",
    "    ff = layers.Dropout(dropout_rate)(ff)\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(ff + x)                  # residual 2\n",
    "\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    outputs = layers.Dense(1, name=\"output\")(x)\n",
    "\n",
    "    model = models.Model(inputs=inputs, outputs=outputs, name=\"TAT_MHA\")\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=1e-3), loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# -----------------------------\n",
    "# Load dataset\n",
    "# -----------------------------\n",
    "print(\"ğŸ“˜ Loading dataset:\", input_file)\n",
    "df = pd.read_excel(input_file)\n",
    "df.columns = [c.strip().lower() for c in df.columns]\n",
    "required_cols = ['date','district','crop_type','average']\n",
    "if not all(c in df.columns for c in required_cols):\n",
    "    raise ValueError(f\"Missing required columns. Required: {required_cols}\")\n",
    "\n",
    "df['date'] = parse_dates_safe(df['date'])\n",
    "df = df.sort_values('date')\n",
    "df = df.dropna(subset=['average'])  # remove entirely missing rows\n",
    "\n",
    "# -----------------------------\n",
    "# Prepare global crop-level series for fallback\n",
    "# -----------------------------\n",
    "# We'll create a crop-level series (mean across districts) aggregated by date\n",
    "crop_level_df = df.groupby(['crop_type','date'], as_index=False)['average'].mean()\n",
    "\n",
    "# -----------------------------\n",
    "# Groups to process\n",
    "# -----------------------------\n",
    "groups = df.groupby(['district','crop_type'])\n",
    "\n",
    "metrics_list = []\n",
    "\n",
    "# -----------------------------\n",
    "# Loop groups\n",
    "# -----------------------------\n",
    "for (district, crop), group in groups:\n",
    "    print(f\"\\nğŸš€ Processing: {district} | {crop}\")\n",
    "    # copy and aggregate duplicate dates by mean\n",
    "    data = group.copy().sort_values('date')\n",
    "    data = data.groupby('date', as_index=False).mean(numeric_only=True)   # keep numeric cols mean\n",
    "    data.set_index('date', inplace=True)\n",
    "    data = data.asfreq('D')\n",
    "\n",
    "    # fill with forward/back + mean\n",
    "    data['average'] = data['average'].ffill().bfill().fillna(data['average'].mean())\n",
    "\n",
    "    # if too few points (< look_back+1), replace with crop-level time series (or global mean)\n",
    "    if data['average'].count() < (look_back + 1):\n",
    "        print(f\"âš ï¸ Not enough data for {district}-{crop} (len={data['average'].count()}). Attempting crop-level fallback.\")\n",
    "        crop_ts = crop_level_df[crop_level_df['crop_type'] == crop].copy()\n",
    "        if crop_ts.empty:\n",
    "            # fallback to global average series across all crops\n",
    "            print(\"   â†’ No crop-level series found. Using global mean series instead.\")\n",
    "            global_ts = df.groupby('date', as_index=False)['average'].mean()\n",
    "            crop_ts = global_ts.rename(columns={'average':'average'})\n",
    "        crop_ts.set_index('date', inplace=True)\n",
    "        crop_ts = crop_ts.asfreq('D')\n",
    "        crop_ts['average'] = crop_ts['average'].ffill().bfill().fillna(crop_ts['average'].mean())\n",
    "        data = crop_ts.copy()\n",
    "\n",
    "    # Feature engineering\n",
    "    data['Lag_1'] = data['average'].shift(1)\n",
    "    data['Lag_7'] = data['average'].shift(7)\n",
    "    data['MA_7'] = data['average'].rolling(window=7).mean()\n",
    "    data['MA_30'] = data['average'].rolling(window=30).mean()\n",
    "    # backfill then forward fill to ensure no NaNs\n",
    "    data[['Lag_1','Lag_7','MA_7','MA_30']] = data[['Lag_1','Lag_7','MA_7','MA_30']].bfill().ffill()\n",
    "\n",
    "    # Prepare features matrix and target\n",
    "    # Features order: ['average', 'Lag_1', 'Lag_7', 'MA_7', 'MA_30']  (average included so model sees target history)\n",
    "    feature_cols = ['average','Lag_1','Lag_7','MA_7','MA_30']\n",
    "    features_raw = data[feature_cols].values.astype('float32')   # shape (N, F)\n",
    "    target_raw = data['average'].values.astype('float32')        # shape (N,)\n",
    "\n",
    "    # Fit scalers (scale features & target separately)\n",
    "    scaler_X = MinMaxScaler()\n",
    "    scaler_y = MinMaxScaler()\n",
    "    # Fit scaler_X on entire features_raw\n",
    "    scaler_X.fit(features_raw)\n",
    "    scaler_y.fit(target_raw.reshape(-1,1))\n",
    "\n",
    "    features_scaled = scaler_X.transform(features_raw)   # (N,F)\n",
    "    target_scaled = scaler_y.transform(target_raw.reshape(-1,1)).flatten()\n",
    "\n",
    "    # Create supervised sequences\n",
    "    X, y = create_multifeature_dataset(features_scaled, target_scaled, look_back)\n",
    "    if len(X) == 0:\n",
    "        print(f\"âš ï¸ After sequence creation, no training samples for {district}-{crop}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Train/val split (80/20)\n",
    "    n = len(X)\n",
    "    split = int(n * 0.8)\n",
    "    X_train, y_train = X[:split], y[:split]\n",
    "    X_val, y_val = X[split:], y[split:]\n",
    "\n",
    "    # Build model (input_shape = (look_back, num_features))\n",
    "    input_shape = (look_back, features_scaled.shape[1])\n",
    "    model = build_tat_mha(input_shape, d_model=d_model, num_heads=num_heads, ff_dim=ff_dim, dropout_rate=dropout_rate)\n",
    "    model.summary(print_fn=lambda s: None)  # suppress long summary\n",
    "\n",
    "    # Callbacks\n",
    "    es = callbacks.EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True, verbose=0)\n",
    "    rl = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4, min_lr=1e-6, verbose=0)\n",
    "    log_path = os.path.join(output_logs, f\"{district}_{crop}_tat_mha_training.log\")\n",
    "\n",
    "    # Train\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        callbacks=[es, rl],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Save training log\n",
    "    with open(log_path, \"w\") as f:\n",
    "        f.write(\"Loss,Val_Loss\\n\")\n",
    "        for i in range(len(history.history['loss'])):\n",
    "            f.write(f\"{history.history['loss'][i]},{history.history['val_loss'][i] if 'val_loss' in history.history else ''}\\n\")\n",
    "\n",
    "    # Predict on all sequences (to align with original timeseries)\n",
    "    preds_scaled = model.predict(X, batch_size=64).flatten()\n",
    "    preds = scaler_y.inverse_transform(preds_scaled.reshape(-1,1)).flatten()  # real scale\n",
    "\n",
    "    # Align predictions with dataframe: first look_back entries are NaN\n",
    "    preds_full = np.concatenate([np.full(look_back, np.nan), preds])   # length = N\n",
    "    data_out = data.copy().reset_index()\n",
    "    data_out['Predicted'] = np.round(preds_full, 2)\n",
    "\n",
    "    # Metrics (only where both actual & predicted exist)\n",
    "    mask = ~np.isnan(data_out['Predicted'])\n",
    "    if mask.sum() == 0:\n",
    "        print(f\"âš ï¸ No overlapping points for metrics for {district}-{crop}. Skipping metrics.\")\n",
    "        continue\n",
    "    y_true = data_out.loc[mask, 'average'].values\n",
    "    y_pred = data_out.loc[mask, 'Predicted'].values\n",
    "\n",
    "    mae = round(mean_absolute_error(y_true, y_pred), 2)\n",
    "    rmse = round(np.sqrt(mean_squared_error(y_true, y_pred)), 2)\n",
    "    r2 = round(r2_score(y_true, y_pred), 4)\n",
    "    mape_v = round(mape(y_true, y_pred), 2)\n",
    "    accuracy = round(100 - mape_v, 2)\n",
    "\n",
    "    metrics_list.append({\n",
    "        'District': district,\n",
    "        'Crop': crop,\n",
    "        'MAE': mae,\n",
    "        'RMSE': rmse,\n",
    "        'R2': r2,\n",
    "        'MAPE(%)': mape_v,\n",
    "        'Accuracy(%)': accuracy\n",
    "    })\n",
    "\n",
    "    print(f\"âœ… {district} - {crop} | MAE={mae}, RMSE={rmse}, RÂ²={r2}, MAPE={mape_v}%, Acc={accuracy}%\")\n",
    "\n",
    "    # Save model\n",
    "    model_path = os.path.join(output_models, f\"{district}_{crop}_tat_mha.keras\")\n",
    "    model.save(model_path, include_optimizer=False)\n",
    "\n",
    "    # Save historical predictions CSV\n",
    "    out_csv = os.path.join(output_csv, f\"{district}_{crop}_tat_mha_daily.csv\")\n",
    "    data_out[['date','average','Predicted']].to_csv(out_csv, index=False, float_format=\"%.2f\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # Recursive future forecast (30 days)\n",
    "    # -----------------------------\n",
    "    # We'll use last look_back raw features (unscaled) and iteratively generate future features\n",
    "    # Start from last raw feature rows:\n",
    "    raw_features = features_raw.copy()   # (N, F) unscaled features\n",
    "    last_window_raw = raw_features[-look_back:].copy()   # (look_back, F)\n",
    "    future_preds = []\n",
    "    for step in range(future_steps):\n",
    "        # Scale the window using scaler_X\n",
    "        window_scaled = scaler_X.transform(last_window_raw)  # (look_back, F)\n",
    "        # model expects batch dimension\n",
    "        window_scaled = window_scaled[np.newaxis, ...]       # (1, look_back, F)\n",
    "        pred_scaled = model.predict(window_scaled, verbose=0).flatten()[0]\n",
    "        pred_unscaled = float(scaler_y.inverse_transform(np.array([[pred_scaled]]))[0,0])\n",
    "        # append\n",
    "        future_preds.append(round(pred_unscaled,2))\n",
    "\n",
    "        # construct next raw feature row:\n",
    "        # new_average = pred_unscaled\n",
    "        prev_avgs = np.concatenate([last_window_raw[:,0], np.array([pred_unscaled])])  # previous + new\n",
    "        # Lag_1 is last element before new (i.e., last_window_raw[-1,0])\n",
    "        lag1 = float(last_window_raw[-1,0]) if last_window_raw.shape[0] >= 1 else pred_unscaled\n",
    "        # Lag_7: take 7-th back from prev_avgs (if exists)\n",
    "        lag7 = float(prev_avgs[-8]) if len(prev_avgs) >= 8 else float(prev_avgs.mean())\n",
    "        ma7 = float(prev_avgs[-7:].mean()) if len(prev_avgs) >= 7 else float(prev_avgs.mean())\n",
    "        # for MA30 similar\n",
    "        ma30 = float(prev_avgs[-30:].mean()) if len(prev_avgs) >= 30 else float(prev_avgs.mean())\n",
    "\n",
    "        new_row = np.array([pred_unscaled, lag1, lag7, ma7, ma30], dtype='float32')\n",
    "        # append and drop oldest\n",
    "        last_window_raw = np.vstack([last_window_raw[1:], new_row])\n",
    "\n",
    "    # Save future forecast CSV\n",
    "    future_dates = pd.date_range(start=data_out['date'].iat[-1] + pd.Timedelta(days=1), periods=future_steps, freq='D')\n",
    "    future_df = pd.DataFrame({'date': future_dates, 'Forecast': future_preds})\n",
    "    future_df['District'] = district\n",
    "    future_df['Crop'] = crop\n",
    "    future_df.to_csv(os.path.join(output_csv, f\"{district}_{crop}_tat_mha_future.csv\"), index=False, float_format=\"%.2f\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # Plot historical + pred + future\n",
    "    # -----------------------------\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.plot(data_out['date'], data_out['average'], label='Actual', color='blue')\n",
    "    plt.plot(data_out['date'], data_out['Predicted'], label='Predicted (TAT-MHA)', color='red', linestyle='dashed')\n",
    "    plt.plot(future_df['date'], future_df['Forecast'], label=f'Future {future_steps}d', color='green', linestyle='dotted')\n",
    "    plt.title(f\"TAT-MHA Forecast - {district} | {crop}\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Average Price\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_graphs, f\"{district}_{crop}_tat_mha_graph.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    # cleanup\n",
    "    del model, X, y, X_train, X_val, preds_scaled, preds, data_out, future_df, last_window_raw\n",
    "    gc.collect()\n",
    "\n",
    "# Save metrics\n",
    "metrics_df = pd.DataFrame(metrics_list)\n",
    "metrics_df = metrics_df.round(2)\n",
    "metrics_df.to_csv(metrics_file, index=False)\n",
    "print(\"\\nğŸ“Š All combinations processed. Metrics saved to:\", metrics_file)\n",
    "print(metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8648d68b-e08a-4625-bbc4-feace3025bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TAT+MQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3577c85-7622-4555-b892-25760538c891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Loading dataset: dataset/Crop_price_forecast_Daily.xlsx\n",
      "\n",
      "ğŸš€ Processing: All Districts | full_state\n",
      "Epoch 1/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 25ms/step - loss: 0.0490 - mae: 0.1339 - val_loss: 0.0338 - val_mae: 0.1510 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0059 - mae: 0.0594 - val_loss: 0.0206 - val_mae: 0.1232 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0037 - mae: 0.0478 - val_loss: 0.0078 - val_mae: 0.0707 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0028 - mae: 0.0412 - val_loss: 0.0041 - val_mae: 0.0468 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0023 - mae: 0.0381 - val_loss: 0.0058 - val_mae: 0.0615 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0017 - mae: 0.0328 - val_loss: 0.0065 - val_mae: 0.0678 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0016 - mae: 0.0314 - val_loss: 0.0035 - val_mae: 0.0465 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 0.0013 - mae: 0.0284 - val_loss: 0.0033 - val_mae: 0.0454 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0013 - mae: 0.0280 - val_loss: 0.0033 - val_mae: 0.0462 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0011 - mae: 0.0259 - val_loss: 0.0017 - val_mae: 0.0319 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0010 - mae: 0.0252 - val_loss: 0.0018 - val_mae: 0.0334 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 9.7320e-04 - mae: 0.0245 - val_loss: 0.0040 - val_mae: 0.0535 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 9.3273e-04 - mae: 0.0238 - val_loss: 0.0029 - val_mae: 0.0441 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 6.9622e-04 - mae: 0.0206 - val_loss: 0.0014 - val_mae: 0.0296 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 6.3074e-04 - mae: 0.0194 - val_loss: 0.0016 - val_mae: 0.0307 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 6.3475e-04 - mae: 0.0196 - val_loss: 0.0014 - val_mae: 0.0285 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 5.9051e-04 - mae: 0.0189 - val_loss: 0.0013 - val_mae: 0.0282 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 5.5681e-04 - mae: 0.0183 - val_loss: 0.0014 - val_mae: 0.0295 - learning_rate: 5.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 5.8318e-04 - mae: 0.0187 - val_loss: 0.0012 - val_mae: 0.0270 - learning_rate: 5.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 5.3647e-04 - mae: 0.0181 - val_loss: 0.0012 - val_mae: 0.0267 - learning_rate: 5.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 5.2940e-04 - mae: 0.0178 - val_loss: 0.0014 - val_mae: 0.0297 - learning_rate: 5.0000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 5.4393e-04 - mae: 0.0181 - val_loss: 0.0011 - val_mae: 0.0262 - learning_rate: 5.0000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 4.4433e-04 - mae: 0.0164 - val_loss: 0.0012 - val_mae: 0.0275 - learning_rate: 2.5000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 4.2862e-04 - mae: 0.0160 - val_loss: 0.0011 - val_mae: 0.0258 - learning_rate: 2.5000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 4.2678e-04 - mae: 0.0160 - val_loss: 0.0011 - val_mae: 0.0256 - learning_rate: 2.5000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 4.2987e-04 - mae: 0.0160 - val_loss: 0.0010 - val_mae: 0.0251 - learning_rate: 2.5000e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 4.3094e-04 - mae: 0.0161 - val_loss: 0.0012 - val_mae: 0.0276 - learning_rate: 2.5000e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 3.8032e-04 - mae: 0.0150 - val_loss: 9.8743e-04 - val_mae: 0.0245 - learning_rate: 1.2500e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 3.9545e-04 - mae: 0.0154 - val_loss: 9.7746e-04 - val_mae: 0.0244 - learning_rate: 1.2500e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 3.8201e-04 - mae: 0.0151 - val_loss: 0.0010 - val_mae: 0.0250 - learning_rate: 1.2500e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 3.9565e-04 - mae: 0.0154 - val_loss: 0.0011 - val_mae: 0.0255 - learning_rate: 1.2500e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 3.9264e-04 - mae: 0.0154 - val_loss: 0.0010 - val_mae: 0.0250 - learning_rate: 6.2500e-05\n",
      "Epoch 33/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 3.8234e-04 - mae: 0.0153 - val_loss: 9.6565e-04 - val_mae: 0.0242 - learning_rate: 6.2500e-05\n",
      "Epoch 34/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 3.6388e-04 - mae: 0.0146 - val_loss: 9.8307e-04 - val_mae: 0.0244 - learning_rate: 6.2500e-05\n",
      "Epoch 35/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 3.6094e-04 - mae: 0.0147 - val_loss: 9.8782e-04 - val_mae: 0.0246 - learning_rate: 3.1250e-05\n",
      "Epoch 36/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 3.7432e-04 - mae: 0.0149 - val_loss: 0.0010 - val_mae: 0.0250 - learning_rate: 3.1250e-05\n",
      "Epoch 37/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 3.6254e-04 - mae: 0.0146 - val_loss: 0.0010 - val_mae: 0.0253 - learning_rate: 3.1250e-05\n",
      "Epoch 38/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 3.4690e-04 - mae: 0.0143 - val_loss: 9.9808e-04 - val_mae: 0.0248 - learning_rate: 1.5625e-05\n",
      "Epoch 39/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 3.5062e-04 - mae: 0.0145 - val_loss: 9.9505e-04 - val_mae: 0.0247 - learning_rate: 1.5625e-05\n",
      "Epoch 40/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 3.5132e-04 - mae: 0.0144 - val_loss: 9.7228e-04 - val_mae: 0.0244 - learning_rate: 1.5625e-05\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step   \n",
      " âœ… All Districts - full_state | MAE=56.94, RMSE=73.73, RÂ²=0.983, MAPE=3.02%, Acc=96.98%\n",
      "\n",
      "ğŸš€ Processing: Bagalkot | onion\n",
      "Epoch 1/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - loss: 0.0562 - mae: 0.1293 - val_loss: 0.0067 - val_mae: 0.0726 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0053 - mae: 0.0552 - val_loss: 0.0053 - val_mae: 0.0654 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0036 - mae: 0.0465 - val_loss: 0.0070 - val_mae: 0.0760 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0027 - mae: 0.0402 - val_loss: 0.0030 - val_mae: 0.0447 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0020 - mae: 0.0344 - val_loss: 0.0042 - val_mae: 0.0582 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0021 - mae: 0.0352 - val_loss: 0.0059 - val_mae: 0.0703 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0016 - mae: 0.0298 - val_loss: 7.2622e-04 - val_mae: 0.0164 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0015 - mae: 0.0290 - val_loss: 0.0012 - val_mae: 0.0229 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0013 - mae: 0.0266 - val_loss: 8.8354e-04 - val_mae: 0.0208 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0012 - mae: 0.0251 - val_loss: 0.0011 - val_mae: 0.0241 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 9.8646e-04 - mae: 0.0227 - val_loss: 0.0011 - val_mae: 0.0269 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 9.7130e-04 - mae: 0.0224 - val_loss: 9.1182e-04 - val_mae: 0.0211 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 9.0881e-04 - mae: 0.0220 - val_loss: 0.0011 - val_mae: 0.0253 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 8.7613e-04 - mae: 0.0215 - val_loss: 5.6820e-04 - val_mae: 0.0135 - learning_rate: 2.5000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 8.1856e-04 - mae: 0.0207 - val_loss: 7.2021e-04 - val_mae: 0.0195 - learning_rate: 2.5000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 8.3184e-04 - mae: 0.0204 - val_loss: 5.2010e-04 - val_mae: 0.0148 - learning_rate: 2.5000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 8.2739e-04 - mae: 0.0204 - val_loss: 4.5849e-04 - val_mae: 0.0125 - learning_rate: 2.5000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 8.1439e-04 - mae: 0.0205 - val_loss: 6.5788e-04 - val_mae: 0.0185 - learning_rate: 2.5000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 8.0577e-04 - mae: 0.0203 - val_loss: 4.4575e-04 - val_mae: 0.0115 - learning_rate: 2.5000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 7.9869e-04 - mae: 0.0201 - val_loss: 4.3338e-04 - val_mae: 0.0125 - learning_rate: 2.5000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 7.3460e-04 - mae: 0.0191 - val_loss: 4.3175e-04 - val_mae: 0.0129 - learning_rate: 1.2500e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 6.8486e-04 - mae: 0.0186 - val_loss: 4.0777e-04 - val_mae: 0.0110 - learning_rate: 1.2500e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 7.0214e-04 - mae: 0.0185 - val_loss: 5.9818e-04 - val_mae: 0.0179 - learning_rate: 1.2500e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 6.6940e-04 - mae: 0.0183 - val_loss: 6.0884e-04 - val_mae: 0.0183 - learning_rate: 6.2500e-05\n",
      "Epoch 25/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 6.7945e-04 - mae: 0.0180 - val_loss: 4.4155e-04 - val_mae: 0.0125 - learning_rate: 6.2500e-05\n",
      "Epoch 26/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 6.6274e-04 - mae: 0.0181 - val_loss: 4.3338e-04 - val_mae: 0.0129 - learning_rate: 6.2500e-05\n",
      "Epoch 27/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 6.5285e-04 - mae: 0.0179 - val_loss: 4.8878e-04 - val_mae: 0.0149 - learning_rate: 3.1250e-05\n",
      "Epoch 28/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 6.3856e-04 - mae: 0.0176 - val_loss: 4.0925e-04 - val_mae: 0.0115 - learning_rate: 3.1250e-05\n",
      "Epoch 29/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 6.6733e-04 - mae: 0.0181 - val_loss: 4.3451e-04 - val_mae: 0.0131 - learning_rate: 3.1250e-05\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step   \n",
      " âœ… Bagalkot - onion | MAE=92.89, RMSE=155.72, RÂ²=0.9537, MAPE=8.03%, Acc=91.97%\n",
      "\n",
      "ğŸš€ Processing: Bagalkot | wheat\n",
      "Epoch 1/50\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - loss: 0.0329 - mae: 0.1172 - val_loss: 0.0159 - val_mae: 0.0906 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0062 - mae: 0.0605 - val_loss: 0.0094 - val_mae: 0.0754 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0038 - mae: 0.0462 - val_loss: 0.0068 - val_mae: 0.0581 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0027 - mae: 0.0380 - val_loss: 0.0055 - val_mae: 0.0539 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0020 - mae: 0.0313 - val_loss: 0.0050 - val_mae: 0.0453 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0017 - mae: 0.0285 - val_loss: 0.0040 - val_mae: 0.0406 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0016 - mae: 0.0268 - val_loss: 0.0034 - val_mae: 0.0394 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0013 - mae: 0.0229 - val_loss: 0.0028 - val_mae: 0.0380 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0012 - mae: 0.0216 - val_loss: 0.0023 - val_mae: 0.0331 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0010 - mae: 0.0195 - val_loss: 0.0021 - val_mae: 0.0303 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0011 - mae: 0.0208 - val_loss: 0.0020 - val_mae: 0.0304 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 8.8654e-04 - mae: 0.0174 - val_loss: 0.0017 - val_mae: 0.0245 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0011 - mae: 0.0214 - val_loss: 0.0017 - val_mae: 0.0221 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 8.6842e-04 - mae: 0.0169 - val_loss: 0.0016 - val_mae: 0.0217 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 8.4586e-04 - mae: 0.0164 - val_loss: 0.0015 - val_mae: 0.0251 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 8.9510e-04 - mae: 0.0177 - val_loss: 0.0015 - val_mae: 0.0241 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 8.7017e-04 - mae: 0.0171 - val_loss: 0.0014 - val_mae: 0.0249 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 8.2329e-04 - mae: 0.0162 - val_loss: 0.0015 - val_mae: 0.0288 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 8.4248e-04 - mae: 0.0166 - val_loss: 0.0015 - val_mae: 0.0294 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 8.2041e-04 - mae: 0.0162 - val_loss: 0.0018 - val_mae: 0.0348 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 7.0447e-04 - mae: 0.0139 - val_loss: 0.0016 - val_mae: 0.0326 - learning_rate: 5.0000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 7.0167e-04 - mae: 0.0140 - val_loss: 0.0015 - val_mae: 0.0301 - learning_rate: 5.0000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 6.8583e-04 - mae: 0.0135 - val_loss: 0.0016 - val_mae: 0.0322 - learning_rate: 5.0000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m121/121\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 6.6942e-04 - mae: 0.0131 - val_loss: 0.0019 - val_mae: 0.0373 - learning_rate: 2.5000e-04\n",
      "\u001b[1m76/76\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step  \n",
      " âœ… Bagalkot - wheat | MAE=87.16, RMSE=128.76, RÂ²=0.935, MAPE=4.45%, Acc=95.55%\n",
      "\n",
      "ğŸš€ Processing: Bangalore | capsicum\n",
      "Epoch 1/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - loss: 0.0649 - mae: 0.1605 - val_loss: 0.0139 - val_mae: 0.0943 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0107 - mae: 0.0794 - val_loss: 0.0105 - val_mae: 0.0809 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0082 - mae: 0.0684 - val_loss: 0.0063 - val_mae: 0.0595 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0075 - mae: 0.0664 - val_loss: 0.0063 - val_mae: 0.0608 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0061 - mae: 0.0594 - val_loss: 0.0059 - val_mae: 0.0590 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0052 - mae: 0.0539 - val_loss: 0.0060 - val_mae: 0.0596 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0047 - mae: 0.0517 - val_loss: 0.0060 - val_mae: 0.0599 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0046 - mae: 0.0518 - val_loss: 0.0061 - val_mae: 0.0608 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0037 - mae: 0.0447 - val_loss: 0.0053 - val_mae: 0.0552 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0036 - mae: 0.0440 - val_loss: 0.0067 - val_mae: 0.0633 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0034 - mae: 0.0429 - val_loss: 0.0057 - val_mae: 0.0573 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0033 - mae: 0.0426 - val_loss: 0.0048 - val_mae: 0.0519 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0032 - mae: 0.0418 - val_loss: 0.0052 - val_mae: 0.0547 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0031 - mae: 0.0414 - val_loss: 0.0052 - val_mae: 0.0545 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0032 - mae: 0.0416 - val_loss: 0.0051 - val_mae: 0.0543 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0029 - mae: 0.0392 - val_loss: 0.0046 - val_mae: 0.0504 - learning_rate: 2.5000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0028 - mae: 0.0382 - val_loss: 0.0043 - val_mae: 0.0485 - learning_rate: 2.5000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0029 - mae: 0.0387 - val_loss: 0.0044 - val_mae: 0.0496 - learning_rate: 2.5000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0029 - mae: 0.0387 - val_loss: 0.0043 - val_mae: 0.0486 - learning_rate: 2.5000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0028 - mae: 0.0383 - val_loss: 0.0045 - val_mae: 0.0504 - learning_rate: 2.5000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0026 - mae: 0.0372 - val_loss: 0.0046 - val_mae: 0.0514 - learning_rate: 1.2500e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0028 - mae: 0.0380 - val_loss: 0.0044 - val_mae: 0.0495 - learning_rate: 1.2500e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0027 - mae: 0.0372 - val_loss: 0.0045 - val_mae: 0.0507 - learning_rate: 1.2500e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0026 - mae: 0.0364 - val_loss: 0.0041 - val_mae: 0.0476 - learning_rate: 6.2500e-05\n",
      "Epoch 25/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0025 - mae: 0.0361 - val_loss: 0.0041 - val_mae: 0.0472 - learning_rate: 6.2500e-05\n",
      "Epoch 26/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0026 - mae: 0.0362 - val_loss: 0.0042 - val_mae: 0.0482 - learning_rate: 6.2500e-05\n",
      "Epoch 27/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0025 - mae: 0.0360 - val_loss: 0.0043 - val_mae: 0.0486 - learning_rate: 6.2500e-05\n",
      "Epoch 28/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0025 - mae: 0.0361 - val_loss: 0.0040 - val_mae: 0.0467 - learning_rate: 3.1250e-05\n",
      "Epoch 29/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0025 - mae: 0.0360 - val_loss: 0.0041 - val_mae: 0.0473 - learning_rate: 3.1250e-05\n",
      "Epoch 30/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0025 - mae: 0.0359 - val_loss: 0.0041 - val_mae: 0.0471 - learning_rate: 3.1250e-05\n",
      "Epoch 31/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0025 - mae: 0.0360 - val_loss: 0.0040 - val_mae: 0.0467 - learning_rate: 3.1250e-05\n",
      "Epoch 32/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0025 - mae: 0.0357 - val_loss: 0.0041 - val_mae: 0.0470 - learning_rate: 1.5625e-05\n",
      "Epoch 33/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0025 - mae: 0.0359 - val_loss: 0.0041 - val_mae: 0.0470 - learning_rate: 1.5625e-05\n",
      "Epoch 34/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0025 - mae: 0.0353 - val_loss: 0.0041 - val_mae: 0.0472 - learning_rate: 1.5625e-05\n",
      "Epoch 35/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0025 - mae: 0.0356 - val_loss: 0.0041 - val_mae: 0.0469 - learning_rate: 7.8125e-06\n",
      "\u001b[1m83/83\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step   \n",
      " âœ… Bangalore - capsicum | MAE=262.05, RMSE=364.01, RÂ²=0.876, MAPE=9.98%, Acc=90.02%\n",
      "\n",
      "ğŸš€ Processing: Bangalore | onion\n",
      "Epoch 1/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - loss: 0.0742 - mae: 0.1586 - val_loss: 0.0125 - val_mae: 0.0779 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0097 - mae: 0.0768 - val_loss: 0.0092 - val_mae: 0.0724 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0067 - mae: 0.0637 - val_loss: 0.0105 - val_mae: 0.0765 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0047 - mae: 0.0522 - val_loss: 0.0114 - val_mae: 0.0863 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0034 - mae: 0.0442 - val_loss: 0.0048 - val_mae: 0.0470 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0028 - mae: 0.0391 - val_loss: 0.0041 - val_mae: 0.0407 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0022 - mae: 0.0347 - val_loss: 0.0048 - val_mae: 0.0527 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0022 - mae: 0.0346 - val_loss: 0.0048 - val_mae: 0.0522 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0019 - mae: 0.0315 - val_loss: 0.0027 - val_mae: 0.0333 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0017 - mae: 0.0294 - val_loss: 0.0041 - val_mae: 0.0444 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0015 - mae: 0.0273 - val_loss: 0.0045 - val_mae: 0.0486 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0016 - mae: 0.0288 - val_loss: 0.0039 - val_mae: 0.0431 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0012 - mae: 0.0237 - val_loss: 0.0032 - val_mae: 0.0371 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0012 - mae: 0.0235 - val_loss: 0.0028 - val_mae: 0.0341 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0011 - mae: 0.0229 - val_loss: 0.0028 - val_mae: 0.0336 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0011 - mae: 0.0225 - val_loss: 0.0026 - val_mae: 0.0328 - learning_rate: 2.5000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0011 - mae: 0.0231 - val_loss: 0.0031 - val_mae: 0.0363 - learning_rate: 2.5000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0010 - mae: 0.0220 - val_loss: 0.0034 - val_mae: 0.0395 - learning_rate: 2.5000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0011 - mae: 0.0217 - val_loss: 0.0026 - val_mae: 0.0324 - learning_rate: 1.2500e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0010 - mae: 0.0214 - val_loss: 0.0027 - val_mae: 0.0331 - learning_rate: 1.2500e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 9.8740e-04 - mae: 0.0209 - val_loss: 0.0026 - val_mae: 0.0326 - learning_rate: 1.2500e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0010 - mae: 0.0209 - val_loss: 0.0026 - val_mae: 0.0324 - learning_rate: 6.2500e-05\n",
      "Epoch 23/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 9.6191e-04 - mae: 0.0208 - val_loss: 0.0025 - val_mae: 0.0318 - learning_rate: 6.2500e-05\n",
      "Epoch 24/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0010 - mae: 0.0210 - val_loss: 0.0024 - val_mae: 0.0310 - learning_rate: 6.2500e-05\n",
      "Epoch 25/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 9.8527e-04 - mae: 0.0208 - val_loss: 0.0027 - val_mae: 0.0332 - learning_rate: 6.2500e-05\n",
      "Epoch 26/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 9.6323e-04 - mae: 0.0205 - val_loss: 0.0026 - val_mae: 0.0323 - learning_rate: 6.2500e-05\n",
      "Epoch 27/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 9.7601e-04 - mae: 0.0207 - val_loss: 0.0025 - val_mae: 0.0312 - learning_rate: 6.2500e-05\n",
      "Epoch 28/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 9.4508e-04 - mae: 0.0205 - val_loss: 0.0024 - val_mae: 0.0310 - learning_rate: 3.1250e-05\n",
      "Epoch 29/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 9.5021e-04 - mae: 0.0205 - val_loss: 0.0026 - val_mae: 0.0320 - learning_rate: 3.1250e-05\n",
      "Epoch 30/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 9.8556e-04 - mae: 0.0205 - val_loss: 0.0024 - val_mae: 0.0313 - learning_rate: 3.1250e-05\n",
      "Epoch 31/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 9.1841e-04 - mae: 0.0202 - val_loss: 0.0024 - val_mae: 0.0310 - learning_rate: 1.5625e-05\n",
      "Epoch 32/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 9.2141e-04 - mae: 0.0199 - val_loss: 0.0024 - val_mae: 0.0310 - learning_rate: 1.5625e-05\n",
      "Epoch 33/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 9.2436e-04 - mae: 0.0201 - val_loss: 0.0024 - val_mae: 0.0310 - learning_rate: 1.5625e-05\n",
      "Epoch 34/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 9.0178e-04 - mae: 0.0199 - val_loss: 0.0024 - val_mae: 0.0311 - learning_rate: 7.8125e-06\n",
      "Epoch 35/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 9.0145e-04 - mae: 0.0200 - val_loss: 0.0023 - val_mae: 0.0310 - learning_rate: 7.8125e-06\n",
      "Epoch 36/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 9.1201e-04 - mae: 0.0200 - val_loss: 0.0023 - val_mae: 0.0305 - learning_rate: 7.8125e-06\n",
      "Epoch 37/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 9.3653e-04 - mae: 0.0198 - val_loss: 0.0023 - val_mae: 0.0307 - learning_rate: 7.8125e-06\n",
      "Epoch 38/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 9.2501e-04 - mae: 0.0200 - val_loss: 0.0024 - val_mae: 0.0309 - learning_rate: 7.8125e-06\n",
      "Epoch 39/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 9.2653e-04 - mae: 0.0199 - val_loss: 0.0023 - val_mae: 0.0307 - learning_rate: 7.8125e-06\n",
      "Epoch 40/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 9.1187e-04 - mae: 0.0198 - val_loss: 0.0024 - val_mae: 0.0307 - learning_rate: 3.9063e-06\n",
      "Epoch 41/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 8.7467e-04 - mae: 0.0197 - val_loss: 0.0023 - val_mae: 0.0305 - learning_rate: 3.9063e-06\n",
      "Epoch 42/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 9.1506e-04 - mae: 0.0201 - val_loss: 0.0023 - val_mae: 0.0305 - learning_rate: 3.9063e-06\n",
      "Epoch 43/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 8.8072e-04 - mae: 0.0201 - val_loss: 0.0023 - val_mae: 0.0305 - learning_rate: 1.9531e-06\n",
      "Epoch 44/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 8.8881e-04 - mae: 0.0198 - val_loss: 0.0023 - val_mae: 0.0304 - learning_rate: 1.9531e-06\n",
      "Epoch 45/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 8.8095e-04 - mae: 0.0196 - val_loss: 0.0023 - val_mae: 0.0305 - learning_rate: 1.9531e-06\n",
      "Epoch 46/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 9.1031e-04 - mae: 0.0199 - val_loss: 0.0023 - val_mae: 0.0305 - learning_rate: 1.0000e-06\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step   \n",
      " âœ… Bangalore - onion | MAE=126.8, RMSE=201.97, RÂ²=0.9484, MAPE=7.04%, Acc=92.96%\n",
      "\n",
      "ğŸš€ Processing: Bangalore | tomato\n",
      "Epoch 1/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - loss: 0.0404 - mae: 0.1258 - val_loss: 0.0120 - val_mae: 0.0710 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0074 - mae: 0.0664 - val_loss: 0.0091 - val_mae: 0.0638 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0052 - mae: 0.0548 - val_loss: 0.0061 - val_mae: 0.0496 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0038 - mae: 0.0462 - val_loss: 0.0056 - val_mae: 0.0473 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0032 - mae: 0.0415 - val_loss: 0.0057 - val_mae: 0.0506 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0025 - mae: 0.0365 - val_loss: 0.0058 - val_mae: 0.0515 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0024 - mae: 0.0362 - val_loss: 0.0076 - val_mae: 0.0657 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0018 - mae: 0.0305 - val_loss: 0.0045 - val_mae: 0.0419 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0017 - mae: 0.0292 - val_loss: 0.0043 - val_mae: 0.0410 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0016 - mae: 0.0290 - val_loss: 0.0042 - val_mae: 0.0410 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0015 - mae: 0.0276 - val_loss: 0.0042 - val_mae: 0.0408 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0014 - mae: 0.0267 - val_loss: 0.0040 - val_mae: 0.0406 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0014 - mae: 0.0261 - val_loss: 0.0039 - val_mae: 0.0416 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0014 - mae: 0.0265 - val_loss: 0.0044 - val_mae: 0.0414 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0014 - mae: 0.0260 - val_loss: 0.0037 - val_mae: 0.0395 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0014 - mae: 0.0257 - val_loss: 0.0040 - val_mae: 0.0401 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0013 - mae: 0.0246 - val_loss: 0.0035 - val_mae: 0.0399 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0013 - mae: 0.0253 - val_loss: 0.0035 - val_mae: 0.0382 - learning_rate: 5.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0013 - mae: 0.0247 - val_loss: 0.0035 - val_mae: 0.0387 - learning_rate: 5.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0012 - mae: 0.0240 - val_loss: 0.0036 - val_mae: 0.0420 - learning_rate: 5.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0011 - mae: 0.0231 - val_loss: 0.0036 - val_mae: 0.0388 - learning_rate: 2.5000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0011 - mae: 0.0231 - val_loss: 0.0034 - val_mae: 0.0377 - learning_rate: 2.5000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0011 - mae: 0.0234 - val_loss: 0.0035 - val_mae: 0.0387 - learning_rate: 2.5000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0012 - mae: 0.0236 - val_loss: 0.0034 - val_mae: 0.0379 - learning_rate: 2.5000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0011 - mae: 0.0228 - val_loss: 0.0033 - val_mae: 0.0373 - learning_rate: 2.5000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0010 - mae: 0.0213 - val_loss: 0.0033 - val_mae: 0.0376 - learning_rate: 1.2500e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 9.9233e-04 - mae: 0.0212 - val_loss: 0.0032 - val_mae: 0.0375 - learning_rate: 1.2500e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 9.7122e-04 - mae: 0.0210 - val_loss: 0.0033 - val_mae: 0.0373 - learning_rate: 1.2500e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0010 - mae: 0.0215 - val_loss: 0.0032 - val_mae: 0.0373 - learning_rate: 1.2500e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 9.9115e-04 - mae: 0.0214 - val_loss: 0.0032 - val_mae: 0.0370 - learning_rate: 1.2500e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 9.5192e-04 - mae: 0.0206 - val_loss: 0.0032 - val_mae: 0.0383 - learning_rate: 6.2500e-05\n",
      "Epoch 32/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 9.1361e-04 - mae: 0.0202 - val_loss: 0.0032 - val_mae: 0.0384 - learning_rate: 6.2500e-05\n",
      "Epoch 33/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 9.1920e-04 - mae: 0.0200 - val_loss: 0.0033 - val_mae: 0.0380 - learning_rate: 6.2500e-05\n",
      "Epoch 34/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 8.9470e-04 - mae: 0.0198 - val_loss: 0.0032 - val_mae: 0.0376 - learning_rate: 3.1250e-05\n",
      "Epoch 35/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 9.0115e-04 - mae: 0.0201 - val_loss: 0.0033 - val_mae: 0.0380 - learning_rate: 3.1250e-05\n",
      "Epoch 36/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 9.0041e-04 - mae: 0.0199 - val_loss: 0.0033 - val_mae: 0.0379 - learning_rate: 3.1250e-05\n",
      "Epoch 37/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 8.9224e-04 - mae: 0.0200 - val_loss: 0.0033 - val_mae: 0.0382 - learning_rate: 1.5625e-05\n",
      "Epoch 38/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 8.8166e-04 - mae: 0.0197 - val_loss: 0.0033 - val_mae: 0.0377 - learning_rate: 1.5625e-05\n",
      "Epoch 39/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 8.7615e-04 - mae: 0.0197 - val_loss: 0.0033 - val_mae: 0.0376 - learning_rate: 1.5625e-05\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step   \n",
      " âœ… Bangalore - tomato | MAE=253.97, RMSE=360.98, RÂ²=0.9091, MAPE=22.2%, Acc=77.8%\n",
      "\n",
      "ğŸš€ Processing: Bangalore | wheat\n",
      "Epoch 1/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 20ms/step - loss: 0.0829 - mae: 0.1506 - val_loss: 0.0129 - val_mae: 0.1034 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0050 - mae: 0.0537 - val_loss: 0.0071 - val_mae: 0.0738 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0040 - mae: 0.0481 - val_loss: 0.0078 - val_mae: 0.0791 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0031 - mae: 0.0415 - val_loss: 0.0097 - val_mae: 0.0916 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0027 - mae: 0.0386 - val_loss: 0.0098 - val_mae: 0.0931 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0020 - mae: 0.0326 - val_loss: 0.0082 - val_mae: 0.0852 - learning_rate: 5.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0019 - mae: 0.0318 - val_loss: 0.0114 - val_mae: 0.1019 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0018 - mae: 0.0304 - val_loss: 0.0081 - val_mae: 0.0828 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0015 - mae: 0.0275 - val_loss: 0.0075 - val_mae: 0.0792 - learning_rate: 2.5000e-04\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step   \n",
      " âœ… Bangalore - wheat | MAE=208.77, RMSE=305.09, RÂ²=0.7174, MAPE=8.66%, Acc=91.34%\n",
      "\n",
      "ğŸš€ Processing: Belgaum | capsicum\n",
      "Epoch 1/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 42ms/step - loss: 0.0980 - mae: 0.2442 - val_loss: 0.0039 - val_mae: 0.0481 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0152 - mae: 0.0916 - val_loss: 0.0036 - val_mae: 0.0523 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0121 - mae: 0.0797 - val_loss: 0.0043 - val_mae: 0.0589 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0113 - mae: 0.0767 - val_loss: 0.0034 - val_mae: 0.0515 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0102 - mae: 0.0712 - val_loss: 0.0025 - val_mae: 0.0422 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0104 - mae: 0.0720 - val_loss: 0.0027 - val_mae: 0.0439 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0100 - mae: 0.0710 - val_loss: 0.0058 - val_mae: 0.0681 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0098 - mae: 0.0696 - val_loss: 0.0063 - val_mae: 0.0712 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0090 - mae: 0.0671 - val_loss: 0.0050 - val_mae: 0.0630 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0088 - mae: 0.0665 - val_loss: 0.0027 - val_mae: 0.0456 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0077 - mae: 0.0604 - val_loss: 0.0040 - val_mae: 0.0559 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0081 - mae: 0.0615 - val_loss: 0.0033 - val_mae: 0.0503 - learning_rate: 2.5000e-04\n",
      "\u001b[1m19/19\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step \n",
      " âœ… Belgaum - capsicum | MAE=419.91, RMSE=581.58, RÂ²=0.4644, MAPE=15.25%, Acc=84.75%\n",
      "\n",
      "ğŸš€ Processing: Belgaum | onion\n",
      "Epoch 1/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - loss: 0.0942 - mae: 0.1454 - val_loss: 0.0016 - val_mae: 0.0291 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0064 - mae: 0.0621 - val_loss: 0.0052 - val_mae: 0.0620 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0053 - mae: 0.0568 - val_loss: 0.0045 - val_mae: 0.0579 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0047 - mae: 0.0535 - val_loss: 0.0030 - val_mae: 0.0436 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0038 - mae: 0.0479 - val_loss: 0.0014 - val_mae: 0.0261 - learning_rate: 5.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0036 - mae: 0.0461 - val_loss: 0.0014 - val_mae: 0.0250 - learning_rate: 5.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0033 - mae: 0.0438 - val_loss: 0.0012 - val_mae: 0.0239 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0029 - mae: 0.0417 - val_loss: 0.0012 - val_mae: 0.0249 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0027 - mae: 0.0398 - val_loss: 0.0014 - val_mae: 0.0267 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0027 - mae: 0.0395 - val_loss: 0.0015 - val_mae: 0.0278 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0023 - mae: 0.0361 - val_loss: 0.0017 - val_mae: 0.0309 - learning_rate: 2.5000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0021 - mae: 0.0346 - val_loss: 0.0013 - val_mae: 0.0273 - learning_rate: 2.5000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0020 - mae: 0.0340 - val_loss: 0.0011 - val_mae: 0.0229 - learning_rate: 2.5000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0019 - mae: 0.0327 - val_loss: 0.0012 - val_mae: 0.0249 - learning_rate: 2.5000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0018 - mae: 0.0318 - val_loss: 0.0022 - val_mae: 0.0386 - learning_rate: 2.5000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0018 - mae: 0.0310 - val_loss: 0.0012 - val_mae: 0.0240 - learning_rate: 2.5000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0017 - mae: 0.0309 - val_loss: 0.0012 - val_mae: 0.0255 - learning_rate: 1.2500e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0017 - mae: 0.0302 - val_loss: 0.0011 - val_mae: 0.0232 - learning_rate: 1.2500e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0017 - mae: 0.0299 - val_loss: 0.0011 - val_mae: 0.0241 - learning_rate: 1.2500e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0015 - mae: 0.0289 - val_loss: 0.0017 - val_mae: 0.0326 - learning_rate: 6.2500e-05\n",
      "Epoch 21/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0015 - mae: 0.0288 - val_loss: 0.0016 - val_mae: 0.0306 - learning_rate: 6.2500e-05\n",
      "Epoch 22/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0015 - mae: 0.0285 - val_loss: 0.0017 - val_mae: 0.0318 - learning_rate: 6.2500e-05\n",
      "Epoch 23/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0015 - mae: 0.0278 - val_loss: 0.0017 - val_mae: 0.0323 - learning_rate: 3.1250e-05\n",
      "Epoch 24/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0014 - mae: 0.0277 - val_loss: 0.0015 - val_mae: 0.0289 - learning_rate: 3.1250e-05\n",
      "Epoch 25/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0014 - mae: 0.0277 - val_loss: 0.0014 - val_mae: 0.0282 - learning_rate: 3.1250e-05\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step   \n",
      " âœ… Belgaum - onion | MAE=194.61, RMSE=317.55, RÂ²=0.9044, MAPE=12.51%, Acc=87.49%\n",
      "\n",
      "ğŸš€ Processing: Belgaum | tomato\n",
      "Epoch 1/50\n",
      "\u001b[1m130/130\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - loss: 0.0377 - mae: 0.1021 - val_loss: 0.0174 - val_mae: 0.0927 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m130/130\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0047 - mae: 0.0543 - val_loss: 0.0127 - val_mae: 0.0800 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m130/130\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0034 - mae: 0.0462 - val_loss: 0.0140 - val_mae: 0.0885 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m130/130\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0022 - mae: 0.0376 - val_loss: 0.0111 - val_mae: 0.0755 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m130/130\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0016 - mae: 0.0310 - val_loss: 0.0094 - val_mae: 0.0674 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m130/130\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0011 - mae: 0.0266 - val_loss: 0.0082 - val_mae: 0.0623 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m130/130\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 8.7370e-04 - mae: 0.0232 - val_loss: 0.0090 - val_mae: 0.0696 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m130/130\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 7.5817e-04 - mae: 0.0213 - val_loss: 0.0081 - val_mae: 0.0623 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m130/130\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 5.1396e-04 - mae: 0.0175 - val_loss: 0.0079 - val_mae: 0.0579 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m130/130\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 4.5532e-04 - mae: 0.0163 - val_loss: 0.0083 - val_mae: 0.0588 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m130/130\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 3.7105e-04 - mae: 0.0147 - val_loss: 0.0085 - val_mae: 0.0583 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m130/130\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 3.3242e-04 - mae: 0.0138 - val_loss: 0.0086 - val_mae: 0.0590 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m130/130\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 2.7169e-04 - mae: 0.0122 - val_loss: 0.0088 - val_mae: 0.0594 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m130/130\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 2.6147e-04 - mae: 0.0118 - val_loss: 0.0087 - val_mae: 0.0589 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m130/130\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 2.5711e-04 - mae: 0.0117 - val_loss: 0.0089 - val_mae: 0.0594 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m130/130\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 2.2630e-04 - mae: 0.0107 - val_loss: 0.0093 - val_mae: 0.0617 - learning_rate: 2.5000e-04\n",
      "\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step   \n",
      " âœ… Belgaum - tomato | MAE=171.9, RMSE=399.42, RÂ²=0.8734, MAPE=8.98%, Acc=91.02%\n",
      "\n",
      "ğŸš€ Processing: Belgaum | wheat\n",
      "Epoch 1/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - loss: 0.0668 - mae: 0.1583 - val_loss: 0.0700 - val_mae: 0.2458 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0072 - mae: 0.0668 - val_loss: 0.0265 - val_mae: 0.1385 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0053 - mae: 0.0575 - val_loss: 0.0340 - val_mae: 0.1660 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0040 - mae: 0.0499 - val_loss: 0.0165 - val_mae: 0.1052 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0030 - mae: 0.0428 - val_loss: 0.0190 - val_mae: 0.1174 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0029 - mae: 0.0428 - val_loss: 0.0068 - val_mae: 0.0656 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0026 - mae: 0.0401 - val_loss: 0.0135 - val_mae: 0.0945 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0019 - mae: 0.0338 - val_loss: 0.0099 - val_mae: 0.0795 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0019 - mae: 0.0341 - val_loss: 0.0122 - val_mae: 0.0892 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0014 - mae: 0.0293 - val_loss: 0.0096 - val_mae: 0.0782 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0014 - mae: 0.0291 - val_loss: 0.0111 - val_mae: 0.0850 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0014 - mae: 0.0290 - val_loss: 0.0127 - val_mae: 0.0924 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0012 - mae: 0.0264 - val_loss: 0.0067 - val_mae: 0.0647 - learning_rate: 2.5000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0011 - mae: 0.0260 - val_loss: 0.0077 - val_mae: 0.0692 - learning_rate: 2.5000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0011 - mae: 0.0255 - val_loss: 0.0061 - val_mae: 0.0613 - learning_rate: 2.5000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0011 - mae: 0.0253 - val_loss: 0.0070 - val_mae: 0.0655 - learning_rate: 2.5000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0011 - mae: 0.0258 - val_loss: 0.0071 - val_mae: 0.0662 - learning_rate: 2.5000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0010 - mae: 0.0251 - val_loss: 0.0078 - val_mae: 0.0694 - learning_rate: 2.5000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 9.1912e-04 - mae: 0.0234 - val_loss: 0.0110 - val_mae: 0.0851 - learning_rate: 1.2500e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 9.0827e-04 - mae: 0.0232 - val_loss: 0.0092 - val_mae: 0.0766 - learning_rate: 1.2500e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 8.9528e-04 - mae: 0.0231 - val_loss: 0.0073 - val_mae: 0.0671 - learning_rate: 1.2500e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 8.4322e-04 - mae: 0.0223 - val_loss: 0.0075 - val_mae: 0.0681 - learning_rate: 6.2500e-05\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step   \n",
      " âœ… Belgaum - wheat | MAE=74.55, RMSE=102.25, RÂ²=0.9608, MAPE=3.16%, Acc=96.84%\n",
      "\n",
      "ğŸš€ Processing: Bellary | capsicum\n",
      "Epoch 1/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - loss: 0.1103 - mae: 0.1987 - val_loss: 0.0116 - val_mae: 0.0368 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0054 - mae: 0.0563 - val_loss: 0.0096 - val_mae: 0.0522 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0051 - mae: 0.0545 - val_loss: 0.0092 - val_mae: 0.0594 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0045 - mae: 0.0511 - val_loss: 0.0077 - val_mae: 0.0499 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0037 - mae: 0.0452 - val_loss: 0.0062 - val_mae: 0.0344 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0031 - mae: 0.0406 - val_loss: 0.0072 - val_mae: 0.0426 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0024 - mae: 0.0350 - val_loss: 0.0059 - val_mae: 0.0254 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0019 - mae: 0.0301 - val_loss: 0.0065 - val_mae: 0.0301 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0018 - mae: 0.0295 - val_loss: 0.0060 - val_mae: 0.0243 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0013 - mae: 0.0238 - val_loss: 0.0060 - val_mae: 0.0195 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0010 - mae: 0.0220 - val_loss: 0.0065 - val_mae: 0.0261 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 9.4421e-04 - mae: 0.0209 - val_loss: 0.0066 - val_mae: 0.0229 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 8.1694e-04 - mae: 0.0193 - val_loss: 0.0069 - val_mae: 0.0214 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m75/75\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 7.3009e-04 - mae: 0.0182 - val_loss: 0.0068 - val_mae: 0.0224 - learning_rate: 2.5000e-04\n",
      "\u001b[1m47/47\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step  \n",
      " âœ… Bellary - capsicum | MAE=30.2, RMSE=88.35, RÂ²=0.6117, MAPE=1.55%, Acc=98.45%\n",
      "\n",
      "ğŸš€ Processing: Bellary | onion\n",
      "Epoch 1/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - loss: 0.0395 - mae: 0.1283 - val_loss: 0.0012 - val_mae: 0.0261 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0066 - mae: 0.0627 - val_loss: 0.0011 - val_mae: 0.0244 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0047 - mae: 0.0528 - val_loss: 0.0014 - val_mae: 0.0263 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0044 - mae: 0.0509 - val_loss: 0.0011 - val_mae: 0.0246 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0030 - mae: 0.0418 - val_loss: 9.9522e-04 - val_mae: 0.0196 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0025 - mae: 0.0377 - val_loss: 0.0013 - val_mae: 0.0279 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0024 - mae: 0.0364 - val_loss: 0.0017 - val_mae: 0.0331 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0019 - mae: 0.0319 - val_loss: 0.0012 - val_mae: 0.0266 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0019 - mae: 0.0313 - val_loss: 0.0018 - val_mae: 0.0360 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0017 - mae: 0.0294 - val_loss: 0.0014 - val_mae: 0.0305 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0017 - mae: 0.0287 - val_loss: 0.0014 - val_mae: 0.0308 - learning_rate: 2.5000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0015 - mae: 0.0276 - val_loss: 0.0011 - val_mae: 0.0247 - learning_rate: 2.5000e-04\n",
      "\u001b[1m80/80\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step   \n",
      " âœ… Bellary - onion | MAE=160.78, RMSE=232.19, RÂ²=0.8224, MAPE=14.48%, Acc=85.52%\n",
      "\n",
      "ğŸš€ Processing: Bellary | tomato\n",
      "Epoch 1/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0582 - mae: 0.1374 - val_loss: 0.0193 - val_mae: 0.0525 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0072 - mae: 0.0666 - val_loss: 0.0212 - val_mae: 0.0823 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0054 - mae: 0.0576 - val_loss: 0.0159 - val_mae: 0.0553 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0034 - mae: 0.0448 - val_loss: 0.0154 - val_mae: 0.0550 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0025 - mae: 0.0373 - val_loss: 0.0164 - val_mae: 0.0590 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0019 - mae: 0.0322 - val_loss: 0.0144 - val_mae: 0.0514 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0016 - mae: 0.0288 - val_loss: 0.0146 - val_mae: 0.0554 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0014 - mae: 0.0269 - val_loss: 0.0140 - val_mae: 0.0566 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0014 - mae: 0.0260 - val_loss: 0.0139 - val_mae: 0.0546 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0012 - mae: 0.0238 - val_loss: 0.0125 - val_mae: 0.0482 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0011 - mae: 0.0229 - val_loss: 0.0119 - val_mae: 0.0467 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0011 - mae: 0.0230 - val_loss: 0.0128 - val_mae: 0.0577 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0010 - mae: 0.0219 - val_loss: 0.0125 - val_mae: 0.0564 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0010 - mae: 0.0216 - val_loss: 0.0116 - val_mae: 0.0472 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0010 - mae: 0.0218 - val_loss: 0.0112 - val_mae: 0.0514 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 9.4455e-04 - mae: 0.0210 - val_loss: 0.0101 - val_mae: 0.0395 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 8.8919e-04 - mae: 0.0199 - val_loss: 0.0106 - val_mae: 0.0432 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 9.1436e-04 - mae: 0.0203 - val_loss: 0.0109 - val_mae: 0.0508 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 9.3127e-04 - mae: 0.0207 - val_loss: 0.0099 - val_mae: 0.0393 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 8.4348e-04 - mae: 0.0194 - val_loss: 0.0103 - val_mae: 0.0418 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 8.4725e-04 - mae: 0.0195 - val_loss: 0.0101 - val_mae: 0.0413 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 7.7497e-04 - mae: 0.0183 - val_loss: 0.0102 - val_mae: 0.0425 - learning_rate: 0.0010\n",
      "Epoch 23/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 7.4677e-04 - mae: 0.0180 - val_loss: 0.0092 - val_mae: 0.0349 - learning_rate: 5.0000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 7.8588e-04 - mae: 0.0187 - val_loss: 0.0085 - val_mae: 0.0336 - learning_rate: 5.0000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 7.6697e-04 - mae: 0.0185 - val_loss: 0.0090 - val_mae: 0.0339 - learning_rate: 5.0000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 7.4252e-04 - mae: 0.0180 - val_loss: 0.0091 - val_mae: 0.0342 - learning_rate: 5.0000e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 7.4897e-04 - mae: 0.0182 - val_loss: 0.0091 - val_mae: 0.0357 - learning_rate: 5.0000e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 6.5091e-04 - mae: 0.0160 - val_loss: 0.0087 - val_mae: 0.0330 - learning_rate: 2.5000e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 6.7686e-04 - mae: 0.0163 - val_loss: 0.0086 - val_mae: 0.0329 - learning_rate: 2.5000e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 6.7558e-04 - mae: 0.0165 - val_loss: 0.0087 - val_mae: 0.0345 - learning_rate: 2.5000e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 6.4913e-04 - mae: 0.0161 - val_loss: 0.0084 - val_mae: 0.0331 - learning_rate: 1.2500e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 6.5694e-04 - mae: 0.0161 - val_loss: 0.0081 - val_mae: 0.0331 - learning_rate: 1.2500e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 6.6771e-04 - mae: 0.0163 - val_loss: 0.0083 - val_mae: 0.0329 - learning_rate: 1.2500e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 6.7252e-04 - mae: 0.0162 - val_loss: 0.0084 - val_mae: 0.0330 - learning_rate: 1.2500e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 6.4054e-04 - mae: 0.0159 - val_loss: 0.0085 - val_mae: 0.0338 - learning_rate: 1.2500e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 6.3581e-04 - mae: 0.0154 - val_loss: 0.0082 - val_mae: 0.0338 - learning_rate: 6.2500e-05\n",
      "Epoch 37/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 6.3813e-04 - mae: 0.0156 - val_loss: 0.0081 - val_mae: 0.0337 - learning_rate: 6.2500e-05\n",
      "Epoch 38/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 6.2861e-04 - mae: 0.0155 - val_loss: 0.0084 - val_mae: 0.0341 - learning_rate: 6.2500e-05\n",
      "Epoch 39/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 6.2345e-04 - mae: 0.0153 - val_loss: 0.0081 - val_mae: 0.0333 - learning_rate: 3.1250e-05\n",
      "Epoch 40/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 6.2469e-04 - mae: 0.0152 - val_loss: 0.0080 - val_mae: 0.0338 - learning_rate: 3.1250e-05\n",
      "Epoch 41/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 6.1530e-04 - mae: 0.0151 - val_loss: 0.0080 - val_mae: 0.0331 - learning_rate: 3.1250e-05\n",
      "Epoch 42/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 6.2411e-04 - mae: 0.0154 - val_loss: 0.0080 - val_mae: 0.0331 - learning_rate: 3.1250e-05\n",
      "Epoch 43/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 6.3194e-04 - mae: 0.0153 - val_loss: 0.0080 - val_mae: 0.0330 - learning_rate: 3.1250e-05\n",
      "Epoch 44/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 6.2166e-04 - mae: 0.0153 - val_loss: 0.0079 - val_mae: 0.0325 - learning_rate: 3.1250e-05\n",
      "Epoch 45/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 6.1698e-04 - mae: 0.0151 - val_loss: 0.0081 - val_mae: 0.0337 - learning_rate: 3.1250e-05\n",
      "Epoch 46/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 6.2789e-04 - mae: 0.0153 - val_loss: 0.0082 - val_mae: 0.0338 - learning_rate: 3.1250e-05\n",
      "Epoch 47/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 6.2058e-04 - mae: 0.0153 - val_loss: 0.0079 - val_mae: 0.0330 - learning_rate: 3.1250e-05\n",
      "Epoch 48/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 6.2028e-04 - mae: 0.0150 - val_loss: 0.0080 - val_mae: 0.0330 - learning_rate: 1.5625e-05\n",
      "Epoch 49/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 6.1450e-04 - mae: 0.0152 - val_loss: 0.0080 - val_mae: 0.0331 - learning_rate: 1.5625e-05\n",
      "Epoch 50/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 6.0588e-04 - mae: 0.0151 - val_loss: 0.0079 - val_mae: 0.0336 - learning_rate: 1.5625e-05\n",
      "\u001b[1m80/80\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step   \n",
      " âœ… Bellary - tomato | MAE=124.65, RMSE=308.44, RÂ²=0.7571, MAPE=12.97%, Acc=87.03%\n",
      "\n",
      "ğŸš€ Processing: Bellary | wheat\n",
      "Epoch 1/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0625 - mae: 0.1475 - val_loss: 0.0559 - val_mae: 0.1650 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0068 - mae: 0.0654 - val_loss: 0.0345 - val_mae: 0.1105 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0046 - mae: 0.0538 - val_loss: 0.0637 - val_mae: 0.2088 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0041 - mae: 0.0503 - val_loss: 0.0459 - val_mae: 0.1626 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0028 - mae: 0.0409 - val_loss: 0.0290 - val_mae: 0.1058 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0019 - mae: 0.0340 - val_loss: 0.0295 - val_mae: 0.1089 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0019 - mae: 0.0338 - val_loss: 0.0315 - val_mae: 0.1212 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0012 - mae: 0.0268 - val_loss: 0.0232 - val_mae: 0.0861 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0010 - mae: 0.0239 - val_loss: 0.0167 - val_mae: 0.0704 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 8.3748e-04 - mae: 0.0216 - val_loss: 0.0229 - val_mae: 0.0952 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 7.3005e-04 - mae: 0.0199 - val_loss: 0.0192 - val_mae: 0.0785 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 7.4160e-04 - mae: 0.0205 - val_loss: 0.0154 - val_mae: 0.0620 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 5.9659e-04 - mae: 0.0179 - val_loss: 0.0217 - val_mae: 0.0952 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 5.9141e-04 - mae: 0.0179 - val_loss: 0.0190 - val_mae: 0.0806 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 5.1258e-04 - mae: 0.0165 - val_loss: 0.0189 - val_mae: 0.0775 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 4.3442e-04 - mae: 0.0149 - val_loss: 0.0165 - val_mae: 0.0660 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 4.4419e-04 - mae: 0.0149 - val_loss: 0.0186 - val_mae: 0.0810 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 4.0863e-04 - mae: 0.0142 - val_loss: 0.0156 - val_mae: 0.0641 - learning_rate: 5.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 3.7616e-04 - mae: 0.0136 - val_loss: 0.0161 - val_mae: 0.0690 - learning_rate: 2.5000e-04\n",
      "\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step   \n",
      " âœ… Bellary - wheat | MAE=82.15, RMSE=231.48, RÂ²=0.8578, MAPE=3.34%, Acc=96.66%\n",
      "\n",
      "ğŸš€ Processing: Bidar | onion\n",
      "Epoch 1/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0538 - mae: 0.1320 - val_loss: 0.0210 - val_mae: 0.0475 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0053 - mae: 0.0557 - val_loss: 0.0171 - val_mae: 0.0510 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0040 - mae: 0.0490 - val_loss: 0.0177 - val_mae: 0.1005 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0036 - mae: 0.0462 - val_loss: 0.0218 - val_mae: 0.1298 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0031 - mae: 0.0423 - val_loss: 0.0169 - val_mae: 0.0960 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0021 - mae: 0.0351 - val_loss: 0.0156 - val_mae: 0.0788 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0017 - mae: 0.0318 - val_loss: 0.0186 - val_mae: 0.1160 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0015 - mae: 0.0295 - val_loss: 0.0138 - val_mae: 0.0673 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0014 - mae: 0.0281 - val_loss: 0.0134 - val_mae: 0.0505 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0011 - mae: 0.0248 - val_loss: 0.0142 - val_mae: 0.0844 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0010 - mae: 0.0244 - val_loss: 0.0152 - val_mae: 0.0993 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 8.2858e-04 - mae: 0.0214 - val_loss: 0.0138 - val_mae: 0.0822 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 7.0670e-04 - mae: 0.0199 - val_loss: 0.0123 - val_mae: 0.0542 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 6.3039e-04 - mae: 0.0179 - val_loss: 0.0123 - val_mae: 0.0595 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 5.9813e-04 - mae: 0.0174 - val_loss: 0.0121 - val_mae: 0.0676 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 5.6022e-04 - mae: 0.0172 - val_loss: 0.0119 - val_mae: 0.0655 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 5.7153e-04 - mae: 0.0172 - val_loss: 0.0121 - val_mae: 0.0681 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 5.6616e-04 - mae: 0.0170 - val_loss: 0.0118 - val_mae: 0.0448 - learning_rate: 5.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 5.1379e-04 - mae: 0.0162 - val_loss: 0.0124 - val_mae: 0.0735 - learning_rate: 5.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 4.8587e-04 - mae: 0.0156 - val_loss: 0.0114 - val_mae: 0.0612 - learning_rate: 5.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 4.4911e-04 - mae: 0.0152 - val_loss: 0.0119 - val_mae: 0.0690 - learning_rate: 5.0000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 4.8842e-04 - mae: 0.0157 - val_loss: 0.0113 - val_mae: 0.0631 - learning_rate: 5.0000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 4.1664e-04 - mae: 0.0141 - val_loss: 0.0122 - val_mae: 0.0789 - learning_rate: 5.0000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 3.7845e-04 - mae: 0.0133 - val_loss: 0.0109 - val_mae: 0.0567 - learning_rate: 2.5000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 3.6952e-04 - mae: 0.0131 - val_loss: 0.0111 - val_mae: 0.0608 - learning_rate: 2.5000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 3.4074e-04 - mae: 0.0127 - val_loss: 0.0111 - val_mae: 0.0625 - learning_rate: 2.5000e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 3.6596e-04 - mae: 0.0131 - val_loss: 0.0107 - val_mae: 0.0474 - learning_rate: 2.5000e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 3.1570e-04 - mae: 0.0121 - val_loss: 0.0106 - val_mae: 0.0480 - learning_rate: 2.5000e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 3.3748e-04 - mae: 0.0130 - val_loss: 0.0107 - val_mae: 0.0607 - learning_rate: 2.5000e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 3.3400e-04 - mae: 0.0125 - val_loss: 0.0109 - val_mae: 0.0394 - learning_rate: 2.5000e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 3.1431e-04 - mae: 0.0122 - val_loss: 0.0107 - val_mae: 0.0546 - learning_rate: 2.5000e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 3.0544e-04 - mae: 0.0116 - val_loss: 0.0106 - val_mae: 0.0479 - learning_rate: 1.2500e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 2.9751e-04 - mae: 0.0116 - val_loss: 0.0105 - val_mae: 0.0415 - learning_rate: 1.2500e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 2.8771e-04 - mae: 0.0116 - val_loss: 0.0104 - val_mae: 0.0561 - learning_rate: 1.2500e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 2.7628e-04 - mae: 0.0112 - val_loss: 0.0102 - val_mae: 0.0537 - learning_rate: 1.2500e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 2.7584e-04 - mae: 0.0113 - val_loss: 0.0103 - val_mae: 0.0526 - learning_rate: 1.2500e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 2.7826e-04 - mae: 0.0114 - val_loss: 0.0101 - val_mae: 0.0497 - learning_rate: 1.2500e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 2.7163e-04 - mae: 0.0111 - val_loss: 0.0102 - val_mae: 0.0510 - learning_rate: 1.2500e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 2.4746e-04 - mae: 0.0104 - val_loss: 0.0103 - val_mae: 0.0491 - learning_rate: 6.2500e-05\n",
      "Epoch 40/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 2.5110e-04 - mae: 0.0107 - val_loss: 0.0102 - val_mae: 0.0453 - learning_rate: 6.2500e-05\n",
      "Epoch 41/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 2.5993e-04 - mae: 0.0108 - val_loss: 0.0100 - val_mae: 0.0519 - learning_rate: 6.2500e-05\n",
      "Epoch 42/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 2.5477e-04 - mae: 0.0108 - val_loss: 0.0101 - val_mae: 0.0480 - learning_rate: 6.2500e-05\n",
      "Epoch 43/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 2.6597e-04 - mae: 0.0108 - val_loss: 0.0101 - val_mae: 0.0498 - learning_rate: 6.2500e-05\n",
      "Epoch 44/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 2.7297e-04 - mae: 0.0109 - val_loss: 0.0101 - val_mae: 0.0418 - learning_rate: 6.2500e-05\n",
      "Epoch 45/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 2.4322e-04 - mae: 0.0104 - val_loss: 0.0100 - val_mae: 0.0466 - learning_rate: 3.1250e-05\n",
      "Epoch 46/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 2.4469e-04 - mae: 0.0104 - val_loss: 0.0099 - val_mae: 0.0486 - learning_rate: 3.1250e-05\n",
      "Epoch 47/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 2.5852e-04 - mae: 0.0104 - val_loss: 0.0100 - val_mae: 0.0481 - learning_rate: 3.1250e-05\n",
      "Epoch 48/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 2.2930e-04 - mae: 0.0101 - val_loss: 0.0100 - val_mae: 0.0464 - learning_rate: 1.5625e-05\n",
      "Epoch 49/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 2.3547e-04 - mae: 0.0100 - val_loss: 0.0100 - val_mae: 0.0462 - learning_rate: 1.5625e-05\n",
      "Epoch 50/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 2.2844e-04 - mae: 0.0102 - val_loss: 0.0100 - val_mae: 0.0479 - learning_rate: 1.5625e-05\n",
      "\u001b[1m81/81\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step   \n",
      " âœ… Bidar - onion | MAE=62.25, RMSE=143.88, RÂ²=0.8479, MAPE=4.29%, Acc=95.71%\n",
      "\n",
      "ğŸš€ Processing: Bidar | wheat\n",
      "Epoch 1/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - loss: 0.0513 - mae: 0.1444 - val_loss: 0.0066 - val_mae: 0.0673 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0076 - mae: 0.0668 - val_loss: 0.0279 - val_mae: 0.1555 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0071 - mae: 0.0624 - val_loss: 0.0383 - val_mae: 0.1866 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0066 - mae: 0.0595 - val_loss: 0.0316 - val_mae: 0.1690 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0053 - mae: 0.0522 - val_loss: 0.0077 - val_mae: 0.0748 - learning_rate: 5.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0038 - mae: 0.0448 - val_loss: 0.0145 - val_mae: 0.1100 - learning_rate: 5.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0044 - mae: 0.0477 - val_loss: 0.0120 - val_mae: 0.0993 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0038 - mae: 0.0454 - val_loss: 0.0063 - val_mae: 0.0674 - learning_rate: 2.5000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0034 - mae: 0.0422 - val_loss: 0.0058 - val_mae: 0.0649 - learning_rate: 2.5000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0035 - mae: 0.0426 - val_loss: 0.0055 - val_mae: 0.0630 - learning_rate: 2.5000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0031 - mae: 0.0398 - val_loss: 0.0063 - val_mae: 0.0681 - learning_rate: 2.5000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0032 - mae: 0.0403 - val_loss: 0.0052 - val_mae: 0.0606 - learning_rate: 2.5000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0030 - mae: 0.0383 - val_loss: 0.0077 - val_mae: 0.0773 - learning_rate: 2.5000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0031 - mae: 0.0395 - val_loss: 0.0078 - val_mae: 0.0780 - learning_rate: 2.5000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0031 - mae: 0.0395 - val_loss: 0.0063 - val_mae: 0.0686 - learning_rate: 2.5000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0027 - mae: 0.0366 - val_loss: 0.0039 - val_mae: 0.0507 - learning_rate: 1.2500e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0027 - mae: 0.0363 - val_loss: 0.0046 - val_mae: 0.0568 - learning_rate: 1.2500e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0028 - mae: 0.0373 - val_loss: 0.0037 - val_mae: 0.0498 - learning_rate: 1.2500e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0026 - mae: 0.0355 - val_loss: 0.0040 - val_mae: 0.0523 - learning_rate: 1.2500e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0027 - mae: 0.0358 - val_loss: 0.0046 - val_mae: 0.0571 - learning_rate: 1.2500e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0026 - mae: 0.0357 - val_loss: 0.0046 - val_mae: 0.0570 - learning_rate: 1.2500e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0023 - mae: 0.0330 - val_loss: 0.0031 - val_mae: 0.0441 - learning_rate: 6.2500e-05\n",
      "Epoch 23/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0022 - mae: 0.0319 - val_loss: 0.0034 - val_mae: 0.0467 - learning_rate: 6.2500e-05\n",
      "Epoch 24/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0023 - mae: 0.0331 - val_loss: 0.0036 - val_mae: 0.0491 - learning_rate: 6.2500e-05\n",
      "Epoch 25/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0023 - mae: 0.0330 - val_loss: 0.0038 - val_mae: 0.0507 - learning_rate: 6.2500e-05\n",
      "Epoch 26/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0021 - mae: 0.0311 - val_loss: 0.0029 - val_mae: 0.0422 - learning_rate: 3.1250e-05\n",
      "Epoch 27/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0020 - mae: 0.0307 - val_loss: 0.0028 - val_mae: 0.0414 - learning_rate: 3.1250e-05\n",
      "Epoch 28/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0020 - mae: 0.0302 - val_loss: 0.0029 - val_mae: 0.0422 - learning_rate: 3.1250e-05\n",
      "Epoch 29/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0021 - mae: 0.0305 - val_loss: 0.0030 - val_mae: 0.0429 - learning_rate: 3.1250e-05\n",
      "Epoch 30/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0020 - mae: 0.0302 - val_loss: 0.0027 - val_mae: 0.0396 - learning_rate: 1.5625e-05\n",
      "Epoch 31/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0020 - mae: 0.0294 - val_loss: 0.0025 - val_mae: 0.0383 - learning_rate: 1.5625e-05\n",
      "Epoch 32/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0020 - mae: 0.0300 - val_loss: 0.0026 - val_mae: 0.0386 - learning_rate: 1.5625e-05\n",
      "Epoch 33/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0020 - mae: 0.0300 - val_loss: 0.0026 - val_mae: 0.0386 - learning_rate: 1.5625e-05\n",
      "Epoch 34/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0020 - mae: 0.0294 - val_loss: 0.0026 - val_mae: 0.0393 - learning_rate: 1.5625e-05\n",
      "Epoch 35/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0019 - mae: 0.0296 - val_loss: 0.0026 - val_mae: 0.0387 - learning_rate: 7.8125e-06\n",
      "Epoch 36/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0019 - mae: 0.0291 - val_loss: 0.0026 - val_mae: 0.0388 - learning_rate: 7.8125e-06\n",
      "Epoch 37/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0019 - mae: 0.0293 - val_loss: 0.0026 - val_mae: 0.0385 - learning_rate: 7.8125e-06\n",
      "Epoch 38/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0019 - mae: 0.0291 - val_loss: 0.0025 - val_mae: 0.0380 - learning_rate: 3.9063e-06\n",
      "Epoch 39/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0019 - mae: 0.0288 - val_loss: 0.0026 - val_mae: 0.0385 - learning_rate: 3.9063e-06\n",
      "Epoch 40/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0019 - mae: 0.0292 - val_loss: 0.0025 - val_mae: 0.0384 - learning_rate: 3.9063e-06\n",
      "Epoch 41/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0019 - mae: 0.0286 - val_loss: 0.0025 - val_mae: 0.0377 - learning_rate: 1.9531e-06\n",
      "Epoch 42/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0019 - mae: 0.0288 - val_loss: 0.0025 - val_mae: 0.0377 - learning_rate: 1.9531e-06\n",
      "Epoch 43/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0019 - mae: 0.0289 - val_loss: 0.0025 - val_mae: 0.0374 - learning_rate: 1.9531e-06\n",
      "Epoch 44/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0019 - mae: 0.0289 - val_loss: 0.0025 - val_mae: 0.0377 - learning_rate: 1.0000e-06\n",
      "Epoch 45/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0019 - mae: 0.0286 - val_loss: 0.0025 - val_mae: 0.0380 - learning_rate: 1.0000e-06\n",
      "Epoch 46/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0019 - mae: 0.0285 - val_loss: 0.0025 - val_mae: 0.0378 - learning_rate: 1.0000e-06\n",
      "Epoch 47/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0019 - mae: 0.0290 - val_loss: 0.0025 - val_mae: 0.0375 - learning_rate: 1.0000e-06\n",
      "Epoch 48/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0019 - mae: 0.0287 - val_loss: 0.0025 - val_mae: 0.0375 - learning_rate: 1.0000e-06\n",
      "Epoch 49/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0018 - mae: 0.0284 - val_loss: 0.0025 - val_mae: 0.0377 - learning_rate: 1.0000e-06\n",
      "Epoch 50/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0019 - mae: 0.0286 - val_loss: 0.0025 - val_mae: 0.0374 - learning_rate: 1.0000e-06\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step   \n",
      " âœ… Bidar - wheat | MAE=95.58, RMSE=146.16, RÂ²=0.9203, MAPE=4.13%, Acc=95.87%\n",
      "\n",
      "ğŸš€ Processing: Bijapur | onion\n",
      "Epoch 1/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0333 - mae: 0.1027 - val_loss: 0.0013 - val_mae: 0.0274 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0037 - mae: 0.0469 - val_loss: 0.0010 - val_mae: 0.0244 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0026 - mae: 0.0392 - val_loss: 0.0035 - val_mae: 0.0523 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0022 - mae: 0.0354 - val_loss: 9.3202e-04 - val_mae: 0.0225 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0016 - mae: 0.0302 - val_loss: 7.3497e-04 - val_mae: 0.0183 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0013 - mae: 0.0264 - val_loss: 6.9296e-04 - val_mae: 0.0175 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0013 - mae: 0.0258 - val_loss: 8.1991e-04 - val_mae: 0.0204 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0011 - mae: 0.0233 - val_loss: 7.3993e-04 - val_mae: 0.0179 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 8.3687e-04 - mae: 0.0198 - val_loss: 8.2792e-04 - val_mae: 0.0206 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 7.6603e-04 - mae: 0.0188 - val_loss: 7.3261e-04 - val_mae: 0.0179 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 7.8784e-04 - mae: 0.0190 - val_loss: 7.5135e-04 - val_mae: 0.0183 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 7.1940e-04 - mae: 0.0177 - val_loss: 8.5150e-04 - val_mae: 0.0211 - learning_rate: 2.5000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 6.8850e-04 - mae: 0.0174 - val_loss: 7.3076e-04 - val_mae: 0.0182 - learning_rate: 2.5000e-04\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step   \n",
      " âœ… Bijapur - onion | MAE=120.31, RMSE=235.04, RÂ²=0.885, MAPE=9.47%, Acc=90.53%\n",
      "\n",
      "ğŸš€ Processing: Bijapur | wheat\n",
      "Epoch 1/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0442 - mae: 0.1424 - val_loss: 0.0050 - val_mae: 0.0547 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0096 - mae: 0.0756 - val_loss: 0.0018 - val_mae: 0.0359 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0062 - mae: 0.0604 - val_loss: 9.9130e-04 - val_mae: 0.0259 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0050 - mae: 0.0540 - val_loss: 5.8853e-04 - val_mae: 0.0187 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0041 - mae: 0.0490 - val_loss: 0.0012 - val_mae: 0.0289 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0035 - mae: 0.0438 - val_loss: 8.3254e-04 - val_mae: 0.0226 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0029 - mae: 0.0397 - val_loss: 0.0011 - val_mae: 0.0261 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0027 - mae: 0.0379 - val_loss: 7.3977e-04 - val_mae: 0.0214 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0024 - mae: 0.0358 - val_loss: 7.1673e-04 - val_mae: 0.0213 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0023 - mae: 0.0348 - val_loss: 0.0010 - val_mae: 0.0257 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0021 - mae: 0.0330 - val_loss: 6.2977e-04 - val_mae: 0.0199 - learning_rate: 2.5000e-04\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step   \n",
      " âœ… Bijapur - wheat | MAE=208.77, RMSE=269.59, RÂ²=0.8453, MAPE=9.69%, Acc=90.31%\n",
      "\n",
      "ğŸš€ Processing: Chamrajnagar | onion\n",
      "Epoch 1/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.1105 - mae: 0.1727 - val_loss: 0.0508 - val_mae: 0.1862 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0079 - mae: 0.0652 - val_loss: 0.0589 - val_mae: 0.2165 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0061 - mae: 0.0586 - val_loss: 0.0231 - val_mae: 0.1266 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0049 - mae: 0.0526 - val_loss: 0.0121 - val_mae: 0.0870 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0038 - mae: 0.0460 - val_loss: 0.0058 - val_mae: 0.0532 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0033 - mae: 0.0433 - val_loss: 0.0133 - val_mae: 0.1040 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0026 - mae: 0.0373 - val_loss: 0.0051 - val_mae: 0.0550 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0023 - mae: 0.0348 - val_loss: 0.0047 - val_mae: 0.0538 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0019 - mae: 0.0316 - val_loss: 0.0051 - val_mae: 0.0590 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0017 - mae: 0.0287 - val_loss: 0.0036 - val_mae: 0.0426 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0016 - mae: 0.0286 - val_loss: 0.0033 - val_mae: 0.0389 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0015 - mae: 0.0274 - val_loss: 0.0050 - val_mae: 0.0478 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0013 - mae: 0.0250 - val_loss: 0.0039 - val_mae: 0.0398 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0011 - mae: 0.0228 - val_loss: 0.0033 - val_mae: 0.0348 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0011 - mae: 0.0217 - val_loss: 0.0026 - val_mae: 0.0304 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0011 - mae: 0.0224 - val_loss: 0.0034 - val_mae: 0.0363 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 9.8702e-04 - mae: 0.0212 - val_loss: 0.0025 - val_mae: 0.0349 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 9.7482e-04 - mae: 0.0215 - val_loss: 0.0025 - val_mae: 0.0310 - learning_rate: 5.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 8.7702e-04 - mae: 0.0193 - val_loss: 0.0041 - val_mae: 0.0438 - learning_rate: 2.5000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 8.3704e-04 - mae: 0.0190 - val_loss: 0.0032 - val_mae: 0.0364 - learning_rate: 2.5000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 7.8002e-04 - mae: 0.0182 - val_loss: 0.0048 - val_mae: 0.0490 - learning_rate: 2.5000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 8.0311e-04 - mae: 0.0182 - val_loss: 0.0032 - val_mae: 0.0358 - learning_rate: 1.2500e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 7.8841e-04 - mae: 0.0181 - val_loss: 0.0028 - val_mae: 0.0321 - learning_rate: 1.2500e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 7.3520e-04 - mae: 0.0176 - val_loss: 0.0025 - val_mae: 0.0308 - learning_rate: 1.2500e-04\n",
      "\u001b[1m84/84\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step   \n",
      " âœ… Chamrajnagar - onion | MAE=107.48, RMSE=191.44, RÂ²=0.9697, MAPE=6.37%, Acc=93.63%\n",
      "\n",
      "ğŸš€ Processing: Chamrajnagar | tomato\n",
      "Epoch 1/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - loss: 0.0588 - mae: 0.1296 - val_loss: 0.0073 - val_mae: 0.0708 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0040 - mae: 0.0500 - val_loss: 0.0026 - val_mae: 0.0334 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0029 - mae: 0.0430 - val_loss: 0.0030 - val_mae: 0.0340 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0023 - mae: 0.0379 - val_loss: 0.0051 - val_mae: 0.0391 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0016 - mae: 0.0314 - val_loss: 0.0084 - val_mae: 0.0515 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0011 - mae: 0.0259 - val_loss: 0.0070 - val_mae: 0.0453 - learning_rate: 5.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 9.4267e-04 - mae: 0.0242 - val_loss: 0.0078 - val_mae: 0.0474 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 7.4511e-04 - mae: 0.0213 - val_loss: 0.0087 - val_mae: 0.0508 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 7.1435e-04 - mae: 0.0211 - val_loss: 0.0076 - val_mae: 0.0479 - learning_rate: 2.5000e-04\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step   \n",
      " âœ… Chamrajnagar - tomato | MAE=430.72, RMSE=625.1, RÂ²=0.6603, MAPE=42.71%, Acc=57.29%\n",
      "\n",
      "ğŸš€ Processing: Chamrajnagar | wheat\n",
      " âš  Sparse series; falling back to crop-level aggregated series.\n",
      "Epoch 1/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - loss: 0.0606 - mae: 0.1494 - val_loss: 0.0440 - val_mae: 0.1785 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0078 - mae: 0.0702 - val_loss: 0.0245 - val_mae: 0.1274 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0053 - mae: 0.0575 - val_loss: 0.0424 - val_mae: 0.1878 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0042 - mae: 0.0514 - val_loss: 0.0286 - val_mae: 0.1491 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0029 - mae: 0.0420 - val_loss: 0.0186 - val_mae: 0.1139 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0026 - mae: 0.0400 - val_loss: 0.0144 - val_mae: 0.0969 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0023 - mae: 0.0374 - val_loss: 0.0170 - val_mae: 0.1115 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0020 - mae: 0.0353 - val_loss: 0.0134 - val_mae: 0.0955 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0017 - mae: 0.0316 - val_loss: 0.0111 - val_mae: 0.0858 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0016 - mae: 0.0304 - val_loss: 0.0065 - val_mae: 0.0598 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0012 - mae: 0.0262 - val_loss: 0.0080 - val_mae: 0.0700 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0011 - mae: 0.0257 - val_loss: 0.0047 - val_mae: 0.0491 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0011 - mae: 0.0246 - val_loss: 0.0054 - val_mae: 0.0535 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 9.4503e-04 - mae: 0.0229 - val_loss: 0.0149 - val_mae: 0.1109 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 9.4534e-04 - mae: 0.0227 - val_loss: 0.0046 - val_mae: 0.0489 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 6.3905e-04 - mae: 0.0181 - val_loss: 0.0042 - val_mae: 0.0461 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 6.7498e-04 - mae: 0.0187 - val_loss: 0.0036 - val_mae: 0.0421 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 6.1682e-04 - mae: 0.0178 - val_loss: 0.0039 - val_mae: 0.0453 - learning_rate: 5.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 6.4970e-04 - mae: 0.0183 - val_loss: 0.0040 - val_mae: 0.0453 - learning_rate: 5.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 6.1117e-04 - mae: 0.0177 - val_loss: 0.0034 - val_mae: 0.0420 - learning_rate: 5.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 5.6943e-04 - mae: 0.0168 - val_loss: 0.0028 - val_mae: 0.0386 - learning_rate: 5.0000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 6.7873e-04 - mae: 0.0186 - val_loss: 0.0022 - val_mae: 0.0362 - learning_rate: 5.0000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 5.8731e-04 - mae: 0.0169 - val_loss: 0.0030 - val_mae: 0.0391 - learning_rate: 5.0000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 5.4073e-04 - mae: 0.0161 - val_loss: 0.0023 - val_mae: 0.0354 - learning_rate: 5.0000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 5.4520e-04 - mae: 0.0163 - val_loss: 0.0023 - val_mae: 0.0363 - learning_rate: 5.0000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 4.4913e-04 - mae: 0.0145 - val_loss: 0.0028 - val_mae: 0.0373 - learning_rate: 2.5000e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 4.6686e-04 - mae: 0.0148 - val_loss: 0.0026 - val_mae: 0.0368 - learning_rate: 2.5000e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 4.5352e-04 - mae: 0.0145 - val_loss: 0.0023 - val_mae: 0.0363 - learning_rate: 2.5000e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 4.4151e-04 - mae: 0.0142 - val_loss: 0.0025 - val_mae: 0.0361 - learning_rate: 1.2500e-04\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step   \n",
      " âœ… Chamrajnagar - wheat | MAE=58.14, RMSE=76.55, RÂ²=0.977, MAPE=2.54%, Acc=97.46%\n",
      "\n",
      "ğŸš€ Processing: Chikmagalur | capsicum\n",
      "Epoch 1/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 21ms/step - loss: 0.0708 - mae: 0.1909 - val_loss: 0.0914 - val_mae: 0.2173 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0088 - mae: 0.0738 - val_loss: 0.0677 - val_mae: 0.2021 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0079 - mae: 0.0704 - val_loss: 0.0548 - val_mae: 0.1882 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0070 - mae: 0.0659 - val_loss: 0.0455 - val_mae: 0.1724 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0050 - mae: 0.0561 - val_loss: 0.0297 - val_mae: 0.1396 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0042 - mae: 0.0510 - val_loss: 0.0306 - val_mae: 0.1436 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0049 - mae: 0.0557 - val_loss: 0.0259 - val_mae: 0.1154 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0031 - mae: 0.0434 - val_loss: 0.0339 - val_mae: 0.1533 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0028 - mae: 0.0412 - val_loss: 0.0328 - val_mae: 0.1460 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0031 - mae: 0.0440 - val_loss: 0.0331 - val_mae: 0.1476 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0029 - mae: 0.0420 - val_loss: 0.0272 - val_mae: 0.1127 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0022 - mae: 0.0363 - val_loss: 0.0246 - val_mae: 0.1139 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0019 - mae: 0.0344 - val_loss: 0.0238 - val_mae: 0.1187 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0020 - mae: 0.0340 - val_loss: 0.0239 - val_mae: 0.1180 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0020 - mae: 0.0341 - val_loss: 0.0227 - val_mae: 0.1092 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0021 - mae: 0.0356 - val_loss: 0.0235 - val_mae: 0.1247 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0021 - mae: 0.0362 - val_loss: 0.0212 - val_mae: 0.1104 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0019 - mae: 0.0333 - val_loss: 0.0212 - val_mae: 0.1134 - learning_rate: 5.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0017 - mae: 0.0318 - val_loss: 0.0219 - val_mae: 0.1207 - learning_rate: 5.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0016 - mae: 0.0311 - val_loss: 0.0217 - val_mae: 0.1200 - learning_rate: 5.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0016 - mae: 0.0306 - val_loss: 0.0203 - val_mae: 0.1102 - learning_rate: 2.5000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0014 - mae: 0.0279 - val_loss: 0.0206 - val_mae: 0.1127 - learning_rate: 2.5000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0014 - mae: 0.0279 - val_loss: 0.0205 - val_mae: 0.1093 - learning_rate: 2.5000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0013 - mae: 0.0272 - val_loss: 0.0204 - val_mae: 0.1076 - learning_rate: 2.5000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0013 - mae: 0.0264 - val_loss: 0.0196 - val_mae: 0.1062 - learning_rate: 1.2500e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0012 - mae: 0.0261 - val_loss: 0.0199 - val_mae: 0.1109 - learning_rate: 1.2500e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0012 - mae: 0.0262 - val_loss: 0.0197 - val_mae: 0.1070 - learning_rate: 1.2500e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0012 - mae: 0.0267 - val_loss: 0.0196 - val_mae: 0.1085 - learning_rate: 1.2500e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0012 - mae: 0.0258 - val_loss: 0.0195 - val_mae: 0.1069 - learning_rate: 6.2500e-05\n",
      "Epoch 30/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0011 - mae: 0.0245 - val_loss: 0.0196 - val_mae: 0.1068 - learning_rate: 6.2500e-05\n",
      "Epoch 31/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0012 - mae: 0.0255 - val_loss: 0.0197 - val_mae: 0.1092 - learning_rate: 6.2500e-05\n",
      "Epoch 32/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0012 - mae: 0.0257 - val_loss: 0.0192 - val_mae: 0.1045 - learning_rate: 6.2500e-05\n",
      "Epoch 33/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0012 - mae: 0.0255 - val_loss: 0.0191 - val_mae: 0.1057 - learning_rate: 6.2500e-05\n",
      "Epoch 34/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0012 - mae: 0.0253 - val_loss: 0.0192 - val_mae: 0.1057 - learning_rate: 6.2500e-05\n",
      "Epoch 35/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0011 - mae: 0.0240 - val_loss: 0.0195 - val_mae: 0.1075 - learning_rate: 6.2500e-05\n",
      "Epoch 36/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0011 - mae: 0.0248 - val_loss: 0.0193 - val_mae: 0.1068 - learning_rate: 6.2500e-05\n",
      "Epoch 37/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0011 - mae: 0.0241 - val_loss: 0.0189 - val_mae: 0.1048 - learning_rate: 3.1250e-05\n",
      "Epoch 38/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0010 - mae: 0.0238 - val_loss: 0.0191 - val_mae: 0.1070 - learning_rate: 3.1250e-05\n",
      "Epoch 39/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0011 - mae: 0.0248 - val_loss: 0.0189 - val_mae: 0.1062 - learning_rate: 3.1250e-05\n",
      "Epoch 40/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0011 - mae: 0.0242 - val_loss: 0.0191 - val_mae: 0.1066 - learning_rate: 3.1250e-05\n",
      "Epoch 41/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0011 - mae: 0.0247 - val_loss: 0.0189 - val_mae: 0.1051 - learning_rate: 1.5625e-05\n",
      "Epoch 42/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0011 - mae: 0.0241 - val_loss: 0.0185 - val_mae: 0.1030 - learning_rate: 1.5625e-05\n",
      "Epoch 43/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0011 - mae: 0.0243 - val_loss: 0.0184 - val_mae: 0.1022 - learning_rate: 1.5625e-05\n",
      "Epoch 44/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0010 - mae: 0.0238 - val_loss: 0.0186 - val_mae: 0.1039 - learning_rate: 1.5625e-05\n",
      "Epoch 45/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0011 - mae: 0.0246 - val_loss: 0.0184 - val_mae: 0.1021 - learning_rate: 1.5625e-05\n",
      "Epoch 46/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0011 - mae: 0.0243 - val_loss: 0.0188 - val_mae: 0.1041 - learning_rate: 1.5625e-05\n",
      "Epoch 47/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0011 - mae: 0.0245 - val_loss: 0.0186 - val_mae: 0.1031 - learning_rate: 7.8125e-06\n",
      "Epoch 48/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 9.8943e-04 - mae: 0.0232 - val_loss: 0.0185 - val_mae: 0.1033 - learning_rate: 7.8125e-06\n",
      "Epoch 49/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0011 - mae: 0.0239 - val_loss: 0.0188 - val_mae: 0.1051 - learning_rate: 7.8125e-06\n",
      "Epoch 50/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0011 - mae: 0.0244 - val_loss: 0.0187 - val_mae: 0.1045 - learning_rate: 3.9063e-06\n",
      "\u001b[1m32/32\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step \n",
      " âœ… Chikmagalur - capsicum | MAE=121.71, RMSE=227.41, RÂ²=0.8585, MAPE=6.63%, Acc=93.37%\n",
      "\n",
      "ğŸš€ Processing: Chikmagalur | onion\n",
      "Epoch 1/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - loss: 0.0713 - mae: 0.1564 - val_loss: 0.0148 - val_mae: 0.0792 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0072 - mae: 0.0654 - val_loss: 0.0052 - val_mae: 0.0474 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0043 - mae: 0.0514 - val_loss: 0.0030 - val_mae: 0.0394 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0034 - mae: 0.0456 - val_loss: 0.0033 - val_mae: 0.0435 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0028 - mae: 0.0410 - val_loss: 0.0020 - val_mae: 0.0319 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0025 - mae: 0.0391 - val_loss: 0.0017 - val_mae: 0.0278 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0017 - mae: 0.0320 - val_loss: 0.0030 - val_mae: 0.0445 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0015 - mae: 0.0301 - val_loss: 0.0017 - val_mae: 0.0287 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0014 - mae: 0.0284 - val_loss: 0.0018 - val_mae: 0.0303 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0011 - mae: 0.0249 - val_loss: 0.0015 - val_mae: 0.0272 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0011 - mae: 0.0243 - val_loss: 0.0014 - val_mae: 0.0265 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0010 - mae: 0.0237 - val_loss: 0.0018 - val_mae: 0.0309 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0010 - mae: 0.0239 - val_loss: 0.0014 - val_mae: 0.0258 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 9.5752e-04 - mae: 0.0233 - val_loss: 0.0019 - val_mae: 0.0302 - learning_rate: 2.5000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 9.1312e-04 - mae: 0.0224 - val_loss: 0.0020 - val_mae: 0.0329 - learning_rate: 2.5000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 9.1492e-04 - mae: 0.0223 - val_loss: 0.0018 - val_mae: 0.0293 - learning_rate: 2.5000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 8.4118e-04 - mae: 0.0213 - val_loss: 0.0018 - val_mae: 0.0293 - learning_rate: 1.2500e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 8.2233e-04 - mae: 0.0210 - val_loss: 0.0017 - val_mae: 0.0278 - learning_rate: 1.2500e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 8.6682e-04 - mae: 0.0217 - val_loss: 0.0017 - val_mae: 0.0276 - learning_rate: 1.2500e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 7.8765e-04 - mae: 0.0203 - val_loss: 0.0015 - val_mae: 0.0261 - learning_rate: 6.2500e-05\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step   \n",
      " âœ… Chikmagalur - onion | MAE=83.33, RMSE=125.93, RÂ²=0.9688, MAPE=5.26%, Acc=94.74%\n",
      "\n",
      "ğŸš€ Processing: Chikmagalur | tomato\n",
      "Epoch 1/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - loss: 0.0762 - mae: 0.1592 - val_loss: 0.0287 - val_mae: 0.1257 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0076 - mae: 0.0672 - val_loss: 0.0256 - val_mae: 0.1322 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0055 - mae: 0.0575 - val_loss: 0.0178 - val_mae: 0.1114 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0039 - mae: 0.0488 - val_loss: 0.0117 - val_mae: 0.0854 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0032 - mae: 0.0434 - val_loss: 0.0096 - val_mae: 0.0732 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0021 - mae: 0.0346 - val_loss: 0.0091 - val_mae: 0.0726 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0017 - mae: 0.0311 - val_loss: 0.0081 - val_mae: 0.0670 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0014 - mae: 0.0283 - val_loss: 0.0077 - val_mae: 0.0644 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0013 - mae: 0.0263 - val_loss: 0.0065 - val_mae: 0.0581 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0012 - mae: 0.0250 - val_loss: 0.0074 - val_mae: 0.0645 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0010 - mae: 0.0238 - val_loss: 0.0063 - val_mae: 0.0564 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 9.9604e-04 - mae: 0.0229 - val_loss: 0.0071 - val_mae: 0.0616 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 9.3056e-04 - mae: 0.0217 - val_loss: 0.0075 - val_mae: 0.0647 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 8.9504e-04 - mae: 0.0215 - val_loss: 0.0077 - val_mae: 0.0657 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 8.6531e-04 - mae: 0.0210 - val_loss: 0.0070 - val_mae: 0.0600 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 8.5474e-04 - mae: 0.0208 - val_loss: 0.0064 - val_mae: 0.0551 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 8.2661e-04 - mae: 0.0204 - val_loss: 0.0065 - val_mae: 0.0558 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 7.6612e-04 - mae: 0.0194 - val_loss: 0.0066 - val_mae: 0.0556 - learning_rate: 2.5000e-04\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step   \n",
      " âœ… Chikmagalur - tomato | MAE=161.61, RMSE=253.85, RÂ²=0.8749, MAPE=14.46%, Acc=85.54%\n",
      "\n",
      "ğŸš€ Processing: Chikmagalur | wheat\n",
      "Epoch 1/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - loss: 0.0454 - mae: 0.1522 - val_loss: 5.8834e-04 - val_mae: 0.0181 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0070 - mae: 0.0659 - val_loss: 0.0076 - val_mae: 0.0851 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0042 - mae: 0.0515 - val_loss: 8.8080e-04 - val_mae: 0.0228 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0023 - mae: 0.0378 - val_loss: 0.0031 - val_mae: 0.0503 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0017 - mae: 0.0321 - val_loss: 6.5799e-04 - val_mae: 0.0194 - learning_rate: 5.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0014 - mae: 0.0293 - val_loss: 0.0014 - val_mae: 0.0322 - learning_rate: 5.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0013 - mae: 0.0284 - val_loss: 0.0026 - val_mae: 0.0483 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0011 - mae: 0.0264 - val_loss: 4.7034e-04 - val_mae: 0.0179 - learning_rate: 2.5000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 9.9205e-04 - mae: 0.0246 - val_loss: 7.3055e-04 - val_mae: 0.0214 - learning_rate: 2.5000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0011 - mae: 0.0256 - val_loss: 3.4769e-04 - val_mae: 0.0143 - learning_rate: 2.5000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 9.3464e-04 - mae: 0.0236 - val_loss: 5.1353e-04 - val_mae: 0.0177 - learning_rate: 2.5000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 9.4222e-04 - mae: 0.0238 - val_loss: 8.3433e-04 - val_mae: 0.0260 - learning_rate: 2.5000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 8.6692e-04 - mae: 0.0229 - val_loss: 2.6372e-04 - val_mae: 0.0126 - learning_rate: 2.5000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 8.4731e-04 - mae: 0.0225 - val_loss: 2.9088e-04 - val_mae: 0.0133 - learning_rate: 1.2500e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 7.1266e-04 - mae: 0.0203 - val_loss: 3.3692e-04 - val_mae: 0.0142 - learning_rate: 1.2500e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 7.1959e-04 - mae: 0.0205 - val_loss: 2.0895e-04 - val_mae: 0.0103 - learning_rate: 1.2500e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 7.1085e-04 - mae: 0.0205 - val_loss: 2.8293e-04 - val_mae: 0.0126 - learning_rate: 1.2500e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 7.0444e-04 - mae: 0.0204 - val_loss: 2.7283e-04 - val_mae: 0.0118 - learning_rate: 1.2500e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 6.6031e-04 - mae: 0.0196 - val_loss: 2.3237e-04 - val_mae: 0.0108 - learning_rate: 1.2500e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 6.4842e-04 - mae: 0.0193 - val_loss: 3.7245e-04 - val_mae: 0.0152 - learning_rate: 6.2500e-05\n",
      "Epoch 21/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 6.2803e-04 - mae: 0.0190 - val_loss: 3.5336e-04 - val_mae: 0.0152 - learning_rate: 6.2500e-05\n",
      "Epoch 22/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 6.3957e-04 - mae: 0.0193 - val_loss: 4.7667e-04 - val_mae: 0.0177 - learning_rate: 6.2500e-05\n",
      "Epoch 23/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 6.4833e-04 - mae: 0.0191 - val_loss: 5.7141e-04 - val_mae: 0.0210 - learning_rate: 3.1250e-05\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step   \n",
      " âœ… Chikmagalur - wheat | MAE=28.28, RMSE=38.26, RÂ²=0.9938, MAPE=1.45%, Acc=98.55%\n",
      "\n",
      "ğŸš€ Processing: Chitradurga | onion\n",
      "Epoch 1/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - loss: 0.0375 - mae: 0.1304 - val_loss: 0.0172 - val_mae: 0.1302 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0076 - mae: 0.0653 - val_loss: 0.0022 - val_mae: 0.0405 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0048 - mae: 0.0508 - val_loss: 7.8249e-04 - val_mae: 0.0250 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0037 - mae: 0.0445 - val_loss: 0.0013 - val_mae: 0.0318 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0033 - mae: 0.0426 - val_loss: 4.9571e-04 - val_mae: 0.0175 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0027 - mae: 0.0373 - val_loss: 1.7956e-04 - val_mae: 0.0100 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0022 - mae: 0.0327 - val_loss: 0.0011 - val_mae: 0.0323 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0021 - mae: 0.0324 - val_loss: 1.6654e-04 - val_mae: 0.0073 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0021 - mae: 0.0332 - val_loss: 6.2836e-04 - val_mae: 0.0221 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 5.3800e-04 - val_mae: 0.0214 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 3.1405e-04 - val_mae: 0.0153 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0014 - mae: 0.0251 - val_loss: 4.4719e-04 - val_mae: 0.0192 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0012 - mae: 0.0218 - val_loss: 5.5954e-04 - val_mae: 0.0219 - learning_rate: 2.5000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0011 - mae: 0.0207 - val_loss: 4.7143e-04 - val_mae: 0.0193 - learning_rate: 2.5000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0012 - mae: 0.0214 - val_loss: 0.0012 - val_mae: 0.0336 - learning_rate: 2.5000e-04\n",
      "\u001b[1m81/81\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step   \n",
      " âœ… Chitradurga - onion | MAE=42.53, RMSE=73.68, RÂ²=0.9739, MAPE=3.2%, Acc=96.8%\n",
      "\n",
      "ğŸš€ Processing: Chitradurga | tomato\n",
      "Epoch 1/50\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0668 - mae: 0.1660 - val_loss: 7.4905e-06 - val_mae: 0.0027 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0091 - mae: 0.0716 - val_loss: 0.0017 - val_mae: 0.0413 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0073 - mae: 0.0649 - val_loss: 0.0018 - val_mae: 0.0420 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 0.0050 - mae: 0.0528 - val_loss: 9.6085e-06 - val_mae: 0.0031 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0033 - mae: 0.0434 - val_loss: 1.8670e-04 - val_mae: 0.0137 - learning_rate: 5.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0025 - mae: 0.0385 - val_loss: 0.0040 - val_mae: 0.0632 - learning_rate: 5.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0022 - mae: 0.0362 - val_loss: 5.9983e-04 - val_mae: 0.0245 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0021 - mae: 0.0348 - val_loss: 6.1921e-04 - val_mae: 0.0249 - learning_rate: 2.5000e-04\n",
      "\u001b[1m69/69\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step  \n",
      " âœ… Chitradurga - tomato | MAE=285.4, RMSE=463.0, RÂ²=0.7942, MAPE=33.79%, Acc=66.21%\n",
      "\n",
      "ğŸš€ Processing: Chitradurga | wheat\n",
      "Epoch 1/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.1356 - mae: 0.2363 - val_loss: 0.0569 - val_mae: 0.2372 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0217 - mae: 0.1220 - val_loss: 0.0374 - val_mae: 0.1923 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0082 - mae: 0.0711 - val_loss: 0.0014 - val_mae: 0.0346 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0048 - mae: 0.0551 - val_loss: 1.5978e-04 - val_mae: 0.0105 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0038 - mae: 0.0484 - val_loss: 2.4797e-04 - val_mae: 0.0125 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0031 - mae: 0.0429 - val_loss: 6.0348e-04 - val_mae: 0.0222 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0027 - mae: 0.0410 - val_loss: 1.4373e-04 - val_mae: 0.0098 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0021 - mae: 0.0359 - val_loss: 1.1382e-04 - val_mae: 0.0087 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0020 - mae: 0.0344 - val_loss: 0.0024 - val_mae: 0.0479 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0019 - mae: 0.0338 - val_loss: 9.2156e-04 - val_mae: 0.0289 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0015 - mae: 0.0301 - val_loss: 1.5594e-04 - val_mae: 0.0099 - learning_rate: 2.5000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0015 - mae: 0.0292 - val_loss: 1.0343e-04 - val_mae: 0.0082 - learning_rate: 2.5000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0014 - mae: 0.0285 - val_loss: 3.6789e-04 - val_mae: 0.0156 - learning_rate: 2.5000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0013 - mae: 0.0279 - val_loss: 2.3956e-04 - val_mae: 0.0121 - learning_rate: 1.2500e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0013 - mae: 0.0279 - val_loss: 1.6329e-04 - val_mae: 0.0104 - learning_rate: 1.2500e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0012 - mae: 0.0268 - val_loss: 2.2714e-04 - val_mae: 0.0120 - learning_rate: 1.2500e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0012 - mae: 0.0261 - val_loss: 2.4081e-04 - val_mae: 0.0123 - learning_rate: 6.2500e-05\n",
      "Epoch 18/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0012 - mae: 0.0263 - val_loss: 2.6021e-04 - val_mae: 0.0129 - learning_rate: 6.2500e-05\n",
      "Epoch 19/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0012 - mae: 0.0260 - val_loss: 1.3992e-04 - val_mae: 0.0098 - learning_rate: 6.2500e-05\n",
      "\u001b[1m62/62\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step   \n",
      " âœ… Chitradurga - wheat | MAE=32.59, RMSE=44.52, RÂ²=0.9941, MAPE=1.48%, Acc=98.52%\n",
      "\n",
      "ğŸš€ Processing: Davangere | capsicum\n",
      "Epoch 1/50\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - loss: 0.0418 - mae: 0.1307 - val_loss: 0.0235 - val_mae: 0.1253 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0074 - mae: 0.0674 - val_loss: 0.0085 - val_mae: 0.0593 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0052 - mae: 0.0566 - val_loss: 0.0165 - val_mae: 0.1070 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0040 - mae: 0.0498 - val_loss: 0.0068 - val_mae: 0.0547 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0030 - mae: 0.0431 - val_loss: 0.0080 - val_mae: 0.0664 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0025 - mae: 0.0388 - val_loss: 0.0064 - val_mae: 0.0559 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0022 - mae: 0.0357 - val_loss: 0.0055 - val_mae: 0.0488 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0019 - mae: 0.0335 - val_loss: 0.0052 - val_mae: 0.0475 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0016 - mae: 0.0312 - val_loss: 0.0046 - val_mae: 0.0428 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0016 - mae: 0.0301 - val_loss: 0.0049 - val_mae: 0.0456 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0015 - mae: 0.0293 - val_loss: 0.0055 - val_mae: 0.0510 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0014 - mae: 0.0277 - val_loss: 0.0067 - val_mae: 0.0603 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0012 - mae: 0.0254 - val_loss: 0.0039 - val_mae: 0.0390 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0011 - mae: 0.0249 - val_loss: 0.0038 - val_mae: 0.0396 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0010 - mae: 0.0237 - val_loss: 0.0038 - val_mae: 0.0386 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0011 - mae: 0.0241 - val_loss: 0.0036 - val_mae: 0.0396 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0011 - mae: 0.0243 - val_loss: 0.0036 - val_mae: 0.0386 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0010 - mae: 0.0234 - val_loss: 0.0038 - val_mae: 0.0400 - learning_rate: 5.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 9.9225e-04 - mae: 0.0229 - val_loss: 0.0043 - val_mae: 0.0451 - learning_rate: 5.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 9.5194e-04 - mae: 0.0221 - val_loss: 0.0035 - val_mae: 0.0376 - learning_rate: 2.5000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 8.9977e-04 - mae: 0.0221 - val_loss: 0.0033 - val_mae: 0.0365 - learning_rate: 2.5000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 9.0688e-04 - mae: 0.0219 - val_loss: 0.0035 - val_mae: 0.0379 - learning_rate: 2.5000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 9.0637e-04 - mae: 0.0219 - val_loss: 0.0032 - val_mae: 0.0359 - learning_rate: 2.5000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 8.7703e-04 - mae: 0.0214 - val_loss: 0.0032 - val_mae: 0.0370 - learning_rate: 2.5000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 8.9097e-04 - mae: 0.0216 - val_loss: 0.0032 - val_mae: 0.0366 - learning_rate: 2.5000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 9.0728e-04 - mae: 0.0218 - val_loss: 0.0031 - val_mae: 0.0358 - learning_rate: 2.5000e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 9.0260e-04 - mae: 0.0217 - val_loss: 0.0030 - val_mae: 0.0359 - learning_rate: 2.5000e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 8.5964e-04 - mae: 0.0210 - val_loss: 0.0031 - val_mae: 0.0359 - learning_rate: 2.5000e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 8.8366e-04 - mae: 0.0216 - val_loss: 0.0030 - val_mae: 0.0356 - learning_rate: 2.5000e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 8.6350e-04 - mae: 0.0210 - val_loss: 0.0031 - val_mae: 0.0367 - learning_rate: 1.2500e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 8.2685e-04 - mae: 0.0205 - val_loss: 0.0031 - val_mae: 0.0362 - learning_rate: 1.2500e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 8.2441e-04 - mae: 0.0205 - val_loss: 0.0030 - val_mae: 0.0360 - learning_rate: 1.2500e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 8.1145e-04 - mae: 0.0201 - val_loss: 0.0035 - val_mae: 0.0400 - learning_rate: 6.2500e-05\n",
      "Epoch 34/50\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 8.3004e-04 - mae: 0.0205 - val_loss: 0.0037 - val_mae: 0.0422 - learning_rate: 6.2500e-05\n",
      "Epoch 35/50\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 8.0462e-04 - mae: 0.0202 - val_loss: 0.0034 - val_mae: 0.0392 - learning_rate: 6.2500e-05\n",
      "Epoch 36/50\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 7.8923e-04 - mae: 0.0197 - val_loss: 0.0038 - val_mae: 0.0428 - learning_rate: 3.1250e-05\n",
      "\u001b[1m70/70\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step   \n",
      " âœ… Davangere - capsicum | MAE=332.01, RMSE=533.98, RÂ²=0.9053, MAPE=10.93%, Acc=89.07%\n",
      "\n",
      "ğŸš€ Processing: Davangere | onion\n",
      "Epoch 1/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0774 - mae: 0.1399 - val_loss: 0.0036 - val_mae: 0.0447 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0071 - mae: 0.0654 - val_loss: 0.0084 - val_mae: 0.0844 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0061 - mae: 0.0606 - val_loss: 0.0033 - val_mae: 0.0500 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0056 - mae: 0.0579 - val_loss: 0.0110 - val_mae: 0.1011 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0044 - mae: 0.0510 - val_loss: 0.0205 - val_mae: 0.1396 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0038 - mae: 0.0461 - val_loss: 0.0130 - val_mae: 0.1094 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0030 - mae: 0.0406 - val_loss: 0.0035 - val_mae: 0.0501 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0028 - mae: 0.0392 - val_loss: 0.0021 - val_mae: 0.0315 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0025 - mae: 0.0360 - val_loss: 0.0064 - val_mae: 0.0724 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0024 - mae: 0.0361 - val_loss: 0.0088 - val_mae: 0.0878 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0021 - mae: 0.0329 - val_loss: 0.0073 - val_mae: 0.0792 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0020 - mae: 0.0321 - val_loss: 0.0022 - val_mae: 0.0325 - learning_rate: 2.5000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0020 - mae: 0.0319 - val_loss: 0.0029 - val_mae: 0.0428 - learning_rate: 2.5000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0018 - mae: 0.0303 - val_loss: 0.0043 - val_mae: 0.0574 - learning_rate: 2.5000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0017 - mae: 0.0294 - val_loss: 0.0024 - val_mae: 0.0372 - learning_rate: 1.2500e-04\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step   \n",
      " âœ… Davangere - onion | MAE=226.13, RMSE=429.34, RÂ²=0.6501, MAPE=16.51%, Acc=83.49%\n",
      "\n",
      "ğŸš€ Processing: Davangere | tomato\n",
      "Epoch 1/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0477 - mae: 0.1268 - val_loss: 0.0272 - val_mae: 0.1005 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0060 - mae: 0.0608 - val_loss: 0.0157 - val_mae: 0.0810 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0048 - mae: 0.0535 - val_loss: 0.0176 - val_mae: 0.0891 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0034 - mae: 0.0452 - val_loss: 0.0180 - val_mae: 0.0958 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0026 - mae: 0.0399 - val_loss: 0.0135 - val_mae: 0.0791 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0020 - mae: 0.0342 - val_loss: 0.0144 - val_mae: 0.0851 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0018 - mae: 0.0319 - val_loss: 0.0119 - val_mae: 0.0732 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0014 - mae: 0.0283 - val_loss: 0.0102 - val_mae: 0.0645 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0012 - mae: 0.0262 - val_loss: 0.0094 - val_mae: 0.0623 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0012 - mae: 0.0253 - val_loss: 0.0100 - val_mae: 0.0645 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0011 - mae: 0.0243 - val_loss: 0.0102 - val_mae: 0.0666 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0010 - mae: 0.0238 - val_loss: 0.0090 - val_mae: 0.0611 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 9.7722e-04 - mae: 0.0230 - val_loss: 0.0096 - val_mae: 0.0638 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 9.3498e-04 - mae: 0.0221 - val_loss: 0.0098 - val_mae: 0.0643 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 8.6581e-04 - mae: 0.0210 - val_loss: 0.0091 - val_mae: 0.0613 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 8.0447e-04 - mae: 0.0197 - val_loss: 0.0087 - val_mae: 0.0579 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 7.4939e-04 - mae: 0.0191 - val_loss: 0.0093 - val_mae: 0.0605 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 7.6208e-04 - mae: 0.0195 - val_loss: 0.0092 - val_mae: 0.0593 - learning_rate: 5.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 7.2721e-04 - mae: 0.0186 - val_loss: 0.0086 - val_mae: 0.0571 - learning_rate: 5.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 7.2035e-04 - mae: 0.0185 - val_loss: 0.0088 - val_mae: 0.0576 - learning_rate: 5.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 7.4907e-04 - mae: 0.0190 - val_loss: 0.0084 - val_mae: 0.0567 - learning_rate: 5.0000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 7.2686e-04 - mae: 0.0186 - val_loss: 0.0084 - val_mae: 0.0565 - learning_rate: 5.0000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 7.2826e-04 - mae: 0.0187 - val_loss: 0.0082 - val_mae: 0.0558 - learning_rate: 5.0000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 7.4555e-04 - mae: 0.0188 - val_loss: 0.0086 - val_mae: 0.0571 - learning_rate: 5.0000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 7.3824e-04 - mae: 0.0190 - val_loss: 0.0082 - val_mae: 0.0561 - learning_rate: 5.0000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 7.1337e-04 - mae: 0.0184 - val_loss: 0.0082 - val_mae: 0.0562 - learning_rate: 5.0000e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 6.4867e-04 - mae: 0.0172 - val_loss: 0.0087 - val_mae: 0.0573 - learning_rate: 2.5000e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 6.5521e-04 - mae: 0.0174 - val_loss: 0.0087 - val_mae: 0.0573 - learning_rate: 2.5000e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 6.4591e-04 - mae: 0.0173 - val_loss: 0.0086 - val_mae: 0.0568 - learning_rate: 2.5000e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 6.4015e-04 - mae: 0.0170 - val_loss: 0.0086 - val_mae: 0.0565 - learning_rate: 1.2500e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 6.1578e-04 - mae: 0.0166 - val_loss: 0.0085 - val_mae: 0.0562 - learning_rate: 1.2500e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 6.2488e-04 - mae: 0.0168 - val_loss: 0.0087 - val_mae: 0.0571 - learning_rate: 1.2500e-04\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step   \n",
      " âœ… Davangere - tomato | MAE=210.21, RMSE=376.29, RÂ²=0.8566, MAPE=21.9%, Acc=78.1%\n",
      "\n",
      "ğŸš€ Processing: Davangere | wheat\n",
      "Epoch 1/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - loss: 0.0911 - mae: 0.1960 - val_loss: 0.0100 - val_mae: 0.0794 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0169 - mae: 0.1023 - val_loss: 0.0165 - val_mae: 0.1208 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0075 - mae: 0.0680 - val_loss: 0.0199 - val_mae: 0.1276 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0037 - mae: 0.0482 - val_loss: 0.0270 - val_mae: 0.1464 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0026 - mae: 0.0401 - val_loss: 0.0105 - val_mae: 0.0645 - learning_rate: 5.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0020 - mae: 0.0355 - val_loss: 0.0129 - val_mae: 0.0722 - learning_rate: 5.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0020 - mae: 0.0347 - val_loss: 0.0114 - val_mae: 0.0642 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0015 - mae: 0.0300 - val_loss: 0.0134 - val_mae: 0.0782 - learning_rate: 2.5000e-04\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step   \n",
      " âœ… Davangere - wheat | MAE=263.1, RMSE=317.24, RÂ²=0.6334, MAPE=12.72%, Acc=87.28%\n",
      "\n",
      "ğŸš€ Processing: Dharwad | capsicum\n",
      "Epoch 1/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 333ms/step - loss: 1.4199 - mae: 0.9441 - val_loss: 0.0279 - val_mae: 0.1607 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 1.1180 - mae: 0.9240 - val_loss: 0.2021 - val_mae: 0.4479 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.2441 - mae: 0.4074 - val_loss: 1.2959 - val_mae: 1.1378 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.3486 - mae: 0.4873 - val_loss: 1.2367 - val_mae: 1.1114 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.2703 - mae: 0.4076 - val_loss: 0.6832 - val_mae: 0.8257 - learning_rate: 5.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1159 - mae: 0.2445 - val_loss: 0.2270 - val_mae: 0.4747 - learning_rate: 5.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.1011 - mae: 0.2893 - val_loss: 0.0568 - val_mae: 0.2345 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.1277 - mae: 0.3241 - val_loss: 0.0465 - val_mae: 0.2112 - learning_rate: 2.5000e-04\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 275ms/step\n",
      " âœ… Dharwad - capsicum | MAE=2830.12, RMSE=3491.81, RÂ²=-8.6215, MAPE=148.79%, Acc=-48.79%\n",
      "\n",
      "ğŸš€ Processing: Dharwad | onion\n",
      "Epoch 1/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - loss: 0.0437 - mae: 0.1246 - val_loss: 0.0043 - val_mae: 0.0535 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0066 - mae: 0.0620 - val_loss: 0.0047 - val_mae: 0.0460 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0048 - mae: 0.0527 - val_loss: 0.0047 - val_mae: 0.0515 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0035 - mae: 0.0444 - val_loss: 0.0042 - val_mae: 0.0495 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0028 - mae: 0.0393 - val_loss: 0.0028 - val_mae: 0.0410 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0023 - mae: 0.0352 - val_loss: 0.0023 - val_mae: 0.0373 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0019 - mae: 0.0316 - val_loss: 0.0028 - val_mae: 0.0438 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0018 - mae: 0.0303 - val_loss: 0.0014 - val_mae: 0.0248 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0016 - mae: 0.0278 - val_loss: 0.0015 - val_mae: 0.0281 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0015 - mae: 0.0276 - val_loss: 0.0018 - val_mae: 0.0324 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0014 - mae: 0.0268 - val_loss: 0.0013 - val_mae: 0.0257 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0013 - mae: 0.0241 - val_loss: 0.0012 - val_mae: 0.0232 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0012 - mae: 0.0239 - val_loss: 0.0011 - val_mae: 0.0216 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0012 - mae: 0.0231 - val_loss: 0.0011 - val_mae: 0.0214 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0012 - mae: 0.0229 - val_loss: 0.0011 - val_mae: 0.0217 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0011 - mae: 0.0211 - val_loss: 0.0011 - val_mae: 0.0223 - learning_rate: 2.5000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0011 - mae: 0.0216 - val_loss: 0.0014 - val_mae: 0.0271 - learning_rate: 2.5000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0011 - mae: 0.0219 - val_loss: 0.0013 - val_mae: 0.0250 - learning_rate: 2.5000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0010 - mae: 0.0206 - val_loss: 0.0012 - val_mae: 0.0234 - learning_rate: 1.2500e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0010 - mae: 0.0206 - val_loss: 0.0012 - val_mae: 0.0235 - learning_rate: 1.2500e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0010 - mae: 0.0208 - val_loss: 0.0011 - val_mae: 0.0228 - learning_rate: 1.2500e-04\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step   \n",
      " âœ… Dharwad - onion | MAE=133.04, RMSE=225.93, RÂ²=0.9133, MAPE=10.08%, Acc=89.92%\n",
      "\n",
      "ğŸš€ Processing: Dharwad | tomato\n",
      "Epoch 1/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - loss: 0.1403 - mae: 0.2917 - val_loss: 0.0556 - val_mae: 0.1659 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0143 - mae: 0.0929 - val_loss: 0.0477 - val_mae: 0.1117 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0098 - mae: 0.0762 - val_loss: 0.0420 - val_mae: 0.1019 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0085 - mae: 0.0728 - val_loss: 0.0381 - val_mae: 0.0915 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0081 - mae: 0.0709 - val_loss: 0.0369 - val_mae: 0.1210 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0085 - mae: 0.0723 - val_loss: 0.0427 - val_mae: 0.0786 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0066 - mae: 0.0635 - val_loss: 0.0432 - val_mae: 0.0869 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0078 - mae: 0.0690 - val_loss: 0.0452 - val_mae: 0.0890 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0054 - mae: 0.0577 - val_loss: 0.0465 - val_mae: 0.0902 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0047 - mae: 0.0535 - val_loss: 0.0421 - val_mae: 0.0964 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0051 - mae: 0.0559 - val_loss: 0.0464 - val_mae: 0.0797 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0044 - mae: 0.0523 - val_loss: 0.0464 - val_mae: 0.0856 - learning_rate: 2.5000e-04\n",
      "\u001b[1m19/19\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step \n",
      " âœ… Dharwad - tomato | MAE=546.29, RMSE=763.54, RÂ²=0.1128, MAPE=30.22%, Acc=69.78%\n",
      "\n",
      "ğŸš€ Processing: Dharwad | wheat\n",
      "Epoch 1/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - loss: 0.0660 - mae: 0.1542 - val_loss: 0.0689 - val_mae: 0.2351 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0066 - mae: 0.0643 - val_loss: 0.0239 - val_mae: 0.1236 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0045 - mae: 0.0531 - val_loss: 0.0254 - val_mae: 0.1298 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0038 - mae: 0.0490 - val_loss: 0.0196 - val_mae: 0.1099 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0027 - mae: 0.0412 - val_loss: 0.0231 - val_mae: 0.1226 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0022 - mae: 0.0373 - val_loss: 0.0132 - val_mae: 0.0851 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0020 - mae: 0.0351 - val_loss: 0.0180 - val_mae: 0.1033 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0020 - mae: 0.0344 - val_loss: 0.0135 - val_mae: 0.0853 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0017 - mae: 0.0320 - val_loss: 0.0120 - val_mae: 0.0799 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0015 - mae: 0.0298 - val_loss: 0.0116 - val_mae: 0.0780 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0015 - mae: 0.0299 - val_loss: 0.0138 - val_mae: 0.0861 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0014 - mae: 0.0291 - val_loss: 0.0131 - val_mae: 0.0834 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0014 - mae: 0.0283 - val_loss: 0.0120 - val_mae: 0.0792 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0011 - mae: 0.0251 - val_loss: 0.0153 - val_mae: 0.0919 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0012 - mae: 0.0259 - val_loss: 0.0153 - val_mae: 0.0918 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0011 - mae: 0.0255 - val_loss: 0.0144 - val_mae: 0.0884 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0011 - mae: 0.0241 - val_loss: 0.0130 - val_mae: 0.0825 - learning_rate: 2.5000e-04\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step   \n",
      " âœ… Dharwad - wheat | MAE=112.44, RMSE=165.8, RÂ²=0.8744, MAPE=5.46%, Acc=94.54%\n",
      "\n",
      "ğŸš€ Processing: Gadag | onion\n",
      "Epoch 1/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0468 - mae: 0.1501 - val_loss: 0.0113 - val_mae: 0.0860 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0114 - mae: 0.0832 - val_loss: 0.0051 - val_mae: 0.0639 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0064 - mae: 0.0616 - val_loss: 0.0040 - val_mae: 0.0445 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0051 - mae: 0.0543 - val_loss: 0.0019 - val_mae: 0.0349 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0036 - mae: 0.0440 - val_loss: 0.0017 - val_mae: 0.0255 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0030 - mae: 0.0395 - val_loss: 0.0016 - val_mae: 0.0272 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 0.0027 - mae: 0.0373 - val_loss: 0.0024 - val_mae: 0.0383 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0027 - mae: 0.0367 - val_loss: 0.0022 - val_mae: 0.0332 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0023 - mae: 0.0336 - val_loss: 0.0022 - val_mae: 0.0371 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0022 - mae: 0.0328 - val_loss: 0.0018 - val_mae: 0.0274 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0021 - mae: 0.0316 - val_loss: 0.0021 - val_mae: 0.0309 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0019 - mae: 0.0298 - val_loss: 0.0019 - val_mae: 0.0301 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0018 - mae: 0.0282 - val_loss: 0.0024 - val_mae: 0.0385 - learning_rate: 2.5000e-04\n",
      "\u001b[1m80/80\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step  \n",
      " âœ… Gadag - onion | MAE=100.09, RMSE=146.12, RÂ²=0.9479, MAPE=9.77%, Acc=90.23%\n",
      "\n",
      "ğŸš€ Processing: Gadag | tomato\n",
      "Epoch 1/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - loss: 0.4808 - mae: 0.5130 - val_loss: 0.2915 - val_mae: 0.5301 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0429 - mae: 0.1709 - val_loss: 0.0598 - val_mae: 0.2346 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0238 - mae: 0.1262 - val_loss: 0.0488 - val_mae: 0.2125 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0170 - mae: 0.1025 - val_loss: 0.0269 - val_mae: 0.1572 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0137 - mae: 0.0922 - val_loss: 0.0185 - val_mae: 0.1275 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0104 - mae: 0.0808 - val_loss: 0.0104 - val_mae: 0.0709 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0103 - mae: 0.0788 - val_loss: 0.0107 - val_mae: 0.0569 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0092 - mae: 0.0757 - val_loss: 0.0114 - val_mae: 0.0866 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0072 - mae: 0.0658 - val_loss: 0.0100 - val_mae: 0.0660 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0076 - mae: 0.0693 - val_loss: 0.0096 - val_mae: 0.0739 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0060 - mae: 0.0602 - val_loss: 0.0100 - val_mae: 0.0739 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0058 - mae: 0.0595 - val_loss: 0.0106 - val_mae: 0.0828 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0057 - mae: 0.0587 - val_loss: 0.0084 - val_mae: 0.0698 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0053 - mae: 0.0562 - val_loss: 0.0095 - val_mae: 0.0626 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0050 - mae: 0.0561 - val_loss: 0.0100 - val_mae: 0.0663 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0048 - mae: 0.0536 - val_loss: 0.0064 - val_mae: 0.0580 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0044 - mae: 0.0515 - val_loss: 0.0084 - val_mae: 0.0491 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0038 - mae: 0.0484 - val_loss: 0.0127 - val_mae: 0.0987 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0042 - mae: 0.0497 - val_loss: 0.0080 - val_mae: 0.0669 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0032 - mae: 0.0447 - val_loss: 0.0084 - val_mae: 0.0608 - learning_rate: 5.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0035 - mae: 0.0462 - val_loss: 0.0079 - val_mae: 0.0446 - learning_rate: 5.0000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0034 - mae: 0.0455 - val_loss: 0.0085 - val_mae: 0.0483 - learning_rate: 5.0000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0032 - mae: 0.0441 - val_loss: 0.0078 - val_mae: 0.0605 - learning_rate: 2.5000e-04\n",
      "\u001b[1m19/19\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step \n",
      " âœ… Gadag - tomato | MAE=384.46, RMSE=492.2, RÂ²=0.9448, MAPE=9.78%, Acc=90.22%\n",
      "\n",
      "ğŸš€ Processing: Gadag | wheat\n",
      "Epoch 1/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - loss: 0.0366 - mae: 0.1177 - val_loss: 0.0301 - val_mae: 0.1577 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0055 - mae: 0.0583 - val_loss: 0.0215 - val_mae: 0.1319 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0035 - mae: 0.0466 - val_loss: 0.0230 - val_mae: 0.1390 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0026 - mae: 0.0397 - val_loss: 0.0169 - val_mae: 0.1150 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0021 - mae: 0.0349 - val_loss: 0.0081 - val_mae: 0.0736 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0019 - mae: 0.0334 - val_loss: 0.0105 - val_mae: 0.0856 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0014 - mae: 0.0281 - val_loss: 0.0090 - val_mae: 0.0788 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0013 - mae: 0.0259 - val_loss: 0.0108 - val_mae: 0.0885 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0011 - mae: 0.0247 - val_loss: 0.0127 - val_mae: 0.0977 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0010 - mae: 0.0227 - val_loss: 0.0183 - val_mae: 0.1224 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0010 - mae: 0.0221 - val_loss: 0.0160 - val_mae: 0.1132 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 9.3843e-04 - mae: 0.0214 - val_loss: 0.0091 - val_mae: 0.0798 - learning_rate: 2.5000e-04\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step   \n",
      " âœ… Gadag - wheat | MAE=178.13, RMSE=257.84, RÂ²=0.7694, MAPE=8.64%, Acc=91.36%\n",
      "\n",
      "ğŸš€ Processing: Hassan | capsicum\n",
      "Epoch 1/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - loss: 0.0522 - mae: 0.1345 - val_loss: 0.0198 - val_mae: 0.1200 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0075 - mae: 0.0689 - val_loss: 0.0247 - val_mae: 0.1304 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0056 - mae: 0.0595 - val_loss: 0.0261 - val_mae: 0.1383 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0051 - mae: 0.0564 - val_loss: 0.0201 - val_mae: 0.1208 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0036 - mae: 0.0465 - val_loss: 0.0120 - val_mae: 0.0904 - learning_rate: 5.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0031 - mae: 0.0433 - val_loss: 0.0175 - val_mae: 0.1162 - learning_rate: 5.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0025 - mae: 0.0389 - val_loss: 0.0161 - val_mae: 0.1111 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0023 - mae: 0.0371 - val_loss: 0.0113 - val_mae: 0.0917 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0021 - mae: 0.0354 - val_loss: 0.0241 - val_mae: 0.1415 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0018 - mae: 0.0323 - val_loss: 0.0142 - val_mae: 0.1042 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0016 - mae: 0.0302 - val_loss: 0.0170 - val_mae: 0.1159 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0014 - mae: 0.0283 - val_loss: 0.0064 - val_mae: 0.0584 - learning_rate: 2.5000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0014 - mae: 0.0282 - val_loss: 0.0065 - val_mae: 0.0589 - learning_rate: 2.5000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0013 - mae: 0.0278 - val_loss: 0.0079 - val_mae: 0.0664 - learning_rate: 2.5000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0013 - mae: 0.0265 - val_loss: 0.0071 - val_mae: 0.0597 - learning_rate: 2.5000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0012 - mae: 0.0256 - val_loss: 0.0097 - val_mae: 0.0783 - learning_rate: 1.2500e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0011 - mae: 0.0248 - val_loss: 0.0084 - val_mae: 0.0691 - learning_rate: 1.2500e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0011 - mae: 0.0241 - val_loss: 0.0096 - val_mae: 0.0767 - learning_rate: 1.2500e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0010 - mae: 0.0239 - val_loss: 0.0095 - val_mae: 0.0762 - learning_rate: 6.2500e-05\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step   \n",
      " âœ… Hassan - capsicum | MAE=109.88, RMSE=192.51, RÂ²=0.9531, MAPE=5.93%, Acc=94.07%\n",
      "\n",
      "ğŸš€ Processing: Hassan | onion\n",
      "Epoch 1/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - loss: 0.0620 - mae: 0.1555 - val_loss: 0.0047 - val_mae: 0.0487 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0079 - mae: 0.0689 - val_loss: 0.0028 - val_mae: 0.0396 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0049 - mae: 0.0546 - val_loss: 0.0053 - val_mae: 0.0622 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0038 - mae: 0.0477 - val_loss: 0.0039 - val_mae: 0.0505 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0025 - mae: 0.0386 - val_loss: 0.0055 - val_mae: 0.0646 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0020 - mae: 0.0333 - val_loss: 0.0032 - val_mae: 0.0447 - learning_rate: 5.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0018 - mae: 0.0319 - val_loss: 0.0026 - val_mae: 0.0364 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0017 - mae: 0.0313 - val_loss: 0.0035 - val_mae: 0.0441 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0017 - mae: 0.0304 - val_loss: 0.0025 - val_mae: 0.0349 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0014 - mae: 0.0274 - val_loss: 0.0023 - val_mae: 0.0319 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0014 - mae: 0.0274 - val_loss: 0.0024 - val_mae: 0.0317 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0013 - mae: 0.0269 - val_loss: 0.0022 - val_mae: 0.0300 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0012 - mae: 0.0254 - val_loss: 0.0021 - val_mae: 0.0298 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0012 - mae: 0.0251 - val_loss: 0.0023 - val_mae: 0.0330 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0012 - mae: 0.0254 - val_loss: 0.0024 - val_mae: 0.0365 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0011 - mae: 0.0237 - val_loss: 0.0019 - val_mae: 0.0288 - learning_rate: 2.5000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0011 - mae: 0.0234 - val_loss: 0.0019 - val_mae: 0.0287 - learning_rate: 2.5000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0010 - mae: 0.0230 - val_loss: 0.0020 - val_mae: 0.0311 - learning_rate: 2.5000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 9.9005e-04 - mae: 0.0227 - val_loss: 0.0018 - val_mae: 0.0287 - learning_rate: 2.5000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 9.4302e-04 - mae: 0.0220 - val_loss: 0.0019 - val_mae: 0.0307 - learning_rate: 1.2500e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 9.4735e-04 - mae: 0.0222 - val_loss: 0.0018 - val_mae: 0.0280 - learning_rate: 1.2500e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 9.1171e-04 - mae: 0.0216 - val_loss: 0.0018 - val_mae: 0.0280 - learning_rate: 1.2500e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 8.9329e-04 - mae: 0.0216 - val_loss: 0.0018 - val_mae: 0.0280 - learning_rate: 1.2500e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 8.9453e-04 - mae: 0.0214 - val_loss: 0.0018 - val_mae: 0.0285 - learning_rate: 1.2500e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 8.9738e-04 - mae: 0.0215 - val_loss: 0.0018 - val_mae: 0.0279 - learning_rate: 6.2500e-05\n",
      "Epoch 26/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 8.6350e-04 - mae: 0.0211 - val_loss: 0.0017 - val_mae: 0.0277 - learning_rate: 6.2500e-05\n",
      "Epoch 27/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 8.6464e-04 - mae: 0.0211 - val_loss: 0.0017 - val_mae: 0.0277 - learning_rate: 6.2500e-05\n",
      "Epoch 28/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 8.7961e-04 - mae: 0.0211 - val_loss: 0.0018 - val_mae: 0.0288 - learning_rate: 3.1250e-05\n",
      "Epoch 29/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 8.8901e-04 - mae: 0.0212 - val_loss: 0.0018 - val_mae: 0.0285 - learning_rate: 3.1250e-05\n",
      "Epoch 30/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 8.6363e-04 - mae: 0.0211 - val_loss: 0.0018 - val_mae: 0.0290 - learning_rate: 3.1250e-05\n",
      "Epoch 31/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 8.5421e-04 - mae: 0.0207 - val_loss: 0.0018 - val_mae: 0.0282 - learning_rate: 1.5625e-05\n",
      "Epoch 32/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 8.2530e-04 - mae: 0.0205 - val_loss: 0.0018 - val_mae: 0.0287 - learning_rate: 1.5625e-05\n",
      "Epoch 33/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 8.6068e-04 - mae: 0.0208 - val_loss: 0.0018 - val_mae: 0.0289 - learning_rate: 1.5625e-05\n",
      "Epoch 34/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 8.3938e-04 - mae: 0.0206 - val_loss: 0.0018 - val_mae: 0.0286 - learning_rate: 7.8125e-06\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step   \n",
      " âœ… Hassan - onion | MAE=105.74, RMSE=154.08, RÂ²=0.9438, MAPE=7.5%, Acc=92.5%\n",
      "\n",
      "ğŸš€ Processing: Hassan | tomato\n",
      "Epoch 1/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - loss: 0.1250 - mae: 0.1657 - val_loss: 0.0277 - val_mae: 0.0988 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0074 - mae: 0.0650 - val_loss: 0.0166 - val_mae: 0.0828 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0063 - mae: 0.0610 - val_loss: 0.0155 - val_mae: 0.0794 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0049 - mae: 0.0539 - val_loss: 0.0155 - val_mae: 0.0807 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0040 - mae: 0.0488 - val_loss: 0.0160 - val_mae: 0.0826 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0032 - mae: 0.0437 - val_loss: 0.0158 - val_mae: 0.0832 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0026 - mae: 0.0387 - val_loss: 0.0154 - val_mae: 0.0836 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0024 - mae: 0.0371 - val_loss: 0.0146 - val_mae: 0.0826 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0022 - mae: 0.0357 - val_loss: 0.0139 - val_mae: 0.0806 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0020 - mae: 0.0340 - val_loss: 0.0128 - val_mae: 0.0761 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0017 - mae: 0.0311 - val_loss: 0.0145 - val_mae: 0.0855 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0015 - mae: 0.0292 - val_loss: 0.0121 - val_mae: 0.0765 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0013 - mae: 0.0273 - val_loss: 0.0119 - val_mae: 0.0741 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0013 - mae: 0.0272 - val_loss: 0.0117 - val_mae: 0.0731 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0011 - mae: 0.0244 - val_loss: 0.0118 - val_mae: 0.0733 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 9.7505e-04 - mae: 0.0233 - val_loss: 0.0104 - val_mae: 0.0679 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 9.0828e-04 - mae: 0.0226 - val_loss: 0.0100 - val_mae: 0.0676 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 7.9748e-04 - mae: 0.0209 - val_loss: 0.0102 - val_mae: 0.0675 - learning_rate: 5.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 7.5226e-04 - mae: 0.0202 - val_loss: 0.0095 - val_mae: 0.0651 - learning_rate: 5.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 7.0912e-04 - mae: 0.0198 - val_loss: 0.0092 - val_mae: 0.0620 - learning_rate: 5.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 6.4616e-04 - mae: 0.0192 - val_loss: 0.0085 - val_mae: 0.0618 - learning_rate: 5.0000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 5.8668e-04 - mae: 0.0181 - val_loss: 0.0087 - val_mae: 0.0588 - learning_rate: 5.0000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 5.5723e-04 - mae: 0.0174 - val_loss: 0.0082 - val_mae: 0.0594 - learning_rate: 5.0000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 5.1511e-04 - mae: 0.0170 - val_loss: 0.0072 - val_mae: 0.0609 - learning_rate: 5.0000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 5.0888e-04 - mae: 0.0167 - val_loss: 0.0071 - val_mae: 0.0573 - learning_rate: 5.0000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 4.9771e-04 - mae: 0.0165 - val_loss: 0.0076 - val_mae: 0.0629 - learning_rate: 5.0000e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 4.8795e-04 - mae: 0.0162 - val_loss: 0.0067 - val_mae: 0.0517 - learning_rate: 5.0000e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 5.0150e-04 - mae: 0.0164 - val_loss: 0.0074 - val_mae: 0.0531 - learning_rate: 5.0000e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 4.5509e-04 - mae: 0.0158 - val_loss: 0.0072 - val_mae: 0.0522 - learning_rate: 5.0000e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 4.2366e-04 - mae: 0.0151 - val_loss: 0.0063 - val_mae: 0.0499 - learning_rate: 5.0000e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 4.2213e-04 - mae: 0.0152 - val_loss: 0.0064 - val_mae: 0.0538 - learning_rate: 5.0000e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 4.0823e-04 - mae: 0.0150 - val_loss: 0.0068 - val_mae: 0.0539 - learning_rate: 5.0000e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 3.8295e-04 - mae: 0.0145 - val_loss: 0.0063 - val_mae: 0.0501 - learning_rate: 5.0000e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 3.7113e-04 - mae: 0.0140 - val_loss: 0.0065 - val_mae: 0.0528 - learning_rate: 2.5000e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 3.4147e-04 - mae: 0.0132 - val_loss: 0.0064 - val_mae: 0.0492 - learning_rate: 2.5000e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 3.3926e-04 - mae: 0.0133 - val_loss: 0.0064 - val_mae: 0.0507 - learning_rate: 2.5000e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 3.2114e-04 - mae: 0.0129 - val_loss: 0.0065 - val_mae: 0.0494 - learning_rate: 1.2500e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 3.2916e-04 - mae: 0.0131 - val_loss: 0.0065 - val_mae: 0.0529 - learning_rate: 1.2500e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 3.1932e-04 - mae: 0.0128 - val_loss: 0.0066 - val_mae: 0.0501 - learning_rate: 1.2500e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 3.1467e-04 - mae: 0.0127 - val_loss: 0.0066 - val_mae: 0.0510 - learning_rate: 6.2500e-05\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step   \n",
      " âœ… Hassan - tomato | MAE=136.43, RMSE=242.0, RÂ²=0.9079, MAPE=11.79%, Acc=88.21%\n",
      "\n",
      "ğŸš€ Processing: Hassan | wheat\n",
      "Epoch 1/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - loss: 0.0293 - mae: 0.1052 - val_loss: 0.0032 - val_mae: 0.0484 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0060 - mae: 0.0584 - val_loss: 0.0037 - val_mae: 0.0535 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0032 - mae: 0.0417 - val_loss: 0.0042 - val_mae: 0.0590 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0021 - mae: 0.0322 - val_loss: 0.0019 - val_mae: 0.0375 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0015 - mae: 0.0274 - val_loss: 0.0033 - val_mae: 0.0532 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0011 - mae: 0.0225 - val_loss: 0.0015 - val_mae: 0.0345 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 8.8502e-04 - mae: 0.0215 - val_loss: 0.0045 - val_mae: 0.0626 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 6.5320e-04 - mae: 0.0183 - val_loss: 0.0026 - val_mae: 0.0464 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 6.5363e-04 - mae: 0.0186 - val_loss: 0.0025 - val_mae: 0.0453 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 4.5303e-04 - mae: 0.0152 - val_loss: 0.0029 - val_mae: 0.0488 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 4.5170e-04 - mae: 0.0150 - val_loss: 0.0029 - val_mae: 0.0490 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 4.2091e-04 - mae: 0.0147 - val_loss: 0.0021 - val_mae: 0.0410 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 3.6172e-04 - mae: 0.0134 - val_loss: 0.0032 - val_mae: 0.0526 - learning_rate: 2.5000e-04\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step   \n",
      " âœ… Hassan - wheat | MAE=97.89, RMSE=168.69, RÂ²=0.9276, MAPE=4.17%, Acc=95.83%\n",
      "\n",
      "ğŸš€ Processing: Haveri | capsicum\n",
      " âš  Sparse series; falling back to crop-level aggregated series.\n",
      "Epoch 1/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - loss: 0.0383 - mae: 0.1258 - val_loss: 0.0121 - val_mae: 0.0820 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0067 - mae: 0.0633 - val_loss: 0.0100 - val_mae: 0.0772 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0047 - mae: 0.0543 - val_loss: 0.0108 - val_mae: 0.0820 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0037 - mae: 0.0475 - val_loss: 0.0064 - val_mae: 0.0620 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0031 - mae: 0.0442 - val_loss: 0.0064 - val_mae: 0.0619 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0029 - mae: 0.0422 - val_loss: 0.0057 - val_mae: 0.0583 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0024 - mae: 0.0379 - val_loss: 0.0056 - val_mae: 0.0580 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0021 - mae: 0.0352 - val_loss: 0.0048 - val_mae: 0.0535 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0019 - mae: 0.0336 - val_loss: 0.0048 - val_mae: 0.0529 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0018 - mae: 0.0327 - val_loss: 0.0045 - val_mae: 0.0512 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0019 - mae: 0.0334 - val_loss: 0.0044 - val_mae: 0.0507 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0021 - mae: 0.0355 - val_loss: 0.0052 - val_mae: 0.0540 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0015 - mae: 0.0298 - val_loss: 0.0045 - val_mae: 0.0508 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0015 - mae: 0.0295 - val_loss: 0.0044 - val_mae: 0.0505 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0013 - mae: 0.0280 - val_loss: 0.0047 - val_mae: 0.0506 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0013 - mae: 0.0282 - val_loss: 0.0045 - val_mae: 0.0506 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0011 - mae: 0.0260 - val_loss: 0.0048 - val_mae: 0.0502 - learning_rate: 2.5000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0011 - mae: 0.0249 - val_loss: 0.0045 - val_mae: 0.0486 - learning_rate: 2.5000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0011 - mae: 0.0255 - val_loss: 0.0048 - val_mae: 0.0497 - learning_rate: 2.5000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0010 - mae: 0.0244 - val_loss: 0.0044 - val_mae: 0.0484 - learning_rate: 1.2500e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0010 - mae: 0.0246 - val_loss: 0.0045 - val_mae: 0.0486 - learning_rate: 1.2500e-04\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step   \n",
      " âœ… Haveri - capsicum | MAE=176.91, RMSE=216.21, RÂ²=0.9108, MAPE=7.41%, Acc=92.59%\n",
      "\n",
      "ğŸš€ Processing: Haveri | onion\n",
      "Epoch 1/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 18ms/step - loss: 0.0555 - mae: 0.1474 - val_loss: 0.0049 - val_mae: 0.0373 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0109 - mae: 0.0795 - val_loss: 0.0034 - val_mae: 0.0402 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0084 - mae: 0.0700 - val_loss: 0.0174 - val_mae: 0.1243 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0058 - mae: 0.0579 - val_loss: 0.0059 - val_mae: 0.0702 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0046 - mae: 0.0515 - val_loss: 0.0042 - val_mae: 0.0578 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0032 - mae: 0.0422 - val_loss: 0.0066 - val_mae: 0.0751 - learning_rate: 5.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0029 - mae: 0.0396 - val_loss: 0.0065 - val_mae: 0.0743 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0025 - mae: 0.0370 - val_loss: 0.0036 - val_mae: 0.0528 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0022 - mae: 0.0338 - val_loss: 0.0029 - val_mae: 0.0461 - learning_rate: 2.5000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0022 - mae: 0.0341 - val_loss: 0.0039 - val_mae: 0.0550 - learning_rate: 2.5000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0020 - mae: 0.0323 - val_loss: 0.0021 - val_mae: 0.0354 - learning_rate: 2.5000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0020 - mae: 0.0321 - val_loss: 0.0028 - val_mae: 0.0435 - learning_rate: 2.5000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0020 - mae: 0.0315 - val_loss: 0.0021 - val_mae: 0.0345 - learning_rate: 2.5000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0020 - mae: 0.0312 - val_loss: 0.0038 - val_mae: 0.0536 - learning_rate: 2.5000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0018 - mae: 0.0293 - val_loss: 0.0023 - val_mae: 0.0387 - learning_rate: 1.2500e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0018 - mae: 0.0297 - val_loss: 0.0034 - val_mae: 0.0498 - learning_rate: 1.2500e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0017 - mae: 0.0289 - val_loss: 0.0024 - val_mae: 0.0397 - learning_rate: 1.2500e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0017 - mae: 0.0288 - val_loss: 0.0024 - val_mae: 0.0396 - learning_rate: 6.2500e-05\n",
      "\u001b[1m76/76\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step   \n",
      " âœ… Haveri - onion | MAE=97.01, RMSE=145.94, RÂ²=0.943, MAPE=6.45%, Acc=93.55%\n",
      "\n",
      "ğŸš€ Processing: Haveri | tomato\n",
      "Epoch 1/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 32ms/step - loss: 0.0983 - mae: 0.2333 - val_loss: 1.6023 - val_mae: 1.0899 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0313 - mae: 0.1402 - val_loss: 0.1946 - val_mae: 0.4165 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0136 - mae: 0.0945 - val_loss: 0.1082 - val_mae: 0.2978 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0085 - mae: 0.0727 - val_loss: 0.1039 - val_mae: 0.2913 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0062 - mae: 0.0625 - val_loss: 0.0557 - val_mae: 0.1957 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0037 - mae: 0.0479 - val_loss: 0.0494 - val_mae: 0.1784 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0032 - mae: 0.0455 - val_loss: 0.0568 - val_mae: 0.1947 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0025 - mae: 0.0398 - val_loss: 0.0594 - val_mae: 0.1931 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0027 - mae: 0.0419 - val_loss: 0.0473 - val_mae: 0.1552 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0021 - mae: 0.0368 - val_loss: 0.0497 - val_mae: 0.1441 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0020 - mae: 0.0355 - val_loss: 0.0488 - val_mae: 0.1368 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0016 - mae: 0.0323 - val_loss: 0.0425 - val_mae: 0.1364 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0016 - mae: 0.0315 - val_loss: 0.0525 - val_mae: 0.1724 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0016 - mae: 0.0318 - val_loss: 0.0636 - val_mae: 0.1964 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0011 - mae: 0.0261 - val_loss: 0.0572 - val_mae: 0.1720 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 9.6911e-04 - mae: 0.0245 - val_loss: 0.0443 - val_mae: 0.1432 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 9.7518e-04 - mae: 0.0246 - val_loss: 0.0382 - val_mae: 0.1306 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0011 - mae: 0.0260 - val_loss: 0.0440 - val_mae: 0.1425 - learning_rate: 5.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 9.0580e-04 - mae: 0.0238 - val_loss: 0.0487 - val_mae: 0.1710 - learning_rate: 5.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 7.5833e-04 - mae: 0.0217 - val_loss: 0.0466 - val_mae: 0.1449 - learning_rate: 5.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 6.4363e-04 - mae: 0.0202 - val_loss: 0.0515 - val_mae: 0.1532 - learning_rate: 2.5000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 6.6457e-04 - mae: 0.0204 - val_loss: 0.0486 - val_mae: 0.1480 - learning_rate: 2.5000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 6.7498e-04 - mae: 0.0209 - val_loss: 0.0503 - val_mae: 0.1470 - learning_rate: 2.5000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 6.7472e-04 - mae: 0.0206 - val_loss: 0.0489 - val_mae: 0.1469 - learning_rate: 1.2500e-04\n",
      "\u001b[1m23/23\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step \n",
      " âœ… Haveri - tomato | MAE=394.34, RMSE=733.9, RÂ²=0.9021, MAPE=29.24%, Acc=70.76%\n",
      "\n",
      "ğŸš€ Processing: Haveri | wheat\n",
      "Epoch 1/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - loss: 0.0408 - mae: 0.1330 - val_loss: 0.0291 - val_mae: 0.1427 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0065 - mae: 0.0640 - val_loss: 0.0234 - val_mae: 0.1312 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0042 - mae: 0.0515 - val_loss: 0.0124 - val_mae: 0.0868 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0027 - mae: 0.0412 - val_loss: 0.0143 - val_mae: 0.0998 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0021 - mae: 0.0356 - val_loss: 0.0076 - val_mae: 0.0627 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0017 - mae: 0.0320 - val_loss: 0.0043 - val_mae: 0.0349 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0013 - mae: 0.0285 - val_loss: 0.0052 - val_mae: 0.0499 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0013 - mae: 0.0277 - val_loss: 0.0040 - val_mae: 0.0363 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0011 - mae: 0.0261 - val_loss: 0.0053 - val_mae: 0.0527 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 8.5509e-04 - mae: 0.0226 - val_loss: 0.0036 - val_mae: 0.0334 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 8.0516e-04 - mae: 0.0218 - val_loss: 0.0025 - val_mae: 0.0280 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 7.5657e-04 - mae: 0.0211 - val_loss: 0.0029 - val_mae: 0.0280 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 6.7220e-04 - mae: 0.0199 - val_loss: 0.0022 - val_mae: 0.0253 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 6.8832e-04 - mae: 0.0204 - val_loss: 0.0020 - val_mae: 0.0254 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 5.1536e-04 - mae: 0.0173 - val_loss: 0.0021 - val_mae: 0.0230 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 5.5469e-04 - mae: 0.0180 - val_loss: 0.0028 - val_mae: 0.0324 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 5.2951e-04 - mae: 0.0176 - val_loss: 0.0018 - val_mae: 0.0250 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 5.3537e-04 - mae: 0.0178 - val_loss: 0.0017 - val_mae: 0.0234 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 5.0792e-04 - mae: 0.0173 - val_loss: 0.0016 - val_mae: 0.0222 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 5.5861e-04 - mae: 0.0181 - val_loss: 0.0015 - val_mae: 0.0225 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 5.1032e-04 - mae: 0.0173 - val_loss: 0.0015 - val_mae: 0.0229 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 4.6301e-04 - mae: 0.0165 - val_loss: 0.0015 - val_mae: 0.0196 - learning_rate: 0.0010\n",
      "Epoch 23/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 4.8026e-04 - mae: 0.0169 - val_loss: 0.0015 - val_mae: 0.0316 - learning_rate: 0.0010\n",
      "Epoch 24/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 3.2071e-04 - mae: 0.0134 - val_loss: 0.0014 - val_mae: 0.0282 - learning_rate: 5.0000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 3.1368e-04 - mae: 0.0131 - val_loss: 0.0017 - val_mae: 0.0359 - learning_rate: 5.0000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 3.0639e-04 - mae: 0.0131 - val_loss: 0.0016 - val_mae: 0.0346 - learning_rate: 5.0000e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 3.2200e-04 - mae: 0.0134 - val_loss: 0.0012 - val_mae: 0.0260 - learning_rate: 5.0000e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 2.9513e-04 - mae: 0.0129 - val_loss: 0.0013 - val_mae: 0.0299 - learning_rate: 5.0000e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 3.1551e-04 - mae: 0.0134 - val_loss: 0.0013 - val_mae: 0.0293 - learning_rate: 5.0000e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 3.2235e-04 - mae: 0.0135 - val_loss: 0.0011 - val_mae: 0.0213 - learning_rate: 5.0000e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 3.0477e-04 - mae: 0.0130 - val_loss: 0.0012 - val_mae: 0.0160 - learning_rate: 5.0000e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 3.1531e-04 - mae: 0.0135 - val_loss: 0.0012 - val_mae: 0.0286 - learning_rate: 5.0000e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 3.0107e-04 - mae: 0.0131 - val_loss: 0.0011 - val_mae: 0.0232 - learning_rate: 5.0000e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 2.5393e-04 - mae: 0.0117 - val_loss: 0.0015 - val_mae: 0.0358 - learning_rate: 2.5000e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 2.4229e-04 - mae: 0.0114 - val_loss: 0.0015 - val_mae: 0.0351 - learning_rate: 2.5000e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 2.4171e-04 - mae: 0.0115 - val_loss: 0.0012 - val_mae: 0.0294 - learning_rate: 2.5000e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 2.3369e-04 - mae: 0.0113 - val_loss: 0.0011 - val_mae: 0.0279 - learning_rate: 1.2500e-04\n",
      "\u001b[1m83/83\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step   \n",
      " âœ… Haveri - wheat | MAE=26.18, RMSE=38.43, RÂ²=0.9884, MAPE=1.37%, Acc=98.63%\n",
      "\n",
      "ğŸš€ Processing: Kalburgi | capsicum\n",
      "Epoch 1/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 34ms/step - loss: 0.3798 - mae: 0.4509 - val_loss: 0.1070 - val_mae: 0.3029 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0315 - mae: 0.1389 - val_loss: 0.0185 - val_mae: 0.0798 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0227 - mae: 0.1151 - val_loss: 0.0188 - val_mae: 0.0818 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0203 - mae: 0.1120 - val_loss: 0.0173 - val_mae: 0.0791 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0193 - mae: 0.1066 - val_loss: 0.0204 - val_mae: 0.0948 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0173 - mae: 0.1012 - val_loss: 0.0166 - val_mae: 0.0804 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0166 - mae: 0.0993 - val_loss: 0.0212 - val_mae: 0.1035 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0155 - mae: 0.0950 - val_loss: 0.0215 - val_mae: 0.1077 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0143 - mae: 0.0939 - val_loss: 0.0196 - val_mae: 0.1010 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0139 - mae: 0.0911 - val_loss: 0.0149 - val_mae: 0.0804 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0126 - mae: 0.0859 - val_loss: 0.0129 - val_mae: 0.0721 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0117 - mae: 0.0833 - val_loss: 0.0117 - val_mae: 0.0699 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0123 - mae: 0.0829 - val_loss: 0.0134 - val_mae: 0.0763 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0117 - mae: 0.0831 - val_loss: 0.0105 - val_mae: 0.0694 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0112 - mae: 0.0793 - val_loss: 0.0101 - val_mae: 0.0686 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0112 - mae: 0.0813 - val_loss: 0.0104 - val_mae: 0.0676 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0106 - mae: 0.0785 - val_loss: 0.0135 - val_mae: 0.0792 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0109 - mae: 0.0787 - val_loss: 0.0116 - val_mae: 0.0706 - learning_rate: 5.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0097 - mae: 0.0756 - val_loss: 0.0093 - val_mae: 0.0691 - learning_rate: 2.5000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0103 - mae: 0.0774 - val_loss: 0.0090 - val_mae: 0.0695 - learning_rate: 2.5000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0101 - mae: 0.0761 - val_loss: 0.0094 - val_mae: 0.0678 - learning_rate: 2.5000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0098 - mae: 0.0747 - val_loss: 0.0088 - val_mae: 0.0707 - learning_rate: 2.5000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0098 - mae: 0.0730 - val_loss: 0.0087 - val_mae: 0.0704 - learning_rate: 2.5000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0093 - mae: 0.0726 - val_loss: 0.0086 - val_mae: 0.0721 - learning_rate: 2.5000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0101 - mae: 0.0763 - val_loss: 0.0094 - val_mae: 0.0673 - learning_rate: 2.5000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0084 - mae: 0.0686 - val_loss: 0.0091 - val_mae: 0.0686 - learning_rate: 2.5000e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0091 - mae: 0.0727 - val_loss: 0.0116 - val_mae: 0.0724 - learning_rate: 2.5000e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0088 - mae: 0.0706 - val_loss: 0.0085 - val_mae: 0.0734 - learning_rate: 1.2500e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0083 - mae: 0.0697 - val_loss: 0.0090 - val_mae: 0.0690 - learning_rate: 1.2500e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0087 - mae: 0.0708 - val_loss: 0.0089 - val_mae: 0.0693 - learning_rate: 1.2500e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0080 - mae: 0.0670 - val_loss: 0.0089 - val_mae: 0.0693 - learning_rate: 6.2500e-05\n",
      "Epoch 32/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0084 - mae: 0.0691 - val_loss: 0.0091 - val_mae: 0.0683 - learning_rate: 6.2500e-05\n",
      "Epoch 33/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0083 - mae: 0.0684 - val_loss: 0.0092 - val_mae: 0.0681 - learning_rate: 6.2500e-05\n",
      "Epoch 34/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0089 - mae: 0.0702 - val_loss: 0.0089 - val_mae: 0.0693 - learning_rate: 3.1250e-05\n",
      "Epoch 35/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0084 - mae: 0.0681 - val_loss: 0.0091 - val_mae: 0.0686 - learning_rate: 3.1250e-05\n",
      "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step \n",
      " âœ… Kalburgi - capsicum | MAE=431.07, RMSE=588.98, RÂ²=0.765, MAPE=20.68%, Acc=79.32%\n",
      "\n",
      "ğŸš€ Processing: Kalburgi | onion\n",
      "Epoch 1/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - loss: 0.2714 - mae: 0.3828 - val_loss: 0.0480 - val_mae: 0.2098 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0202 - mae: 0.1102 - val_loss: 0.0038 - val_mae: 0.0457 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0121 - mae: 0.0827 - val_loss: 0.0033 - val_mae: 0.0443 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0115 - mae: 0.0794 - val_loss: 0.0027 - val_mae: 0.0397 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0115 - mae: 0.0799 - val_loss: 0.0024 - val_mae: 0.0392 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0123 - mae: 0.0828 - val_loss: 0.0053 - val_mae: 0.0616 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0109 - mae: 0.0806 - val_loss: 0.0025 - val_mae: 0.0405 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0087 - mae: 0.0700 - val_loss: 0.0025 - val_mae: 0.0414 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0093 - mae: 0.0713 - val_loss: 0.0053 - val_mae: 0.0621 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0085 - mae: 0.0680 - val_loss: 0.0029 - val_mae: 0.0451 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0085 - mae: 0.0681 - val_loss: 0.0036 - val_mae: 0.0509 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0084 - mae: 0.0678 - val_loss: 0.0032 - val_mae: 0.0471 - learning_rate: 2.5000e-04\n",
      "\u001b[1m19/19\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step \n",
      " âœ… Kalburgi - onion | MAE=354.21, RMSE=475.0, RÂ²=0.5574, MAPE=25.87%, Acc=74.13%\n",
      "\n",
      "ğŸš€ Processing: Kalburgi | tomato\n",
      "Epoch 1/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 74ms/step - loss: 0.4823 - mae: 0.4068 - val_loss: 0.0216 - val_mae: 0.1318 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0250 - mae: 0.1235 - val_loss: 0.0089 - val_mae: 0.0735 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0186 - mae: 0.1016 - val_loss: 0.0091 - val_mae: 0.0768 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0163 - mae: 0.0954 - val_loss: 0.0100 - val_mae: 0.0868 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0157 - mae: 0.0942 - val_loss: 0.0091 - val_mae: 0.0824 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0149 - mae: 0.0914 - val_loss: 0.0072 - val_mae: 0.0717 - learning_rate: 5.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0137 - mae: 0.0886 - val_loss: 0.0057 - val_mae: 0.0636 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0146 - mae: 0.0905 - val_loss: 0.0051 - val_mae: 0.0557 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0139 - mae: 0.0898 - val_loss: 0.0045 - val_mae: 0.0555 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0145 - mae: 0.0914 - val_loss: 0.0042 - val_mae: 0.0533 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0134 - mae: 0.0870 - val_loss: 0.0037 - val_mae: 0.0472 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0129 - mae: 0.0841 - val_loss: 0.0034 - val_mae: 0.0456 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0131 - mae: 0.0842 - val_loss: 0.0039 - val_mae: 0.0481 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0138 - mae: 0.0868 - val_loss: 0.0045 - val_mae: 0.0549 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0134 - mae: 0.0862 - val_loss: 0.0034 - val_mae: 0.0455 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0127 - mae: 0.0843 - val_loss: 0.0028 - val_mae: 0.0393 - learning_rate: 2.5000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0126 - mae: 0.0831 - val_loss: 0.0027 - val_mae: 0.0386 - learning_rate: 2.5000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0127 - mae: 0.0855 - val_loss: 0.0035 - val_mae: 0.0436 - learning_rate: 2.5000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0132 - mae: 0.0849 - val_loss: 0.0028 - val_mae: 0.0392 - learning_rate: 2.5000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0119 - mae: 0.0804 - val_loss: 0.0030 - val_mae: 0.0406 - learning_rate: 2.5000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0122 - mae: 0.0826 - val_loss: 0.0027 - val_mae: 0.0398 - learning_rate: 1.2500e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0129 - mae: 0.0828 - val_loss: 0.0029 - val_mae: 0.0407 - learning_rate: 1.2500e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0128 - mae: 0.0832 - val_loss: 0.0023 - val_mae: 0.0352 - learning_rate: 1.2500e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0116 - mae: 0.0796 - val_loss: 0.0026 - val_mae: 0.0379 - learning_rate: 1.2500e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0116 - mae: 0.0786 - val_loss: 0.0028 - val_mae: 0.0398 - learning_rate: 1.2500e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0122 - mae: 0.0812 - val_loss: 0.0027 - val_mae: 0.0383 - learning_rate: 1.2500e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0117 - mae: 0.0804 - val_loss: 0.0026 - val_mae: 0.0380 - learning_rate: 6.2500e-05\n",
      "Epoch 28/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0114 - mae: 0.0784 - val_loss: 0.0026 - val_mae: 0.0380 - learning_rate: 6.2500e-05\n",
      "Epoch 29/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0114 - mae: 0.0779 - val_loss: 0.0025 - val_mae: 0.0374 - learning_rate: 6.2500e-05\n",
      "Epoch 30/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0112 - mae: 0.0774 - val_loss: 0.0027 - val_mae: 0.0387 - learning_rate: 3.1250e-05\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step \n",
      " âœ… Kalburgi - tomato | MAE=560.67, RMSE=846.02, RÂ²=0.7734, MAPE=42.14%, Acc=57.86%\n",
      "\n",
      "ğŸš€ Processing: Kalburgi | wheat\n",
      "Epoch 1/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - loss: 0.0347 - mae: 0.1186 - val_loss: 0.0215 - val_mae: 0.0858 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0039 - mae: 0.0494 - val_loss: 0.0193 - val_mae: 0.0771 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0024 - mae: 0.0379 - val_loss: 0.0185 - val_mae: 0.0649 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0020 - mae: 0.0342 - val_loss: 0.0137 - val_mae: 0.0577 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0012 - mae: 0.0270 - val_loss: 0.0132 - val_mae: 0.0589 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 9.7606e-04 - mae: 0.0238 - val_loss: 0.0127 - val_mae: 0.0498 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 9.0512e-04 - mae: 0.0227 - val_loss: 0.0132 - val_mae: 0.0477 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 6.9545e-04 - mae: 0.0198 - val_loss: 0.0133 - val_mae: 0.0404 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 5.8019e-04 - mae: 0.0177 - val_loss: 0.0118 - val_mae: 0.0561 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 5.5631e-04 - mae: 0.0176 - val_loss: 0.0120 - val_mae: 0.0500 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 4.7804e-04 - mae: 0.0159 - val_loss: 0.0119 - val_mae: 0.0441 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 4.8472e-04 - mae: 0.0163 - val_loss: 0.0117 - val_mae: 0.0502 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 4.3563e-04 - mae: 0.0153 - val_loss: 0.0118 - val_mae: 0.0582 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 4.2757e-04 - mae: 0.0148 - val_loss: 0.0124 - val_mae: 0.0523 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 4.0067e-04 - mae: 0.0147 - val_loss: 0.0123 - val_mae: 0.0370 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 2.8106e-04 - mae: 0.0115 - val_loss: 0.0120 - val_mae: 0.0392 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 2.8477e-04 - mae: 0.0118 - val_loss: 0.0123 - val_mae: 0.0382 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 3.1516e-04 - mae: 0.0128 - val_loss: 0.0130 - val_mae: 0.0344 - learning_rate: 5.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 2.4324e-04 - mae: 0.0107 - val_loss: 0.0132 - val_mae: 0.0365 - learning_rate: 2.5000e-04\n",
      "\u001b[1m84/84\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step   \n",
      " âœ… Kalburgi - wheat | MAE=96.73, RMSE=170.86, RÂ²=0.8442, MAPE=3.98%, Acc=96.02%\n",
      "\n",
      "ğŸš€ Processing: Karwar(Uttar Kannad) | onion\n",
      "Epoch 1/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - loss: 0.1932 - mae: 0.3080 - val_loss: 0.2386 - val_mae: 0.4323 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0249 - mae: 0.1187 - val_loss: 0.1049 - val_mae: 0.2703 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0116 - mae: 0.0825 - val_loss: 0.0672 - val_mae: 0.1988 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0092 - mae: 0.0752 - val_loss: 0.0722 - val_mae: 0.2043 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0075 - mae: 0.0685 - val_loss: 0.0772 - val_mae: 0.2044 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0068 - mae: 0.0654 - val_loss: 0.0736 - val_mae: 0.1881 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0057 - mae: 0.0595 - val_loss: 0.0646 - val_mae: 0.1649 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0048 - mae: 0.0545 - val_loss: 0.0596 - val_mae: 0.1531 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0050 - mae: 0.0551 - val_loss: 0.0764 - val_mae: 0.1855 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0047 - mae: 0.0530 - val_loss: 0.0643 - val_mae: 0.1627 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0045 - mae: 0.0526 - val_loss: 0.0635 - val_mae: 0.1562 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0038 - mae: 0.0488 - val_loss: 0.0603 - val_mae: 0.1493 - learning_rate: 2.5000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0045 - mae: 0.0517 - val_loss: 0.0581 - val_mae: 0.1436 - learning_rate: 2.5000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0039 - mae: 0.0486 - val_loss: 0.0601 - val_mae: 0.1475 - learning_rate: 2.5000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0037 - mae: 0.0484 - val_loss: 0.0624 - val_mae: 0.1526 - learning_rate: 2.5000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0039 - mae: 0.0480 - val_loss: 0.0559 - val_mae: 0.1376 - learning_rate: 2.5000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0036 - mae: 0.0474 - val_loss: 0.0587 - val_mae: 0.1428 - learning_rate: 2.5000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0035 - mae: 0.0459 - val_loss: 0.0543 - val_mae: 0.1326 - learning_rate: 2.5000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0037 - mae: 0.0469 - val_loss: 0.0562 - val_mae: 0.1366 - learning_rate: 2.5000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0031 - mae: 0.0425 - val_loss: 0.0610 - val_mae: 0.1491 - learning_rate: 2.5000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0031 - mae: 0.0430 - val_loss: 0.0602 - val_mae: 0.1478 - learning_rate: 2.5000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0031 - mae: 0.0428 - val_loss: 0.0554 - val_mae: 0.1351 - learning_rate: 1.2500e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0034 - mae: 0.0452 - val_loss: 0.0553 - val_mae: 0.1345 - learning_rate: 1.2500e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0031 - mae: 0.0430 - val_loss: 0.0533 - val_mae: 0.1295 - learning_rate: 1.2500e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0032 - mae: 0.0435 - val_loss: 0.0559 - val_mae: 0.1367 - learning_rate: 1.2500e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0030 - mae: 0.0422 - val_loss: 0.0578 - val_mae: 0.1424 - learning_rate: 1.2500e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0029 - mae: 0.0412 - val_loss: 0.0536 - val_mae: 0.1316 - learning_rate: 1.2500e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0028 - mae: 0.0401 - val_loss: 0.0542 - val_mae: 0.1334 - learning_rate: 6.2500e-05\n",
      "Epoch 29/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0028 - mae: 0.0410 - val_loss: 0.0586 - val_mae: 0.1449 - learning_rate: 6.2500e-05\n",
      "Epoch 30/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0027 - mae: 0.0389 - val_loss: 0.0588 - val_mae: 0.1456 - learning_rate: 6.2500e-05\n",
      "Epoch 31/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0027 - mae: 0.0394 - val_loss: 0.0587 - val_mae: 0.1453 - learning_rate: 3.1250e-05\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step \n",
      " âœ… Karwar(Uttar Kannad) - onion | MAE=269.07, RMSE=413.74, RÂ²=0.889, MAPE=13.95%, Acc=86.05%\n",
      "\n",
      "ğŸš€ Processing: Karwar(Uttar Kannad) | tomato\n",
      "Epoch 1/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 55ms/step - loss: 0.9019 - mae: 0.7186 - val_loss: 0.1032 - val_mae: 0.2611 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0847 - mae: 0.2444 - val_loss: 0.0292 - val_mae: 0.1408 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0274 - mae: 0.1340 - val_loss: 0.0296 - val_mae: 0.1261 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0182 - mae: 0.1054 - val_loss: 0.0488 - val_mae: 0.1636 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0132 - mae: 0.0924 - val_loss: 0.0521 - val_mae: 0.1708 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0127 - mae: 0.0897 - val_loss: 0.0574 - val_mae: 0.1821 - learning_rate: 5.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0123 - mae: 0.0873 - val_loss: 0.0543 - val_mae: 0.1753 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0131 - mae: 0.0913 - val_loss: 0.0529 - val_mae: 0.1734 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0129 - mae: 0.0891 - val_loss: 0.0586 - val_mae: 0.1852 - learning_rate: 2.5000e-04\n",
      "\u001b[1m9/9\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step \n",
      " âœ… Karwar(Uttar Kannad) - tomato | MAE=893.22, RMSE=972.96, RÂ²=-0.5963, MAPE=132.19%, Acc=-32.19%\n",
      "\n",
      "ğŸš€ Processing: Karwar(Uttar Kannad) | wheat\n",
      "Epoch 1/50\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 33ms/step - loss: 0.3851 - mae: 0.4378 - val_loss: 0.0091 - val_mae: 0.0937 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0210 - mae: 0.1142 - val_loss: 0.0012 - val_mae: 0.0224 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0131 - mae: 0.0878 - val_loss: 8.5286e-04 - val_mae: 0.0101 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0131 - mae: 0.0892 - val_loss: 8.6037e-04 - val_mae: 0.0106 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0125 - mae: 0.0870 - val_loss: 9.0533e-04 - val_mae: 0.0132 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0120 - mae: 0.0853 - val_loss: 8.4411e-04 - val_mae: 0.0094 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0112 - mae: 0.0815 - val_loss: 0.0013 - val_mae: 0.0256 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0112 - mae: 0.0818 - val_loss: 9.8550e-04 - val_mae: 0.0167 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0108 - mae: 0.0802 - val_loss: 0.0015 - val_mae: 0.0303 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0100 - mae: 0.0771 - val_loss: 0.0032 - val_mae: 0.0518 - learning_rate: 2.5000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0097 - mae: 0.0760 - val_loss: 0.0022 - val_mae: 0.0411 - learning_rate: 2.5000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0093 - mae: 0.0744 - val_loss: 0.0042 - val_mae: 0.0616 - learning_rate: 2.5000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0087 - mae: 0.0715 - val_loss: 0.0032 - val_mae: 0.0521 - learning_rate: 1.2500e-04\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step \n",
      " âœ… Karwar(Uttar Kannad) - wheat | MAE=53.27, RMSE=89.23, RÂ²=0.6462, MAPE=3.58%, Acc=96.42%\n",
      "\n",
      "ğŸš€ Processing: Kolar | capsicum\n",
      "Epoch 1/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - loss: 0.0360 - mae: 0.1277 - val_loss: 0.0133 - val_mae: 0.0949 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0076 - mae: 0.0671 - val_loss: 0.0113 - val_mae: 0.0871 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0056 - mae: 0.0580 - val_loss: 0.0091 - val_mae: 0.0778 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0050 - mae: 0.0539 - val_loss: 0.0067 - val_mae: 0.0637 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0038 - mae: 0.0471 - val_loss: 0.0081 - val_mae: 0.0752 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0037 - mae: 0.0463 - val_loss: 0.0081 - val_mae: 0.0749 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0032 - mae: 0.0422 - val_loss: 0.0088 - val_mae: 0.0808 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0028 - mae: 0.0391 - val_loss: 0.0052 - val_mae: 0.0531 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0023 - mae: 0.0354 - val_loss: 0.0050 - val_mae: 0.0519 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0023 - mae: 0.0349 - val_loss: 0.0048 - val_mae: 0.0511 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0023 - mae: 0.0346 - val_loss: 0.0048 - val_mae: 0.0525 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0024 - mae: 0.0357 - val_loss: 0.0046 - val_mae: 0.0518 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0021 - mae: 0.0334 - val_loss: 0.0054 - val_mae: 0.0598 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0022 - mae: 0.0340 - val_loss: 0.0049 - val_mae: 0.0558 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0021 - mae: 0.0334 - val_loss: 0.0074 - val_mae: 0.0726 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0020 - mae: 0.0318 - val_loss: 0.0043 - val_mae: 0.0512 - learning_rate: 2.5000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0019 - mae: 0.0313 - val_loss: 0.0044 - val_mae: 0.0526 - learning_rate: 2.5000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0019 - mae: 0.0312 - val_loss: 0.0042 - val_mae: 0.0499 - learning_rate: 2.5000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0019 - mae: 0.0310 - val_loss: 0.0042 - val_mae: 0.0489 - learning_rate: 2.5000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0019 - mae: 0.0307 - val_loss: 0.0042 - val_mae: 0.0500 - learning_rate: 2.5000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0019 - mae: 0.0309 - val_loss: 0.0041 - val_mae: 0.0484 - learning_rate: 2.5000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0019 - mae: 0.0313 - val_loss: 0.0041 - val_mae: 0.0490 - learning_rate: 2.5000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0019 - mae: 0.0311 - val_loss: 0.0042 - val_mae: 0.0502 - learning_rate: 2.5000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0018 - mae: 0.0301 - val_loss: 0.0043 - val_mae: 0.0506 - learning_rate: 2.5000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0018 - mae: 0.0298 - val_loss: 0.0041 - val_mae: 0.0489 - learning_rate: 1.2500e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0017 - mae: 0.0295 - val_loss: 0.0041 - val_mae: 0.0493 - learning_rate: 1.2500e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0017 - mae: 0.0289 - val_loss: 0.0040 - val_mae: 0.0484 - learning_rate: 1.2500e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0017 - mae: 0.0288 - val_loss: 0.0042 - val_mae: 0.0505 - learning_rate: 6.2500e-05\n",
      "Epoch 29/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0017 - mae: 0.0288 - val_loss: 0.0044 - val_mae: 0.0523 - learning_rate: 6.2500e-05\n",
      "Epoch 30/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0017 - mae: 0.0290 - val_loss: 0.0042 - val_mae: 0.0508 - learning_rate: 6.2500e-05\n",
      "Epoch 31/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0017 - mae: 0.0289 - val_loss: 0.0040 - val_mae: 0.0492 - learning_rate: 3.1250e-05\n",
      "Epoch 32/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0017 - mae: 0.0287 - val_loss: 0.0040 - val_mae: 0.0490 - learning_rate: 3.1250e-05\n",
      "Epoch 33/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0017 - mae: 0.0288 - val_loss: 0.0040 - val_mae: 0.0485 - learning_rate: 3.1250e-05\n",
      "Epoch 34/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0017 - mae: 0.0285 - val_loss: 0.0041 - val_mae: 0.0496 - learning_rate: 1.5625e-05\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step   \n",
      " âœ… Kolar - capsicum | MAE=168.16, RMSE=235.31, RÂ²=0.9415, MAPE=7.15%, Acc=92.85%\n",
      "\n",
      "ğŸš€ Processing: Kolar | onion\n",
      "Epoch 1/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 19ms/step - loss: 0.0796 - mae: 0.1534 - val_loss: 0.0176 - val_mae: 0.0853 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0093 - mae: 0.0738 - val_loss: 0.0110 - val_mae: 0.0726 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0065 - mae: 0.0617 - val_loss: 0.0080 - val_mae: 0.0610 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0049 - mae: 0.0536 - val_loss: 0.0117 - val_mae: 0.0827 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0039 - mae: 0.0463 - val_loss: 0.0059 - val_mae: 0.0522 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0028 - mae: 0.0389 - val_loss: 0.0077 - val_mae: 0.0680 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0026 - mae: 0.0375 - val_loss: 0.0051 - val_mae: 0.0535 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0021 - mae: 0.0334 - val_loss: 0.0040 - val_mae: 0.0454 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0019 - mae: 0.0307 - val_loss: 0.0036 - val_mae: 0.0440 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0017 - mae: 0.0285 - val_loss: 0.0028 - val_mae: 0.0368 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0017 - mae: 0.0282 - val_loss: 0.0025 - val_mae: 0.0327 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0014 - mae: 0.0258 - val_loss: 0.0025 - val_mae: 0.0341 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0013 - mae: 0.0251 - val_loss: 0.0021 - val_mae: 0.0300 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0012 - mae: 0.0239 - val_loss: 0.0018 - val_mae: 0.0282 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0011 - mae: 0.0223 - val_loss: 0.0017 - val_mae: 0.0282 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0012 - mae: 0.0232 - val_loss: 0.0016 - val_mae: 0.0272 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0011 - mae: 0.0226 - val_loss: 0.0016 - val_mae: 0.0274 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0011 - mae: 0.0221 - val_loss: 0.0024 - val_mae: 0.0361 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0011 - mae: 0.0223 - val_loss: 0.0016 - val_mae: 0.0296 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 8.8838e-04 - mae: 0.0196 - val_loss: 0.0014 - val_mae: 0.0257 - learning_rate: 5.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 9.9702e-04 - mae: 0.0213 - val_loss: 0.0013 - val_mae: 0.0253 - learning_rate: 5.0000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 9.8150e-04 - mae: 0.0208 - val_loss: 0.0014 - val_mae: 0.0263 - learning_rate: 5.0000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 8.7666e-04 - mae: 0.0194 - val_loss: 0.0013 - val_mae: 0.0252 - learning_rate: 5.0000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 8.0684e-04 - mae: 0.0181 - val_loss: 0.0014 - val_mae: 0.0260 - learning_rate: 2.5000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 7.9883e-04 - mae: 0.0182 - val_loss: 0.0013 - val_mae: 0.0248 - learning_rate: 2.5000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 8.0362e-04 - mae: 0.0181 - val_loss: 0.0013 - val_mae: 0.0247 - learning_rate: 2.5000e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 7.8075e-04 - mae: 0.0179 - val_loss: 0.0013 - val_mae: 0.0246 - learning_rate: 2.5000e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 7.9441e-04 - mae: 0.0181 - val_loss: 0.0013 - val_mae: 0.0243 - learning_rate: 2.5000e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 7.4108e-04 - mae: 0.0170 - val_loss: 0.0012 - val_mae: 0.0242 - learning_rate: 1.2500e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 7.2705e-04 - mae: 0.0171 - val_loss: 0.0012 - val_mae: 0.0239 - learning_rate: 1.2500e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 7.2074e-04 - mae: 0.0167 - val_loss: 0.0013 - val_mae: 0.0243 - learning_rate: 1.2500e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 7.0210e-04 - mae: 0.0166 - val_loss: 0.0012 - val_mae: 0.0239 - learning_rate: 6.2500e-05\n",
      "Epoch 33/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 7.1981e-04 - mae: 0.0165 - val_loss: 0.0012 - val_mae: 0.0247 - learning_rate: 6.2500e-05\n",
      "Epoch 34/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 6.8934e-04 - mae: 0.0162 - val_loss: 0.0012 - val_mae: 0.0238 - learning_rate: 6.2500e-05\n",
      "Epoch 35/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 6.7281e-04 - mae: 0.0160 - val_loss: 0.0012 - val_mae: 0.0243 - learning_rate: 3.1250e-05\n",
      "Epoch 36/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 6.6800e-04 - mae: 0.0159 - val_loss: 0.0012 - val_mae: 0.0251 - learning_rate: 3.1250e-05\n",
      "Epoch 37/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 6.7485e-04 - mae: 0.0161 - val_loss: 0.0013 - val_mae: 0.0259 - learning_rate: 3.1250e-05\n",
      "Epoch 38/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 6.8080e-04 - mae: 0.0157 - val_loss: 0.0012 - val_mae: 0.0244 - learning_rate: 1.5625e-05\n",
      "Epoch 39/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 6.7164e-04 - mae: 0.0157 - val_loss: 0.0013 - val_mae: 0.0253 - learning_rate: 1.5625e-05\n",
      "Epoch 40/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 6.6132e-04 - mae: 0.0156 - val_loss: 0.0012 - val_mae: 0.0247 - learning_rate: 1.5625e-05\n",
      "Epoch 41/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 6.7021e-04 - mae: 0.0157 - val_loss: 0.0012 - val_mae: 0.0243 - learning_rate: 7.8125e-06\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step  \n",
      " âœ… Kolar - onion | MAE=83.95, RMSE=144.38, RÂ²=0.974, MAPE=4.68%, Acc=95.32%\n",
      "\n",
      "ğŸš€ Processing: Kolar | tomato\n",
      "Epoch 1/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 18ms/step - loss: 0.0795 - mae: 0.1526 - val_loss: 0.0181 - val_mae: 0.0937 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0053 - mae: 0.0572 - val_loss: 0.0093 - val_mae: 0.0476 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0045 - mae: 0.0523 - val_loss: 0.0072 - val_mae: 0.0421 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0035 - mae: 0.0471 - val_loss: 0.0061 - val_mae: 0.0382 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0033 - mae: 0.0451 - val_loss: 0.0057 - val_mae: 0.0428 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0030 - mae: 0.0431 - val_loss: 0.0046 - val_mae: 0.0347 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0023 - mae: 0.0383 - val_loss: 0.0055 - val_mae: 0.0426 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0022 - mae: 0.0371 - val_loss: 0.0039 - val_mae: 0.0329 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0020 - mae: 0.0345 - val_loss: 0.0044 - val_mae: 0.0386 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0018 - mae: 0.0331 - val_loss: 0.0051 - val_mae: 0.0449 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0019 - mae: 0.0340 - val_loss: 0.0048 - val_mae: 0.0422 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0013 - mae: 0.0274 - val_loss: 0.0061 - val_mae: 0.0560 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0013 - mae: 0.0273 - val_loss: 0.0052 - val_mae: 0.0496 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0012 - mae: 0.0260 - val_loss: 0.0073 - val_mae: 0.0661 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0010 - mae: 0.0246 - val_loss: 0.0055 - val_mae: 0.0534 - learning_rate: 2.5000e-04\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step   \n",
      " âœ… Kolar - tomato | MAE=173.15, RMSE=296.35, RÂ²=0.8517, MAPE=17.68%, Acc=82.32%\n",
      "\n",
      "ğŸš€ Processing: Kolar | wheat\n",
      "Epoch 1/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 18ms/step - loss: 0.0297 - mae: 0.1072 - val_loss: 0.0423 - val_mae: 0.1738 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0048 - mae: 0.0556 - val_loss: 0.0293 - val_mae: 0.1416 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0031 - mae: 0.0441 - val_loss: 0.0191 - val_mae: 0.1070 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0021 - mae: 0.0371 - val_loss: 0.0173 - val_mae: 0.1041 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0016 - mae: 0.0316 - val_loss: 0.0145 - val_mae: 0.0956 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0012 - mae: 0.0274 - val_loss: 0.0105 - val_mae: 0.0735 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0013 - mae: 0.0281 - val_loss: 0.0100 - val_mae: 0.0717 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 8.0549e-04 - mae: 0.0225 - val_loss: 0.0069 - val_mae: 0.0507 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 5.9779e-04 - mae: 0.0193 - val_loss: 0.0063 - val_mae: 0.0474 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 5.5109e-04 - mae: 0.0185 - val_loss: 0.0067 - val_mae: 0.0496 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 4.3471e-04 - mae: 0.0164 - val_loss: 0.0060 - val_mae: 0.0459 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 4.1273e-04 - mae: 0.0161 - val_loss: 0.0054 - val_mae: 0.0434 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 5.1359e-04 - mae: 0.0181 - val_loss: 0.0090 - val_mae: 0.0689 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 3.6261e-04 - mae: 0.0149 - val_loss: 0.0064 - val_mae: 0.0494 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 3.3868e-04 - mae: 0.0146 - val_loss: 0.0045 - val_mae: 0.0431 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 3.0166e-04 - mae: 0.0136 - val_loss: 0.0056 - val_mae: 0.0432 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 2.2011e-04 - mae: 0.0116 - val_loss: 0.0041 - val_mae: 0.0468 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 2.2727e-04 - mae: 0.0118 - val_loss: 0.0061 - val_mae: 0.0455 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 2.4521e-04 - mae: 0.0123 - val_loss: 0.0058 - val_mae: 0.0436 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 2.3872e-04 - mae: 0.0121 - val_loss: 0.0039 - val_mae: 0.0443 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 1.6878e-04 - mae: 0.0100 - val_loss: 0.0043 - val_mae: 0.0448 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 2.2735e-04 - mae: 0.0120 - val_loss: 0.0057 - val_mae: 0.0425 - learning_rate: 0.0010\n",
      "Epoch 23/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 2.0037e-04 - mae: 0.0110 - val_loss: 0.0048 - val_mae: 0.0436 - learning_rate: 0.0010\n",
      "Epoch 24/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 1.3061e-04 - mae: 0.0087 - val_loss: 0.0048 - val_mae: 0.0436 - learning_rate: 5.0000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 1.2439e-04 - mae: 0.0085 - val_loss: 0.0049 - val_mae: 0.0434 - learning_rate: 5.0000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 1.1626e-04 - mae: 0.0081 - val_loss: 0.0045 - val_mae: 0.0446 - learning_rate: 5.0000e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 1.1092e-04 - mae: 0.0078 - val_loss: 0.0045 - val_mae: 0.0450 - learning_rate: 2.5000e-04\n",
      "\u001b[1m84/84\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step  \n",
      " âœ… Kolar - wheat | MAE=61.2, RMSE=97.94, RÂ²=0.9662, MAPE=2.62%, Acc=97.38%\n",
      "\n",
      "ğŸš€ Processing: Koppal | onion\n",
      "Epoch 1/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 257ms/step - loss: 0.4191 - mae: 0.5599 - val_loss: 0.0950 - val_mae: 0.3068 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.2274 - mae: 0.4094 - val_loss: 0.0269 - val_mae: 0.1620 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.1212 - mae: 0.2912 - val_loss: 0.0726 - val_mae: 0.2684 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0674 - mae: 0.2159 - val_loss: 0.0016 - val_mae: 0.0316 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0506 - mae: 0.1806 - val_loss: 0.2378 - val_mae: 0.4871 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0543 - mae: 0.1866 - val_loss: 0.0488 - val_mae: 0.2194 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0466 - mae: 0.1868 - val_loss: 0.0845 - val_mae: 0.2896 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0263 - mae: 0.1181 - val_loss: 0.1960 - val_mae: 0.4419 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0269 - mae: 0.1122 - val_loss: 0.1347 - val_mae: 0.3661 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0278 - mae: 0.1382 - val_loss: 0.1057 - val_mae: 0.3241 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0229 - mae: 0.1152 - val_loss: 0.1298 - val_mae: 0.3593 - learning_rate: 2.5000e-04\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 177ms/step\n",
      " âœ… Koppal - onion | MAE=1278.26, RMSE=1507.16, RÂ²=-0.4149, MAPE=86.11%, Acc=13.89%\n",
      "\n",
      "ğŸš€ Processing: Koppal | tomato\n",
      "Epoch 1/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 214ms/step - loss: 0.9258 - mae: 0.6660 - val_loss: 0.8573 - val_mae: 0.9259 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.5540 - mae: 0.5880 - val_loss: 0.4135 - val_mae: 0.6428 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.3432 - mae: 0.5705 - val_loss: 0.0966 - val_mae: 0.3098 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0669 - mae: 0.2209 - val_loss: 0.1431 - val_mae: 0.3774 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.1276 - mae: 0.3327 - val_loss: 6.1044e-04 - val_mae: 0.0189 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0380 - mae: 0.1630 - val_loss: 0.0764 - val_mae: 0.2762 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0516 - mae: 0.1987 - val_loss: 0.0021 - val_mae: 0.0450 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0270 - mae: 0.1414 - val_loss: 0.0405 - val_mae: 0.2011 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0255 - mae: 0.1420 - val_loss: 0.0041 - val_mae: 0.0636 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0103 - mae: 0.0789 - val_loss: 0.0098 - val_mae: 0.0982 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0202 - mae: 0.1260 - val_loss: 0.0086 - val_mae: 0.0923 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0145 - mae: 0.1028 - val_loss: 7.5906e-04 - val_mae: 0.0256 - learning_rate: 2.5000e-04\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 163ms/step\n",
      " âœ… Koppal - tomato | MAE=403.28, RMSE=517.2, RÂ²=-0.1756, MAPE=70.97%, Acc=29.03%\n",
      "\n",
      "ğŸš€ Processing: Koppal | wheat\n",
      "Epoch 1/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0741 - mae: 0.1741 - val_loss: 0.0094 - val_mae: 0.0616 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0072 - mae: 0.0668 - val_loss: 0.0088 - val_mae: 0.0854 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0041 - mae: 0.0503 - val_loss: 0.0051 - val_mae: 0.0656 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0030 - mae: 0.0434 - val_loss: 0.0069 - val_mae: 0.0760 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0023 - mae: 0.0376 - val_loss: 0.0043 - val_mae: 0.0603 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0020 - mae: 0.0355 - val_loss: 0.0062 - val_mae: 0.0727 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0014 - mae: 0.0296 - val_loss: 0.0047 - val_mae: 0.0625 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0012 - mae: 0.0271 - val_loss: 0.0107 - val_mae: 0.0994 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0011 - mae: 0.0250 - val_loss: 0.0024 - val_mae: 0.0450 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 9.7406e-04 - mae: 0.0238 - val_loss: 0.0061 - val_mae: 0.0725 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 8.2664e-04 - mae: 0.0220 - val_loss: 0.0057 - val_mae: 0.0694 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 8.3167e-04 - mae: 0.0218 - val_loss: 0.0059 - val_mae: 0.0713 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 7.5204e-04 - mae: 0.0207 - val_loss: 0.0035 - val_mae: 0.0537 - learning_rate: 2.5000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 7.0662e-04 - mae: 0.0201 - val_loss: 0.0053 - val_mae: 0.0672 - learning_rate: 2.5000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 7.6361e-04 - mae: 0.0209 - val_loss: 0.0073 - val_mae: 0.0806 - learning_rate: 2.5000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 7.0319e-04 - mae: 0.0198 - val_loss: 0.0053 - val_mae: 0.0676 - learning_rate: 1.2500e-04\n",
      "\u001b[1m81/81\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step   \n",
      " âœ… Koppal - wheat | MAE=41.73, RMSE=54.68, RÂ²=0.9818, MAPE=2.29%, Acc=97.71%\n",
      "\n",
      "ğŸš€ Processing: Madikeri(Kodagu) | onion\n",
      "Epoch 1/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 32ms/step - loss: 0.0462 - mae: 0.1444 - val_loss: 9.7659e-04 - val_mae: 0.0266 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0073 - mae: 0.0668 - val_loss: 0.0037 - val_mae: 0.0605 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0041 - mae: 0.0503 - val_loss: 0.0037 - val_mae: 0.0598 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0031 - mae: 0.0436 - val_loss: 5.9097e-04 - val_mae: 0.0216 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0022 - mae: 0.0362 - val_loss: 3.0160e-04 - val_mae: 0.0153 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0017 - mae: 0.0318 - val_loss: 0.0133 - val_mae: 0.1138 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0015 - mae: 0.0302 - val_loss: 0.0257 - val_mae: 0.1588 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0013 - mae: 0.0276 - val_loss: 9.9730e-04 - val_mae: 0.0270 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 7.7715e-04 - mae: 0.0206 - val_loss: 0.0044 - val_mae: 0.0639 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 7.8508e-04 - mae: 0.0205 - val_loss: 3.7985e-04 - val_mae: 0.0150 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 6.9729e-04 - mae: 0.0197 - val_loss: 4.2688e-04 - val_mae: 0.0182 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 5.7853e-04 - mae: 0.0177 - val_loss: 7.9014e-04 - val_mae: 0.0260 - learning_rate: 2.5000e-04\n",
      "\u001b[1m77/77\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step   \n",
      " âœ… Madikeri(Kodagu) - onion | MAE=47.19, RMSE=57.51, RÂ²=0.986, MAPE=3.91%, Acc=96.09%\n",
      "\n",
      "ğŸš€ Processing: Madikeri(Kodagu) | tomato\n",
      "Epoch 1/50\n",
      "\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - loss: 0.0577 - mae: 0.1757 - val_loss: 0.0217 - val_mae: 0.1343 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0178 - mae: 0.1050 - val_loss: 0.0301 - val_mae: 0.1688 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0118 - mae: 0.0874 - val_loss: 0.0018 - val_mae: 0.0366 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0087 - mae: 0.0737 - val_loss: 4.2527e-04 - val_mae: 0.0176 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0056 - mae: 0.0598 - val_loss: 1.1690e-04 - val_mae: 0.0093 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0043 - mae: 0.0522 - val_loss: 0.0010 - val_mae: 0.0314 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0042 - mae: 0.0514 - val_loss: 0.0029 - val_mae: 0.0535 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0044 - mae: 0.0516 - val_loss: 8.0757e-04 - val_mae: 0.0275 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0025 - mae: 0.0390 - val_loss: 0.0037 - val_mae: 0.0610 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0027 - mae: 0.0407 - val_loss: 8.6073e-04 - val_mae: 0.0287 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0022 - mae: 0.0367 - val_loss: 0.0079 - val_mae: 0.0888 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0025 - mae: 0.0389 - val_loss: 5.6399e-04 - val_mae: 0.0227 - learning_rate: 2.5000e-04\n",
      "\u001b[1m51/51\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step  \n",
      " âœ… Madikeri(Kodagu) - tomato | MAE=42.88, RMSE=57.66, RÂ²=0.9612, MAPE=5.31%, Acc=94.69%\n",
      "\n",
      "ğŸš€ Processing: Madikeri(Kodagu) | wheat\n",
      "Epoch 1/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - loss: 0.1983 - mae: 0.2174 - val_loss: 0.0765 - val_mae: 0.2675 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0109 - mae: 0.0764 - val_loss: 0.0588 - val_mae: 0.2313 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0095 - mae: 0.0702 - val_loss: 0.0600 - val_mae: 0.2334 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0096 - mae: 0.0702 - val_loss: 0.0724 - val_mae: 0.2554 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0086 - mae: 0.0658 - val_loss: 0.0581 - val_mae: 0.2283 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0081 - mae: 0.0639 - val_loss: 0.0492 - val_mae: 0.2075 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0079 - mae: 0.0645 - val_loss: 0.0577 - val_mae: 0.2225 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0072 - mae: 0.0610 - val_loss: 0.0333 - val_mae: 0.1695 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0065 - mae: 0.0563 - val_loss: 0.0364 - val_mae: 0.1699 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0061 - mae: 0.0545 - val_loss: 0.0279 - val_mae: 0.1446 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0057 - mae: 0.0532 - val_loss: 0.0075 - val_mae: 0.0721 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0053 - mae: 0.0508 - val_loss: 0.0058 - val_mae: 0.0703 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0045 - mae: 0.0471 - val_loss: 0.0081 - val_mae: 0.0802 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0043 - mae: 0.0454 - val_loss: 0.0093 - val_mae: 0.0868 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0034 - mae: 0.0407 - val_loss: 0.0124 - val_mae: 0.0957 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0020 - mae: 0.0302 - val_loss: 0.0235 - val_mae: 0.1376 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0016 - mae: 0.0270 - val_loss: 0.0335 - val_mae: 0.1687 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0014 - mae: 0.0244 - val_loss: 0.0333 - val_mae: 0.1693 - learning_rate: 5.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0012 - mae: 0.0223 - val_loss: 0.0311 - val_mae: 0.1625 - learning_rate: 2.5000e-04\n",
      "\u001b[1m71/71\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step  \n",
      " âœ… Madikeri(Kodagu) - wheat | MAE=817.71, RMSE=1057.5, RÂ²=0.9657, MAPE=33.53%, Acc=66.47%\n",
      "\n",
      "ğŸš€ Processing: Mandya | capsicum\n",
      "Epoch 1/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - loss: 0.0400 - mae: 0.1319 - val_loss: 0.0863 - val_mae: 0.2714 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0101 - mae: 0.0760 - val_loss: 0.0382 - val_mae: 0.1705 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0054 - mae: 0.0555 - val_loss: 0.0129 - val_mae: 0.0928 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0048 - mae: 0.0531 - val_loss: 0.0164 - val_mae: 0.1062 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0033 - mae: 0.0436 - val_loss: 0.0071 - val_mae: 0.0692 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0033 - mae: 0.0440 - val_loss: 0.0091 - val_mae: 0.0781 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0026 - mae: 0.0384 - val_loss: 0.0060 - val_mae: 0.0616 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0019 - mae: 0.0317 - val_loss: 0.0064 - val_mae: 0.0632 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0019 - mae: 0.0315 - val_loss: 0.0063 - val_mae: 0.0602 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0017 - mae: 0.0298 - val_loss: 0.0072 - val_mae: 0.0640 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0014 - mae: 0.0257 - val_loss: 0.0070 - val_mae: 0.0565 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0014 - mae: 0.0265 - val_loss: 0.0069 - val_mae: 0.0565 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0014 - mae: 0.0262 - val_loss: 0.0070 - val_mae: 0.0575 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0012 - mae: 0.0250 - val_loss: 0.0078 - val_mae: 0.0580 - learning_rate: 2.5000e-04\n",
      "\u001b[1m78/78\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step   \n",
      " âœ… Mandya - capsicum | MAE=144.07, RMSE=191.67, RÂ²=0.9662, MAPE=10.17%, Acc=89.83%\n",
      "\n",
      "ğŸš€ Processing: Mandya | onion\n",
      "Epoch 1/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0324 - mae: 0.1115 - val_loss: 0.0319 - val_mae: 0.1500 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0057 - mae: 0.0578 - val_loss: 0.0053 - val_mae: 0.0599 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0040 - mae: 0.0480 - val_loss: 0.0048 - val_mae: 0.0483 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0026 - mae: 0.0379 - val_loss: 0.0039 - val_mae: 0.0528 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0021 - mae: 0.0332 - val_loss: 0.0028 - val_mae: 0.0410 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0016 - mae: 0.0278 - val_loss: 0.0033 - val_mae: 0.0476 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0012 - mae: 0.0239 - val_loss: 0.0026 - val_mae: 0.0411 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0012 - mae: 0.0236 - val_loss: 0.0025 - val_mae: 0.0394 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0010 - mae: 0.0213 - val_loss: 0.0028 - val_mae: 0.0425 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 9.3908e-04 - mae: 0.0204 - val_loss: 0.0026 - val_mae: 0.0410 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 8.0576e-04 - mae: 0.0192 - val_loss: 0.0032 - val_mae: 0.0461 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 6.4719e-04 - mae: 0.0169 - val_loss: 0.0020 - val_mae: 0.0330 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 5.3955e-04 - mae: 0.0158 - val_loss: 0.0021 - val_mae: 0.0344 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 6.0777e-04 - mae: 0.0168 - val_loss: 0.0022 - val_mae: 0.0351 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 5.1147e-04 - mae: 0.0156 - val_loss: 0.0022 - val_mae: 0.0350 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 4.5822e-04 - mae: 0.0146 - val_loss: 0.0019 - val_mae: 0.0309 - learning_rate: 2.5000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 4.3125e-04 - mae: 0.0139 - val_loss: 0.0021 - val_mae: 0.0330 - learning_rate: 2.5000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 4.4633e-04 - mae: 0.0145 - val_loss: 0.0018 - val_mae: 0.0279 - learning_rate: 2.5000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 4.0718e-04 - mae: 0.0136 - val_loss: 0.0018 - val_mae: 0.0284 - learning_rate: 2.5000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 4.1587e-04 - mae: 0.0138 - val_loss: 0.0018 - val_mae: 0.0279 - learning_rate: 2.5000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 3.9802e-04 - mae: 0.0132 - val_loss: 0.0018 - val_mae: 0.0278 - learning_rate: 2.5000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 3.9036e-04 - mae: 0.0132 - val_loss: 0.0020 - val_mae: 0.0295 - learning_rate: 1.2500e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 3.6777e-04 - mae: 0.0131 - val_loss: 0.0021 - val_mae: 0.0309 - learning_rate: 1.2500e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 3.7697e-04 - mae: 0.0131 - val_loss: 0.0027 - val_mae: 0.0384 - learning_rate: 1.2500e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 3.4817e-04 - mae: 0.0125 - val_loss: 0.0021 - val_mae: 0.0312 - learning_rate: 6.2500e-05\n",
      "\u001b[1m84/84\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step  \n",
      " âœ… Mandya - onion | MAE=58.64, RMSE=98.83, RÂ²=0.9602, MAPE=4.15%, Acc=95.85%\n",
      "\n",
      "ğŸš€ Processing: Mandya | tomato\n",
      "Epoch 1/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 18ms/step - loss: 0.0600 - mae: 0.1325 - val_loss: 0.0329 - val_mae: 0.1139 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0049 - mae: 0.0552 - val_loss: 0.0260 - val_mae: 0.0906 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0034 - mae: 0.0457 - val_loss: 0.0210 - val_mae: 0.0776 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0026 - mae: 0.0397 - val_loss: 0.0227 - val_mae: 0.0847 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0020 - mae: 0.0346 - val_loss: 0.0218 - val_mae: 0.0823 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0016 - mae: 0.0303 - val_loss: 0.0236 - val_mae: 0.0875 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0011 - mae: 0.0252 - val_loss: 0.0223 - val_mae: 0.0834 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0011 - mae: 0.0249 - val_loss: 0.0202 - val_mae: 0.0738 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 9.5645e-04 - mae: 0.0230 - val_loss: 0.0191 - val_mae: 0.0702 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 8.7873e-04 - mae: 0.0218 - val_loss: 0.0223 - val_mae: 0.0865 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 8.4710e-04 - mae: 0.0218 - val_loss: 0.0208 - val_mae: 0.0799 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 8.1257e-04 - mae: 0.0210 - val_loss: 0.0197 - val_mae: 0.0741 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 6.7607e-04 - mae: 0.0186 - val_loss: 0.0188 - val_mae: 0.0709 - learning_rate: 2.5000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 6.4699e-04 - mae: 0.0181 - val_loss: 0.0201 - val_mae: 0.0786 - learning_rate: 2.5000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 6.2852e-04 - mae: 0.0179 - val_loss: 0.0194 - val_mae: 0.0765 - learning_rate: 2.5000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 5.8243e-04 - mae: 0.0171 - val_loss: 0.0191 - val_mae: 0.0747 - learning_rate: 2.5000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 5.5647e-04 - mae: 0.0165 - val_loss: 0.0210 - val_mae: 0.0833 - learning_rate: 1.2500e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 5.8499e-04 - mae: 0.0167 - val_loss: 0.0202 - val_mae: 0.0797 - learning_rate: 1.2500e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 5.6951e-04 - mae: 0.0163 - val_loss: 0.0205 - val_mae: 0.0817 - learning_rate: 1.2500e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 5.5341e-04 - mae: 0.0159 - val_loss: 0.0193 - val_mae: 0.0756 - learning_rate: 6.2500e-05\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step  \n",
      " âœ… Mandya - tomato | MAE=173.05, RMSE=500.85, RÂ²=0.5982, MAPE=12.76%, Acc=87.24%\n",
      "\n",
      "ğŸš€ Processing: Mandya | wheat\n",
      "Epoch 1/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 31ms/step - loss: 0.1306 - mae: 0.2403 - val_loss: 0.0063 - val_mae: 0.0680 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0166 - mae: 0.1021 - val_loss: 0.0048 - val_mae: 0.0596 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0079 - mae: 0.0686 - val_loss: 0.0029 - val_mae: 0.0478 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0066 - mae: 0.0635 - val_loss: 0.0033 - val_mae: 0.0545 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0058 - mae: 0.0595 - val_loss: 2.3753e-04 - val_mae: 0.0136 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0047 - mae: 0.0534 - val_loss: 5.7495e-04 - val_mae: 0.0190 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0040 - mae: 0.0495 - val_loss: 4.9016e-04 - val_mae: 0.0151 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0034 - mae: 0.0456 - val_loss: 0.0020 - val_mae: 0.0418 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0026 - mae: 0.0393 - val_loss: 0.0025 - val_mae: 0.0477 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0024 - mae: 0.0381 - val_loss: 6.4147e-04 - val_mae: 0.0202 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0020 - mae: 0.0346 - val_loss: 0.0015 - val_mae: 0.0325 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0018 - mae: 0.0333 - val_loss: 5.6628e-04 - val_mae: 0.0202 - learning_rate: 2.5000e-04\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step  \n",
      " âœ… Mandya - wheat | MAE=68.7, RMSE=101.31, RÂ²=0.8883, MAPE=3.25%, Acc=96.75%\n",
      "\n",
      "ğŸš€ Processing: Mangalore(Dakshin Kannad) | onion\n",
      "Epoch 1/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0752 - mae: 0.1553 - val_loss: 0.0150 - val_mae: 0.0912 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0067 - mae: 0.0637 - val_loss: 0.0115 - val_mae: 0.0788 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0051 - mae: 0.0557 - val_loss: 0.0090 - val_mae: 0.0554 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0046 - mae: 0.0521 - val_loss: 0.0090 - val_mae: 0.0621 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0035 - mae: 0.0462 - val_loss: 0.0090 - val_mae: 0.0656 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0028 - mae: 0.0399 - val_loss: 0.0084 - val_mae: 0.0639 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0023 - mae: 0.0360 - val_loss: 0.0092 - val_mae: 0.0738 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0019 - mae: 0.0330 - val_loss: 0.0081 - val_mae: 0.0635 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0018 - mae: 0.0324 - val_loss: 0.0072 - val_mae: 0.0547 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0017 - mae: 0.0311 - val_loss: 0.0072 - val_mae: 0.0585 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0014 - mae: 0.0275 - val_loss: 0.0064 - val_mae: 0.0518 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0013 - mae: 0.0266 - val_loss: 0.0063 - val_mae: 0.0518 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0011 - mae: 0.0235 - val_loss: 0.0058 - val_mae: 0.0488 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0011 - mae: 0.0246 - val_loss: 0.0056 - val_mae: 0.0517 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 9.8590e-04 - mae: 0.0222 - val_loss: 0.0049 - val_mae: 0.0428 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 9.5302e-04 - mae: 0.0220 - val_loss: 0.0045 - val_mae: 0.0419 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 9.0271e-04 - mae: 0.0210 - val_loss: 0.0042 - val_mae: 0.0404 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 7.9690e-04 - mae: 0.0199 - val_loss: 0.0040 - val_mae: 0.0378 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 8.5603e-04 - mae: 0.0210 - val_loss: 0.0038 - val_mae: 0.0374 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 7.8800e-04 - mae: 0.0199 - val_loss: 0.0036 - val_mae: 0.0397 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 7.4911e-04 - mae: 0.0193 - val_loss: 0.0033 - val_mae: 0.0365 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 7.9501e-04 - mae: 0.0201 - val_loss: 0.0033 - val_mae: 0.0361 - learning_rate: 0.0010\n",
      "Epoch 23/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 6.7570e-04 - mae: 0.0186 - val_loss: 0.0033 - val_mae: 0.0359 - learning_rate: 0.0010\n",
      "Epoch 24/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 5.7604e-04 - mae: 0.0166 - val_loss: 0.0029 - val_mae: 0.0352 - learning_rate: 0.0010\n",
      "Epoch 25/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 6.4718e-04 - mae: 0.0183 - val_loss: 0.0028 - val_mae: 0.0347 - learning_rate: 0.0010\n",
      "Epoch 26/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 5.5635e-04 - mae: 0.0166 - val_loss: 0.0027 - val_mae: 0.0338 - learning_rate: 0.0010\n",
      "Epoch 27/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 5.3512e-04 - mae: 0.0166 - val_loss: 0.0038 - val_mae: 0.0428 - learning_rate: 0.0010\n",
      "Epoch 28/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 5.0251e-04 - mae: 0.0156 - val_loss: 0.0027 - val_mae: 0.0345 - learning_rate: 0.0010\n",
      "Epoch 29/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 4.7595e-04 - mae: 0.0151 - val_loss: 0.0027 - val_mae: 0.0341 - learning_rate: 0.0010\n",
      "Epoch 30/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 3.9204e-04 - mae: 0.0131 - val_loss: 0.0024 - val_mae: 0.0333 - learning_rate: 5.0000e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 3.9073e-04 - mae: 0.0131 - val_loss: 0.0022 - val_mae: 0.0326 - learning_rate: 5.0000e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 3.9469e-04 - mae: 0.0133 - val_loss: 0.0024 - val_mae: 0.0337 - learning_rate: 5.0000e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 3.7776e-04 - mae: 0.0131 - val_loss: 0.0020 - val_mae: 0.0319 - learning_rate: 5.0000e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 3.8022e-04 - mae: 0.0130 - val_loss: 0.0020 - val_mae: 0.0320 - learning_rate: 5.0000e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 3.8093e-04 - mae: 0.0131 - val_loss: 0.0020 - val_mae: 0.0318 - learning_rate: 5.0000e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 3.7870e-04 - mae: 0.0130 - val_loss: 0.0020 - val_mae: 0.0332 - learning_rate: 5.0000e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 3.2776e-04 - mae: 0.0117 - val_loss: 0.0019 - val_mae: 0.0308 - learning_rate: 2.5000e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 3.2174e-04 - mae: 0.0115 - val_loss: 0.0019 - val_mae: 0.0306 - learning_rate: 2.5000e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 3.3081e-04 - mae: 0.0118 - val_loss: 0.0019 - val_mae: 0.0308 - learning_rate: 2.5000e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 3.2490e-04 - mae: 0.0116 - val_loss: 0.0019 - val_mae: 0.0311 - learning_rate: 2.5000e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 3.0768e-04 - mae: 0.0110 - val_loss: 0.0018 - val_mae: 0.0307 - learning_rate: 1.2500e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 2.9960e-04 - mae: 0.0108 - val_loss: 0.0018 - val_mae: 0.0300 - learning_rate: 1.2500e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 2.9702e-04 - mae: 0.0106 - val_loss: 0.0018 - val_mae: 0.0307 - learning_rate: 1.2500e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 2.9935e-04 - mae: 0.0107 - val_loss: 0.0018 - val_mae: 0.0303 - learning_rate: 1.2500e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 2.9265e-04 - mae: 0.0105 - val_loss: 0.0018 - val_mae: 0.0307 - learning_rate: 1.2500e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 2.8973e-04 - mae: 0.0105 - val_loss: 0.0017 - val_mae: 0.0302 - learning_rate: 6.2500e-05\n",
      "Epoch 47/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 2.8906e-04 - mae: 0.0105 - val_loss: 0.0017 - val_mae: 0.0305 - learning_rate: 6.2500e-05\n",
      "Epoch 48/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 2.9048e-04 - mae: 0.0103 - val_loss: 0.0018 - val_mae: 0.0308 - learning_rate: 6.2500e-05\n",
      "Epoch 49/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 2.8812e-04 - mae: 0.0103 - val_loss: 0.0018 - val_mae: 0.0312 - learning_rate: 3.1250e-05\n",
      "Epoch 50/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 2.7713e-04 - mae: 0.0101 - val_loss: 0.0017 - val_mae: 0.0305 - learning_rate: 3.1250e-05\n",
      "\u001b[1m81/81\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step  \n",
      " âœ… Mangalore(Dakshin Kannad) - onion | MAE=99.33, RMSE=142.69, RÂ²=0.9747, MAPE=4.5%, Acc=95.5%\n",
      "\n",
      "ğŸš€ Processing: Mangalore(Dakshin Kannad) | tomato\n",
      "Epoch 1/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 55ms/step - loss: 0.2062 - mae: 0.3684 - val_loss: 0.0438 - val_mae: 0.1882 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0251 - mae: 0.1180 - val_loss: 0.0254 - val_mae: 0.1315 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0202 - mae: 0.1063 - val_loss: 0.0323 - val_mae: 0.1445 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0175 - mae: 0.0997 - val_loss: 0.0204 - val_mae: 0.1184 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0154 - mae: 0.0949 - val_loss: 0.0163 - val_mae: 0.1093 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0145 - mae: 0.0931 - val_loss: 0.0201 - val_mae: 0.1192 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0122 - mae: 0.0869 - val_loss: 0.0159 - val_mae: 0.1092 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0111 - mae: 0.0807 - val_loss: 0.0157 - val_mae: 0.1078 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0107 - mae: 0.0789 - val_loss: 0.0139 - val_mae: 0.1026 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0112 - mae: 0.0845 - val_loss: 0.0179 - val_mae: 0.1111 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0133 - mae: 0.0870 - val_loss: 0.0131 - val_mae: 0.0984 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0094 - mae: 0.0746 - val_loss: 0.0111 - val_mae: 0.0857 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0119 - mae: 0.0860 - val_loss: 0.0090 - val_mae: 0.0774 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0115 - mae: 0.0826 - val_loss: 0.0113 - val_mae: 0.0891 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0089 - mae: 0.0712 - val_loss: 0.0080 - val_mae: 0.0691 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0087 - mae: 0.0726 - val_loss: 0.0074 - val_mae: 0.0666 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0079 - mae: 0.0684 - val_loss: 0.0119 - val_mae: 0.0887 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0102 - mae: 0.0793 - val_loss: 0.0092 - val_mae: 0.0755 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0084 - mae: 0.0713 - val_loss: 0.0094 - val_mae: 0.0796 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0067 - mae: 0.0651 - val_loss: 0.0088 - val_mae: 0.0757 - learning_rate: 5.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0063 - mae: 0.0598 - val_loss: 0.0123 - val_mae: 0.0852 - learning_rate: 5.0000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0060 - mae: 0.0598 - val_loss: 0.0124 - val_mae: 0.0851 - learning_rate: 5.0000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0058 - mae: 0.0594 - val_loss: 0.0125 - val_mae: 0.0862 - learning_rate: 2.5000e-04\n",
      "\u001b[1m13/13\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step \n",
      " âœ… Mangalore(Dakshin Kannad) - tomato | MAE=416.47, RMSE=486.31, RÂ²=0.8407, MAPE=23.25%, Acc=76.75%\n",
      "\n",
      "ğŸš€ Processing: Mangalore(Dakshin Kannad) | wheat\n",
      "Epoch 1/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 53ms/step - loss: 0.1785 - mae: 0.3274 - val_loss: 0.0148 - val_mae: 0.1130 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0334 - mae: 0.1488 - val_loss: 0.1128 - val_mae: 0.3332 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0231 - mae: 0.1243 - val_loss: 0.0864 - val_mae: 0.2911 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0187 - mae: 0.1113 - val_loss: 0.0459 - val_mae: 0.2106 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0158 - mae: 0.1033 - val_loss: 0.0503 - val_mae: 0.2211 - learning_rate: 5.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0111 - mae: 0.0835 - val_loss: 0.0439 - val_mae: 0.2064 - learning_rate: 5.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0108 - mae: 0.0826 - val_loss: 0.0277 - val_mae: 0.1628 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0090 - mae: 0.0758 - val_loss: 0.0237 - val_mae: 0.1502 - learning_rate: 2.5000e-04\n",
      "\u001b[1m13/13\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step \n",
      " âœ… Mangalore(Dakshin Kannad) - wheat | MAE=478.99, RMSE=556.65, RÂ²=0.2058, MAPE=19.97%, Acc=80.03%\n",
      "\n",
      "ğŸš€ Processing: Mysore | capsicum\n",
      "Epoch 1/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 19ms/step - loss: 0.0462 - mae: 0.1289 - val_loss: 0.0093 - val_mae: 0.0661 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0054 - mae: 0.0580 - val_loss: 0.0059 - val_mae: 0.0558 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0033 - mae: 0.0451 - val_loss: 0.0078 - val_mae: 0.0627 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0028 - mae: 0.0416 - val_loss: 0.0056 - val_mae: 0.0571 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0020 - mae: 0.0347 - val_loss: 0.0052 - val_mae: 0.0524 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0017 - mae: 0.0312 - val_loss: 0.0057 - val_mae: 0.0537 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0014 - mae: 0.0281 - val_loss: 0.0050 - val_mae: 0.0515 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0014 - mae: 0.0280 - val_loss: 0.0052 - val_mae: 0.0512 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0013 - mae: 0.0272 - val_loss: 0.0060 - val_mae: 0.0540 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0012 - mae: 0.0256 - val_loss: 0.0054 - val_mae: 0.0509 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0010 - mae: 0.0240 - val_loss: 0.0053 - val_mae: 0.0504 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0011 - mae: 0.0245 - val_loss: 0.0052 - val_mae: 0.0495 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0010 - mae: 0.0240 - val_loss: 0.0052 - val_mae: 0.0493 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 9.6674e-04 - mae: 0.0227 - val_loss: 0.0056 - val_mae: 0.0501 - learning_rate: 2.5000e-04\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step   \n",
      " âœ… Mysore - capsicum | MAE=274.06, RMSE=417.12, RÂ²=0.8464, MAPE=10.37%, Acc=89.63%\n",
      "\n",
      "ğŸš€ Processing: Mysore | onion\n",
      "Epoch 1/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0525 - mae: 0.1372 - val_loss: 0.0251 - val_mae: 0.1075 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0062 - mae: 0.0617 - val_loss: 0.0218 - val_mae: 0.1156 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0043 - mae: 0.0509 - val_loss: 0.0173 - val_mae: 0.1045 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0033 - mae: 0.0443 - val_loss: 0.0189 - val_mae: 0.1163 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0026 - mae: 0.0385 - val_loss: 0.0068 - val_mae: 0.0505 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0019 - mae: 0.0328 - val_loss: 0.0079 - val_mae: 0.0604 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0017 - mae: 0.0305 - val_loss: 0.0050 - val_mae: 0.0401 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0015 - mae: 0.0281 - val_loss: 0.0073 - val_mae: 0.0596 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0014 - mae: 0.0269 - val_loss: 0.0051 - val_mae: 0.0425 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0012 - mae: 0.0248 - val_loss: 0.0061 - val_mae: 0.0508 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0011 - mae: 0.0220 - val_loss: 0.0053 - val_mae: 0.0441 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0010 - mae: 0.0212 - val_loss: 0.0056 - val_mae: 0.0465 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 9.7595e-04 - mae: 0.0208 - val_loss: 0.0053 - val_mae: 0.0449 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 8.7418e-04 - mae: 0.0194 - val_loss: 0.0072 - val_mae: 0.0593 - learning_rate: 2.5000e-04\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step  \n",
      " âœ… Mysore - onion | MAE=147.5, RMSE=249.74, RÂ²=0.8604, MAPE=8.32%, Acc=91.68%\n",
      "\n",
      "ğŸš€ Processing: Mysore | tomato\n",
      "Epoch 1/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 19ms/step - loss: 0.0423 - mae: 0.1290 - val_loss: 0.0100 - val_mae: 0.0697 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0067 - mae: 0.0632 - val_loss: 0.0141 - val_mae: 0.0995 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0043 - mae: 0.0504 - val_loss: 0.0143 - val_mae: 0.1009 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0030 - mae: 0.0407 - val_loss: 0.0108 - val_mae: 0.0834 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0022 - mae: 0.0337 - val_loss: 0.0128 - val_mae: 0.0963 - learning_rate: 5.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0020 - mae: 0.0328 - val_loss: 0.0082 - val_mae: 0.0715 - learning_rate: 5.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0018 - mae: 0.0312 - val_loss: 0.0088 - val_mae: 0.0754 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0018 - mae: 0.0300 - val_loss: 0.0062 - val_mae: 0.0592 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0015 - mae: 0.0275 - val_loss: 0.0065 - val_mae: 0.0629 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0015 - mae: 0.0275 - val_loss: 0.0038 - val_mae: 0.0432 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0014 - mae: 0.0258 - val_loss: 0.0050 - val_mae: 0.0524 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0014 - mae: 0.0261 - val_loss: 0.0037 - val_mae: 0.0434 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0013 - mae: 0.0250 - val_loss: 0.0043 - val_mae: 0.0491 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0011 - mae: 0.0235 - val_loss: 0.0048 - val_mae: 0.0534 - learning_rate: 2.5000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0011 - mae: 0.0232 - val_loss: 0.0047 - val_mae: 0.0522 - learning_rate: 2.5000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0011 - mae: 0.0232 - val_loss: 0.0041 - val_mae: 0.0478 - learning_rate: 2.5000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0011 - mae: 0.0223 - val_loss: 0.0031 - val_mae: 0.0394 - learning_rate: 1.2500e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0011 - mae: 0.0226 - val_loss: 0.0037 - val_mae: 0.0448 - learning_rate: 1.2500e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0011 - mae: 0.0226 - val_loss: 0.0038 - val_mae: 0.0456 - learning_rate: 1.2500e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0011 - mae: 0.0222 - val_loss: 0.0036 - val_mae: 0.0439 - learning_rate: 1.2500e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 9.9736e-04 - mae: 0.0212 - val_loss: 0.0029 - val_mae: 0.0380 - learning_rate: 6.2500e-05\n",
      "Epoch 22/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 9.9876e-04 - mae: 0.0214 - val_loss: 0.0032 - val_mae: 0.0403 - learning_rate: 6.2500e-05\n",
      "Epoch 23/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 9.9486e-04 - mae: 0.0216 - val_loss: 0.0026 - val_mae: 0.0359 - learning_rate: 6.2500e-05\n",
      "Epoch 24/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0010 - mae: 0.0213 - val_loss: 0.0025 - val_mae: 0.0353 - learning_rate: 6.2500e-05\n",
      "Epoch 25/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0010 - mae: 0.0216 - val_loss: 0.0030 - val_mae: 0.0390 - learning_rate: 6.2500e-05\n",
      "Epoch 26/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0010 - mae: 0.0214 - val_loss: 0.0027 - val_mae: 0.0362 - learning_rate: 6.2500e-05\n",
      "Epoch 27/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 9.4956e-04 - mae: 0.0207 - val_loss: 0.0029 - val_mae: 0.0385 - learning_rate: 3.1250e-05\n",
      "Epoch 28/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 9.8026e-04 - mae: 0.0211 - val_loss: 0.0028 - val_mae: 0.0380 - learning_rate: 3.1250e-05\n",
      "Epoch 29/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 9.5669e-04 - mae: 0.0208 - val_loss: 0.0027 - val_mae: 0.0369 - learning_rate: 3.1250e-05\n",
      "Epoch 30/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 9.4378e-04 - mae: 0.0205 - val_loss: 0.0028 - val_mae: 0.0377 - learning_rate: 1.5625e-05\n",
      "Epoch 31/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 9.3836e-04 - mae: 0.0206 - val_loss: 0.0025 - val_mae: 0.0358 - learning_rate: 1.5625e-05\n",
      "Epoch 32/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 9.4493e-04 - mae: 0.0206 - val_loss: 0.0027 - val_mae: 0.0371 - learning_rate: 1.5625e-05\n",
      "Epoch 33/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 9.3170e-04 - mae: 0.0203 - val_loss: 0.0025 - val_mae: 0.0353 - learning_rate: 7.8125e-06\n",
      "Epoch 34/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 9.4125e-04 - mae: 0.0205 - val_loss: 0.0025 - val_mae: 0.0351 - learning_rate: 7.8125e-06\n",
      "Epoch 35/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 9.5425e-04 - mae: 0.0207 - val_loss: 0.0024 - val_mae: 0.0346 - learning_rate: 7.8125e-06\n",
      "Epoch 36/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 9.4608e-04 - mae: 0.0203 - val_loss: 0.0025 - val_mae: 0.0356 - learning_rate: 7.8125e-06\n",
      "Epoch 37/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 9.5083e-04 - mae: 0.0205 - val_loss: 0.0025 - val_mae: 0.0354 - learning_rate: 7.8125e-06\n",
      "Epoch 38/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 9.5073e-04 - mae: 0.0206 - val_loss: 0.0025 - val_mae: 0.0355 - learning_rate: 7.8125e-06\n",
      "Epoch 39/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 9.4176e-04 - mae: 0.0203 - val_loss: 0.0024 - val_mae: 0.0349 - learning_rate: 3.9063e-06\n",
      "Epoch 40/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 9.1220e-04 - mae: 0.0200 - val_loss: 0.0024 - val_mae: 0.0351 - learning_rate: 3.9063e-06\n",
      "Epoch 41/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 9.2219e-04 - mae: 0.0203 - val_loss: 0.0024 - val_mae: 0.0348 - learning_rate: 3.9063e-06\n",
      "Epoch 42/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 9.1438e-04 - mae: 0.0202 - val_loss: 0.0024 - val_mae: 0.0349 - learning_rate: 1.9531e-06\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step  \n",
      " âœ… Mysore - tomato | MAE=95.08, RMSE=152.96, RÂ²=0.9334, MAPE=7.41%, Acc=92.59%\n",
      "\n",
      "ğŸš€ Processing: Mysore | wheat\n",
      "Epoch 1/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 20ms/step - loss: 0.0526 - mae: 0.1215 - val_loss: 0.0025 - val_mae: 0.0211 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0045 - mae: 0.0535 - val_loss: 0.0023 - val_mae: 0.0170 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0033 - mae: 0.0458 - val_loss: 0.0022 - val_mae: 0.0186 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0022 - mae: 0.0373 - val_loss: 0.0038 - val_mae: 0.0440 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0012 - mae: 0.0269 - val_loss: 0.0033 - val_mae: 0.0378 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 7.5839e-04 - mae: 0.0219 - val_loss: 0.0022 - val_mae: 0.0199 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 5.0047e-04 - mae: 0.0178 - val_loss: 0.0025 - val_mae: 0.0263 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 4.2742e-04 - mae: 0.0163 - val_loss: 0.0026 - val_mae: 0.0278 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 3.6270e-04 - mae: 0.0150 - val_loss: 0.0026 - val_mae: 0.0286 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 3.2950e-04 - mae: 0.0144 - val_loss: 0.0023 - val_mae: 0.0221 - learning_rate: 2.5000e-04\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step  \n",
      " âœ… Mysore - wheat | MAE=353.87, RMSE=821.06, RÂ²=0.349, MAPE=16.11%, Acc=83.89%\n",
      "\n",
      "ğŸš€ Processing: Raichur | onion\n",
      "Epoch 1/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 26ms/step - loss: 0.1072 - mae: 0.1663 - val_loss: 0.0046 - val_mae: 0.0566 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0067 - mae: 0.0630 - val_loss: 0.0032 - val_mae: 0.0479 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0052 - mae: 0.0554 - val_loss: 0.0067 - val_mae: 0.0776 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0045 - mae: 0.0522 - val_loss: 0.0025 - val_mae: 0.0441 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0035 - mae: 0.0447 - val_loss: 0.0010 - val_mae: 0.0256 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0026 - mae: 0.0384 - val_loss: 0.0012 - val_mae: 0.0291 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0023 - mae: 0.0355 - val_loss: 5.8831e-04 - val_mae: 0.0168 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0020 - mae: 0.0331 - val_loss: 5.3688e-04 - val_mae: 0.0160 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0017 - mae: 0.0301 - val_loss: 8.4971e-04 - val_mae: 0.0234 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0016 - mae: 0.0281 - val_loss: 5.7640e-04 - val_mae: 0.0176 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0014 - mae: 0.0258 - val_loss: 6.0263e-04 - val_mae: 0.0184 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0012 - mae: 0.0248 - val_loss: 4.6113e-04 - val_mae: 0.0150 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0013 - mae: 0.0243 - val_loss: 5.9991e-04 - val_mae: 0.0183 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0013 - mae: 0.0249 - val_loss: 4.4907e-04 - val_mae: 0.0149 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0012 - mae: 0.0238 - val_loss: 4.2997e-04 - val_mae: 0.0144 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0011 - mae: 0.0225 - val_loss: 5.0935e-04 - val_mae: 0.0166 - learning_rate: 2.5000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0011 - mae: 0.0227 - val_loss: 6.7441e-04 - val_mae: 0.0201 - learning_rate: 2.5000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0011 - mae: 0.0222 - val_loss: 4.3752e-04 - val_mae: 0.0149 - learning_rate: 2.5000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0010 - mae: 0.0212 - val_loss: 4.8671e-04 - val_mae: 0.0164 - learning_rate: 1.2500e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0010 - mae: 0.0214 - val_loss: 5.6738e-04 - val_mae: 0.0180 - learning_rate: 1.2500e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0011 - mae: 0.0214 - val_loss: 6.8502e-04 - val_mae: 0.0207 - learning_rate: 1.2500e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0010 - mae: 0.0214 - val_loss: 4.7626e-04 - val_mae: 0.0163 - learning_rate: 6.2500e-05\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step  \n",
      " âœ… Raichur - onion | MAE=142.32, RMSE=238.85, RÂ²=0.9097, MAPE=12.5%, Acc=87.5%\n",
      "\n",
      "ğŸš€ Processing: Raichur | tomato\n",
      "Epoch 1/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 78ms/step - loss: 0.8310 - mae: 0.6976 - val_loss: 0.0513 - val_mae: 0.2256 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1070 - mae: 0.2792 - val_loss: 6.4342e-04 - val_mae: 0.0214 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0331 - mae: 0.1456 - val_loss: 1.9354e-04 - val_mae: 0.0117 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0252 - mae: 0.1229 - val_loss: 0.0016 - val_mae: 0.0385 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0232 - mae: 0.1136 - val_loss: 0.0021 - val_mae: 0.0416 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0174 - mae: 0.0994 - val_loss: 7.7770e-04 - val_mae: 0.0242 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0186 - mae: 0.1024 - val_loss: 8.7276e-04 - val_mae: 0.0273 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0174 - mae: 0.0986 - val_loss: 5.5011e-04 - val_mae: 0.0181 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0180 - mae: 0.0985 - val_loss: 0.0012 - val_mae: 0.0319 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0170 - mae: 0.0990 - val_loss: 0.0011 - val_mae: 0.0297 - learning_rate: 2.5000e-04\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step \n",
      " âœ… Raichur - tomato | MAE=171.99, RMSE=227.22, RÂ²=0.7037, MAPE=26.8%, Acc=73.2%\n",
      "\n",
      "ğŸš€ Processing: Raichur | wheat\n",
      "Epoch 1/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 28ms/step - loss: 0.0912 - mae: 0.1543 - val_loss: 0.0856 - val_mae: 0.2662 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0081 - mae: 0.0718 - val_loss: 0.0656 - val_mae: 0.2318 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0060 - mae: 0.0614 - val_loss: 0.0526 - val_mae: 0.2074 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0043 - mae: 0.0518 - val_loss: 0.0241 - val_mae: 0.1335 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0034 - mae: 0.0453 - val_loss: 0.0185 - val_mae: 0.1161 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0025 - mae: 0.0382 - val_loss: 0.0178 - val_mae: 0.1138 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0023 - mae: 0.0372 - val_loss: 0.0149 - val_mae: 0.1039 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0018 - mae: 0.0319 - val_loss: 0.0252 - val_mae: 0.1381 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0015 - mae: 0.0278 - val_loss: 0.0154 - val_mae: 0.1054 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0014 - mae: 0.0272 - val_loss: 0.0149 - val_mae: 0.1038 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0012 - mae: 0.0243 - val_loss: 0.0188 - val_mae: 0.1174 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0012 - mae: 0.0251 - val_loss: 0.0213 - val_mae: 0.1260 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0011 - mae: 0.0235 - val_loss: 0.0150 - val_mae: 0.1041 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0010 - mae: 0.0217 - val_loss: 0.0182 - val_mae: 0.1156 - learning_rate: 2.5000e-04\n",
      "\u001b[1m84/84\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step   \n",
      " âœ… Raichur - wheat | MAE=75.53, RMSE=106.17, RÂ²=0.9182, MAPE=3.93%, Acc=96.07%\n",
      "\n",
      "ğŸš€ Processing: Shimoga | capsicum\n",
      "Epoch 1/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 760ms/step - loss: 0.5748 - mae: 0.6826 - val_loss: 1.5035 - val_mae: 1.2253 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.4441 - mae: 0.5973 - val_loss: 0.0608 - val_mae: 0.2423 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.1182 - mae: 0.2889 - val_loss: 0.0704 - val_mae: 0.2623 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.2210 - mae: 0.4412 - val_loss: 0.0083 - val_mae: 0.0850 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0266 - mae: 0.1374 - val_loss: 0.2145 - val_mae: 0.4623 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.1377 - mae: 0.3559 - val_loss: 0.1219 - val_mae: 0.3481 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0533 - mae: 0.1976 - val_loss: 0.0013 - val_mae: 0.0302 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.0288 - mae: 0.1342 - val_loss: 0.0613 - val_mae: 0.2461 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0766 - mae: 0.2613 - val_loss: 0.0175 - val_mae: 0.1297 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.0177 - mae: 0.1111 - val_loss: 0.0173 - val_mae: 0.1294 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.0273 - mae: 0.1393 - val_loss: 0.0374 - val_mae: 0.1919 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0333 - mae: 0.1647 - val_loss: 0.0229 - val_mae: 0.1491 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.0156 - mae: 0.0983 - val_loss: 0.0037 - val_mae: 0.0555 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0046 - mae: 0.0542 - val_loss: 8.5048e-04 - val_mae: 0.0242 - learning_rate: 2.5000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0096 - mae: 0.0787 - val_loss: 8.7361e-04 - val_mae: 0.0251 - learning_rate: 2.5000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0115 - mae: 0.0879 - val_loss: 9.5234e-04 - val_mae: 0.0261 - learning_rate: 2.5000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0111 - mae: 0.0858 - val_loss: 7.4158e-04 - val_mae: 0.0235 - learning_rate: 2.5000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0146 - mae: 0.1015 - val_loss: 0.0027 - val_mae: 0.0440 - learning_rate: 2.5000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.0088 - mae: 0.0755 - val_loss: 0.0084 - val_mae: 0.0877 - learning_rate: 2.5000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0082 - mae: 0.0750 - val_loss: 0.0144 - val_mae: 0.1169 - learning_rate: 2.5000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0139 - mae: 0.0917 - val_loss: 0.0157 - val_mae: 0.1224 - learning_rate: 1.2500e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0098 - mae: 0.0805 - val_loss: 0.0150 - val_mae: 0.1192 - learning_rate: 1.2500e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0081 - mae: 0.0696 - val_loss: 0.0128 - val_mae: 0.1097 - learning_rate: 1.2500e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0121 - mae: 0.0889 - val_loss: 0.0112 - val_mae: 0.1022 - learning_rate: 6.2500e-05\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 369ms/step\n",
      " âœ… Shimoga - capsicum | MAE=45.72, RMSE=52.08, RÂ²=0.8572, MAPE=2.79%, Acc=97.21%\n",
      "\n",
      "ğŸš€ Processing: Shimoga | onion\n",
      "Epoch 1/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 18ms/step - loss: 0.0910 - mae: 0.1532 - val_loss: 0.0144 - val_mae: 0.0829 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0054 - mae: 0.0567 - val_loss: 0.0102 - val_mae: 0.0679 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0041 - mae: 0.0496 - val_loss: 0.0067 - val_mae: 0.0512 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0031 - mae: 0.0432 - val_loss: 0.0062 - val_mae: 0.0475 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0025 - mae: 0.0382 - val_loss: 0.0066 - val_mae: 0.0503 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0020 - mae: 0.0339 - val_loss: 0.0060 - val_mae: 0.0488 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0014 - mae: 0.0279 - val_loss: 0.0066 - val_mae: 0.0504 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0013 - mae: 0.0262 - val_loss: 0.0065 - val_mae: 0.0517 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0011 - mae: 0.0228 - val_loss: 0.0060 - val_mae: 0.0478 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 8.8254e-04 - mae: 0.0200 - val_loss: 0.0060 - val_mae: 0.0462 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 8.4731e-04 - mae: 0.0194 - val_loss: 0.0056 - val_mae: 0.0434 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 8.0722e-04 - mae: 0.0190 - val_loss: 0.0059 - val_mae: 0.0458 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 7.4536e-04 - mae: 0.0182 - val_loss: 0.0061 - val_mae: 0.0461 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 7.3495e-04 - mae: 0.0179 - val_loss: 0.0058 - val_mae: 0.0448 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 6.7669e-04 - mae: 0.0166 - val_loss: 0.0058 - val_mae: 0.0442 - learning_rate: 2.5000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 6.5875e-04 - mae: 0.0161 - val_loss: 0.0055 - val_mae: 0.0425 - learning_rate: 2.5000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 6.5310e-04 - mae: 0.0163 - val_loss: 0.0056 - val_mae: 0.0428 - learning_rate: 2.5000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 6.4440e-04 - mae: 0.0162 - val_loss: 0.0055 - val_mae: 0.0422 - learning_rate: 2.5000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 6.2448e-04 - mae: 0.0156 - val_loss: 0.0056 - val_mae: 0.0429 - learning_rate: 2.5000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 6.1266e-04 - mae: 0.0153 - val_loss: 0.0058 - val_mae: 0.0440 - learning_rate: 1.2500e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 6.0423e-04 - mae: 0.0153 - val_loss: 0.0056 - val_mae: 0.0432 - learning_rate: 1.2500e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 6.1183e-04 - mae: 0.0152 - val_loss: 0.0057 - val_mae: 0.0440 - learning_rate: 1.2500e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 5.7036e-04 - mae: 0.0149 - val_loss: 0.0058 - val_mae: 0.0446 - learning_rate: 6.2500e-05\n",
      "Epoch 24/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 5.7349e-04 - mae: 0.0144 - val_loss: 0.0057 - val_mae: 0.0441 - learning_rate: 6.2500e-05\n",
      "Epoch 25/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 5.8550e-04 - mae: 0.0145 - val_loss: 0.0056 - val_mae: 0.0431 - learning_rate: 6.2500e-05\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step   \n",
      " âœ… Shimoga - onion | MAE=150.92, RMSE=356.11, RÂ²=0.8531, MAPE=40.72%, Acc=59.28%\n",
      "\n",
      "ğŸš€ Processing: Shimoga | tomato\n",
      "Epoch 1/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 21ms/step - loss: 0.0497 - mae: 0.1251 - val_loss: 0.0051 - val_mae: 0.0506 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0054 - mae: 0.0583 - val_loss: 0.0059 - val_mae: 0.0493 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0040 - mae: 0.0497 - val_loss: 0.0064 - val_mae: 0.0522 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0028 - mae: 0.0414 - val_loss: 0.0060 - val_mae: 0.0493 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0020 - mae: 0.0345 - val_loss: 0.0067 - val_mae: 0.0561 - learning_rate: 5.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0016 - mae: 0.0311 - val_loss: 0.0045 - val_mae: 0.0395 - learning_rate: 5.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0014 - mae: 0.0286 - val_loss: 0.0042 - val_mae: 0.0366 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0011 - mae: 0.0256 - val_loss: 0.0048 - val_mae: 0.0409 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0010 - mae: 0.0241 - val_loss: 0.0046 - val_mae: 0.0387 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 8.7007e-04 - mae: 0.0221 - val_loss: 0.0043 - val_mae: 0.0378 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 7.7539e-04 - mae: 0.0206 - val_loss: 0.0042 - val_mae: 0.0369 - learning_rate: 2.5000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 7.2740e-04 - mae: 0.0200 - val_loss: 0.0046 - val_mae: 0.0397 - learning_rate: 2.5000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 7.3069e-04 - mae: 0.0199 - val_loss: 0.0040 - val_mae: 0.0356 - learning_rate: 2.5000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 6.8479e-04 - mae: 0.0190 - val_loss: 0.0043 - val_mae: 0.0377 - learning_rate: 2.5000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 6.2834e-04 - mae: 0.0182 - val_loss: 0.0042 - val_mae: 0.0376 - learning_rate: 2.5000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 6.1266e-04 - mae: 0.0180 - val_loss: 0.0038 - val_mae: 0.0352 - learning_rate: 2.5000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 5.9393e-04 - mae: 0.0177 - val_loss: 0.0037 - val_mae: 0.0350 - learning_rate: 2.5000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 5.3095e-04 - mae: 0.0164 - val_loss: 0.0038 - val_mae: 0.0352 - learning_rate: 2.5000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 5.1310e-04 - mae: 0.0161 - val_loss: 0.0037 - val_mae: 0.0354 - learning_rate: 2.5000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 4.8629e-04 - mae: 0.0155 - val_loss: 0.0037 - val_mae: 0.0347 - learning_rate: 1.2500e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 4.7325e-04 - mae: 0.0152 - val_loss: 0.0036 - val_mae: 0.0346 - learning_rate: 1.2500e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 4.5383e-04 - mae: 0.0147 - val_loss: 0.0037 - val_mae: 0.0350 - learning_rate: 1.2500e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 4.4660e-04 - mae: 0.0146 - val_loss: 0.0036 - val_mae: 0.0349 - learning_rate: 1.2500e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 4.2445e-04 - mae: 0.0143 - val_loss: 0.0036 - val_mae: 0.0348 - learning_rate: 1.2500e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 4.1960e-04 - mae: 0.0141 - val_loss: 0.0035 - val_mae: 0.0344 - learning_rate: 6.2500e-05\n",
      "Epoch 26/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 4.3342e-04 - mae: 0.0143 - val_loss: 0.0037 - val_mae: 0.0352 - learning_rate: 6.2500e-05\n",
      "Epoch 27/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 4.2587e-04 - mae: 0.0141 - val_loss: 0.0035 - val_mae: 0.0340 - learning_rate: 6.2500e-05\n",
      "Epoch 28/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 4.1195e-04 - mae: 0.0138 - val_loss: 0.0034 - val_mae: 0.0338 - learning_rate: 6.2500e-05\n",
      "Epoch 29/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 4.0400e-04 - mae: 0.0138 - val_loss: 0.0034 - val_mae: 0.0339 - learning_rate: 6.2500e-05\n",
      "Epoch 30/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 4.1260e-04 - mae: 0.0140 - val_loss: 0.0035 - val_mae: 0.0340 - learning_rate: 6.2500e-05\n",
      "Epoch 31/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 3.9266e-04 - mae: 0.0133 - val_loss: 0.0034 - val_mae: 0.0337 - learning_rate: 3.1250e-05\n",
      "Epoch 32/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 3.9675e-04 - mae: 0.0133 - val_loss: 0.0034 - val_mae: 0.0337 - learning_rate: 3.1250e-05\n",
      "Epoch 33/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 3.8899e-04 - mae: 0.0133 - val_loss: 0.0034 - val_mae: 0.0335 - learning_rate: 3.1250e-05\n",
      "Epoch 34/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 3.7158e-04 - mae: 0.0130 - val_loss: 0.0034 - val_mae: 0.0335 - learning_rate: 1.5625e-05\n",
      "Epoch 35/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 3.8103e-04 - mae: 0.0131 - val_loss: 0.0034 - val_mae: 0.0335 - learning_rate: 1.5625e-05\n",
      "Epoch 36/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 3.9322e-04 - mae: 0.0132 - val_loss: 0.0034 - val_mae: 0.0335 - learning_rate: 1.5625e-05\n",
      "Epoch 37/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 3.7721e-04 - mae: 0.0129 - val_loss: 0.0034 - val_mae: 0.0333 - learning_rate: 1.5625e-05\n",
      "Epoch 38/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 3.6817e-04 - mae: 0.0128 - val_loss: 0.0033 - val_mae: 0.0332 - learning_rate: 7.8125e-06\n",
      "Epoch 39/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 3.5201e-04 - mae: 0.0127 - val_loss: 0.0033 - val_mae: 0.0332 - learning_rate: 7.8125e-06\n",
      "Epoch 40/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 3.6763e-04 - mae: 0.0129 - val_loss: 0.0033 - val_mae: 0.0332 - learning_rate: 7.8125e-06\n",
      "Epoch 41/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 3.7049e-04 - mae: 0.0129 - val_loss: 0.0033 - val_mae: 0.0332 - learning_rate: 3.9063e-06\n",
      "Epoch 42/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 3.6271e-04 - mae: 0.0125 - val_loss: 0.0033 - val_mae: 0.0332 - learning_rate: 3.9063e-06\n",
      "Epoch 43/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 3.6382e-04 - mae: 0.0128 - val_loss: 0.0033 - val_mae: 0.0332 - learning_rate: 3.9063e-06\n",
      "Epoch 44/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 3.6533e-04 - mae: 0.0126 - val_loss: 0.0033 - val_mae: 0.0332 - learning_rate: 1.9531e-06\n",
      "Epoch 45/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 3.7233e-04 - mae: 0.0129 - val_loss: 0.0033 - val_mae: 0.0332 - learning_rate: 1.9531e-06\n",
      "Epoch 46/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 3.6166e-04 - mae: 0.0126 - val_loss: 0.0033 - val_mae: 0.0333 - learning_rate: 1.9531e-06\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step   \n",
      " âœ… Shimoga - tomato | MAE=240.28, RMSE=511.03, RÂ²=0.753, MAPE=46.33%, Acc=53.67%\n",
      "\n",
      "ğŸš€ Processing: Shimoga | wheat\n",
      "Epoch 1/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0486 - mae: 0.1263 - val_loss: 3.3803e-04 - val_mae: 0.0169 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0044 - mae: 0.0508 - val_loss: 0.0016 - val_mae: 0.0399 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0031 - mae: 0.0419 - val_loss: 0.0023 - val_mae: 0.0469 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0025 - mae: 0.0370 - val_loss: 0.0030 - val_mae: 0.0539 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0019 - mae: 0.0322 - val_loss: 0.0024 - val_mae: 0.0482 - learning_rate: 5.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0015 - mae: 0.0273 - val_loss: 3.9131e-04 - val_mae: 0.0175 - learning_rate: 5.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0013 - mae: 0.0256 - val_loss: 2.8016e-04 - val_mae: 0.0155 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0013 - mae: 0.0242 - val_loss: 5.6386e-04 - val_mae: 0.0219 - learning_rate: 2.5000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0011 - mae: 0.0225 - val_loss: 1.4661e-04 - val_mae: 0.0082 - learning_rate: 2.5000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0011 - mae: 0.0224 - val_loss: 9.5641e-04 - val_mae: 0.0295 - learning_rate: 2.5000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 9.9363e-04 - mae: 0.0204 - val_loss: 1.1659e-04 - val_mae: 0.0067 - learning_rate: 2.5000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 9.8804e-04 - mae: 0.0210 - val_loss: 5.0243e-04 - val_mae: 0.0204 - learning_rate: 2.5000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 9.2577e-04 - mae: 0.0198 - val_loss: 1.8461e-04 - val_mae: 0.0101 - learning_rate: 1.2500e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 8.6524e-04 - mae: 0.0189 - val_loss: 1.9584e-04 - val_mae: 0.0106 - learning_rate: 1.2500e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 8.8227e-04 - mae: 0.0195 - val_loss: 6.6993e-04 - val_mae: 0.0242 - learning_rate: 1.2500e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 8.1365e-04 - mae: 0.0185 - val_loss: 5.6811e-04 - val_mae: 0.0220 - learning_rate: 6.2500e-05\n",
      "Epoch 17/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 7.8054e-04 - mae: 0.0179 - val_loss: 3.3802e-04 - val_mae: 0.0160 - learning_rate: 6.2500e-05\n",
      "Epoch 18/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 8.0546e-04 - mae: 0.0183 - val_loss: 6.2774e-04 - val_mae: 0.0233 - learning_rate: 6.2500e-05\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step  \n",
      " âœ… Shimoga - wheat | MAE=308.0, RMSE=622.17, RÂ²=0.1995, MAPE=13.67%, Acc=86.33%\n",
      "\n",
      "ğŸš€ Processing: Tumkur | onion\n",
      "Epoch 1/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 19ms/step - loss: 0.0716 - mae: 0.1478 - val_loss: 0.0651 - val_mae: 0.2369 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0050 - mae: 0.0553 - val_loss: 0.0389 - val_mae: 0.1774 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0037 - mae: 0.0477 - val_loss: 0.0252 - val_mae: 0.1368 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0028 - mae: 0.0409 - val_loss: 0.0191 - val_mae: 0.1147 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0023 - mae: 0.0374 - val_loss: 0.0143 - val_mae: 0.0948 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0018 - mae: 0.0335 - val_loss: 0.0188 - val_mae: 0.1140 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0014 - mae: 0.0291 - val_loss: 0.0119 - val_mae: 0.0810 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0011 - mae: 0.0258 - val_loss: 0.0094 - val_mae: 0.0677 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 8.9529e-04 - mae: 0.0229 - val_loss: 0.0091 - val_mae: 0.0665 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 8.0503e-04 - mae: 0.0218 - val_loss: 0.0105 - val_mae: 0.0750 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 6.7284e-04 - mae: 0.0198 - val_loss: 0.0099 - val_mae: 0.0720 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 6.5764e-04 - mae: 0.0193 - val_loss: 0.0095 - val_mae: 0.0702 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 5.1815e-04 - mae: 0.0171 - val_loss: 0.0068 - val_mae: 0.0560 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 4.5788e-04 - mae: 0.0159 - val_loss: 0.0085 - val_mae: 0.0646 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 4.3867e-04 - mae: 0.0155 - val_loss: 0.0082 - val_mae: 0.0634 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 4.4505e-04 - mae: 0.0159 - val_loss: 0.0079 - val_mae: 0.0626 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 4.1371e-04 - mae: 0.0150 - val_loss: 0.0082 - val_mae: 0.0642 - learning_rate: 2.5000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 3.9580e-04 - mae: 0.0147 - val_loss: 0.0076 - val_mae: 0.0612 - learning_rate: 2.5000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 3.9071e-04 - mae: 0.0147 - val_loss: 0.0072 - val_mae: 0.0589 - learning_rate: 2.5000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 3.6200e-04 - mae: 0.0142 - val_loss: 0.0075 - val_mae: 0.0608 - learning_rate: 1.2500e-04\n",
      "\u001b[1m85/85\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step  \n",
      " âœ… Tumkur - onion | MAE=198.87, RMSE=402.36, RÂ²=0.9506, MAPE=5.44%, Acc=94.56%\n",
      "\n",
      "ğŸš€ Processing: Tumkur | tomato\n",
      "Epoch 1/50\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 20ms/step - loss: 0.1087 - mae: 0.1817 - val_loss: 0.0517 - val_mae: 0.1752 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0067 - mae: 0.0648 - val_loss: 0.0428 - val_mae: 0.1580 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0054 - mae: 0.0585 - val_loss: 0.0335 - val_mae: 0.1399 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0050 - mae: 0.0565 - val_loss: 0.0506 - val_mae: 0.1827 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0039 - mae: 0.0500 - val_loss: 0.0515 - val_mae: 0.1792 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0035 - mae: 0.0470 - val_loss: 0.0511 - val_mae: 0.1822 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0027 - mae: 0.0407 - val_loss: 0.0389 - val_mae: 0.1500 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0025 - mae: 0.0399 - val_loss: 0.0389 - val_mae: 0.1503 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0023 - mae: 0.0377 - val_loss: 0.0368 - val_mae: 0.1454 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0018 - mae: 0.0338 - val_loss: 0.0392 - val_mae: 0.1495 - learning_rate: 2.5000e-04\n",
      "\u001b[1m78/78\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step  \n",
      " âœ… Tumkur - tomato | MAE=529.84, RMSE=974.84, RÂ²=0.5626, MAPE=36.69%, Acc=63.31%\n",
      "\n",
      "ğŸš€ Processing: Tumkur | wheat\n",
      "Epoch 1/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 19ms/step - loss: 0.0755 - mae: 0.1479 - val_loss: 0.0092 - val_mae: 0.0560 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0049 - mae: 0.0559 - val_loss: 0.0155 - val_mae: 0.0990 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0042 - mae: 0.0516 - val_loss: 0.0128 - val_mae: 0.0837 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0039 - mae: 0.0494 - val_loss: 0.0084 - val_mae: 0.0472 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0031 - mae: 0.0447 - val_loss: 0.0127 - val_mae: 0.0840 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0024 - mae: 0.0391 - val_loss: 0.0108 - val_mae: 0.0674 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0024 - mae: 0.0393 - val_loss: 0.0099 - val_mae: 0.0624 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0017 - mae: 0.0327 - val_loss: 0.0062 - val_mae: 0.0238 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0016 - mae: 0.0316 - val_loss: 0.0066 - val_mae: 0.0252 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0013 - mae: 0.0288 - val_loss: 0.0076 - val_mae: 0.0402 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0013 - mae: 0.0286 - val_loss: 0.0072 - val_mae: 0.0359 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0011 - mae: 0.0257 - val_loss: 0.0063 - val_mae: 0.0230 - learning_rate: 2.5000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 9.9427e-04 - mae: 0.0250 - val_loss: 0.0071 - val_mae: 0.0336 - learning_rate: 2.5000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0010 - mae: 0.0252 - val_loss: 0.0073 - val_mae: 0.0322 - learning_rate: 2.5000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 8.9533e-04 - mae: 0.0236 - val_loss: 0.0072 - val_mae: 0.0327 - learning_rate: 1.2500e-04\n",
      "\u001b[1m76/76\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step  \n",
      " âœ… Tumkur - wheat | MAE=122.11, RMSE=359.37, RÂ²=0.7939, MAPE=4.58%, Acc=95.42%\n",
      "\n",
      "ğŸš€ Processing: Udupi | capsicum\n",
      "Epoch 1/50\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 19ms/step - loss: 0.0539 - mae: 0.1499 - val_loss: 0.0174 - val_mae: 0.1001 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0084 - mae: 0.0716 - val_loss: 0.0184 - val_mae: 0.0987 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0048 - mae: 0.0533 - val_loss: 0.0178 - val_mae: 0.0927 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0040 - mae: 0.0478 - val_loss: 0.0159 - val_mae: 0.0894 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0035 - mae: 0.0448 - val_loss: 0.0146 - val_mae: 0.0884 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0031 - mae: 0.0407 - val_loss: 0.0143 - val_mae: 0.0851 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0026 - mae: 0.0363 - val_loss: 0.0138 - val_mae: 0.0857 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0024 - mae: 0.0347 - val_loss: 0.0136 - val_mae: 0.0845 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0022 - mae: 0.0330 - val_loss: 0.0140 - val_mae: 0.0869 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0023 - mae: 0.0342 - val_loss: 0.0128 - val_mae: 0.0836 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0018 - mae: 0.0284 - val_loss: 0.0131 - val_mae: 0.0853 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0018 - mae: 0.0296 - val_loss: 0.0141 - val_mae: 0.0895 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0017 - mae: 0.0287 - val_loss: 0.0142 - val_mae: 0.0870 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0013 - mae: 0.0232 - val_loss: 0.0147 - val_mae: 0.0884 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0012 - mae: 0.0233 - val_loss: 0.0145 - val_mae: 0.0873 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0012 - mae: 0.0226 - val_loss: 0.0154 - val_mae: 0.0894 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0011 - mae: 0.0217 - val_loss: 0.0160 - val_mae: 0.0939 - learning_rate: 2.5000e-04\n",
      "\u001b[1m78/78\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step  \n",
      " âœ… Udupi - capsicum | MAE=287.49, RMSE=523.91, RÂ²=0.8773, MAPE=7.61%, Acc=92.39%\n",
      "\n",
      "ğŸš€ Processing: Udupi | onion\n",
      "Epoch 1/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 19ms/step - loss: 0.0760 - mae: 0.1662 - val_loss: 0.0081 - val_mae: 0.0625 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0090 - mae: 0.0727 - val_loss: 0.0095 - val_mae: 0.0624 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0066 - mae: 0.0620 - val_loss: 0.0142 - val_mae: 0.0868 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0053 - mae: 0.0554 - val_loss: 0.0083 - val_mae: 0.0510 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0040 - mae: 0.0488 - val_loss: 0.0073 - val_mae: 0.0544 - learning_rate: 5.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0036 - mae: 0.0457 - val_loss: 0.0066 - val_mae: 0.0473 - learning_rate: 5.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0030 - mae: 0.0415 - val_loss: 0.0080 - val_mae: 0.0617 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0026 - mae: 0.0386 - val_loss: 0.0060 - val_mae: 0.0474 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0023 - mae: 0.0358 - val_loss: 0.0071 - val_mae: 0.0580 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0021 - mae: 0.0339 - val_loss: 0.0054 - val_mae: 0.0433 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0019 - mae: 0.0321 - val_loss: 0.0056 - val_mae: 0.0426 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0017 - mae: 0.0308 - val_loss: 0.0059 - val_mae: 0.0456 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0016 - mae: 0.0287 - val_loss: 0.0054 - val_mae: 0.0460 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0015 - mae: 0.0285 - val_loss: 0.0048 - val_mae: 0.0393 - learning_rate: 2.5000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0014 - mae: 0.0274 - val_loss: 0.0051 - val_mae: 0.0385 - learning_rate: 2.5000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0013 - mae: 0.0260 - val_loss: 0.0049 - val_mae: 0.0408 - learning_rate: 2.5000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0012 - mae: 0.0254 - val_loss: 0.0054 - val_mae: 0.0434 - learning_rate: 2.5000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0012 - mae: 0.0250 - val_loss: 0.0050 - val_mae: 0.0384 - learning_rate: 1.2500e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0011 - mae: 0.0239 - val_loss: 0.0051 - val_mae: 0.0386 - learning_rate: 1.2500e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0012 - mae: 0.0242 - val_loss: 0.0050 - val_mae: 0.0382 - learning_rate: 1.2500e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0011 - mae: 0.0233 - val_loss: 0.0050 - val_mae: 0.0377 - learning_rate: 6.2500e-05\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step   \n",
      " âœ… Udupi - onion | MAE=255.41, RMSE=399.25, RÂ²=0.9057, MAPE=14.4%, Acc=85.6%\n",
      "\n",
      "ğŸš€ Processing: Udupi | tomato\n",
      "Epoch 1/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0598 - mae: 0.1373 - val_loss: 0.0290 - val_mae: 0.1047 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0077 - mae: 0.0677 - val_loss: 0.0188 - val_mae: 0.0917 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0059 - mae: 0.0596 - val_loss: 0.0153 - val_mae: 0.0834 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0039 - mae: 0.0481 - val_loss: 0.0121 - val_mae: 0.0704 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0031 - mae: 0.0417 - val_loss: 0.0116 - val_mae: 0.0699 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0026 - mae: 0.0383 - val_loss: 0.0100 - val_mae: 0.0671 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0021 - mae: 0.0331 - val_loss: 0.0089 - val_mae: 0.0602 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0018 - mae: 0.0312 - val_loss: 0.0087 - val_mae: 0.0608 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0019 - mae: 0.0323 - val_loss: 0.0082 - val_mae: 0.0594 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0015 - mae: 0.0272 - val_loss: 0.0073 - val_mae: 0.0532 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0014 - mae: 0.0261 - val_loss: 0.0075 - val_mae: 0.0558 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0013 - mae: 0.0259 - val_loss: 0.0066 - val_mae: 0.0508 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0013 - mae: 0.0256 - val_loss: 0.0064 - val_mae: 0.0489 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0012 - mae: 0.0248 - val_loss: 0.0069 - val_mae: 0.0532 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0013 - mae: 0.0257 - val_loss: 0.0073 - val_mae: 0.0547 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0011 - mae: 0.0238 - val_loss: 0.0071 - val_mae: 0.0536 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 9.8315e-04 - mae: 0.0220 - val_loss: 0.0062 - val_mae: 0.0522 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 9.1444e-04 - mae: 0.0210 - val_loss: 0.0061 - val_mae: 0.0517 - learning_rate: 5.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 9.4508e-04 - mae: 0.0208 - val_loss: 0.0059 - val_mae: 0.0486 - learning_rate: 5.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 9.3002e-04 - mae: 0.0209 - val_loss: 0.0059 - val_mae: 0.0463 - learning_rate: 5.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 9.3302e-04 - mae: 0.0213 - val_loss: 0.0057 - val_mae: 0.0464 - learning_rate: 5.0000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 8.8370e-04 - mae: 0.0208 - val_loss: 0.0058 - val_mae: 0.0458 - learning_rate: 5.0000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 9.3110e-04 - mae: 0.0215 - val_loss: 0.0057 - val_mae: 0.0456 - learning_rate: 5.0000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 8.4404e-04 - mae: 0.0204 - val_loss: 0.0058 - val_mae: 0.0450 - learning_rate: 5.0000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 7.4238e-04 - mae: 0.0186 - val_loss: 0.0064 - val_mae: 0.0464 - learning_rate: 2.5000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 7.4057e-04 - mae: 0.0185 - val_loss: 0.0063 - val_mae: 0.0457 - learning_rate: 2.5000e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 7.3249e-04 - mae: 0.0186 - val_loss: 0.0058 - val_mae: 0.0448 - learning_rate: 2.5000e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 7.6354e-04 - mae: 0.0186 - val_loss: 0.0060 - val_mae: 0.0454 - learning_rate: 1.2500e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 7.1387e-04 - mae: 0.0183 - val_loss: 0.0060 - val_mae: 0.0454 - learning_rate: 1.2500e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 7.0418e-04 - mae: 0.0182 - val_loss: 0.0061 - val_mae: 0.0452 - learning_rate: 1.2500e-04\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step  \n",
      " âœ… Udupi - tomato | MAE=215.76, RMSE=390.15, RÂ²=0.9111, MAPE=11.35%, Acc=88.65%\n",
      "\n",
      "ğŸš€ Processing: Udupi | wheat\n",
      "Epoch 1/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 54ms/step - loss: 0.2287 - mae: 0.3671 - val_loss: 0.1853 - val_mae: 0.4277 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0385 - mae: 0.1570 - val_loss: 0.0815 - val_mae: 0.2822 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0199 - mae: 0.1170 - val_loss: 0.0551 - val_mae: 0.2320 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0152 - mae: 0.0997 - val_loss: 0.0450 - val_mae: 0.2101 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0134 - mae: 0.0916 - val_loss: 0.0497 - val_mae: 0.2215 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0126 - mae: 0.0903 - val_loss: 0.0339 - val_mae: 0.1827 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0108 - mae: 0.0836 - val_loss: 0.0696 - val_mae: 0.2631 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0131 - mae: 0.0920 - val_loss: 0.0441 - val_mae: 0.2094 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0101 - mae: 0.0811 - val_loss: 0.0344 - val_mae: 0.1847 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0085 - mae: 0.0738 - val_loss: 0.0224 - val_mae: 0.1489 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0090 - mae: 0.0759 - val_loss: 0.0261 - val_mae: 0.1608 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0083 - mae: 0.0721 - val_loss: 0.0253 - val_mae: 0.1583 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0080 - mae: 0.0718 - val_loss: 0.0207 - val_mae: 0.1431 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m21/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0075 - mae: 0.0699"
     ]
    }
   ],
   "source": [
    "\n",
    "import os, gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks, optimizers\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "# -----------------------------\n",
    "# Config\n",
    "# -----------------------------\n",
    "input_file = \"dataset/Crop_price_forecast_Daily.xlsx\"\n",
    "output_folder = \"tat_mqa_state_output_fixed2\"\n",
    "output_models = os.path.join(output_folder, \"models\")\n",
    "output_csv = os.path.join(output_folder, \"predictions\")\n",
    "output_graphs = os.path.join(output_folder, \"graphs\")\n",
    "metrics_file = os.path.join(output_folder, \"tat_mqa_metrics.csv\")\n",
    "\n",
    "look_back = 30\n",
    "future_steps = 30\n",
    "epochs = 50\n",
    "batch_size = 32\n",
    "d_model = 64        # final internal dimension\n",
    "num_heads = 4\n",
    "# For multi-query we choose per-head depth; when concatenated -> d_model\n",
    "depth = d_model // num_heads\n",
    "ff_dim = 128\n",
    "dropout_rate = 0.15\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "os.makedirs(output_models, exist_ok=True)\n",
    "os.makedirs(output_csv, exist_ok=True)\n",
    "os.makedirs(output_graphs, exist_ok=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Helpers\n",
    "# -----------------------------\n",
    "def parse_dates_safe(series):\n",
    "    try:\n",
    "        return pd.to_datetime(series, dayfirst=True)\n",
    "    except:\n",
    "        return pd.to_datetime(series, dayfirst=False)\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    mask = y_true != 0\n",
    "    return np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100 if np.any(mask) else np.nan\n",
    "\n",
    "def create_sequences(X, y, look_back):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - look_back):\n",
    "        Xs.append(X[i:i+look_back])\n",
    "        ys.append(y[i+look_back])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "# -----------------------------\n",
    "# Robust Multi-Query Attention layer (shared K,V; separate Q per head)\n",
    "# - No einsum strings, only tf.matmul + reshape/concat\n",
    "# -----------------------------\n",
    "class MultiQueryAttentionLayer(layers.Layer):\n",
    "    def __init__(self, num_heads, depth, dropout=0.1, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        assert depth > 0, \"depth must be > 0\"\n",
    "        self.num_heads = num_heads\n",
    "        self.depth = depth\n",
    "        self.dropout = layers.Dropout(dropout)\n",
    "        # Q per head (each produces (B, T, depth))\n",
    "        self.q_projs = [layers.Dense(depth, name=f\"q_proj_{i}\") for i in range(num_heads)]\n",
    "        # Shared K and V (produce (B, T, depth))\n",
    "        self.k_proj = layers.Dense(depth, name=\"k_proj_shared\")\n",
    "        self.v_proj = layers.Dense(depth, name=\"v_proj_shared\")\n",
    "        # Output projection to restore d_model\n",
    "        self.out = layers.Dense(depth * num_heads, name=\"out_proj\")  # will produce d_model when depth*num_heads = d_model\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        # x: (B, T, d_model) or (B,T,F) depending on upstream projection\n",
    "        B = tf.shape(x)[0]\n",
    "        T = tf.shape(x)[1]\n",
    "\n",
    "        # Shared K and V -> shape (B, T, depth)\n",
    "        K = self.k_proj(x)  # (B, T, depth)\n",
    "        V = self.v_proj(x)  # (B, T, depth)\n",
    "\n",
    "        # For attention matmul we want K^T per batch: we will use tf.matmul(Q_head, K_transposed)\n",
    "        # K_transposed for matmul: for each batch compute (depth, T). TF batched matmul handles this.\n",
    "\n",
    "        head_contexts = []\n",
    "        for q_layer in self.q_projs:\n",
    "            Q = q_layer(x)  # (B, T, depth)\n",
    "            # scores = Q @ K^T  -> (B, T, T)\n",
    "            # tf.matmul handles batch: tf.matmul(Q, K, transpose_b=True) => (B, T, T)\n",
    "            scores = tf.matmul(Q, K, transpose_b=True)  # (B, T, T)\n",
    "            scores = scores / tf.math.sqrt(tf.cast(self.depth, tf.float32))\n",
    "            weights = tf.nn.softmax(scores, axis=-1)  # (B, T, T)\n",
    "            weights = self.dropout(weights, training=training)\n",
    "            # context = weights @ V -> (B, T, depth)\n",
    "            context = tf.matmul(weights, V)  # (B, T, depth)\n",
    "            head_contexts.append(context)\n",
    "\n",
    "        # Concatenate head contexts along last axis -> (B, T, depth * num_heads) == d_model\n",
    "        concat = tf.concat(head_contexts, axis=-1)  # (B, T, d_model)\n",
    "        out = self.out(concat)  # (B, T, d_model) â€” final linear (optional)\n",
    "        return out\n",
    "\n",
    "    def get_config(self):\n",
    "        cfg = super().get_config()\n",
    "        cfg.update({\"num_heads\": self.num_heads, \"depth\": self.depth})\n",
    "        return cfg\n",
    "\n",
    "# -----------------------------\n",
    "# Build TAT + MQA model\n",
    "# -----------------------------\n",
    "def build_tat_mqa(input_shape, d_model=64, num_heads=4, depth=16, ff_dim=128, dropout=0.15):\n",
    "    seq_len, num_features = input_shape\n",
    "    inputs = layers.Input(shape=(seq_len, num_features), name=\"inputs\")\n",
    "    # project features to d_model\n",
    "    proj = layers.Dense(d_model, name=\"proj\")(inputs)  # (B, T, d_model)\n",
    "\n",
    "    # Multi-Query Attention: we feed proj and let layer produce (B,T,d_model)\n",
    "    attn_out = MultiQueryAttentionLayer(num_heads=num_heads, depth=depth, dropout=dropout)(proj)\n",
    "    attn_out = layers.Dropout(dropout)(attn_out)\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(proj + attn_out)\n",
    "\n",
    "    # Feed-forward\n",
    "    ff = layers.Dense(ff_dim, activation=\"relu\")(x)\n",
    "    ff = layers.Dense(d_model)(ff)\n",
    "    ff = layers.Dropout(dropout)(ff)\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x + ff)\n",
    "\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    outputs = layers.Dense(1, name=\"output\")(x)\n",
    "\n",
    "    model = models.Model(inputs=inputs, outputs=outputs, name=\"TAT_MQA_fixed\")\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=1e-3), loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# -----------------------------\n",
    "# Load dataset & prepare\n",
    "# -----------------------------\n",
    "print(\"ğŸ“˜ Loading dataset:\", input_file)\n",
    "df = pd.read_excel(input_file)\n",
    "df.columns = [c.strip().lower() for c in df.columns]\n",
    "required = ['date', 'district', 'crop_type', 'average']\n",
    "if not all(c in df.columns for c in required):\n",
    "    raise ValueError(f\"Missing required columns. Need: {required}\")\n",
    "\n",
    "df['date'] = parse_dates_safe(df['date'])\n",
    "df = df.sort_values('date')\n",
    "df = df.dropna(subset=['average'])\n",
    "\n",
    "# crop-level fallback time series (mean across districts for each crop/date)\n",
    "crop_level_df = df.groupby(['crop_type','date'], as_index=False)['average'].mean()\n",
    "\n",
    "metrics = []\n",
    "\n",
    "# -----------------------------\n",
    "# Iterate over each (district, crop)\n",
    "# -----------------------------\n",
    "groups = df.groupby(['district','crop_type'])\n",
    "for (district, crop), group in groups:\n",
    "    print(f\"\\nğŸš€ Processing: {district} | {crop}\")\n",
    "\n",
    "    # aggregate duplicate dates with mean\n",
    "    data = group.groupby('date', as_index=False).mean(numeric_only=True)\n",
    "    data.set_index('date', inplace=True)\n",
    "\n",
    "    # ensure daily frequency\n",
    "    data = data.asfreq('D')\n",
    "\n",
    "    # fill missing average by forward/backward/mean\n",
    "    data['average'] = data['average'].ffill().bfill().fillna(data['average'].mean())\n",
    "\n",
    "    # fallback to crop-level series if too few points\n",
    "    if data['average'].count() < (look_back + 1):\n",
    "        print(\" âš  Sparse series; falling back to crop-level aggregated series.\")\n",
    "        crop_ts = crop_level_df[crop_level_df['crop_type'] == crop].copy()\n",
    "        if crop_ts.empty:\n",
    "            crop_ts = df.groupby('date', as_index=False)['average'].mean()\n",
    "        crop_ts.set_index('date', inplace=True)\n",
    "        crop_ts = crop_ts.asfreq('D')\n",
    "        crop_ts['average'] = crop_ts['average'].ffill().bfill().fillna(crop_ts['average'].mean())\n",
    "        data = crop_ts.copy()\n",
    "\n",
    "    # Feature engineering (lags and moving averages)\n",
    "    data['Lag_1'] = data['average'].shift(1)\n",
    "    data['Lag_7'] = data['average'].shift(7)\n",
    "    data['MA_7'] = data['average'].rolling(7).mean()\n",
    "    data['MA_30'] = data['average'].rolling(30).mean()\n",
    "    data[['Lag_1','Lag_7','MA_7','MA_30']] = data[['Lag_1','Lag_7','MA_7','MA_30']].bfill().ffill()\n",
    "\n",
    "    feature_cols = ['average','Lag_1','Lag_7','MA_7','MA_30']\n",
    "    raw_X = data[feature_cols].values.astype('float32')\n",
    "    raw_y = data['average'].values.astype('float32')\n",
    "\n",
    "    # scaling\n",
    "    scaler_X = MinMaxScaler()\n",
    "    scaler_y = MinMaxScaler()\n",
    "    X_scaled = scaler_X.fit_transform(raw_X)\n",
    "    y_scaled = scaler_y.fit_transform(raw_y.reshape(-1,1)).flatten()\n",
    "\n",
    "    # create sequences\n",
    "    X, y = create_sequences(X_scaled, y_scaled, look_back)\n",
    "    if len(X) == 0:\n",
    "        print(\" âš  Not enough windows after sequence creation. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # train/val split\n",
    "    n = len(X)\n",
    "    split = int(n * 0.8)\n",
    "    X_train, y_train = X[:split], y[:split]\n",
    "    X_val, y_val = X[split:], y[split:]\n",
    "\n",
    "    # build and train model\n",
    "    input_shape = (look_back, X.shape[2])\n",
    "    model = build_tat_mqa(input_shape, d_model=d_model, num_heads=num_heads, depth=depth, ff_dim=ff_dim, dropout=dropout_rate)\n",
    "\n",
    "    es = callbacks.EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True, verbose=0)\n",
    "    rl = callbacks.ReduceLROnPlateau(monitor='val_loss', patience=3, factor=0.5, min_lr=1e-6, verbose=0)\n",
    "\n",
    "    model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, batch_size=batch_size, callbacks=[es, rl], verbose=1)\n",
    "\n",
    "    # predict full series\n",
    "    preds_scaled = model.predict(X, batch_size=64).flatten()\n",
    "    preds_inv = scaler_y.inverse_transform(preds_scaled.reshape(-1,1)).flatten()\n",
    "    preds_full = np.concatenate([np.full(look_back, np.nan), preds_inv])\n",
    "\n",
    "    out_df = data.reset_index()\n",
    "    out_df['Predicted'] = np.round(preds_full, 2)\n",
    "\n",
    "    # metrics (only where prediction exists)\n",
    "    mask = ~np.isnan(out_df['Predicted'])\n",
    "    if mask.sum() == 0:\n",
    "        print(\" âš  No overlapping predicted points for metrics; skipping metric calculation.\")\n",
    "    else:\n",
    "        y_true = out_df.loc[mask, 'average'].values\n",
    "        y_pred = out_df.loc[mask, 'Predicted'].values\n",
    "        mae = round(mean_absolute_error(y_true, y_pred), 2)\n",
    "        rmse = round(np.sqrt(mean_squared_error(y_true, y_pred)), 2)\n",
    "        r2 = round(r2_score(y_true, y_pred), 4)\n",
    "        mape_v = round(mean_absolute_percentage_error(y_true, y_pred), 2)\n",
    "        acc = round(100 - mape_v, 2)\n",
    "        metrics.append({'District': district, 'Crop': crop, 'MAE': mae, 'RMSE': rmse, 'R2': r2, 'MAPE(%)': mape_v, 'Accuracy(%)': acc})\n",
    "        print(f\" âœ… {district} - {crop} | MAE={mae}, RMSE={rmse}, RÂ²={r2}, MAPE={mape_v}%, Acc={acc}%\")\n",
    "\n",
    "    # save model and CSV and graph\n",
    "    safe_name = f\"{district}_{crop}\".replace(\" \", \"_\").replace(\"/\", \"_\")\n",
    "    model.save(os.path.join(output_models, f\"{safe_name}_tat_mqa.keras\"), include_optimizer=False)\n",
    "    out_df[['date','average','Predicted']].to_csv(os.path.join(output_csv, f\"{safe_name}_tat_mqa_daily.csv\"), index=False, float_format=\"%.2f\")\n",
    "\n",
    "    # 30-day recursive forecast (uses raw_X last window)\n",
    "    raw_window = raw_X[-look_back:].copy()\n",
    "    future_preds = []\n",
    "    for _ in range(future_steps):\n",
    "        win_scaled = scaler_X.transform(raw_window)\n",
    "        pred_scaled = model.predict(win_scaled[np.newaxis, ...], verbose=0).flatten()[0]\n",
    "        pred_unscaled = float(scaler_y.inverse_transform([[pred_scaled]])[0,0])\n",
    "        future_preds.append(round(pred_unscaled, 2))\n",
    "        # build features for next step: average, lag1, lag7, ma7, ma30\n",
    "        past_avgs = np.concatenate([raw_X[:,0], np.array(future_preds)])\n",
    "        lag1 = raw_window[-1,0] if raw_window.shape[0] >= 1 else pred_unscaled\n",
    "        lag7 = past_avgs[-8] if len(past_avgs) >= 8 else float(np.mean(past_avgs))\n",
    "        ma7 = float(np.mean(past_avgs[-7:])) if len(past_avgs) >= 7 else float(np.mean(past_avgs))\n",
    "        ma30 = float(np.mean(past_avgs[-30:])) if len(past_avgs) >= 30 else float(np.mean(past_avgs))\n",
    "        new_row = np.array([pred_unscaled, lag1, lag7, ma7, ma30], dtype='float32')\n",
    "        raw_window = np.vstack([raw_window[1:], new_row])\n",
    "\n",
    "    future_dates = pd.date_range(start=out_df['date'].iat[-1] + pd.Timedelta(days=1), periods=future_steps, freq='D')\n",
    "    future_df = pd.DataFrame({'date': future_dates, 'Forecast': future_preds})\n",
    "    future_df.to_csv(os.path.join(output_csv, f\"{safe_name}_tat_mqa_future.csv\"), index=False, float_format=\"%.2f\")\n",
    "\n",
    "    # plot\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.plot(out_df['date'], out_df['average'], label='Actual', color='blue')\n",
    "    plt.plot(out_df['date'], out_df['Predicted'], label='Predicted (TAT-MQA)', color='red', linestyle='--')\n",
    "    plt.plot(future_df['date'], future_df['Forecast'], label='Future (30d)', color='green', linestyle='dotted')\n",
    "    plt.title(f\"TAT-MQA Forecast - {district} | {crop}\")\n",
    "    plt.xlabel(\"Date\"); plt.ylabel(\"Average Price\")\n",
    "    plt.legend(); plt.grid(True); plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_graphs, f\"{safe_name}_tat_mqa_graph.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    # cleanup\n",
    "    del model, X, y, X_train, X_val, preds_scaled, preds_inv, out_df, future_df, raw_window\n",
    "    gc.collect()\n",
    "\n",
    "# Save metrics\n",
    "metrics_df = pd.DataFrame(metrics).round(2)\n",
    "metrics_df.to_csv(metrics_file, index=False)\n",
    "print(\"\\nğŸ“Š All done. Metrics saved to:\", metrics_file)\n",
    "print(metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be95674-be6b-4a46-9305-73c21bc8d655",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TAT+GQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9398f6e5-812e-4450-be88-d92ea2ae4b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 5.3034e-04 - mae: 0.0117 - val_loss: 0.0081 - val_mae: 0.0478 - learning_rate: 3.1250e-05\n",
      "Epoch 44/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 5.3605e-04 - mae: 0.0120 - val_loss: 0.0081 - val_mae: 0.0496 - learning_rate: 3.1250e-05\n",
      "Epoch 45/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 5.4229e-04 - mae: 0.0119 - val_loss: 0.0079 - val_mae: 0.0459 - learning_rate: 3.1250e-05\n",
      "Epoch 46/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 5.3526e-04 - mae: 0.0117 - val_loss: 0.0079 - val_mae: 0.0476 - learning_rate: 1.5625e-05\n",
      "Epoch 47/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 5.2739e-04 - mae: 0.0118 - val_loss: 0.0079 - val_mae: 0.0481 - learning_rate: 1.5625e-05\n",
      "Epoch 48/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 5.3902e-04 - mae: 0.0119 - val_loss: 0.0079 - val_mae: 0.0503 - learning_rate: 1.5625e-05\n",
      "Epoch 49/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 5.1966e-04 - mae: 0.0116 - val_loss: 0.0079 - val_mae: 0.0482 - learning_rate: 7.8125e-06\n",
      "\u001b[1m161/161\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step    \n",
      "âœ… Bidar - onion | MAE=80.59, RMSE=142.29, RÂ²=0.8512, MAPE=6.03%, Acc=93.97%\n",
      "\n",
      "ğŸš€ Processing: Bidar | wheat\n",
      "Epoch 1/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 21ms/step - loss: 0.0534 - mae: 0.1360 - val_loss: 0.0203 - val_mae: 0.1331 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0091 - mae: 0.0730 - val_loss: 0.0482 - val_mae: 0.2146 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0082 - mae: 0.0669 - val_loss: 0.0401 - val_mae: 0.1953 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0069 - mae: 0.0624 - val_loss: 0.0518 - val_mae: 0.2237 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0065 - mae: 0.0587 - val_loss: 0.0094 - val_mae: 0.0891 - learning_rate: 5.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0047 - mae: 0.0508 - val_loss: 0.0120 - val_mae: 0.1025 - learning_rate: 5.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0046 - mae: 0.0494 - val_loss: 0.0143 - val_mae: 0.1128 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0042 - mae: 0.0473 - val_loss: 0.0073 - val_mae: 0.0772 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0036 - mae: 0.0437 - val_loss: 0.0204 - val_mae: 0.1371 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0045 - mae: 0.0479 - val_loss: 0.0211 - val_mae: 0.1396 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0043 - mae: 0.0468 - val_loss: 0.0120 - val_mae: 0.1026 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0032 - mae: 0.0402 - val_loss: 0.0074 - val_mae: 0.0780 - learning_rate: 2.5000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0033 - mae: 0.0407 - val_loss: 0.0071 - val_mae: 0.0765 - learning_rate: 2.5000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0029 - mae: 0.0382 - val_loss: 0.0083 - val_mae: 0.0835 - learning_rate: 2.5000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0032 - mae: 0.0399 - val_loss: 0.0090 - val_mae: 0.0875 - learning_rate: 2.5000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0031 - mae: 0.0388 - val_loss: 0.0094 - val_mae: 0.0898 - learning_rate: 2.5000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0030 - mae: 0.0387 - val_loss: 0.0053 - val_mae: 0.0647 - learning_rate: 1.2500e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0026 - mae: 0.0357 - val_loss: 0.0069 - val_mae: 0.0750 - learning_rate: 1.2500e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0028 - mae: 0.0376 - val_loss: 0.0074 - val_mae: 0.0781 - learning_rate: 1.2500e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0028 - mae: 0.0367 - val_loss: 0.0064 - val_mae: 0.0720 - learning_rate: 1.2500e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0025 - mae: 0.0340 - val_loss: 0.0043 - val_mae: 0.0573 - learning_rate: 6.2500e-05\n",
      "Epoch 22/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0024 - mae: 0.0336 - val_loss: 0.0043 - val_mae: 0.0571 - learning_rate: 6.2500e-05\n",
      "Epoch 23/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0024 - mae: 0.0342 - val_loss: 0.0048 - val_mae: 0.0612 - learning_rate: 6.2500e-05\n",
      "Epoch 24/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0025 - mae: 0.0344 - val_loss: 0.0037 - val_mae: 0.0521 - learning_rate: 6.2500e-05\n",
      "Epoch 25/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0024 - mae: 0.0335 - val_loss: 0.0045 - val_mae: 0.0586 - learning_rate: 6.2500e-05\n",
      "Epoch 26/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0024 - mae: 0.0334 - val_loss: 0.0048 - val_mae: 0.0609 - learning_rate: 6.2500e-05\n",
      "Epoch 27/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0026 - mae: 0.0347 - val_loss: 0.0050 - val_mae: 0.0629 - learning_rate: 6.2500e-05\n",
      "Epoch 28/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0023 - mae: 0.0326 - val_loss: 0.0036 - val_mae: 0.0510 - learning_rate: 3.1250e-05\n",
      "Epoch 29/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0023 - mae: 0.0325 - val_loss: 0.0031 - val_mae: 0.0466 - learning_rate: 3.1250e-05\n",
      "Epoch 30/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0022 - mae: 0.0319 - val_loss: 0.0036 - val_mae: 0.0514 - learning_rate: 3.1250e-05\n",
      "Epoch 31/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0022 - mae: 0.0320 - val_loss: 0.0034 - val_mae: 0.0499 - learning_rate: 3.1250e-05\n",
      "Epoch 32/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0022 - mae: 0.0319 - val_loss: 0.0034 - val_mae: 0.0494 - learning_rate: 3.1250e-05\n",
      "Epoch 33/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0021 - mae: 0.0311 - val_loss: 0.0029 - val_mae: 0.0449 - learning_rate: 1.5625e-05\n",
      "Epoch 34/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0021 - mae: 0.0309 - val_loss: 0.0030 - val_mae: 0.0455 - learning_rate: 1.5625e-05\n",
      "Epoch 35/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0021 - mae: 0.0308 - val_loss: 0.0031 - val_mae: 0.0465 - learning_rate: 1.5625e-05\n",
      "Epoch 36/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0021 - mae: 0.0310 - val_loss: 0.0033 - val_mae: 0.0485 - learning_rate: 1.5625e-05\n",
      "Epoch 37/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0021 - mae: 0.0305 - val_loss: 0.0030 - val_mae: 0.0453 - learning_rate: 7.8125e-06\n",
      "Epoch 38/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0021 - mae: 0.0308 - val_loss: 0.0028 - val_mae: 0.0440 - learning_rate: 7.8125e-06\n",
      "Epoch 39/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0021 - mae: 0.0305 - val_loss: 0.0031 - val_mae: 0.0463 - learning_rate: 7.8125e-06\n",
      "Epoch 40/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0021 - mae: 0.0300 - val_loss: 0.0030 - val_mae: 0.0452 - learning_rate: 3.9063e-06\n",
      "Epoch 41/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0021 - mae: 0.0302 - val_loss: 0.0029 - val_mae: 0.0449 - learning_rate: 3.9063e-06\n",
      "Epoch 42/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0021 - mae: 0.0306 - val_loss: 0.0028 - val_mae: 0.0436 - learning_rate: 3.9063e-06\n",
      "Epoch 43/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0021 - mae: 0.0302 - val_loss: 0.0029 - val_mae: 0.0449 - learning_rate: 3.9063e-06\n",
      "Epoch 44/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0021 - mae: 0.0300 - val_loss: 0.0029 - val_mae: 0.0444 - learning_rate: 3.9063e-06\n",
      "Epoch 45/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0021 - mae: 0.0303 - val_loss: 0.0028 - val_mae: 0.0439 - learning_rate: 3.9063e-06\n",
      "Epoch 46/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0020 - mae: 0.0299 - val_loss: 0.0028 - val_mae: 0.0436 - learning_rate: 1.9531e-06\n",
      "Epoch 47/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0021 - mae: 0.0300 - val_loss: 0.0028 - val_mae: 0.0432 - learning_rate: 1.9531e-06\n",
      "Epoch 48/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0020 - mae: 0.0300 - val_loss: 0.0028 - val_mae: 0.0433 - learning_rate: 1.9531e-06\n",
      "Epoch 49/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0020 - mae: 0.0300 - val_loss: 0.0028 - val_mae: 0.0440 - learning_rate: 9.7656e-07\n",
      "Epoch 50/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0021 - mae: 0.0302 - val_loss: 0.0028 - val_mae: 0.0440 - learning_rate: 9.7656e-07\n",
      "\u001b[1m171/171\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step\n",
      "âœ… Bidar - wheat | MAE=102.0, RMSE=151.66, RÂ²=0.9142, MAPE=4.32%, Acc=95.68%\n",
      "\n",
      "ğŸš€ Processing: Bijapur | onion\n",
      "Epoch 1/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 25ms/step - loss: 0.3339 - mae: 0.2579 - val_loss: 0.0039 - val_mae: 0.0490 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0071 - mae: 0.0649 - val_loss: 0.0020 - val_mae: 0.0379 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0062 - mae: 0.0608 - val_loss: 0.0011 - val_mae: 0.0231 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0050 - mae: 0.0545 - val_loss: 0.0016 - val_mae: 0.0329 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0047 - mae: 0.0525 - val_loss: 0.0024 - val_mae: 0.0421 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0041 - mae: 0.0493 - val_loss: 0.0012 - val_mae: 0.0254 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0034 - mae: 0.0448 - val_loss: 8.8814e-04 - val_mae: 0.0204 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0031 - mae: 0.0427 - val_loss: 8.2762e-04 - val_mae: 0.0197 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0029 - mae: 0.0409 - val_loss: 9.3105e-04 - val_mae: 0.0217 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0027 - mae: 0.0389 - val_loss: 0.0014 - val_mae: 0.0285 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0025 - mae: 0.0378 - val_loss: 8.9301e-04 - val_mae: 0.0205 - learning_rate: 2.5000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0022 - mae: 0.0352 - val_loss: 0.0011 - val_mae: 0.0224 - learning_rate: 2.5000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0022 - mae: 0.0345 - val_loss: 0.0010 - val_mae: 0.0221 - learning_rate: 2.5000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0021 - mae: 0.0339 - val_loss: 9.5064e-04 - val_mae: 0.0215 - learning_rate: 1.2500e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0021 - mae: 0.0339 - val_loss: 9.3117e-04 - val_mae: 0.0211 - learning_rate: 1.2500e-04\n",
      "\u001b[1m170/170\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step    \n",
      "âœ… Bijapur - onion | MAE=157.92, RMSE=280.12, RÂ²=0.8367, MAPE=13.01%, Acc=86.99%\n",
      "\n",
      "ğŸš€ Processing: Bijapur | wheat\n",
      "Epoch 1/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 19ms/step - loss: 0.0336 - mae: 0.1157 - val_loss: 0.0022 - val_mae: 0.0412 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0061 - mae: 0.0598 - val_loss: 0.0030 - val_mae: 0.0494 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0044 - mae: 0.0509 - val_loss: 0.0015 - val_mae: 0.0334 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0044 - mae: 0.0507 - val_loss: 5.3147e-04 - val_mae: 0.0178 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0034 - mae: 0.0430 - val_loss: 0.0011 - val_mae: 0.0283 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0035 - mae: 0.0447 - val_loss: 5.1432e-04 - val_mae: 0.0174 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0029 - mae: 0.0393 - val_loss: 5.0579e-04 - val_mae: 0.0169 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0023 - mae: 0.0346 - val_loss: 5.5346e-04 - val_mae: 0.0177 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0021 - mae: 0.0323 - val_loss: 5.9257e-04 - val_mae: 0.0186 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0022 - mae: 0.0335 - val_loss: 6.5596e-04 - val_mae: 0.0203 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0019 - mae: 0.0308 - val_loss: 0.0013 - val_mae: 0.0310 - learning_rate: 2.5000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0019 - mae: 0.0302 - val_loss: 0.0036 - val_mae: 0.0558 - learning_rate: 2.5000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0019 - mae: 0.0307 - val_loss: 0.0036 - val_mae: 0.0561 - learning_rate: 2.5000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0018 - mae: 0.0294 - val_loss: 0.0017 - val_mae: 0.0368 - learning_rate: 1.2500e-04\n",
      "\u001b[1m170/170\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step   \n",
      "âœ… Bijapur - wheat | MAE=101.74, RMSE=166.65, RÂ²=0.9409, MAPE=4.42%, Acc=95.58%\n",
      "\n",
      "ğŸš€ Processing: Chamrajnagar | onion\n",
      "Epoch 1/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 17ms/step - loss: 0.1296 - mae: 0.1839 - val_loss: 0.0044 - val_mae: 0.0468 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0057 - mae: 0.0577 - val_loss: 0.0042 - val_mae: 0.0489 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0048 - mae: 0.0537 - val_loss: 0.0052 - val_mae: 0.0563 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0043 - mae: 0.0504 - val_loss: 0.0068 - val_mae: 0.0643 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0031 - mae: 0.0428 - val_loss: 0.0051 - val_mae: 0.0537 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0024 - mae: 0.0369 - val_loss: 0.0038 - val_mae: 0.0462 - learning_rate: 5.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0023 - mae: 0.0354 - val_loss: 0.0056 - val_mae: 0.0585 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0020 - mae: 0.0327 - val_loss: 0.0046 - val_mae: 0.0518 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0018 - mae: 0.0305 - val_loss: 0.0056 - val_mae: 0.0573 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0017 - mae: 0.0297 - val_loss: 0.0028 - val_mae: 0.0389 - learning_rate: 2.5000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0015 - mae: 0.0280 - val_loss: 0.0035 - val_mae: 0.0438 - learning_rate: 2.5000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0015 - mae: 0.0274 - val_loss: 0.0041 - val_mae: 0.0484 - learning_rate: 2.5000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0015 - mae: 0.0271 - val_loss: 0.0031 - val_mae: 0.0398 - learning_rate: 2.5000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0014 - mae: 0.0261 - val_loss: 0.0043 - val_mae: 0.0500 - learning_rate: 1.2500e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0013 - mae: 0.0255 - val_loss: 0.0039 - val_mae: 0.0472 - learning_rate: 1.2500e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mae: 0.0253 - val_loss: 0.0048 - val_mae: 0.0548 - learning_rate: 1.2500e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0013 - mae: 0.0246 - val_loss: 0.0036 - val_mae: 0.0447 - learning_rate: 6.2500e-05\n",
      "\u001b[1m167/167\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step\n",
      "âœ… Chamrajnagar - onion | MAE=244.02, RMSE=293.6, RÂ²=0.9286, MAPE=23.0%, Acc=77.0%\n",
      "\n",
      "ğŸš€ Processing: Chamrajnagar | tomato\n",
      "Epoch 1/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 29ms/step - loss: 0.1413 - mae: 0.1783 - val_loss: 0.0036 - val_mae: 0.0408 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0038 - mae: 0.0496 - val_loss: 0.0023 - val_mae: 0.0311 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0034 - mae: 0.0463 - val_loss: 0.0038 - val_mae: 0.0461 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0032 - mae: 0.0449 - val_loss: 0.0023 - val_mae: 0.0316 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0026 - mae: 0.0413 - val_loss: 0.0033 - val_mae: 0.0412 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0024 - mae: 0.0385 - val_loss: 0.0023 - val_mae: 0.0324 - learning_rate: 5.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0022 - mae: 0.0372 - val_loss: 0.0023 - val_mae: 0.0322 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0020 - mae: 0.0358 - val_loss: 0.0028 - val_mae: 0.0374 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0019 - mae: 0.0349 - val_loss: 0.0024 - val_mae: 0.0339 - learning_rate: 2.5000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0018 - mae: 0.0335 - val_loss: 0.0023 - val_mae: 0.0329 - learning_rate: 2.5000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0016 - mae: 0.0323 - val_loss: 0.0024 - val_mae: 0.0336 - learning_rate: 2.5000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0015 - mae: 0.0312 - val_loss: 0.0022 - val_mae: 0.0325 - learning_rate: 1.2500e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0015 - mae: 0.0308 - val_loss: 0.0021 - val_mae: 0.0322 - learning_rate: 1.2500e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0015 - mae: 0.0306 - val_loss: 0.0021 - val_mae: 0.0314 - learning_rate: 1.2500e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mae: 0.0291 - val_loss: 0.0021 - val_mae: 0.0317 - learning_rate: 1.2500e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0013 - mae: 0.0286 - val_loss: 0.0024 - val_mae: 0.0345 - learning_rate: 1.2500e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0013 - mae: 0.0286 - val_loss: 0.0022 - val_mae: 0.0323 - learning_rate: 1.2500e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0012 - mae: 0.0274 - val_loss: 0.0021 - val_mae: 0.0327 - learning_rate: 1.2500e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0011 - mae: 0.0266 - val_loss: 0.0020 - val_mae: 0.0315 - learning_rate: 6.2500e-05\n",
      "Epoch 20/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0011 - mae: 0.0265 - val_loss: 0.0020 - val_mae: 0.0309 - learning_rate: 6.2500e-05\n",
      "Epoch 21/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0011 - mae: 0.0267 - val_loss: 0.0021 - val_mae: 0.0319 - learning_rate: 6.2500e-05\n",
      "Epoch 22/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0011 - mae: 0.0265 - val_loss: 0.0020 - val_mae: 0.0313 - learning_rate: 3.1250e-05\n",
      "Epoch 23/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0011 - mae: 0.0263 - val_loss: 0.0020 - val_mae: 0.0310 - learning_rate: 3.1250e-05\n",
      "Epoch 24/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0010 - mae: 0.0253 - val_loss: 0.0021 - val_mae: 0.0310 - learning_rate: 3.1250e-05\n",
      "Epoch 25/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0011 - mae: 0.0259 - val_loss: 0.0020 - val_mae: 0.0302 - learning_rate: 1.5625e-05\n",
      "Epoch 26/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0010 - mae: 0.0254 - val_loss: 0.0020 - val_mae: 0.0306 - learning_rate: 1.5625e-05\n",
      "Epoch 27/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0010 - mae: 0.0255 - val_loss: 0.0020 - val_mae: 0.0302 - learning_rate: 1.5625e-05\n",
      "Epoch 28/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0010 - mae: 0.0255 - val_loss: 0.0019 - val_mae: 0.0302 - learning_rate: 1.5625e-05\n",
      "Epoch 29/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 9.8735e-04 - mae: 0.0248 - val_loss: 0.0020 - val_mae: 0.0301 - learning_rate: 7.8125e-06\n",
      "Epoch 30/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0010 - mae: 0.0251 - val_loss: 0.0019 - val_mae: 0.0300 - learning_rate: 7.8125e-06\n",
      "Epoch 31/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0010 - mae: 0.0256 - val_loss: 0.0019 - val_mae: 0.0300 - learning_rate: 7.8125e-06\n",
      "Epoch 32/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 9.3647e-04 - mae: 0.0244 - val_loss: 0.0019 - val_mae: 0.0300 - learning_rate: 3.9063e-06\n",
      "Epoch 33/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 9.7909e-04 - mae: 0.0249 - val_loss: 0.0019 - val_mae: 0.0299 - learning_rate: 3.9063e-06\n",
      "Epoch 34/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 9.9972e-04 - mae: 0.0252 - val_loss: 0.0019 - val_mae: 0.0297 - learning_rate: 3.9063e-06\n",
      "Epoch 35/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0010 - mae: 0.0252 - val_loss: 0.0019 - val_mae: 0.0296 - learning_rate: 1.9531e-06\n",
      "Epoch 36/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 9.9058e-04 - mae: 0.0249 - val_loss: 0.0019 - val_mae: 0.0298 - learning_rate: 1.9531e-06\n",
      "Epoch 37/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 9.4953e-04 - mae: 0.0245 - val_loss: 0.0019 - val_mae: 0.0299 - learning_rate: 1.9531e-06\n",
      "Epoch 38/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 9.6256e-04 - mae: 0.0249 - val_loss: 0.0019 - val_mae: 0.0299 - learning_rate: 9.7656e-07\n",
      "Epoch 39/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 9.6873e-04 - mae: 0.0246 - val_loss: 0.0019 - val_mae: 0.0299 - learning_rate: 9.7656e-07\n",
      "Epoch 40/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0010 - mae: 0.0253 - val_loss: 0.0019 - val_mae: 0.0300 - learning_rate: 9.7656e-07\n",
      "Epoch 41/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 9.4136e-04 - mae: 0.0242 - val_loss: 0.0019 - val_mae: 0.0300 - learning_rate: 4.8828e-07\n",
      "Epoch 42/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0010 - mae: 0.0252 - val_loss: 0.0019 - val_mae: 0.0300 - learning_rate: 4.8828e-07\n",
      "\u001b[1m171/171\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step    \n",
      "âœ… Chamrajnagar - tomato | MAE=379.37, RMSE=512.3, RÂ²=0.7718, MAPE=37.36%, Acc=62.64%\n",
      "\n",
      "ğŸš€ Processing: Chamrajnagar | wheat\n",
      "âš ï¸ Not enough points for Chamrajnagar-wheat. Using crop-level fallback.\n",
      "Epoch 1/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - loss: 0.0434 - mae: 0.1195 - val_loss: 0.0255 - val_mae: 0.1531 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0046 - mae: 0.0536 - val_loss: 0.0047 - val_mae: 0.0549 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0034 - mae: 0.0461 - val_loss: 0.0050 - val_mae: 0.0591 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0028 - mae: 0.0414 - val_loss: 0.0020 - val_mae: 0.0326 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0024 - mae: 0.0383 - val_loss: 0.0033 - val_mae: 0.0457 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0017 - mae: 0.0321 - val_loss: 0.0033 - val_mae: 0.0498 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0013 - mae: 0.0276 - val_loss: 0.0052 - val_mae: 0.0677 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0011 - mae: 0.0243 - val_loss: 0.0034 - val_mae: 0.0543 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0010 - mae: 0.0241 - val_loss: 0.0016 - val_mae: 0.0328 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 9.1013e-04 - mae: 0.0225 - val_loss: 0.0021 - val_mae: 0.0410 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 8.9271e-04 - mae: 0.0220 - val_loss: 0.0014 - val_mae: 0.0295 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 7.8411e-04 - mae: 0.0205 - val_loss: 0.0016 - val_mae: 0.0319 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 7.4236e-04 - mae: 0.0198 - val_loss: 0.0014 - val_mae: 0.0294 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 6.9255e-04 - mae: 0.0188 - val_loss: 0.0014 - val_mae: 0.0279 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 6.2091e-04 - mae: 0.0178 - val_loss: 0.0014 - val_mae: 0.0272 - learning_rate: 2.5000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 6.3692e-04 - mae: 0.0178 - val_loss: 0.0013 - val_mae: 0.0261 - learning_rate: 2.5000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 6.2030e-04 - mae: 0.0180 - val_loss: 0.0014 - val_mae: 0.0280 - learning_rate: 2.5000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 5.6172e-04 - mae: 0.0167 - val_loss: 0.0017 - val_mae: 0.0327 - learning_rate: 1.2500e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 5.4150e-04 - mae: 0.0164 - val_loss: 0.0015 - val_mae: 0.0307 - learning_rate: 1.2500e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 5.3473e-04 - mae: 0.0163 - val_loss: 0.0016 - val_mae: 0.0306 - learning_rate: 1.2500e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 5.5718e-04 - mae: 0.0163 - val_loss: 0.0016 - val_mae: 0.0320 - learning_rate: 6.2500e-05\n",
      "Epoch 22/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 5.2032e-04 - mae: 0.0160 - val_loss: 0.0014 - val_mae: 0.0276 - learning_rate: 6.2500e-05\n",
      "Epoch 23/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 5.2203e-04 - mae: 0.0158 - val_loss: 0.0014 - val_mae: 0.0289 - learning_rate: 6.2500e-05\n",
      "\u001b[1m171/171\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step    \n",
      "âœ… Chamrajnagar - wheat | MAE=50.79, RMSE=67.07, RÂ²=0.9823, MAPE=2.26%, Acc=97.74%\n",
      "\n",
      "ğŸš€ Processing: Chikmagalur | capsicum\n",
      "Epoch 1/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 29ms/step - loss: 0.2636 - mae: 0.3391 - val_loss: 0.0566 - val_mae: 0.1942 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0104 - mae: 0.0788 - val_loss: 0.0538 - val_mae: 0.1793 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0080 - mae: 0.0683 - val_loss: 0.0422 - val_mae: 0.1467 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0076 - mae: 0.0679 - val_loss: 0.0282 - val_mae: 0.1226 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0050 - mae: 0.0553 - val_loss: 0.0203 - val_mae: 0.1059 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0051 - mae: 0.0562 - val_loss: 0.0186 - val_mae: 0.1036 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0041 - mae: 0.0494 - val_loss: 0.0169 - val_mae: 0.0933 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0037 - mae: 0.0474 - val_loss: 0.0184 - val_mae: 0.1037 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0041 - mae: 0.0502 - val_loss: 0.0171 - val_mae: 0.0998 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0032 - mae: 0.0439 - val_loss: 0.0177 - val_mae: 0.0950 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0027 - mae: 0.0400 - val_loss: 0.0160 - val_mae: 0.0915 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0024 - mae: 0.0379 - val_loss: 0.0160 - val_mae: 0.0901 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0024 - mae: 0.0372 - val_loss: 0.0170 - val_mae: 0.0981 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0023 - mae: 0.0368 - val_loss: 0.0171 - val_mae: 0.0980 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0022 - mae: 0.0369 - val_loss: 0.0162 - val_mae: 0.0902 - learning_rate: 2.5000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0019 - mae: 0.0332 - val_loss: 0.0167 - val_mae: 0.0922 - learning_rate: 2.5000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0019 - mae: 0.0325 - val_loss: 0.0164 - val_mae: 0.0888 - learning_rate: 2.5000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0018 - mae: 0.0324 - val_loss: 0.0165 - val_mae: 0.0907 - learning_rate: 1.2500e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m52/52\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0018 - mae: 0.0321 - val_loss: 0.0165 - val_mae: 0.0902 - learning_rate: 1.2500e-04\n",
      "\u001b[1m64/64\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step  \n",
      "âœ… Chikmagalur - capsicum | MAE=123.04, RMSE=217.65, RÂ²=0.8704, MAPE=7.16%, Acc=92.84%\n",
      "\n",
      "ğŸš€ Processing: Chikmagalur | onion\n",
      "Epoch 1/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - loss: 0.0509 - mae: 0.1303 - val_loss: 0.0024 - val_mae: 0.0351 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0050 - mae: 0.0563 - val_loss: 0.0037 - val_mae: 0.0514 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0041 - mae: 0.0509 - val_loss: 0.0020 - val_mae: 0.0336 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0032 - mae: 0.0449 - val_loss: 0.0018 - val_mae: 0.0302 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0025 - mae: 0.0385 - val_loss: 0.0020 - val_mae: 0.0326 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0020 - mae: 0.0348 - val_loss: 0.0017 - val_mae: 0.0282 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0021 - mae: 0.0354 - val_loss: 0.0018 - val_mae: 0.0283 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0016 - mae: 0.0294 - val_loss: 0.0021 - val_mae: 0.0349 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0014 - mae: 0.0285 - val_loss: 0.0021 - val_mae: 0.0347 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0014 - mae: 0.0280 - val_loss: 0.0018 - val_mae: 0.0300 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0013 - mae: 0.0267 - val_loss: 0.0016 - val_mae: 0.0269 - learning_rate: 2.5000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0013 - mae: 0.0264 - val_loss: 0.0017 - val_mae: 0.0266 - learning_rate: 2.5000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0013 - mae: 0.0266 - val_loss: 0.0017 - val_mae: 0.0294 - learning_rate: 2.5000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0013 - mae: 0.0263 - val_loss: 0.0018 - val_mae: 0.0307 - learning_rate: 2.5000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0012 - mae: 0.0249 - val_loss: 0.0017 - val_mae: 0.0296 - learning_rate: 1.2500e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0011 - mae: 0.0246 - val_loss: 0.0019 - val_mae: 0.0319 - learning_rate: 1.2500e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0011 - mae: 0.0243 - val_loss: 0.0019 - val_mae: 0.0329 - learning_rate: 1.2500e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0011 - mae: 0.0240 - val_loss: 0.0017 - val_mae: 0.0294 - learning_rate: 6.2500e-05\n",
      "\u001b[1m171/171\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step    \n",
      "âœ… Chikmagalur - onion | MAE=100.61, RMSE=146.96, RÂ²=0.9575, MAPE=6.92%, Acc=93.08%\n",
      "\n",
      "ğŸš€ Processing: Chikmagalur | tomato\n",
      "Epoch 1/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - loss: 0.0364 - mae: 0.1088 - val_loss: 0.0078 - val_mae: 0.0600 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0034 - mae: 0.0450 - val_loss: 0.0087 - val_mae: 0.0626 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0029 - mae: 0.0420 - val_loss: 0.0064 - val_mae: 0.0489 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0025 - mae: 0.0383 - val_loss: 0.0059 - val_mae: 0.0487 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0020 - mae: 0.0337 - val_loss: 0.0066 - val_mae: 0.0544 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0016 - mae: 0.0303 - val_loss: 0.0065 - val_mae: 0.0542 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0014 - mae: 0.0280 - val_loss: 0.0066 - val_mae: 0.0579 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0013 - mae: 0.0259 - val_loss: 0.0057 - val_mae: 0.0496 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0011 - mae: 0.0239 - val_loss: 0.0059 - val_mae: 0.0542 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0011 - mae: 0.0238 - val_loss: 0.0060 - val_mae: 0.0544 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0011 - mae: 0.0238 - val_loss: 0.0056 - val_mae: 0.0512 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0011 - mae: 0.0231 - val_loss: 0.0043 - val_mae: 0.0429 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0010 - mae: 0.0223 - val_loss: 0.0064 - val_mae: 0.0597 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0010 - mae: 0.0224 - val_loss: 0.0053 - val_mae: 0.0514 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0010 - mae: 0.0224 - val_loss: 0.0056 - val_mae: 0.0535 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 9.1660e-04 - mae: 0.0212 - val_loss: 0.0050 - val_mae: 0.0493 - learning_rate: 2.5000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 8.9328e-04 - mae: 0.0211 - val_loss: 0.0042 - val_mae: 0.0428 - learning_rate: 2.5000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 8.9122e-04 - mae: 0.0205 - val_loss: 0.0041 - val_mae: 0.0423 - learning_rate: 2.5000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 8.6165e-04 - mae: 0.0204 - val_loss: 0.0036 - val_mae: 0.0383 - learning_rate: 2.5000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 8.1437e-04 - mae: 0.0198 - val_loss: 0.0036 - val_mae: 0.0386 - learning_rate: 2.5000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 8.7108e-04 - mae: 0.0205 - val_loss: 0.0036 - val_mae: 0.0389 - learning_rate: 2.5000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 8.0479e-04 - mae: 0.0194 - val_loss: 0.0038 - val_mae: 0.0396 - learning_rate: 2.5000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 7.7540e-04 - mae: 0.0192 - val_loss: 0.0036 - val_mae: 0.0387 - learning_rate: 1.2500e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 7.7499e-04 - mae: 0.0190 - val_loss: 0.0037 - val_mae: 0.0393 - learning_rate: 1.2500e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 7.9692e-04 - mae: 0.0192 - val_loss: 0.0036 - val_mae: 0.0384 - learning_rate: 1.2500e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 7.5371e-04 - mae: 0.0185 - val_loss: 0.0035 - val_mae: 0.0378 - learning_rate: 6.2500e-05\n",
      "Epoch 27/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 7.4366e-04 - mae: 0.0183 - val_loss: 0.0035 - val_mae: 0.0379 - learning_rate: 6.2500e-05\n",
      "Epoch 28/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 7.5776e-04 - mae: 0.0185 - val_loss: 0.0034 - val_mae: 0.0373 - learning_rate: 6.2500e-05\n",
      "Epoch 29/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 7.2322e-04 - mae: 0.0180 - val_loss: 0.0035 - val_mae: 0.0383 - learning_rate: 6.2500e-05\n",
      "Epoch 30/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 7.6938e-04 - mae: 0.0188 - val_loss: 0.0035 - val_mae: 0.0378 - learning_rate: 6.2500e-05\n",
      "Epoch 31/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 7.3945e-04 - mae: 0.0184 - val_loss: 0.0034 - val_mae: 0.0374 - learning_rate: 6.2500e-05\n",
      "Epoch 32/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 7.3429e-04 - mae: 0.0180 - val_loss: 0.0034 - val_mae: 0.0372 - learning_rate: 3.1250e-05\n",
      "Epoch 33/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 7.1466e-04 - mae: 0.0178 - val_loss: 0.0033 - val_mae: 0.0370 - learning_rate: 3.1250e-05\n",
      "Epoch 34/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 7.2022e-04 - mae: 0.0179 - val_loss: 0.0032 - val_mae: 0.0365 - learning_rate: 3.1250e-05\n",
      "Epoch 35/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 7.1062e-04 - mae: 0.0179 - val_loss: 0.0032 - val_mae: 0.0365 - learning_rate: 3.1250e-05\n",
      "Epoch 36/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 7.0909e-04 - mae: 0.0181 - val_loss: 0.0032 - val_mae: 0.0364 - learning_rate: 3.1250e-05\n",
      "Epoch 37/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 7.0941e-04 - mae: 0.0180 - val_loss: 0.0032 - val_mae: 0.0366 - learning_rate: 3.1250e-05\n",
      "Epoch 38/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 7.1676e-04 - mae: 0.0179 - val_loss: 0.0032 - val_mae: 0.0365 - learning_rate: 1.5625e-05\n",
      "Epoch 39/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 7.1492e-04 - mae: 0.0177 - val_loss: 0.0033 - val_mae: 0.0368 - learning_rate: 1.5625e-05\n",
      "Epoch 40/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 6.9604e-04 - mae: 0.0175 - val_loss: 0.0033 - val_mae: 0.0371 - learning_rate: 1.5625e-05\n",
      "Epoch 41/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 7.1197e-04 - mae: 0.0177 - val_loss: 0.0032 - val_mae: 0.0364 - learning_rate: 7.8125e-06\n",
      "Epoch 42/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 6.8274e-04 - mae: 0.0175 - val_loss: 0.0033 - val_mae: 0.0368 - learning_rate: 7.8125e-06\n",
      "Epoch 43/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 6.8600e-04 - mae: 0.0172 - val_loss: 0.0032 - val_mae: 0.0366 - learning_rate: 7.8125e-06\n",
      "\u001b[1m171/171\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step   \n",
      "âœ… Chikmagalur - tomato | MAE=113.07, RMSE=191.73, RÂ²=0.9286, MAPE=10.65%, Acc=89.35%\n",
      "\n",
      "ğŸš€ Processing: Chikmagalur | wheat\n",
      "Epoch 1/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0355 - mae: 0.1101 - val_loss: 2.9703e-04 - val_mae: 0.0125 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0048 - mae: 0.0552 - val_loss: 0.0026 - val_mae: 0.0480 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0038 - mae: 0.0482 - val_loss: 9.2361e-04 - val_mae: 0.0276 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0027 - mae: 0.0409 - val_loss: 2.6095e-04 - val_mae: 0.0125 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0018 - mae: 0.0333 - val_loss: 0.0011 - val_mae: 0.0314 - learning_rate: 5.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0017 - mae: 0.0326 - val_loss: 7.0786e-04 - val_mae: 0.0234 - learning_rate: 5.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0012 - mae: 0.0272 - val_loss: 1.8814e-04 - val_mae: 0.0097 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0013 - mae: 0.0279 - val_loss: 2.8751e-04 - val_mae: 0.0122 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0010 - mae: 0.0247 - val_loss: 3.0701e-04 - val_mae: 0.0134 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 9.7782e-04 - mae: 0.0247 - val_loss: 2.6384e-04 - val_mae: 0.0117 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 8.2046e-04 - mae: 0.0221 - val_loss: 3.5024e-04 - val_mae: 0.0152 - learning_rate: 2.5000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 7.7948e-04 - mae: 0.0215 - val_loss: 0.0013 - val_mae: 0.0330 - learning_rate: 2.5000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 7.8862e-04 - mae: 0.0216 - val_loss: 3.1043e-04 - val_mae: 0.0136 - learning_rate: 2.5000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 7.0686e-04 - mae: 0.0201 - val_loss: 8.2545e-04 - val_mae: 0.0258 - learning_rate: 1.2500e-04\n",
      "\u001b[1m171/171\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step    \n",
      "âœ… Chikmagalur - wheat | MAE=29.02, RMSE=39.82, RÂ²=0.9933, MAPE=1.59%, Acc=98.41%\n",
      "\n",
      "ğŸš€ Processing: Chitradurga | onion\n",
      "Epoch 1/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 27ms/step - loss: 0.0373 - mae: 0.1215 - val_loss: 0.0016 - val_mae: 0.0388 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0075 - mae: 0.0640 - val_loss: 1.0118e-04 - val_mae: 0.0046 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0053 - mae: 0.0529 - val_loss: 8.7316e-05 - val_mae: 0.0026 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0037 - mae: 0.0422 - val_loss: 1.6469e-04 - val_mae: 0.0098 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0031 - mae: 0.0380 - val_loss: 1.5604e-04 - val_mae: 0.0084 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0025 - mae: 0.0316 - val_loss: 1.0109e-04 - val_mae: 0.0043 - learning_rate: 5.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0021 - mae: 0.0285 - val_loss: 1.0323e-04 - val_mae: 0.0046 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0022 - mae: 0.0291 - val_loss: 1.7606e-04 - val_mae: 0.0100 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0019 - mae: 0.0265 - val_loss: 4.7226e-04 - val_mae: 0.0207 - learning_rate: 2.5000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0019 - mae: 0.0261 - val_loss: 9.2685e-05 - val_mae: 0.0041 - learning_rate: 2.5000e-04\n",
      "\u001b[1m161/161\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step   \n",
      "âœ… Chitradurga - onion | MAE=43.45, RMSE=95.13, RÂ²=0.9566, MAPE=3.54%, Acc=96.46%\n",
      "\n",
      "ğŸš€ Processing: Chitradurga | tomato\n",
      "Epoch 1/50\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - loss: 0.1349 - mae: 0.1821 - val_loss: 1.2148e-05 - val_mae: 0.0035 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0044 - mae: 0.0529 - val_loss: 2.5936e-04 - val_mae: 0.0161 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0042 - mae: 0.0509 - val_loss: 3.1722e-04 - val_mae: 0.0178 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0040 - mae: 0.0505 - val_loss: 2.5279e-05 - val_mae: 0.0050 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0031 - mae: 0.0439 - val_loss: 8.9007e-05 - val_mae: 0.0094 - learning_rate: 5.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0030 - mae: 0.0431 - val_loss: 1.4885e-05 - val_mae: 0.0039 - learning_rate: 5.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0026 - mae: 0.0403 - val_loss: 5.4498e-06 - val_mae: 0.0023 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0024 - mae: 0.0381 - val_loss: 3.8257e-06 - val_mae: 0.0020 - learning_rate: 2.5000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0021 - mae: 0.0362 - val_loss: 1.7203e-05 - val_mae: 0.0041 - learning_rate: 2.5000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0020 - mae: 0.0353 - val_loss: 4.4953e-05 - val_mae: 0.0067 - learning_rate: 2.5000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0018 - mae: 0.0338 - val_loss: 2.3870e-06 - val_mae: 0.0015 - learning_rate: 1.2500e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0018 - mae: 0.0333 - val_loss: 2.0352e-04 - val_mae: 0.0143 - learning_rate: 1.2500e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0017 - mae: 0.0333 - val_loss: 6.4328e-05 - val_mae: 0.0080 - learning_rate: 1.2500e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0017 - mae: 0.0330 - val_loss: 5.8655e-08 - val_mae: 2.4219e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 15/50\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0017 - mae: 0.0323 - val_loss: 1.4049e-05 - val_mae: 0.0037 - learning_rate: 6.2500e-05\n",
      "Epoch 16/50\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0016 - mae: 0.0315 - val_loss: 1.1463e-05 - val_mae: 0.0034 - learning_rate: 6.2500e-05\n",
      "Epoch 17/50\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0016 - mae: 0.0315 - val_loss: 6.0430e-06 - val_mae: 0.0025 - learning_rate: 3.1250e-05\n",
      "Epoch 18/50\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0016 - mae: 0.0317 - val_loss: 4.1477e-05 - val_mae: 0.0064 - learning_rate: 3.1250e-05\n",
      "Epoch 19/50\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0016 - mae: 0.0318 - val_loss: 5.5684e-08 - val_mae: 2.3597e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 20/50\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0015 - mae: 0.0304 - val_loss: 1.0350e-06 - val_mae: 0.0010 - learning_rate: 1.5625e-05\n",
      "Epoch 21/50\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0016 - mae: 0.0309 - val_loss: 4.1585e-07 - val_mae: 6.4486e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 22/50\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0015 - mae: 0.0309 - val_loss: 1.2359e-05 - val_mae: 0.0035 - learning_rate: 1.5625e-05\n",
      "Epoch 23/50\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0015 - mae: 0.0304 - val_loss: 3.0003e-06 - val_mae: 0.0017 - learning_rate: 7.8125e-06\n",
      "Epoch 24/50\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0015 - mae: 0.0301 - val_loss: 3.0819e-06 - val_mae: 0.0018 - learning_rate: 7.8125e-06\n",
      "Epoch 25/50\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0016 - mae: 0.0312 - val_loss: 4.6825e-07 - val_mae: 6.8429e-04 - learning_rate: 7.8125e-06\n",
      "Epoch 26/50\n",
      "\u001b[1m111/111\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0015 - mae: 0.0304 - val_loss: 4.1167e-07 - val_mae: 6.4161e-04 - learning_rate: 3.9063e-06\n",
      "\u001b[1m138/138\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step   \n",
      "âœ… Chitradurga - tomato | MAE=43.53, RMSE=100.75, RÂ²=0.9903, MAPE=3.51%, Acc=96.49%\n",
      "\n",
      "ğŸš€ Processing: Chitradurga | wheat\n",
      "Epoch 1/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - loss: 0.0535 - mae: 0.1228 - val_loss: 6.7348e-04 - val_mae: 0.0252 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0039 - mae: 0.0481 - val_loss: 0.0016 - val_mae: 0.0396 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0032 - mae: 0.0438 - val_loss: 1.0193e-04 - val_mae: 0.0082 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0031 - mae: 0.0430 - val_loss: 8.5682e-04 - val_mae: 0.0280 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0023 - mae: 0.0369 - val_loss: 0.0023 - val_mae: 0.0471 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0022 - mae: 0.0361 - val_loss: 1.9893e-04 - val_mae: 0.0109 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0017 - mae: 0.0307 - val_loss: 0.0015 - val_mae: 0.0370 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0015 - mae: 0.0288 - val_loss: 2.1520e-04 - val_mae: 0.0118 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0015 - mae: 0.0281 - val_loss: 7.4320e-04 - val_mae: 0.0250 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0012 - mae: 0.0246 - val_loss: 5.4270e-04 - val_mae: 0.0205 - learning_rate: 2.5000e-04\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step   \n",
      "âœ… Chitradurga - wheat | MAE=52.84, RMSE=79.58, RÂ²=0.981, MAPE=2.92%, Acc=97.08%\n",
      "\n",
      "ğŸš€ Processing: Davangere | capsicum\n",
      "Epoch 1/50\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - loss: 0.0812 - mae: 0.1538 - val_loss: 0.0114 - val_mae: 0.0694 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0071 - mae: 0.0661 - val_loss: 0.0072 - val_mae: 0.0508 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0059 - mae: 0.0605 - val_loss: 0.0060 - val_mae: 0.0452 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0043 - mae: 0.0515 - val_loss: 0.0056 - val_mae: 0.0450 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0039 - mae: 0.0498 - val_loss: 0.0055 - val_mae: 0.0448 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0029 - mae: 0.0417 - val_loss: 0.0055 - val_mae: 0.0458 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0022 - mae: 0.0366 - val_loss: 0.0050 - val_mae: 0.0431 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0019 - mae: 0.0335 - val_loss: 0.0048 - val_mae: 0.0409 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0017 - mae: 0.0320 - val_loss: 0.0051 - val_mae: 0.0448 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0016 - mae: 0.0310 - val_loss: 0.0049 - val_mae: 0.0432 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0014 - mae: 0.0285 - val_loss: 0.0048 - val_mae: 0.0425 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0012 - mae: 0.0252 - val_loss: 0.0045 - val_mae: 0.0399 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0010 - mae: 0.0240 - val_loss: 0.0050 - val_mae: 0.0466 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0011 - mae: 0.0246 - val_loss: 0.0052 - val_mae: 0.0490 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0010 - mae: 0.0238 - val_loss: 0.0048 - val_mae: 0.0450 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0010 - mae: 0.0235 - val_loss: 0.0045 - val_mae: 0.0417 - learning_rate: 2.5000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 9.4011e-04 - mae: 0.0224 - val_loss: 0.0048 - val_mae: 0.0456 - learning_rate: 2.5000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 9.5994e-04 - mae: 0.0226 - val_loss: 0.0050 - val_mae: 0.0480 - learning_rate: 2.5000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 9.2900e-04 - mae: 0.0221 - val_loss: 0.0044 - val_mae: 0.0399 - learning_rate: 1.2500e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 8.7773e-04 - mae: 0.0212 - val_loss: 0.0044 - val_mae: 0.0404 - learning_rate: 1.2500e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 8.8355e-04 - mae: 0.0215 - val_loss: 0.0044 - val_mae: 0.0397 - learning_rate: 1.2500e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 9.1107e-04 - mae: 0.0219 - val_loss: 0.0044 - val_mae: 0.0404 - learning_rate: 1.2500e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 9.2375e-04 - mae: 0.0219 - val_loss: 0.0044 - val_mae: 0.0403 - learning_rate: 1.2500e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 8.8336e-04 - mae: 0.0212 - val_loss: 0.0045 - val_mae: 0.0414 - learning_rate: 1.2500e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 8.7181e-04 - mae: 0.0210 - val_loss: 0.0044 - val_mae: 0.0397 - learning_rate: 6.2500e-05\n",
      "Epoch 26/50\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 8.5222e-04 - mae: 0.0211 - val_loss: 0.0044 - val_mae: 0.0397 - learning_rate: 6.2500e-05\n",
      "Epoch 27/50\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 8.9663e-04 - mae: 0.0211 - val_loss: 0.0044 - val_mae: 0.0395 - learning_rate: 6.2500e-05\n",
      "Epoch 28/50\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 8.2760e-04 - mae: 0.0204 - val_loss: 0.0044 - val_mae: 0.0405 - learning_rate: 3.1250e-05\n",
      "Epoch 29/50\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.3231e-04 - mae: 0.0205 - val_loss: 0.0044 - val_mae: 0.0401 - learning_rate: 3.1250e-05\n",
      "Epoch 30/50\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 8.3710e-04 - mae: 0.0205 - val_loss: 0.0044 - val_mae: 0.0398 - learning_rate: 3.1250e-05\n",
      "Epoch 31/50\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.3277e-04 - mae: 0.0203 - val_loss: 0.0044 - val_mae: 0.0399 - learning_rate: 1.5625e-05\n",
      "Epoch 32/50\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 8.3432e-04 - mae: 0.0203 - val_loss: 0.0044 - val_mae: 0.0396 - learning_rate: 1.5625e-05\n",
      "Epoch 33/50\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 8.2750e-04 - mae: 0.0204 - val_loss: 0.0044 - val_mae: 0.0400 - learning_rate: 1.5625e-05\n",
      "Epoch 34/50\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 8.5397e-04 - mae: 0.0207 - val_loss: 0.0044 - val_mae: 0.0399 - learning_rate: 7.8125e-06\n",
      "Epoch 35/50\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.1389e-04 - mae: 0.0202 - val_loss: 0.0044 - val_mae: 0.0400 - learning_rate: 7.8125e-06\n",
      "Epoch 36/50\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 8.3274e-04 - mae: 0.0204 - val_loss: 0.0044 - val_mae: 0.0399 - learning_rate: 7.8125e-06\n",
      "Epoch 37/50\n",
      "\u001b[1m112/112\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 8.3105e-04 - mae: 0.0207 - val_loss: 0.0044 - val_mae: 0.0397 - learning_rate: 3.9063e-06\n",
      "\u001b[1m140/140\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 39ms/step\n",
      "âœ… Davangere - capsicum | MAE=338.65, RMSE=593.39, RÂ²=0.883, MAPE=9.96%, Acc=90.04%\n",
      "\n",
      "ğŸš€ Processing: Davangere | onion\n",
      "Epoch 1/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 22ms/step - loss: 0.0615 - mae: 0.1281 - val_loss: 4.0697e-04 - val_mae: 0.0164 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0046 - mae: 0.0512 - val_loss: 4.8817e-04 - val_mae: 0.0174 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0039 - mae: 0.0473 - val_loss: 0.0056 - val_mae: 0.0720 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0033 - mae: 0.0431 - val_loss: 0.0043 - val_mae: 0.0624 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0028 - mae: 0.0383 - val_loss: 0.0017 - val_mae: 0.0371 - learning_rate: 5.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0024 - mae: 0.0353 - val_loss: 0.0032 - val_mae: 0.0533 - learning_rate: 5.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0024 - mae: 0.0350 - val_loss: 0.0025 - val_mae: 0.0467 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0021 - mae: 0.0319 - val_loss: 0.0014 - val_mae: 0.0347 - learning_rate: 2.5000e-04\n",
      "\u001b[1m171/171\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step \n",
      "âœ… Davangere - onion | MAE=301.49, RMSE=455.41, RÂ²=0.6063, MAPE=35.46%, Acc=64.54%\n",
      "\n",
      "ğŸš€ Processing: Davangere | tomato\n",
      "Epoch 1/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 21ms/step - loss: 0.0918 - mae: 0.1588 - val_loss: 0.0180 - val_mae: 0.0760 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0055 - mae: 0.0583 - val_loss: 0.0124 - val_mae: 0.0687 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0047 - mae: 0.0545 - val_loss: 0.0096 - val_mae: 0.0597 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0035 - mae: 0.0466 - val_loss: 0.0094 - val_mae: 0.0600 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0027 - mae: 0.0408 - val_loss: 0.0081 - val_mae: 0.0563 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0023 - mae: 0.0370 - val_loss: 0.0077 - val_mae: 0.0579 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0018 - mae: 0.0327 - val_loss: 0.0078 - val_mae: 0.0564 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0016 - mae: 0.0302 - val_loss: 0.0081 - val_mae: 0.0560 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0014 - mae: 0.0288 - val_loss: 0.0081 - val_mae: 0.0554 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0012 - mae: 0.0257 - val_loss: 0.0089 - val_mae: 0.0590 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0011 - mae: 0.0254 - val_loss: 0.0079 - val_mae: 0.0542 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0011 - mae: 0.0248 - val_loss: 0.0081 - val_mae: 0.0552 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0010 - mae: 0.0236 - val_loss: 0.0075 - val_mae: 0.0532 - learning_rate: 2.5000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0010 - mae: 0.0232 - val_loss: 0.0079 - val_mae: 0.0537 - learning_rate: 2.5000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0010 - mae: 0.0231 - val_loss: 0.0074 - val_mae: 0.0528 - learning_rate: 2.5000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 9.6540e-04 - mae: 0.0228 - val_loss: 0.0077 - val_mae: 0.0534 - learning_rate: 2.5000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 9.9813e-04 - mae: 0.0229 - val_loss: 0.0079 - val_mae: 0.0538 - learning_rate: 2.5000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 9.6646e-04 - mae: 0.0228 - val_loss: 0.0076 - val_mae: 0.0530 - learning_rate: 2.5000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 9.2823e-04 - mae: 0.0218 - val_loss: 0.0077 - val_mae: 0.0531 - learning_rate: 1.2500e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 9.0855e-04 - mae: 0.0216 - val_loss: 0.0076 - val_mae: 0.0531 - learning_rate: 1.2500e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 9.1308e-04 - mae: 0.0217 - val_loss: 0.0075 - val_mae: 0.0529 - learning_rate: 1.2500e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 8.4901e-04 - mae: 0.0208 - val_loss: 0.0074 - val_mae: 0.0530 - learning_rate: 6.2500e-05\n",
      "Epoch 23/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 8.6277e-04 - mae: 0.0209 - val_loss: 0.0073 - val_mae: 0.0528 - learning_rate: 6.2500e-05\n",
      "Epoch 24/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 8.8790e-04 - mae: 0.0212 - val_loss: 0.0073 - val_mae: 0.0528 - learning_rate: 6.2500e-05\n",
      "Epoch 25/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.6060e-04 - mae: 0.0209 - val_loss: 0.0074 - val_mae: 0.0528 - learning_rate: 3.1250e-05\n",
      "Epoch 26/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.6966e-04 - mae: 0.0211 - val_loss: 0.0073 - val_mae: 0.0527 - learning_rate: 3.1250e-05\n",
      "Epoch 27/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 8.7109e-04 - mae: 0.0213 - val_loss: 0.0073 - val_mae: 0.0527 - learning_rate: 3.1250e-05\n",
      "Epoch 28/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 8.5413e-04 - mae: 0.0211 - val_loss: 0.0073 - val_mae: 0.0526 - learning_rate: 1.5625e-05\n",
      "Epoch 29/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 8.3928e-04 - mae: 0.0207 - val_loss: 0.0073 - val_mae: 0.0527 - learning_rate: 1.5625e-05\n",
      "Epoch 30/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 8.5499e-04 - mae: 0.0209 - val_loss: 0.0073 - val_mae: 0.0526 - learning_rate: 1.5625e-05\n",
      "Epoch 31/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 8.3157e-04 - mae: 0.0207 - val_loss: 0.0073 - val_mae: 0.0531 - learning_rate: 7.8125e-06\n",
      "Epoch 32/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 8.2572e-04 - mae: 0.0204 - val_loss: 0.0073 - val_mae: 0.0526 - learning_rate: 7.8125e-06\n",
      "Epoch 33/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.2498e-04 - mae: 0.0204 - val_loss: 0.0073 - val_mae: 0.0526 - learning_rate: 7.8125e-06\n",
      "Epoch 34/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 8.5786e-04 - mae: 0.0208 - val_loss: 0.0073 - val_mae: 0.0527 - learning_rate: 7.8125e-06\n",
      "Epoch 35/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 8.3847e-04 - mae: 0.0204 - val_loss: 0.0073 - val_mae: 0.0527 - learning_rate: 3.9063e-06\n",
      "Epoch 36/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 8.4309e-04 - mae: 0.0207 - val_loss: 0.0073 - val_mae: 0.0527 - learning_rate: 3.9063e-06\n",
      "Epoch 37/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 8.6066e-04 - mae: 0.0207 - val_loss: 0.0073 - val_mae: 0.0528 - learning_rate: 3.9063e-06\n",
      "Epoch 38/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 8.5182e-04 - mae: 0.0208 - val_loss: 0.0073 - val_mae: 0.0528 - learning_rate: 1.9531e-06\n",
      "\u001b[1m171/171\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step   \n",
      "âœ… Davangere - tomato | MAE=194.41, RMSE=357.61, RÂ²=0.8705, MAPE=19.73%, Acc=80.27%\n",
      "\n",
      "ğŸš€ Processing: Davangere | wheat\n",
      "Epoch 1/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 21ms/step - loss: 0.0357 - mae: 0.1097 - val_loss: 0.0026 - val_mae: 0.0208 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0035 - mae: 0.0470 - val_loss: 0.0064 - val_mae: 0.0720 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0024 - mae: 0.0384 - val_loss: 0.0055 - val_mae: 0.0646 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0017 - mae: 0.0326 - val_loss: 0.0025 - val_mae: 0.0225 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0014 - mae: 0.0287 - val_loss: 0.0025 - val_mae: 0.0213 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 9.9388e-04 - mae: 0.0243 - val_loss: 0.0037 - val_mae: 0.0453 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 9.9669e-04 - mae: 0.0241 - val_loss: 0.0035 - val_mae: 0.0422 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 7.0315e-04 - mae: 0.0198 - val_loss: 0.0042 - val_mae: 0.0515 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 6.3485e-04 - mae: 0.0187 - val_loss: 0.0043 - val_mae: 0.0519 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 5.9826e-04 - mae: 0.0182 - val_loss: 0.0039 - val_mae: 0.0477 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 5.6064e-04 - mae: 0.0173 - val_loss: 0.0042 - val_mae: 0.0507 - learning_rate: 2.5000e-04\n",
      "\u001b[1m171/171\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step    \n",
      "âœ… Davangere - wheat | MAE=45.46, RMSE=81.0, RÂ²=0.9761, MAPE=2.31%, Acc=97.69%\n",
      "\n",
      "ğŸš€ Processing: Dharwad | capsicum\n",
      "Epoch 1/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 560ms/step - loss: 5.4834 - mae: 1.9202 - val_loss: 0.2482 - val_mae: 0.4889 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 3.0991 - mae: 1.6438 - val_loss: 0.7739 - val_mae: 0.8742 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 2.0225 - mae: 1.2838 - val_loss: 0.1422 - val_mae: 0.3640 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3717 - mae: 0.4982 - val_loss: 1.9293 - val_mae: 1.3857 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.8260 - mae: 0.7790 - val_loss: 2.4981 - val_mae: 1.5776 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.8559 - mae: 0.8013 - val_loss: 1.3102 - val_mae: 1.1404 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.3770 - mae: 0.4459 - val_loss: 0.6640 - val_mae: 0.8089 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.1936 - mae: 0.3166 - val_loss: 0.2395 - val_mae: 0.4795 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.1834 - mae: 0.3973 - val_loss: 0.0611 - val_mae: 0.2257 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.2235 - mae: 0.4383 - val_loss: 0.0210 - val_mae: 0.1311 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.2307 - mae: 0.4303 - val_loss: 0.0216 - val_mae: 0.1327 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.2009 - mae: 0.4086 - val_loss: 0.0444 - val_mae: 0.1882 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.1312 - mae: 0.3226 - val_loss: 0.0892 - val_mae: 0.2739 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.1150 - mae: 0.2807 - val_loss: 0.1072 - val_mae: 0.3036 - learning_rate: 2.5000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.1176 - mae: 0.2742 - val_loss: 0.1112 - val_mae: 0.3086 - learning_rate: 2.5000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.1088 - mae: 0.2524 - val_loss: 0.0979 - val_mae: 0.2844 - learning_rate: 2.5000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.1070 - mae: 0.2485 - val_loss: 0.0847 - val_mae: 0.2600 - learning_rate: 1.2500e-04\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 174ms/step\n",
      "âœ… Dharwad - capsicum | MAE=1334.74, RMSE=1556.7, RÂ²=-0.9123, MAPE=67.14%, Acc=32.86%\n",
      "\n",
      "ğŸš€ Processing: Dharwad | onion\n",
      "Epoch 1/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - loss: 0.0937 - mae: 0.1586 - val_loss: 0.0030 - val_mae: 0.0463 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0059 - mae: 0.0595 - val_loss: 0.0028 - val_mae: 0.0420 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0050 - mae: 0.0547 - val_loss: 0.0023 - val_mae: 0.0361 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0045 - mae: 0.0516 - val_loss: 0.0020 - val_mae: 0.0341 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0041 - mae: 0.0489 - val_loss: 0.0022 - val_mae: 0.0356 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0033 - mae: 0.0441 - val_loss: 0.0040 - val_mae: 0.0553 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0031 - mae: 0.0421 - val_loss: 0.0013 - val_mae: 0.0241 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0027 - mae: 0.0389 - val_loss: 0.0039 - val_mae: 0.0543 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0024 - mae: 0.0355 - val_loss: 0.0017 - val_mae: 0.0272 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0021 - mae: 0.0329 - val_loss: 0.0017 - val_mae: 0.0273 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0017 - mae: 0.0296 - val_loss: 0.0014 - val_mae: 0.0245 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0017 - mae: 0.0289 - val_loss: 0.0015 - val_mae: 0.0262 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0017 - mae: 0.0295 - val_loss: 0.0013 - val_mae: 0.0234 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0014 - mae: 0.0261 - val_loss: 0.0013 - val_mae: 0.0237 - learning_rate: 2.5000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0014 - mae: 0.0262 - val_loss: 0.0015 - val_mae: 0.0254 - learning_rate: 2.5000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0014 - mae: 0.0252 - val_loss: 0.0013 - val_mae: 0.0235 - learning_rate: 2.5000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0014 - mae: 0.0254 - val_loss: 0.0014 - val_mae: 0.0251 - learning_rate: 1.2500e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0014 - mae: 0.0254 - val_loss: 0.0013 - val_mae: 0.0233 - learning_rate: 1.2500e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0014 - mae: 0.0250 - val_loss: 0.0013 - val_mae: 0.0233 - learning_rate: 1.2500e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0014 - mae: 0.0246 - val_loss: 0.0013 - val_mae: 0.0234 - learning_rate: 6.2500e-05\n",
      "Epoch 21/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0013 - mae: 0.0244 - val_loss: 0.0013 - val_mae: 0.0229 - learning_rate: 6.2500e-05\n",
      "Epoch 22/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0247 - val_loss: 0.0013 - val_mae: 0.0235 - learning_rate: 6.2500e-05\n",
      "Epoch 23/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0013 - mae: 0.0242 - val_loss: 0.0013 - val_mae: 0.0227 - learning_rate: 3.1250e-05\n",
      "Epoch 24/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0013 - mae: 0.0239 - val_loss: 0.0013 - val_mae: 0.0231 - learning_rate: 3.1250e-05\n",
      "Epoch 25/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0013 - mae: 0.0240 - val_loss: 0.0013 - val_mae: 0.0228 - learning_rate: 3.1250e-05\n",
      "Epoch 26/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0013 - mae: 0.0235 - val_loss: 0.0013 - val_mae: 0.0240 - learning_rate: 1.5625e-05\n",
      "Epoch 27/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0013 - mae: 0.0240 - val_loss: 0.0013 - val_mae: 0.0237 - learning_rate: 1.5625e-05\n",
      "Epoch 28/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0013 - mae: 0.0236 - val_loss: 0.0014 - val_mae: 0.0255 - learning_rate: 1.5625e-05\n",
      "Epoch 29/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0013 - mae: 0.0236 - val_loss: 0.0013 - val_mae: 0.0242 - learning_rate: 7.8125e-06\n",
      "Epoch 30/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0012 - mae: 0.0237 - val_loss: 0.0013 - val_mae: 0.0242 - learning_rate: 7.8125e-06\n",
      "\u001b[1m171/171\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step    \n",
      "âœ… Dharwad - onion | MAE=153.73, RMSE=242.7, RÂ²=0.9, MAPE=13.26%, Acc=86.74%\n",
      "\n",
      "ğŸš€ Processing: Dharwad | tomato\n",
      "Epoch 1/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 60ms/step - loss: 0.1699 - mae: 0.3094 - val_loss: 0.0925 - val_mae: 0.2172 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0096 - mae: 0.0777 - val_loss: 0.0453 - val_mae: 0.1473 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0067 - mae: 0.0639 - val_loss: 0.0464 - val_mae: 0.1068 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0052 - mae: 0.0566 - val_loss: 0.0442 - val_mae: 0.1080 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0046 - mae: 0.0522 - val_loss: 0.0443 - val_mae: 0.0974 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0044 - mae: 0.0510 - val_loss: 0.0456 - val_mae: 0.1035 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0047 - mae: 0.0520 - val_loss: 0.0506 - val_mae: 0.0848 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0040 - mae: 0.0498 - val_loss: 0.0482 - val_mae: 0.1113 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0039 - mae: 0.0489 - val_loss: 0.0534 - val_mae: 0.0960 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0039 - mae: 0.0493 - val_loss: 0.0530 - val_mae: 0.1088 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0035 - mae: 0.0460 - val_loss: 0.0509 - val_mae: 0.1266 - learning_rate: 2.5000e-04\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step  \n",
      "âœ… Dharwad - tomato | MAE=361.44, RMSE=722.96, RÂ²=0.2046, MAPE=18.05%, Acc=81.95%\n",
      "\n",
      "ğŸš€ Processing: Dharwad | wheat\n",
      "Epoch 1/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 21ms/step - loss: 0.0479 - mae: 0.1321 - val_loss: 0.0279 - val_mae: 0.1414 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0051 - mae: 0.0569 - val_loss: 0.0069 - val_mae: 0.0595 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0039 - mae: 0.0499 - val_loss: 0.0060 - val_mae: 0.0555 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0031 - mae: 0.0442 - val_loss: 0.0072 - val_mae: 0.0647 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0024 - mae: 0.0389 - val_loss: 0.0066 - val_mae: 0.0621 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0019 - mae: 0.0339 - val_loss: 0.0074 - val_mae: 0.0702 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0017 - mae: 0.0316 - val_loss: 0.0055 - val_mae: 0.0540 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0014 - mae: 0.0286 - val_loss: 0.0054 - val_mae: 0.0514 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0014 - mae: 0.0283 - val_loss: 0.0055 - val_mae: 0.0554 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0013 - mae: 0.0273 - val_loss: 0.0055 - val_mae: 0.0563 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0011 - mae: 0.0246 - val_loss: 0.0053 - val_mae: 0.0514 - learning_rate: 2.5000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0011 - mae: 0.0249 - val_loss: 0.0053 - val_mae: 0.0515 - learning_rate: 2.5000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0010 - mae: 0.0241 - val_loss: 0.0053 - val_mae: 0.0522 - learning_rate: 2.5000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0010 - mae: 0.0238 - val_loss: 0.0052 - val_mae: 0.0521 - learning_rate: 2.5000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 9.3475e-04 - mae: 0.0227 - val_loss: 0.0053 - val_mae: 0.0514 - learning_rate: 1.2500e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 9.2108e-04 - mae: 0.0225 - val_loss: 0.0053 - val_mae: 0.0516 - learning_rate: 1.2500e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 9.2114e-04 - mae: 0.0226 - val_loss: 0.0053 - val_mae: 0.0517 - learning_rate: 1.2500e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 8.8923e-04 - mae: 0.0220 - val_loss: 0.0052 - val_mae: 0.0521 - learning_rate: 6.2500e-05\n",
      "Epoch 19/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 8.8596e-04 - mae: 0.0222 - val_loss: 0.0052 - val_mae: 0.0520 - learning_rate: 6.2500e-05\n",
      "Epoch 20/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 8.6029e-04 - mae: 0.0218 - val_loss: 0.0052 - val_mae: 0.0520 - learning_rate: 6.2500e-05\n",
      "Epoch 21/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 8.8000e-04 - mae: 0.0217 - val_loss: 0.0052 - val_mae: 0.0517 - learning_rate: 6.2500e-05\n",
      "Epoch 22/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 8.8403e-04 - mae: 0.0218 - val_loss: 0.0052 - val_mae: 0.0519 - learning_rate: 6.2500e-05\n",
      "Epoch 23/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 8.5569e-04 - mae: 0.0216 - val_loss: 0.0053 - val_mae: 0.0518 - learning_rate: 6.2500e-05\n",
      "Epoch 24/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 8.5328e-04 - mae: 0.0216 - val_loss: 0.0052 - val_mae: 0.0524 - learning_rate: 3.1250e-05\n",
      "Epoch 25/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 8.6823e-04 - mae: 0.0217 - val_loss: 0.0053 - val_mae: 0.0516 - learning_rate: 3.1250e-05\n",
      "Epoch 26/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 8.5734e-04 - mae: 0.0216 - val_loss: 0.0052 - val_mae: 0.0519 - learning_rate: 3.1250e-05\n",
      "Epoch 27/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 8.3378e-04 - mae: 0.0214 - val_loss: 0.0052 - val_mae: 0.0523 - learning_rate: 1.5625e-05\n",
      "Epoch 28/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 8.3902e-04 - mae: 0.0213 - val_loss: 0.0052 - val_mae: 0.0525 - learning_rate: 1.5625e-05\n",
      "Epoch 29/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 8.2353e-04 - mae: 0.0212 - val_loss: 0.0052 - val_mae: 0.0520 - learning_rate: 1.5625e-05\n",
      "\u001b[1m171/171\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step   \n",
      "âœ… Dharwad - wheat | MAE=77.55, RMSE=114.22, RÂ²=0.9404, MAPE=3.85%, Acc=96.15%\n",
      "\n",
      "ğŸš€ Processing: Gadag | onion\n",
      "Epoch 1/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 27ms/step - loss: 0.0565 - mae: 0.1351 - val_loss: 0.0037 - val_mae: 0.0449 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0066 - mae: 0.0614 - val_loss: 0.0019 - val_mae: 0.0217 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0050 - mae: 0.0538 - val_loss: 0.0018 - val_mae: 0.0288 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0042 - mae: 0.0484 - val_loss: 0.0017 - val_mae: 0.0333 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0039 - mae: 0.0472 - val_loss: 0.0101 - val_mae: 0.0949 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0037 - mae: 0.0446 - val_loss: 0.0062 - val_mae: 0.0737 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0029 - mae: 0.0392 - val_loss: 0.0012 - val_mae: 0.0250 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0024 - mae: 0.0350 - val_loss: 0.0019 - val_mae: 0.0373 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0025 - mae: 0.0359 - val_loss: 0.0018 - val_mae: 0.0362 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0025 - mae: 0.0347 - val_loss: 0.0017 - val_mae: 0.0350 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0022 - mae: 0.0327 - val_loss: 0.0016 - val_mae: 0.0323 - learning_rate: 2.5000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0022 - mae: 0.0321 - val_loss: 0.0014 - val_mae: 0.0289 - learning_rate: 2.5000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0021 - mae: 0.0315 - val_loss: 0.0012 - val_mae: 0.0235 - learning_rate: 2.5000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0020 - mae: 0.0303 - val_loss: 0.0014 - val_mae: 0.0291 - learning_rate: 1.2500e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0019 - mae: 0.0295 - val_loss: 0.0017 - val_mae: 0.0330 - learning_rate: 1.2500e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0020 - mae: 0.0302 - val_loss: 0.0016 - val_mae: 0.0321 - learning_rate: 1.2500e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0019 - mae: 0.0290 - val_loss: 0.0024 - val_mae: 0.0432 - learning_rate: 6.2500e-05\n",
      "Epoch 18/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0019 - mae: 0.0288 - val_loss: 0.0022 - val_mae: 0.0402 - learning_rate: 6.2500e-05\n",
      "Epoch 19/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0019 - mae: 0.0291 - val_loss: 0.0015 - val_mae: 0.0300 - learning_rate: 6.2500e-05\n",
      "Epoch 20/50\n",
      "\u001b[1m128/128\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0019 - mae: 0.0290 - val_loss: 0.0022 - val_mae: 0.0402 - learning_rate: 3.1250e-05\n",
      "\u001b[1m160/160\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step    \n",
      "âœ… Gadag - onion | MAE=92.36, RMSE=137.03, RÂ²=0.9542, MAPE=9.08%, Acc=90.92%\n",
      "\n",
      "ğŸš€ Processing: Gadag | tomato\n",
      "Epoch 1/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 46ms/step - loss: 0.0897 - mae: 0.2280 - val_loss: 0.0210 - val_mae: 0.1402 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0125 - mae: 0.0850 - val_loss: 0.0280 - val_mae: 0.1431 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0085 - mae: 0.0713 - val_loss: 0.0085 - val_mae: 0.0363 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0079 - mae: 0.0670 - val_loss: 0.0151 - val_mae: 0.0899 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0062 - mae: 0.0593 - val_loss: 0.0134 - val_mae: 0.0805 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0069 - mae: 0.0627 - val_loss: 0.0072 - val_mae: 0.0343 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0064 - mae: 0.0602 - val_loss: 0.0080 - val_mae: 0.0363 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0068 - mae: 0.0635 - val_loss: 0.0077 - val_mae: 0.0341 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0057 - mae: 0.0574 - val_loss: 0.0088 - val_mae: 0.0452 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0052 - mae: 0.0540 - val_loss: 0.0122 - val_mae: 0.0743 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0055 - mae: 0.0560 - val_loss: 0.0225 - val_mae: 0.1262 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0050 - mae: 0.0532 - val_loss: 0.0119 - val_mae: 0.0743 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0039 - mae: 0.0462 - val_loss: 0.0098 - val_mae: 0.0587 - learning_rate: 2.5000e-04\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step  \n",
      "âœ… Gadag - tomato | MAE=235.17, RMSE=486.07, RÂ²=0.9462, MAPE=6.73%, Acc=93.27%\n",
      "\n",
      "ğŸš€ Processing: Gadag | wheat\n",
      "Epoch 1/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 20ms/step - loss: 0.0729 - mae: 0.1404 - val_loss: 0.0183 - val_mae: 0.1205 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0048 - mae: 0.0546 - val_loss: 0.0068 - val_mae: 0.0710 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0031 - mae: 0.0434 - val_loss: 0.0031 - val_mae: 0.0446 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0022 - mae: 0.0357 - val_loss: 0.0020 - val_mae: 0.0348 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0017 - mae: 0.0309 - val_loss: 0.0037 - val_mae: 0.0487 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0014 - mae: 0.0277 - val_loss: 0.0038 - val_mae: 0.0493 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0012 - mae: 0.0251 - val_loss: 0.0032 - val_mae: 0.0442 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0010 - mae: 0.0227 - val_loss: 0.0033 - val_mae: 0.0454 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 9.5822e-04 - mae: 0.0217 - val_loss: 0.0035 - val_mae: 0.0465 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 9.0939e-04 - mae: 0.0211 - val_loss: 0.0034 - val_mae: 0.0457 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 8.7415e-04 - mae: 0.0203 - val_loss: 0.0039 - val_mae: 0.0492 - learning_rate: 2.5000e-04\n",
      "\u001b[1m170/170\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step   \n",
      "âœ… Gadag - wheat | MAE=111.91, RMSE=163.3, RÂ²=0.9075, MAPE=5.59%, Acc=94.41%\n",
      "\n",
      "ğŸš€ Processing: Hassan | capsicum\n",
      "Epoch 1/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - loss: 0.0311 - mae: 0.1052 - val_loss: 0.0104 - val_mae: 0.0801 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0047 - mae: 0.0534 - val_loss: 0.0075 - val_mae: 0.0660 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0037 - mae: 0.0477 - val_loss: 0.0087 - val_mae: 0.0754 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0026 - mae: 0.0385 - val_loss: 0.0102 - val_mae: 0.0841 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0021 - mae: 0.0347 - val_loss: 0.0073 - val_mae: 0.0673 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0018 - mae: 0.0307 - val_loss: 0.0113 - val_mae: 0.0918 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0016 - mae: 0.0286 - val_loss: 0.0097 - val_mae: 0.0835 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0015 - mae: 0.0286 - val_loss: 0.0064 - val_mae: 0.0608 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0013 - mae: 0.0253 - val_loss: 0.0059 - val_mae: 0.0585 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0012 - mae: 0.0238 - val_loss: 0.0047 - val_mae: 0.0531 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0012 - mae: 0.0249 - val_loss: 0.0051 - val_mae: 0.0565 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0011 - mae: 0.0231 - val_loss: 0.0042 - val_mae: 0.0498 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0011 - mae: 0.0228 - val_loss: 0.0058 - val_mae: 0.0604 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0012 - mae: 0.0249 - val_loss: 0.0052 - val_mae: 0.0574 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0012 - mae: 0.0241 - val_loss: 0.0053 - val_mae: 0.0590 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 8.7426e-04 - mae: 0.0190 - val_loss: 0.0046 - val_mae: 0.0517 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 8.3353e-04 - mae: 0.0184 - val_loss: 0.0051 - val_mae: 0.0554 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 8.6598e-04 - mae: 0.0194 - val_loss: 0.0051 - val_mae: 0.0544 - learning_rate: 5.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 7.4260e-04 - mae: 0.0170 - val_loss: 0.0036 - val_mae: 0.0442 - learning_rate: 2.5000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 7.2137e-04 - mae: 0.0168 - val_loss: 0.0035 - val_mae: 0.0438 - learning_rate: 2.5000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 7.3610e-04 - mae: 0.0168 - val_loss: 0.0038 - val_mae: 0.0467 - learning_rate: 2.5000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 7.3289e-04 - mae: 0.0171 - val_loss: 0.0038 - val_mae: 0.0465 - learning_rate: 2.5000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 7.0029e-04 - mae: 0.0165 - val_loss: 0.0036 - val_mae: 0.0445 - learning_rate: 1.2500e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 6.8001e-04 - mae: 0.0159 - val_loss: 0.0034 - val_mae: 0.0432 - learning_rate: 1.2500e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 6.9000e-04 - mae: 0.0161 - val_loss: 0.0035 - val_mae: 0.0447 - learning_rate: 1.2500e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 6.6408e-04 - mae: 0.0160 - val_loss: 0.0035 - val_mae: 0.0453 - learning_rate: 1.2500e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 6.6593e-04 - mae: 0.0157 - val_loss: 0.0035 - val_mae: 0.0449 - learning_rate: 1.2500e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 6.5162e-04 - mae: 0.0154 - val_loss: 0.0041 - val_mae: 0.0489 - learning_rate: 6.2500e-05\n",
      "Epoch 29/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6.4000e-04 - mae: 0.0153 - val_loss: 0.0037 - val_mae: 0.0463 - learning_rate: 6.2500e-05\n",
      "Epoch 30/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6.6272e-04 - mae: 0.0156 - val_loss: 0.0038 - val_mae: 0.0464 - learning_rate: 6.2500e-05\n",
      "Epoch 31/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 6.4335e-04 - mae: 0.0151 - val_loss: 0.0036 - val_mae: 0.0456 - learning_rate: 3.1250e-05\n",
      "\u001b[1m171/171\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step   \n",
      "âœ… Hassan - capsicum | MAE=160.05, RMSE=202.82, RÂ²=0.9479, MAPE=8.86%, Acc=91.14%\n",
      "\n",
      "ğŸš€ Processing: Hassan | onion\n",
      "Epoch 1/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 25ms/step - loss: 0.0584 - mae: 0.1426 - val_loss: 0.0025 - val_mae: 0.0307 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0054 - mae: 0.0571 - val_loss: 0.0028 - val_mae: 0.0391 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0042 - mae: 0.0506 - val_loss: 0.0087 - val_mae: 0.0842 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0035 - mae: 0.0462 - val_loss: 0.0023 - val_mae: 0.0312 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0029 - mae: 0.0413 - val_loss: 0.0025 - val_mae: 0.0334 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0022 - mae: 0.0354 - val_loss: 0.0029 - val_mae: 0.0390 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0020 - mae: 0.0338 - val_loss: 0.0024 - val_mae: 0.0329 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0017 - mae: 0.0307 - val_loss: 0.0024 - val_mae: 0.0331 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0017 - mae: 0.0309 - val_loss: 0.0023 - val_mae: 0.0309 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0014 - mae: 0.0273 - val_loss: 0.0024 - val_mae: 0.0319 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0014 - mae: 0.0271 - val_loss: 0.0023 - val_mae: 0.0312 - learning_rate: 2.5000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0013 - mae: 0.0260 - val_loss: 0.0022 - val_mae: 0.0302 - learning_rate: 2.5000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0013 - mae: 0.0261 - val_loss: 0.0024 - val_mae: 0.0342 - learning_rate: 2.5000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0013 - mae: 0.0267 - val_loss: 0.0023 - val_mae: 0.0337 - learning_rate: 2.5000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0013 - mae: 0.0259 - val_loss: 0.0022 - val_mae: 0.0322 - learning_rate: 2.5000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0012 - mae: 0.0248 - val_loss: 0.0021 - val_mae: 0.0302 - learning_rate: 1.2500e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0012 - mae: 0.0252 - val_loss: 0.0021 - val_mae: 0.0298 - learning_rate: 1.2500e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0012 - mae: 0.0245 - val_loss: 0.0020 - val_mae: 0.0292 - learning_rate: 1.2500e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0012 - mae: 0.0243 - val_loss: 0.0021 - val_mae: 0.0296 - learning_rate: 1.2500e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0011 - mae: 0.0244 - val_loss: 0.0020 - val_mae: 0.0290 - learning_rate: 1.2500e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0011 - mae: 0.0238 - val_loss: 0.0020 - val_mae: 0.0290 - learning_rate: 6.2500e-05\n",
      "Epoch 22/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0011 - mae: 0.0240 - val_loss: 0.0020 - val_mae: 0.0293 - learning_rate: 6.2500e-05\n",
      "Epoch 23/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0011 - mae: 0.0237 - val_loss: 0.0020 - val_mae: 0.0298 - learning_rate: 6.2500e-05\n",
      "Epoch 24/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0011 - mae: 0.0237 - val_loss: 0.0020 - val_mae: 0.0294 - learning_rate: 3.1250e-05\n",
      "Epoch 25/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0011 - mae: 0.0234 - val_loss: 0.0022 - val_mae: 0.0310 - learning_rate: 3.1250e-05\n",
      "Epoch 26/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0011 - mae: 0.0234 - val_loss: 0.0020 - val_mae: 0.0295 - learning_rate: 3.1250e-05\n",
      "Epoch 27/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0011 - mae: 0.0231 - val_loss: 0.0020 - val_mae: 0.0289 - learning_rate: 1.5625e-05\n",
      "Epoch 28/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0011 - mae: 0.0232 - val_loss: 0.0020 - val_mae: 0.0294 - learning_rate: 1.5625e-05\n",
      "Epoch 29/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0011 - mae: 0.0233 - val_loss: 0.0020 - val_mae: 0.0288 - learning_rate: 1.5625e-05\n",
      "Epoch 30/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0011 - mae: 0.0233 - val_loss: 0.0020 - val_mae: 0.0289 - learning_rate: 1.5625e-05\n",
      "Epoch 31/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0011 - mae: 0.0233 - val_loss: 0.0020 - val_mae: 0.0291 - learning_rate: 1.5625e-05\n",
      "Epoch 32/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0011 - mae: 0.0230 - val_loss: 0.0020 - val_mae: 0.0287 - learning_rate: 1.5625e-05\n",
      "Epoch 33/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0010 - mae: 0.0226 - val_loss: 0.0020 - val_mae: 0.0288 - learning_rate: 7.8125e-06\n",
      "Epoch 34/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0010 - mae: 0.0230 - val_loss: 0.0020 - val_mae: 0.0290 - learning_rate: 7.8125e-06\n",
      "Epoch 35/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0010 - mae: 0.0229 - val_loss: 0.0020 - val_mae: 0.0287 - learning_rate: 7.8125e-06\n",
      "Epoch 36/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0010 - mae: 0.0227 - val_loss: 0.0020 - val_mae: 0.0290 - learning_rate: 3.9063e-06\n",
      "Epoch 37/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0010 - mae: 0.0228 - val_loss: 0.0020 - val_mae: 0.0289 - learning_rate: 3.9063e-06\n",
      "Epoch 38/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 9.8471e-04 - mae: 0.0226 - val_loss: 0.0020 - val_mae: 0.0290 - learning_rate: 3.9063e-06\n",
      "Epoch 39/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0010 - mae: 0.0229 - val_loss: 0.0020 - val_mae: 0.0290 - learning_rate: 1.9531e-06\n",
      "Epoch 40/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0010 - mae: 0.0226 - val_loss: 0.0020 - val_mae: 0.0291 - learning_rate: 1.9531e-06\n",
      "Epoch 41/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0010 - mae: 0.0228 - val_loss: 0.0020 - val_mae: 0.0289 - learning_rate: 1.9531e-06\n",
      "Epoch 42/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0010 - mae: 0.0228 - val_loss: 0.0020 - val_mae: 0.0291 - learning_rate: 9.7656e-07\n",
      "\u001b[1m171/171\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step    \n",
      "âœ… Hassan - onion | MAE=108.92, RMSE=166.43, RÂ²=0.9345, MAPE=7.71%, Acc=92.29%\n",
      "\n",
      "ğŸš€ Processing: Hassan | tomato\n",
      "Epoch 1/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 20ms/step - loss: 0.0848 - mae: 0.1515 - val_loss: 0.0104 - val_mae: 0.0640 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0040 - mae: 0.0505 - val_loss: 0.0117 - val_mae: 0.0672 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0031 - mae: 0.0438 - val_loss: 0.0093 - val_mae: 0.0628 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0024 - mae: 0.0385 - val_loss: 0.0110 - val_mae: 0.0761 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0018 - mae: 0.0329 - val_loss: 0.0088 - val_mae: 0.0638 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0014 - mae: 0.0288 - val_loss: 0.0091 - val_mae: 0.0668 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0011 - mae: 0.0257 - val_loss: 0.0075 - val_mae: 0.0593 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 7.6032e-04 - mae: 0.0208 - val_loss: 0.0077 - val_mae: 0.0613 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 7.4180e-04 - mae: 0.0207 - val_loss: 0.0069 - val_mae: 0.0570 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 6.7100e-04 - mae: 0.0195 - val_loss: 0.0065 - val_mae: 0.0551 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 5.6382e-04 - mae: 0.0175 - val_loss: 0.0059 - val_mae: 0.0509 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 4.9793e-04 - mae: 0.0162 - val_loss: 0.0057 - val_mae: 0.0496 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 5.1079e-04 - mae: 0.0164 - val_loss: 0.0061 - val_mae: 0.0529 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 4.6749e-04 - mae: 0.0156 - val_loss: 0.0055 - val_mae: 0.0492 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 4.6746e-04 - mae: 0.0157 - val_loss: 0.0054 - val_mae: 0.0488 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 4.6293e-04 - mae: 0.0155 - val_loss: 0.0056 - val_mae: 0.0512 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 4.4001e-04 - mae: 0.0151 - val_loss: 0.0055 - val_mae: 0.0508 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 3.7685e-04 - mae: 0.0137 - val_loss: 0.0049 - val_mae: 0.0457 - learning_rate: 5.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 3.7772e-04 - mae: 0.0137 - val_loss: 0.0050 - val_mae: 0.0466 - learning_rate: 5.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 3.6917e-04 - mae: 0.0135 - val_loss: 0.0054 - val_mae: 0.0502 - learning_rate: 5.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 4.0082e-04 - mae: 0.0141 - val_loss: 0.0049 - val_mae: 0.0466 - learning_rate: 5.0000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 3.4024e-04 - mae: 0.0127 - val_loss: 0.0048 - val_mae: 0.0457 - learning_rate: 2.5000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 3.2692e-04 - mae: 0.0124 - val_loss: 0.0047 - val_mae: 0.0450 - learning_rate: 2.5000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 3.4009e-04 - mae: 0.0126 - val_loss: 0.0048 - val_mae: 0.0459 - learning_rate: 2.5000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 3.2333e-04 - mae: 0.0124 - val_loss: 0.0046 - val_mae: 0.0439 - learning_rate: 2.5000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 3.1511e-04 - mae: 0.0122 - val_loss: 0.0047 - val_mae: 0.0448 - learning_rate: 2.5000e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 3.2727e-04 - mae: 0.0124 - val_loss: 0.0046 - val_mae: 0.0443 - learning_rate: 2.5000e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 3.2830e-04 - mae: 0.0123 - val_loss: 0.0046 - val_mae: 0.0443 - learning_rate: 2.5000e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 3.1201e-04 - mae: 0.0119 - val_loss: 0.0048 - val_mae: 0.0461 - learning_rate: 1.2500e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 3.0931e-04 - mae: 0.0120 - val_loss: 0.0046 - val_mae: 0.0449 - learning_rate: 1.2500e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 3.1455e-04 - mae: 0.0120 - val_loss: 0.0046 - val_mae: 0.0446 - learning_rate: 1.2500e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 3.1157e-04 - mae: 0.0119 - val_loss: 0.0048 - val_mae: 0.0461 - learning_rate: 6.2500e-05\n",
      "\u001b[1m171/171\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step   \n",
      "âœ… Hassan - tomato | MAE=104.74, RMSE=206.46, RÂ²=0.933, MAPE=7.39%, Acc=92.61%\n",
      "\n",
      "ğŸš€ Processing: Hassan | wheat\n",
      "Epoch 1/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 19ms/step - loss: 0.0552 - mae: 0.1334 - val_loss: 0.0037 - val_mae: 0.0530 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0051 - mae: 0.0524 - val_loss: 0.0024 - val_mae: 0.0423 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0044 - mae: 0.0479 - val_loss: 0.0051 - val_mae: 0.0671 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0030 - mae: 0.0383 - val_loss: 0.0016 - val_mae: 0.0352 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0026 - mae: 0.0343 - val_loss: 0.0014 - val_mae: 0.0343 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0020 - mae: 0.0279 - val_loss: 0.0014 - val_mae: 0.0343 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0017 - mae: 0.0250 - val_loss: 0.0017 - val_mae: 0.0390 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0017 - mae: 0.0247 - val_loss: 4.5353e-04 - val_mae: 0.0177 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0015 - mae: 0.0220 - val_loss: 3.4157e-04 - val_mae: 0.0147 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0013 - mae: 0.0205 - val_loss: 6.8008e-04 - val_mae: 0.0232 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0014 - mae: 0.0216 - val_loss: 2.2359e-04 - val_mae: 0.0112 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0012 - mae: 0.0182 - val_loss: 1.8922e-04 - val_mae: 0.0102 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0012 - mae: 0.0198 - val_loss: 2.3827e-04 - val_mae: 0.0120 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0011 - mae: 0.0184 - val_loss: 1.9858e-04 - val_mae: 0.0107 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0010 - mae: 0.0170 - val_loss: 1.5975e-04 - val_mae: 0.0093 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 9.8393e-04 - mae: 0.0166 - val_loss: 1.6021e-04 - val_mae: 0.0095 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 8.9522e-04 - mae: 0.0158 - val_loss: 2.1343e-04 - val_mae: 0.0118 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 8.1212e-04 - mae: 0.0140 - val_loss: 2.9189e-04 - val_mae: 0.0150 - learning_rate: 2.5000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 7.8315e-04 - mae: 0.0140 - val_loss: 7.6917e-04 - val_mae: 0.0253 - learning_rate: 2.5000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 7.9353e-04 - mae: 0.0142 - val_loss: 8.0422e-04 - val_mae: 0.0256 - learning_rate: 2.5000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 7.3981e-04 - mae: 0.0134 - val_loss: 0.0012 - val_mae: 0.0307 - learning_rate: 1.2500e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 7.3988e-04 - mae: 0.0133 - val_loss: 0.0021 - val_mae: 0.0411 - learning_rate: 1.2500e-04\n",
      "\u001b[1m170/170\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step\n",
      "âœ… Hassan - wheat | MAE=65.53, RMSE=168.13, RÂ²=0.9281, MAPE=3.09%, Acc=96.91%\n",
      "\n",
      "ğŸš€ Processing: Haveri | capsicum\n",
      "âš ï¸ Not enough points for Haveri-capsicum. Using crop-level fallback.\n",
      "Epoch 1/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 20ms/step - loss: 0.0391 - mae: 0.1225 - val_loss: 0.0164 - val_mae: 0.1083 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0058 - mae: 0.0602 - val_loss: 0.0078 - val_mae: 0.0682 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0044 - mae: 0.0529 - val_loss: 0.0058 - val_mae: 0.0603 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0036 - mae: 0.0474 - val_loss: 0.0058 - val_mae: 0.0601 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0031 - mae: 0.0437 - val_loss: 0.0051 - val_mae: 0.0556 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0029 - mae: 0.0428 - val_loss: 0.0053 - val_mae: 0.0571 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0026 - mae: 0.0405 - val_loss: 0.0049 - val_mae: 0.0548 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0024 - mae: 0.0386 - val_loss: 0.0049 - val_mae: 0.0545 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0022 - mae: 0.0362 - val_loss: 0.0047 - val_mae: 0.0531 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0018 - mae: 0.0328 - val_loss: 0.0057 - val_mae: 0.0592 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0018 - mae: 0.0326 - val_loss: 0.0047 - val_mae: 0.0533 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0016 - mae: 0.0309 - val_loss: 0.0041 - val_mae: 0.0491 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0016 - mae: 0.0307 - val_loss: 0.0040 - val_mae: 0.0488 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0015 - mae: 0.0305 - val_loss: 0.0041 - val_mae: 0.0489 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0015 - mae: 0.0301 - val_loss: 0.0039 - val_mae: 0.0478 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0015 - mae: 0.0299 - val_loss: 0.0038 - val_mae: 0.0474 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0014 - mae: 0.0290 - val_loss: 0.0051 - val_mae: 0.0559 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0015 - mae: 0.0299 - val_loss: 0.0043 - val_mae: 0.0504 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0013 - mae: 0.0272 - val_loss: 0.0048 - val_mae: 0.0541 - learning_rate: 5.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0013 - mae: 0.0282 - val_loss: 0.0045 - val_mae: 0.0526 - learning_rate: 5.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0013 - mae: 0.0283 - val_loss: 0.0039 - val_mae: 0.0479 - learning_rate: 5.0000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0011 - mae: 0.0244 - val_loss: 0.0037 - val_mae: 0.0463 - learning_rate: 2.5000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 9.7227e-04 - mae: 0.0236 - val_loss: 0.0038 - val_mae: 0.0473 - learning_rate: 2.5000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0010 - mae: 0.0241 - val_loss: 0.0041 - val_mae: 0.0492 - learning_rate: 2.5000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0010 - mae: 0.0242 - val_loss: 0.0037 - val_mae: 0.0466 - learning_rate: 2.5000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 9.8171e-04 - mae: 0.0234 - val_loss: 0.0037 - val_mae: 0.0461 - learning_rate: 1.2500e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 9.8041e-04 - mae: 0.0237 - val_loss: 0.0037 - val_mae: 0.0464 - learning_rate: 1.2500e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 9.5075e-04 - mae: 0.0232 - val_loss: 0.0038 - val_mae: 0.0472 - learning_rate: 1.2500e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 9.3811e-04 - mae: 0.0232 - val_loss: 0.0039 - val_mae: 0.0481 - learning_rate: 6.2500e-05\n",
      "Epoch 30/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 9.5808e-04 - mae: 0.0235 - val_loss: 0.0037 - val_mae: 0.0464 - learning_rate: 6.2500e-05\n",
      "Epoch 31/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 9.2975e-04 - mae: 0.0230 - val_loss: 0.0037 - val_mae: 0.0462 - learning_rate: 6.2500e-05\n",
      "Epoch 32/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 9.1883e-04 - mae: 0.0228 - val_loss: 0.0039 - val_mae: 0.0482 - learning_rate: 3.1250e-05\n",
      "Epoch 33/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 9.2616e-04 - mae: 0.0228 - val_loss: 0.0039 - val_mae: 0.0480 - learning_rate: 3.1250e-05\n",
      "Epoch 34/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 9.3262e-04 - mae: 0.0228 - val_loss: 0.0038 - val_mae: 0.0471 - learning_rate: 3.1250e-05\n",
      "Epoch 35/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 9.0379e-04 - mae: 0.0225 - val_loss: 0.0040 - val_mae: 0.0486 - learning_rate: 1.5625e-05\n",
      "Epoch 36/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 9.0734e-04 - mae: 0.0226 - val_loss: 0.0038 - val_mae: 0.0474 - learning_rate: 1.5625e-05\n",
      "Epoch 37/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 9.1937e-04 - mae: 0.0227 - val_loss: 0.0039 - val_mae: 0.0484 - learning_rate: 1.5625e-05\n",
      "Epoch 38/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 8.9869e-04 - mae: 0.0224 - val_loss: 0.0038 - val_mae: 0.0473 - learning_rate: 7.8125e-06\n",
      "\u001b[1m171/171\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step    \n",
      "âœ… Haveri - capsicum | MAE=126.38, RMSE=172.27, RÂ²=0.9434, MAPE=5.02%, Acc=94.98%\n",
      "\n",
      "ğŸš€ Processing: Haveri | onion\n",
      "Epoch 1/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 21ms/step - loss: 0.1263 - mae: 0.1923 - val_loss: 0.0044 - val_mae: 0.0469 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0087 - mae: 0.0721 - val_loss: 0.0024 - val_mae: 0.0320 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0074 - mae: 0.0666 - val_loss: 0.0052 - val_mae: 0.0598 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0064 - mae: 0.0610 - val_loss: 0.0042 - val_mae: 0.0533 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0050 - mae: 0.0532 - val_loss: 0.0017 - val_mae: 0.0271 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0047 - mae: 0.0523 - val_loss: 0.0017 - val_mae: 0.0294 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0038 - mae: 0.0458 - val_loss: 0.0020 - val_mae: 0.0344 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0039 - mae: 0.0463 - val_loss: 0.0017 - val_mae: 0.0285 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0028 - mae: 0.0380 - val_loss: 0.0016 - val_mae: 0.0286 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0026 - mae: 0.0359 - val_loss: 0.0016 - val_mae: 0.0279 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0026 - mae: 0.0361 - val_loss: 0.0017 - val_mae: 0.0293 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0023 - mae: 0.0337 - val_loss: 0.0015 - val_mae: 0.0267 - learning_rate: 2.5000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0023 - mae: 0.0328 - val_loss: 0.0016 - val_mae: 0.0279 - learning_rate: 2.5000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0024 - mae: 0.0336 - val_loss: 0.0016 - val_mae: 0.0295 - learning_rate: 2.5000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0023 - mae: 0.0324 - val_loss: 0.0014 - val_mae: 0.0254 - learning_rate: 2.5000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0021 - mae: 0.0314 - val_loss: 0.0017 - val_mae: 0.0308 - learning_rate: 1.2500e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0020 - mae: 0.0310 - val_loss: 0.0016 - val_mae: 0.0292 - learning_rate: 1.2500e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0020 - mae: 0.0311 - val_loss: 0.0015 - val_mae: 0.0280 - learning_rate: 1.2500e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0019 - mae: 0.0299 - val_loss: 0.0018 - val_mae: 0.0329 - learning_rate: 6.2500e-05\n",
      "Epoch 20/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0020 - mae: 0.0301 - val_loss: 0.0022 - val_mae: 0.0377 - learning_rate: 6.2500e-05\n",
      "Epoch 21/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0019 - mae: 0.0297 - val_loss: 0.0019 - val_mae: 0.0346 - learning_rate: 6.2500e-05\n",
      "Epoch 22/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0019 - mae: 0.0295 - val_loss: 0.0020 - val_mae: 0.0350 - learning_rate: 3.1250e-05\n",
      "\u001b[1m152/152\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step    \n",
      "âœ… Haveri - onion | MAE=85.77, RMSE=146.28, RÂ²=0.9427, MAPE=5.78%, Acc=94.22%\n",
      "\n",
      "ğŸš€ Processing: Haveri | tomato\n",
      "Epoch 1/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 44ms/step - loss: 0.1136 - mae: 0.2531 - val_loss: 0.2899 - val_mae: 0.4804 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0079 - mae: 0.0702 - val_loss: 0.0307 - val_mae: 0.1305 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0056 - mae: 0.0589 - val_loss: 0.0334 - val_mae: 0.1303 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0045 - mae: 0.0532 - val_loss: 0.0303 - val_mae: 0.1179 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0046 - mae: 0.0540 - val_loss: 0.0300 - val_mae: 0.1086 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0037 - mae: 0.0481 - val_loss: 0.0299 - val_mae: 0.1218 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0037 - mae: 0.0478 - val_loss: 0.0282 - val_mae: 0.1412 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0038 - mae: 0.0493 - val_loss: 0.0282 - val_mae: 0.1201 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0033 - mae: 0.0460 - val_loss: 0.0258 - val_mae: 0.1064 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0027 - mae: 0.0415 - val_loss: 0.0302 - val_mae: 0.1251 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0022 - mae: 0.0373 - val_loss: 0.0226 - val_mae: 0.0799 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0019 - mae: 0.0347 - val_loss: 0.0220 - val_mae: 0.0793 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0021 - mae: 0.0365 - val_loss: 0.0198 - val_mae: 0.0774 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0016 - mae: 0.0319 - val_loss: 0.0185 - val_mae: 0.0778 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0017 - mae: 0.0324 - val_loss: 0.0215 - val_mae: 0.0766 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0012 - mae: 0.0278 - val_loss: 0.0199 - val_mae: 0.0810 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0011 - mae: 0.0269 - val_loss: 0.0255 - val_mae: 0.1014 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0011 - mae: 0.0261 - val_loss: 0.0194 - val_mae: 0.0730 - learning_rate: 5.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 9.2887e-04 - mae: 0.0241 - val_loss: 0.0189 - val_mae: 0.0728 - learning_rate: 5.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 9.2702e-04 - mae: 0.0243 - val_loss: 0.0180 - val_mae: 0.0704 - learning_rate: 5.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 8.6005e-04 - mae: 0.0230 - val_loss: 0.0176 - val_mae: 0.0713 - learning_rate: 5.0000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 8.2465e-04 - mae: 0.0225 - val_loss: 0.0175 - val_mae: 0.0747 - learning_rate: 5.0000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 8.2975e-04 - mae: 0.0231 - val_loss: 0.0190 - val_mae: 0.0796 - learning_rate: 5.0000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 6.3061e-04 - mae: 0.0200 - val_loss: 0.0178 - val_mae: 0.0720 - learning_rate: 5.0000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 6.8763e-04 - mae: 0.0208 - val_loss: 0.0193 - val_mae: 0.0829 - learning_rate: 2.5000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 6.8860e-04 - mae: 0.0213 - val_loss: 0.0169 - val_mae: 0.0688 - learning_rate: 2.5000e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 7.3745e-04 - mae: 0.0216 - val_loss: 0.0176 - val_mae: 0.0687 - learning_rate: 2.5000e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 7.2472e-04 - mae: 0.0213 - val_loss: 0.0179 - val_mae: 0.0698 - learning_rate: 2.5000e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 6.4465e-04 - mae: 0.0205 - val_loss: 0.0180 - val_mae: 0.0697 - learning_rate: 2.5000e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 5.5796e-04 - mae: 0.0187 - val_loss: 0.0193 - val_mae: 0.0806 - learning_rate: 1.2500e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 5.9307e-04 - mae: 0.0194 - val_loss: 0.0174 - val_mae: 0.0750 - learning_rate: 1.2500e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 6.5792e-04 - mae: 0.0203 - val_loss: 0.0194 - val_mae: 0.0879 - learning_rate: 1.2500e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 5.8519e-04 - mae: 0.0194 - val_loss: 0.0179 - val_mae: 0.0758 - learning_rate: 6.2500e-05\n",
      "\u001b[1m46/46\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step  \n",
      "âœ… Haveri - tomato | MAE=230.15, RMSE=492.24, RÂ²=0.956, MAPE=14.03%, Acc=85.97%\n",
      "\n",
      "ğŸš€ Processing: Haveri | wheat\n",
      "Epoch 1/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 18ms/step - loss: 0.0539 - mae: 0.1299 - val_loss: 9.1177e-04 - val_mae: 0.0147 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0031 - mae: 0.0442 - val_loss: 0.0019 - val_mae: 0.0377 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0024 - mae: 0.0385 - val_loss: 0.0020 - val_mae: 0.0365 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0019 - mae: 0.0340 - val_loss: 0.0021 - val_mae: 0.0355 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0015 - mae: 0.0307 - val_loss: 0.0023 - val_mae: 0.0412 - learning_rate: 5.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0012 - mae: 0.0267 - val_loss: 0.0027 - val_mae: 0.0474 - learning_rate: 5.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0011 - mae: 0.0264 - val_loss: 0.0018 - val_mae: 0.0334 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0010 - mae: 0.0248 - val_loss: 0.0019 - val_mae: 0.0343 - learning_rate: 2.5000e-04\n",
      "\u001b[1m166/166\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step   \n",
      "âœ… Haveri - wheat | MAE=32.22, RMSE=47.56, RÂ²=0.9823, MAPE=1.81%, Acc=98.19%\n",
      "\n",
      "ğŸš€ Processing: Kalburgi | capsicum\n",
      "Epoch 1/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 0.3141 - mae: 0.4036 - val_loss: 0.0710 - val_mae: 0.2373 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0263 - mae: 0.1266 - val_loss: 0.0139 - val_mae: 0.0696 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0167 - mae: 0.0997 - val_loss: 0.0116 - val_mae: 0.0674 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0124 - mae: 0.0864 - val_loss: 0.0104 - val_mae: 0.0691 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0117 - mae: 0.0829 - val_loss: 0.0109 - val_mae: 0.0722 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0123 - mae: 0.0849 - val_loss: 0.0094 - val_mae: 0.0673 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0124 - mae: 0.0867 - val_loss: 0.0151 - val_mae: 0.0930 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0116 - mae: 0.0833 - val_loss: 0.0115 - val_mae: 0.0784 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0094 - mae: 0.0747 - val_loss: 0.0087 - val_mae: 0.0658 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0097 - mae: 0.0743 - val_loss: 0.0071 - val_mae: 0.0617 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0091 - mae: 0.0709 - val_loss: 0.0074 - val_mae: 0.0648 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0088 - mae: 0.0704 - val_loss: 0.0100 - val_mae: 0.0765 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0109 - mae: 0.0812 - val_loss: 0.0149 - val_mae: 0.0975 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0090 - mae: 0.0707 - val_loss: 0.0077 - val_mae: 0.0724 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0082 - mae: 0.0679 - val_loss: 0.0095 - val_mae: 0.0732 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0085 - mae: 0.0702 - val_loss: 0.0094 - val_mae: 0.0716 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m29/29\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0080 - mae: 0.0680 - val_loss: 0.0072 - val_mae: 0.0647 - learning_rate: 2.5000e-04\n",
      "\u001b[1m36/36\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step  \n",
      "âœ… Kalburgi - capsicum | MAE=416.15, RMSE=562.78, RÂ²=0.7854, MAPE=20.32%, Acc=79.68%\n",
      "\n",
      "ğŸš€ Processing: Kalburgi | onion\n",
      "Epoch 1/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - loss: 0.2196 - mae: 0.3398 - val_loss: 0.0341 - val_mae: 0.1762 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0150 - mae: 0.0936 - val_loss: 0.0026 - val_mae: 0.0413 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0109 - mae: 0.0794 - val_loss: 0.0027 - val_mae: 0.0413 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0095 - mae: 0.0730 - val_loss: 0.0034 - val_mae: 0.0476 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0094 - mae: 0.0708 - val_loss: 0.0032 - val_mae: 0.0417 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0086 - mae: 0.0689 - val_loss: 0.0035 - val_mae: 0.0427 - learning_rate: 5.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0078 - mae: 0.0646 - val_loss: 0.0026 - val_mae: 0.0368 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0078 - mae: 0.0649 - val_loss: 0.0026 - val_mae: 0.0369 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0076 - mae: 0.0654 - val_loss: 0.0029 - val_mae: 0.0413 - learning_rate: 2.5000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0077 - mae: 0.0650 - val_loss: 0.0027 - val_mae: 0.0424 - learning_rate: 2.5000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0077 - mae: 0.0656 - val_loss: 0.0028 - val_mae: 0.0377 - learning_rate: 2.5000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0075 - mae: 0.0636 - val_loss: 0.0027 - val_mae: 0.0407 - learning_rate: 1.2500e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0072 - mae: 0.0616 - val_loss: 0.0027 - val_mae: 0.0397 - learning_rate: 1.2500e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0080 - mae: 0.0663 - val_loss: 0.0029 - val_mae: 0.0408 - learning_rate: 1.2500e-04\n",
      "\u001b[1m38/38\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step \n",
      "âœ… Kalburgi - onion | MAE=292.64, RMSE=421.51, RÂ²=0.6515, MAPE=20.39%, Acc=79.61%\n",
      "\n",
      "ğŸš€ Processing: Kalburgi | tomato\n",
      "Epoch 1/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - loss: 0.3860 - mae: 0.4539 - val_loss: 0.0103 - val_mae: 0.0899 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0283 - mae: 0.1305 - val_loss: 0.0097 - val_mae: 0.0835 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0179 - mae: 0.1004 - val_loss: 0.0069 - val_mae: 0.0632 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0171 - mae: 0.0994 - val_loss: 0.0072 - val_mae: 0.0642 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0174 - mae: 0.0998 - val_loss: 0.0052 - val_mae: 0.0549 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0160 - mae: 0.0960 - val_loss: 0.0039 - val_mae: 0.0514 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0153 - mae: 0.0935 - val_loss: 0.0041 - val_mae: 0.0526 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0155 - mae: 0.0940 - val_loss: 0.0055 - val_mae: 0.0627 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0147 - mae: 0.0922 - val_loss: 0.0033 - val_mae: 0.0452 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0137 - mae: 0.0878 - val_loss: 0.0054 - val_mae: 0.0571 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0128 - mae: 0.0846 - val_loss: 0.0029 - val_mae: 0.0423 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0137 - mae: 0.0884 - val_loss: 0.0026 - val_mae: 0.0397 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0127 - mae: 0.0837 - val_loss: 0.0052 - val_mae: 0.0567 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0122 - mae: 0.0818 - val_loss: 0.0031 - val_mae: 0.0436 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0134 - mae: 0.0858 - val_loss: 0.0043 - val_mae: 0.0507 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0130 - mae: 0.0837 - val_loss: 0.0052 - val_mae: 0.0557 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0116 - mae: 0.0787 - val_loss: 0.0054 - val_mae: 0.0574 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0109 - mae: 0.0755 - val_loss: 0.0042 - val_mae: 0.0494 - learning_rate: 5.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m31/31\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0116 - mae: 0.0799 - val_loss: 0.0046 - val_mae: 0.0523 - learning_rate: 2.5000e-04\n",
      "\u001b[1m39/39\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step \n",
      "âœ… Kalburgi - tomato | MAE=580.31, RMSE=858.48, RÂ²=0.7667, MAPE=43.06%, Acc=56.94%\n",
      "\n",
      "ğŸš€ Processing: Kalburgi | wheat\n",
      "Epoch 1/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - loss: 0.1213 - mae: 0.1811 - val_loss: 0.0085 - val_mae: 0.0387 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0057 - mae: 0.0597 - val_loss: 0.0062 - val_mae: 0.0368 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0045 - mae: 0.0530 - val_loss: 0.0072 - val_mae: 0.0605 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0036 - mae: 0.0471 - val_loss: 0.0083 - val_mae: 0.0736 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0024 - mae: 0.0382 - val_loss: 0.0076 - val_mae: 0.0665 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0019 - mae: 0.0335 - val_loss: 0.0061 - val_mae: 0.0443 - learning_rate: 5.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0016 - mae: 0.0310 - val_loss: 0.0060 - val_mae: 0.0418 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0014 - mae: 0.0287 - val_loss: 0.0057 - val_mae: 0.0315 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0012 - mae: 0.0263 - val_loss: 0.0058 - val_mae: 0.0311 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0011 - mae: 0.0249 - val_loss: 0.0058 - val_mae: 0.0332 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 9.5488e-04 - mae: 0.0234 - val_loss: 0.0067 - val_mae: 0.0580 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 8.3037e-04 - mae: 0.0212 - val_loss: 0.0057 - val_mae: 0.0306 - learning_rate: 2.5000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 7.6838e-04 - mae: 0.0204 - val_loss: 0.0058 - val_mae: 0.0284 - learning_rate: 2.5000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 7.4373e-04 - mae: 0.0199 - val_loss: 0.0056 - val_mae: 0.0290 - learning_rate: 2.5000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 7.0725e-04 - mae: 0.0194 - val_loss: 0.0061 - val_mae: 0.0294 - learning_rate: 2.5000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 7.1006e-04 - mae: 0.0193 - val_loss: 0.0055 - val_mae: 0.0298 - learning_rate: 2.5000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 6.2243e-04 - mae: 0.0181 - val_loss: 0.0055 - val_mae: 0.0272 - learning_rate: 2.5000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6.1610e-04 - mae: 0.0175 - val_loss: 0.0056 - val_mae: 0.0267 - learning_rate: 1.2500e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 5.9951e-04 - mae: 0.0173 - val_loss: 0.0057 - val_mae: 0.0271 - learning_rate: 1.2500e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 5.7340e-04 - mae: 0.0170 - val_loss: 0.0056 - val_mae: 0.0264 - learning_rate: 1.2500e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 5.7595e-04 - mae: 0.0168 - val_loss: 0.0056 - val_mae: 0.0272 - learning_rate: 6.2500e-05\n",
      "Epoch 22/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 5.5437e-04 - mae: 0.0167 - val_loss: 0.0056 - val_mae: 0.0261 - learning_rate: 6.2500e-05\n",
      "Epoch 23/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 5.7685e-04 - mae: 0.0167 - val_loss: 0.0056 - val_mae: 0.0268 - learning_rate: 6.2500e-05\n",
      "\u001b[1m167/167\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step    \n",
      "âœ… Kalburgi - wheat | MAE=39.95, RMSE=114.36, RÂ²=0.9302, MAPE=1.51%, Acc=98.49%\n",
      "\n",
      "ğŸš€ Processing: Karwar(Uttar Kannad) | onion\n",
      "Epoch 1/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 38ms/step - loss: 0.5813 - mae: 0.4990 - val_loss: 0.2218 - val_mae: 0.4270 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0234 - mae: 0.1158 - val_loss: 0.0532 - val_mae: 0.1790 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0131 - mae: 0.0867 - val_loss: 0.0339 - val_mae: 0.1165 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0102 - mae: 0.0766 - val_loss: 0.0248 - val_mae: 0.0877 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0088 - mae: 0.0706 - val_loss: 0.0201 - val_mae: 0.0765 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0076 - mae: 0.0666 - val_loss: 0.0165 - val_mae: 0.0705 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0067 - mae: 0.0639 - val_loss: 0.0110 - val_mae: 0.0515 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0058 - mae: 0.0596 - val_loss: 0.0132 - val_mae: 0.0677 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0058 - mae: 0.0587 - val_loss: 0.0100 - val_mae: 0.0520 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0051 - mae: 0.0564 - val_loss: 0.0092 - val_mae: 0.0442 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0053 - mae: 0.0574 - val_loss: 0.0081 - val_mae: 0.0391 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0050 - mae: 0.0565 - val_loss: 0.0084 - val_mae: 0.0418 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0044 - mae: 0.0520 - val_loss: 0.0077 - val_mae: 0.0393 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0049 - mae: 0.0544 - val_loss: 0.0110 - val_mae: 0.0638 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0047 - mae: 0.0541 - val_loss: 0.0112 - val_mae: 0.0642 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0044 - mae: 0.0517 - val_loss: 0.0098 - val_mae: 0.0540 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0039 - mae: 0.0487 - val_loss: 0.0086 - val_mae: 0.0447 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0034 - mae: 0.0454 - val_loss: 0.0112 - val_mae: 0.0641 - learning_rate: 5.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0038 - mae: 0.0481 - val_loss: 0.0084 - val_mae: 0.0448 - learning_rate: 5.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m45/45\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0035 - mae: 0.0459 - val_loss: 0.0094 - val_mae: 0.0525 - learning_rate: 2.5000e-04\n",
      "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step  \n",
      "âœ… Karwar(Uttar Kannad) - onion | MAE=85.95, RMSE=175.88, RÂ²=0.9799, MAPE=8.4%, Acc=91.6%\n",
      "\n",
      "ğŸš€ Processing: Karwar(Uttar Kannad) | tomato\n",
      "Epoch 1/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 66ms/step - loss: 0.3489 - mae: 0.4668 - val_loss: 0.0882 - val_mae: 0.2423 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0348 - mae: 0.1505 - val_loss: 0.0654 - val_mae: 0.2051 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0130 - mae: 0.0881 - val_loss: 0.0430 - val_mae: 0.1518 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0118 - mae: 0.0816 - val_loss: 0.0373 - val_mae: 0.1396 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0095 - mae: 0.0738 - val_loss: 0.0379 - val_mae: 0.1434 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0091 - mae: 0.0728 - val_loss: 0.0324 - val_mae: 0.1306 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0094 - mae: 0.0745 - val_loss: 0.0294 - val_mae: 0.1224 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0075 - mae: 0.0662 - val_loss: 0.0222 - val_mae: 0.1056 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0075 - mae: 0.0670 - val_loss: 0.0144 - val_mae: 0.0910 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0075 - mae: 0.0691 - val_loss: 0.0216 - val_mae: 0.1064 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0064 - mae: 0.0617 - val_loss: 0.0156 - val_mae: 0.0938 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0061 - mae: 0.0611 - val_loss: 0.0160 - val_mae: 0.0915 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0058 - mae: 0.0582 - val_loss: 0.0142 - val_mae: 0.0889 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0064 - mae: 0.0612 - val_loss: 0.0141 - val_mae: 0.0886 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0060 - mae: 0.0597 - val_loss: 0.0153 - val_mae: 0.0909 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0059 - mae: 0.0594 - val_loss: 0.0138 - val_mae: 0.0884 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0053 - mae: 0.0556 - val_loss: 0.0134 - val_mae: 0.0890 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0053 - mae: 0.0557 - val_loss: 0.0143 - val_mae: 0.0886 - learning_rate: 5.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0051 - mae: 0.0552 - val_loss: 0.0134 - val_mae: 0.0873 - learning_rate: 5.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0053 - mae: 0.0561 - val_loss: 0.0142 - val_mae: 0.0876 - learning_rate: 5.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0053 - mae: 0.0546 - val_loss: 0.0142 - val_mae: 0.0873 - learning_rate: 2.5000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0052 - mae: 0.0559 - val_loss: 0.0136 - val_mae: 0.0862 - learning_rate: 2.5000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0054 - mae: 0.0572 - val_loss: 0.0131 - val_mae: 0.0860 - learning_rate: 2.5000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0053 - mae: 0.0572 - val_loss: 0.0127 - val_mae: 0.0873 - learning_rate: 2.5000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0052 - mae: 0.0549 - val_loss: 0.0127 - val_mae: 0.0867 - learning_rate: 2.5000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0051 - mae: 0.0548 - val_loss: 0.0127 - val_mae: 0.0865 - learning_rate: 2.5000e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0056 - mae: 0.0580 - val_loss: 0.0126 - val_mae: 0.0866 - learning_rate: 2.5000e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0051 - mae: 0.0534 - val_loss: 0.0126 - val_mae: 0.0856 - learning_rate: 2.5000e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0056 - mae: 0.0570 - val_loss: 0.0129 - val_mae: 0.0850 - learning_rate: 2.5000e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0051 - mae: 0.0551 - val_loss: 0.0124 - val_mae: 0.0861 - learning_rate: 2.5000e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0054 - mae: 0.0566 - val_loss: 0.0125 - val_mae: 0.0868 - learning_rate: 2.5000e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0053 - mae: 0.0548 - val_loss: 0.0124 - val_mae: 0.0854 - learning_rate: 2.5000e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0049 - mae: 0.0533 - val_loss: 0.0135 - val_mae: 0.0851 - learning_rate: 2.5000e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0047 - mae: 0.0515 - val_loss: 0.0130 - val_mae: 0.0843 - learning_rate: 1.2500e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0052 - mae: 0.0551 - val_loss: 0.0129 - val_mae: 0.0841 - learning_rate: 1.2500e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0044 - mae: 0.0501 - val_loss: 0.0128 - val_mae: 0.0841 - learning_rate: 1.2500e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0048 - mae: 0.0527 - val_loss: 0.0134 - val_mae: 0.0849 - learning_rate: 6.2500e-05\n",
      "\u001b[1m18/18\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step \n",
      "âœ… Karwar(Uttar Kannad) - tomato | MAE=240.14, RMSE=331.34, RÂ²=0.8149, MAPE=23.55%, Acc=76.45%\n",
      "\n",
      "ğŸš€ Processing: Karwar(Uttar Kannad) | wheat\n",
      "Epoch 1/50\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 43ms/step - loss: 0.4260 - mae: 0.4610 - val_loss: 8.3429e-04 - val_mae: 0.0052 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0187 - mae: 0.1090 - val_loss: 8.2180e-04 - val_mae: 0.0039 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0116 - mae: 0.0833 - val_loss: 8.1147e-04 - val_mae: 0.0021 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0109 - mae: 0.0813 - val_loss: 8.7336e-04 - val_mae: 0.0115 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0093 - mae: 0.0752 - val_loss: 0.0014 - val_mae: 0.0275 - learning_rate: 5.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0095 - mae: 0.0759 - val_loss: 0.0027 - val_mae: 0.0465 - learning_rate: 5.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0085 - mae: 0.0711 - val_loss: 0.0021 - val_mae: 0.0395 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0081 - mae: 0.0710 - val_loss: 0.0021 - val_mae: 0.0389 - learning_rate: 2.5000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0073 - mae: 0.0674 - val_loss: 0.0026 - val_mae: 0.0454 - learning_rate: 2.5000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0072 - mae: 0.0668 - val_loss: 0.0031 - val_mae: 0.0509 - learning_rate: 2.5000e-04\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step  \n",
      "âœ… Karwar(Uttar Kannad) - wheat | MAE=44.15, RMSE=81.04, RÂ²=0.7082, MAPE=2.99%, Acc=97.01%\n",
      "\n",
      "ğŸš€ Processing: Kolar | capsicum\n",
      "Epoch 1/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - loss: 0.0542 - mae: 0.1350 - val_loss: 0.0072 - val_mae: 0.0676 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0053 - mae: 0.0549 - val_loss: 0.0066 - val_mae: 0.0631 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0045 - mae: 0.0508 - val_loss: 0.0081 - val_mae: 0.0720 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0043 - mae: 0.0499 - val_loss: 0.0076 - val_mae: 0.0699 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0038 - mae: 0.0462 - val_loss: 0.0107 - val_mae: 0.0862 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0034 - mae: 0.0430 - val_loss: 0.0054 - val_mae: 0.0570 - learning_rate: 5.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0032 - mae: 0.0423 - val_loss: 0.0061 - val_mae: 0.0618 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0031 - mae: 0.0416 - val_loss: 0.0073 - val_mae: 0.0697 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0030 - mae: 0.0401 - val_loss: 0.0045 - val_mae: 0.0512 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0031 - mae: 0.0412 - val_loss: 0.0054 - val_mae: 0.0578 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0030 - mae: 0.0405 - val_loss: 0.0062 - val_mae: 0.0638 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0028 - mae: 0.0389 - val_loss: 0.0050 - val_mae: 0.0558 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0025 - mae: 0.0365 - val_loss: 0.0050 - val_mae: 0.0558 - learning_rate: 2.5000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0025 - mae: 0.0362 - val_loss: 0.0054 - val_mae: 0.0593 - learning_rate: 2.5000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0024 - mae: 0.0354 - val_loss: 0.0055 - val_mae: 0.0595 - learning_rate: 2.5000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0023 - mae: 0.0351 - val_loss: 0.0051 - val_mae: 0.0572 - learning_rate: 1.2500e-04\n",
      "\u001b[1m171/171\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step\n",
      "âœ… Kolar - capsicum | MAE=186.45, RMSE=261.56, RÂ²=0.9277, MAPE=8.05%, Acc=91.95%\n",
      "\n",
      "ğŸš€ Processing: Kolar | onion\n",
      "Epoch 1/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 15ms/step - loss: 0.1022 - mae: 0.1632 - val_loss: 0.0028 - val_mae: 0.0371 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0069 - mae: 0.0646 - val_loss: 0.0031 - val_mae: 0.0393 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0056 - mae: 0.0582 - val_loss: 0.0061 - val_mae: 0.0530 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0047 - mae: 0.0529 - val_loss: 0.0043 - val_mae: 0.0450 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0039 - mae: 0.0478 - val_loss: 0.0027 - val_mae: 0.0357 - learning_rate: 5.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0037 - mae: 0.0474 - val_loss: 0.0028 - val_mae: 0.0408 - learning_rate: 5.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0036 - mae: 0.0462 - val_loss: 0.0023 - val_mae: 0.0329 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0029 - mae: 0.0406 - val_loss: 0.0024 - val_mae: 0.0338 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0025 - mae: 0.0375 - val_loss: 0.0055 - val_mae: 0.0597 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0024 - mae: 0.0374 - val_loss: 0.0023 - val_mae: 0.0316 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0021 - mae: 0.0343 - val_loss: 0.0021 - val_mae: 0.0303 - learning_rate: 2.5000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0022 - mae: 0.0346 - val_loss: 0.0025 - val_mae: 0.0374 - learning_rate: 2.5000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0021 - mae: 0.0338 - val_loss: 0.0022 - val_mae: 0.0318 - learning_rate: 2.5000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0020 - mae: 0.0335 - val_loss: 0.0023 - val_mae: 0.0322 - learning_rate: 2.5000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0017 - mae: 0.0305 - val_loss: 0.0022 - val_mae: 0.0325 - learning_rate: 1.2500e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0019 - mae: 0.0322 - val_loss: 0.0021 - val_mae: 0.0324 - learning_rate: 1.2500e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0018 - mae: 0.0314 - val_loss: 0.0020 - val_mae: 0.0297 - learning_rate: 1.2500e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0017 - mae: 0.0295 - val_loss: 0.0020 - val_mae: 0.0297 - learning_rate: 6.2500e-05\n",
      "Epoch 19/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0016 - mae: 0.0293 - val_loss: 0.0021 - val_mae: 0.0302 - learning_rate: 6.2500e-05\n",
      "Epoch 20/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0016 - mae: 0.0289 - val_loss: 0.0021 - val_mae: 0.0309 - learning_rate: 6.2500e-05\n",
      "Epoch 21/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0016 - mae: 0.0289 - val_loss: 0.0021 - val_mae: 0.0302 - learning_rate: 3.1250e-05\n",
      "Epoch 22/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0016 - mae: 0.0284 - val_loss: 0.0021 - val_mae: 0.0299 - learning_rate: 3.1250e-05\n",
      "Epoch 23/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0016 - mae: 0.0286 - val_loss: 0.0021 - val_mae: 0.0298 - learning_rate: 3.1250e-05\n",
      "Epoch 24/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0015 - mae: 0.0282 - val_loss: 0.0021 - val_mae: 0.0302 - learning_rate: 1.5625e-05\n",
      "Epoch 25/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0015 - mae: 0.0280 - val_loss: 0.0022 - val_mae: 0.0311 - learning_rate: 1.5625e-05\n",
      "\u001b[1m171/171\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step    \n",
      "âœ… Kolar - onion | MAE=108.42, RMSE=179.12, RÂ²=0.96, MAPE=6.79%, Acc=93.21%\n",
      "\n",
      "ğŸš€ Processing: Kolar | tomato\n",
      "Epoch 1/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 24ms/step - loss: 0.0517 - mae: 0.1277 - val_loss: 0.0055 - val_mae: 0.0436 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0050 - mae: 0.0560 - val_loss: 0.0085 - val_mae: 0.0719 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0042 - mae: 0.0508 - val_loss: 0.0045 - val_mae: 0.0379 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0031 - mae: 0.0440 - val_loss: 0.0037 - val_mae: 0.0369 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0023 - mae: 0.0379 - val_loss: 0.0070 - val_mae: 0.0684 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0020 - mae: 0.0354 - val_loss: 0.0033 - val_mae: 0.0362 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0016 - mae: 0.0317 - val_loss: 0.0029 - val_mae: 0.0371 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0017 - mae: 0.0317 - val_loss: 0.0030 - val_mae: 0.0393 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0013 - mae: 0.0277 - val_loss: 0.0024 - val_mae: 0.0344 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0012 - mae: 0.0268 - val_loss: 0.0031 - val_mae: 0.0438 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0011 - mae: 0.0247 - val_loss: 0.0024 - val_mae: 0.0363 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0011 - mae: 0.0253 - val_loss: 0.0029 - val_mae: 0.0430 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 8.9712e-04 - mae: 0.0224 - val_loss: 0.0022 - val_mae: 0.0283 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 8.6827e-04 - mae: 0.0222 - val_loss: 0.0021 - val_mae: 0.0270 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 8.2128e-04 - mae: 0.0214 - val_loss: 0.0021 - val_mae: 0.0328 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 7.9593e-04 - mae: 0.0210 - val_loss: 0.0020 - val_mae: 0.0298 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 7.7055e-04 - mae: 0.0206 - val_loss: 0.0020 - val_mae: 0.0288 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 7.5107e-04 - mae: 0.0201 - val_loss: 0.0020 - val_mae: 0.0287 - learning_rate: 2.5000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 7.4631e-04 - mae: 0.0202 - val_loss: 0.0019 - val_mae: 0.0277 - learning_rate: 2.5000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 7.4142e-04 - mae: 0.0201 - val_loss: 0.0020 - val_mae: 0.0306 - learning_rate: 2.5000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 7.1916e-04 - mae: 0.0197 - val_loss: 0.0020 - val_mae: 0.0292 - learning_rate: 2.5000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 7.1601e-04 - mae: 0.0196 - val_loss: 0.0019 - val_mae: 0.0267 - learning_rate: 2.5000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 7.0938e-04 - mae: 0.0195 - val_loss: 0.0019 - val_mae: 0.0277 - learning_rate: 1.2500e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 6.8186e-04 - mae: 0.0192 - val_loss: 0.0019 - val_mae: 0.0276 - learning_rate: 1.2500e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 7.0411e-04 - mae: 0.0194 - val_loss: 0.0019 - val_mae: 0.0268 - learning_rate: 1.2500e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 6.4717e-04 - mae: 0.0185 - val_loss: 0.0018 - val_mae: 0.0275 - learning_rate: 6.2500e-05\n",
      "Epoch 27/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 6.4165e-04 - mae: 0.0184 - val_loss: 0.0019 - val_mae: 0.0278 - learning_rate: 6.2500e-05\n",
      "Epoch 28/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 6.6409e-04 - mae: 0.0187 - val_loss: 0.0018 - val_mae: 0.0268 - learning_rate: 6.2500e-05\n",
      "Epoch 29/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 6.4043e-04 - mae: 0.0183 - val_loss: 0.0018 - val_mae: 0.0264 - learning_rate: 6.2500e-05\n",
      "Epoch 30/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 6.4093e-04 - mae: 0.0184 - val_loss: 0.0018 - val_mae: 0.0278 - learning_rate: 6.2500e-05\n",
      "Epoch 31/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 6.3081e-04 - mae: 0.0181 - val_loss: 0.0018 - val_mae: 0.0271 - learning_rate: 6.2500e-05\n",
      "Epoch 32/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 6.4249e-04 - mae: 0.0184 - val_loss: 0.0018 - val_mae: 0.0273 - learning_rate: 3.1250e-05\n",
      "Epoch 33/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 6.4819e-04 - mae: 0.0183 - val_loss: 0.0018 - val_mae: 0.0268 - learning_rate: 3.1250e-05\n",
      "Epoch 34/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 6.4012e-04 - mae: 0.0183 - val_loss: 0.0018 - val_mae: 0.0262 - learning_rate: 3.1250e-05\n",
      "Epoch 35/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 6.4785e-04 - mae: 0.0183 - val_loss: 0.0018 - val_mae: 0.0275 - learning_rate: 1.5625e-05\n",
      "Epoch 36/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 6.4109e-04 - mae: 0.0181 - val_loss: 0.0018 - val_mae: 0.0270 - learning_rate: 1.5625e-05\n",
      "Epoch 37/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 6.2549e-04 - mae: 0.0181 - val_loss: 0.0018 - val_mae: 0.0269 - learning_rate: 1.5625e-05\n",
      "Epoch 38/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 6.2902e-04 - mae: 0.0181 - val_loss: 0.0018 - val_mae: 0.0284 - learning_rate: 7.8125e-06\n",
      "Epoch 39/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 6.2957e-04 - mae: 0.0180 - val_loss: 0.0018 - val_mae: 0.0280 - learning_rate: 7.8125e-06\n",
      "Epoch 40/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 6.1699e-04 - mae: 0.0179 - val_loss: 0.0018 - val_mae: 0.0278 - learning_rate: 7.8125e-06\n",
      "Epoch 41/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 6.3147e-04 - mae: 0.0182 - val_loss: 0.0018 - val_mae: 0.0278 - learning_rate: 3.9063e-06\n",
      "Epoch 42/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 6.3217e-04 - mae: 0.0182 - val_loss: 0.0018 - val_mae: 0.0277 - learning_rate: 3.9063e-06\n",
      "Epoch 43/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 6.3420e-04 - mae: 0.0181 - val_loss: 0.0018 - val_mae: 0.0275 - learning_rate: 3.9063e-06\n",
      "Epoch 44/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 6.3398e-04 - mae: 0.0182 - val_loss: 0.0018 - val_mae: 0.0280 - learning_rate: 1.9531e-06\n",
      "\u001b[1m171/171\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step    \n",
      "âœ… Kolar - tomato | MAE=164.7, RMSE=236.46, RÂ²=0.9056, MAPE=17.52%, Acc=82.48%\n",
      "\n",
      "ğŸš€ Processing: Kolar | wheat\n",
      "Epoch 1/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 23ms/step - loss: 0.0317 - mae: 0.1003 - val_loss: 0.0038 - val_mae: 0.0392 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0039 - mae: 0.0501 - val_loss: 0.0036 - val_mae: 0.0573 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0027 - mae: 0.0410 - val_loss: 0.0023 - val_mae: 0.0270 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0022 - mae: 0.0370 - val_loss: 0.0038 - val_mae: 0.0402 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0016 - mae: 0.0321 - val_loss: 0.0021 - val_mae: 0.0223 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0012 - mae: 0.0280 - val_loss: 0.0036 - val_mae: 0.0484 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 8.8488e-04 - mae: 0.0237 - val_loss: 0.0030 - val_mae: 0.0349 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 9.7020e-04 - mae: 0.0249 - val_loss: 0.0029 - val_mae: 0.0348 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 6.4784e-04 - mae: 0.0202 - val_loss: 0.0030 - val_mae: 0.0406 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 5.0339e-04 - mae: 0.0177 - val_loss: 0.0030 - val_mae: 0.0416 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 4.9696e-04 - mae: 0.0178 - val_loss: 0.0033 - val_mae: 0.0409 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 4.3893e-04 - mae: 0.0165 - val_loss: 0.0032 - val_mae: 0.0412 - learning_rate: 2.5000e-04\n",
      "\u001b[1m167/167\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step\n",
      "âœ… Kolar - wheat | MAE=44.21, RMSE=75.83, RÂ²=0.9798, MAPE=2.11%, Acc=97.89%\n",
      "\n",
      "ğŸš€ Processing: Koppal | onion\n",
      "Epoch 1/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 341ms/step - loss: 2.8099 - mae: 1.3392 - val_loss: 1.3201 - val_mae: 1.1482 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 1.7369 - mae: 1.2459 - val_loss: 0.0034 - val_mae: 0.0466 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.1997 - mae: 0.3682 - val_loss: 0.9052 - val_mae: 0.9500 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.5616 - mae: 0.7120 - val_loss: 0.3845 - val_mae: 0.6182 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0998 - mae: 0.2571 - val_loss: 0.0033 - val_mae: 0.0429 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.1712 - mae: 0.3516 - val_loss: 0.0125 - val_mae: 0.1032 - learning_rate: 5.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.1490 - mae: 0.3250 - val_loss: 0.0070 - val_mae: 0.0728 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0582 - mae: 0.1907 - val_loss: 0.0963 - val_mae: 0.3077 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0460 - mae: 0.1694 - val_loss: 0.1462 - val_mae: 0.3803 - learning_rate: 2.5000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0528 - mae: 0.1851 - val_loss: 0.1556 - val_mae: 0.3925 - learning_rate: 2.5000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0506 - mae: 0.1774 - val_loss: 0.1313 - val_mae: 0.3604 - learning_rate: 2.5000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0446 - mae: 0.1694 - val_loss: 0.1134 - val_mae: 0.3346 - learning_rate: 1.2500e-04\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step\n",
      "âœ… Koppal - onion | MAE=1426.75, RMSE=1848.7, RÂ²=-1.1288, MAPE=116.35%, Acc=-16.35%\n",
      "\n",
      "ğŸš€ Processing: Koppal | tomato\n",
      "Epoch 1/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 337ms/step - loss: 1.7531 - mae: 0.9415 - val_loss: 1.3118 - val_mae: 1.1453 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.5879 - mae: 0.6884 - val_loss: 0.0941 - val_mae: 0.3068 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.2579 - mae: 0.4782 - val_loss: 0.4098 - val_mae: 0.6401 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.1238 - mae: 0.3043 - val_loss: 1.5546e-04 - val_mae: 0.0101 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.1277 - mae: 0.3064 - val_loss: 0.0335 - val_mae: 0.1826 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0819 - mae: 0.2311 - val_loss: 0.0305 - val_mae: 0.1739 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0425 - mae: 0.1811 - val_loss: 0.0790 - val_mae: 0.2804 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0447 - mae: 0.1936 - val_loss: 0.0181 - val_mae: 0.1333 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0093 - mae: 0.0756 - val_loss: 0.0023 - val_mae: 0.0452 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0138 - mae: 0.1009 - val_loss: 0.0114 - val_mae: 0.1053 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0186 - mae: 0.1188 - val_loss: 0.0055 - val_mae: 0.0721 - learning_rate: 2.5000e-04\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step\n",
      "âœ… Koppal - tomato | MAE=1280.54, RMSE=1769.97, RÂ²=-12.7682, MAPE=230.45%, Acc=-130.45%\n",
      "\n",
      "ğŸš€ Processing: Koppal | wheat\n",
      "Epoch 1/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 19ms/step - loss: 0.0385 - mae: 0.1092 - val_loss: 0.0026 - val_mae: 0.0463 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0029 - mae: 0.0427 - val_loss: 0.0056 - val_mae: 0.0685 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0025 - mae: 0.0396 - val_loss: 0.0025 - val_mae: 0.0472 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0020 - mae: 0.0353 - val_loss: 0.0018 - val_mae: 0.0359 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0017 - mae: 0.0326 - val_loss: 0.0059 - val_mae: 0.0704 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0013 - mae: 0.0281 - val_loss: 0.0037 - val_mae: 0.0364 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0013 - mae: 0.0285 - val_loss: 0.0017 - val_mae: 0.0367 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 9.5601e-04 - mae: 0.0235 - val_loss: 0.0023 - val_mae: 0.0456 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 9.3464e-04 - mae: 0.0232 - val_loss: 0.0028 - val_mae: 0.0490 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 8.1445e-04 - mae: 0.0214 - val_loss: 0.0024 - val_mae: 0.0460 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 7.8851e-04 - mae: 0.0210 - val_loss: 0.0024 - val_mae: 0.0461 - learning_rate: 2.5000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 7.6933e-04 - mae: 0.0208 - val_loss: 0.0038 - val_mae: 0.0575 - learning_rate: 2.5000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 7.1687e-04 - mae: 0.0200 - val_loss: 0.0026 - val_mae: 0.0475 - learning_rate: 2.5000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 6.7268e-04 - mae: 0.0192 - val_loss: 0.0026 - val_mae: 0.0473 - learning_rate: 1.2500e-04\n",
      "\u001b[1m162/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step   \n",
      "âœ… Koppal - wheat | MAE=43.53, RMSE=52.26, RÂ²=0.9834, MAPE=2.59%, Acc=97.41%\n",
      "\n",
      "ğŸš€ Processing: Madikeri(Kodagu) | onion\n",
      "Epoch 1/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - loss: 0.0500 - mae: 0.1341 - val_loss: 2.4273e-04 - val_mae: 0.0145 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0055 - mae: 0.0570 - val_loss: 0.0024 - val_mae: 0.0487 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0046 - mae: 0.0524 - val_loss: 1.3291e-04 - val_mae: 0.0112 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0035 - mae: 0.0457 - val_loss: 2.1413e-04 - val_mae: 0.0135 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0037 - mae: 0.0471 - val_loss: 0.0032 - val_mae: 0.0562 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0029 - mae: 0.0411 - val_loss: 5.5957e-04 - val_mae: 0.0218 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0021 - mae: 0.0350 - val_loss: 4.1294e-06 - val_mae: 0.0017 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0021 - mae: 0.0348 - val_loss: 2.3904e-04 - val_mae: 0.0154 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0019 - mae: 0.0334 - val_loss: 3.1171e-05 - val_mae: 0.0054 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0018 - mae: 0.0325 - val_loss: 1.5918e-05 - val_mae: 0.0033 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0016 - mae: 0.0296 - val_loss: 5.3151e-05 - val_mae: 0.0072 - learning_rate: 2.5000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0015 - mae: 0.0283 - val_loss: 2.5333e-05 - val_mae: 0.0050 - learning_rate: 2.5000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0014 - mae: 0.0275 - val_loss: 1.5062e-06 - val_mae: 0.0012 - learning_rate: 2.5000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0013 - mae: 0.0260 - val_loss: 2.1670e-04 - val_mae: 0.0147 - learning_rate: 1.2500e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0012 - mae: 0.0251 - val_loss: 9.1264e-05 - val_mae: 0.0095 - learning_rate: 1.2500e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0012 - mae: 0.0253 - val_loss: 1.0833e-04 - val_mae: 0.0104 - learning_rate: 1.2500e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0012 - mae: 0.0250 - val_loss: 1.0096e-04 - val_mae: 0.0100 - learning_rate: 6.2500e-05\n",
      "Epoch 18/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0012 - mae: 0.0246 - val_loss: 4.2677e-04 - val_mae: 0.0206 - learning_rate: 6.2500e-05\n",
      "Epoch 19/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0012 - mae: 0.0250 - val_loss: 5.7420e-04 - val_mae: 0.0239 - learning_rate: 6.2500e-05\n",
      "Epoch 20/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0011 - mae: 0.0242 - val_loss: 8.7318e-05 - val_mae: 0.0092 - learning_rate: 3.1250e-05\n",
      "\u001b[1m154/154\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step   \n",
      "âœ… Madikeri(Kodagu) - onion | MAE=26.2, RMSE=47.49, RÂ²=0.9905, MAPE=2.29%, Acc=97.71%\n",
      "\n",
      "ğŸš€ Processing: Madikeri(Kodagu) | tomato\n",
      "Epoch 1/50\n",
      "\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 22ms/step - loss: 0.0548 - mae: 0.1468 - val_loss: 2.1271e-04 - val_mae: 0.0128 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0071 - mae: 0.0658 - val_loss: 6.2422e-05 - val_mae: 0.0068 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0047 - mae: 0.0530 - val_loss: 0.0027 - val_mae: 0.0517 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0039 - mae: 0.0475 - val_loss: 5.4376e-04 - val_mae: 0.0227 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0031 - mae: 0.0426 - val_loss: 1.0251e-04 - val_mae: 0.0073 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0029 - mae: 0.0415 - val_loss: 0.0058 - val_mae: 0.0756 - learning_rate: 5.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0025 - mae: 0.0383 - val_loss: 0.0086 - val_mae: 0.0924 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0022 - mae: 0.0348 - val_loss: 0.0045 - val_mae: 0.0666 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m82/82\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0020 - mae: 0.0330 - val_loss: 6.4378e-04 - val_mae: 0.0235 - learning_rate: 2.5000e-04\n",
      "\u001b[1m102/102\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step   \n",
      "âœ… Madikeri(Kodagu) - tomato | MAE=24.97, RMSE=45.23, RÂ²=0.9761, MAPE=2.92%, Acc=97.08%\n",
      "\n",
      "ğŸš€ Processing: Madikeri(Kodagu) | wheat\n",
      "Epoch 1/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - loss: 0.2298 - mae: 0.2002 - val_loss: 0.0222 - val_mae: 0.1439 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0058 - mae: 0.0530 - val_loss: 0.0019 - val_mae: 0.0373 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0048 - mae: 0.0493 - val_loss: 0.0026 - val_mae: 0.0471 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0044 - mae: 0.0455 - val_loss: 0.0057 - val_mae: 0.0724 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0041 - mae: 0.0433 - val_loss: 0.0046 - val_mae: 0.0658 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0035 - mae: 0.0401 - val_loss: 0.0037 - val_mae: 0.0579 - learning_rate: 5.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0032 - mae: 0.0373 - val_loss: 0.0026 - val_mae: 0.0486 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0031 - mae: 0.0366 - val_loss: 0.0025 - val_mae: 0.0486 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0030 - mae: 0.0354 - val_loss: 0.0015 - val_mae: 0.0373 - learning_rate: 2.5000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0027 - mae: 0.0337 - val_loss: 0.0022 - val_mae: 0.0456 - learning_rate: 2.5000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0028 - mae: 0.0333 - val_loss: 0.0013 - val_mae: 0.0360 - learning_rate: 2.5000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0027 - mae: 0.0331 - val_loss: 0.0023 - val_mae: 0.0475 - learning_rate: 2.5000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0026 - mae: 0.0313 - val_loss: 6.0945e-04 - val_mae: 0.0243 - learning_rate: 2.5000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0025 - mae: 0.0306 - val_loss: 0.0024 - val_mae: 0.0485 - learning_rate: 2.5000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0025 - mae: 0.0297 - val_loss: 0.0016 - val_mae: 0.0392 - learning_rate: 2.5000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0023 - mae: 0.0282 - val_loss: 0.0011 - val_mae: 0.0323 - learning_rate: 2.5000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0023 - mae: 0.0287 - val_loss: 0.0010 - val_mae: 0.0315 - learning_rate: 1.2500e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0022 - mae: 0.0282 - val_loss: 6.7638e-04 - val_mae: 0.0252 - learning_rate: 1.2500e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0021 - mae: 0.0270 - val_loss: 0.0010 - val_mae: 0.0310 - learning_rate: 1.2500e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m113/113\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0020 - mae: 0.0260 - val_loss: 8.2354e-04 - val_mae: 0.0274 - learning_rate: 6.2500e-05\n",
      "\u001b[1m142/142\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step\n",
      "âœ… Madikeri(Kodagu) - wheat | MAE=343.0, RMSE=695.2, RÂ²=0.9852, MAPE=9.77%, Acc=90.23%\n",
      "\n",
      "ğŸš€ Processing: Mandya | capsicum\n",
      "Epoch 1/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 20ms/step - loss: 0.0602 - mae: 0.1442 - val_loss: 0.0154 - val_mae: 0.1036 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0057 - mae: 0.0584 - val_loss: 0.0090 - val_mae: 0.0789 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0045 - mae: 0.0514 - val_loss: 0.0215 - val_mae: 0.1275 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0042 - mae: 0.0497 - val_loss: 0.0165 - val_mae: 0.1109 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0039 - mae: 0.0481 - val_loss: 0.0195 - val_mae: 0.1226 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0025 - mae: 0.0373 - val_loss: 0.0073 - val_mae: 0.0687 - learning_rate: 5.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0024 - mae: 0.0356 - val_loss: 0.0064 - val_mae: 0.0635 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0025 - mae: 0.0368 - val_loss: 0.0077 - val_mae: 0.0714 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0022 - mae: 0.0344 - val_loss: 0.0080 - val_mae: 0.0725 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0021 - mae: 0.0339 - val_loss: 0.0064 - val_mae: 0.0631 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0020 - mae: 0.0327 - val_loss: 0.0120 - val_mae: 0.0929 - learning_rate: 2.5000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0017 - mae: 0.0303 - val_loss: 0.0086 - val_mae: 0.0755 - learning_rate: 2.5000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0017 - mae: 0.0304 - val_loss: 0.0067 - val_mae: 0.0643 - learning_rate: 2.5000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0016 - mae: 0.0289 - val_loss: 0.0062 - val_mae: 0.0611 - learning_rate: 1.2500e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0016 - mae: 0.0288 - val_loss: 0.0064 - val_mae: 0.0622 - learning_rate: 1.2500e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0015 - mae: 0.0278 - val_loss: 0.0061 - val_mae: 0.0605 - learning_rate: 1.2500e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0015 - mae: 0.0270 - val_loss: 0.0058 - val_mae: 0.0576 - learning_rate: 1.2500e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0015 - mae: 0.0278 - val_loss: 0.0054 - val_mae: 0.0536 - learning_rate: 1.2500e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0015 - mae: 0.0279 - val_loss: 0.0073 - val_mae: 0.0686 - learning_rate: 1.2500e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0015 - mae: 0.0274 - val_loss: 0.0056 - val_mae: 0.0558 - learning_rate: 1.2500e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0015 - mae: 0.0274 - val_loss: 0.0060 - val_mae: 0.0594 - learning_rate: 1.2500e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0014 - mae: 0.0262 - val_loss: 0.0062 - val_mae: 0.0609 - learning_rate: 6.2500e-05\n",
      "Epoch 23/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0013 - mae: 0.0253 - val_loss: 0.0061 - val_mae: 0.0597 - learning_rate: 6.2500e-05\n",
      "Epoch 24/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0014 - mae: 0.0262 - val_loss: 0.0061 - val_mae: 0.0600 - learning_rate: 6.2500e-05\n",
      "Epoch 25/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0013 - mae: 0.0246 - val_loss: 0.0065 - val_mae: 0.0629 - learning_rate: 3.1250e-05\n",
      "\u001b[1m156/156\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step    \n",
      "âœ… Mandya - capsicum | MAE=106.91, RMSE=170.05, RÂ²=0.9734, MAPE=6.72%, Acc=93.28%\n",
      "\n",
      "ğŸš€ Processing: Mandya | onion\n",
      "Epoch 1/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 20ms/step - loss: 0.0571 - mae: 0.1372 - val_loss: 0.0066 - val_mae: 0.0613 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0055 - mae: 0.0568 - val_loss: 0.0066 - val_mae: 0.0681 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0046 - mae: 0.0514 - val_loss: 0.0030 - val_mae: 0.0342 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0030 - mae: 0.0408 - val_loss: 0.0025 - val_mae: 0.0319 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0027 - mae: 0.0379 - val_loss: 0.0038 - val_mae: 0.0468 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0021 - mae: 0.0327 - val_loss: 0.0051 - val_mae: 0.0606 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0017 - mae: 0.0285 - val_loss: 0.0041 - val_mae: 0.0510 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0039 - val_mae: 0.0495 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0014 - mae: 0.0249 - val_loss: 0.0041 - val_mae: 0.0512 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0013 - mae: 0.0230 - val_loss: 0.0034 - val_mae: 0.0440 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0012 - mae: 0.0222 - val_loss: 0.0025 - val_mae: 0.0343 - learning_rate: 2.5000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0012 - mae: 0.0213 - val_loss: 0.0024 - val_mae: 0.0325 - learning_rate: 2.5000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0012 - mae: 0.0210 - val_loss: 0.0026 - val_mae: 0.0340 - learning_rate: 2.5000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0012 - mae: 0.0210 - val_loss: 0.0025 - val_mae: 0.0334 - learning_rate: 2.5000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0011 - mae: 0.0206 - val_loss: 0.0024 - val_mae: 0.0322 - learning_rate: 2.5000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0011 - mae: 0.0191 - val_loss: 0.0029 - val_mae: 0.0385 - learning_rate: 1.2500e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0010 - mae: 0.0190 - val_loss: 0.0033 - val_mae: 0.0433 - learning_rate: 1.2500e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0010 - mae: 0.0188 - val_loss: 0.0029 - val_mae: 0.0387 - learning_rate: 1.2500e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 9.9481e-04 - mae: 0.0182 - val_loss: 0.0028 - val_mae: 0.0373 - learning_rate: 6.2500e-05\n",
      "Epoch 20/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 9.9512e-04 - mae: 0.0182 - val_loss: 0.0030 - val_mae: 0.0400 - learning_rate: 6.2500e-05\n",
      "Epoch 21/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0010 - mae: 0.0184 - val_loss: 0.0028 - val_mae: 0.0382 - learning_rate: 6.2500e-05\n",
      "Epoch 22/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 9.6705e-04 - mae: 0.0178 - val_loss: 0.0028 - val_mae: 0.0370 - learning_rate: 3.1250e-05\n",
      "\u001b[1m167/167\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step\n",
      "âœ… Mandya - onion | MAE=58.61, RMSE=128.23, RÂ²=0.9331, MAPE=3.63%, Acc=96.37%\n",
      "\n",
      "ğŸš€ Processing: Mandya | tomato\n",
      "Epoch 1/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 19ms/step - loss: 0.0961 - mae: 0.1555 - val_loss: 0.0206 - val_mae: 0.0801 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0050 - mae: 0.0560 - val_loss: 0.0188 - val_mae: 0.0778 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0041 - mae: 0.0503 - val_loss: 0.0156 - val_mae: 0.0709 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0034 - mae: 0.0461 - val_loss: 0.0161 - val_mae: 0.0741 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0032 - mae: 0.0443 - val_loss: 0.0158 - val_mae: 0.0809 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0025 - mae: 0.0388 - val_loss: 0.0107 - val_mae: 0.0597 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0023 - mae: 0.0376 - val_loss: 0.0110 - val_mae: 0.0589 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0018 - mae: 0.0328 - val_loss: 0.0096 - val_mae: 0.0544 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0016 - mae: 0.0308 - val_loss: 0.0106 - val_mae: 0.0602 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0015 - mae: 0.0303 - val_loss: 0.0091 - val_mae: 0.0526 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0012 - mae: 0.0266 - val_loss: 0.0132 - val_mae: 0.0737 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0014 - mae: 0.0294 - val_loss: 0.0106 - val_mae: 0.0576 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0012 - mae: 0.0264 - val_loss: 0.0096 - val_mae: 0.0540 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 8.0975e-04 - mae: 0.0208 - val_loss: 0.0094 - val_mae: 0.0533 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 8.1137e-04 - mae: 0.0210 - val_loss: 0.0094 - val_mae: 0.0529 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 7.6335e-04 - mae: 0.0202 - val_loss: 0.0096 - val_mae: 0.0524 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 6.5457e-04 - mae: 0.0186 - val_loss: 0.0101 - val_mae: 0.0556 - learning_rate: 2.5000e-04\n",
      "\u001b[1m171/171\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step \n",
      "âœ… Mandya - tomato | MAE=182.37, RMSE=371.34, RÂ²=0.7792, MAPE=24.59%, Acc=75.41%\n",
      "\n",
      "ğŸš€ Processing: Mandya | wheat\n",
      "Epoch 1/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 26ms/step - loss: 0.1723 - mae: 0.2383 - val_loss: 2.8648e-04 - val_mae: 0.0148 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0069 - mae: 0.0655 - val_loss: 0.0023 - val_mae: 0.0454 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0066 - mae: 0.0641 - val_loss: 0.0032 - val_mae: 0.0514 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0054 - mae: 0.0582 - val_loss: 3.3331e-04 - val_mae: 0.0152 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0051 - mae: 0.0560 - val_loss: 0.0023 - val_mae: 0.0461 - learning_rate: 5.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0047 - mae: 0.0544 - val_loss: 5.0509e-04 - val_mae: 0.0207 - learning_rate: 5.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0041 - mae: 0.0512 - val_loss: 1.1427e-04 - val_mae: 0.0094 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0039 - mae: 0.0493 - val_loss: 6.5331e-04 - val_mae: 0.0245 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0035 - mae: 0.0467 - val_loss: 2.7593e-04 - val_mae: 0.0140 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0030 - mae: 0.0432 - val_loss: 5.5603e-05 - val_mae: 0.0062 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0027 - mae: 0.0404 - val_loss: 1.0643e-04 - val_mae: 0.0090 - learning_rate: 2.5000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0028 - mae: 0.0408 - val_loss: 4.9714e-05 - val_mae: 0.0062 - learning_rate: 2.5000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0024 - mae: 0.0384 - val_loss: 1.1352e-04 - val_mae: 0.0091 - learning_rate: 2.5000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0023 - mae: 0.0368 - val_loss: 9.3447e-05 - val_mae: 0.0078 - learning_rate: 1.2500e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0023 - mae: 0.0369 - val_loss: 1.4213e-04 - val_mae: 0.0096 - learning_rate: 1.2500e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0023 - mae: 0.0369 - val_loss: 2.5097e-04 - val_mae: 0.0131 - learning_rate: 1.2500e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0021 - mae: 0.0356 - val_loss: 1.8109e-04 - val_mae: 0.0109 - learning_rate: 6.2500e-05\n",
      "Epoch 18/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0021 - mae: 0.0355 - val_loss: 1.7781e-04 - val_mae: 0.0108 - learning_rate: 6.2500e-05\n",
      "Epoch 19/50\n",
      "\u001b[1m86/86\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0021 - mae: 0.0352 - val_loss: 1.8570e-04 - val_mae: 0.0111 - learning_rate: 6.2500e-05\n",
      "\u001b[1m108/108\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 21ms/step\n",
      "âœ… Mandya - wheat | MAE=17.29, RMSE=35.34, RÂ²=0.9864, MAPE=0.73%, Acc=99.27%\n",
      "\n",
      "ğŸš€ Processing: Mangalore(Dakshin Kannad) | onion\n",
      "Epoch 1/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 22ms/step - loss: 0.0620 - mae: 0.1321 - val_loss: 0.0109 - val_mae: 0.0891 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0047 - mae: 0.0534 - val_loss: 0.0091 - val_mae: 0.0829 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0035 - mae: 0.0458 - val_loss: 0.0058 - val_mae: 0.0594 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0027 - mae: 0.0394 - val_loss: 0.0050 - val_mae: 0.0536 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0023 - mae: 0.0369 - val_loss: 0.0046 - val_mae: 0.0502 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0020 - mae: 0.0333 - val_loss: 0.0042 - val_mae: 0.0455 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0015 - mae: 0.0283 - val_loss: 0.0045 - val_mae: 0.0494 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0015 - mae: 0.0281 - val_loss: 0.0046 - val_mae: 0.0518 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0014 - mae: 0.0269 - val_loss: 0.0037 - val_mae: 0.0410 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0014 - mae: 0.0272 - val_loss: 0.0041 - val_mae: 0.0461 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0014 - mae: 0.0273 - val_loss: 0.0039 - val_mae: 0.0374 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0012 - mae: 0.0259 - val_loss: 0.0046 - val_mae: 0.0495 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 8.6826e-04 - mae: 0.0198 - val_loss: 0.0051 - val_mae: 0.0562 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 7.9029e-04 - mae: 0.0188 - val_loss: 0.0042 - val_mae: 0.0454 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 9.3126e-04 - mae: 0.0210 - val_loss: 0.0045 - val_mae: 0.0493 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m129/129\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 7.9387e-04 - mae: 0.0188 - val_loss: 0.0049 - val_mae: 0.0541 - learning_rate: 2.5000e-04\n",
      "\u001b[1m161/161\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step    \n",
      "âœ… Mangalore(Dakshin Kannad) - onion | MAE=123.17, RMSE=196.87, RÂ²=0.9518, MAPE=7.19%, Acc=92.81%\n",
      "\n",
      "ğŸš€ Processing: Mangalore(Dakshin Kannad) | tomato\n",
      "Epoch 1/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 72ms/step - loss: 0.4805 - mae: 0.5478 - val_loss: 0.1823 - val_mae: 0.3850 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0681 - mae: 0.2110 - val_loss: 0.0669 - val_mae: 0.2274 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0183 - mae: 0.1009 - val_loss: 0.0300 - val_mae: 0.1453 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0134 - mae: 0.0874 - val_loss: 0.0204 - val_mae: 0.1085 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0130 - mae: 0.0871 - val_loss: 0.0135 - val_mae: 0.0964 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0123 - mae: 0.0835 - val_loss: 0.0140 - val_mae: 0.0960 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0098 - mae: 0.0762 - val_loss: 0.0090 - val_mae: 0.0760 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0104 - mae: 0.0772 - val_loss: 0.0078 - val_mae: 0.0664 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0097 - mae: 0.0744 - val_loss: 0.0073 - val_mae: 0.0631 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0084 - mae: 0.0669 - val_loss: 0.0078 - val_mae: 0.0618 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0082 - mae: 0.0687 - val_loss: 0.0049 - val_mae: 0.0487 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0081 - mae: 0.0669 - val_loss: 0.0074 - val_mae: 0.0664 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0087 - mae: 0.0701 - val_loss: 0.0062 - val_mae: 0.0547 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0078 - mae: 0.0681 - val_loss: 0.0111 - val_mae: 0.0817 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0074 - mae: 0.0650 - val_loss: 0.0073 - val_mae: 0.0619 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0075 - mae: 0.0657 - val_loss: 0.0067 - val_mae: 0.0590 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0071 - mae: 0.0629 - val_loss: 0.0074 - val_mae: 0.0620 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0064 - mae: 0.0582 - val_loss: 0.0062 - val_mae: 0.0572 - learning_rate: 2.5000e-04\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step  \n",
      "âœ… Mangalore(Dakshin Kannad) - tomato | MAE=244.48, RMSE=376.93, RÂ²=0.9043, MAPE=11.52%, Acc=88.48%\n",
      "\n",
      "ğŸš€ Processing: Mangalore(Dakshin Kannad) | wheat\n",
      "Epoch 1/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 51ms/step - loss: 0.2094 - mae: 0.3579 - val_loss: 0.0014 - val_mae: 0.0321 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0324 - mae: 0.1435 - val_loss: 0.0049 - val_mae: 0.0653 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0109 - mae: 0.0843 - val_loss: 0.0048 - val_mae: 0.0651 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0053 - mae: 0.0576 - val_loss: 0.0063 - val_mae: 0.0762 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0052 - mae: 0.0558 - val_loss: 0.0011 - val_mae: 0.0277 - learning_rate: 5.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0044 - mae: 0.0528 - val_loss: 8.9526e-04 - val_mae: 0.0250 - learning_rate: 5.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0045 - mae: 0.0529 - val_loss: 5.7417e-04 - val_mae: 0.0207 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0046 - mae: 0.0518 - val_loss: 6.9473e-04 - val_mae: 0.0223 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0046 - mae: 0.0518 - val_loss: 4.8421e-04 - val_mae: 0.0185 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0049 - mae: 0.0553 - val_loss: 4.9593e-04 - val_mae: 0.0184 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0041 - mae: 0.0497 - val_loss: 8.4988e-04 - val_mae: 0.0246 - learning_rate: 2.5000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0039 - mae: 0.0479 - val_loss: 7.3586e-04 - val_mae: 0.0230 - learning_rate: 2.5000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0041 - mae: 0.0497 - val_loss: 0.0011 - val_mae: 0.0272 - learning_rate: 2.5000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0043 - mae: 0.0493 - val_loss: 0.0014 - val_mae: 0.0319 - learning_rate: 1.2500e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0039 - mae: 0.0486 - val_loss: 0.0010 - val_mae: 0.0271 - learning_rate: 1.2500e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0039 - mae: 0.0478 - val_loss: 9.2700e-04 - val_mae: 0.0256 - learning_rate: 1.2500e-04\n",
      "\u001b[1m26/26\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step \n",
      "âœ… Mangalore(Dakshin Kannad) - wheat | MAE=82.74, RMSE=103.24, RÂ²=0.9727, MAPE=3.15%, Acc=96.85%\n",
      "\n",
      "ğŸš€ Processing: Mysore | capsicum\n",
      "Epoch 1/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 18ms/step - loss: 0.0610 - mae: 0.1386 - val_loss: 0.0090 - val_mae: 0.0661 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0054 - mae: 0.0583 - val_loss: 0.0074 - val_mae: 0.0623 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0044 - mae: 0.0525 - val_loss: 0.0056 - val_mae: 0.0559 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0038 - mae: 0.0488 - val_loss: 0.0059 - val_mae: 0.0547 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0030 - mae: 0.0428 - val_loss: 0.0049 - val_mae: 0.0499 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0028 - mae: 0.0411 - val_loss: 0.0064 - val_mae: 0.0632 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0026 - mae: 0.0399 - val_loss: 0.0048 - val_mae: 0.0489 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0020 - mae: 0.0345 - val_loss: 0.0045 - val_mae: 0.0485 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0017 - mae: 0.0319 - val_loss: 0.0043 - val_mae: 0.0470 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0017 - mae: 0.0325 - val_loss: 0.0052 - val_mae: 0.0560 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0016 - mae: 0.0306 - val_loss: 0.0045 - val_mae: 0.0472 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0015 - mae: 0.0299 - val_loss: 0.0042 - val_mae: 0.0461 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0014 - mae: 0.0293 - val_loss: 0.0041 - val_mae: 0.0449 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0014 - mae: 0.0281 - val_loss: 0.0040 - val_mae: 0.0446 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0013 - mae: 0.0271 - val_loss: 0.0039 - val_mae: 0.0441 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0013 - mae: 0.0274 - val_loss: 0.0040 - val_mae: 0.0444 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0012 - mae: 0.0267 - val_loss: 0.0045 - val_mae: 0.0462 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0012 - mae: 0.0265 - val_loss: 0.0040 - val_mae: 0.0437 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0011 - mae: 0.0247 - val_loss: 0.0039 - val_mae: 0.0455 - learning_rate: 5.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0011 - mae: 0.0247 - val_loss: 0.0039 - val_mae: 0.0448 - learning_rate: 5.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0010 - mae: 0.0239 - val_loss: 0.0039 - val_mae: 0.0449 - learning_rate: 5.0000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 9.0559e-04 - mae: 0.0222 - val_loss: 0.0038 - val_mae: 0.0433 - learning_rate: 2.5000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 9.1116e-04 - mae: 0.0223 - val_loss: 0.0039 - val_mae: 0.0424 - learning_rate: 2.5000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 9.3168e-04 - mae: 0.0226 - val_loss: 0.0038 - val_mae: 0.0425 - learning_rate: 2.5000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 8.9171e-04 - mae: 0.0220 - val_loss: 0.0038 - val_mae: 0.0422 - learning_rate: 2.5000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 8.4722e-04 - mae: 0.0212 - val_loss: 0.0038 - val_mae: 0.0425 - learning_rate: 1.2500e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 8.0245e-04 - mae: 0.0208 - val_loss: 0.0038 - val_mae: 0.0421 - learning_rate: 1.2500e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 8.2971e-04 - mae: 0.0208 - val_loss: 0.0038 - val_mae: 0.0427 - learning_rate: 1.2500e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 8.2112e-04 - mae: 0.0208 - val_loss: 0.0038 - val_mae: 0.0425 - learning_rate: 6.2500e-05\n",
      "Epoch 30/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 8.3982e-04 - mae: 0.0211 - val_loss: 0.0038 - val_mae: 0.0423 - learning_rate: 6.2500e-05\n",
      "Epoch 31/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 8.1794e-04 - mae: 0.0207 - val_loss: 0.0038 - val_mae: 0.0422 - learning_rate: 6.2500e-05\n",
      "Epoch 32/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 8.1384e-04 - mae: 0.0206 - val_loss: 0.0038 - val_mae: 0.0428 - learning_rate: 3.1250e-05\n",
      "Epoch 33/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 7.9990e-04 - mae: 0.0206 - val_loss: 0.0039 - val_mae: 0.0451 - learning_rate: 3.1250e-05\n",
      "\u001b[1m171/171\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step    \n",
      "âœ… Mysore - capsicum | MAE=241.02, RMSE=366.29, RÂ²=0.8816, MAPE=9.57%, Acc=90.43%\n",
      "\n",
      "ğŸš€ Processing: Mysore | onion\n",
      "Epoch 1/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - loss: 0.1049 - mae: 0.1698 - val_loss: 0.0165 - val_mae: 0.0795 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0062 - mae: 0.0620 - val_loss: 0.0047 - val_mae: 0.0405 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0050 - mae: 0.0548 - val_loss: 0.0041 - val_mae: 0.0409 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0040 - mae: 0.0488 - val_loss: 0.0027 - val_mae: 0.0300 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0027 - mae: 0.0390 - val_loss: 0.0025 - val_mae: 0.0299 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0021 - mae: 0.0346 - val_loss: 0.0025 - val_mae: 0.0302 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0017 - mae: 0.0302 - val_loss: 0.0028 - val_mae: 0.0362 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0014 - mae: 0.0270 - val_loss: 0.0032 - val_mae: 0.0354 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0012 - mae: 0.0242 - val_loss: 0.0040 - val_mae: 0.0350 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0011 - mae: 0.0231 - val_loss: 0.0037 - val_mae: 0.0347 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0011 - mae: 0.0229 - val_loss: 0.0045 - val_mae: 0.0362 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0011 - mae: 0.0220 - val_loss: 0.0046 - val_mae: 0.0393 - learning_rate: 2.5000e-04\n",
      "\u001b[1m171/171\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step    \n",
      "âœ… Mysore - onion | MAE=114.17, RMSE=200.78, RÂ²=0.9098, MAPE=6.86%, Acc=93.14%\n",
      "\n",
      "ğŸš€ Processing: Mysore | tomato\n",
      "Epoch 1/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 18ms/step - loss: 0.0671 - mae: 0.1363 - val_loss: 0.0071 - val_mae: 0.0607 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0050 - mae: 0.0545 - val_loss: 0.0091 - val_mae: 0.0773 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0042 - mae: 0.0507 - val_loss: 0.0042 - val_mae: 0.0463 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0033 - mae: 0.0444 - val_loss: 0.0056 - val_mae: 0.0581 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0029 - mae: 0.0408 - val_loss: 0.0062 - val_mae: 0.0613 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0023 - mae: 0.0358 - val_loss: 0.0058 - val_mae: 0.0604 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0020 - mae: 0.0336 - val_loss: 0.0052 - val_mae: 0.0569 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0018 - mae: 0.0318 - val_loss: 0.0040 - val_mae: 0.0473 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0017 - mae: 0.0304 - val_loss: 0.0036 - val_mae: 0.0439 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0016 - mae: 0.0297 - val_loss: 0.0034 - val_mae: 0.0426 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0016 - mae: 0.0296 - val_loss: 0.0033 - val_mae: 0.0406 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0015 - mae: 0.0283 - val_loss: 0.0032 - val_mae: 0.0397 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0014 - mae: 0.0271 - val_loss: 0.0031 - val_mae: 0.0388 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0014 - mae: 0.0268 - val_loss: 0.0032 - val_mae: 0.0410 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0014 - mae: 0.0265 - val_loss: 0.0033 - val_mae: 0.0412 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0013 - mae: 0.0250 - val_loss: 0.0031 - val_mae: 0.0405 - learning_rate: 2.5000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0012 - mae: 0.0247 - val_loss: 0.0032 - val_mae: 0.0407 - learning_rate: 2.5000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0012 - mae: 0.0246 - val_loss: 0.0029 - val_mae: 0.0376 - learning_rate: 2.5000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0012 - mae: 0.0240 - val_loss: 0.0029 - val_mae: 0.0374 - learning_rate: 2.5000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0012 - mae: 0.0243 - val_loss: 0.0032 - val_mae: 0.0416 - learning_rate: 2.5000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0012 - mae: 0.0239 - val_loss: 0.0031 - val_mae: 0.0396 - learning_rate: 2.5000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0011 - mae: 0.0237 - val_loss: 0.0028 - val_mae: 0.0373 - learning_rate: 1.2500e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0011 - mae: 0.0228 - val_loss: 0.0029 - val_mae: 0.0387 - learning_rate: 1.2500e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0012 - mae: 0.0238 - val_loss: 0.0030 - val_mae: 0.0392 - learning_rate: 1.2500e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0011 - mae: 0.0230 - val_loss: 0.0028 - val_mae: 0.0376 - learning_rate: 6.2500e-05\n",
      "Epoch 26/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0011 - mae: 0.0225 - val_loss: 0.0027 - val_mae: 0.0368 - learning_rate: 6.2500e-05\n",
      "Epoch 27/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0011 - mae: 0.0224 - val_loss: 0.0028 - val_mae: 0.0371 - learning_rate: 6.2500e-05\n",
      "Epoch 28/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0011 - mae: 0.0224 - val_loss: 0.0027 - val_mae: 0.0368 - learning_rate: 6.2500e-05\n",
      "Epoch 29/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0011 - mae: 0.0224 - val_loss: 0.0026 - val_mae: 0.0360 - learning_rate: 6.2500e-05\n",
      "Epoch 30/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0010 - mae: 0.0220 - val_loss: 0.0028 - val_mae: 0.0381 - learning_rate: 3.1250e-05\n",
      "Epoch 31/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0010 - mae: 0.0221 - val_loss: 0.0029 - val_mae: 0.0388 - learning_rate: 3.1250e-05\n",
      "Epoch 32/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0010 - mae: 0.0218 - val_loss: 0.0029 - val_mae: 0.0379 - learning_rate: 3.1250e-05\n",
      "Epoch 33/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0010 - mae: 0.0218 - val_loss: 0.0029 - val_mae: 0.0381 - learning_rate: 1.5625e-05\n",
      "Epoch 34/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0010 - mae: 0.0219 - val_loss: 0.0028 - val_mae: 0.0375 - learning_rate: 1.5625e-05\n",
      "Epoch 35/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0010 - mae: 0.0217 - val_loss: 0.0028 - val_mae: 0.0369 - learning_rate: 1.5625e-05\n",
      "Epoch 36/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0010 - mae: 0.0215 - val_loss: 0.0029 - val_mae: 0.0385 - learning_rate: 7.8125e-06\n",
      "\u001b[1m171/171\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step    \n",
      "âœ… Mysore - tomato | MAE=104.6, RMSE=161.94, RÂ²=0.9254, MAPE=8.68%, Acc=91.32%\n",
      "\n",
      "ğŸš€ Processing: Mysore | wheat\n",
      "Epoch 1/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - loss: 0.1290 - mae: 0.1544 - val_loss: 0.0023 - val_mae: 0.0216 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0036 - mae: 0.0479 - val_loss: 0.0027 - val_mae: 0.0289 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0033 - mae: 0.0463 - val_loss: 0.0019 - val_mae: 0.0136 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0029 - mae: 0.0430 - val_loss: 0.0019 - val_mae: 0.0135 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0026 - mae: 0.0405 - val_loss: 0.0020 - val_mae: 0.0145 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0021 - mae: 0.0361 - val_loss: 0.0019 - val_mae: 0.0128 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0018 - mae: 0.0334 - val_loss: 0.0019 - val_mae: 0.0130 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0016 - mae: 0.0320 - val_loss: 0.0021 - val_mae: 0.0172 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0013 - mae: 0.0286 - val_loss: 0.0024 - val_mae: 0.0254 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0010 - mae: 0.0251 - val_loss: 0.0019 - val_mae: 0.0121 - learning_rate: 2.5000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 9.3478e-04 - mae: 0.0245 - val_loss: 0.0025 - val_mae: 0.0273 - learning_rate: 2.5000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 8.5705e-04 - mae: 0.0234 - val_loss: 0.0025 - val_mae: 0.0274 - learning_rate: 2.5000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 7.5162e-04 - mae: 0.0219 - val_loss: 0.0022 - val_mae: 0.0210 - learning_rate: 1.2500e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 7.3704e-04 - mae: 0.0217 - val_loss: 0.0023 - val_mae: 0.0226 - learning_rate: 1.2500e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 6.9976e-04 - mae: 0.0212 - val_loss: 0.0022 - val_mae: 0.0208 - learning_rate: 1.2500e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 6.7074e-04 - mae: 0.0205 - val_loss: 0.0021 - val_mae: 0.0179 - learning_rate: 6.2500e-05\n",
      "Epoch 17/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 6.5249e-04 - mae: 0.0204 - val_loss: 0.0023 - val_mae: 0.0221 - learning_rate: 6.2500e-05\n",
      "\u001b[1m170/170\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step   \n",
      "âœ… Mysore - wheat | MAE=373.72, RMSE=764.54, RÂ²=0.4356, MAPE=17.51%, Acc=82.49%\n",
      "\n",
      "ğŸš€ Processing: Raichur | onion\n",
      "Epoch 1/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 24ms/step - loss: 0.0540 - mae: 0.1233 - val_loss: 8.8430e-04 - val_mae: 0.0235 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0048 - mae: 0.0527 - val_loss: 7.7871e-04 - val_mae: 0.0215 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0036 - mae: 0.0455 - val_loss: 5.9275e-04 - val_mae: 0.0182 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0032 - mae: 0.0424 - val_loss: 4.7270e-04 - val_mae: 0.0149 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0026 - mae: 0.0389 - val_loss: 4.6357e-04 - val_mae: 0.0158 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0023 - mae: 0.0348 - val_loss: 4.7890e-04 - val_mae: 0.0159 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0019 - mae: 0.0320 - val_loss: 6.2964e-04 - val_mae: 0.0198 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0016 - mae: 0.0281 - val_loss: 4.5048e-04 - val_mae: 0.0156 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0015 - mae: 0.0268 - val_loss: 4.1112e-04 - val_mae: 0.0141 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0014 - mae: 0.0261 - val_loss: 4.1640e-04 - val_mae: 0.0141 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0014 - mae: 0.0249 - val_loss: 4.1103e-04 - val_mae: 0.0141 - learning_rate: 2.5000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0013 - mae: 0.0244 - val_loss: 4.2418e-04 - val_mae: 0.0149 - learning_rate: 2.5000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0013 - mae: 0.0237 - val_loss: 4.2362e-04 - val_mae: 0.0142 - learning_rate: 2.5000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0012 - mae: 0.0231 - val_loss: 4.3131e-04 - val_mae: 0.0151 - learning_rate: 1.2500e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0012 - mae: 0.0229 - val_loss: 4.9246e-04 - val_mae: 0.0168 - learning_rate: 1.2500e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0012 - mae: 0.0225 - val_loss: 5.1473e-04 - val_mae: 0.0173 - learning_rate: 1.2500e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0011 - mae: 0.0216 - val_loss: 4.0298e-04 - val_mae: 0.0137 - learning_rate: 6.2500e-05\n",
      "Epoch 18/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0011 - mae: 0.0218 - val_loss: 4.0558e-04 - val_mae: 0.0143 - learning_rate: 6.2500e-05\n",
      "Epoch 19/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0012 - mae: 0.0219 - val_loss: 3.9951e-04 - val_mae: 0.0141 - learning_rate: 6.2500e-05\n",
      "Epoch 20/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0012 - mae: 0.0216 - val_loss: 4.8268e-04 - val_mae: 0.0155 - learning_rate: 3.1250e-05\n",
      "Epoch 21/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0012 - mae: 0.0218 - val_loss: 4.4043e-04 - val_mae: 0.0146 - learning_rate: 3.1250e-05\n",
      "Epoch 22/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0011 - mae: 0.0214 - val_loss: 4.5390e-04 - val_mae: 0.0149 - learning_rate: 3.1250e-05\n",
      "Epoch 23/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0012 - mae: 0.0219 - val_loss: 4.3884e-04 - val_mae: 0.0145 - learning_rate: 1.5625e-05\n",
      "Epoch 24/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0011 - mae: 0.0213 - val_loss: 4.1706e-04 - val_mae: 0.0140 - learning_rate: 1.5625e-05\n",
      "Epoch 25/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0011 - mae: 0.0216 - val_loss: 4.5172e-04 - val_mae: 0.0148 - learning_rate: 1.5625e-05\n",
      "Epoch 26/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0011 - mae: 0.0216 - val_loss: 4.1925e-04 - val_mae: 0.0140 - learning_rate: 7.8125e-06\n",
      "\u001b[1m169/169\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step   \n",
      "âœ… Raichur - onion | MAE=134.2, RMSE=237.98, RÂ²=0.9104, MAPE=11.21%, Acc=88.79%\n",
      "\n",
      "ğŸš€ Processing: Raichur | tomato\n",
      "Epoch 1/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 78ms/step - loss: 0.6733 - mae: 0.5531 - val_loss: 0.0788 - val_mae: 0.2783 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0476 - mae: 0.1736 - val_loss: 0.0032 - val_mae: 0.0544 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0163 - mae: 0.1033 - val_loss: 0.0059 - val_mae: 0.0654 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0081 - mae: 0.0669 - val_loss: 0.0065 - val_mae: 0.0685 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0052 - mae: 0.0568 - val_loss: 0.0060 - val_mae: 0.0613 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0039 - mae: 0.0503 - val_loss: 0.0075 - val_mae: 0.0715 - learning_rate: 5.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0036 - mae: 0.0481 - val_loss: 0.0107 - val_mae: 0.0913 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0035 - mae: 0.0476 - val_loss: 0.0105 - val_mae: 0.0902 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m15/15\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0034 - mae: 0.0465 - val_loss: 0.0105 - val_mae: 0.0898 - learning_rate: 2.5000e-04\n",
      "\u001b[1m19/19\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step \n",
      "âœ… Raichur - tomato | MAE=113.95, RMSE=155.42, RÂ²=0.8614, MAPE=18.46%, Acc=81.54%\n",
      "\n",
      "ğŸš€ Processing: Raichur | wheat\n",
      "Epoch 1/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 18ms/step - loss: 0.0522 - mae: 0.1202 - val_loss: 0.0105 - val_mae: 0.0899 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0039 - mae: 0.0480 - val_loss: 0.0064 - val_mae: 0.0728 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0034 - mae: 0.0455 - val_loss: 0.0052 - val_mae: 0.0647 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0030 - mae: 0.0418 - val_loss: 0.0042 - val_mae: 0.0588 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0025 - mae: 0.0381 - val_loss: 0.0010 - val_mae: 0.0228 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0019 - mae: 0.0326 - val_loss: 0.0022 - val_mae: 0.0394 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0019 - mae: 0.0325 - val_loss: 0.0016 - val_mae: 0.0331 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0017 - mae: 0.0303 - val_loss: 0.0021 - val_mae: 0.0389 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0014 - mae: 0.0269 - val_loss: 0.0025 - val_mae: 0.0422 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0013 - mae: 0.0259 - val_loss: 0.0047 - val_mae: 0.0584 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0013 - mae: 0.0265 - val_loss: 0.0046 - val_mae: 0.0577 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m134/134\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0012 - mae: 0.0248 - val_loss: 0.0031 - val_mae: 0.0468 - learning_rate: 2.5000e-04\n",
      "\u001b[1m168/168\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step   \n",
      "âœ… Raichur - wheat | MAE=30.8, RMSE=47.5, RÂ²=0.9836, MAPE=1.77%, Acc=98.23%\n",
      "\n",
      "ğŸš€ Processing: Shimoga | capsicum\n",
      "Epoch 1/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 863ms/step - loss: 1.0453 - mae: 0.8801 - val_loss: 0.6265 - val_mae: 0.7912 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.8021 - mae: 0.8713 - val_loss: 0.1017 - val_mae: 0.3175 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0698 - mae: 0.2445 - val_loss: 0.1200 - val_mae: 0.3447 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.3221 - mae: 0.5500 - val_loss: 0.0886 - val_mae: 0.2952 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.2221 - mae: 0.4388 - val_loss: 0.0393 - val_mae: 0.1945 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0262 - mae: 0.1238 - val_loss: 0.3605 - val_mae: 0.5992 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.1472 - mae: 0.3709 - val_loss: 0.3940 - val_mae: 0.6265 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - loss: 0.1441 - mae: 0.3528 - val_loss: 0.1139 - val_mae: 0.3354 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0180 - mae: 0.1067 - val_loss: 0.0277 - val_mae: 0.1623 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0157 - mae: 0.1013 - val_loss: 0.0024 - val_mae: 0.0394 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.0321 - mae: 0.1526 - val_loss: 0.0016 - val_mae: 0.0339 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.0372 - mae: 0.1754 - val_loss: 0.0012 - val_mae: 0.0298 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.0224 - mae: 0.1321 - val_loss: 0.0077 - val_mae: 0.0811 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.0074 - mae: 0.0680 - val_loss: 0.0285 - val_mae: 0.1655 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0094 - mae: 0.0803 - val_loss: 0.0476 - val_mae: 0.2159 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.0155 - mae: 0.1069 - val_loss: 0.0478 - val_mae: 0.2164 - learning_rate: 2.5000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0162 - mae: 0.1113 - val_loss: 0.0383 - val_mae: 0.1931 - learning_rate: 2.5000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0131 - mae: 0.0975 - val_loss: 0.0248 - val_mae: 0.1545 - learning_rate: 2.5000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 0.0078 - mae: 0.0699 - val_loss: 0.0186 - val_mae: 0.1328 - learning_rate: 1.2500e-04\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step\n",
      "âœ… Shimoga - capsicum | MAE=87.63, RMSE=100.09, RÂ²=0.4728, MAPE=5.51%, Acc=94.49%\n",
      "\n",
      "ğŸš€ Processing: Shimoga | onion\n",
      "Epoch 1/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 18ms/step - loss: 0.2141 - mae: 0.2131 - val_loss: 0.0099 - val_mae: 0.0712 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0064 - mae: 0.0623 - val_loss: 0.0074 - val_mae: 0.0574 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0053 - mae: 0.0566 - val_loss: 0.0065 - val_mae: 0.0514 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0039 - mae: 0.0492 - val_loss: 0.0061 - val_mae: 0.0485 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0036 - mae: 0.0470 - val_loss: 0.0070 - val_mae: 0.0622 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0032 - mae: 0.0434 - val_loss: 0.0065 - val_mae: 0.0512 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0026 - mae: 0.0392 - val_loss: 0.0065 - val_mae: 0.0505 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0020 - mae: 0.0333 - val_loss: 0.0067 - val_mae: 0.0538 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0018 - mae: 0.0321 - val_loss: 0.0067 - val_mae: 0.0551 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0016 - mae: 0.0298 - val_loss: 0.0066 - val_mae: 0.0533 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0015 - mae: 0.0283 - val_loss: 0.0066 - val_mae: 0.0540 - learning_rate: 2.5000e-04\n",
      "\u001b[1m171/171\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step   \n",
      "âœ… Shimoga - onion | MAE=194.35, RMSE=395.62, RÂ²=0.8188, MAPE=47.47%, Acc=52.53%\n",
      "\n",
      "ğŸš€ Processing: Shimoga | tomato\n",
      "Epoch 1/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - loss: 0.0966 - mae: 0.1563 - val_loss: 0.0091 - val_mae: 0.0627 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0042 - mae: 0.0516 - val_loss: 0.0056 - val_mae: 0.0441 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0035 - mae: 0.0472 - val_loss: 0.0050 - val_mae: 0.0449 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0030 - mae: 0.0435 - val_loss: 0.0036 - val_mae: 0.0338 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0026 - mae: 0.0398 - val_loss: 0.0035 - val_mae: 0.0342 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0022 - mae: 0.0375 - val_loss: 0.0040 - val_mae: 0.0428 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0017 - mae: 0.0322 - val_loss: 0.0034 - val_mae: 0.0340 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0015 - mae: 0.0304 - val_loss: 0.0035 - val_mae: 0.0347 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0012 - mae: 0.0269 - val_loss: 0.0037 - val_mae: 0.0357 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 9.1366e-04 - mae: 0.0230 - val_loss: 0.0032 - val_mae: 0.0303 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 7.7233e-04 - mae: 0.0212 - val_loss: 0.0034 - val_mae: 0.0327 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 8.1486e-04 - mae: 0.0219 - val_loss: 0.0032 - val_mae: 0.0312 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 7.1720e-04 - mae: 0.0200 - val_loss: 0.0033 - val_mae: 0.0326 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 5.9184e-04 - mae: 0.0179 - val_loss: 0.0030 - val_mae: 0.0301 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 5.3290e-04 - mae: 0.0168 - val_loss: 0.0030 - val_mae: 0.0330 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 4.8862e-04 - mae: 0.0161 - val_loss: 0.0030 - val_mae: 0.0298 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 4.7333e-04 - mae: 0.0155 - val_loss: 0.0031 - val_mae: 0.0313 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 4.0945e-04 - mae: 0.0143 - val_loss: 0.0029 - val_mae: 0.0297 - learning_rate: 2.5000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 4.2283e-04 - mae: 0.0145 - val_loss: 0.0028 - val_mae: 0.0302 - learning_rate: 2.5000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 4.3725e-04 - mae: 0.0146 - val_loss: 0.0028 - val_mae: 0.0299 - learning_rate: 2.5000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 4.0432e-04 - mae: 0.0138 - val_loss: 0.0028 - val_mae: 0.0294 - learning_rate: 2.5000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 4.0262e-04 - mae: 0.0138 - val_loss: 0.0028 - val_mae: 0.0313 - learning_rate: 2.5000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 4.0734e-04 - mae: 0.0142 - val_loss: 0.0028 - val_mae: 0.0321 - learning_rate: 2.5000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 3.6616e-04 - mae: 0.0131 - val_loss: 0.0028 - val_mae: 0.0314 - learning_rate: 1.2500e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 3.6300e-04 - mae: 0.0129 - val_loss: 0.0028 - val_mae: 0.0321 - learning_rate: 1.2500e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 3.6308e-04 - mae: 0.0129 - val_loss: 0.0026 - val_mae: 0.0301 - learning_rate: 1.2500e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 3.6293e-04 - mae: 0.0129 - val_loss: 0.0027 - val_mae: 0.0307 - learning_rate: 1.2500e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 3.4826e-04 - mae: 0.0127 - val_loss: 0.0027 - val_mae: 0.0293 - learning_rate: 1.2500e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 3.5072e-04 - mae: 0.0126 - val_loss: 0.0027 - val_mae: 0.0298 - learning_rate: 1.2500e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 3.3537e-04 - mae: 0.0125 - val_loss: 0.0026 - val_mae: 0.0288 - learning_rate: 6.2500e-05\n",
      "Epoch 31/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 3.5969e-04 - mae: 0.0127 - val_loss: 0.0026 - val_mae: 0.0275 - learning_rate: 6.2500e-05\n",
      "Epoch 32/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 3.3565e-04 - mae: 0.0124 - val_loss: 0.0026 - val_mae: 0.0290 - learning_rate: 6.2500e-05\n",
      "Epoch 33/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 3.2796e-04 - mae: 0.0119 - val_loss: 0.0026 - val_mae: 0.0285 - learning_rate: 3.1250e-05\n",
      "Epoch 34/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 3.2575e-04 - mae: 0.0121 - val_loss: 0.0026 - val_mae: 0.0281 - learning_rate: 3.1250e-05\n",
      "Epoch 35/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 3.3095e-04 - mae: 0.0121 - val_loss: 0.0026 - val_mae: 0.0286 - learning_rate: 3.1250e-05\n",
      "Epoch 36/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 3.2253e-04 - mae: 0.0120 - val_loss: 0.0026 - val_mae: 0.0277 - learning_rate: 1.5625e-05\n",
      "Epoch 37/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 3.2274e-04 - mae: 0.0119 - val_loss: 0.0026 - val_mae: 0.0285 - learning_rate: 1.5625e-05\n",
      "Epoch 38/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 3.1489e-04 - mae: 0.0119 - val_loss: 0.0026 - val_mae: 0.0289 - learning_rate: 1.5625e-05\n",
      "Epoch 39/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 3.0406e-04 - mae: 0.0117 - val_loss: 0.0026 - val_mae: 0.0280 - learning_rate: 7.8125e-06\n",
      "Epoch 40/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 3.1391e-04 - mae: 0.0118 - val_loss: 0.0026 - val_mae: 0.0282 - learning_rate: 7.8125e-06\n",
      "Epoch 41/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 3.2344e-04 - mae: 0.0120 - val_loss: 0.0026 - val_mae: 0.0281 - learning_rate: 7.8125e-06\n",
      "Epoch 42/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 3.2272e-04 - mae: 0.0119 - val_loss: 0.0026 - val_mae: 0.0280 - learning_rate: 3.9063e-06\n",
      "Epoch 43/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 3.2641e-04 - mae: 0.0119 - val_loss: 0.0026 - val_mae: 0.0282 - learning_rate: 3.9063e-06\n",
      "Epoch 44/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 3.1145e-04 - mae: 0.0119 - val_loss: 0.0026 - val_mae: 0.0281 - learning_rate: 3.9063e-06\n",
      "Epoch 45/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 3.1920e-04 - mae: 0.0119 - val_loss: 0.0026 - val_mae: 0.0283 - learning_rate: 1.9531e-06\n",
      "Epoch 46/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 3.1184e-04 - mae: 0.0117 - val_loss: 0.0026 - val_mae: 0.0282 - learning_rate: 1.9531e-06\n",
      "Epoch 47/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 3.0810e-04 - mae: 0.0115 - val_loss: 0.0026 - val_mae: 0.0283 - learning_rate: 1.9531e-06\n",
      "Epoch 48/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 3.1633e-04 - mae: 0.0118 - val_loss: 0.0026 - val_mae: 0.0280 - learning_rate: 9.7656e-07\n",
      "Epoch 49/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 3.2815e-04 - mae: 0.0120 - val_loss: 0.0025 - val_mae: 0.0280 - learning_rate: 9.7656e-07\n",
      "Epoch 50/50\n",
      "\u001b[1m136/136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 3.0003e-04 - mae: 0.0116 - val_loss: 0.0025 - val_mae: 0.0281 - learning_rate: 9.7656e-07\n",
      "\u001b[1m170/170\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step    \n",
      "âœ… Shimoga - tomato | MAE=237.93, RMSE=462.43, RÂ²=0.7978, MAPE=44.71%, Acc=55.29%\n",
      "\n",
      "ğŸš€ Processing: Shimoga | wheat\n",
      "Epoch 1/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 18ms/step - loss: 0.0764 - mae: 0.1435 - val_loss: 0.0014 - val_mae: 0.0363 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0042 - mae: 0.0504 - val_loss: 2.2325e-04 - val_mae: 0.0121 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0033 - mae: 0.0431 - val_loss: 4.7322e-04 - val_mae: 0.0200 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0024 - mae: 0.0369 - val_loss: 3.6754e-04 - val_mae: 0.0172 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0022 - mae: 0.0344 - val_loss: 9.6153e-05 - val_mae: 0.0073 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.0016 - mae: 0.0293 - val_loss: 1.6876e-04 - val_mae: 0.0117 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0014 - mae: 0.0262 - val_loss: 2.7994e-04 - val_mae: 0.0146 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0013 - mae: 0.0251 - val_loss: 6.8176e-05 - val_mae: 0.0035 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0011 - mae: 0.0226 - val_loss: 7.8487e-05 - val_mae: 0.0041 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0010 - mae: 0.0218 - val_loss: 8.0178e-05 - val_mae: 0.0044 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0011 - mae: 0.0224 - val_loss: 1.1211e-04 - val_mae: 0.0088 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 8.7911e-04 - mae: 0.0194 - val_loss: 9.0954e-05 - val_mae: 0.0053 - learning_rate: 2.5000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 8.1988e-04 - mae: 0.0182 - val_loss: 1.2257e-04 - val_mae: 0.0076 - learning_rate: 2.5000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 8.5834e-04 - mae: 0.0188 - val_loss: 6.7372e-05 - val_mae: 0.0034 - learning_rate: 2.5000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 7.8409e-04 - mae: 0.0177 - val_loss: 6.5488e-05 - val_mae: 0.0037 - learning_rate: 1.2500e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 7.9348e-04 - mae: 0.0179 - val_loss: 6.5745e-05 - val_mae: 0.0037 - learning_rate: 1.2500e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 7.5957e-04 - mae: 0.0171 - val_loss: 6.6012e-05 - val_mae: 0.0043 - learning_rate: 1.2500e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 7.6068e-04 - mae: 0.0172 - val_loss: 6.4471e-05 - val_mae: 0.0033 - learning_rate: 6.2500e-05\n",
      "Epoch 19/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 7.1423e-04 - mae: 0.0168 - val_loss: 1.4825e-04 - val_mae: 0.0093 - learning_rate: 6.2500e-05\n",
      "Epoch 20/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 7.5425e-04 - mae: 0.0168 - val_loss: 9.2997e-05 - val_mae: 0.0057 - learning_rate: 6.2500e-05\n",
      "Epoch 21/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 7.0852e-04 - mae: 0.0164 - val_loss: 6.3158e-05 - val_mae: 0.0037 - learning_rate: 3.1250e-05\n",
      "Epoch 22/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 7.2331e-04 - mae: 0.0162 - val_loss: 6.5099e-05 - val_mae: 0.0043 - learning_rate: 3.1250e-05\n",
      "Epoch 23/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 7.2884e-04 - mae: 0.0163 - val_loss: 6.8146e-05 - val_mae: 0.0050 - learning_rate: 3.1250e-05\n",
      "Epoch 24/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 7.3521e-04 - mae: 0.0163 - val_loss: 6.5946e-05 - val_mae: 0.0045 - learning_rate: 1.5625e-05\n",
      "Epoch 25/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 6.9894e-04 - mae: 0.0163 - val_loss: 6.4564e-05 - val_mae: 0.0042 - learning_rate: 1.5625e-05\n",
      "Epoch 26/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 6.9461e-04 - mae: 0.0162 - val_loss: 7.6504e-05 - val_mae: 0.0061 - learning_rate: 1.5625e-05\n",
      "Epoch 27/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 7.0487e-04 - mae: 0.0162 - val_loss: 6.5722e-05 - val_mae: 0.0045 - learning_rate: 7.8125e-06\n",
      "Epoch 28/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 6.8386e-04 - mae: 0.0158 - val_loss: 6.6632e-05 - val_mae: 0.0047 - learning_rate: 7.8125e-06\n",
      "\u001b[1m171/171\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step   \n",
      "âœ… Shimoga - wheat | MAE=245.01, RMSE=592.48, RÂ²=0.2741, MAPE=11.15%, Acc=88.85%\n",
      "\n",
      "ğŸš€ Processing: Tumkur | onion\n",
      "Epoch 1/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 20ms/step - loss: 0.0688 - mae: 0.1372 - val_loss: 0.0508 - val_mae: 0.2059 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0036 - mae: 0.0471 - val_loss: 0.0042 - val_mae: 0.0409 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0029 - mae: 0.0419 - val_loss: 0.0037 - val_mae: 0.0371 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0026 - mae: 0.0396 - val_loss: 0.0035 - val_mae: 0.0356 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0021 - mae: 0.0354 - val_loss: 0.0046 - val_mae: 0.0420 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0018 - mae: 0.0330 - val_loss: 0.0045 - val_mae: 0.0426 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0015 - mae: 0.0300 - val_loss: 0.0052 - val_mae: 0.0454 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0014 - mae: 0.0282 - val_loss: 0.0052 - val_mae: 0.0472 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0012 - mae: 0.0260 - val_loss: 0.0065 - val_mae: 0.0524 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0011 - mae: 0.0253 - val_loss: 0.0057 - val_mae: 0.0486 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m135/135\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0010 - mae: 0.0241 - val_loss: 0.0065 - val_mae: 0.0518 - learning_rate: 2.5000e-04\n",
      "\u001b[1m169/169\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step   \n",
      "âœ… Tumkur - onion | MAE=188.2, RMSE=338.02, RÂ²=0.9652, MAPE=6.67%, Acc=93.33%\n",
      "\n",
      "ğŸš€ Processing: Tumkur | tomato\n",
      "Epoch 1/50\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 24ms/step - loss: 0.0974 - mae: 0.1650 - val_loss: 0.0522 - val_mae: 0.1853 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0053 - mae: 0.0579 - val_loss: 0.0300 - val_mae: 0.1342 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0049 - mae: 0.0561 - val_loss: 0.0116 - val_mae: 0.0833 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0042 - mae: 0.0517 - val_loss: 0.0128 - val_mae: 0.0925 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0035 - mae: 0.0470 - val_loss: 0.0200 - val_mae: 0.1170 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0027 - mae: 0.0414 - val_loss: 0.0084 - val_mae: 0.0661 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0019 - mae: 0.0347 - val_loss: 0.0121 - val_mae: 0.0897 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0013 - mae: 0.0284 - val_loss: 0.0129 - val_mae: 0.0869 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 8.8301e-04 - mae: 0.0230 - val_loss: 0.0131 - val_mae: 0.0824 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 6.6560e-04 - mae: 0.0195 - val_loss: 0.0139 - val_mae: 0.0862 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6.5164e-04 - mae: 0.0193 - val_loss: 0.0126 - val_mae: 0.0782 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 5.8138e-04 - mae: 0.0182 - val_loss: 0.0129 - val_mae: 0.0795 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 5.2312e-04 - mae: 0.0167 - val_loss: 0.0144 - val_mae: 0.0873 - learning_rate: 2.5000e-04\n",
      "\u001b[1m155/155\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step    \n",
      "âœ… Tumkur - tomato | MAE=248.21, RMSE=493.43, RÂ²=0.8879, MAPE=16.21%, Acc=83.79%\n",
      "\n",
      "ğŸš€ Processing: Tumkur | wheat\n",
      "Epoch 1/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 71ms/step - loss: 0.1274 - mae: 0.1746 - val_loss: 0.0160 - val_mae: 0.0861 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - loss: 0.0056 - mae: 0.0587 - val_loss: 0.0088 - val_mae: 0.0450 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0045 - mae: 0.0538 - val_loss: 0.0100 - val_mae: 0.0631 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0038 - mae: 0.0491 - val_loss: 0.0105 - val_mae: 0.0690 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0032 - mae: 0.0451 - val_loss: 0.0055 - val_mae: 0.0356 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0027 - mae: 0.0410 - val_loss: 0.0067 - val_mae: 0.0394 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0022 - mae: 0.0376 - val_loss: 0.0057 - val_mae: 0.0221 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0017 - mae: 0.0323 - val_loss: 0.0070 - val_mae: 0.0337 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0012 - mae: 0.0277 - val_loss: 0.0061 - val_mae: 0.0276 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 9.2541e-04 - mae: 0.0239 - val_loss: 0.0069 - val_mae: 0.0302 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 7.9496e-04 - mae: 0.0221 - val_loss: 0.0063 - val_mae: 0.0290 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m122/122\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 6.7155e-04 - mae: 0.0202 - val_loss: 0.0069 - val_mae: 0.0262 - learning_rate: 2.5000e-04\n",
      "\u001b[1m152/152\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step    \n",
      "âœ… Tumkur - wheat | MAE=177.54, RMSE=360.55, RÂ²=0.7925, MAPE=7.21%, Acc=92.79%\n",
      "\n",
      "ğŸš€ Processing: Udupi | capsicum\n",
      "Epoch 1/50\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 25ms/step - loss: 0.0653 - mae: 0.1523 - val_loss: 0.0134 - val_mae: 0.0849 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0066 - mae: 0.0632 - val_loss: 0.0180 - val_mae: 0.1079 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0064 - mae: 0.0625 - val_loss: 0.0128 - val_mae: 0.0854 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0051 - mae: 0.0547 - val_loss: 0.0118 - val_mae: 0.0793 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0046 - mae: 0.0516 - val_loss: 0.0116 - val_mae: 0.0806 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0039 - mae: 0.0478 - val_loss: 0.0106 - val_mae: 0.0720 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0039 - mae: 0.0473 - val_loss: 0.0110 - val_mae: 0.0738 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0035 - mae: 0.0443 - val_loss: 0.0105 - val_mae: 0.0720 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0031 - mae: 0.0411 - val_loss: 0.0102 - val_mae: 0.0710 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0028 - mae: 0.0387 - val_loss: 0.0101 - val_mae: 0.0705 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0024 - mae: 0.0355 - val_loss: 0.0100 - val_mae: 0.0712 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0023 - mae: 0.0348 - val_loss: 0.0100 - val_mae: 0.0699 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0023 - mae: 0.0346 - val_loss: 0.0101 - val_mae: 0.0703 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0018 - mae: 0.0284 - val_loss: 0.0099 - val_mae: 0.0693 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0017 - mae: 0.0270 - val_loss: 0.0097 - val_mae: 0.0686 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0016 - mae: 0.0265 - val_loss: 0.0095 - val_mae: 0.0674 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0017 - mae: 0.0280 - val_loss: 0.0099 - val_mae: 0.0691 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0016 - mae: 0.0261 - val_loss: 0.0095 - val_mae: 0.0676 - learning_rate: 5.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0016 - mae: 0.0270 - val_loss: 0.0096 - val_mae: 0.0683 - learning_rate: 5.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0014 - mae: 0.0249 - val_loss: 0.0093 - val_mae: 0.0668 - learning_rate: 2.5000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m124/124\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0014 - mae: 0.0241 - val_loss: 0.0092 - val_mae: 0.0664 - learning_rate: 2.5000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 90ms/step - loss: 0.1330 - mae: 0.1859 - val_loss: 0.0053 - val_mae: 0.0463 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 0.0074 - mae: 0.0663 - val_loss: 0.0052 - val_mae: 0.0482 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0059 - mae: 0.0594 - val_loss: 0.0057 - val_mae: 0.0507 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0056 - mae: 0.0572 - val_loss: 0.0044 - val_mae: 0.0411 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0046 - mae: 0.0522 - val_loss: 0.0040 - val_mae: 0.0397 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0038 - mae: 0.0472 - val_loss: 0.0041 - val_mae: 0.0428 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0033 - mae: 0.0431 - val_loss: 0.0039 - val_mae: 0.0391 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0025 - mae: 0.0379 - val_loss: 0.0058 - val_mae: 0.0550 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0023 - mae: 0.0351 - val_loss: 0.0038 - val_mae: 0.0353 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0020 - mae: 0.0331 - val_loss: 0.0042 - val_mae: 0.0397 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0019 - mae: 0.0323 - val_loss: 0.0047 - val_mae: 0.0449 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0019 - mae: 0.0320 - val_loss: 0.0039 - val_mae: 0.0357 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0017 - mae: 0.0299 - val_loss: 0.0039 - val_mae: 0.0350 - learning_rate: 2.5000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0017 - mae: 0.0297 - val_loss: 0.0039 - val_mae: 0.0352 - learning_rate: 2.5000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0017 - mae: 0.0298 - val_loss: 0.0041 - val_mae: 0.0365 - learning_rate: 2.5000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0015 - mae: 0.0278 - val_loss: 0.0041 - val_mae: 0.0353 - learning_rate: 1.2500e-04\n",
      "\u001b[1m171/171\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step\n",
      "âœ… Udupi - onion | MAE=213.42, RMSE=378.38, RÂ²=0.9153, MAPE=10.24%, Acc=89.76%\n",
      "\n",
      "ğŸš€ Processing: Udupi | tomato\n",
      "Epoch 1/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 18ms/step - loss: 0.1128 - mae: 0.1680 - val_loss: 0.0177 - val_mae: 0.0876 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0062 - mae: 0.0607 - val_loss: 0.0132 - val_mae: 0.0792 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0053 - mae: 0.0561 - val_loss: 0.0116 - val_mae: 0.0733 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0045 - mae: 0.0515 - val_loss: 0.0106 - val_mae: 0.0715 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m137/137\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0040 - mae: 0.0484 - val_loss: 0.0103 - val_mae: 0.0685 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m 25/137\u001b[0m \u001b[32mâ”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0045 - mae: 0.0514\n",
      "ğŸš€ Processing: Udupi | wheat\n",
      "Epoch 1/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 77ms/step - loss: 0.5281 - mae: 0.5429 - val_loss: 0.1073 - val_mae: 0.3251 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0522 - mae: 0.1830 - val_loss: 0.0102 - val_mae: 0.0917 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0220 - mae: 0.1206 - val_loss: 0.0668 - val_mae: 0.2559 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0144 - mae: 0.0966 - val_loss: 0.0247 - val_mae: 0.1552 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0075 - mae: 0.0700 - val_loss: 0.0111 - val_mae: 0.1048 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0059 - mae: 0.0607 - val_loss: 0.0116 - val_mae: 0.1079 - learning_rate: 5.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0054 - mae: 0.0575 - val_loss: 0.0048 - val_mae: 0.0692 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0056 - mae: 0.0601 - val_loss: 0.0024 - val_mae: 0.0484 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0057 - mae: 0.0605 - val_loss: 0.0034 - val_mae: 0.0583 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0052 - mae: 0.0580 - val_loss: 0.0053 - val_mae: 0.0730 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0056 - mae: 0.0591 - val_loss: 0.0028 - val_mae: 0.0532 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0049 - mae: 0.0556 - val_loss: 0.0046 - val_mae: 0.0680 - learning_rate: 2.5000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0046 - mae: 0.0546 - val_loss: 0.0069 - val_mae: 0.0829 - learning_rate: 2.5000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0048 - mae: 0.0552 - val_loss: 0.0074 - val_mae: 0.0860 - learning_rate: 2.5000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0045 - mae: 0.0545 - val_loss: 0.0076 - val_mae: 0.0872 - learning_rate: 1.2500e-04\n",
      "\u001b[1m28/28\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step  \n",
      "âœ… Udupi - wheat | MAE=46.56, RMSE=48.85, RÂ²=0.9405, MAPE=2.77%, Acc=97.23%\n",
      "\n",
      "ğŸ“Š All combinations done. Metrics saved to: tat_gqa_state_output\\tat_gqa_metrics.csv\n",
      "         District        Crop     MAE    RMSE    R2  MAPE(%)  Accuracy(%)\n",
      "0   All Districts  full_state   74.38   94.56  0.97     3.98        96.02\n",
      "1        Bagalkot       onion   93.83  166.65  0.95     8.20        91.80\n",
      "2        Bagalkot       wheat   54.88  116.29  0.95     2.60        97.40\n",
      "3       Bangalore    capsicum  283.65  403.52  0.85    10.23        89.77\n",
      "4       Bangalore       onion  128.00  208.02  0.95     7.07        92.93\n",
      "..            ...         ...     ...     ...   ...      ...          ...\n",
      "85         Tumkur       wheat  177.54  360.55  0.79     7.21        92.79\n",
      "86          Udupi    capsicum  218.29  444.62  0.91     5.50        94.50\n",
      "87          Udupi       onion  213.42  378.38  0.92    10.24        89.76\n",
      "88          Udupi      tomato  283.81  469.82  0.87    15.14        84.86\n",
      "89          Udupi       wheat   46.56   48.85  0.94     2.77        97.23\n",
      "\n",
      "[90 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os, gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks, optimizers\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "# -----------------------------\n",
    "# Config\n",
    "# -----------------------------\n",
    "input_file = \"dataset/Crop_price_forecast_Daily.xlsx\"\n",
    "output_folder = \"tat_gqa_state_output\"\n",
    "output_models = os.path.join(output_folder, \"models\")\n",
    "output_csv = os.path.join(output_folder, \"predictions\")\n",
    "output_graphs = os.path.join(output_folder, \"graphs\")\n",
    "metrics_file = os.path.join(output_folder, \"tat_gqa_metrics.csv\")\n",
    "\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "os.makedirs(output_models, exist_ok=True)\n",
    "os.makedirs(output_csv, exist_ok=True)\n",
    "os.makedirs(output_graphs, exist_ok=True)\n",
    "\n",
    "look_back = 30\n",
    "future_steps = 30\n",
    "epochs = 50\n",
    "batch_size = 32\n",
    "d_model = 64\n",
    "num_heads = 4\n",
    "group_size = 2   # number of heads per query group\n",
    "ff_dim = 128\n",
    "dropout_rate = 0.15\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# -----------------------------\n",
    "# Helper Functions\n",
    "# -----------------------------\n",
    "def parse_dates_safe(series):\n",
    "    try:\n",
    "        return pd.to_datetime(series, dayfirst=True)\n",
    "    except:\n",
    "        return pd.to_datetime(series, dayfirst=False)\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    mask = y_true != 0\n",
    "    return np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100 if np.any(mask) else np.nan\n",
    "\n",
    "def create_dataset(X, y, look_back):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - look_back):\n",
    "        Xs.append(X[i:i+look_back])\n",
    "        ys.append(y[i+look_back])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "# -----------------------------\n",
    "# Custom Grouped Query Attention\n",
    "# -----------------------------\n",
    "class GroupedQueryAttention(layers.Layer):\n",
    "    def __init__(self, d_model, num_heads=4, group_size=2, dropout=0.15):\n",
    "        super().__init__()\n",
    "        assert num_heads % group_size == 0, \"num_heads must be divisible by group_size\"\n",
    "        self.num_heads = num_heads\n",
    "        self.group_size = group_size\n",
    "        self.d_model = d_model\n",
    "        self.depth = d_model // num_heads\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.Wq = layers.Dense(d_model)\n",
    "        self.Wk = layers.Dense(d_model)\n",
    "        self.Wv = layers.Dense(d_model)\n",
    "        self.dense = layers.Dense(d_model)\n",
    "\n",
    "    def call(self, v, k, q):\n",
    "        B = tf.shape(q)[0]\n",
    "        Q = self.Wq(q)\n",
    "        K = self.Wk(k)\n",
    "        V = self.Wv(v)\n",
    "\n",
    "        Q = tf.reshape(Q, (B, -1, self.num_heads, self.depth))\n",
    "        K = tf.reshape(K, (B, -1, self.num_heads, self.depth))\n",
    "        V = tf.reshape(V, (B, -1, self.num_heads, self.depth))\n",
    "\n",
    "        # Group heads together for grouped queries\n",
    "        grouped_heads = self.num_heads // self.group_size\n",
    "        Q_groups = tf.reshape(Q, (B, -1, grouped_heads, self.group_size * self.depth))\n",
    "        K_groups = tf.reshape(K, (B, -1, grouped_heads, self.group_size * self.depth))\n",
    "        V_groups = tf.reshape(V, (B, -1, grouped_heads, self.group_size * self.depth))\n",
    "\n",
    "        attn_scores = tf.matmul(Q_groups, K_groups, transpose_b=True) / tf.math.sqrt(tf.cast(self.depth, tf.float32))\n",
    "        attn_weights = tf.nn.softmax(attn_scores, axis=-1)\n",
    "        attn_output = tf.matmul(attn_weights, V_groups)\n",
    "\n",
    "        attn_output = tf.reshape(attn_output, (B, -1, self.d_model))\n",
    "        output = self.dense(attn_output)\n",
    "        return output\n",
    "\n",
    "# -----------------------------\n",
    "# Build TAT + GQA model\n",
    "# -----------------------------\n",
    "def build_tat_gqa(input_shape, d_model=64, num_heads=4, group_size=2, ff_dim=128, dropout=0.15):\n",
    "    seq_len, num_features = input_shape\n",
    "    inputs = layers.Input(shape=(seq_len, num_features))\n",
    "\n",
    "    proj = layers.Dense(d_model)(inputs)\n",
    "    attn_out = GroupedQueryAttention(d_model, num_heads, group_size, dropout)(proj, proj, proj)\n",
    "    attn_out = layers.Dropout(dropout)(attn_out)\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(proj + attn_out)\n",
    "\n",
    "    ff = layers.Dense(ff_dim, activation='relu')(x)\n",
    "    ff = layers.Dense(d_model)(ff)\n",
    "    ff = layers.Dropout(dropout)(ff)\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x + ff)\n",
    "\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    outputs = layers.Dense(1)(x)\n",
    "\n",
    "    model = models.Model(inputs=inputs, outputs=outputs, name=\"TAT_GQA\")\n",
    "    model.compile(optimizer=optimizers.Adam(1e-3), loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# -----------------------------\n",
    "# Load Dataset\n",
    "# -----------------------------\n",
    "print(f\"ğŸ“˜ Loading dataset: {input_file}\")\n",
    "df = pd.read_excel(input_file)\n",
    "df.columns = [c.strip().lower() for c in df.columns]\n",
    "required = ['date', 'district', 'crop_type', 'average']\n",
    "if not all(c in df.columns for c in required):\n",
    "    raise ValueError(f\"Missing required columns: {required}\")\n",
    "\n",
    "df['date'] = parse_dates_safe(df['date'])\n",
    "df = df.sort_values('date')\n",
    "df = df.dropna(subset=['average'])\n",
    "\n",
    "# crop-level fallback\n",
    "crop_level_df = df.groupby(['crop_type', 'date'], as_index=False)['average'].mean()\n",
    "\n",
    "metrics_list = []\n",
    "\n",
    "# -----------------------------\n",
    "# Process each (district, crop)\n",
    "# -----------------------------\n",
    "for (district, crop), group in df.groupby(['district', 'crop_type']):\n",
    "    print(f\"\\nğŸš€ Processing: {district} | {crop}\")\n",
    "\n",
    "    data = group.groupby('date', as_index=False).mean(numeric_only=True)\n",
    "    data.set_index('date', inplace=True)\n",
    "    data = data.asfreq('D')\n",
    "    data['average'] = data['average'].ffill().bfill().fillna(data['average'].mean())\n",
    "\n",
    "    if len(data) < look_back + 1:\n",
    "        print(f\"âš ï¸ Not enough points for {district}-{crop}. Using crop-level fallback.\")\n",
    "        crop_ts = crop_level_df[crop_level_df['crop_type'] == crop].copy()\n",
    "        if crop_ts.empty:\n",
    "            crop_ts = df.groupby('date', as_index=False)['average'].mean()\n",
    "        crop_ts.set_index('date', inplace=True)\n",
    "        crop_ts = crop_ts.asfreq('D')\n",
    "        crop_ts['average'] = crop_ts['average'].ffill().bfill().fillna(crop_ts['average'].mean())\n",
    "        data = crop_ts.copy()\n",
    "\n",
    "    # Feature Engineering\n",
    "    data['Lag_1'] = data['average'].shift(1)\n",
    "    data['Lag_7'] = data['average'].shift(7)\n",
    "    data['MA_7'] = data['average'].rolling(7).mean()\n",
    "    data['MA_30'] = data['average'].rolling(30).mean()\n",
    "    data[['Lag_1', 'Lag_7', 'MA_7', 'MA_30']] = data[['Lag_1', 'Lag_7', 'MA_7', 'MA_30']].bfill().ffill()\n",
    "\n",
    "    feature_cols = ['average', 'Lag_1', 'Lag_7', 'MA_7', 'MA_30']\n",
    "    X_raw = data[feature_cols].values\n",
    "    y_raw = data['average'].values\n",
    "\n",
    "    scaler_X = MinMaxScaler()\n",
    "    scaler_y = MinMaxScaler()\n",
    "    X_scaled = scaler_X.fit_transform(X_raw)\n",
    "    y_scaled = scaler_y.fit_transform(y_raw.reshape(-1, 1)).flatten()\n",
    "\n",
    "    X, y = create_dataset(X_scaled, y_scaled, look_back)\n",
    "    if len(X) == 0:\n",
    "        print(f\"âš ï¸ No data window for {district}-{crop}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    n = len(X)\n",
    "    split = int(n * 0.8)\n",
    "    X_train, y_train = X[:split], y[:split]\n",
    "    X_val, y_val = X[split:], y[split:]\n",
    "\n",
    "    # Build Model\n",
    "    model = build_tat_gqa((look_back, X.shape[2]), d_model, num_heads, group_size, ff_dim, dropout_rate)\n",
    "    es = callbacks.EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True)\n",
    "    rl = callbacks.ReduceLROnPlateau(monitor='val_loss', patience=3, factor=0.5, verbose=0)\n",
    "\n",
    "    model.fit(X_train, y_train, validation_data=(X_val, y_val),\n",
    "              epochs=epochs, batch_size=batch_size, callbacks=[es, rl], verbose=1)\n",
    "\n",
    "    # Predictions\n",
    "    preds_scaled = model.predict(X).flatten()\n",
    "    preds = scaler_y.inverse_transform(preds_scaled.reshape(-1,1)).flatten()\n",
    "    preds_full = np.concatenate([np.full(look_back, np.nan), preds])\n",
    "\n",
    "    data_out = data.copy().reset_index()\n",
    "    data_out['Predicted'] = np.round(preds_full, 2)\n",
    "\n",
    "    # Metrics\n",
    "    mask = ~np.isnan(data_out['Predicted'])\n",
    "    y_true, y_pred = data_out.loc[mask, 'average'], data_out.loc[mask, 'Predicted']\n",
    "\n",
    "    mae = round(mean_absolute_error(y_true, y_pred), 2)\n",
    "    rmse = round(np.sqrt(mean_squared_error(y_true, y_pred)), 2)\n",
    "    r2 = round(r2_score(y_true, y_pred), 4)\n",
    "    mape_val = round(mean_absolute_percentage_error(y_true, y_pred), 2)\n",
    "    acc = round(100 - mape_val, 2)\n",
    "    metrics_list.append({'District': district, 'Crop': crop,\n",
    "                         'MAE': mae, 'RMSE': rmse, 'R2': r2,\n",
    "                         'MAPE(%)': mape_val, 'Accuracy(%)': acc})\n",
    "    print(f\"âœ… {district} - {crop} | MAE={mae}, RMSE={rmse}, RÂ²={r2}, MAPE={mape_val}%, Acc={acc}%\")\n",
    "\n",
    "    # Save predictions\n",
    "    data_out[['date', 'average', 'Predicted']].to_csv(\n",
    "        os.path.join(output_csv, f\"{district}_{crop}_tat_gqa_daily.csv\"), index=False, float_format=\"%.2f\"\n",
    "    )\n",
    "    model.save(os.path.join(output_models, f\"{district}_{crop}_tat_gqa.keras\"), include_optimizer=False)\n",
    "\n",
    "    # 30-day Future Forecast\n",
    "    last_window = X_scaled[-look_back:]\n",
    "    raw_last = X_raw[-look_back:]\n",
    "    future_preds = []\n",
    "    for _ in range(future_steps):\n",
    "        pred_scaled = model.predict(last_window[np.newaxis, ...], verbose=0).flatten()[0]\n",
    "        pred_unscaled = scaler_y.inverse_transform([[pred_scaled]])[0,0]\n",
    "        future_preds.append(round(pred_unscaled, 2))\n",
    "        new_row = np.array([pred_unscaled,\n",
    "                            raw_last[-1,0], raw_last[-7,0] if len(raw_last)>=7 else pred_unscaled,\n",
    "                            np.mean(raw_last[-7:,0]) if len(raw_last)>=7 else pred_unscaled,\n",
    "                            np.mean(raw_last[-30:,0]) if len(raw_last)>=30 else pred_unscaled])\n",
    "        raw_last = np.vstack([raw_last[1:], new_row])\n",
    "        last_window = scaler_X.transform(raw_last)\n",
    "\n",
    "    future_dates = pd.date_range(start=data_out['date'].iloc[-1] + pd.Timedelta(days=1),\n",
    "                                 periods=future_steps, freq='D')\n",
    "    future_df = pd.DataFrame({'Date': future_dates, 'Forecast': future_preds})\n",
    "    future_df.to_csv(os.path.join(output_csv, f\"{district}_{crop}_tat_gqa_future.csv\"),\n",
    "                     index=False, float_format=\"%.2f\")\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.plot(data_out['date'], data_out['average'], label='Actual', color='blue')\n",
    "    plt.plot(data_out['date'], data_out['Predicted'], label='Predicted (TAT-GQA)', color='red', linestyle='--')\n",
    "    plt.plot(future_df['Date'], future_df['Forecast'], label='Future (30d)', color='green', linestyle='dotted')\n",
    "    plt.title(f\"TAT-GQA Forecast - {district} | {crop}\")\n",
    "    plt.xlabel(\"Date\"); plt.ylabel(\"Average Price\")\n",
    "    plt.legend(); plt.grid(True); plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_graphs, f\"{district}_{crop}_tat_gqa_graph.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    del model, X, y, X_train, X_val\n",
    "    gc.collect()\n",
    "\n",
    "# Save metrics\n",
    "metrics_df = pd.DataFrame(metrics_list).round(2)\n",
    "metrics_df.to_csv(metrics_file, index=False)\n",
    "print(\"\\nğŸ“Š All combinations done. Metrics saved to:\", metrics_file)\n",
    "print(metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e2c050-4e05-4625-8fa7-33bbee04d4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TAT+HA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d457e6-d104-4928-864f-3a5d3f8abf71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Loading dataset: dataset/Crop_price_forecast_Daily.xlsx\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os, gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks, optimizers\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "# -----------------------------\n",
    "# Configuration\n",
    "# -----------------------------\n",
    "input_file = \"dataset/Crop_price_forecast_Daily.xlsx\"\n",
    "output_folder = \"tat_ha_state_output\"\n",
    "output_models = os.path.join(output_folder, \"models\")\n",
    "output_csv = os.path.join(output_folder, \"predictions\")\n",
    "output_graphs = os.path.join(output_folder, \"graphs\")\n",
    "metrics_file = os.path.join(output_folder, \"tat_ha_metrics.csv\")\n",
    "\n",
    "look_back = 30\n",
    "epochs = 50\n",
    "batch_size = 32\n",
    "d_model = 64\n",
    "num_heads = 4\n",
    "ff_dim = 128\n",
    "dropout_rate = 0.15\n",
    "future_steps = 30\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "for d in [output_folder, output_models, output_csv, output_graphs]:\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Helper functions\n",
    "# -----------------------------\n",
    "def parse_dates_safe(series):\n",
    "    try:\n",
    "        return pd.to_datetime(series, dayfirst=True)\n",
    "    except:\n",
    "        return pd.to_datetime(series, dayfirst=False)\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    mask = y_true != 0\n",
    "    return np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100 if np.any(mask) else np.nan\n",
    "\n",
    "def create_sequences(X, y, look_back):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - look_back):\n",
    "        Xs.append(X[i:i+look_back])\n",
    "        ys.append(y[i+look_back])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "# -----------------------------\n",
    "# âœ… Hierarchical Attention Block\n",
    "# -----------------------------\n",
    "class HierarchicalAttention(layers.Layer):\n",
    "    \"\"\"\n",
    "    Two-level attention:\n",
    "    - Feature-level attention: learns which features are most important per timestep.\n",
    "    - Temporal-level attention: learns which timesteps are most important overall.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, num_heads, dropout_rate=0.1, ff_dim=128):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        self.depth = d_model // num_heads\n",
    "\n",
    "        self.feature_dense = layers.Dense(d_model, activation='tanh')\n",
    "        self.feature_att = layers.Dense(1, activation=None)\n",
    "\n",
    "        self.temporal_att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=self.depth)\n",
    "        self.dropout = layers.Dropout(dropout_rate)\n",
    "        self.ffn = tf.keras.Sequential([\n",
    "            layers.Dense(ff_dim, activation='relu'),\n",
    "            layers.Dense(d_model)\n",
    "        ])\n",
    "        self.norm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        # x shape: (batch, time, features)\n",
    "        # Feature-level attention\n",
    "        feat_proj = self.feature_dense(x)  # (B, T, d_model)\n",
    "        feat_scores = self.feature_att(feat_proj)  # (B, T, 1)\n",
    "        feat_weights = tf.nn.softmax(feat_scores, axis=2)\n",
    "        feat_context = tf.reduce_sum(feat_proj * feat_weights, axis=2, keepdims=True)\n",
    "\n",
    "        # Temporal-level attention\n",
    "        temp_out = self.temporal_att(feat_context, feat_context)\n",
    "        temp_out = self.dropout(temp_out, training=training)\n",
    "        out1 = self.norm1(feat_context + temp_out)\n",
    "\n",
    "        # Feed-forward\n",
    "        ff_out = self.ffn(out1)\n",
    "        ff_out = self.dropout(ff_out, training=training)\n",
    "        out2 = self.norm2(out1 + ff_out)\n",
    "        return out2\n",
    "\n",
    "# -----------------------------\n",
    "# Build Model\n",
    "# -----------------------------\n",
    "def build_tat_ha(input_shape, d_model=64, num_heads=4, ff_dim=128, dropout=0.15):\n",
    "    seq_len, num_features = input_shape\n",
    "    inputs = layers.Input(shape=(seq_len, num_features))\n",
    "    x = layers.Dense(d_model)(inputs)\n",
    "\n",
    "    # Hierarchical Attention block\n",
    "    x = HierarchicalAttention(d_model, num_heads, dropout, ff_dim)(x)\n",
    "\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    outputs = layers.Dense(1)(x)\n",
    "\n",
    "    model = models.Model(inputs, outputs, name=\"TAT_HA\")\n",
    "    model.compile(optimizer=optimizers.Adam(1e-3), loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# -----------------------------\n",
    "# Load dataset\n",
    "# -----------------------------\n",
    "print(\"ğŸ“˜ Loading dataset:\", input_file)\n",
    "df = pd.read_excel(input_file)\n",
    "df.columns = [c.strip().lower() for c in df.columns]\n",
    "df['date'] = parse_dates_safe(df['date'])\n",
    "df = df.sort_values('date').dropna(subset=['average'])\n",
    "\n",
    "crop_level_df = df.groupby(['crop_type', 'date'], as_index=False)['average'].mean()\n",
    "\n",
    "metrics = []\n",
    "\n",
    "# -----------------------------\n",
    "# Training loop per district-crop\n",
    "# -----------------------------\n",
    "for (district, crop), group in df.groupby(['district', 'crop_type']):\n",
    "    print(f\"\\nğŸš€ Processing: {district} | {crop}\")\n",
    "\n",
    "    data = group.groupby('date', as_index=False).mean(numeric_only=True)\n",
    "    data.set_index('date', inplace=True)\n",
    "    data = data.asfreq('D')\n",
    "    data['average'] = data['average'].ffill().bfill().fillna(data['average'].mean())\n",
    "\n",
    "    if len(data) < look_back + 1:\n",
    "        print(\"âš ï¸ Sparse data â€” using crop-level fallback.\")\n",
    "        crop_ts = crop_level_df[crop_level_df['crop_type'] == crop].copy()\n",
    "        if crop_ts.empty:\n",
    "            crop_ts = df.groupby('date', as_index=False)['average'].mean()\n",
    "        crop_ts.set_index('date', inplace=True)\n",
    "        crop_ts = crop_ts.asfreq('D')\n",
    "        crop_ts['average'] = crop_ts['average'].ffill().bfill().fillna(crop_ts['average'].mean())\n",
    "        data = crop_ts.copy()\n",
    "\n",
    "    # Feature engineering\n",
    "    data['Lag_1'] = data['average'].shift(1)\n",
    "    data['Lag_7'] = data['average'].shift(7)\n",
    "    data['MA_7'] = data['average'].rolling(7).mean()\n",
    "    data['MA_30'] = data['average'].rolling(30).mean()\n",
    "    data[['Lag_1','Lag_7','MA_7','MA_30']] = data[['Lag_1','Lag_7','MA_7','MA_30']].bfill().ffill()\n",
    "\n",
    "    feature_cols = ['average','Lag_1','Lag_7','MA_7','MA_30']\n",
    "    raw_X, raw_y = data[feature_cols].values, data['average'].values\n",
    "\n",
    "    scaler_X, scaler_y = MinMaxScaler(), MinMaxScaler()\n",
    "    X_scaled = scaler_X.fit_transform(raw_X)\n",
    "    y_scaled = scaler_y.fit_transform(raw_y.reshape(-1,1)).flatten()\n",
    "\n",
    "    X, y = create_sequences(X_scaled, y_scaled, look_back)\n",
    "    if len(X) == 0:\n",
    "        print(\"âš ï¸ Insufficient data â€” skipping.\")\n",
    "        continue\n",
    "\n",
    "    n = len(X)\n",
    "    split = int(n * 0.8)\n",
    "    X_train, y_train, X_val, y_val = X[:split], y[:split], X[split:], y[split:]\n",
    "\n",
    "    model = build_tat_ha((look_back, X.shape[2]), d_model, num_heads, ff_dim, dropout_rate)\n",
    "    es = callbacks.EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True)\n",
    "    rl = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)\n",
    "\n",
    "    model.fit(X_train, y_train, validation_data=(X_val, y_val),\n",
    "              epochs=epochs, batch_size=batch_size, callbacks=[es, rl], verbose=1)\n",
    "\n",
    "    preds_scaled = model.predict(X).flatten()\n",
    "    preds = scaler_y.inverse_transform(preds_scaled.reshape(-1,1)).flatten()\n",
    "    preds_full = np.concatenate([np.full(look_back, np.nan), preds])\n",
    "    out_df = data.reset_index()\n",
    "    out_df['Predicted'] = np.round(preds_full, 2)\n",
    "\n",
    "    mask = ~np.isnan(out_df['Predicted'])\n",
    "    y_true, y_pred = out_df.loc[mask,'average'], out_df.loc[mask,'Predicted']\n",
    "    mae = round(mean_absolute_error(y_true, y_pred), 2)\n",
    "    rmse = round(np.sqrt(mean_squared_error(y_true, y_pred)), 2)\n",
    "    r2 = round(r2_score(y_true, y_pred), 4)\n",
    "    mape_v = round(mean_absolute_percentage_error(y_true, y_pred), 2)\n",
    "    acc = round(100 - mape_v, 2)\n",
    "\n",
    "    metrics.append({'District':district,'Crop':crop,'MAE':mae,'RMSE':rmse,'R2':r2,'MAPE(%)':mape_v,'Accuracy(%)':acc})\n",
    "    print(f\"âœ… {district} - {crop} | MAE={mae}, RMSE={rmse}, RÂ²={r2}, MAPE={mape_v}%, Acc={acc}%\")\n",
    "\n",
    "    # Save model, CSV, and graph\n",
    "    safe_name = f\"{district}_{crop}\".replace(\" \", \"_\").replace(\"/\", \"_\")\n",
    "    model.save(os.path.join(output_models, f\"{safe_name}_tat_ha.keras\"), include_optimizer=False)\n",
    "    out_df[['date','average','Predicted']].to_csv(os.path.join(output_csv, f\"{safe_name}_tat_ha_daily.csv\"), index=False, float_format=\"%.2f\")\n",
    "\n",
    "    # Plot graph\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.plot(out_df['date'], out_df['average'], label='Actual', color='blue')\n",
    "    plt.plot(out_df['date'], out_df['Predicted'], label='Predicted', color='red', linestyle='--')\n",
    "    plt.title(f\"TAT+HA Forecast: {district} | {crop}\")\n",
    "    plt.xlabel(\"Date\"); plt.ylabel(\"Average Price\")\n",
    "    plt.legend(); plt.grid(True); plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_graphs, f\"{safe_name}_tat_ha_graph.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    del model, X, y\n",
    "    gc.collect()\n",
    "\n",
    "# Save metrics\n",
    "metrics_df = pd.DataFrame(metrics).round(2)\n",
    "metrics_df.to_csv(metrics_file, index=False)\n",
    "print(\"\\nğŸ“Š All done. Metrics saved to:\", metrics_file)\n",
    "print(metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da29c97-1ef0-4119-be24-635a64298d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fed6f17-e1be-4278-ad02-49b7c58c5b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks, optimizers\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "# -----------------------------\n",
    "# Configuration\n",
    "# -----------------------------\n",
    "input_file = \"dataset/Crop_price_forecast_Daily.xlsx\"\n",
    "output_folder = \"lstm_state_output\"\n",
    "output_models = os.path.join(output_folder, \"models\")\n",
    "output_csv = os.path.join(output_folder, \"predictions\")\n",
    "output_graphs = os.path.join(output_folder, \"graphs\")\n",
    "metrics_file = os.path.join(output_folder, \"lstm_metrics.csv\")\n",
    "\n",
    "look_back = 30\n",
    "epochs = 50\n",
    "batch_size = 32\n",
    "future_steps = 30\n",
    "lstm_units = 128\n",
    "dropout_rate = 0.2\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "for d in [output_folder, output_models, output_csv, output_graphs]:\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Helper Functions\n",
    "# -----------------------------\n",
    "def parse_dates_safe(series):\n",
    "    try:\n",
    "        return pd.to_datetime(series, dayfirst=True)\n",
    "    except:\n",
    "        return pd.to_datetime(series, dayfirst=False)\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    mask = y_true != 0\n",
    "    return np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100 if np.any(mask) else np.nan\n",
    "\n",
    "def create_sequences(X, y, look_back):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - look_back):\n",
    "        Xs.append(X[i:i+look_back])\n",
    "        ys.append(y[i+look_back])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "# -----------------------------\n",
    "# LSTM Model Builder\n",
    "# -----------------------------\n",
    "def build_lstm(input_shape, units=128, dropout=0.2):\n",
    "    model = models.Sequential([\n",
    "        layers.LSTM(units, return_sequences=True, input_shape=input_shape),\n",
    "        layers.Dropout(dropout),\n",
    "        layers.LSTM(units // 2),\n",
    "        layers.Dropout(dropout),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=optimizers.Adam(1e-3), loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# -----------------------------\n",
    "# Load Dataset\n",
    "# -----------------------------\n",
    "print(\"ğŸ“˜ Loading dataset:\", input_file)\n",
    "df = pd.read_excel(input_file)\n",
    "df.columns = [c.strip().lower() for c in df.columns]\n",
    "df['date'] = parse_dates_safe(df['date'])\n",
    "df = df.sort_values('date').dropna(subset=['average'])\n",
    "\n",
    "crop_level_df = df.groupby(['crop_type', 'date'], as_index=False)['average'].mean()\n",
    "\n",
    "metrics = []\n",
    "\n",
    "# -----------------------------\n",
    "# Process per (District, Crop)\n",
    "# -----------------------------\n",
    "for (district, crop), group in df.groupby(['district', 'crop_type']):\n",
    "    print(f\"\\nğŸš€ Processing: {district} | {crop}\")\n",
    "\n",
    "    data = group.groupby('date', as_index=False).mean(numeric_only=True)\n",
    "    data.set_index('date', inplace=True)\n",
    "    data = data.asfreq('D')\n",
    "    data['average'] = data['average'].ffill().bfill().fillna(data['average'].mean())\n",
    "\n",
    "    # Fallback for sparse data\n",
    "    if len(data) < look_back + 1:\n",
    "        print(\"âš ï¸ Sparse data â€” using crop-level fallback.\")\n",
    "        crop_ts = crop_level_df[crop_level_df['crop_type'] == crop].copy()\n",
    "        if crop_ts.empty:\n",
    "            crop_ts = df.groupby('date', as_index=False)['average'].mean()\n",
    "        crop_ts.set_index('date', inplace=True)\n",
    "        crop_ts = crop_ts.asfreq('D')\n",
    "        crop_ts['average'] = crop_ts['average'].ffill().bfill().fillna(crop_ts['average'].mean())\n",
    "        data = crop_ts.copy()\n",
    "\n",
    "    # Feature Engineering\n",
    "    data['Lag_1'] = data['average'].shift(1)\n",
    "    data['Lag_7'] = data['average'].shift(7)\n",
    "    data['MA_7'] = data['average'].rolling(7).mean()\n",
    "    data['MA_30'] = data['average'].rolling(30).mean()\n",
    "    data[['Lag_1','Lag_7','MA_7','MA_30']] = data[['Lag_1','Lag_7','MA_7','MA_30']].bfill().ffill()\n",
    "\n",
    "    feature_cols = ['average','Lag_1','Lag_7','MA_7','MA_30']\n",
    "    raw_X, raw_y = data[feature_cols].values, data['average'].values\n",
    "\n",
    "    scaler_X, scaler_y = MinMaxScaler(), MinMaxScaler()\n",
    "    X_scaled = scaler_X.fit_transform(raw_X)\n",
    "    y_scaled = scaler_y.fit_transform(raw_y.reshape(-1,1)).flatten()\n",
    "\n",
    "    X, y = create_sequences(X_scaled, y_scaled, look_back)\n",
    "    if len(X) == 0:\n",
    "        print(\"âš ï¸ Insufficient data â€” skipping.\")\n",
    "        continue\n",
    "\n",
    "    n = len(X)\n",
    "    split = int(n * 0.8)\n",
    "    X_train, y_train, X_val, y_val = X[:split], y[:split], X[split:], y[split:]\n",
    "\n",
    "    # Build model\n",
    "    model = build_lstm((look_back, X.shape[2]), units=lstm_units, dropout=dropout_rate)\n",
    "    es = callbacks.EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True)\n",
    "    rl = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)\n",
    "\n",
    "    # Train model\n",
    "    model.fit(X_train, y_train, validation_data=(X_val, y_val),\n",
    "              epochs=epochs, batch_size=batch_size, callbacks=[es, rl], verbose=1)\n",
    "\n",
    "    # Predictions\n",
    "    preds_scaled = model.predict(X, batch_size=64).flatten()\n",
    "    preds = scaler_y.inverse_transform(preds_scaled.reshape(-1,1)).flatten()\n",
    "    preds_full = np.concatenate([np.full(look_back, np.nan), preds])\n",
    "    out_df = data.reset_index()\n",
    "    out_df['Predicted'] = np.round(preds_full, 2)\n",
    "\n",
    "    # Metrics\n",
    "    mask = ~np.isnan(out_df['Predicted'])\n",
    "    y_true, y_pred = out_df.loc[mask,'average'], out_df.loc[mask,'Predicted']\n",
    "    mae = round(mean_absolute_error(y_true, y_pred), 2)\n",
    "    rmse = round(np.sqrt(mean_squared_error(y_true, y_pred)), 2)\n",
    "    r2 = round(r2_score(y_true, y_pred), 4)\n",
    "    mape_v = round(mean_absolute_percentage_error(y_true, y_pred), 2)\n",
    "    acc = round(100 - mape_v, 2)\n",
    "    metrics.append({'District':district,'Crop':crop,'MAE':mae,'RMSE':rmse,'R2':r2,'MAPE(%)':mape_v,'Accuracy(%)':acc})\n",
    "    print(f\"âœ… {district} - {crop} | MAE={mae}, RMSE={rmse}, RÂ²={r2}, MAPE={mape_v}%, Acc={acc}%\")\n",
    "\n",
    "    # Save model and results\n",
    "    safe_name = f\"{district}_{crop}\".replace(\" \", \"_\").replace(\"/\", \"_\")\n",
    "    model.save(os.path.join(output_models, f\"{safe_name}_lstm.keras\"), include_optimizer=False)\n",
    "    out_df[['date','average','Predicted']].to_csv(os.path.join(output_csv, f\"{safe_name}_lstm_daily.csv\"), index=False, float_format=\"%.2f\")\n",
    "\n",
    "    # Future 30-day forecast\n",
    "    raw_window = raw_X[-look_back:].copy()\n",
    "    future_preds = []\n",
    "    for _ in range(future_steps):\n",
    "        scaled_window = scaler_X.transform(raw_window)\n",
    "        pred_scaled = model.predict(scaled_window[np.newaxis, ...], verbose=0).flatten()[0]\n",
    "        pred_unscaled = float(scaler_y.inverse_transform([[pred_scaled]])[0,0])\n",
    "        future_preds.append(round(pred_unscaled, 2))\n",
    "\n",
    "        # Generate next stepâ€™s features\n",
    "        lag1 = raw_window[-1,0] if len(raw_window) >= 1 else pred_unscaled\n",
    "        lag7 = raw_window[-7,0] if len(raw_window) >= 7 else np.mean(raw_window[:,0])\n",
    "        ma7 = np.mean(np.append(raw_window[:,0], pred_unscaled)[-7:])\n",
    "        ma30 = np.mean(np.append(raw_window[:,0], pred_unscaled)[-30:])\n",
    "        new_row = np.array([pred_unscaled, lag1, lag7, ma7, ma30], dtype='float32')\n",
    "        raw_window = np.vstack([raw_window[1:], new_row])\n",
    "\n",
    "    future_dates = pd.date_range(start=out_df['date'].iloc[-1] + pd.Timedelta(days=1),\n",
    "                                 periods=future_steps, freq='D')\n",
    "    future_df = pd.DataFrame({'date':future_dates, 'Forecast':future_preds})\n",
    "    future_df.to_csv(os.path.join(output_csv, f\"{safe_name}_lstm_future.csv\"), index=False, float_format=\"%.2f\")\n",
    "\n",
    "    # Plot graph\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.plot(out_df['date'], out_df['average'], label='Actual', color='blue')\n",
    "    plt.plot(out_df['date'], out_df['Predicted'], label='Predicted (LSTM)', color='red', linestyle='--')\n",
    "    plt.plot(future_df['date'], future_df['Forecast'], label='Future (30 days)', color='green', linestyle='dotted')\n",
    "    plt.title(f\"LSTM Forecast: {district} | {crop}\")\n",
    "    plt.xlabel(\"Date\"); plt.ylabel(\"Average Price\")\n",
    "    plt.legend(); plt.grid(True); plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_graphs, f\"{safe_name}_lstm_graph.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    del model, X, y\n",
    "    gc.collect()\n",
    "\n",
    "# Save metrics\n",
    "metrics_df = pd.DataFrame(metrics).round(2)\n",
    "metrics_df.to_csv(metrics_file, index=False)\n",
    "print(\"\\nğŸ“Š All done. Metrics saved to:\", metrics_file)\n",
    "print(metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472c50c3-32b5-4fe1-9efa-03784653a9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7c8ff5-440b-47a4-a84b-57576d579462",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks, optimizers\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "# -----------------------------\n",
    "# Configuration\n",
    "# -----------------------------\n",
    "input_file = \"dataset/Crop_price_forecast_Daily.xlsx\"\n",
    "output_folder = \"gru_state_output\"\n",
    "output_models = os.path.join(output_folder, \"models\")\n",
    "output_csv = os.path.join(output_folder, \"predictions\")\n",
    "output_graphs = os.path.join(output_folder, \"graphs\")\n",
    "metrics_file = os.path.join(output_folder, \"gru_metrics.csv\")\n",
    "\n",
    "look_back = 30\n",
    "epochs = 50\n",
    "batch_size = 32\n",
    "future_steps = 30\n",
    "gru_units = 128\n",
    "dropout_rate = 0.2\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "for d in [output_folder, output_models, output_csv, output_graphs]:\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Helper Functions\n",
    "# -----------------------------\n",
    "def parse_dates_safe(series):\n",
    "    try:\n",
    "        return pd.to_datetime(series, dayfirst=True)\n",
    "    except:\n",
    "        return pd.to_datetime(series, dayfirst=False)\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    mask = y_true != 0\n",
    "    return np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100 if np.any(mask) else np.nan\n",
    "\n",
    "def create_sequences(X, y, look_back):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - look_back):\n",
    "        Xs.append(X[i:i+look_back])\n",
    "        ys.append(y[i+look_back])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "# -----------------------------\n",
    "# GRU Model Builder\n",
    "# -----------------------------\n",
    "def build_gru(input_shape, units=128, dropout=0.2):\n",
    "    model = models.Sequential([\n",
    "        layers.GRU(units, return_sequences=True, input_shape=input_shape),\n",
    "        layers.Dropout(dropout),\n",
    "        layers.GRU(units // 2),\n",
    "        layers.Dropout(dropout),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=optimizers.Adam(1e-3), loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# -----------------------------\n",
    "# Load Dataset\n",
    "# -----------------------------\n",
    "print(\"ğŸ“˜ Loading dataset:\", input_file)\n",
    "df = pd.read_excel(input_file)\n",
    "df.columns = [c.strip().lower() for c in df.columns]\n",
    "df['date'] = parse_dates_safe(df['date'])\n",
    "df = df.sort_values('date').dropna(subset=['average'])\n",
    "\n",
    "# crop-level fallback if needed\n",
    "crop_level_df = df.groupby(['crop_type', 'date'], as_index=False)['average'].mean()\n",
    "\n",
    "metrics = []\n",
    "\n",
    "# -----------------------------\n",
    "# Process per (District, Crop)\n",
    "# -----------------------------\n",
    "for (district, crop), group in df.groupby(['district', 'crop_type']):\n",
    "    print(f\"\\nğŸš€ Processing: {district} | {crop}\")\n",
    "\n",
    "    # Prepare data for each (district, crop)\n",
    "    data = group.groupby('date', as_index=False).mean(numeric_only=True)\n",
    "    data.set_index('date', inplace=True)\n",
    "    data = data.asfreq('D')\n",
    "    data['average'] = data['average'].ffill().bfill().fillna(data['average'].mean())\n",
    "\n",
    "    # Fallback if data is too short\n",
    "    if len(data) < look_back + 1:\n",
    "        print(\"âš ï¸ Sparse data â€” using crop-level fallback.\")\n",
    "        crop_ts = crop_level_df[crop_level_df['crop_type'] == crop].copy()\n",
    "        if crop_ts.empty:\n",
    "            crop_ts = df.groupby('date', as_index=False)['average'].mean()\n",
    "        crop_ts.set_index('date', inplace=True)\n",
    "        crop_ts = crop_ts.asfreq('D')\n",
    "        crop_ts['average'] = crop_ts['average'].ffill().bfill().fillna(crop_ts['average'].mean())\n",
    "        data = crop_ts.copy()\n",
    "\n",
    "    # Feature Engineering\n",
    "    data['Lag_1'] = data['average'].shift(1)\n",
    "    data['Lag_7'] = data['average'].shift(7)\n",
    "    data['MA_7'] = data['average'].rolling(7).mean()\n",
    "    data['MA_30'] = data['average'].rolling(30).mean()\n",
    "    data[['Lag_1','Lag_7','MA_7','MA_30']] = data[['Lag_1','Lag_7','MA_7','MA_30']].bfill().ffill()\n",
    "\n",
    "    feature_cols = ['average','Lag_1','Lag_7','MA_7','MA_30']\n",
    "    raw_X, raw_y = data[feature_cols].values, data['average'].values\n",
    "\n",
    "    scaler_X, scaler_y = MinMaxScaler(), MinMaxScaler()\n",
    "    X_scaled = scaler_X.fit_transform(raw_X)\n",
    "    y_scaled = scaler_y.fit_transform(raw_y.reshape(-1,1)).flatten()\n",
    "\n",
    "    X, y = create_sequences(X_scaled, y_scaled, look_back)\n",
    "    if len(X) == 0:\n",
    "        print(\"âš ï¸ Insufficient data â€” skipping.\")\n",
    "        continue\n",
    "\n",
    "    n = len(X)\n",
    "    split = int(n * 0.8)\n",
    "    X_train, y_train, X_val, y_val = X[:split], y[:split], X[split:], y[split:]\n",
    "\n",
    "    # Build GRU model\n",
    "    model = build_gru((look_back, X.shape[2]), units=gru_units, dropout=dropout_rate)\n",
    "    es = callbacks.EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True)\n",
    "    rl = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)\n",
    "\n",
    "    # Train\n",
    "    model.fit(X_train, y_train, validation_data=(X_val, y_val),\n",
    "              epochs=epochs, batch_size=batch_size, callbacks=[es, rl], verbose=1)\n",
    "\n",
    "    # Predict\n",
    "    preds_scaled = model.predict(X, batch_size=64).flatten()\n",
    "    preds = scaler_y.inverse_transform(preds_scaled.reshape(-1,1)).flatten()\n",
    "    preds_full = np.concatenate([np.full(look_back, np.nan), preds])\n",
    "    out_df = data.reset_index()\n",
    "    out_df['Predicted'] = np.round(preds_full, 2)\n",
    "\n",
    "    # Metrics\n",
    "    mask = ~np.isnan(out_df['Predicted'])\n",
    "    y_true, y_pred = out_df.loc[mask,'average'], out_df.loc[mask,'Predicted']\n",
    "    mae = round(mean_absolute_error(y_true, y_pred), 2)\n",
    "    rmse = round(np.sqrt(mean_squared_error(y_true, y_pred)), 2)\n",
    "    r2 = round(r2_score(y_true, y_pred), 4)\n",
    "    mape_v = round(mean_absolute_percentage_error(y_true, y_pred), 2)\n",
    "    acc = round(100 - mape_v, 2)\n",
    "    metrics.append({'District':district,'Crop':crop,'MAE':mae,'RMSE':rmse,'R2':r2,'MAPE(%)':mape_v,'Accuracy(%)':acc})\n",
    "    print(f\"âœ… {district} - {crop} | MAE={mae}, RMSE={rmse}, RÂ²={r2}, MAPE={mape_v}%, Acc={acc}%\")\n",
    "\n",
    "    # Save model and results\n",
    "    safe_name = f\"{district}_{crop}\".replace(\" \", \"_\").replace(\"/\", \"_\")\n",
    "    model.save(os.path.join(output_models, f\"{safe_name}_gru.keras\"), include_optimizer=False)\n",
    "    out_df[['date','average','Predicted']].to_csv(os.path.join(output_csv, f\"{safe_name}_gru_daily.csv\"), index=False, float_format=\"%.2f\")\n",
    "\n",
    "    # Future 30-day forecast\n",
    "    raw_window = raw_X[-look_back:].copy()\n",
    "    future_preds = []\n",
    "    for _ in range(future_steps):\n",
    "        scaled_window = scaler_X.transform(raw_window)\n",
    "        pred_scaled = model.predict(scaled_window[np.newaxis, ...], verbose=0).flatten()[0]\n",
    "        pred_unscaled = float(scaler_y.inverse_transform([[pred_scaled]])[0,0])\n",
    "        future_preds.append(round(pred_unscaled, 2))\n",
    "\n",
    "        # Build next features\n",
    "        lag1 = raw_window[-1,0] if len(raw_window) >= 1 else pred_unscaled\n",
    "        lag7 = raw_window[-7,0] if len(raw_window) >= 7 else np.mean(raw_window[:,0])\n",
    "        ma7 = np.mean(np.append(raw_window[:,0], pred_unscaled)[-7:])\n",
    "        ma30 = np.mean(np.append(raw_window[:,0], pred_unscaled)[-30:])\n",
    "        new_row = np.array([pred_unscaled, lag1, lag7, ma7, ma30], dtype='float32')\n",
    "        raw_window = np.vstack([raw_window[1:], new_row])\n",
    "\n",
    "    future_dates = pd.date_range(start=out_df['date'].iloc[-1] + pd.Timedelta(days=1),\n",
    "                                 periods=future_steps, freq='D')\n",
    "    future_df = pd.DataFrame({'date':future_dates, 'Forecast':future_preds})\n",
    "    future_df.to_csv(os.path.join(output_csv, f\"{safe_name}_gru_future.csv\"), index=False, float_format=\"%.2f\")\n",
    "\n",
    "    # Plot graph\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.plot(out_df['date'], out_df['average'], label='Actual', color='blue')\n",
    "    plt.plot(out_df['date'], out_df['Predicted'], label='Predicted (GRU)', color='red', linestyle='--')\n",
    "    plt.plot(future_df['date'], future_df['Forecast'], label='Future (30 days)', color='green', linestyle='dotted')\n",
    "    plt.title(f\"GRU Forecast: {district} | {crop}\")\n",
    "    plt.xlabel(\"Date\"); plt.ylabel(\"Average Price\")\n",
    "    plt.legend(); plt.grid(True); plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_graphs, f\"{safe_name}_gru_graph.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    del model, X, y\n",
    "    gc.collect()\n",
    "\n",
    "# Save metrics\n",
    "metrics_df = pd.DataFrame(metrics).round(2)\n",
    "metrics_df.to_csv(metrics_file, index=False)\n",
    "print(\"\\nğŸ“Š All done. Metrics saved to:\", metrics_file)\n",
    "print(metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42db3ab2-7e25-4b3a-8773-ea22e2d6a193",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
