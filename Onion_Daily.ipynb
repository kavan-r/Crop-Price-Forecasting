{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269d1fb4-1fef-48c0-beff-f6e854d17c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3d21fb8-3916-4f4b-99c3-e70512d2e462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: prophet in c:\\users\\ravik\\appdata\\roaming\\python\\python312\\site-packages (1.1.7)\n",
      "Requirement already satisfied: cmdstanpy>=1.0.4 in c:\\users\\ravik\\appdata\\roaming\\python\\python312\\site-packages (from prophet) (1.2.5)\n",
      "Requirement already satisfied: numpy>=1.15.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from prophet) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from prophet) (3.9.2)\n",
      "Requirement already satisfied: pandas>=1.0.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from prophet) (2.2.2)\n",
      "Requirement already satisfied: holidays<1,>=0.25 in c:\\users\\ravik\\appdata\\roaming\\python\\python312\\site-packages (from prophet) (0.81)\n",
      "Requirement already satisfied: tqdm>=4.36.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from prophet) (4.66.5)\n",
      "Requirement already satisfied: importlib_resources in c:\\users\\ravik\\appdata\\roaming\\python\\python312\\site-packages (from prophet) (6.5.2)\n",
      "Requirement already satisfied: stanio<2.0.0,>=0.4.0 in c:\\users\\ravik\\appdata\\roaming\\python\\python312\\site-packages (from cmdstanpy>=1.0.4->prophet) (0.5.1)\n",
      "Requirement already satisfied: python-dateutil in c:\\programdata\\anaconda3\\lib\\site-packages (from holidays<1,>=0.25->prophet) (2.9.0.post0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (3.1.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=1.0.4->prophet) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=1.0.4->prophet) (2023.3)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm>=4.36.1->prophet) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil->holidays<1,>=0.25->prophet) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e8e7e39-14d9-4477-8840-00dff9f21e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Processing: onion_Bagalkot_daily.csv ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:28:28 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:28:42 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for onion_Bagalkot_daily.csv:\n",
      "  MAE        : 642.4\n",
      "  RMSE       : 848.76\n",
      "  R²         : -0.3121\n",
      "  MAPE(%)    : 67.88\n",
      "  Accuracy(%) : 32.12\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: prophet_output_csv\\onion_Bagalkot_daily_prophet_updated.csv\n",
      "========== Processing: onion_Bangalore_daily.csv ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:28:45 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:29:11 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for onion_Bangalore_daily.csv:\n",
      "  MAE        : 571.46\n",
      "  RMSE       : 824.89\n",
      "  R²         : 0.4287\n",
      "  MAPE(%)    : 46.04\n",
      "  Accuracy(%) : 53.96\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: prophet_output_csv\\onion_Bangalore_daily_prophet_updated.csv\n",
      "========== Processing: onion_Belgaum_daily.csv ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:29:16 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:29:26 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for onion_Belgaum_daily.csv:\n",
      "  MAE        : 441.73\n",
      "  RMSE       : 728.72\n",
      "  R²         : 0.5068\n",
      "  MAPE(%)    : 31.59\n",
      "  Accuracy(%) : 68.41\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: prophet_output_csv\\onion_Belgaum_daily_prophet_updated.csv\n",
      "========== Processing: onion_Bellary_daily.csv ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:29:31 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:29:43 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for onion_Bellary_daily.csv:\n",
      "  MAE        : 254.65\n",
      "  RMSE       : 414.62\n",
      "  R²         : 0.4986\n",
      "  MAPE(%)    : 20.08\n",
      "  Accuracy(%) : 79.92\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: prophet_output_csv\\onion_Bellary_daily_prophet_updated.csv\n",
      "========== Processing: onion_Bidar_daily.csv ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:29:47 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:29:55 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for onion_Bidar_daily.csv:\n",
      "  MAE        : 348.13\n",
      "  RMSE       : 436.15\n",
      "  R²         : -0.5419\n",
      "  MAPE(%)    : 46.6\n",
      "  Accuracy(%) : 53.4\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: prophet_output_csv\\onion_Bidar_daily_prophet_updated.csv\n",
      "========== Processing: onion_Bijapur_daily.csv ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:30:00 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:30:09 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for onion_Bijapur_daily.csv:\n",
      "  MAE        : 494.8\n",
      "  RMSE       : 685.14\n",
      "  R²         : 0.292\n",
      "  MAPE(%)    : 58.67\n",
      "  Accuracy(%) : 41.33\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: prophet_output_csv\\onion_Bijapur_daily_prophet_updated.csv\n",
      "========== Processing: onion_Chamrajnagar_daily.csv ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:30:14 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:30:57 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for onion_Chamrajnagar_daily.csv:\n",
      "  MAE        : 806.58\n",
      "  RMSE       : 1223.68\n",
      "  R²         : -1.1309\n",
      "  MAPE(%)    : 109.61\n",
      "  Accuracy(%) : -9.61\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: prophet_output_csv\\onion_Chamrajnagar_daily_prophet_updated.csv\n",
      "========== Processing: onion_Chikmagalur_daily.csv ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:31:05 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:31:43 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for onion_Chikmagalur_daily.csv:\n",
      "  MAE        : 646.61\n",
      "  RMSE       : 839.76\n",
      "  R²         : 0.0824\n",
      "  MAPE(%)    : 49.61\n",
      "  Accuracy(%) : 50.39\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: prophet_output_csv\\onion_Chikmagalur_daily_prophet_updated.csv\n",
      "========== Processing: onion_Chitradurga_daily.csv ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:31:50 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:31:53 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for onion_Chitradurga_daily.csv:\n",
      "  MAE        : 547.75\n",
      "  RMSE       : 703.94\n",
      "  R²         : 0.2659\n",
      "  MAPE(%)    : 37.19\n",
      "  Accuracy(%) : 62.81\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: prophet_output_csv\\onion_Chitradurga_daily_prophet_updated.csv\n",
      "========== Processing: onion_Davangere_daily.csv ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:31:59 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:32:17 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for onion_Davangere_daily.csv:\n",
      "  MAE        : 411.07\n",
      "  RMSE       : 642.46\n",
      "  R²         : 0.3322\n",
      "  MAPE(%)    : 33.09\n",
      "  Accuracy(%) : 66.91\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: prophet_output_csv\\onion_Davangere_daily_prophet_updated.csv\n",
      "========== Processing: onion_Dharwad_daily.csv ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:32:22 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:32:30 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for onion_Dharwad_daily.csv:\n",
      "  MAE        : 338.25\n",
      "  RMSE       : 492.53\n",
      "  R²         : 0.5892\n",
      "  MAPE(%)    : 30.57\n",
      "  Accuracy(%) : 69.43\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: prophet_output_csv\\onion_Dharwad_daily_prophet_updated.csv\n",
      "========== Processing: onion_Gadag_daily.csv ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:32:35 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:32:43 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for onion_Gadag_daily.csv:\n",
      "  MAE        : 253.01\n",
      "  RMSE       : 363.47\n",
      "  R²         : 0.6761\n",
      "  MAPE(%)    : 22.47\n",
      "  Accuracy(%) : 77.53\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: prophet_output_csv\\onion_Gadag_daily_prophet_updated.csv\n",
      "========== Processing: onion_Hassan_daily.csv ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:32:49 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:33:46 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for onion_Hassan_daily.csv:\n",
      "  MAE        : 703.87\n",
      "  RMSE       : 1079.77\n",
      "  R²         : 0.0884\n",
      "  MAPE(%)    : 71.58\n",
      "  Accuracy(%) : 28.42\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: prophet_output_csv\\onion_Hassan_daily_prophet_updated.csv\n",
      "========== Processing: onion_Haveri_daily.csv ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:33:52 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:34:10 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for onion_Haveri_daily.csv:\n",
      "  MAE        : 282.6\n",
      "  RMSE       : 374.4\n",
      "  R²         : 0.6177\n",
      "  MAPE(%)    : 19.09\n",
      "  Accuracy(%) : 80.91\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: prophet_output_csv\\onion_Haveri_daily_prophet_updated.csv\n",
      "========== Processing: onion_Kolar_daily.csv ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:34:19 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:35:47 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for onion_Kolar_daily.csv:\n",
      "  MAE        : 1046.48\n",
      "  RMSE       : 1225.22\n",
      "  R²         : -0.5989\n",
      "  MAPE(%)    : 83.62\n",
      "  Accuracy(%) : 16.38\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: prophet_output_csv\\onion_Kolar_daily_prophet_updated.csv\n",
      "========== Processing: onion_MadikeriKodagu_daily.csv ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:35:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:36:09 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for onion_MadikeriKodagu_daily.csv:\n",
      "  MAE        : 361.37\n",
      "  RMSE       : 464.35\n",
      "  R²         : 0.1009\n",
      "  MAPE(%)    : 30.18\n",
      "  Accuracy(%) : 69.82\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: prophet_output_csv\\onion_MadikeriKodagu_daily_prophet_updated.csv\n",
      "========== Processing: onion_Mandya_daily.csv ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:36:15 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:36:32 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for onion_Mandya_daily.csv:\n",
      "  MAE        : 565.46\n",
      "  RMSE       : 665.12\n",
      "  R²         : 0.184\n",
      "  MAPE(%)    : 74.75\n",
      "  Accuracy(%) : 25.25\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: prophet_output_csv\\onion_Mandya_daily_prophet_updated.csv\n",
      "========== Processing: onion_MangaloreDakshin_Kannad_daily.csv ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:36:37 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:36:43 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for onion_MangaloreDakshin_Kannad_daily.csv:\n",
      "  MAE        : 254.12\n",
      "  RMSE       : 350.68\n",
      "  R²         : 0.8212\n",
      "  MAPE(%)    : 14.9\n",
      "  Accuracy(%) : 85.1\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: prophet_output_csv\\onion_MangaloreDakshin_Kannad_daily_prophet_updated.csv\n",
      "========== Processing: onion_Mysore_daily.csv ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:36:49 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:37:29 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for onion_Mysore_daily.csv:\n",
      "  MAE        : 555.22\n",
      "  RMSE       : 846.0\n",
      "  R²         : 0.3405\n",
      "  MAPE(%)    : 40.0\n",
      "  Accuracy(%) : 60.0\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: prophet_output_csv\\onion_Mysore_daily_prophet_updated.csv\n",
      "========== Processing: onion_Raichur_daily.csv ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:37:34 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:37:46 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for onion_Raichur_daily.csv:\n",
      "  MAE        : 344.52\n",
      "  RMSE       : 510.02\n",
      "  R²         : 0.5823\n",
      "  MAPE(%)    : 34.0\n",
      "  Accuracy(%) : 66.0\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: prophet_output_csv\\onion_Raichur_daily_prophet_updated.csv\n",
      "========== Processing: onion_Shimoga_daily.csv ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:37:51 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:38:06 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for onion_Shimoga_daily.csv:\n",
      "  MAE        : 577.69\n",
      "  RMSE       : 842.86\n",
      "  R²         : -0.5081\n",
      "  MAPE(%)    : 55.01\n",
      "  Accuracy(%) : 44.99\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: prophet_output_csv\\onion_Shimoga_daily_prophet_updated.csv\n",
      "========== Processing: onion_Tumkur_daily.csv ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:38:13 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:38:26 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for onion_Tumkur_daily.csv:\n",
      "  MAE        : 1198.4\n",
      "  RMSE       : 2070.52\n",
      "  R²         : 0.5927\n",
      "  MAPE(%)    : 35.59\n",
      "  Accuracy(%) : 64.41\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: prophet_output_csv\\onion_Tumkur_daily_prophet_updated.csv\n",
      "========== Processing: onion_Udupi_daily.csv ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:38:31 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:38:41 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for onion_Udupi_daily.csv:\n",
      "  MAE        : 1024.61\n",
      "  RMSE       : 1374.78\n",
      "  R²         : -0.4535\n",
      "  MAPE(%)    : 71.08\n",
      "  Accuracy(%) : 28.92\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: prophet_output_csv\\onion_Udupi_daily_prophet_updated.csv\n",
      "✅ Multiple CSVs processed! Metrics saved to prophet_metrics.csv. Models, updated CSVs, and graphs saved in respective folders.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from prophet import Prophet\n",
    "import joblib\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "# -----------------------------\n",
    "# Suppress warnings\n",
    "# -----------------------------\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# -----------------------------\n",
    "# Paths\n",
    "# -----------------------------\n",
    "input_folder = \"dataset\"\n",
    "output_models = \"prophet_output_models\"\n",
    "output_csv = \"prophet_output_csv\"\n",
    "output_metrics_csv = \"prophet_metrics.csv\"\n",
    "output_graphs = \"prophet_output_graphs\"\n",
    "\n",
    "os.makedirs(output_models, exist_ok=True)\n",
    "os.makedirs(output_csv, exist_ok=True)\n",
    "os.makedirs(output_graphs, exist_ok=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Prepare metrics storage\n",
    "# -----------------------------\n",
    "metrics_list = []\n",
    "\n",
    "# -----------------------------\n",
    "# Function to robustly parse dates (all formats)\n",
    "# -----------------------------\n",
    "def parse_dates_safe(date_series):\n",
    "    return pd.to_datetime(date_series, errors='coerce', dayfirst=False, infer_datetime_format=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Function to calculate MAPE safely\n",
    "# -----------------------------\n",
    "def mean_absolute_percentage_error_safe(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    # Avoid division by zero\n",
    "    mask = y_true != 0\n",
    "    if mask.sum() == 0:\n",
    "        return np.nan\n",
    "    mape = np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100\n",
    "    # Handle any remaining inf or NaN\n",
    "    if np.isnan(mape) or np.isinf(mape):\n",
    "        return np.nan\n",
    "    return mape\n",
    "\n",
    "# -----------------------------\n",
    "# Process each CSV\n",
    "# -----------------------------\n",
    "for file in os.listdir(input_folder):\n",
    "    if file.endswith(\".csv\"):\n",
    "        file_path = os.path.join(input_folder, file)\n",
    "        print(f\"========== Processing: {file} ==========\")\n",
    "\n",
    "        # Load CSV\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # -----------------------------\n",
    "        # Convert 'Date' column safely\n",
    "        # -----------------------------\n",
    "        df['Date'] = parse_dates_safe(df['Date'])\n",
    "        df = df.sort_values('Date')\n",
    "\n",
    "        # Drop rows with NaT after conversion\n",
    "        df = df.dropna(subset=['Date'])\n",
    "        if df.empty:\n",
    "            print(f\"⚠️ No valid dates found in {file}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        # -----------------------------\n",
    "        # Handle missing values in Average Price\n",
    "        # -----------------------------\n",
    "        if df['Average Price'].isna().sum() > 0:\n",
    "            mean_value = df['Average Price'].mean()\n",
    "            df['Average Price'].fillna(mean_value, inplace=True)\n",
    "            print(f\"Filled {df['Average Price'].isna().sum()} missing values with mean: {mean_value:.2f}\")\n",
    "\n",
    "        # Round actual values\n",
    "        df['Average Price'] = df['Average Price'].round(2)\n",
    "\n",
    "        # -----------------------------\n",
    "        # Prepare data for Prophet\n",
    "        # -----------------------------\n",
    "        prophet_df = df[['Date', 'Average Price']].rename(columns={'Date': 'ds', 'Average Price': 'y'})\n",
    "\n",
    "        # Skip files with less than 2 valid rows (Prophet requirement)\n",
    "        if len(prophet_df) < 2:\n",
    "            print(f\"⚠️ Not enough data points in {file} for Prophet. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        # Build and fit Prophet model\n",
    "        model = Prophet(daily_seasonality=True)\n",
    "        model.fit(prophet_df)\n",
    "\n",
    "        # Predict for existing dates\n",
    "        future = model.make_future_dataframe(periods=0)\n",
    "        forecast = model.predict(future)\n",
    "        df['Predicted'] = forecast['yhat']  # keep full precision for metrics\n",
    "\n",
    "        # -----------------------------\n",
    "        # Handle NaNs in predictions for metrics\n",
    "        # -----------------------------\n",
    "        metrics_df = df.dropna(subset=['Average Price', 'Predicted'])\n",
    "        y_true = metrics_df['Average Price'].values\n",
    "        y_pred = metrics_df['Predicted'].values\n",
    "\n",
    "        # Round predictions for saving\n",
    "        df['Predicted'] = df['Predicted'].round(2)\n",
    "\n",
    "        # Rename Average Price to Actual in main df for plotting\n",
    "        df.rename(columns={'Average Price': 'Actual'}, inplace=True)\n",
    "\n",
    "        # -----------------------------\n",
    "        # Calculate metrics\n",
    "        # -----------------------------\n",
    "        mae = round(mean_absolute_error(y_true, y_pred), 2)\n",
    "        rmse = round(np.sqrt(mean_squared_error(y_true, y_pred)), 2)\n",
    "        r2 = round(r2_score(y_true, y_pred), 4)\n",
    "        mape = round(mean_absolute_percentage_error_safe(y_true, y_pred), 2)\n",
    "        accuracy = round(100 - mape if not np.isnan(mape) else np.nan, 2)\n",
    "\n",
    "        print(f\"Metrics for {file}:\")\n",
    "        print(f\"  MAE        : {mae}\")\n",
    "        print(f\"  RMSE       : {rmse}\")\n",
    "        print(f\"  R²         : {r2}\")\n",
    "        print(f\"  MAPE(%)    : {mape}\")\n",
    "        print(f\"  Accuracy(%) : {accuracy}\\n\")\n",
    "\n",
    "        # Save metrics\n",
    "        metrics_list.append({\n",
    "            'File': file,\n",
    "            'MAE': mae,\n",
    "            'RMSE': rmse,\n",
    "            'R2': r2,\n",
    "            'MAPE(%)': mape,\n",
    "            'Accuracy(%)': accuracy\n",
    "        })\n",
    "\n",
    "        # -----------------------------\n",
    "        # Save model\n",
    "        # -----------------------------\n",
    "        model_file = os.path.join(output_models, file.replace(\".csv\", \"_prophet_model.pkl\"))\n",
    "        joblib.dump(model, model_file)\n",
    "\n",
    "        # -----------------------------\n",
    "        # Save CSV with only Date, Actual, and Predicted\n",
    "        # -----------------------------\n",
    "        save_df = df[['Date', 'Actual', 'Predicted']]\n",
    "        updated_csv_path = os.path.join(output_csv, file.replace(\".csv\", \"_prophet_updated.csv\"))\n",
    "        save_df.to_csv(updated_csv_path, index=False)\n",
    "        print(f\"Saved updated CSV with Date, Actual & Predicted: {updated_csv_path}\")\n",
    "\n",
    "        # -----------------------------\n",
    "        # Add MA7 & MA30 for graphs\n",
    "        # -----------------------------\n",
    "        df['MA7'] = df['Actual'].rolling(7).mean()\n",
    "        df['MA30'] = df['Actual'].rolling(30).mean()\n",
    "\n",
    "        # -----------------------------\n",
    "        # Plot graph\n",
    "        # -----------------------------\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(df['Date'], df['Actual'], label='Actual', color='blue')\n",
    "        plt.plot(df['Date'], df['Predicted'], label='Predicted', color='red')\n",
    "        plt.plot(df['Date'], df['MA7'], label='MA7', color='green', linestyle='--')\n",
    "        plt.plot(df['Date'], df['MA30'], label='MA30', color='orange', linestyle='--')\n",
    "        plt.title(f\"{file} - Actual vs Predicted with Moving Averages\")\n",
    "        plt.xlabel(\"Date\")\n",
    "        plt.ylabel(\"Price\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        graph_path = os.path.join(output_graphs, file.replace(\".csv\", \"_prophet_graph.png\"))\n",
    "        plt.savefig(graph_path, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "# -----------------------------\n",
    "# Save all metrics to CSV\n",
    "# -----------------------------\n",
    "metrics_df = pd.DataFrame(metrics_list)\n",
    "metrics_df.to_csv(output_metrics_csv, index=False)\n",
    "print(f\"✅ Multiple CSVs processed! Metrics saved to {output_metrics_csv}. Models, updated CSVs, and graphs saved in respective folders.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0416d76-cdd1-4c8d-8b03-5ef3d2357770",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33397cf0-2ce3-48af-af60-61ba2e304cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Processing: onion_Bagalkot_daily.csv ==========\n",
      "Metrics for onion_Bagalkot_daily.csv:\n",
      "  MAE        : 114.62\n",
      "  RMSE       : 196.27\n",
      "  R²         : 0.9339\n",
      "  MAPE(%)    : 11.23\n",
      "  Accuracy(%) : 88.77\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: arima_output_csv\\onion_Bagalkot_daily_arima_updated.csv\n",
      "========== Processing: onion_Bangalore_daily.csv ==========\n",
      "Metrics for onion_Bangalore_daily.csv:\n",
      "  MAE        : 367.99\n",
      "  RMSE       : 557.5\n",
      "  R²         : 0.6998\n",
      "  MAPE(%)    : 23.55\n",
      "  Accuracy(%) : 76.45\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: arima_output_csv\\onion_Bangalore_daily_arima_updated.csv\n",
      "========== Processing: onion_Belgaum_daily.csv ==========\n",
      "Metrics for onion_Belgaum_daily.csv:\n",
      "  MAE        : 118.47\n",
      "  RMSE       : 232.88\n",
      "  R²         : 0.9444\n",
      "  MAPE(%)    : 11.35\n",
      "  Accuracy(%) : 88.65\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: arima_output_csv\\onion_Belgaum_daily_arima_updated.csv\n",
      "========== Processing: onion_Bellary_daily.csv ==========\n",
      "Metrics for onion_Bellary_daily.csv:\n",
      "  MAE        : 154.59\n",
      "  RMSE       : 289.68\n",
      "  R²         : 0.7662\n",
      "  MAPE(%)    : 11.42\n",
      "  Accuracy(%) : 88.58\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: arima_output_csv\\onion_Bellary_daily_arima_updated.csv\n",
      "========== Processing: onion_Bidar_daily.csv ==========\n",
      "Metrics for onion_Bidar_daily.csv:\n",
      "  MAE        : 99.47\n",
      "  RMSE       : 174.65\n",
      "  R²         : 0.8097\n",
      "  MAPE(%)    : 11.05\n",
      "  Accuracy(%) : 88.95\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: arima_output_csv\\onion_Bidar_daily_arima_updated.csv\n",
      "========== Processing: onion_Bijapur_daily.csv ==========\n",
      "Metrics for onion_Bijapur_daily.csv:\n",
      "  MAE        : 284.11\n",
      "  RMSE       : 411.62\n",
      "  R²         : 0.6742\n",
      "  MAPE(%)    : 29.69\n",
      "  Accuracy(%) : 70.31\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: arima_output_csv\\onion_Bijapur_daily_arima_updated.csv\n",
      "========== Processing: onion_Chamrajnagar_daily.csv ==========\n",
      "Metrics for onion_Chamrajnagar_daily.csv:\n",
      "  MAE        : 330.95\n",
      "  RMSE       : 645.2\n",
      "  R²         : 0.716\n",
      "  MAPE(%)    : 38.38\n",
      "  Accuracy(%) : 61.62\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: arima_output_csv\\onion_Chamrajnagar_daily_arima_updated.csv\n",
      "========== Processing: onion_Chikmagalur_daily.csv ==========\n",
      "Metrics for onion_Chikmagalur_daily.csv:\n",
      "  MAE        : 506.63\n",
      "  RMSE       : 750.42\n",
      "  R²         : 0.4317\n",
      "  MAPE(%)    : 34.78\n",
      "  Accuracy(%) : 65.22\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: arima_output_csv\\onion_Chikmagalur_daily_arima_updated.csv\n",
      "========== Processing: onion_Chitradurga_daily.csv ==========\n",
      "Metrics for onion_Chitradurga_daily.csv:\n",
      "  MAE        : 310.51\n",
      "  RMSE       : 567.83\n",
      "  R²         : 0.4246\n",
      "  MAPE(%)    : 24.78\n",
      "  Accuracy(%) : 75.22\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: arima_output_csv\\onion_Chitradurga_daily_arima_updated.csv\n",
      "========== Processing: onion_Davangere_daily.csv ==========\n",
      "Metrics for onion_Davangere_daily.csv:\n",
      "  MAE        : 219.6\n",
      "  RMSE       : 383.23\n",
      "  R²         : 0.6736\n",
      "  MAPE(%)    : 25.37\n",
      "  Accuracy(%) : 74.63\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: arima_output_csv\\onion_Davangere_daily_arima_updated.csv\n",
      "========== Processing: onion_Dharwad_daily.csv ==========\n",
      "Metrics for onion_Dharwad_daily.csv:\n",
      "  MAE        : 85.06\n",
      "  RMSE       : 158.42\n",
      "  R²         : 0.9565\n",
      "  MAPE(%)    : 7.14\n",
      "  Accuracy(%) : 92.86\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: arima_output_csv\\onion_Dharwad_daily_arima_updated.csv\n",
      "========== Processing: onion_Gadag_daily.csv ==========\n",
      "Metrics for onion_Gadag_daily.csv:\n",
      "  MAE        : 24.26\n",
      "  RMSE       : 70.52\n",
      "  R²         : 0.9878\n",
      "  MAPE(%)    : 1.89\n",
      "  Accuracy(%) : 98.11\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: arima_output_csv\\onion_Gadag_daily_arima_updated.csv\n",
      "========== Processing: onion_Hassan_daily.csv ==========\n",
      "Metrics for onion_Hassan_daily.csv:\n",
      "  MAE        : 469.7\n",
      "  RMSE       : 697.76\n",
      "  R²         : 0.4318\n",
      "  MAPE(%)    : 37.32\n",
      "  Accuracy(%) : 62.68\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: arima_output_csv\\onion_Hassan_daily_arima_updated.csv\n",
      "========== Processing: onion_Haveri_daily.csv ==========\n",
      "Metrics for onion_Haveri_daily.csv:\n",
      "  MAE        : 220.12\n",
      "  RMSE       : 361.74\n",
      "  R²         : 0.7504\n",
      "  MAPE(%)    : 17.7\n",
      "  Accuracy(%) : 82.3\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: arima_output_csv\\onion_Haveri_daily_arima_updated.csv\n",
      "========== Processing: onion_Kolar_daily.csv ==========\n",
      "Metrics for onion_Kolar_daily.csv:\n",
      "  MAE        : 523.88\n",
      "  RMSE       : 791.47\n",
      "  R²         : 0.4904\n",
      "  MAPE(%)    : 44.19\n",
      "  Accuracy(%) : 55.81\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: arima_output_csv\\onion_Kolar_daily_arima_updated.csv\n",
      "========== Processing: onion_MadikeriKodagu_daily.csv ==========\n",
      "Metrics for onion_MadikeriKodagu_daily.csv:\n",
      "  MAE        : 33.14\n",
      "  RMSE       : 102.57\n",
      "  R²         : 0.9597\n",
      "  MAPE(%)    : 5.48\n",
      "  Accuracy(%) : 94.52\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: arima_output_csv\\onion_MadikeriKodagu_daily_arima_updated.csv\n",
      "========== Processing: onion_Mandya_daily.csv ==========\n",
      "Metrics for onion_Mandya_daily.csv:\n",
      "  MAE        : 465.52\n",
      "  RMSE       : 583.69\n",
      "  R²         : 0.3867\n",
      "  MAPE(%)    : 40.93\n",
      "  Accuracy(%) : 59.07\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: arima_output_csv\\onion_Mandya_daily_arima_updated.csv\n",
      "========== Processing: onion_MangaloreDakshin_Kannad_daily.csv ==========\n",
      "Metrics for onion_MangaloreDakshin_Kannad_daily.csv:\n",
      "  MAE        : 39.29\n",
      "  RMSE       : 115.51\n",
      "  R²         : 0.9823\n",
      "  MAPE(%)    : 2.12\n",
      "  Accuracy(%) : 97.88\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: arima_output_csv\\onion_MangaloreDakshin_Kannad_daily_arima_updated.csv\n",
      "========== Processing: onion_Mysore_daily.csv ==========\n",
      "Metrics for onion_Mysore_daily.csv:\n",
      "  MAE        : 413.86\n",
      "  RMSE       : 585.89\n",
      "  R²         : 0.4494\n",
      "  MAPE(%)    : 28.69\n",
      "  Accuracy(%) : 71.31\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: arima_output_csv\\onion_Mysore_daily_arima_updated.csv\n",
      "========== Processing: onion_Raichur_daily.csv ==========\n",
      "Metrics for onion_Raichur_daily.csv:\n",
      "  MAE        : 128.56\n",
      "  RMSE       : 222.4\n",
      "  R²         : 0.923\n",
      "  MAPE(%)    : 11.24\n",
      "  Accuracy(%) : 88.76\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: arima_output_csv\\onion_Raichur_daily_arima_updated.csv\n",
      "========== Processing: onion_Shimoga_daily.csv ==========\n",
      "Metrics for onion_Shimoga_daily.csv:\n",
      "  MAE        : 326.96\n",
      "  RMSE       : 565.77\n",
      "  R²         : 0.6583\n",
      "  MAPE(%)    : 37.01\n",
      "  Accuracy(%) : 62.99\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: arima_output_csv\\onion_Shimoga_daily_arima_updated.csv\n",
      "========== Processing: onion_Tumkur_daily.csv ==========\n",
      "Metrics for onion_Tumkur_daily.csv:\n",
      "  MAE        : 880.04\n",
      "  RMSE       : 1479.52\n",
      "  R²         : 0.5971\n",
      "  MAPE(%)    : 37.34\n",
      "  Accuracy(%) : 62.66\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: arima_output_csv\\onion_Tumkur_daily_arima_updated.csv\n",
      "========== Processing: onion_Udupi_daily.csv ==========\n",
      "Metrics for onion_Udupi_daily.csv:\n",
      "  MAE        : 148.7\n",
      "  RMSE       : 293.46\n",
      "  R²         : 0.9448\n",
      "  MAPE(%)    : 8.27\n",
      "  Accuracy(%) : 91.73\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: arima_output_csv\\onion_Udupi_daily_arima_updated.csv\n",
      "✅ Multiple CSVs processed! Metrics saved to arima_metrics.csv. Models, updated CSVs, and graphs saved in respective folders.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import joblib\n",
    "import warnings\n",
    "\n",
    "# -----------------------------\n",
    "# Suppress warnings\n",
    "# -----------------------------\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# -----------------------------\n",
    "# Paths\n",
    "# -----------------------------\n",
    "input_folder = \"dataset\"\n",
    "output_models = \"arima_output_models\"\n",
    "output_csv = \"arima_output_csv\"\n",
    "output_metrics_csv = \"arima_metrics.csv\"\n",
    "output_graphs = \"arima_output_graphs\"\n",
    "\n",
    "os.makedirs(output_models, exist_ok=True)\n",
    "os.makedirs(output_csv, exist_ok=True)\n",
    "os.makedirs(output_graphs, exist_ok=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Metrics storage\n",
    "# -----------------------------\n",
    "metrics_list = []\n",
    "\n",
    "# -----------------------------\n",
    "# Robust date parsing (allow all formats)\n",
    "# -----------------------------\n",
    "def parse_dates_safe(date_series):\n",
    "    return pd.to_datetime(date_series, errors='coerce', infer_datetime_format=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Safe MAPE calculation (handle NaN/Inf)\n",
    "# -----------------------------\n",
    "def mean_absolute_percentage_error_safe(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    mask = y_true != 0\n",
    "    if mask.sum() == 0:\n",
    "        return 0.0\n",
    "    mape = np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100\n",
    "    if np.isnan(mape) or np.isinf(mape):\n",
    "        return 0.0\n",
    "    return mape\n",
    "\n",
    "# -----------------------------\n",
    "# Process each CSV\n",
    "# -----------------------------\n",
    "for file in os.listdir(input_folder):\n",
    "    if file.endswith(\".csv\"):\n",
    "        file_path = os.path.join(input_folder, file)\n",
    "        print(f\"========== Processing: {file} ==========\")\n",
    "\n",
    "        # Load CSV\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # -----------------------------\n",
    "        # Convert 'Date' column safely\n",
    "        # -----------------------------\n",
    "        df['Date'] = parse_dates_safe(df['Date'])\n",
    "        df = df.sort_values('Date')\n",
    "\n",
    "        # Drop rows with invalid dates\n",
    "        df = df.dropna(subset=['Date'])\n",
    "        if df.empty:\n",
    "            print(f\"⚠️ No valid dates found in {file}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        # -----------------------------\n",
    "        # Handle missing Average Price\n",
    "        # -----------------------------\n",
    "        if df['Average Price'].isna().sum() > 0:\n",
    "            mean_value = df['Average Price'].mean()\n",
    "            df['Average Price'].fillna(mean_value, inplace=True)\n",
    "            print(f\"Filled {df['Average Price'].isna().sum()} missing values with mean: {mean_value:.2f}\")\n",
    "\n",
    "        df['Average Price'] = df['Average Price'].round(2)\n",
    "\n",
    "        # -----------------------------\n",
    "        # Fit ARIMA model\n",
    "        # -----------------------------\n",
    "        order = (5, 1, 0)\n",
    "        model = ARIMA(df['Average Price'], order=order)\n",
    "        model_fit = model.fit()\n",
    "\n",
    "        # Predict for existing dates\n",
    "        df['Predicted'] = model_fit.predict(start=0, end=len(df)-1)\n",
    "        df['Predicted'] = df['Predicted'].round(2)\n",
    "\n",
    "        # -----------------------------\n",
    "        # Rename Average Price to Actual\n",
    "        # -----------------------------\n",
    "        df.rename(columns={'Average Price': 'Actual'}, inplace=True)\n",
    "\n",
    "        # -----------------------------\n",
    "        # Calculate metrics\n",
    "        # -----------------------------\n",
    "        y_true = df['Actual'].values\n",
    "        y_pred = df['Predicted'].values\n",
    "        mae = round(mean_absolute_error(y_true, y_pred), 2)\n",
    "        rmse = round(np.sqrt(mean_squared_error(y_true, y_pred)), 2)\n",
    "        r2 = round(r2_score(y_true, y_pred), 4)\n",
    "        mape = round(mean_absolute_percentage_error_safe(y_true, y_pred), 2)\n",
    "        accuracy = round(100 - mape, 2)\n",
    "\n",
    "        print(f\"Metrics for {file}:\")\n",
    "        print(f\"  MAE        : {mae}\")\n",
    "        print(f\"  RMSE       : {rmse}\")\n",
    "        print(f\"  R²         : {r2}\")\n",
    "        print(f\"  MAPE(%)    : {mape}\")\n",
    "        print(f\"  Accuracy(%) : {accuracy}\\n\")\n",
    "\n",
    "        # Save metrics\n",
    "        metrics_list.append({\n",
    "            'File': file,\n",
    "            'MAE': mae,\n",
    "            'RMSE': rmse,\n",
    "            'R2': r2,\n",
    "            'MAPE(%)': mape,\n",
    "            'Accuracy(%)': accuracy\n",
    "        })\n",
    "\n",
    "        # -----------------------------\n",
    "        # Save model\n",
    "        # -----------------------------\n",
    "        model_file = os.path.join(output_models, file.replace(\".csv\", \"_arima_model.pkl\"))\n",
    "        joblib.dump(model_fit, model_file)\n",
    "\n",
    "        # -----------------------------\n",
    "        # Save CSV with only Date, Actual, Predicted\n",
    "        # -----------------------------\n",
    "        save_df = df[['Date', 'Actual', 'Predicted']]\n",
    "        updated_csv_path = os.path.join(output_csv, file.replace(\".csv\", \"_arima_updated.csv\"))\n",
    "        save_df.to_csv(updated_csv_path, index=False)\n",
    "        print(f\"Saved updated CSV with Date, Actual & Predicted: {updated_csv_path}\")\n",
    "\n",
    "        # -----------------------------\n",
    "        # Add MA7 & MA30 for graphs\n",
    "        # -----------------------------\n",
    "        df['MA7'] = df['Actual'].rolling(7).mean()\n",
    "        df['MA30'] = df['Actual'].rolling(30).mean()\n",
    "\n",
    "        # -----------------------------\n",
    "        # Plot graph\n",
    "        # -----------------------------\n",
    "        plt.figure(figsize=(12,6))\n",
    "        plt.plot(df['Date'], df['Actual'], label='Actual', color='blue')\n",
    "        plt.plot(df['Date'], df['Predicted'], label='Predicted', color='red')\n",
    "        plt.plot(df['Date'], df['MA7'], label='MA7', color='green', linestyle='--')\n",
    "        plt.plot(df['Date'], df['MA30'], label='MA30', color='orange', linestyle='--')\n",
    "        plt.title(f\"{file} - Actual vs Predicted with Moving Averages\")\n",
    "        plt.xlabel(\"Date\")\n",
    "        plt.ylabel(\"Price\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        graph_path = os.path.join(output_graphs, file.replace(\".csv\", \"_arima_graph.png\"))\n",
    "        plt.savefig(graph_path, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "# -----------------------------\n",
    "# Save all metrics to CSV\n",
    "# -----------------------------\n",
    "metrics_df = pd.DataFrame(metrics_list)\n",
    "metrics_df.to_csv(output_metrics_csv, index=False)\n",
    "print(f\"✅ Multiple CSVs processed! Metrics saved to {output_metrics_csv}. Models, updated CSVs, and graphs saved in respective folders.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ac58d8-14f3-441a-b9dd-acd95a4605fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SARIMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e268b615-5339-4b40-b418-4c3e888d0b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Processing: onion_Bagalkot_daily.csv ==========\n",
      "Metrics for onion_Bagalkot_daily.csv:\n",
      "  MAE        : 117.45\n",
      "  RMSE       : 200.26\n",
      "  R²         : 0.9312\n",
      "  MAPE(%)    : 11.52\n",
      "  Accuracy(%) : 88.48\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: sarimax_output_csv\\onion_Bagalkot_daily_sarimax_updated.csv\n",
      "========== Processing: onion_Bangalore_daily.csv ==========\n",
      "Metrics for onion_Bangalore_daily.csv:\n",
      "  MAE        : 365.72\n",
      "  RMSE       : 547.26\n",
      "  R²         : 0.7107\n",
      "  MAPE(%)    : 23.43\n",
      "  Accuracy(%) : 76.57\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: sarimax_output_csv\\onion_Bangalore_daily_sarimax_updated.csv\n",
      "========== Processing: onion_Belgaum_daily.csv ==========\n",
      "Metrics for onion_Belgaum_daily.csv:\n",
      "  MAE        : 119.72\n",
      "  RMSE       : 233.89\n",
      "  R²         : 0.9439\n",
      "  MAPE(%)    : 11.41\n",
      "  Accuracy(%) : 88.59\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: sarimax_output_csv\\onion_Belgaum_daily_sarimax_updated.csv\n",
      "========== Processing: onion_Bellary_daily.csv ==========\n",
      "Metrics for onion_Bellary_daily.csv:\n",
      "  MAE        : 157.8\n",
      "  RMSE       : 288.52\n",
      "  R²         : 0.7681\n",
      "  MAPE(%)    : 11.68\n",
      "  Accuracy(%) : 88.32\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: sarimax_output_csv\\onion_Bellary_daily_sarimax_updated.csv\n",
      "========== Processing: onion_Bidar_daily.csv ==========\n",
      "Metrics for onion_Bidar_daily.csv:\n",
      "  MAE        : 105.84\n",
      "  RMSE       : 179.61\n",
      "  R²         : 0.7988\n",
      "  MAPE(%)    : 11.61\n",
      "  Accuracy(%) : 88.39\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: sarimax_output_csv\\onion_Bidar_daily_sarimax_updated.csv\n",
      "========== Processing: onion_Bijapur_daily.csv ==========\n",
      "Metrics for onion_Bijapur_daily.csv:\n",
      "  MAE        : 288.48\n",
      "  RMSE       : 413.66\n",
      "  R²         : 0.671\n",
      "  MAPE(%)    : 30.15\n",
      "  Accuracy(%) : 69.85\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: sarimax_output_csv\\onion_Bijapur_daily_sarimax_updated.csv\n",
      "========== Processing: onion_Chamrajnagar_daily.csv ==========\n",
      "Metrics for onion_Chamrajnagar_daily.csv:\n",
      "  MAE        : 348.18\n",
      "  RMSE       : 645.63\n",
      "  R²         : 0.7156\n",
      "  MAPE(%)    : 40.34\n",
      "  Accuracy(%) : 59.66\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: sarimax_output_csv\\onion_Chamrajnagar_daily_sarimax_updated.csv\n",
      "========== Processing: onion_Chikmagalur_daily.csv ==========\n",
      "Metrics for onion_Chikmagalur_daily.csv:\n",
      "  MAE        : 491.62\n",
      "  RMSE       : 716.85\n",
      "  R²         : 0.4814\n",
      "  MAPE(%)    : 33.78\n",
      "  Accuracy(%) : 66.22\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: sarimax_output_csv\\onion_Chikmagalur_daily_sarimax_updated.csv\n",
      "========== Processing: onion_Chitradurga_daily.csv ==========\n",
      "Metrics for onion_Chitradurga_daily.csv:\n",
      "  MAE        : 318.0\n",
      "  RMSE       : 546.87\n",
      "  R²         : 0.4663\n",
      "  MAPE(%)    : 25.41\n",
      "  Accuracy(%) : 74.59\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: sarimax_output_csv\\onion_Chitradurga_daily_sarimax_updated.csv\n",
      "========== Processing: onion_Davangere_daily.csv ==========\n",
      "Metrics for onion_Davangere_daily.csv:\n",
      "  MAE        : 221.7\n",
      "  RMSE       : 376.25\n",
      "  R²         : 0.6854\n",
      "  MAPE(%)    : 25.26\n",
      "  Accuracy(%) : 74.74\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: sarimax_output_csv\\onion_Davangere_daily_sarimax_updated.csv\n",
      "========== Processing: onion_Dharwad_daily.csv ==========\n",
      "Metrics for onion_Dharwad_daily.csv:\n",
      "  MAE        : 85.73\n",
      "  RMSE       : 159.13\n",
      "  R²         : 0.9561\n",
      "  MAPE(%)    : 7.24\n",
      "  Accuracy(%) : 92.76\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: sarimax_output_csv\\onion_Dharwad_daily_sarimax_updated.csv\n",
      "========== Processing: onion_Gadag_daily.csv ==========\n",
      "Metrics for onion_Gadag_daily.csv:\n",
      "  MAE        : 25.46\n",
      "  RMSE       : 72.94\n",
      "  R²         : 0.987\n",
      "  MAPE(%)    : 2.12\n",
      "  Accuracy(%) : 97.88\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: sarimax_output_csv\\onion_Gadag_daily_sarimax_updated.csv\n",
      "========== Processing: onion_Hassan_daily.csv ==========\n",
      "Metrics for onion_Hassan_daily.csv:\n",
      "  MAE        : 452.79\n",
      "  RMSE       : 670.98\n",
      "  R²         : 0.4746\n",
      "  MAPE(%)    : 36.0\n",
      "  Accuracy(%) : 64.0\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: sarimax_output_csv\\onion_Hassan_daily_sarimax_updated.csv\n",
      "========== Processing: onion_Haveri_daily.csv ==========\n",
      "Metrics for onion_Haveri_daily.csv:\n",
      "  MAE        : 226.37\n",
      "  RMSE       : 362.33\n",
      "  R²         : 0.7496\n",
      "  MAPE(%)    : 18.23\n",
      "  Accuracy(%) : 81.77\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: sarimax_output_csv\\onion_Haveri_daily_sarimax_updated.csv\n",
      "========== Processing: onion_Kolar_daily.csv ==========\n",
      "Metrics for onion_Kolar_daily.csv:\n",
      "  MAE        : 491.75\n",
      "  RMSE       : 745.83\n",
      "  R²         : 0.5475\n",
      "  MAPE(%)    : 41.24\n",
      "  Accuracy(%) : 58.76\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: sarimax_output_csv\\onion_Kolar_daily_sarimax_updated.csv\n",
      "========== Processing: onion_MadikeriKodagu_daily.csv ==========\n",
      "Metrics for onion_MadikeriKodagu_daily.csv:\n",
      "  MAE        : 37.21\n",
      "  RMSE       : 102.84\n",
      "  R²         : 0.9594\n",
      "  MAPE(%)    : 5.78\n",
      "  Accuracy(%) : 94.22\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: sarimax_output_csv\\onion_MadikeriKodagu_daily_sarimax_updated.csv\n",
      "========== Processing: onion_Mandya_daily.csv ==========\n",
      "Metrics for onion_Mandya_daily.csv:\n",
      "  MAE        : 465.16\n",
      "  RMSE       : 568.78\n",
      "  R²         : 0.4177\n",
      "  MAPE(%)    : 40.82\n",
      "  Accuracy(%) : 59.18\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: sarimax_output_csv\\onion_Mandya_daily_sarimax_updated.csv\n",
      "========== Processing: onion_MangaloreDakshin_Kannad_daily.csv ==========\n",
      "Metrics for onion_MangaloreDakshin_Kannad_daily.csv:\n",
      "  MAE        : 41.01\n",
      "  RMSE       : 118.64\n",
      "  R²         : 0.9814\n",
      "  MAPE(%)    : 2.21\n",
      "  Accuracy(%) : 97.79\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: sarimax_output_csv\\onion_MangaloreDakshin_Kannad_daily_sarimax_updated.csv\n",
      "========== Processing: onion_Mysore_daily.csv ==========\n",
      "Metrics for onion_Mysore_daily.csv:\n",
      "  MAE        : 403.07\n",
      "  RMSE       : 564.33\n",
      "  R²         : 0.4892\n",
      "  MAPE(%)    : 27.92\n",
      "  Accuracy(%) : 72.08\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: sarimax_output_csv\\onion_Mysore_daily_sarimax_updated.csv\n",
      "========== Processing: onion_Raichur_daily.csv ==========\n",
      "Metrics for onion_Raichur_daily.csv:\n",
      "  MAE        : 129.63\n",
      "  RMSE       : 222.62\n",
      "  R²         : 0.9229\n",
      "  MAPE(%)    : 11.35\n",
      "  Accuracy(%) : 88.65\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: sarimax_output_csv\\onion_Raichur_daily_sarimax_updated.csv\n",
      "========== Processing: onion_Shimoga_daily.csv ==========\n",
      "Metrics for onion_Shimoga_daily.csv:\n",
      "  MAE        : 331.0\n",
      "  RMSE       : 557.21\n",
      "  R²         : 0.6686\n",
      "  MAPE(%)    : 40.47\n",
      "  Accuracy(%) : 59.53\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: sarimax_output_csv\\onion_Shimoga_daily_sarimax_updated.csv\n",
      "========== Processing: onion_Tumkur_daily.csv ==========\n",
      "Metrics for onion_Tumkur_daily.csv:\n",
      "  MAE        : 864.03\n",
      "  RMSE       : 1409.86\n",
      "  R²         : 0.6341\n",
      "  MAPE(%)    : 36.75\n",
      "  Accuracy(%) : 63.25\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: sarimax_output_csv\\onion_Tumkur_daily_sarimax_updated.csv\n",
      "========== Processing: onion_Udupi_daily.csv ==========\n",
      "Metrics for onion_Udupi_daily.csv:\n",
      "  MAE        : 152.13\n",
      "  RMSE       : 295.91\n",
      "  R²         : 0.9438\n",
      "  MAPE(%)    : 8.44\n",
      "  Accuracy(%) : 91.56\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: sarimax_output_csv\\onion_Udupi_daily_sarimax_updated.csv\n",
      "✅ Multiple CSVs processed! Metrics saved to sarimax_metrics.csv. Models, updated CSVs, and graphs saved in respective folders.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import warnings\n",
    "import joblib\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")  # Ignore warnings\n",
    "\n",
    "# -----------------------------\n",
    "# Paths\n",
    "# -----------------------------\n",
    "input_folder = \"dataset\"\n",
    "output_models = \"sarimax_output_models\"\n",
    "output_csv = \"sarimax_output_csv\"\n",
    "output_graphs = \"sarimax_output_graphs\"\n",
    "output_metrics_csv = \"sarimax_metrics.csv\"\n",
    "\n",
    "os.makedirs(output_models, exist_ok=True)\n",
    "os.makedirs(output_csv, exist_ok=True)\n",
    "os.makedirs(output_graphs, exist_ok=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Metrics storage\n",
    "# -----------------------------\n",
    "metrics_list = []\n",
    "\n",
    "# -----------------------------\n",
    "# Robust date parsing (allow all formats)\n",
    "# -----------------------------\n",
    "def parse_dates_safe(date_series):\n",
    "    return pd.to_datetime(date_series, errors='coerce', infer_datetime_format=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Safe MAPE calculation (handle NaN/Inf)\n",
    "# -----------------------------\n",
    "def mean_absolute_percentage_error_safe(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    mask = y_true != 0\n",
    "    if mask.sum() == 0:\n",
    "        return 0.0\n",
    "    mape = np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100\n",
    "    if np.isnan(mape) or np.isinf(mape):\n",
    "        return 0.0\n",
    "    return mape\n",
    "\n",
    "# -----------------------------\n",
    "# Process each CSV\n",
    "# -----------------------------\n",
    "for file in os.listdir(input_folder):\n",
    "    if file.endswith(\".csv\"):\n",
    "        file_path = os.path.join(input_folder, file)\n",
    "        print(f\"========== Processing: {file} ==========\")\n",
    "\n",
    "        # Load CSV\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # -----------------------------\n",
    "        # Convert 'Date' column safely\n",
    "        # -----------------------------\n",
    "        df['Date'] = parse_dates_safe(df['Date'])\n",
    "        df = df.sort_values('Date')\n",
    "        df.set_index('Date', inplace=True)\n",
    "\n",
    "        # Drop rows with invalid dates\n",
    "        df = df.dropna(subset=['Average Price'])\n",
    "        if df.empty:\n",
    "            print(f\"⚠️ No valid data found in {file}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        # Handle missing values\n",
    "        if df['Average Price'].isna().sum() > 0:\n",
    "            mean_value = df['Average Price'].mean()\n",
    "            df['Average Price'].fillna(mean_value, inplace=True)\n",
    "            print(f\"Filled {df['Average Price'].isna().sum()} missing values with mean: {mean_value:.2f}\")\n",
    "\n",
    "        # Round actual values\n",
    "        df['Average Price'] = df['Average Price'].round(2)\n",
    "\n",
    "        # Add moving averages\n",
    "        df['MA_7'] = df['Average Price'].rolling(window=7).mean()\n",
    "        df['MA_30'] = df['Average Price'].rolling(window=30).mean()\n",
    "\n",
    "        # SARIMAX order (tune if needed)\n",
    "        order = (1, 1, 1)\n",
    "        seasonal_order = (1, 1, 1, 7)\n",
    "\n",
    "        # Fit SARIMAX model\n",
    "        model = SARIMAX(df['Average Price'],\n",
    "                        order=order,\n",
    "                        seasonal_order=seasonal_order,\n",
    "                        enforce_stationarity=False,\n",
    "                        enforce_invertibility=False)\n",
    "        model_fit = model.fit(disp=False)\n",
    "\n",
    "        # Save model\n",
    "        model_file = os.path.join(output_models, file.replace(\".csv\", \"_sarimax_model.pkl\"))\n",
    "        joblib.dump(model_fit, model_file)\n",
    "\n",
    "        # Predictions\n",
    "        df['Predicted'] = model_fit.predict(start=0, end=len(df)-1)\n",
    "        df['Predicted'] = df['Predicted'].round(2)  # round predictions\n",
    "\n",
    "        # Rename Average Price to Actual\n",
    "        df.rename(columns={'Average Price': 'Actual'}, inplace=True)\n",
    "\n",
    "        # Calculate metrics\n",
    "        y_true = df['Actual'].values\n",
    "        y_pred = df['Predicted'].values\n",
    "        mae = round(mean_absolute_error(y_true, y_pred), 2)\n",
    "        rmse = round(np.sqrt(mean_squared_error(y_true, y_pred)), 2)\n",
    "        r2 = round(r2_score(y_true, y_pred), 4)\n",
    "        mape = round(mean_absolute_percentage_error_safe(y_true, y_pred), 2)\n",
    "        accuracy = round(100 - mape, 2)\n",
    "\n",
    "        print(f\"Metrics for {file}:\")\n",
    "        print(f\"  MAE        : {mae}\")\n",
    "        print(f\"  RMSE       : {rmse}\")\n",
    "        print(f\"  R²         : {r2}\")\n",
    "        print(f\"  MAPE(%)    : {mape}\")\n",
    "        print(f\"  Accuracy(%) : {accuracy}\\n\")\n",
    "\n",
    "        # Save metrics\n",
    "        metrics_list.append({\n",
    "            'File': file,\n",
    "            'MAE': mae,\n",
    "            'RMSE': rmse,\n",
    "            'R2': r2,\n",
    "            'MAPE(%)': mape,\n",
    "            'Accuracy(%)': accuracy\n",
    "        })\n",
    "\n",
    "        # -----------------------------\n",
    "        # Save updated CSV with only Date, Actual, Predicted\n",
    "        # -----------------------------\n",
    "        save_df = df[['Actual', 'Predicted']].copy()\n",
    "        save_df['Date'] = df.index\n",
    "        save_df = save_df[['Date', 'Actual', 'Predicted']]\n",
    "        updated_csv_path = os.path.join(output_csv, file.replace(\".csv\", \"_sarimax_updated.csv\"))\n",
    "        save_df.to_csv(updated_csv_path, index=False)\n",
    "        print(f\"Saved updated CSV with Date, Actual & Predicted: {updated_csv_path}\")\n",
    "\n",
    "        # -----------------------------\n",
    "        # Plot graph\n",
    "        # -----------------------------\n",
    "        plt.figure(figsize=(12,6))\n",
    "        plt.plot(df.index, df['Actual'], label=\"Actual\", color=\"blue\")\n",
    "        plt.plot(df.index, df['Predicted'], label=\"Predicted\", color=\"red\", linestyle=\"dashed\")\n",
    "        plt.plot(df.index, df['MA_7'], label=\"MA 7\", color=\"orange\")\n",
    "        plt.plot(df.index, df['MA_30'], label=\"MA 30\", color=\"green\")\n",
    "        plt.xlabel(\"Date\")\n",
    "        plt.ylabel(\"Average Price\")\n",
    "        plt.title(f\"Price Prediction (SARIMAX) - {file}\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        graph_file = os.path.join(output_graphs, file.replace(\".csv\", \"_sarimax_graph.png\"))\n",
    "        plt.savefig(graph_file, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "# Save all metrics to CSV\n",
    "metrics_df = pd.DataFrame(metrics_list)\n",
    "metrics_df.to_csv(output_metrics_csv, index=False)\n",
    "print(f\"✅ Multiple CSVs processed! Metrics saved to {output_metrics_csv}. Models, updated CSVs, and graphs saved in respective folders.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab063ef-3de3-42c6-9258-7db196a3bcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TAT+MHA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a398d081-4fb2-4de6-8838-ebf65d1d98c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Processing: onion_Bagalkot_daily.csv\n",
      "Epoch 1/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 14ms/step - loss: 0.0122 - mae: 0.0736 - val_loss: 0.0111 - val_mae: 0.0686\n",
      "Epoch 2/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 0.0095 - mae: 0.0676 - val_loss: 0.0107 - val_mae: 0.0680\n",
      "Epoch 3/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 0.0091 - mae: 0.0669 - val_loss: 0.0109 - val_mae: 0.0684\n",
      "Epoch 4/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 0.0092 - mae: 0.0662 - val_loss: 0.0105 - val_mae: 0.0679\n",
      "Epoch 5/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 0.0093 - mae: 0.0664 - val_loss: 0.0105 - val_mae: 0.0679\n",
      "Epoch 6/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0099 - mae: 0.0689 - val_loss: 0.0104 - val_mae: 0.0678\n",
      "Epoch 7/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0094 - mae: 0.0675 - val_loss: 0.0104 - val_mae: 0.0678\n",
      "Epoch 8/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0089 - mae: 0.0655 - val_loss: 0.0097 - val_mae: 0.0677\n",
      "Epoch 9/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0088 - mae: 0.0666 - val_loss: 0.0102 - val_mae: 0.0676\n",
      "Epoch 10/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0102 - mae: 0.0692 - val_loss: 0.0113 - val_mae: 0.0689\n",
      "Epoch 11/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0096 - mae: 0.0682 - val_loss: 0.0109 - val_mae: 0.0684\n",
      "Epoch 12/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0089 - mae: 0.0661 - val_loss: 0.0109 - val_mae: 0.0683\n",
      "Epoch 13/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0092 - mae: 0.0662 - val_loss: 0.0098 - val_mae: 0.0677\n",
      "Epoch 14/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0093 - mae: 0.0681 - val_loss: 0.0114 - val_mae: 0.0691\n",
      "Epoch 15/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - loss: 0.0090 - mae: 0.0662 - val_loss: 0.0106 - val_mae: 0.0680\n",
      "Epoch 16/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0100 - mae: 0.0675 - val_loss: 0.0105 - val_mae: 0.0679\n",
      "Epoch 17/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0094 - mae: 0.0678 - val_loss: 0.0119 - val_mae: 0.0705\n",
      "Epoch 18/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - loss: 0.0090 - mae: 0.0667 - val_loss: 0.0102 - val_mae: 0.0676\n",
      "Epoch 19/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - loss: 0.0098 - mae: 0.0681 - val_loss: 0.0115 - val_mae: 0.0693\n",
      "Epoch 20/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - loss: 0.0102 - mae: 0.0692 - val_loss: 0.0110 - val_mae: 0.0685\n",
      "Epoch 21/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 0.0096 - mae: 0.0679 - val_loss: 0.0105 - val_mae: 0.0679\n",
      "Epoch 22/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 0.0101 - mae: 0.0691 - val_loss: 0.0112 - val_mae: 0.0688\n",
      "Epoch 23/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0096 - mae: 0.0678 - val_loss: 0.0110 - val_mae: 0.0684\n",
      "Epoch 24/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0093 - mae: 0.0676 - val_loss: 0.0108 - val_mae: 0.0681\n",
      "Epoch 25/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0097 - mae: 0.0674 - val_loss: 0.0108 - val_mae: 0.0683\n",
      "Epoch 26/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 0.0091 - mae: 0.0673 - val_loss: 0.0114 - val_mae: 0.0692\n",
      "Epoch 27/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - loss: 0.0093 - mae: 0.0674 - val_loss: 0.0114 - val_mae: 0.0692\n",
      "Epoch 28/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - loss: 0.0096 - mae: 0.0679 - val_loss: 0.0114 - val_mae: 0.0691\n",
      "Epoch 29/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - loss: 0.0093 - mae: 0.0663 - val_loss: 0.0107 - val_mae: 0.0681\n",
      "Epoch 30/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0102 - mae: 0.0688 - val_loss: 0.0105 - val_mae: 0.0679\n",
      "Epoch 31/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 0.0095 - mae: 0.0673 - val_loss: 0.0113 - val_mae: 0.0689\n",
      "Epoch 32/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 0.0104 - mae: 0.0692 - val_loss: 0.0109 - val_mae: 0.0683\n",
      "Epoch 33/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0095 - mae: 0.0681 - val_loss: 0.0112 - val_mae: 0.0688\n",
      "Epoch 34/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0099 - mae: 0.0687 - val_loss: 0.0108 - val_mae: 0.0682\n",
      "Epoch 35/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0090 - mae: 0.0663 - val_loss: 0.0109 - val_mae: 0.0683\n",
      "Epoch 36/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0090 - mae: 0.0664 - val_loss: 0.0107 - val_mae: 0.0681\n",
      "Epoch 37/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0099 - mae: 0.0677 - val_loss: 0.0100 - val_mae: 0.0676\n",
      "Epoch 38/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0092 - mae: 0.0670 - val_loss: 0.0107 - val_mae: 0.0681\n",
      "Epoch 39/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0097 - mae: 0.0676 - val_loss: 0.0104 - val_mae: 0.0678\n",
      "Epoch 40/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0095 - mae: 0.0674 - val_loss: 0.0104 - val_mae: 0.0678\n",
      "Epoch 41/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0093 - mae: 0.0671 - val_loss: 0.0103 - val_mae: 0.0677\n",
      "Epoch 42/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0097 - mae: 0.0678 - val_loss: 0.0112 - val_mae: 0.0687\n",
      "Epoch 43/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - loss: 0.0093 - mae: 0.0678 - val_loss: 0.0113 - val_mae: 0.0690\n",
      "Epoch 44/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 0.0095 - mae: 0.0675 - val_loss: 0.0109 - val_mae: 0.0683\n",
      "Epoch 45/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0086 - mae: 0.0653 - val_loss: 0.0103 - val_mae: 0.0677\n",
      "Epoch 46/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0094 - mae: 0.0678 - val_loss: 0.0108 - val_mae: 0.0682\n",
      "Epoch 47/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0102 - mae: 0.0687 - val_loss: 0.0107 - val_mae: 0.0681\n",
      "Epoch 48/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 0.0103 - mae: 0.0689 - val_loss: 0.0109 - val_mae: 0.0684\n",
      "Epoch 49/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0093 - mae: 0.0678 - val_loss: 0.0115 - val_mae: 0.0694\n",
      "Epoch 50/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0095 - mae: 0.0663 - val_loss: 0.0109 - val_mae: 0.0683\n",
      "Epoch 51/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0090 - mae: 0.0663 - val_loss: 0.0111 - val_mae: 0.0686\n",
      "Epoch 52/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0087 - mae: 0.0664 - val_loss: 0.0110 - val_mae: 0.0685\n",
      "Epoch 53/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0095 - mae: 0.0687 - val_loss: 0.0119 - val_mae: 0.0705\n",
      "Epoch 54/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0092 - mae: 0.0671 - val_loss: 0.0100 - val_mae: 0.0676\n",
      "Epoch 55/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0096 - mae: 0.0685 - val_loss: 0.0114 - val_mae: 0.0692\n",
      "Epoch 56/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0099 - mae: 0.0683 - val_loss: 0.0108 - val_mae: 0.0682\n",
      "Epoch 57/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0097 - mae: 0.0681 - val_loss: 0.0112 - val_mae: 0.0688\n",
      "Epoch 58/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0088 - mae: 0.0658 - val_loss: 0.0114 - val_mae: 0.0691\n",
      "Epoch 59/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 0.0098 - mae: 0.0682 - val_loss: 0.0104 - val_mae: 0.0678\n",
      "Epoch 60/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0096 - mae: 0.0687 - val_loss: 0.0115 - val_mae: 0.0694\n",
      "Epoch 61/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0096 - mae: 0.0683 - val_loss: 0.0121 - val_mae: 0.0710\n",
      "Epoch 62/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0088 - mae: 0.0654 - val_loss: 0.0109 - val_mae: 0.0683\n",
      "Epoch 63/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.0098 - mae: 0.0670 - val_loss: 0.0106 - val_mae: 0.0680\n",
      "Epoch 64/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 0.0092 - mae: 0.0667 - val_loss: 0.0107 - val_mae: 0.0681\n",
      "Epoch 65/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0098 - mae: 0.0682 - val_loss: 0.0106 - val_mae: 0.0679\n",
      "Epoch 66/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 0.0097 - mae: 0.0682 - val_loss: 0.0101 - val_mae: 0.0676\n",
      "Epoch 67/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 0.0095 - mae: 0.0672 - val_loss: 0.0106 - val_mae: 0.0679\n",
      "Epoch 68/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 0.0095 - mae: 0.0675 - val_loss: 0.0113 - val_mae: 0.0690\n",
      "Epoch 69/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 0.0099 - mae: 0.0683 - val_loss: 0.0110 - val_mae: 0.0685\n",
      "Epoch 70/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 0.0096 - mae: 0.0682 - val_loss: 0.0114 - val_mae: 0.0692\n",
      "Epoch 71/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - loss: 0.0101 - mae: 0.0684 - val_loss: 0.0113 - val_mae: 0.0690\n",
      "Epoch 72/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 0.0099 - mae: 0.0681 - val_loss: 0.0109 - val_mae: 0.0683\n",
      "Epoch 73/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 0.0090 - mae: 0.0664 - val_loss: 0.0102 - val_mae: 0.0677\n",
      "Epoch 74/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0089 - mae: 0.0656 - val_loss: 0.0102 - val_mae: 0.0677\n",
      "Epoch 75/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 0.0104 - mae: 0.0692 - val_loss: 0.0106 - val_mae: 0.0679\n",
      "Epoch 76/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - loss: 0.0092 - mae: 0.0670 - val_loss: 0.0104 - val_mae: 0.0678\n",
      "Epoch 77/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 0.0097 - mae: 0.0685 - val_loss: 0.0106 - val_mae: 0.0679\n",
      "Epoch 78/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 0.0093 - mae: 0.0677 - val_loss: 0.0111 - val_mae: 0.0687\n",
      "Epoch 79/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 0.0094 - mae: 0.0681 - val_loss: 0.0113 - val_mae: 0.0690\n",
      "Epoch 80/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - loss: 0.0095 - mae: 0.0675 - val_loss: 0.0106 - val_mae: 0.0679\n",
      "Epoch 81/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 0.0098 - mae: 0.0679 - val_loss: 0.0107 - val_mae: 0.0681\n",
      "Epoch 82/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 0.0090 - mae: 0.0661 - val_loss: 0.0109 - val_mae: 0.0684\n",
      "Epoch 83/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0091 - mae: 0.0669 - val_loss: 0.0109 - val_mae: 0.0684\n",
      "Epoch 84/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 0.0103 - mae: 0.0692 - val_loss: 0.0111 - val_mae: 0.0686\n",
      "Epoch 85/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0103 - mae: 0.0676 - val_loss: 0.0102 - val_mae: 0.0677\n",
      "Epoch 86/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 0.0092 - mae: 0.0674 - val_loss: 0.0109 - val_mae: 0.0683\n",
      "Epoch 87/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 0.0093 - mae: 0.0677 - val_loss: 0.0111 - val_mae: 0.0686\n",
      "Epoch 88/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0101 - mae: 0.0686 - val_loss: 0.0109 - val_mae: 0.0683\n",
      "Epoch 89/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0095 - mae: 0.0677 - val_loss: 0.0109 - val_mae: 0.0683\n",
      "Epoch 90/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 0.0094 - mae: 0.0673 - val_loss: 0.0119 - val_mae: 0.0705\n",
      "Epoch 91/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 0.0100 - mae: 0.0679 - val_loss: 0.0115 - val_mae: 0.0694\n",
      "Epoch 92/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0089 - mae: 0.0662 - val_loss: 0.0115 - val_mae: 0.0694\n",
      "Epoch 93/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 0.0099 - mae: 0.0680 - val_loss: 0.0102 - val_mae: 0.0676\n",
      "Epoch 94/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 0.0097 - mae: 0.0679 - val_loss: 0.0110 - val_mae: 0.0685\n",
      "Epoch 95/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 0.0098 - mae: 0.0690 - val_loss: 0.0108 - val_mae: 0.0683\n",
      "Epoch 96/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0089 - mae: 0.0672 - val_loss: 0.0105 - val_mae: 0.0679\n",
      "Epoch 97/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 0.0090 - mae: 0.0668 - val_loss: 0.0115 - val_mae: 0.0694\n",
      "Epoch 98/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 0.0089 - mae: 0.0658 - val_loss: 0.0107 - val_mae: 0.0680\n",
      "Epoch 99/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 0.0093 - mae: 0.0670 - val_loss: 0.0109 - val_mae: 0.0683\n",
      "Epoch 100/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0088 - mae: 0.0672 - val_loss: 0.0108 - val_mae: 0.0682\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step\n",
      "✅ Done with onion_Bagalkot_daily.csv | MAE=525.85, RMSE=766.84, R2=-0.008, MAPE=53.82%, Accuracy=46.18%\n",
      "\n",
      "🚀 Processing: onion_Bangalore_daily.csv\n",
      "Epoch 1/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 13ms/step - loss: 0.0075 - mae: 0.0570 - val_loss: 0.0110 - val_mae: 0.0671\n",
      "Epoch 2/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - loss: 0.0064 - mae: 0.0529 - val_loss: 0.0110 - val_mae: 0.0672\n",
      "Epoch 3/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - loss: 0.0064 - mae: 0.0531 - val_loss: 0.0117 - val_mae: 0.0693\n",
      "Epoch 4/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - loss: 0.0059 - mae: 0.0513 - val_loss: 0.0115 - val_mae: 0.0687\n",
      "Epoch 5/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - loss: 0.0065 - mae: 0.0522 - val_loss: 0.0113 - val_mae: 0.0681\n",
      "Epoch 6/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - loss: 0.0060 - mae: 0.0514 - val_loss: 0.0114 - val_mae: 0.0684\n",
      "Epoch 7/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - loss: 0.0058 - mae: 0.0512 - val_loss: 0.0114 - val_mae: 0.0686\n",
      "Epoch 8/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - loss: 0.0066 - mae: 0.0534 - val_loss: 0.0110 - val_mae: 0.0671\n",
      "Epoch 9/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - loss: 0.0068 - mae: 0.0537 - val_loss: 0.0110 - val_mae: 0.0672\n",
      "Epoch 10/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - loss: 0.0060 - mae: 0.0516 - val_loss: 0.0120 - val_mae: 0.0705\n",
      "Epoch 11/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 14ms/step - loss: 0.0058 - mae: 0.0502 - val_loss: 0.0112 - val_mae: 0.0676\n",
      "Epoch 12/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - loss: 0.0063 - mae: 0.0522 - val_loss: 0.0111 - val_mae: 0.0675\n",
      "Epoch 13/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - loss: 0.0059 - mae: 0.0516 - val_loss: 0.0117 - val_mae: 0.0695\n",
      "Epoch 14/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - loss: 0.0061 - mae: 0.0516 - val_loss: 0.0112 - val_mae: 0.0679\n",
      "Epoch 15/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - loss: 0.0061 - mae: 0.0516 - val_loss: 0.0108 - val_mae: 0.0665\n",
      "Epoch 16/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - loss: 0.0067 - mae: 0.0538 - val_loss: 0.0110 - val_mae: 0.0671\n",
      "Epoch 17/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - loss: 0.0058 - mae: 0.0510 - val_loss: 0.0117 - val_mae: 0.0696\n",
      "Epoch 18/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - loss: 0.0060 - mae: 0.0515 - val_loss: 0.0108 - val_mae: 0.0666\n",
      "Epoch 19/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - loss: 0.0064 - mae: 0.0525 - val_loss: 0.0114 - val_mae: 0.0685\n",
      "Epoch 20/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - loss: 0.0060 - mae: 0.0518 - val_loss: 0.0114 - val_mae: 0.0685\n",
      "Epoch 21/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - loss: 0.0060 - mae: 0.0519 - val_loss: 0.0113 - val_mae: 0.0680\n",
      "Epoch 22/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - loss: 0.0063 - mae: 0.0521 - val_loss: 0.0113 - val_mae: 0.0680\n",
      "Epoch 23/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - loss: 0.0060 - mae: 0.0514 - val_loss: 0.0110 - val_mae: 0.0672\n",
      "Epoch 24/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - loss: 0.0064 - mae: 0.0526 - val_loss: 0.0115 - val_mae: 0.0686\n",
      "Epoch 25/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - loss: 0.0062 - mae: 0.0517 - val_loss: 0.0121 - val_mae: 0.0709\n",
      "Epoch 26/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - loss: 0.0063 - mae: 0.0528 - val_loss: 0.0110 - val_mae: 0.0671\n",
      "Epoch 27/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - loss: 0.0061 - mae: 0.0517 - val_loss: 0.0111 - val_mae: 0.0676\n",
      "Epoch 28/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - loss: 0.0061 - mae: 0.0518 - val_loss: 0.0111 - val_mae: 0.0675\n",
      "Epoch 29/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - loss: 0.0063 - mae: 0.0526 - val_loss: 0.0110 - val_mae: 0.0672\n",
      "Epoch 30/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - loss: 0.0064 - mae: 0.0526 - val_loss: 0.0114 - val_mae: 0.0684\n",
      "Epoch 31/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - loss: 0.0059 - mae: 0.0513 - val_loss: 0.0116 - val_mae: 0.0690\n",
      "Epoch 32/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - loss: 0.0060 - mae: 0.0515 - val_loss: 0.0114 - val_mae: 0.0685\n",
      "Epoch 33/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - loss: 0.0061 - mae: 0.0519 - val_loss: 0.0107 - val_mae: 0.0662\n",
      "Epoch 34/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - loss: 0.0062 - mae: 0.0521 - val_loss: 0.0107 - val_mae: 0.0662\n",
      "Epoch 35/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 14ms/step - loss: 0.0061 - mae: 0.0521 - val_loss: 0.0111 - val_mae: 0.0676\n",
      "Epoch 36/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 14ms/step - loss: 0.0061 - mae: 0.0523 - val_loss: 0.0104 - val_mae: 0.0653\n",
      "Epoch 37/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - loss: 0.0065 - mae: 0.0523 - val_loss: 0.0110 - val_mae: 0.0672\n",
      "Epoch 38/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - loss: 0.0060 - mae: 0.0518 - val_loss: 0.0116 - val_mae: 0.0693\n",
      "Epoch 39/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - loss: 0.0062 - mae: 0.0522 - val_loss: 0.0112 - val_mae: 0.0677\n",
      "Epoch 40/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - loss: 0.0060 - mae: 0.0516 - val_loss: 0.0115 - val_mae: 0.0688\n",
      "Epoch 41/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - loss: 0.0063 - mae: 0.0532 - val_loss: 0.0112 - val_mae: 0.0677\n",
      "Epoch 42/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - loss: 0.0066 - mae: 0.0530 - val_loss: 0.0111 - val_mae: 0.0676\n",
      "Epoch 43/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - loss: 0.0064 - mae: 0.0523 - val_loss: 0.0115 - val_mae: 0.0689\n",
      "Epoch 44/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - loss: 0.0065 - mae: 0.0530 - val_loss: 0.0107 - val_mae: 0.0663\n",
      "Epoch 45/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - loss: 0.0062 - mae: 0.0525 - val_loss: 0.0114 - val_mae: 0.0684\n",
      "Epoch 46/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - loss: 0.0064 - mae: 0.0524 - val_loss: 0.0117 - val_mae: 0.0695\n",
      "Epoch 47/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - loss: 0.0062 - mae: 0.0517 - val_loss: 0.0108 - val_mae: 0.0665\n",
      "Epoch 48/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - loss: 0.0062 - mae: 0.0525 - val_loss: 0.0109 - val_mae: 0.0669\n",
      "Epoch 49/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - loss: 0.0058 - mae: 0.0510 - val_loss: 0.0108 - val_mae: 0.0666\n",
      "Epoch 50/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - loss: 0.0061 - mae: 0.0519 - val_loss: 0.0110 - val_mae: 0.0673\n",
      "Epoch 51/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - loss: 0.0061 - mae: 0.0519 - val_loss: 0.0121 - val_mae: 0.0708\n",
      "Epoch 52/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - loss: 0.0061 - mae: 0.0517 - val_loss: 0.0113 - val_mae: 0.0681\n",
      "Epoch 53/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - loss: 0.0060 - mae: 0.0519 - val_loss: 0.0114 - val_mae: 0.0685\n",
      "Epoch 54/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0061 - mae: 0.0513 - val_loss: 0.0107 - val_mae: 0.0664\n",
      "Epoch 55/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - loss: 0.0063 - mae: 0.0525 - val_loss: 0.0113 - val_mae: 0.0680\n",
      "Epoch 56/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0061 - mae: 0.0516 - val_loss: 0.0111 - val_mae: 0.0675\n",
      "Epoch 57/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0062 - mae: 0.0520 - val_loss: 0.0116 - val_mae: 0.0693\n",
      "Epoch 58/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0061 - mae: 0.0511 - val_loss: 0.0117 - val_mae: 0.0694\n",
      "Epoch 59/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0061 - mae: 0.0516 - val_loss: 0.0116 - val_mae: 0.0693\n",
      "Epoch 60/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0058 - mae: 0.0509 - val_loss: 0.0112 - val_mae: 0.0678\n",
      "Epoch 61/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0062 - mae: 0.0527 - val_loss: 0.0117 - val_mae: 0.0696\n",
      "Epoch 62/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0056 - mae: 0.0501 - val_loss: 0.0108 - val_mae: 0.0665\n",
      "Epoch 63/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0061 - mae: 0.0519 - val_loss: 0.0109 - val_mae: 0.0670\n",
      "Epoch 64/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0062 - mae: 0.0519 - val_loss: 0.0115 - val_mae: 0.0689\n",
      "Epoch 65/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - loss: 0.0062 - mae: 0.0516 - val_loss: 0.0113 - val_mae: 0.0681\n",
      "Epoch 66/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0063 - mae: 0.0527 - val_loss: 0.0118 - val_mae: 0.0698\n",
      "Epoch 67/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0063 - mae: 0.0517 - val_loss: 0.0113 - val_mae: 0.0680\n",
      "Epoch 68/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - loss: 0.0061 - mae: 0.0519 - val_loss: 0.0114 - val_mae: 0.0683\n",
      "Epoch 69/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - loss: 0.0061 - mae: 0.0521 - val_loss: 0.0118 - val_mae: 0.0699\n",
      "Epoch 70/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0059 - mae: 0.0510 - val_loss: 0.0110 - val_mae: 0.0672\n",
      "Epoch 71/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0060 - mae: 0.0513 - val_loss: 0.0111 - val_mae: 0.0676\n",
      "Epoch 72/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0062 - mae: 0.0521 - val_loss: 0.0116 - val_mae: 0.0690\n",
      "Epoch 73/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0064 - mae: 0.0523 - val_loss: 0.0113 - val_mae: 0.0682\n",
      "Epoch 74/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0065 - mae: 0.0532 - val_loss: 0.0119 - val_mae: 0.0701\n",
      "Epoch 75/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0062 - mae: 0.0516 - val_loss: 0.0110 - val_mae: 0.0672\n",
      "Epoch 76/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0063 - mae: 0.0527 - val_loss: 0.0114 - val_mae: 0.0685\n",
      "Epoch 77/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0060 - mae: 0.0514 - val_loss: 0.0109 - val_mae: 0.0669\n",
      "Epoch 78/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0060 - mae: 0.0515 - val_loss: 0.0114 - val_mae: 0.0685\n",
      "Epoch 79/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0060 - mae: 0.0517 - val_loss: 0.0110 - val_mae: 0.0673\n",
      "Epoch 80/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0060 - mae: 0.0518 - val_loss: 0.0116 - val_mae: 0.0692\n",
      "Epoch 81/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0061 - mae: 0.0514 - val_loss: 0.0110 - val_mae: 0.0672\n",
      "Epoch 82/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0061 - mae: 0.0519 - val_loss: 0.0113 - val_mae: 0.0682\n",
      "Epoch 83/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0061 - mae: 0.0524 - val_loss: 0.0116 - val_mae: 0.0690\n",
      "Epoch 84/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0058 - mae: 0.0514 - val_loss: 0.0111 - val_mae: 0.0674\n",
      "Epoch 85/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0061 - mae: 0.0516 - val_loss: 0.0116 - val_mae: 0.0692\n",
      "Epoch 86/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0059 - mae: 0.0512 - val_loss: 0.0111 - val_mae: 0.0676\n",
      "Epoch 87/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0062 - mae: 0.0516 - val_loss: 0.0113 - val_mae: 0.0682\n",
      "Epoch 88/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0062 - mae: 0.0518 - val_loss: 0.0113 - val_mae: 0.0681\n",
      "Epoch 89/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0057 - mae: 0.0509 - val_loss: 0.0111 - val_mae: 0.0674\n",
      "Epoch 90/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0063 - mae: 0.0518 - val_loss: 0.0108 - val_mae: 0.0666\n",
      "Epoch 91/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0059 - mae: 0.0516 - val_loss: 0.0117 - val_mae: 0.0694\n",
      "Epoch 92/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0059 - mae: 0.0513 - val_loss: 0.0111 - val_mae: 0.0675\n",
      "Epoch 93/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0062 - mae: 0.0522 - val_loss: 0.0119 - val_mae: 0.0701\n",
      "Epoch 94/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0062 - mae: 0.0511 - val_loss: 0.0114 - val_mae: 0.0684\n",
      "Epoch 95/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0064 - mae: 0.0530 - val_loss: 0.0116 - val_mae: 0.0692\n",
      "Epoch 96/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0061 - mae: 0.0514 - val_loss: 0.0109 - val_mae: 0.0667\n",
      "Epoch 97/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0062 - mae: 0.0518 - val_loss: 0.0112 - val_mae: 0.0678\n",
      "Epoch 98/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0062 - mae: 0.0519 - val_loss: 0.0114 - val_mae: 0.0683\n",
      "Epoch 99/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0058 - mae: 0.0503 - val_loss: 0.0110 - val_mae: 0.0672\n",
      "Epoch 100/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0065 - mae: 0.0526 - val_loss: 0.0110 - val_mae: 0.0671\n",
      "\u001b[1m561/561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step\n",
      "✅ Done with onion_Bangalore_daily.csv | MAE=672.78, RMSE=1022.22, R2=-0.0082, MAPE=43.95%, Accuracy=56.05%\n",
      "\n",
      "🚀 Processing: onion_Belgaum_daily.csv\n",
      "Epoch 1/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0082 - mae: 0.0541 - val_loss: 0.0076 - val_mae: 0.0609\n",
      "Epoch 2/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0068 - mae: 0.0515 - val_loss: 0.0073 - val_mae: 0.0595\n",
      "Epoch 3/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0076 - mae: 0.0545 - val_loss: 0.0071 - val_mae: 0.0584\n",
      "Epoch 4/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0076 - mae: 0.0550 - val_loss: 0.0082 - val_mae: 0.0646\n",
      "Epoch 5/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0082 - mae: 0.0568 - val_loss: 0.0081 - val_mae: 0.0641\n",
      "Epoch 6/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0076 - mae: 0.0539 - val_loss: 0.0084 - val_mae: 0.0659\n",
      "Epoch 7/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0073 - mae: 0.0529 - val_loss: 0.0076 - val_mae: 0.0611\n",
      "Epoch 8/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0072 - mae: 0.0535 - val_loss: 0.0079 - val_mae: 0.0629\n",
      "Epoch 9/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0077 - mae: 0.0545 - val_loss: 0.0087 - val_mae: 0.0673\n",
      "Epoch 10/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0068 - mae: 0.0509 - val_loss: 0.0083 - val_mae: 0.0648\n",
      "Epoch 11/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0064 - mae: 0.0513 - val_loss: 0.0073 - val_mae: 0.0595\n",
      "Epoch 12/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0077 - mae: 0.0559 - val_loss: 0.0089 - val_mae: 0.0687\n",
      "Epoch 13/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0073 - mae: 0.0535 - val_loss: 0.0083 - val_mae: 0.0648\n",
      "Epoch 14/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0086 - mae: 0.0562 - val_loss: 0.0086 - val_mae: 0.0668\n",
      "Epoch 15/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0073 - mae: 0.0524 - val_loss: 0.0078 - val_mae: 0.0623\n",
      "Epoch 16/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0077 - mae: 0.0538 - val_loss: 0.0083 - val_mae: 0.0650\n",
      "Epoch 17/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0068 - mae: 0.0518 - val_loss: 0.0080 - val_mae: 0.0631\n",
      "Epoch 18/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0071 - mae: 0.0527 - val_loss: 0.0082 - val_mae: 0.0642\n",
      "Epoch 19/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0073 - mae: 0.0525 - val_loss: 0.0082 - val_mae: 0.0647\n",
      "Epoch 20/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0077 - mae: 0.0553 - val_loss: 0.0086 - val_mae: 0.0670\n",
      "Epoch 21/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0074 - mae: 0.0539 - val_loss: 0.0079 - val_mae: 0.0628\n",
      "Epoch 22/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0078 - mae: 0.0554 - val_loss: 0.0080 - val_mae: 0.0631\n",
      "Epoch 23/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0084 - mae: 0.0550 - val_loss: 0.0089 - val_mae: 0.0688\n",
      "Epoch 24/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0079 - mae: 0.0528 - val_loss: 0.0086 - val_mae: 0.0669\n",
      "Epoch 25/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0079 - mae: 0.0544 - val_loss: 0.0081 - val_mae: 0.0637\n",
      "Epoch 26/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0088 - mae: 0.0567 - val_loss: 0.0086 - val_mae: 0.0666\n",
      "Epoch 27/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0079 - mae: 0.0543 - val_loss: 0.0088 - val_mae: 0.0679\n",
      "Epoch 28/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0079 - mae: 0.0533 - val_loss: 0.0081 - val_mae: 0.0639\n",
      "Epoch 29/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0073 - mae: 0.0526 - val_loss: 0.0083 - val_mae: 0.0652\n",
      "Epoch 30/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0074 - mae: 0.0537 - val_loss: 0.0083 - val_mae: 0.0653\n",
      "Epoch 31/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0069 - mae: 0.0524 - val_loss: 0.0072 - val_mae: 0.0586\n",
      "Epoch 32/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0076 - mae: 0.0555 - val_loss: 0.0080 - val_mae: 0.0633\n",
      "Epoch 33/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0078 - mae: 0.0559 - val_loss: 0.0085 - val_mae: 0.0664\n",
      "Epoch 34/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0082 - mae: 0.0549 - val_loss: 0.0076 - val_mae: 0.0612\n",
      "Epoch 35/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0083 - mae: 0.0566 - val_loss: 0.0088 - val_mae: 0.0680\n",
      "Epoch 36/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0080 - mae: 0.0544 - val_loss: 0.0080 - val_mae: 0.0632\n",
      "Epoch 37/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0077 - mae: 0.0545 - val_loss: 0.0081 - val_mae: 0.0639\n",
      "Epoch 38/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0073 - mae: 0.0534 - val_loss: 0.0082 - val_mae: 0.0643\n",
      "Epoch 39/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0079 - mae: 0.0542 - val_loss: 0.0092 - val_mae: 0.0702\n",
      "Epoch 40/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0075 - mae: 0.0526 - val_loss: 0.0078 - val_mae: 0.0620\n",
      "Epoch 41/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0082 - mae: 0.0557 - val_loss: 0.0084 - val_mae: 0.0656\n",
      "Epoch 42/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0064 - mae: 0.0509 - val_loss: 0.0076 - val_mae: 0.0609\n",
      "Epoch 43/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0075 - mae: 0.0545 - val_loss: 0.0079 - val_mae: 0.0629\n",
      "Epoch 44/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0069 - mae: 0.0528 - val_loss: 0.0085 - val_mae: 0.0665\n",
      "Epoch 45/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0081 - mae: 0.0531 - val_loss: 0.0084 - val_mae: 0.0660\n",
      "Epoch 46/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0080 - mae: 0.0551 - val_loss: 0.0081 - val_mae: 0.0640\n",
      "Epoch 47/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0081 - mae: 0.0537 - val_loss: 0.0079 - val_mae: 0.0625\n",
      "Epoch 48/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0068 - mae: 0.0518 - val_loss: 0.0075 - val_mae: 0.0603\n",
      "Epoch 49/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0082 - mae: 0.0552 - val_loss: 0.0084 - val_mae: 0.0659\n",
      "Epoch 50/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0082 - mae: 0.0532 - val_loss: 0.0086 - val_mae: 0.0666\n",
      "Epoch 51/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0074 - mae: 0.0529 - val_loss: 0.0075 - val_mae: 0.0606\n",
      "Epoch 52/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0064 - mae: 0.0517 - val_loss: 0.0075 - val_mae: 0.0603\n",
      "Epoch 53/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0070 - mae: 0.0519 - val_loss: 0.0081 - val_mae: 0.0641\n",
      "Epoch 54/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0066 - mae: 0.0518 - val_loss: 0.0083 - val_mae: 0.0651\n",
      "Epoch 55/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0078 - mae: 0.0544 - val_loss: 0.0084 - val_mae: 0.0657\n",
      "Epoch 56/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0078 - mae: 0.0536 - val_loss: 0.0076 - val_mae: 0.0610\n",
      "Epoch 57/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0074 - mae: 0.0547 - val_loss: 0.0080 - val_mae: 0.0633\n",
      "Epoch 58/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0066 - mae: 0.0518 - val_loss: 0.0083 - val_mae: 0.0650\n",
      "Epoch 59/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0072 - mae: 0.0526 - val_loss: 0.0084 - val_mae: 0.0655\n",
      "Epoch 60/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0075 - mae: 0.0536 - val_loss: 0.0081 - val_mae: 0.0641\n",
      "Epoch 61/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0077 - mae: 0.0536 - val_loss: 0.0082 - val_mae: 0.0648\n",
      "Epoch 62/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0070 - mae: 0.0526 - val_loss: 0.0075 - val_mae: 0.0607\n",
      "Epoch 63/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0073 - mae: 0.0537 - val_loss: 0.0081 - val_mae: 0.0638\n",
      "Epoch 64/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0069 - mae: 0.0526 - val_loss: 0.0077 - val_mae: 0.0616\n",
      "Epoch 65/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0072 - mae: 0.0542 - val_loss: 0.0083 - val_mae: 0.0651\n",
      "Epoch 66/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0069 - mae: 0.0520 - val_loss: 0.0082 - val_mae: 0.0644\n",
      "Epoch 67/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0074 - mae: 0.0520 - val_loss: 0.0082 - val_mae: 0.0645\n",
      "Epoch 68/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0074 - mae: 0.0536 - val_loss: 0.0083 - val_mae: 0.0651\n",
      "Epoch 69/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0081 - mae: 0.0545 - val_loss: 0.0082 - val_mae: 0.0646\n",
      "Epoch 70/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0076 - mae: 0.0550 - val_loss: 0.0081 - val_mae: 0.0639\n",
      "Epoch 71/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0089 - mae: 0.0562 - val_loss: 0.0083 - val_mae: 0.0653\n",
      "Epoch 72/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0080 - mae: 0.0544 - val_loss: 0.0081 - val_mae: 0.0640\n",
      "Epoch 73/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0065 - mae: 0.0506 - val_loss: 0.0085 - val_mae: 0.0662\n",
      "Epoch 74/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0075 - mae: 0.0531 - val_loss: 0.0082 - val_mae: 0.0644\n",
      "Epoch 75/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0073 - mae: 0.0524 - val_loss: 0.0079 - val_mae: 0.0625\n",
      "Epoch 76/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0076 - mae: 0.0543 - val_loss: 0.0083 - val_mae: 0.0649\n",
      "Epoch 77/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0070 - mae: 0.0515 - val_loss: 0.0080 - val_mae: 0.0634\n",
      "Epoch 78/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0066 - mae: 0.0508 - val_loss: 0.0080 - val_mae: 0.0632\n",
      "Epoch 79/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0070 - mae: 0.0534 - val_loss: 0.0085 - val_mae: 0.0660\n",
      "Epoch 80/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0078 - mae: 0.0543 - val_loss: 0.0085 - val_mae: 0.0665\n",
      "Epoch 81/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0071 - mae: 0.0533 - val_loss: 0.0084 - val_mae: 0.0654\n",
      "Epoch 82/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0079 - mae: 0.0546 - val_loss: 0.0089 - val_mae: 0.0684\n",
      "Epoch 83/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0075 - mae: 0.0533 - val_loss: 0.0084 - val_mae: 0.0656\n",
      "Epoch 84/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0075 - mae: 0.0527 - val_loss: 0.0080 - val_mae: 0.0633\n",
      "Epoch 85/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0080 - mae: 0.0543 - val_loss: 0.0074 - val_mae: 0.0600\n",
      "Epoch 86/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0073 - mae: 0.0536 - val_loss: 0.0080 - val_mae: 0.0636\n",
      "Epoch 87/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0075 - mae: 0.0543 - val_loss: 0.0085 - val_mae: 0.0664\n",
      "Epoch 88/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0087 - mae: 0.0547 - val_loss: 0.0085 - val_mae: 0.0660\n",
      "Epoch 89/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0069 - mae: 0.0526 - val_loss: 0.0079 - val_mae: 0.0628\n",
      "Epoch 90/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0080 - mae: 0.0545 - val_loss: 0.0087 - val_mae: 0.0672\n",
      "Epoch 91/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0073 - mae: 0.0534 - val_loss: 0.0081 - val_mae: 0.0637\n",
      "Epoch 92/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0068 - mae: 0.0509 - val_loss: 0.0074 - val_mae: 0.0602\n",
      "Epoch 93/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0070 - mae: 0.0537 - val_loss: 0.0077 - val_mae: 0.0618\n",
      "Epoch 94/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0071 - mae: 0.0530 - val_loss: 0.0081 - val_mae: 0.0642\n",
      "Epoch 95/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0070 - mae: 0.0515 - val_loss: 0.0078 - val_mae: 0.0624\n",
      "Epoch 96/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0072 - mae: 0.0533 - val_loss: 0.0081 - val_mae: 0.0637\n",
      "Epoch 97/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0068 - mae: 0.0532 - val_loss: 0.0084 - val_mae: 0.0659\n",
      "Epoch 98/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0068 - mae: 0.0526 - val_loss: 0.0079 - val_mae: 0.0627\n",
      "Epoch 99/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0081 - mae: 0.0561 - val_loss: 0.0085 - val_mae: 0.0661\n",
      "Epoch 100/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0085 - mae: 0.0563 - val_loss: 0.0079 - val_mae: 0.0628\n",
      "\u001b[1m201/201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "✅ Done with onion_Belgaum_daily.csv | MAE=638.73, RMSE=996.54, R2=-0.0143, MAPE=53.05%, Accuracy=46.95%\n",
      "\n",
      "🚀 Processing: onion_Bellary_daily.csv\n",
      "Epoch 1/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0065 - mae: 0.0574 - val_loss: 0.0031 - val_mae: 0.0392\n",
      "Epoch 2/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0031 - mae: 0.0399 - val_loss: 0.0034 - val_mae: 0.0424\n",
      "Epoch 3/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0029 - mae: 0.0383 - val_loss: 0.0030 - val_mae: 0.0382\n",
      "Epoch 4/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0029 - mae: 0.0381 - val_loss: 0.0033 - val_mae: 0.0417\n",
      "Epoch 5/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0033 - mae: 0.0392 - val_loss: 0.0029 - val_mae: 0.0378\n",
      "Epoch 6/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0027 - mae: 0.0376 - val_loss: 0.0029 - val_mae: 0.0378\n",
      "Epoch 7/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0033 - mae: 0.0398 - val_loss: 0.0033 - val_mae: 0.0413\n",
      "Epoch 8/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0027 - mae: 0.0379 - val_loss: 0.0034 - val_mae: 0.0425\n",
      "Epoch 9/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0029 - mae: 0.0381 - val_loss: 0.0032 - val_mae: 0.0407\n",
      "Epoch 10/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0029 - mae: 0.0378 - val_loss: 0.0028 - val_mae: 0.0368\n",
      "Epoch 11/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0028 - mae: 0.0381 - val_loss: 0.0031 - val_mae: 0.0393\n",
      "Epoch 12/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0029 - mae: 0.0386 - val_loss: 0.0032 - val_mae: 0.0399\n",
      "Epoch 13/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0026 - mae: 0.0372 - val_loss: 0.0030 - val_mae: 0.0381\n",
      "Epoch 14/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0027 - mae: 0.0378 - val_loss: 0.0033 - val_mae: 0.0410\n",
      "Epoch 15/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0030 - mae: 0.0384 - val_loss: 0.0034 - val_mae: 0.0421\n",
      "Epoch 16/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0028 - mae: 0.0380 - val_loss: 0.0030 - val_mae: 0.0382\n",
      "Epoch 17/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0027 - mae: 0.0377 - val_loss: 0.0034 - val_mae: 0.0425\n",
      "Epoch 18/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0030 - mae: 0.0380 - val_loss: 0.0031 - val_mae: 0.0397\n",
      "Epoch 19/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0029 - mae: 0.0382 - val_loss: 0.0030 - val_mae: 0.0384\n",
      "Epoch 20/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0030 - mae: 0.0387 - val_loss: 0.0030 - val_mae: 0.0386\n",
      "Epoch 21/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0026 - mae: 0.0383 - val_loss: 0.0032 - val_mae: 0.0401\n",
      "Epoch 22/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0032 - mae: 0.0389 - val_loss: 0.0034 - val_mae: 0.0423\n",
      "Epoch 23/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0028 - mae: 0.0362 - val_loss: 0.0030 - val_mae: 0.0388\n",
      "Epoch 24/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0029 - mae: 0.0384 - val_loss: 0.0031 - val_mae: 0.0397\n",
      "Epoch 25/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0029 - mae: 0.0384 - val_loss: 0.0036 - val_mae: 0.0443\n",
      "Epoch 26/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0028 - mae: 0.0381 - val_loss: 0.0028 - val_mae: 0.0366\n",
      "Epoch 27/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0028 - mae: 0.0381 - val_loss: 0.0032 - val_mae: 0.0402\n",
      "Epoch 28/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0035 - mae: 0.0387 - val_loss: 0.0031 - val_mae: 0.0394\n",
      "Epoch 29/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0030 - mae: 0.0390 - val_loss: 0.0031 - val_mae: 0.0391\n",
      "Epoch 30/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0030 - mae: 0.0383 - val_loss: 0.0032 - val_mae: 0.0401\n",
      "Epoch 31/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0029 - mae: 0.0383 - val_loss: 0.0034 - val_mae: 0.0422\n",
      "Epoch 32/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0028 - mae: 0.0373 - val_loss: 0.0031 - val_mae: 0.0391\n",
      "Epoch 33/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0030 - mae: 0.0387 - val_loss: 0.0033 - val_mae: 0.0415\n",
      "Epoch 34/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0032 - mae: 0.0383 - val_loss: 0.0029 - val_mae: 0.0371\n",
      "Epoch 35/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0029 - mae: 0.0389 - val_loss: 0.0030 - val_mae: 0.0387\n",
      "Epoch 36/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0027 - mae: 0.0376 - val_loss: 0.0029 - val_mae: 0.0378\n",
      "Epoch 37/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0028 - mae: 0.0386 - val_loss: 0.0027 - val_mae: 0.0357\n",
      "Epoch 38/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0034 - mae: 0.0392 - val_loss: 0.0032 - val_mae: 0.0404\n",
      "Epoch 39/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0027 - mae: 0.0378 - val_loss: 0.0034 - val_mae: 0.0428\n",
      "Epoch 40/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0030 - mae: 0.0388 - val_loss: 0.0031 - val_mae: 0.0398\n",
      "Epoch 41/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0035 - mae: 0.0386 - val_loss: 0.0032 - val_mae: 0.0405\n",
      "Epoch 42/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0027 - mae: 0.0372 - val_loss: 0.0030 - val_mae: 0.0385\n",
      "Epoch 43/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0027 - mae: 0.0375 - val_loss: 0.0030 - val_mae: 0.0386\n",
      "Epoch 44/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0029 - mae: 0.0380 - val_loss: 0.0031 - val_mae: 0.0397\n",
      "Epoch 45/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0028 - mae: 0.0381 - val_loss: 0.0031 - val_mae: 0.0398\n",
      "Epoch 46/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0026 - mae: 0.0372 - val_loss: 0.0030 - val_mae: 0.0382\n",
      "Epoch 47/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0027 - mae: 0.0374 - val_loss: 0.0032 - val_mae: 0.0401\n",
      "Epoch 48/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0030 - mae: 0.0379 - val_loss: 0.0029 - val_mae: 0.0372\n",
      "Epoch 49/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0033 - mae: 0.0392 - val_loss: 0.0031 - val_mae: 0.0398\n",
      "Epoch 50/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0029 - mae: 0.0380 - val_loss: 0.0031 - val_mae: 0.0395\n",
      "Epoch 51/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0028 - mae: 0.0382 - val_loss: 0.0031 - val_mae: 0.0392\n",
      "Epoch 52/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0030 - mae: 0.0384 - val_loss: 0.0032 - val_mae: 0.0400\n",
      "Epoch 53/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0029 - mae: 0.0384 - val_loss: 0.0033 - val_mae: 0.0412\n",
      "Epoch 54/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0031 - mae: 0.0382 - val_loss: 0.0029 - val_mae: 0.0375\n",
      "Epoch 55/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0026 - mae: 0.0376 - val_loss: 0.0032 - val_mae: 0.0406\n",
      "Epoch 56/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0026 - mae: 0.0373 - val_loss: 0.0031 - val_mae: 0.0394\n",
      "Epoch 57/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0025 - mae: 0.0370 - val_loss: 0.0030 - val_mae: 0.0381\n",
      "Epoch 58/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0033 - mae: 0.0381 - val_loss: 0.0034 - val_mae: 0.0426\n",
      "Epoch 59/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0034 - mae: 0.0392 - val_loss: 0.0033 - val_mae: 0.0411\n",
      "Epoch 60/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0028 - mae: 0.0378 - val_loss: 0.0034 - val_mae: 0.0425\n",
      "Epoch 61/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0029 - mae: 0.0382 - val_loss: 0.0030 - val_mae: 0.0388\n",
      "Epoch 62/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0035 - mae: 0.0392 - val_loss: 0.0033 - val_mae: 0.0413\n",
      "Epoch 63/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0028 - mae: 0.0375 - val_loss: 0.0034 - val_mae: 0.0425\n",
      "Epoch 64/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0028 - mae: 0.0377 - val_loss: 0.0031 - val_mae: 0.0393\n",
      "Epoch 65/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0030 - mae: 0.0391 - val_loss: 0.0033 - val_mae: 0.0417\n",
      "Epoch 66/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0028 - mae: 0.0372 - val_loss: 0.0030 - val_mae: 0.0388\n",
      "Epoch 67/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0024 - mae: 0.0366 - val_loss: 0.0028 - val_mae: 0.0367\n",
      "Epoch 68/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0027 - mae: 0.0371 - val_loss: 0.0028 - val_mae: 0.0369\n",
      "Epoch 69/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0031 - mae: 0.0381 - val_loss: 0.0030 - val_mae: 0.0381\n",
      "Epoch 70/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0032 - mae: 0.0391 - val_loss: 0.0031 - val_mae: 0.0396\n",
      "Epoch 71/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0029 - mae: 0.0391 - val_loss: 0.0032 - val_mae: 0.0399\n",
      "Epoch 72/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0027 - mae: 0.0380 - val_loss: 0.0029 - val_mae: 0.0374\n",
      "Epoch 73/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0030 - mae: 0.0391 - val_loss: 0.0031 - val_mae: 0.0390\n",
      "Epoch 74/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0033 - mae: 0.0387 - val_loss: 0.0030 - val_mae: 0.0387\n",
      "Epoch 75/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0032 - mae: 0.0379 - val_loss: 0.0033 - val_mae: 0.0409\n",
      "Epoch 76/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0029 - mae: 0.0375 - val_loss: 0.0030 - val_mae: 0.0386\n",
      "Epoch 77/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0029 - mae: 0.0374 - val_loss: 0.0029 - val_mae: 0.0370\n",
      "Epoch 78/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0028 - mae: 0.0381 - val_loss: 0.0034 - val_mae: 0.0427\n",
      "Epoch 79/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0027 - mae: 0.0374 - val_loss: 0.0034 - val_mae: 0.0420\n",
      "Epoch 80/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0032 - mae: 0.0394 - val_loss: 0.0033 - val_mae: 0.0417\n",
      "Epoch 81/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0031 - mae: 0.0386 - val_loss: 0.0034 - val_mae: 0.0422\n",
      "Epoch 82/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0028 - mae: 0.0384 - val_loss: 0.0031 - val_mae: 0.0396\n",
      "Epoch 83/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0028 - mae: 0.0382 - val_loss: 0.0029 - val_mae: 0.0375\n",
      "Epoch 84/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0029 - mae: 0.0384 - val_loss: 0.0030 - val_mae: 0.0384\n",
      "Epoch 85/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0029 - mae: 0.0386 - val_loss: 0.0032 - val_mae: 0.0402\n",
      "Epoch 86/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0027 - mae: 0.0377 - val_loss: 0.0031 - val_mae: 0.0393\n",
      "Epoch 87/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0029 - mae: 0.0384 - val_loss: 0.0031 - val_mae: 0.0396\n",
      "Epoch 88/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0032 - mae: 0.0390 - val_loss: 0.0033 - val_mae: 0.0416\n",
      "Epoch 89/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0027 - mae: 0.0380 - val_loss: 0.0030 - val_mae: 0.0385\n",
      "Epoch 90/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0035 - mae: 0.0383 - val_loss: 0.0030 - val_mae: 0.0381\n",
      "Epoch 91/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0031 - mae: 0.0386 - val_loss: 0.0032 - val_mae: 0.0404\n",
      "Epoch 92/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0027 - mae: 0.0376 - val_loss: 0.0028 - val_mae: 0.0369\n",
      "Epoch 93/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0030 - mae: 0.0387 - val_loss: 0.0034 - val_mae: 0.0426\n",
      "Epoch 94/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0030 - mae: 0.0387 - val_loss: 0.0030 - val_mae: 0.0382\n",
      "Epoch 95/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0027 - mae: 0.0377 - val_loss: 0.0031 - val_mae: 0.0396\n",
      "Epoch 96/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0034 - mae: 0.0384 - val_loss: 0.0032 - val_mae: 0.0402\n",
      "Epoch 97/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0030 - mae: 0.0383 - val_loss: 0.0029 - val_mae: 0.0377\n",
      "Epoch 98/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0028 - mae: 0.0371 - val_loss: 0.0030 - val_mae: 0.0384\n",
      "Epoch 99/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0026 - mae: 0.0377 - val_loss: 0.0032 - val_mae: 0.0402\n",
      "Epoch 100/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0027 - mae: 0.0378 - val_loss: 0.0031 - val_mae: 0.0398\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "✅ Done with onion_Bellary_daily.csv | MAE=427.62, RMSE=605.65, R2=-0.0206, MAPE=35.33%, Accuracy=64.67%\n",
      "\n",
      "🚀 Processing: onion_Bidar_daily.csv\n",
      "Epoch 1/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0171 - mae: 0.1068 - val_loss: 0.0203 - val_mae: 0.1046\n",
      "Epoch 2/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0088 - mae: 0.0787 - val_loss: 0.0206 - val_mae: 0.1063\n",
      "Epoch 3/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0077 - mae: 0.0769 - val_loss: 0.0193 - val_mae: 0.0997\n",
      "Epoch 4/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0083 - mae: 0.0777 - val_loss: 0.0192 - val_mae: 0.0995\n",
      "Epoch 5/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0081 - mae: 0.0777 - val_loss: 0.0209 - val_mae: 0.1078\n",
      "Epoch 6/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0079 - mae: 0.0773 - val_loss: 0.0208 - val_mae: 0.1071\n",
      "Epoch 7/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0082 - mae: 0.0781 - val_loss: 0.0204 - val_mae: 0.1054\n",
      "Epoch 8/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0079 - mae: 0.0776 - val_loss: 0.0204 - val_mae: 0.1051\n",
      "Epoch 9/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0080 - mae: 0.0782 - val_loss: 0.0190 - val_mae: 0.0982\n",
      "Epoch 10/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0086 - mae: 0.0792 - val_loss: 0.0210 - val_mae: 0.1079\n",
      "Epoch 11/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0086 - mae: 0.0783 - val_loss: 0.0188 - val_mae: 0.0973\n",
      "Epoch 12/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0080 - mae: 0.0779 - val_loss: 0.0196 - val_mae: 0.1015\n",
      "Epoch 13/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0086 - mae: 0.0784 - val_loss: 0.0205 - val_mae: 0.1060\n",
      "Epoch 14/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0083 - mae: 0.0777 - val_loss: 0.0215 - val_mae: 0.1103\n",
      "Epoch 15/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0083 - mae: 0.0786 - val_loss: 0.0208 - val_mae: 0.1071\n",
      "Epoch 16/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0082 - mae: 0.0780 - val_loss: 0.0196 - val_mae: 0.1013\n",
      "Epoch 17/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0084 - mae: 0.0787 - val_loss: 0.0199 - val_mae: 0.1029\n",
      "Epoch 18/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0082 - mae: 0.0776 - val_loss: 0.0207 - val_mae: 0.1067\n",
      "Epoch 19/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0081 - mae: 0.0784 - val_loss: 0.0211 - val_mae: 0.1086\n",
      "Epoch 20/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0080 - mae: 0.0774 - val_loss: 0.0197 - val_mae: 0.1021\n",
      "Epoch 21/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0083 - mae: 0.0786 - val_loss: 0.0200 - val_mae: 0.1032\n",
      "Epoch 22/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0080 - mae: 0.0770 - val_loss: 0.0191 - val_mae: 0.0992\n",
      "Epoch 23/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0089 - mae: 0.0788 - val_loss: 0.0196 - val_mae: 0.1013\n",
      "Epoch 24/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0084 - mae: 0.0776 - val_loss: 0.0200 - val_mae: 0.1034\n",
      "Epoch 25/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0082 - mae: 0.0774 - val_loss: 0.0212 - val_mae: 0.1091\n",
      "Epoch 26/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0080 - mae: 0.0779 - val_loss: 0.0202 - val_mae: 0.1045\n",
      "Epoch 27/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0083 - mae: 0.0783 - val_loss: 0.0204 - val_mae: 0.1051\n",
      "Epoch 28/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0081 - mae: 0.0775 - val_loss: 0.0215 - val_mae: 0.1106\n",
      "Epoch 29/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0083 - mae: 0.0784 - val_loss: 0.0195 - val_mae: 0.1010\n",
      "Epoch 30/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0083 - mae: 0.0790 - val_loss: 0.0188 - val_mae: 0.0976\n",
      "Epoch 31/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0081 - mae: 0.0780 - val_loss: 0.0195 - val_mae: 0.1011\n",
      "Epoch 32/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0081 - mae: 0.0784 - val_loss: 0.0205 - val_mae: 0.1056\n",
      "Epoch 33/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0086 - mae: 0.0785 - val_loss: 0.0203 - val_mae: 0.1049\n",
      "Epoch 34/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0083 - mae: 0.0784 - val_loss: 0.0189 - val_mae: 0.0980\n",
      "Epoch 35/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0083 - mae: 0.0792 - val_loss: 0.0199 - val_mae: 0.1029\n",
      "Epoch 36/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0084 - mae: 0.0780 - val_loss: 0.0204 - val_mae: 0.1052\n",
      "Epoch 37/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0085 - mae: 0.0777 - val_loss: 0.0193 - val_mae: 0.1000\n",
      "Epoch 38/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0080 - mae: 0.0773 - val_loss: 0.0198 - val_mae: 0.1025\n",
      "Epoch 39/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0079 - mae: 0.0774 - val_loss: 0.0204 - val_mae: 0.1054\n",
      "Epoch 40/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0082 - mae: 0.0777 - val_loss: 0.0212 - val_mae: 0.1088\n",
      "Epoch 41/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0084 - mae: 0.0782 - val_loss: 0.0203 - val_mae: 0.1048\n",
      "Epoch 42/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0081 - mae: 0.0781 - val_loss: 0.0204 - val_mae: 0.1055\n",
      "Epoch 43/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0081 - mae: 0.0783 - val_loss: 0.0207 - val_mae: 0.1068\n",
      "Epoch 44/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0082 - mae: 0.0777 - val_loss: 0.0195 - val_mae: 0.1010\n",
      "Epoch 45/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0082 - mae: 0.0778 - val_loss: 0.0209 - val_mae: 0.1078\n",
      "Epoch 46/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0081 - mae: 0.0778 - val_loss: 0.0225 - val_mae: 0.1147\n",
      "Epoch 47/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0079 - mae: 0.0765 - val_loss: 0.0183 - val_mae: 0.0949\n",
      "Epoch 48/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0079 - mae: 0.0771 - val_loss: 0.0213 - val_mae: 0.1094\n",
      "Epoch 49/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0080 - mae: 0.0773 - val_loss: 0.0207 - val_mae: 0.1068\n",
      "Epoch 50/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0083 - mae: 0.0775 - val_loss: 0.0214 - val_mae: 0.1099\n",
      "Epoch 51/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0090 - mae: 0.0789 - val_loss: 0.0209 - val_mae: 0.1076\n",
      "Epoch 52/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0082 - mae: 0.0783 - val_loss: 0.0187 - val_mae: 0.0971\n",
      "Epoch 53/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0082 - mae: 0.0781 - val_loss: 0.0199 - val_mae: 0.1027\n",
      "Epoch 54/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0096 - mae: 0.0802 - val_loss: 0.0211 - val_mae: 0.1086\n",
      "Epoch 55/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0080 - mae: 0.0764 - val_loss: 0.0213 - val_mae: 0.1094\n",
      "Epoch 56/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0081 - mae: 0.0779 - val_loss: 0.0206 - val_mae: 0.1063\n",
      "Epoch 57/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0082 - mae: 0.0782 - val_loss: 0.0202 - val_mae: 0.1043\n",
      "Epoch 58/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0085 - mae: 0.0784 - val_loss: 0.0205 - val_mae: 0.1057\n",
      "Epoch 59/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0082 - mae: 0.0782 - val_loss: 0.0212 - val_mae: 0.1092\n",
      "Epoch 60/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0081 - mae: 0.0786 - val_loss: 0.0210 - val_mae: 0.1080\n",
      "Epoch 61/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0080 - mae: 0.0778 - val_loss: 0.0188 - val_mae: 0.0976\n",
      "Epoch 62/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0080 - mae: 0.0773 - val_loss: 0.0184 - val_mae: 0.0954\n",
      "Epoch 63/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0085 - mae: 0.0789 - val_loss: 0.0197 - val_mae: 0.1020\n",
      "Epoch 64/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0079 - mae: 0.0777 - val_loss: 0.0216 - val_mae: 0.1110\n",
      "Epoch 65/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0080 - mae: 0.0779 - val_loss: 0.0199 - val_mae: 0.1027\n",
      "Epoch 66/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0086 - mae: 0.0790 - val_loss: 0.0210 - val_mae: 0.1081\n",
      "Epoch 67/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0086 - mae: 0.0791 - val_loss: 0.0204 - val_mae: 0.1054\n",
      "Epoch 68/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0081 - mae: 0.0782 - val_loss: 0.0209 - val_mae: 0.1076\n",
      "Epoch 69/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0087 - mae: 0.0790 - val_loss: 0.0205 - val_mae: 0.1056\n",
      "Epoch 70/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0083 - mae: 0.0778 - val_loss: 0.0198 - val_mae: 0.1023\n",
      "Epoch 71/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0082 - mae: 0.0778 - val_loss: 0.0203 - val_mae: 0.1046\n",
      "Epoch 72/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0084 - mae: 0.0783 - val_loss: 0.0203 - val_mae: 0.1049\n",
      "Epoch 73/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0080 - mae: 0.0763 - val_loss: 0.0211 - val_mae: 0.1086\n",
      "Epoch 74/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0081 - mae: 0.0780 - val_loss: 0.0204 - val_mae: 0.1052\n",
      "Epoch 75/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0085 - mae: 0.0789 - val_loss: 0.0195 - val_mae: 0.1009\n",
      "Epoch 76/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0084 - mae: 0.0786 - val_loss: 0.0211 - val_mae: 0.1085\n",
      "Epoch 77/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0088 - mae: 0.0791 - val_loss: 0.0206 - val_mae: 0.1064\n",
      "Epoch 78/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0080 - mae: 0.0771 - val_loss: 0.0205 - val_mae: 0.1058\n",
      "Epoch 79/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0088 - mae: 0.0782 - val_loss: 0.0223 - val_mae: 0.1138\n",
      "Epoch 80/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0084 - mae: 0.0787 - val_loss: 0.0208 - val_mae: 0.1072\n",
      "Epoch 81/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0085 - mae: 0.0787 - val_loss: 0.0209 - val_mae: 0.1075\n",
      "Epoch 82/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0087 - mae: 0.0783 - val_loss: 0.0201 - val_mae: 0.1038\n",
      "Epoch 83/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0080 - mae: 0.0774 - val_loss: 0.0199 - val_mae: 0.1027\n",
      "Epoch 84/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0084 - mae: 0.0783 - val_loss: 0.0207 - val_mae: 0.1069\n",
      "Epoch 85/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0083 - mae: 0.0782 - val_loss: 0.0207 - val_mae: 0.1066\n",
      "Epoch 86/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0083 - mae: 0.0781 - val_loss: 0.0204 - val_mae: 0.1054\n",
      "Epoch 87/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0081 - mae: 0.0785 - val_loss: 0.0199 - val_mae: 0.1028\n",
      "Epoch 88/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0083 - mae: 0.0781 - val_loss: 0.0189 - val_mae: 0.0979\n",
      "Epoch 89/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0083 - mae: 0.0782 - val_loss: 0.0187 - val_mae: 0.0970\n",
      "Epoch 90/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0086 - mae: 0.0786 - val_loss: 0.0195 - val_mae: 0.1009\n",
      "Epoch 91/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0080 - mae: 0.0780 - val_loss: 0.0186 - val_mae: 0.0965\n",
      "Epoch 92/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0082 - mae: 0.0780 - val_loss: 0.0202 - val_mae: 0.1042\n",
      "Epoch 93/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0079 - mae: 0.0772 - val_loss: 0.0189 - val_mae: 0.0977\n",
      "Epoch 94/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0089 - mae: 0.0792 - val_loss: 0.0210 - val_mae: 0.1083\n",
      "Epoch 95/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.0080 - mae: 0.0780 - val_loss: 0.0199 - val_mae: 0.1031\n",
      "Epoch 96/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0081 - mae: 0.0780 - val_loss: 0.0195 - val_mae: 0.1007\n",
      "Epoch 97/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0082 - mae: 0.0784 - val_loss: 0.0193 - val_mae: 0.0998\n",
      "Epoch 98/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0081 - mae: 0.0781 - val_loss: 0.0196 - val_mae: 0.1015\n",
      "Epoch 99/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0081 - mae: 0.0778 - val_loss: 0.0206 - val_mae: 0.1064\n",
      "Epoch 100/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0083 - mae: 0.0784 - val_loss: 0.0193 - val_mae: 0.0998\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "✅ Done with onion_Bidar_daily.csv | MAE=327.88, RMSE=406.42, R2=-0.0272, MAPE=36.27%, Accuracy=63.73%\n",
      "\n",
      "🚀 Processing: onion_Bijapur_daily.csv\n",
      "Epoch 1/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0079 - mae: 0.0651 - val_loss: 0.0052 - val_mae: 0.0520\n",
      "Epoch 2/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0046 - mae: 0.0509 - val_loss: 0.0052 - val_mae: 0.0520\n",
      "Epoch 3/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0045 - mae: 0.0509 - val_loss: 0.0051 - val_mae: 0.0520\n",
      "Epoch 4/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0047 - mae: 0.0518 - val_loss: 0.0052 - val_mae: 0.0520\n",
      "Epoch 5/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0044 - mae: 0.0513 - val_loss: 0.0050 - val_mae: 0.0522\n",
      "Epoch 6/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0052 - mae: 0.0526 - val_loss: 0.0050 - val_mae: 0.0522\n",
      "Epoch 7/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0047 - mae: 0.0521 - val_loss: 0.0050 - val_mae: 0.0522\n",
      "Epoch 8/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0047 - mae: 0.0517 - val_loss: 0.0051 - val_mae: 0.0520\n",
      "Epoch 9/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0049 - mae: 0.0525 - val_loss: 0.0051 - val_mae: 0.0520\n",
      "Epoch 10/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0051 - mae: 0.0524 - val_loss: 0.0050 - val_mae: 0.0521\n",
      "Epoch 11/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0043 - mae: 0.0511 - val_loss: 0.0050 - val_mae: 0.0521\n",
      "Epoch 12/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0044 - mae: 0.0509 - val_loss: 0.0051 - val_mae: 0.0520\n",
      "Epoch 13/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0047 - mae: 0.0518 - val_loss: 0.0051 - val_mae: 0.0520\n",
      "Epoch 14/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0048 - mae: 0.0518 - val_loss: 0.0050 - val_mae: 0.0522\n",
      "Epoch 15/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0044 - mae: 0.0512 - val_loss: 0.0051 - val_mae: 0.0520\n",
      "Epoch 16/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0044 - mae: 0.0506 - val_loss: 0.0050 - val_mae: 0.0522\n",
      "Epoch 17/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0050 - mae: 0.0525 - val_loss: 0.0050 - val_mae: 0.0522\n",
      "Epoch 18/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0043 - mae: 0.0503 - val_loss: 0.0049 - val_mae: 0.0525\n",
      "Epoch 19/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0046 - mae: 0.0514 - val_loss: 0.0051 - val_mae: 0.0520\n",
      "Epoch 20/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0047 - mae: 0.0507 - val_loss: 0.0049 - val_mae: 0.0525\n",
      "Epoch 21/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0047 - mae: 0.0515 - val_loss: 0.0052 - val_mae: 0.0520\n",
      "Epoch 22/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0045 - mae: 0.0512 - val_loss: 0.0051 - val_mae: 0.0520\n",
      "Epoch 23/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0046 - mae: 0.0516 - val_loss: 0.0052 - val_mae: 0.0520\n",
      "Epoch 24/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0045 - mae: 0.0512 - val_loss: 0.0050 - val_mae: 0.0521\n",
      "Epoch 25/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0046 - mae: 0.0510 - val_loss: 0.0053 - val_mae: 0.0522\n",
      "Epoch 26/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0045 - mae: 0.0513 - val_loss: 0.0052 - val_mae: 0.0520\n",
      "Epoch 27/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0050 - mae: 0.0527 - val_loss: 0.0051 - val_mae: 0.0520\n",
      "Epoch 28/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0048 - mae: 0.0523 - val_loss: 0.0053 - val_mae: 0.0521\n",
      "Epoch 29/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0046 - mae: 0.0515 - val_loss: 0.0049 - val_mae: 0.0523\n",
      "Epoch 30/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0047 - mae: 0.0517 - val_loss: 0.0051 - val_mae: 0.0520\n",
      "Epoch 31/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0046 - mae: 0.0516 - val_loss: 0.0049 - val_mae: 0.0525\n",
      "Epoch 32/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0046 - mae: 0.0514 - val_loss: 0.0052 - val_mae: 0.0520\n",
      "Epoch 33/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0047 - mae: 0.0514 - val_loss: 0.0050 - val_mae: 0.0521\n",
      "Epoch 34/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0045 - mae: 0.0520 - val_loss: 0.0051 - val_mae: 0.0520\n",
      "Epoch 35/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0048 - mae: 0.0518 - val_loss: 0.0050 - val_mae: 0.0521\n",
      "Epoch 36/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0049 - mae: 0.0518 - val_loss: 0.0051 - val_mae: 0.0520\n",
      "Epoch 37/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0047 - mae: 0.0516 - val_loss: 0.0050 - val_mae: 0.0522\n",
      "Epoch 38/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0045 - mae: 0.0514 - val_loss: 0.0050 - val_mae: 0.0521\n",
      "Epoch 39/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0046 - mae: 0.0518 - val_loss: 0.0050 - val_mae: 0.0521\n",
      "Epoch 40/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0047 - mae: 0.0520 - val_loss: 0.0050 - val_mae: 0.0521\n",
      "Epoch 41/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0049 - mae: 0.0523 - val_loss: 0.0055 - val_mae: 0.0525\n",
      "Epoch 42/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0046 - mae: 0.0513 - val_loss: 0.0051 - val_mae: 0.0520\n",
      "Epoch 43/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0048 - mae: 0.0521 - val_loss: 0.0050 - val_mae: 0.0521\n",
      "Epoch 44/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0050 - mae: 0.0523 - val_loss: 0.0051 - val_mae: 0.0520\n",
      "Epoch 45/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0046 - mae: 0.0510 - val_loss: 0.0050 - val_mae: 0.0522\n",
      "Epoch 46/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0051 - mae: 0.0530 - val_loss: 0.0051 - val_mae: 0.0520\n",
      "Epoch 47/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0045 - mae: 0.0510 - val_loss: 0.0050 - val_mae: 0.0522\n",
      "Epoch 48/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0051 - mae: 0.0522 - val_loss: 0.0051 - val_mae: 0.0520\n",
      "Epoch 49/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0044 - mae: 0.0511 - val_loss: 0.0049 - val_mae: 0.0524\n",
      "Epoch 50/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0043 - mae: 0.0510 - val_loss: 0.0051 - val_mae: 0.0520\n",
      "Epoch 51/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0046 - mae: 0.0519 - val_loss: 0.0051 - val_mae: 0.0520\n",
      "Epoch 52/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0048 - mae: 0.0519 - val_loss: 0.0051 - val_mae: 0.0520\n",
      "Epoch 53/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0046 - mae: 0.0515 - val_loss: 0.0050 - val_mae: 0.0521\n",
      "Epoch 54/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0045 - mae: 0.0517 - val_loss: 0.0051 - val_mae: 0.0520\n",
      "Epoch 55/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0046 - mae: 0.0514 - val_loss: 0.0050 - val_mae: 0.0522\n",
      "Epoch 56/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0045 - mae: 0.0516 - val_loss: 0.0051 - val_mae: 0.0520\n",
      "Epoch 57/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0047 - mae: 0.0518 - val_loss: 0.0052 - val_mae: 0.0520\n",
      "Epoch 58/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0047 - mae: 0.0513 - val_loss: 0.0051 - val_mae: 0.0520\n",
      "Epoch 59/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0048 - mae: 0.0520 - val_loss: 0.0050 - val_mae: 0.0521\n",
      "Epoch 60/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0049 - mae: 0.0516 - val_loss: 0.0050 - val_mae: 0.0523\n",
      "Epoch 61/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0049 - mae: 0.0522 - val_loss: 0.0051 - val_mae: 0.0520\n",
      "Epoch 62/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0047 - mae: 0.0520 - val_loss: 0.0049 - val_mae: 0.0527\n",
      "Epoch 63/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0044 - mae: 0.0515 - val_loss: 0.0050 - val_mae: 0.0521\n",
      "Epoch 64/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0046 - mae: 0.0516 - val_loss: 0.0051 - val_mae: 0.0520\n",
      "Epoch 65/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0051 - mae: 0.0519 - val_loss: 0.0050 - val_mae: 0.0521\n",
      "Epoch 66/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0048 - mae: 0.0520 - val_loss: 0.0051 - val_mae: 0.0520\n",
      "Epoch 67/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0045 - mae: 0.0509 - val_loss: 0.0050 - val_mae: 0.0521\n",
      "Epoch 68/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0046 - mae: 0.0518 - val_loss: 0.0051 - val_mae: 0.0520\n",
      "Epoch 69/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0045 - mae: 0.0509 - val_loss: 0.0049 - val_mae: 0.0531\n",
      "Epoch 70/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0045 - mae: 0.0515 - val_loss: 0.0050 - val_mae: 0.0521\n",
      "Epoch 71/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0047 - mae: 0.0518 - val_loss: 0.0050 - val_mae: 0.0522\n",
      "Epoch 72/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0046 - mae: 0.0516 - val_loss: 0.0054 - val_mae: 0.0522\n",
      "Epoch 73/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0044 - mae: 0.0503 - val_loss: 0.0052 - val_mae: 0.0520\n",
      "Epoch 74/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0044 - mae: 0.0510 - val_loss: 0.0050 - val_mae: 0.0523\n",
      "Epoch 75/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0052 - mae: 0.0524 - val_loss: 0.0051 - val_mae: 0.0520\n",
      "Epoch 76/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0045 - mae: 0.0519 - val_loss: 0.0049 - val_mae: 0.0534\n",
      "Epoch 77/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0048 - mae: 0.0520 - val_loss: 0.0051 - val_mae: 0.0520\n",
      "Epoch 78/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0047 - mae: 0.0516 - val_loss: 0.0050 - val_mae: 0.0521\n",
      "Epoch 79/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0043 - mae: 0.0507 - val_loss: 0.0050 - val_mae: 0.0521\n",
      "Epoch 80/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0047 - mae: 0.0521 - val_loss: 0.0052 - val_mae: 0.0520\n",
      "Epoch 81/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0048 - mae: 0.0521 - val_loss: 0.0051 - val_mae: 0.0520\n",
      "Epoch 82/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0043 - mae: 0.0510 - val_loss: 0.0050 - val_mae: 0.0523\n",
      "Epoch 83/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0046 - mae: 0.0517 - val_loss: 0.0052 - val_mae: 0.0520\n",
      "Epoch 84/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0047 - mae: 0.0515 - val_loss: 0.0049 - val_mae: 0.0524\n",
      "Epoch 85/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0047 - mae: 0.0516 - val_loss: 0.0049 - val_mae: 0.0527\n",
      "Epoch 86/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0042 - mae: 0.0508 - val_loss: 0.0051 - val_mae: 0.0520\n",
      "Epoch 87/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0041 - mae: 0.0503 - val_loss: 0.0050 - val_mae: 0.0522\n",
      "Epoch 88/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0045 - mae: 0.0510 - val_loss: 0.0049 - val_mae: 0.0525\n",
      "Epoch 89/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0048 - mae: 0.0522 - val_loss: 0.0051 - val_mae: 0.0520\n",
      "Epoch 90/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0044 - mae: 0.0511 - val_loss: 0.0050 - val_mae: 0.0521\n",
      "Epoch 91/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0049 - mae: 0.0525 - val_loss: 0.0050 - val_mae: 0.0521\n",
      "Epoch 92/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0047 - mae: 0.0518 - val_loss: 0.0051 - val_mae: 0.0520\n",
      "Epoch 93/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0050 - mae: 0.0518 - val_loss: 0.0051 - val_mae: 0.0520\n",
      "Epoch 94/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0045 - mae: 0.0512 - val_loss: 0.0051 - val_mae: 0.0520\n",
      "Epoch 95/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0048 - mae: 0.0521 - val_loss: 0.0051 - val_mae: 0.0520\n",
      "Epoch 96/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0046 - mae: 0.0516 - val_loss: 0.0051 - val_mae: 0.0520\n",
      "Epoch 97/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0051 - mae: 0.0526 - val_loss: 0.0052 - val_mae: 0.0520\n",
      "Epoch 98/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0045 - mae: 0.0510 - val_loss: 0.0049 - val_mae: 0.0527\n",
      "Epoch 99/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0048 - mae: 0.0510 - val_loss: 0.0050 - val_mae: 0.0521\n",
      "Epoch 100/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0049 - mae: 0.0522 - val_loss: 0.0051 - val_mae: 0.0520\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n",
      "✅ Done with onion_Bijapur_daily.csv | MAE=539.97, RMSE=724.35, R2=-0.0066, MAPE=59.42%, Accuracy=40.58%\n",
      "\n",
      "🚀 Processing: onion_Chamrajnagar_daily.csv\n",
      "Epoch 1/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - loss: 0.0060 - mae: 0.0419 - val_loss: 0.0179 - val_mae: 0.1138\n",
      "Epoch 2/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0057 - mae: 0.0403 - val_loss: 0.0194 - val_mae: 0.1202\n",
      "Epoch 3/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0052 - mae: 0.0394 - val_loss: 0.0190 - val_mae: 0.1185\n",
      "Epoch 4/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0060 - mae: 0.0411 - val_loss: 0.0159 - val_mae: 0.1049\n",
      "Epoch 5/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0061 - mae: 0.0423 - val_loss: 0.0181 - val_mae: 0.1144\n",
      "Epoch 6/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0060 - mae: 0.0406 - val_loss: 0.0175 - val_mae: 0.1123\n",
      "Epoch 7/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0058 - mae: 0.0413 - val_loss: 0.0178 - val_mae: 0.1134\n",
      "Epoch 8/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0057 - mae: 0.0411 - val_loss: 0.0193 - val_mae: 0.1195\n",
      "Epoch 9/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0054 - mae: 0.0396 - val_loss: 0.0167 - val_mae: 0.1087\n",
      "Epoch 10/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0064 - mae: 0.0423 - val_loss: 0.0188 - val_mae: 0.1177\n",
      "Epoch 11/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0061 - mae: 0.0420 - val_loss: 0.0191 - val_mae: 0.1188\n",
      "Epoch 12/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.0066 - mae: 0.0422 - val_loss: 0.0181 - val_mae: 0.1146\n",
      "Epoch 13/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0060 - mae: 0.0416 - val_loss: 0.0184 - val_mae: 0.1157\n",
      "Epoch 14/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0055 - mae: 0.0399 - val_loss: 0.0180 - val_mae: 0.1140\n",
      "Epoch 15/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0057 - mae: 0.0409 - val_loss: 0.0174 - val_mae: 0.1116\n",
      "Epoch 16/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0062 - mae: 0.0416 - val_loss: 0.0177 - val_mae: 0.1129\n",
      "Epoch 17/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0056 - mae: 0.0402 - val_loss: 0.0193 - val_mae: 0.1195\n",
      "Epoch 18/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0060 - mae: 0.0413 - val_loss: 0.0197 - val_mae: 0.1213\n",
      "Epoch 19/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0065 - mae: 0.0424 - val_loss: 0.0184 - val_mae: 0.1159\n",
      "Epoch 20/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0066 - mae: 0.0419 - val_loss: 0.0178 - val_mae: 0.1134\n",
      "Epoch 21/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0062 - mae: 0.0422 - val_loss: 0.0186 - val_mae: 0.1168\n",
      "Epoch 22/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0054 - mae: 0.0399 - val_loss: 0.0166 - val_mae: 0.1081\n",
      "Epoch 23/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0058 - mae: 0.0412 - val_loss: 0.0175 - val_mae: 0.1119\n",
      "Epoch 24/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0061 - mae: 0.0409 - val_loss: 0.0168 - val_mae: 0.1091\n",
      "Epoch 25/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0062 - mae: 0.0426 - val_loss: 0.0180 - val_mae: 0.1144\n",
      "Epoch 26/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0062 - mae: 0.0423 - val_loss: 0.0168 - val_mae: 0.1090\n",
      "Epoch 27/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0061 - mae: 0.0415 - val_loss: 0.0183 - val_mae: 0.1156\n",
      "Epoch 28/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0059 - mae: 0.0414 - val_loss: 0.0176 - val_mae: 0.1127\n",
      "Epoch 29/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0057 - mae: 0.0408 - val_loss: 0.0179 - val_mae: 0.1140\n",
      "Epoch 30/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0055 - mae: 0.0407 - val_loss: 0.0183 - val_mae: 0.1155\n",
      "Epoch 31/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0057 - mae: 0.0404 - val_loss: 0.0188 - val_mae: 0.1176\n",
      "Epoch 32/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0056 - mae: 0.0392 - val_loss: 0.0176 - val_mae: 0.1124\n",
      "Epoch 33/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0060 - mae: 0.0415 - val_loss: 0.0182 - val_mae: 0.1150\n",
      "Epoch 34/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.0059 - mae: 0.0411 - val_loss: 0.0173 - val_mae: 0.1110\n",
      "Epoch 35/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.0055 - mae: 0.0410 - val_loss: 0.0169 - val_mae: 0.1096\n",
      "Epoch 36/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.0056 - mae: 0.0409 - val_loss: 0.0173 - val_mae: 0.1112\n",
      "Epoch 37/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.0059 - mae: 0.0408 - val_loss: 0.0179 - val_mae: 0.1137\n",
      "Epoch 38/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 0.0058 - mae: 0.0410 - val_loss: 0.0172 - val_mae: 0.1106\n",
      "Epoch 39/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.0056 - mae: 0.0412 - val_loss: 0.0175 - val_mae: 0.1119\n",
      "Epoch 40/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.0062 - mae: 0.0415 - val_loss: 0.0171 - val_mae: 0.1102\n",
      "Epoch 41/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.0058 - mae: 0.0413 - val_loss: 0.0170 - val_mae: 0.1099\n",
      "Epoch 42/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.0063 - mae: 0.0416 - val_loss: 0.0180 - val_mae: 0.1144\n",
      "Epoch 43/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.0069 - mae: 0.0428 - val_loss: 0.0189 - val_mae: 0.1181\n",
      "Epoch 44/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.0060 - mae: 0.0406 - val_loss: 0.0174 - val_mae: 0.1116\n",
      "Epoch 45/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.0059 - mae: 0.0414 - val_loss: 0.0176 - val_mae: 0.1123\n",
      "Epoch 46/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.0062 - mae: 0.0418 - val_loss: 0.0182 - val_mae: 0.1151\n",
      "Epoch 47/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0059 - mae: 0.0414 - val_loss: 0.0183 - val_mae: 0.1155\n",
      "Epoch 48/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0056 - mae: 0.0401 - val_loss: 0.0180 - val_mae: 0.1142\n",
      "Epoch 49/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0063 - mae: 0.0414 - val_loss: 0.0201 - val_mae: 0.1228\n",
      "Epoch 50/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.0054 - mae: 0.0389 - val_loss: 0.0185 - val_mae: 0.1165\n",
      "Epoch 51/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.0058 - mae: 0.0414 - val_loss: 0.0185 - val_mae: 0.1163\n",
      "Epoch 52/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0057 - mae: 0.0410 - val_loss: 0.0185 - val_mae: 0.1165\n",
      "Epoch 53/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0062 - mae: 0.0420 - val_loss: 0.0169 - val_mae: 0.1094\n",
      "Epoch 54/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.0055 - mae: 0.0402 - val_loss: 0.0176 - val_mae: 0.1124\n",
      "Epoch 55/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0056 - mae: 0.0409 - val_loss: 0.0179 - val_mae: 0.1136\n",
      "Epoch 56/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0063 - mae: 0.0419 - val_loss: 0.0168 - val_mae: 0.1092\n",
      "Epoch 57/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0060 - mae: 0.0409 - val_loss: 0.0193 - val_mae: 0.1197\n",
      "Epoch 58/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.0062 - mae: 0.0416 - val_loss: 0.0184 - val_mae: 0.1158\n",
      "Epoch 59/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0058 - mae: 0.0406 - val_loss: 0.0185 - val_mae: 0.1164\n",
      "Epoch 60/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0063 - mae: 0.0419 - val_loss: 0.0191 - val_mae: 0.1188\n",
      "Epoch 61/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.0058 - mae: 0.0405 - val_loss: 0.0164 - val_mae: 0.1073\n",
      "Epoch 62/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0061 - mae: 0.0412 - val_loss: 0.0186 - val_mae: 0.1168\n",
      "Epoch 63/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0059 - mae: 0.0401 - val_loss: 0.0180 - val_mae: 0.1142\n",
      "Epoch 64/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0059 - mae: 0.0412 - val_loss: 0.0180 - val_mae: 0.1143\n",
      "Epoch 65/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0058 - mae: 0.0405 - val_loss: 0.0175 - val_mae: 0.1121\n",
      "Epoch 66/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0059 - mae: 0.0412 - val_loss: 0.0180 - val_mae: 0.1142\n",
      "Epoch 67/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0065 - mae: 0.0420 - val_loss: 0.0176 - val_mae: 0.1126\n",
      "Epoch 68/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0060 - mae: 0.0407 - val_loss: 0.0185 - val_mae: 0.1164\n",
      "Epoch 69/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0057 - mae: 0.0408 - val_loss: 0.0189 - val_mae: 0.1180\n",
      "Epoch 70/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0056 - mae: 0.0404 - val_loss: 0.0173 - val_mae: 0.1113\n",
      "Epoch 71/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0058 - mae: 0.0409 - val_loss: 0.0184 - val_mae: 0.1157\n",
      "Epoch 72/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0057 - mae: 0.0409 - val_loss: 0.0171 - val_mae: 0.1102\n",
      "Epoch 73/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0056 - mae: 0.0407 - val_loss: 0.0183 - val_mae: 0.1153\n",
      "Epoch 74/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0061 - mae: 0.0414 - val_loss: 0.0182 - val_mae: 0.1149\n",
      "Epoch 75/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0052 - mae: 0.0396 - val_loss: 0.0176 - val_mae: 0.1124\n",
      "Epoch 76/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0057 - mae: 0.0402 - val_loss: 0.0182 - val_mae: 0.1149\n",
      "Epoch 77/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0061 - mae: 0.0420 - val_loss: 0.0192 - val_mae: 0.1191\n",
      "Epoch 78/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0064 - mae: 0.0422 - val_loss: 0.0190 - val_mae: 0.1185\n",
      "Epoch 79/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0059 - mae: 0.0410 - val_loss: 0.0179 - val_mae: 0.1139\n",
      "Epoch 80/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0056 - mae: 0.0407 - val_loss: 0.0185 - val_mae: 0.1162\n",
      "Epoch 81/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0061 - mae: 0.0410 - val_loss: 0.0178 - val_mae: 0.1134\n",
      "Epoch 82/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0056 - mae: 0.0400 - val_loss: 0.0176 - val_mae: 0.1124\n",
      "Epoch 83/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0053 - mae: 0.0396 - val_loss: 0.0191 - val_mae: 0.1190\n",
      "Epoch 84/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0057 - mae: 0.0402 - val_loss: 0.0182 - val_mae: 0.1150\n",
      "Epoch 85/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0061 - mae: 0.0403 - val_loss: 0.0185 - val_mae: 0.1163\n",
      "Epoch 86/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0060 - mae: 0.0410 - val_loss: 0.0182 - val_mae: 0.1150\n",
      "Epoch 87/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0052 - mae: 0.0399 - val_loss: 0.0175 - val_mae: 0.1120\n",
      "Epoch 88/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.0066 - mae: 0.0427 - val_loss: 0.0186 - val_mae: 0.1167\n",
      "Epoch 89/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0060 - mae: 0.0407 - val_loss: 0.0178 - val_mae: 0.1135\n",
      "Epoch 90/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0055 - mae: 0.0401 - val_loss: 0.0179 - val_mae: 0.1140\n",
      "Epoch 91/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0058 - mae: 0.0415 - val_loss: 0.0187 - val_mae: 0.1170\n",
      "Epoch 92/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0053 - mae: 0.0390 - val_loss: 0.0167 - val_mae: 0.1087\n",
      "Epoch 93/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0063 - mae: 0.0415 - val_loss: 0.0189 - val_mae: 0.1180\n",
      "Epoch 94/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0058 - mae: 0.0402 - val_loss: 0.0186 - val_mae: 0.1167\n",
      "Epoch 95/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0054 - mae: 0.0394 - val_loss: 0.0165 - val_mae: 0.1075\n",
      "Epoch 96/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0064 - mae: 0.0429 - val_loss: 0.0175 - val_mae: 0.1118\n",
      "Epoch 97/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0066 - mae: 0.0425 - val_loss: 0.0171 - val_mae: 0.1101\n",
      "Epoch 98/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0056 - mae: 0.0404 - val_loss: 0.0187 - val_mae: 0.1170\n",
      "Epoch 99/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.0056 - mae: 0.0400 - val_loss: 0.0168 - val_mae: 0.1091\n",
      "Epoch 100/100\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.0059 - mae: 0.0412 - val_loss: 0.0190 - val_mae: 0.1183\n",
      "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step\n",
      "✅ Done with onion_Chamrajnagar_daily.csv | MAE=757.23, RMSE=1269.04, R2=-0.0972, MAPE=80.34%, Accuracy=19.66%\n",
      "\n",
      "🚀 Processing: onion_Chikmagalur_daily.csv\n",
      "Epoch 1/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - loss: 0.0336 - mae: 0.1305 - val_loss: 0.0181 - val_mae: 0.0978\n",
      "Epoch 2/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 0.0217 - mae: 0.1111 - val_loss: 0.0194 - val_mae: 0.1016\n",
      "Epoch 3/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 0.0209 - mae: 0.1092 - val_loss: 0.0200 - val_mae: 0.1034\n",
      "Epoch 4/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - loss: 0.0211 - mae: 0.1086 - val_loss: 0.0187 - val_mae: 0.0995\n",
      "Epoch 5/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - loss: 0.0213 - mae: 0.1095 - val_loss: 0.0192 - val_mae: 0.1010\n",
      "Epoch 6/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 0.0209 - mae: 0.1083 - val_loss: 0.0192 - val_mae: 0.1010\n",
      "Epoch 7/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - loss: 0.0214 - mae: 0.1091 - val_loss: 0.0190 - val_mae: 0.1003\n",
      "Epoch 8/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 0.0203 - mae: 0.1068 - val_loss: 0.0177 - val_mae: 0.0965\n",
      "Epoch 9/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 0.0210 - mae: 0.1090 - val_loss: 0.0186 - val_mae: 0.0991\n",
      "Epoch 10/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - loss: 0.0216 - mae: 0.1102 - val_loss: 0.0185 - val_mae: 0.0988\n",
      "Epoch 11/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 0.0203 - mae: 0.1075 - val_loss: 0.0180 - val_mae: 0.0973\n",
      "Epoch 12/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 0.0207 - mae: 0.1083 - val_loss: 0.0191 - val_mae: 0.1009\n",
      "Epoch 13/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 0.0207 - mae: 0.1081 - val_loss: 0.0172 - val_mae: 0.0949\n",
      "Epoch 14/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - loss: 0.0207 - mae: 0.1083 - val_loss: 0.0181 - val_mae: 0.0979\n",
      "Epoch 15/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 0.0206 - mae: 0.1086 - val_loss: 0.0188 - val_mae: 0.0998\n",
      "Epoch 16/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - loss: 0.0211 - mae: 0.1090 - val_loss: 0.0184 - val_mae: 0.0988\n",
      "Epoch 17/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 0.0212 - mae: 0.1091 - val_loss: 0.0184 - val_mae: 0.0987\n",
      "Epoch 18/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 0.0212 - mae: 0.1102 - val_loss: 0.0203 - val_mae: 0.1043\n",
      "Epoch 19/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - loss: 0.0215 - mae: 0.1093 - val_loss: 0.0192 - val_mae: 0.1011\n",
      "Epoch 20/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0211 - mae: 0.1089 - val_loss: 0.0190 - val_mae: 0.1004\n",
      "Epoch 21/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 0.0218 - mae: 0.1111 - val_loss: 0.0195 - val_mae: 0.1018\n",
      "Epoch 22/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0211 - mae: 0.1090 - val_loss: 0.0198 - val_mae: 0.1027\n",
      "Epoch 23/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - loss: 0.0209 - mae: 0.1085 - val_loss: 0.0195 - val_mae: 0.1019\n",
      "Epoch 24/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 0.0212 - mae: 0.1092 - val_loss: 0.0192 - val_mae: 0.1012\n",
      "Epoch 25/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0209 - mae: 0.1085 - val_loss: 0.0191 - val_mae: 0.1009\n",
      "Epoch 26/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 0.0211 - mae: 0.1085 - val_loss: 0.0176 - val_mae: 0.0962\n",
      "Epoch 27/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - loss: 0.0210 - mae: 0.1092 - val_loss: 0.0184 - val_mae: 0.0988\n",
      "Epoch 28/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 0.0209 - mae: 0.1090 - val_loss: 0.0188 - val_mae: 0.0998\n",
      "Epoch 29/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 0.0216 - mae: 0.1104 - val_loss: 0.0184 - val_mae: 0.0986\n",
      "Epoch 30/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - loss: 0.0210 - mae: 0.1090 - val_loss: 0.0194 - val_mae: 0.1016\n",
      "Epoch 31/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - loss: 0.0212 - mae: 0.1091 - val_loss: 0.0182 - val_mae: 0.0980\n",
      "Epoch 32/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 0.0210 - mae: 0.1087 - val_loss: 0.0198 - val_mae: 0.1028\n",
      "Epoch 33/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - loss: 0.0211 - mae: 0.1088 - val_loss: 0.0188 - val_mae: 0.1000\n",
      "Epoch 34/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - loss: 0.0207 - mae: 0.1083 - val_loss: 0.0195 - val_mae: 0.1020\n",
      "Epoch 35/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 0.0211 - mae: 0.1093 - val_loss: 0.0193 - val_mae: 0.1013\n",
      "Epoch 36/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 0.0207 - mae: 0.1076 - val_loss: 0.0184 - val_mae: 0.0986\n",
      "Epoch 37/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 0.0207 - mae: 0.1085 - val_loss: 0.0196 - val_mae: 0.1021\n",
      "Epoch 38/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 0.0210 - mae: 0.1089 - val_loss: 0.0189 - val_mae: 0.1002\n",
      "Epoch 39/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - loss: 0.0215 - mae: 0.1100 - val_loss: 0.0189 - val_mae: 0.1001\n",
      "Epoch 40/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0210 - mae: 0.1085 - val_loss: 0.0187 - val_mae: 0.0996\n",
      "Epoch 41/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 0.0215 - mae: 0.1102 - val_loss: 0.0178 - val_mae: 0.0968\n",
      "Epoch 42/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - loss: 0.0214 - mae: 0.1111 - val_loss: 0.0197 - val_mae: 0.1024\n",
      "Epoch 43/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 0.0213 - mae: 0.1097 - val_loss: 0.0191 - val_mae: 0.1006\n",
      "Epoch 44/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 0.0208 - mae: 0.1089 - val_loss: 0.0175 - val_mae: 0.0958\n",
      "Epoch 45/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 0.0211 - mae: 0.1092 - val_loss: 0.0182 - val_mae: 0.0979\n",
      "Epoch 46/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - loss: 0.0204 - mae: 0.1077 - val_loss: 0.0177 - val_mae: 0.0965\n",
      "Epoch 47/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 0.0210 - mae: 0.1099 - val_loss: 0.0200 - val_mae: 0.1033\n",
      "Epoch 48/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 0.0215 - mae: 0.1097 - val_loss: 0.0188 - val_mae: 0.0999\n",
      "Epoch 49/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 0.0216 - mae: 0.1105 - val_loss: 0.0189 - val_mae: 0.1000\n",
      "Epoch 50/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 0.0208 - mae: 0.1080 - val_loss: 0.0182 - val_mae: 0.0982\n",
      "Epoch 51/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - loss: 0.0209 - mae: 0.1089 - val_loss: 0.0196 - val_mae: 0.1021\n",
      "Epoch 52/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - loss: 0.0215 - mae: 0.1098 - val_loss: 0.0196 - val_mae: 0.1022\n",
      "Epoch 53/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 0.0206 - mae: 0.1076 - val_loss: 0.0192 - val_mae: 0.1011\n",
      "Epoch 54/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 0.0207 - mae: 0.1083 - val_loss: 0.0194 - val_mae: 0.1016\n",
      "Epoch 55/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 0.0212 - mae: 0.1095 - val_loss: 0.0194 - val_mae: 0.1017\n",
      "Epoch 56/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - loss: 0.0208 - mae: 0.1079 - val_loss: 0.0189 - val_mae: 0.1002\n",
      "Epoch 57/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - loss: 0.0206 - mae: 0.1080 - val_loss: 0.0191 - val_mae: 0.1007\n",
      "Epoch 58/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 0.0210 - mae: 0.1092 - val_loss: 0.0197 - val_mae: 0.1025\n",
      "Epoch 59/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - loss: 0.0212 - mae: 0.1092 - val_loss: 0.0179 - val_mae: 0.0971\n",
      "Epoch 60/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 0.0209 - mae: 0.1093 - val_loss: 0.0189 - val_mae: 0.1001\n",
      "Epoch 61/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 0.0212 - mae: 0.1094 - val_loss: 0.0186 - val_mae: 0.0994\n",
      "Epoch 62/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 0.0206 - mae: 0.1078 - val_loss: 0.0185 - val_mae: 0.0989\n",
      "Epoch 63/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 0.0218 - mae: 0.1107 - val_loss: 0.0200 - val_mae: 0.1032\n",
      "Epoch 64/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 0.0212 - mae: 0.1089 - val_loss: 0.0194 - val_mae: 0.1017\n",
      "Epoch 65/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 0.0216 - mae: 0.1106 - val_loss: 0.0188 - val_mae: 0.0997\n",
      "Epoch 66/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 0.0212 - mae: 0.1092 - val_loss: 0.0178 - val_mae: 0.0969\n",
      "Epoch 67/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 0.0208 - mae: 0.1087 - val_loss: 0.0187 - val_mae: 0.0996\n",
      "Epoch 68/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - loss: 0.0211 - mae: 0.1088 - val_loss: 0.0188 - val_mae: 0.0998\n",
      "Epoch 69/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - loss: 0.0210 - mae: 0.1083 - val_loss: 0.0189 - val_mae: 0.1000\n",
      "Epoch 70/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 0.0212 - mae: 0.1094 - val_loss: 0.0185 - val_mae: 0.0990\n",
      "Epoch 71/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 0.0209 - mae: 0.1089 - val_loss: 0.0194 - val_mae: 0.1017\n",
      "Epoch 72/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 0.0214 - mae: 0.1099 - val_loss: 0.0192 - val_mae: 0.1010\n",
      "Epoch 73/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 0.0209 - mae: 0.1089 - val_loss: 0.0181 - val_mae: 0.0978\n",
      "Epoch 74/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 0.0216 - mae: 0.1110 - val_loss: 0.0189 - val_mae: 0.1003\n",
      "Epoch 75/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 0.0212 - mae: 0.1097 - val_loss: 0.0186 - val_mae: 0.0994\n",
      "Epoch 76/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - loss: 0.0213 - mae: 0.1099 - val_loss: 0.0178 - val_mae: 0.0969\n",
      "Epoch 77/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - loss: 0.0216 - mae: 0.1105 - val_loss: 0.0193 - val_mae: 0.1013\n",
      "Epoch 78/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 0.0210 - mae: 0.1093 - val_loss: 0.0185 - val_mae: 0.0991\n",
      "Epoch 79/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - loss: 0.0212 - mae: 0.1102 - val_loss: 0.0195 - val_mae: 0.1020\n",
      "Epoch 80/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - loss: 0.0209 - mae: 0.1085 - val_loss: 0.0190 - val_mae: 0.1003\n",
      "Epoch 81/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 0.0208 - mae: 0.1075 - val_loss: 0.0193 - val_mae: 0.1013\n",
      "Epoch 82/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 0.0208 - mae: 0.1081 - val_loss: 0.0190 - val_mae: 0.1006\n",
      "Epoch 83/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 0.0208 - mae: 0.1080 - val_loss: 0.0177 - val_mae: 0.0965\n",
      "Epoch 84/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - loss: 0.0213 - mae: 0.1101 - val_loss: 0.0189 - val_mae: 0.1003\n",
      "Epoch 85/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 0.0210 - mae: 0.1083 - val_loss: 0.0187 - val_mae: 0.0994\n",
      "Epoch 86/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0204 - mae: 0.1078 - val_loss: 0.0187 - val_mae: 0.0997\n",
      "Epoch 87/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 0.0213 - mae: 0.1094 - val_loss: 0.0196 - val_mae: 0.1023\n",
      "Epoch 88/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 0.0210 - mae: 0.1089 - val_loss: 0.0178 - val_mae: 0.0970\n",
      "Epoch 89/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 0.0209 - mae: 0.1085 - val_loss: 0.0177 - val_mae: 0.0965\n",
      "Epoch 90/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - loss: 0.0210 - mae: 0.1094 - val_loss: 0.0199 - val_mae: 0.1032\n",
      "Epoch 91/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 0.0210 - mae: 0.1087 - val_loss: 0.0185 - val_mae: 0.0989\n",
      "Epoch 92/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 0.0216 - mae: 0.1108 - val_loss: 0.0195 - val_mae: 0.1018\n",
      "Epoch 93/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 0.0209 - mae: 0.1081 - val_loss: 0.0189 - val_mae: 0.1002\n",
      "Epoch 94/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 0.0212 - mae: 0.1097 - val_loss: 0.0190 - val_mae: 0.1006\n",
      "Epoch 95/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - loss: 0.0215 - mae: 0.1096 - val_loss: 0.0186 - val_mae: 0.0992\n",
      "Epoch 96/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - loss: 0.0206 - mae: 0.1080 - val_loss: 0.0196 - val_mae: 0.1023\n",
      "Epoch 97/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - loss: 0.0213 - mae: 0.1100 - val_loss: 0.0200 - val_mae: 0.1033\n",
      "Epoch 98/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 0.0209 - mae: 0.1084 - val_loss: 0.0186 - val_mae: 0.0992\n",
      "Epoch 99/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 0.0213 - mae: 0.1098 - val_loss: 0.0193 - val_mae: 0.1014\n",
      "Epoch 100/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 0.0215 - mae: 0.1105 - val_loss: 0.0197 - val_mae: 0.1024\n",
      "\u001b[1m677/677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step\n",
      "✅ Done with onion_Chikmagalur_daily.csv | MAE=742.03, RMSE=1005.35, R2=-0.0197, MAPE=54.24%, Accuracy=45.76%\n",
      "\n",
      "🚀 Processing: onion_Chitradurga_daily.csv\n",
      "Epoch 1/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.1101 - mae: 0.2575 - val_loss: 0.0100 - val_mae: 0.0842\n",
      "Epoch 2/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0606 - mae: 0.2081 - val_loss: 0.0093 - val_mae: 0.0818\n",
      "Epoch 3/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0587 - mae: 0.2044 - val_loss: 0.0085 - val_mae: 0.0795\n",
      "Epoch 4/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0586 - mae: 0.2051 - val_loss: 0.0096 - val_mae: 0.0828\n",
      "Epoch 5/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0584 - mae: 0.2047 - val_loss: 0.0108 - val_mae: 0.0866\n",
      "Epoch 6/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0617 - mae: 0.2086 - val_loss: 0.0095 - val_mae: 0.0826\n",
      "Epoch 7/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0604 - mae: 0.2078 - val_loss: 0.0103 - val_mae: 0.0852\n",
      "Epoch 8/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0595 - mae: 0.2056 - val_loss: 0.0091 - val_mae: 0.0812\n",
      "Epoch 9/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0596 - mae: 0.2063 - val_loss: 0.0088 - val_mae: 0.0803\n",
      "Epoch 10/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0598 - mae: 0.2067 - val_loss: 0.0096 - val_mae: 0.0830\n",
      "Epoch 11/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0594 - mae: 0.2060 - val_loss: 0.0101 - val_mae: 0.0847\n",
      "Epoch 12/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0601 - mae: 0.2070 - val_loss: 0.0097 - val_mae: 0.0831\n",
      "Epoch 13/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0585 - mae: 0.2035 - val_loss: 0.0087 - val_mae: 0.0800\n",
      "Epoch 14/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0627 - mae: 0.2131 - val_loss: 0.0091 - val_mae: 0.0812\n",
      "Epoch 15/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0573 - mae: 0.2023 - val_loss: 0.0095 - val_mae: 0.0825\n",
      "Epoch 16/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0582 - mae: 0.2029 - val_loss: 0.0095 - val_mae: 0.0827\n",
      "Epoch 17/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0583 - mae: 0.2033 - val_loss: 0.0104 - val_mae: 0.0854\n",
      "Epoch 18/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0597 - mae: 0.2067 - val_loss: 0.0093 - val_mae: 0.0819\n",
      "Epoch 19/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0597 - mae: 0.2059 - val_loss: 0.0093 - val_mae: 0.0821\n",
      "Epoch 20/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0604 - mae: 0.2076 - val_loss: 0.0104 - val_mae: 0.0854\n",
      "Epoch 21/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0597 - mae: 0.2053 - val_loss: 0.0099 - val_mae: 0.0839\n",
      "Epoch 22/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0599 - mae: 0.2060 - val_loss: 0.0099 - val_mae: 0.0840\n",
      "Epoch 23/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0592 - mae: 0.2051 - val_loss: 0.0098 - val_mae: 0.0836\n",
      "Epoch 24/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0579 - mae: 0.2032 - val_loss: 0.0095 - val_mae: 0.0826\n",
      "Epoch 25/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0604 - mae: 0.2086 - val_loss: 0.0103 - val_mae: 0.0853\n",
      "Epoch 26/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0586 - mae: 0.2033 - val_loss: 0.0095 - val_mae: 0.0826\n",
      "Epoch 27/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0592 - mae: 0.2058 - val_loss: 0.0108 - val_mae: 0.0866\n",
      "Epoch 28/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0594 - mae: 0.2050 - val_loss: 0.0087 - val_mae: 0.0802\n",
      "Epoch 29/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0603 - mae: 0.2092 - val_loss: 0.0115 - val_mae: 0.0890\n",
      "Epoch 30/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0607 - mae: 0.2066 - val_loss: 0.0113 - val_mae: 0.0883\n",
      "Epoch 31/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0583 - mae: 0.2027 - val_loss: 0.0087 - val_mae: 0.0802\n",
      "Epoch 32/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0597 - mae: 0.2064 - val_loss: 0.0098 - val_mae: 0.0834\n",
      "Epoch 33/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0587 - mae: 0.2035 - val_loss: 0.0106 - val_mae: 0.0862\n",
      "Epoch 34/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0588 - mae: 0.2042 - val_loss: 0.0101 - val_mae: 0.0846\n",
      "Epoch 35/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0583 - mae: 0.2029 - val_loss: 0.0097 - val_mae: 0.0832\n",
      "Epoch 36/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0596 - mae: 0.2059 - val_loss: 0.0092 - val_mae: 0.0817\n",
      "Epoch 37/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0588 - mae: 0.2049 - val_loss: 0.0113 - val_mae: 0.0883\n",
      "Epoch 38/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0582 - mae: 0.2029 - val_loss: 0.0090 - val_mae: 0.0811\n",
      "Epoch 39/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0609 - mae: 0.2094 - val_loss: 0.0108 - val_mae: 0.0868\n",
      "Epoch 40/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0584 - mae: 0.2035 - val_loss: 0.0095 - val_mae: 0.0826\n",
      "Epoch 41/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0599 - mae: 0.2069 - val_loss: 0.0094 - val_mae: 0.0823\n",
      "Epoch 42/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0589 - mae: 0.2047 - val_loss: 0.0099 - val_mae: 0.0839\n",
      "Epoch 43/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0595 - mae: 0.2068 - val_loss: 0.0095 - val_mae: 0.0826\n",
      "Epoch 44/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0592 - mae: 0.2056 - val_loss: 0.0105 - val_mae: 0.0860\n",
      "Epoch 45/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0602 - mae: 0.2072 - val_loss: 0.0091 - val_mae: 0.0814\n",
      "Epoch 46/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0604 - mae: 0.2074 - val_loss: 0.0108 - val_mae: 0.0868\n",
      "Epoch 47/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0585 - mae: 0.2042 - val_loss: 0.0099 - val_mae: 0.0840\n",
      "Epoch 48/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0577 - mae: 0.2020 - val_loss: 0.0089 - val_mae: 0.0807\n",
      "Epoch 49/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0593 - mae: 0.2055 - val_loss: 0.0101 - val_mae: 0.0844\n",
      "Epoch 50/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0599 - mae: 0.2064 - val_loss: 0.0092 - val_mae: 0.0817\n",
      "Epoch 51/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0585 - mae: 0.2042 - val_loss: 0.0101 - val_mae: 0.0846\n",
      "Epoch 52/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0591 - mae: 0.2053 - val_loss: 0.0109 - val_mae: 0.0871\n",
      "Epoch 53/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0598 - mae: 0.2060 - val_loss: 0.0104 - val_mae: 0.0853\n",
      "Epoch 54/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0604 - mae: 0.2067 - val_loss: 0.0089 - val_mae: 0.0806\n",
      "Epoch 55/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0579 - mae: 0.2036 - val_loss: 0.0098 - val_mae: 0.0835\n",
      "Epoch 56/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0598 - mae: 0.2059 - val_loss: 0.0094 - val_mae: 0.0824\n",
      "Epoch 57/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0582 - mae: 0.2040 - val_loss: 0.0102 - val_mae: 0.0847\n",
      "Epoch 58/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0606 - mae: 0.2078 - val_loss: 0.0093 - val_mae: 0.0818\n",
      "Epoch 59/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0596 - mae: 0.2074 - val_loss: 0.0105 - val_mae: 0.0859\n",
      "Epoch 60/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0581 - mae: 0.2023 - val_loss: 0.0092 - val_mae: 0.0816\n",
      "Epoch 61/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0586 - mae: 0.2042 - val_loss: 0.0109 - val_mae: 0.0871\n",
      "Epoch 62/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0595 - mae: 0.2061 - val_loss: 0.0095 - val_mae: 0.0828\n",
      "Epoch 63/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0583 - mae: 0.2033 - val_loss: 0.0089 - val_mae: 0.0806\n",
      "Epoch 64/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0575 - mae: 0.2023 - val_loss: 0.0098 - val_mae: 0.0835\n",
      "Epoch 65/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0593 - mae: 0.2055 - val_loss: 0.0098 - val_mae: 0.0836\n",
      "Epoch 66/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0588 - mae: 0.2043 - val_loss: 0.0110 - val_mae: 0.0875\n",
      "Epoch 67/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0603 - mae: 0.2074 - val_loss: 0.0100 - val_mae: 0.0842\n",
      "Epoch 68/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0585 - mae: 0.2042 - val_loss: 0.0103 - val_mae: 0.0850\n",
      "Epoch 69/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0596 - mae: 0.2054 - val_loss: 0.0095 - val_mae: 0.0827\n",
      "Epoch 70/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0596 - mae: 0.2065 - val_loss: 0.0094 - val_mae: 0.0824\n",
      "Epoch 71/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0592 - mae: 0.2049 - val_loss: 0.0098 - val_mae: 0.0835\n",
      "Epoch 72/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0590 - mae: 0.2048 - val_loss: 0.0100 - val_mae: 0.0842\n",
      "Epoch 73/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0593 - mae: 0.2047 - val_loss: 0.0095 - val_mae: 0.0825\n",
      "Epoch 74/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0579 - mae: 0.2025 - val_loss: 0.0102 - val_mae: 0.0849\n",
      "Epoch 75/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0591 - mae: 0.2050 - val_loss: 0.0096 - val_mae: 0.0828\n",
      "Epoch 76/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0585 - mae: 0.2042 - val_loss: 0.0089 - val_mae: 0.0807\n",
      "Epoch 77/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0590 - mae: 0.2065 - val_loss: 0.0110 - val_mae: 0.0874\n",
      "Epoch 78/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0594 - mae: 0.2058 - val_loss: 0.0103 - val_mae: 0.0851\n",
      "Epoch 79/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0614 - mae: 0.2095 - val_loss: 0.0107 - val_mae: 0.0865\n",
      "Epoch 80/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0598 - mae: 0.2057 - val_loss: 0.0101 - val_mae: 0.0845\n",
      "Epoch 81/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0601 - mae: 0.2056 - val_loss: 0.0095 - val_mae: 0.0825\n",
      "Epoch 82/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0598 - mae: 0.2055 - val_loss: 0.0101 - val_mae: 0.0847\n",
      "Epoch 83/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0591 - mae: 0.2060 - val_loss: 0.0098 - val_mae: 0.0837\n",
      "Epoch 84/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0598 - mae: 0.2067 - val_loss: 0.0097 - val_mae: 0.0832\n",
      "Epoch 85/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0590 - mae: 0.2051 - val_loss: 0.0092 - val_mae: 0.0818\n",
      "Epoch 86/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0589 - mae: 0.2058 - val_loss: 0.0105 - val_mae: 0.0857\n",
      "Epoch 87/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0593 - mae: 0.2050 - val_loss: 0.0101 - val_mae: 0.0844\n",
      "Epoch 88/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0592 - mae: 0.2048 - val_loss: 0.0107 - val_mae: 0.0864\n",
      "Epoch 89/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0578 - mae: 0.2027 - val_loss: 0.0100 - val_mae: 0.0841\n",
      "Epoch 90/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0590 - mae: 0.2046 - val_loss: 0.0109 - val_mae: 0.0872\n",
      "Epoch 91/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0589 - mae: 0.2041 - val_loss: 0.0095 - val_mae: 0.0825\n",
      "Epoch 92/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0563 - mae: 0.1994 - val_loss: 0.0094 - val_mae: 0.0822\n",
      "Epoch 93/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0592 - mae: 0.2062 - val_loss: 0.0103 - val_mae: 0.0852\n",
      "Epoch 94/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0589 - mae: 0.2053 - val_loss: 0.0098 - val_mae: 0.0835\n",
      "Epoch 95/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0582 - mae: 0.2037 - val_loss: 0.0111 - val_mae: 0.0878\n",
      "Epoch 96/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0591 - mae: 0.2043 - val_loss: 0.0100 - val_mae: 0.0841\n",
      "Epoch 97/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0595 - mae: 0.2054 - val_loss: 0.0098 - val_mae: 0.0837\n",
      "Epoch 98/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0602 - mae: 0.2073 - val_loss: 0.0108 - val_mae: 0.0868\n",
      "Epoch 99/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0610 - mae: 0.2081 - val_loss: 0.0097 - val_mae: 0.0833\n",
      "Epoch 100/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0586 - mae: 0.2039 - val_loss: 0.0092 - val_mae: 0.0816\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step\n",
      "✅ Done with onion_Chitradurga_daily.csv | MAE=611.27, RMSE=746.66, R2=-0.0, MAPE=47.18%, Accuracy=52.82%\n",
      "\n",
      "🚀 Processing: onion_Davangere_daily.csv\n",
      "Epoch 1/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 0.0019 - mae: 0.0307 - val_loss: 0.0079 - val_mae: 0.0565\n",
      "Epoch 2/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0016 - mae: 0.0294 - val_loss: 0.0089 - val_mae: 0.0626\n",
      "Epoch 3/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0017 - mae: 0.0293 - val_loss: 0.0084 - val_mae: 0.0598\n",
      "Epoch 4/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0015 - mae: 0.0290 - val_loss: 0.0085 - val_mae: 0.0604\n",
      "Epoch 5/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0016 - mae: 0.0292 - val_loss: 0.0082 - val_mae: 0.0583\n",
      "Epoch 6/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0290 - val_loss: 0.0082 - val_mae: 0.0586\n",
      "Epoch 7/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0286 - val_loss: 0.0080 - val_mae: 0.0573\n",
      "Epoch 8/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0017 - mae: 0.0295 - val_loss: 0.0082 - val_mae: 0.0587\n",
      "Epoch 9/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0016 - mae: 0.0290 - val_loss: 0.0082 - val_mae: 0.0585\n",
      "Epoch 10/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0017 - mae: 0.0295 - val_loss: 0.0083 - val_mae: 0.0592\n",
      "Epoch 11/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0016 - mae: 0.0295 - val_loss: 0.0083 - val_mae: 0.0593\n",
      "Epoch 12/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0016 - mae: 0.0292 - val_loss: 0.0079 - val_mae: 0.0570\n",
      "Epoch 13/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0015 - mae: 0.0291 - val_loss: 0.0082 - val_mae: 0.0584\n",
      "Epoch 14/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0016 - mae: 0.0286 - val_loss: 0.0083 - val_mae: 0.0589\n",
      "Epoch 15/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0017 - mae: 0.0295 - val_loss: 0.0084 - val_mae: 0.0598\n",
      "Epoch 16/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0016 - mae: 0.0289 - val_loss: 0.0080 - val_mae: 0.0576\n",
      "Epoch 17/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0016 - mae: 0.0292 - val_loss: 0.0085 - val_mae: 0.0602\n",
      "Epoch 18/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0017 - mae: 0.0289 - val_loss: 0.0086 - val_mae: 0.0611\n",
      "Epoch 19/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0287 - val_loss: 0.0083 - val_mae: 0.0591\n",
      "Epoch 20/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0282 - val_loss: 0.0084 - val_mae: 0.0595\n",
      "Epoch 21/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0017 - mae: 0.0297 - val_loss: 0.0081 - val_mae: 0.0580\n",
      "Epoch 22/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0017 - mae: 0.0292 - val_loss: 0.0079 - val_mae: 0.0564\n",
      "Epoch 23/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0286 - val_loss: 0.0080 - val_mae: 0.0571\n",
      "Epoch 24/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0016 - mae: 0.0288 - val_loss: 0.0085 - val_mae: 0.0602\n",
      "Epoch 25/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0015 - mae: 0.0287 - val_loss: 0.0082 - val_mae: 0.0587\n",
      "Epoch 26/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0286 - val_loss: 0.0079 - val_mae: 0.0568\n",
      "Epoch 27/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0016 - mae: 0.0289 - val_loss: 0.0083 - val_mae: 0.0591\n",
      "Epoch 28/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0016 - mae: 0.0295 - val_loss: 0.0084 - val_mae: 0.0600\n",
      "Epoch 29/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0016 - mae: 0.0292 - val_loss: 0.0083 - val_mae: 0.0590\n",
      "Epoch 30/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0016 - mae: 0.0293 - val_loss: 0.0085 - val_mae: 0.0607\n",
      "Epoch 31/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0016 - mae: 0.0294 - val_loss: 0.0085 - val_mae: 0.0603\n",
      "Epoch 32/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0017 - mae: 0.0292 - val_loss: 0.0083 - val_mae: 0.0591\n",
      "Epoch 33/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0016 - mae: 0.0290 - val_loss: 0.0082 - val_mae: 0.0586\n",
      "Epoch 34/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0284 - val_loss: 0.0083 - val_mae: 0.0593\n",
      "Epoch 35/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0285 - val_loss: 0.0083 - val_mae: 0.0589\n",
      "Epoch 36/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0017 - mae: 0.0291 - val_loss: 0.0081 - val_mae: 0.0578\n",
      "Epoch 37/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0018 - mae: 0.0295 - val_loss: 0.0084 - val_mae: 0.0599\n",
      "Epoch 38/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0016 - mae: 0.0284 - val_loss: 0.0086 - val_mae: 0.0613\n",
      "Epoch 39/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0017 - mae: 0.0287 - val_loss: 0.0080 - val_mae: 0.0572\n",
      "Epoch 40/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0016 - mae: 0.0288 - val_loss: 0.0083 - val_mae: 0.0592\n",
      "Epoch 41/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0016 - mae: 0.0291 - val_loss: 0.0081 - val_mae: 0.0582\n",
      "Epoch 42/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0016 - mae: 0.0295 - val_loss: 0.0083 - val_mae: 0.0592\n",
      "Epoch 43/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0015 - mae: 0.0284 - val_loss: 0.0080 - val_mae: 0.0575\n",
      "Epoch 44/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0015 - mae: 0.0289 - val_loss: 0.0084 - val_mae: 0.0596\n",
      "Epoch 45/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0281 - val_loss: 0.0083 - val_mae: 0.0590\n",
      "Epoch 46/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0016 - mae: 0.0289 - val_loss: 0.0085 - val_mae: 0.0601\n",
      "Epoch 47/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0016 - mae: 0.0292 - val_loss: 0.0080 - val_mae: 0.0573\n",
      "Epoch 48/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0016 - mae: 0.0290 - val_loss: 0.0085 - val_mae: 0.0602\n",
      "Epoch 49/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0288 - val_loss: 0.0084 - val_mae: 0.0600\n",
      "Epoch 50/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0017 - mae: 0.0292 - val_loss: 0.0084 - val_mae: 0.0597\n",
      "Epoch 51/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0016 - mae: 0.0290 - val_loss: 0.0082 - val_mae: 0.0584\n",
      "Epoch 52/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0015 - mae: 0.0286 - val_loss: 0.0079 - val_mae: 0.0565\n",
      "Epoch 53/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0016 - mae: 0.0288 - val_loss: 0.0082 - val_mae: 0.0585\n",
      "Epoch 54/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0016 - mae: 0.0292 - val_loss: 0.0081 - val_mae: 0.0580\n",
      "Epoch 55/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0016 - mae: 0.0292 - val_loss: 0.0083 - val_mae: 0.0589\n",
      "Epoch 56/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0016 - mae: 0.0292 - val_loss: 0.0083 - val_mae: 0.0594\n",
      "Epoch 57/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0288 - val_loss: 0.0081 - val_mae: 0.0577\n",
      "Epoch 58/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0016 - mae: 0.0290 - val_loss: 0.0080 - val_mae: 0.0574\n",
      "Epoch 59/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0016 - mae: 0.0297 - val_loss: 0.0083 - val_mae: 0.0593\n",
      "Epoch 60/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0282 - val_loss: 0.0077 - val_mae: 0.0551\n",
      "Epoch 61/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0016 - mae: 0.0293 - val_loss: 0.0082 - val_mae: 0.0587\n",
      "Epoch 62/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0016 - mae: 0.0292 - val_loss: 0.0081 - val_mae: 0.0579\n",
      "Epoch 63/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0016 - mae: 0.0293 - val_loss: 0.0082 - val_mae: 0.0588\n",
      "Epoch 64/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0016 - mae: 0.0293 - val_loss: 0.0081 - val_mae: 0.0578\n",
      "Epoch 65/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0016 - mae: 0.0288 - val_loss: 0.0083 - val_mae: 0.0594\n",
      "Epoch 66/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0015 - mae: 0.0283 - val_loss: 0.0083 - val_mae: 0.0593\n",
      "Epoch 67/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0015 - mae: 0.0286 - val_loss: 0.0079 - val_mae: 0.0567\n",
      "Epoch 68/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0016 - mae: 0.0292 - val_loss: 0.0083 - val_mae: 0.0589\n",
      "Epoch 69/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0016 - mae: 0.0292 - val_loss: 0.0082 - val_mae: 0.0584\n",
      "Epoch 70/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0015 - mae: 0.0286 - val_loss: 0.0080 - val_mae: 0.0572\n",
      "Epoch 71/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0289 - val_loss: 0.0082 - val_mae: 0.0586\n",
      "Epoch 72/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0015 - mae: 0.0284 - val_loss: 0.0078 - val_mae: 0.0563\n",
      "Epoch 73/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0017 - mae: 0.0297 - val_loss: 0.0080 - val_mae: 0.0575\n",
      "Epoch 74/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0016 - mae: 0.0292 - val_loss: 0.0082 - val_mae: 0.0585\n",
      "Epoch 75/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0016 - mae: 0.0289 - val_loss: 0.0081 - val_mae: 0.0579\n",
      "Epoch 76/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0016 - mae: 0.0290 - val_loss: 0.0079 - val_mae: 0.0565\n",
      "Epoch 77/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0016 - mae: 0.0291 - val_loss: 0.0084 - val_mae: 0.0597\n",
      "Epoch 78/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0016 - mae: 0.0290 - val_loss: 0.0082 - val_mae: 0.0588\n",
      "Epoch 79/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0283 - val_loss: 0.0082 - val_mae: 0.0585\n",
      "Epoch 80/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0017 - mae: 0.0291 - val_loss: 0.0082 - val_mae: 0.0586\n",
      "Epoch 81/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0016 - mae: 0.0292 - val_loss: 0.0084 - val_mae: 0.0596\n",
      "Epoch 82/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0016 - mae: 0.0288 - val_loss: 0.0083 - val_mae: 0.0590\n",
      "Epoch 83/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0016 - mae: 0.0288 - val_loss: 0.0082 - val_mae: 0.0587\n",
      "Epoch 84/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0016 - mae: 0.0289 - val_loss: 0.0085 - val_mae: 0.0604\n",
      "Epoch 85/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0016 - mae: 0.0294 - val_loss: 0.0082 - val_mae: 0.0583\n",
      "Epoch 86/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0016 - mae: 0.0290 - val_loss: 0.0082 - val_mae: 0.0588\n",
      "Epoch 87/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0289 - val_loss: 0.0081 - val_mae: 0.0581\n",
      "Epoch 88/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0288 - val_loss: 0.0084 - val_mae: 0.0597\n",
      "Epoch 89/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0284 - val_loss: 0.0082 - val_mae: 0.0584\n",
      "Epoch 90/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0017 - mae: 0.0286 - val_loss: 0.0081 - val_mae: 0.0580\n",
      "Epoch 91/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0016 - mae: 0.0290 - val_loss: 0.0082 - val_mae: 0.0588\n",
      "Epoch 92/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0016 - mae: 0.0292 - val_loss: 0.0085 - val_mae: 0.0605\n",
      "Epoch 93/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0016 - mae: 0.0291 - val_loss: 0.0081 - val_mae: 0.0578\n",
      "Epoch 94/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0017 - mae: 0.0298 - val_loss: 0.0085 - val_mae: 0.0603\n",
      "Epoch 95/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0016 - mae: 0.0295 - val_loss: 0.0081 - val_mae: 0.0581\n",
      "Epoch 96/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0291 - val_loss: 0.0078 - val_mae: 0.0564\n",
      "Epoch 97/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0016 - mae: 0.0289 - val_loss: 0.0082 - val_mae: 0.0587\n",
      "Epoch 98/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0286 - val_loss: 0.0084 - val_mae: 0.0597\n",
      "Epoch 99/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0016 - mae: 0.0294 - val_loss: 0.0079 - val_mae: 0.0569\n",
      "Epoch 100/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0016 - mae: 0.0287 - val_loss: 0.0081 - val_mae: 0.0582\n",
      "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step\n",
      "✅ Done with onion_Davangere_daily.csv | MAE=444.42, RMSE=685.13, R2=-0.0403, MAPE=45.05%, Accuracy=54.95%\n",
      "\n",
      "🚀 Processing: onion_Dharwad_daily.csv\n",
      "Epoch 1/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0132 - mae: 0.0781 - val_loss: 0.0106 - val_mae: 0.0736\n",
      "Epoch 2/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0101 - mae: 0.0726 - val_loss: 0.0106 - val_mae: 0.0736\n",
      "Epoch 3/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0102 - mae: 0.0739 - val_loss: 0.0109 - val_mae: 0.0737\n",
      "Epoch 4/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0105 - mae: 0.0746 - val_loss: 0.0114 - val_mae: 0.0741\n",
      "Epoch 5/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0108 - mae: 0.0736 - val_loss: 0.0115 - val_mae: 0.0743\n",
      "Epoch 6/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0096 - mae: 0.0732 - val_loss: 0.0115 - val_mae: 0.0743\n",
      "Epoch 7/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0103 - mae: 0.0731 - val_loss: 0.0110 - val_mae: 0.0737\n",
      "Epoch 8/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0097 - mae: 0.0728 - val_loss: 0.0121 - val_mae: 0.0751\n",
      "Epoch 9/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0103 - mae: 0.0728 - val_loss: 0.0115 - val_mae: 0.0742\n",
      "Epoch 10/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0104 - mae: 0.0741 - val_loss: 0.0116 - val_mae: 0.0744\n",
      "Epoch 11/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0101 - mae: 0.0730 - val_loss: 0.0120 - val_mae: 0.0750\n",
      "Epoch 12/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0107 - mae: 0.0751 - val_loss: 0.0108 - val_mae: 0.0736\n",
      "Epoch 13/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0106 - mae: 0.0741 - val_loss: 0.0119 - val_mae: 0.0749\n",
      "Epoch 14/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0099 - mae: 0.0713 - val_loss: 0.0109 - val_mae: 0.0737\n",
      "Epoch 15/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0110 - mae: 0.0752 - val_loss: 0.0117 - val_mae: 0.0745\n",
      "Epoch 16/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0101 - mae: 0.0730 - val_loss: 0.0111 - val_mae: 0.0739\n",
      "Epoch 17/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0102 - mae: 0.0749 - val_loss: 0.0118 - val_mae: 0.0747\n",
      "Epoch 18/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0100 - mae: 0.0726 - val_loss: 0.0116 - val_mae: 0.0744\n",
      "Epoch 19/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0114 - mae: 0.0756 - val_loss: 0.0118 - val_mae: 0.0747\n",
      "Epoch 20/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0103 - mae: 0.0740 - val_loss: 0.0118 - val_mae: 0.0747\n",
      "Epoch 21/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0105 - mae: 0.0738 - val_loss: 0.0121 - val_mae: 0.0752\n",
      "Epoch 22/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0099 - mae: 0.0734 - val_loss: 0.0118 - val_mae: 0.0748\n",
      "Epoch 23/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0098 - mae: 0.0719 - val_loss: 0.0110 - val_mae: 0.0738\n",
      "Epoch 24/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0106 - mae: 0.0737 - val_loss: 0.0115 - val_mae: 0.0742\n",
      "Epoch 25/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0105 - mae: 0.0748 - val_loss: 0.0112 - val_mae: 0.0739\n",
      "Epoch 26/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0110 - mae: 0.0753 - val_loss: 0.0117 - val_mae: 0.0746\n",
      "Epoch 27/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0100 - mae: 0.0733 - val_loss: 0.0118 - val_mae: 0.0748\n",
      "Epoch 28/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0106 - mae: 0.0742 - val_loss: 0.0117 - val_mae: 0.0745\n",
      "Epoch 29/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0100 - mae: 0.0734 - val_loss: 0.0113 - val_mae: 0.0740\n",
      "Epoch 30/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0097 - mae: 0.0716 - val_loss: 0.0106 - val_mae: 0.0736\n",
      "Epoch 31/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0109 - mae: 0.0753 - val_loss: 0.0121 - val_mae: 0.0752\n",
      "Epoch 32/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0099 - mae: 0.0727 - val_loss: 0.0110 - val_mae: 0.0738\n",
      "Epoch 33/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0102 - mae: 0.0741 - val_loss: 0.0108 - val_mae: 0.0736\n",
      "Epoch 34/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0103 - mae: 0.0740 - val_loss: 0.0115 - val_mae: 0.0743\n",
      "Epoch 35/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0107 - mae: 0.0744 - val_loss: 0.0115 - val_mae: 0.0743\n",
      "Epoch 36/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0107 - mae: 0.0747 - val_loss: 0.0119 - val_mae: 0.0748\n",
      "Epoch 37/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0105 - mae: 0.0753 - val_loss: 0.0120 - val_mae: 0.0751\n",
      "Epoch 38/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0098 - mae: 0.0724 - val_loss: 0.0109 - val_mae: 0.0737\n",
      "Epoch 39/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0105 - mae: 0.0744 - val_loss: 0.0111 - val_mae: 0.0738\n",
      "Epoch 40/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0105 - mae: 0.0749 - val_loss: 0.0115 - val_mae: 0.0743\n",
      "Epoch 41/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0096 - mae: 0.0728 - val_loss: 0.0115 - val_mae: 0.0742\n",
      "Epoch 42/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0103 - mae: 0.0744 - val_loss: 0.0112 - val_mae: 0.0740\n",
      "Epoch 43/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0101 - mae: 0.0740 - val_loss: 0.0117 - val_mae: 0.0746\n",
      "Epoch 44/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0104 - mae: 0.0747 - val_loss: 0.0112 - val_mae: 0.0739\n",
      "Epoch 45/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0105 - mae: 0.0748 - val_loss: 0.0112 - val_mae: 0.0739\n",
      "Epoch 46/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0102 - mae: 0.0730 - val_loss: 0.0110 - val_mae: 0.0737\n",
      "Epoch 47/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0111 - mae: 0.0761 - val_loss: 0.0118 - val_mae: 0.0746\n",
      "Epoch 48/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0107 - mae: 0.0737 - val_loss: 0.0116 - val_mae: 0.0744\n",
      "Epoch 49/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0114 - mae: 0.0771 - val_loss: 0.0117 - val_mae: 0.0746\n",
      "Epoch 50/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0106 - mae: 0.0746 - val_loss: 0.0112 - val_mae: 0.0739\n",
      "Epoch 51/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0103 - mae: 0.0722 - val_loss: 0.0108 - val_mae: 0.0736\n",
      "Epoch 52/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0098 - mae: 0.0728 - val_loss: 0.0115 - val_mae: 0.0742\n",
      "Epoch 53/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0096 - mae: 0.0709 - val_loss: 0.0115 - val_mae: 0.0743\n",
      "Epoch 54/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0101 - mae: 0.0728 - val_loss: 0.0117 - val_mae: 0.0745\n",
      "Epoch 55/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0112 - mae: 0.0765 - val_loss: 0.0115 - val_mae: 0.0742\n",
      "Epoch 56/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0101 - mae: 0.0728 - val_loss: 0.0118 - val_mae: 0.0747\n",
      "Epoch 57/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0098 - mae: 0.0722 - val_loss: 0.0112 - val_mae: 0.0739\n",
      "Epoch 58/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0100 - mae: 0.0747 - val_loss: 0.0105 - val_mae: 0.0736\n",
      "Epoch 59/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0098 - mae: 0.0730 - val_loss: 0.0113 - val_mae: 0.0740\n",
      "Epoch 60/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0110 - mae: 0.0764 - val_loss: 0.0114 - val_mae: 0.0742\n",
      "Epoch 61/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0108 - mae: 0.0741 - val_loss: 0.0127 - val_mae: 0.0763\n",
      "Epoch 62/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0106 - mae: 0.0730 - val_loss: 0.0103 - val_mae: 0.0737\n",
      "Epoch 63/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0100 - mae: 0.0730 - val_loss: 0.0118 - val_mae: 0.0748\n",
      "Epoch 64/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0100 - mae: 0.0737 - val_loss: 0.0115 - val_mae: 0.0743\n",
      "Epoch 65/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0100 - mae: 0.0722 - val_loss: 0.0111 - val_mae: 0.0739\n",
      "Epoch 66/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0103 - mae: 0.0740 - val_loss: 0.0122 - val_mae: 0.0754\n",
      "Epoch 67/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0091 - mae: 0.0696 - val_loss: 0.0105 - val_mae: 0.0736\n",
      "Epoch 68/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0105 - mae: 0.0752 - val_loss: 0.0119 - val_mae: 0.0749\n",
      "Epoch 69/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0106 - mae: 0.0748 - val_loss: 0.0118 - val_mae: 0.0748\n",
      "Epoch 70/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0102 - mae: 0.0735 - val_loss: 0.0111 - val_mae: 0.0739\n",
      "Epoch 71/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0114 - mae: 0.0765 - val_loss: 0.0110 - val_mae: 0.0738\n",
      "Epoch 72/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0100 - mae: 0.0734 - val_loss: 0.0112 - val_mae: 0.0739\n",
      "Epoch 73/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0106 - mae: 0.0741 - val_loss: 0.0121 - val_mae: 0.0751\n",
      "Epoch 74/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0097 - mae: 0.0710 - val_loss: 0.0111 - val_mae: 0.0738\n",
      "Epoch 75/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0119 - mae: 0.0781 - val_loss: 0.0113 - val_mae: 0.0740\n",
      "Epoch 76/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0098 - mae: 0.0728 - val_loss: 0.0122 - val_mae: 0.0754\n",
      "Epoch 77/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0109 - mae: 0.0744 - val_loss: 0.0110 - val_mae: 0.0737\n",
      "Epoch 78/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0103 - mae: 0.0746 - val_loss: 0.0112 - val_mae: 0.0739\n",
      "Epoch 79/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0108 - mae: 0.0746 - val_loss: 0.0126 - val_mae: 0.0760\n",
      "Epoch 80/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0106 - mae: 0.0735 - val_loss: 0.0120 - val_mae: 0.0751\n",
      "Epoch 81/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0101 - mae: 0.0729 - val_loss: 0.0110 - val_mae: 0.0737\n",
      "Epoch 82/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0108 - mae: 0.0747 - val_loss: 0.0114 - val_mae: 0.0742\n",
      "Epoch 83/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0106 - mae: 0.0741 - val_loss: 0.0116 - val_mae: 0.0744\n",
      "Epoch 84/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0093 - mae: 0.0699 - val_loss: 0.0115 - val_mae: 0.0742\n",
      "Epoch 85/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0107 - mae: 0.0755 - val_loss: 0.0119 - val_mae: 0.0749\n",
      "Epoch 86/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0112 - mae: 0.0745 - val_loss: 0.0112 - val_mae: 0.0739\n",
      "Epoch 87/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0098 - mae: 0.0723 - val_loss: 0.0112 - val_mae: 0.0739\n",
      "Epoch 88/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0111 - mae: 0.0762 - val_loss: 0.0111 - val_mae: 0.0738\n",
      "Epoch 89/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0105 - mae: 0.0743 - val_loss: 0.0107 - val_mae: 0.0736\n",
      "Epoch 90/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0098 - mae: 0.0745 - val_loss: 0.0114 - val_mae: 0.0741\n",
      "Epoch 91/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0106 - mae: 0.0747 - val_loss: 0.0114 - val_mae: 0.0742\n",
      "Epoch 92/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0102 - mae: 0.0730 - val_loss: 0.0113 - val_mae: 0.0740\n",
      "Epoch 93/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0099 - mae: 0.0736 - val_loss: 0.0118 - val_mae: 0.0747\n",
      "Epoch 94/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0108 - mae: 0.0759 - val_loss: 0.0124 - val_mae: 0.0757\n",
      "Epoch 95/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0100 - mae: 0.0726 - val_loss: 0.0118 - val_mae: 0.0747\n",
      "Epoch 96/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0101 - mae: 0.0730 - val_loss: 0.0113 - val_mae: 0.0740\n",
      "Epoch 97/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0100 - mae: 0.0734 - val_loss: 0.0125 - val_mae: 0.0759\n",
      "Epoch 98/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0102 - mae: 0.0732 - val_loss: 0.0113 - val_mae: 0.0740\n",
      "Epoch 99/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0097 - mae: 0.0723 - val_loss: 0.0111 - val_mae: 0.0738\n",
      "Epoch 100/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0105 - mae: 0.0743 - val_loss: 0.0116 - val_mae: 0.0744\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step\n",
      "✅ Done with onion_Dharwad_daily.csv | MAE=547.77, RMSE=764.66, R2=-0.0092, MAPE=54.26%, Accuracy=45.74%\n",
      "\n",
      "🚀 Processing: onion_Gadag_daily.csv\n",
      "Epoch 1/100\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 0.0584 - mae: 0.1793 - val_loss: 0.0444 - val_mae: 0.1405\n",
      "Epoch 2/100\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0358 - mae: 0.1553 - val_loss: 0.0471 - val_mae: 0.1409\n",
      "Epoch 3/100\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0331 - mae: 0.1495 - val_loss: 0.0439 - val_mae: 0.1405\n",
      "Epoch 4/100\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0337 - mae: 0.1510 - val_loss: 0.0453 - val_mae: 0.1405\n",
      "Epoch 5/100\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0346 - mae: 0.1493 - val_loss: 0.0447 - val_mae: 0.1405\n",
      "Epoch 6/100\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0351 - mae: 0.1537 - val_loss: 0.0476 - val_mae: 0.1411\n",
      "Epoch 7/100\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0363 - mae: 0.1553 - val_loss: 0.0468 - val_mae: 0.1407\n",
      "Epoch 8/100\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0348 - mae: 0.1510 - val_loss: 0.0412 - val_mae: 0.1405\n",
      "Epoch 9/100\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0366 - mae: 0.1561 - val_loss: 0.0461 - val_mae: 0.1405\n",
      "Epoch 10/100\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0358 - mae: 0.1534 - val_loss: 0.0472 - val_mae: 0.1409\n",
      "Epoch 11/100\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0345 - mae: 0.1517 - val_loss: 0.0438 - val_mae: 0.1405\n",
      "Epoch 12/100\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0363 - mae: 0.1548 - val_loss: 0.0468 - val_mae: 0.1407\n",
      "Epoch 13/100\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0354 - mae: 0.1538 - val_loss: 0.0456 - val_mae: 0.1405\n",
      "Epoch 14/100\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0344 - mae: 0.1515 - val_loss: 0.0453 - val_mae: 0.1405\n",
      "Epoch 15/100\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0358 - mae: 0.1557 - val_loss: 0.0430 - val_mae: 0.1405\n",
      "Epoch 16/100\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0345 - mae: 0.1522 - val_loss: 0.0440 - val_mae: 0.1405\n",
      "Epoch 17/100\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0327 - mae: 0.1495 - val_loss: 0.0424 - val_mae: 0.1405\n",
      "Epoch 18/100\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0347 - mae: 0.1534 - val_loss: 0.0461 - val_mae: 0.1405\n",
      "Epoch 19/100\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0359 - mae: 0.1539 - val_loss: 0.0450 - val_mae: 0.1405\n",
      "Epoch 20/100\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0335 - mae: 0.1489 - val_loss: 0.0457 - val_mae: 0.1405\n",
      "Epoch 21/100\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0345 - mae: 0.1514 - val_loss: 0.0437 - val_mae: 0.1405\n",
      "Epoch 22/100\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0344 - mae: 0.1502 - val_loss: 0.0461 - val_mae: 0.1405\n",
      "Epoch 23/100\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0342 - mae: 0.1511 - val_loss: 0.0440 - val_mae: 0.1405\n",
      "Epoch 24/100\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0336 - mae: 0.1483 - val_loss: 0.0445 - val_mae: 0.1405\n",
      "Epoch 25/100\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0352 - mae: 0.1535 - val_loss: 0.0474 - val_mae: 0.1410\n",
      "Epoch 26/100\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0344 - mae: 0.1499 - val_loss: 0.0435 - val_mae: 0.1405\n",
      "Epoch 27/100\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0338 - mae: 0.1504 - val_loss: 0.0412 - val_mae: 0.1405\n",
      "Epoch 28/100\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0343 - mae: 0.1519 - val_loss: 0.0459 - val_mae: 0.1405\n",
      "Epoch 29/100\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0356 - mae: 0.1538 - val_loss: 0.0449 - val_mae: 0.1405\n",
      "Epoch 30/100\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0352 - mae: 0.1526 - val_loss: 0.0443 - val_mae: 0.1405\n",
      "Epoch 31/100\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0348 - mae: 0.1523 - val_loss: 0.0440 - val_mae: 0.1405\n",
      "Epoch 32/100\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0338 - mae: 0.1512 - val_loss: 0.0431 - val_mae: 0.1405\n",
      "Epoch 33/100\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0172 - mae: 0.0987 - val_loss: 0.0067 - val_mae: 0.0626\n",
      "Epoch 70/100\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0169 - mae: 0.0980 - val_loss: 0.0053 - val_mae: 0.0516\n",
      "Epoch 71/100\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0168 - mae: 0.0993 - val_loss: 0.0067 - val_mae: 0.0622\n",
      "Epoch 72/100\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0175 - mae: 0.0993 - val_loss: 0.0057 - val_mae: 0.0548\n",
      "Epoch 73/100\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0171 - mae: 0.1003 - val_loss: 0.0066 - val_mae: 0.0613\n",
      "Epoch 74/100\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0166 - mae: 0.0986 - val_loss: 0.0058 - val_mae: 0.0551\n",
      "Epoch 75/100\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0170 - mae: 0.0987 - val_loss: 0.0057 - val_mae: 0.0549\n",
      "Epoch 76/100\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0167 - mae: 0.0977 - val_loss: 0.0064 - val_mae: 0.0602\n",
      "Epoch 77/100\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0167 - mae: 0.0983 - val_loss: 0.0059 - val_mae: 0.0563\n",
      "Epoch 78/100\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0171 - mae: 0.0994 - val_loss: 0.0060 - val_mae: 0.0572\n",
      "Epoch 79/100\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0171 - mae: 0.0991 - val_loss: 0.0058 - val_mae: 0.0556\n",
      "Epoch 80/100\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0171 - mae: 0.0993 - val_loss: 0.0060 - val_mae: 0.0567\n",
      "Epoch 81/100\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0162 - mae: 0.0984 - val_loss: 0.0057 - val_mae: 0.0543\n",
      "Epoch 82/100\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0173 - mae: 0.1001 - val_loss: 0.0065 - val_mae: 0.0612\n",
      "Epoch 97/100\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0165 - mae: 0.0970 - val_loss: 0.0065 - val_mae: 0.0612\n",
      "Epoch 98/100\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0167 - mae: 0.0979 - val_loss: 0.0064 - val_mae: 0.0600\n",
      "Epoch 99/100\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0166 - mae: 0.0982 - val_loss: 0.0054 - val_mae: 0.0519\n",
      "Epoch 100/100\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0171 - mae: 0.0992 - val_loss: 0.0061 - val_mae: 0.0580\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step\n",
      "✅ Done with onion_Haveri_daily.csv | MAE=543.14, RMSE=726.67, R2=-0.0059, MAPE=47.97%, Accuracy=52.03%\n",
      "\n",
      "🚀 Processing: onion_Kolar_daily.csv\n",
      "Epoch 1/100\n",
      "\u001b[1m1943/1943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 11ms/step - loss: 0.0023 - mae: 0.0329 - val_loss: 0.0031 - val_mae: 0.0395\n",
      "Epoch 2/100\n",
      "\u001b[1m1943/1943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - loss: 0.0022 - mae: 0.0322 - val_loss: 0.0031 - val_mae: 0.0397\n",
      "Epoch 3/100\n",
      "\u001b[1m1943/1943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - loss: 0.0024 - mae: 0.0328 - val_loss: 0.0034 - val_mae: 0.0425\n",
      "Epoch 11/100\n",
      "\u001b[1m1943/1943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - loss: 0.0023 - mae: 0.0323 - val_loss: 0.0034 - val_mae: 0.0421\n",
      "Epoch 12/100\n",
      "\u001b[1m1943/1943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - loss: 0.0023 - mae: 0.0324 - val_loss: 0.0034 - val_mae: 0.0426\n",
      "Epoch 13/100\n",
      "\u001b[1m1943/1943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - loss: 0.0022 - mae: 0.0320 - val_loss: 0.0028 - val_mae: 0.0370\n",
      "Epoch 20/100\n",
      "\u001b[1m1943/1943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - loss: 0.0023 - mae: 0.0323 - val_loss: 0.0034 - val_mae: 0.0428\n",
      "Epoch 21/100\n",
      "\u001b[1m1943/1943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - loss: 0.0022 - mae: 0.0322 - val_loss: 0.0029 - val_mae: 0.0375\n",
      "Epoch 22/100\n",
      "\u001b[1m1943/1943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - loss: 0.0021 - mae: 0.0316 - val_loss: 0.0028 - val_mae: 0.0369\n",
      "Epoch 29/100\n",
      "\u001b[1m1943/1943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 9ms/step - loss: 0.0021 - mae: 0.0319 - val_loss: 0.0033 - val_mae: 0.0415\n",
      "Epoch 30/100\n",
      "\u001b[1m1943/1943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - loss: 0.0023 - mae: 0.0324 - val_loss: 0.0034 - val_mae: 0.0422\n",
      "Epoch 31/100\n",
      "\u001b[1m1943/1943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - loss: 0.0023 - mae: 0.0321 - val_loss: 0.0032 - val_mae: 0.0408\n",
      "Epoch 32/100\n",
      "\u001b[1m1943/1943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - loss: 0.0022 - mae: 0.0322 - val_loss: 0.0031 - val_mae: 0.0395\n",
      "Epoch 40/100\n",
      "\u001b[1m1943/1943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 9ms/step - loss: 0.0023 - mae: 0.0325 - val_loss: 0.0030 - val_mae: 0.0383\n",
      "Epoch 41/100\n",
      "\u001b[1m1943/1943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 9ms/step - loss: 0.0023 - mae: 0.0326 - val_loss: 0.0034 - val_mae: 0.0427\n",
      "Epoch 42/100\n",
      "\u001b[1m1943/1943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 0.0022 - mae: 0.0321 - val_loss: 0.0032 - val_mae: 0.0400\n",
      "Epoch 43/100\n",
      "\u001b[1m1943/1943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - loss: 0.0022 - mae: 0.0325 - val_loss: 0.0030 - val_mae: 0.0384\n",
      "Epoch 53/100\n",
      "\u001b[1m1943/1943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - loss: 0.0021 - mae: 0.0319 - val_loss: 0.0030 - val_mae: 0.0385\n",
      "Epoch 54/100\n",
      "\u001b[1m1943/1943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - loss: 0.0022 - mae: 0.0321 - val_loss: 0.0032 - val_mae: 0.0408\n",
      "Epoch 55/100\n",
      "\u001b[1m1943/1943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - loss: 0.0022 - mae: 0.0321 - val_loss: 0.0032 - val_mae: 0.0409\n",
      "Epoch 56/100\n",
      "\u001b[1m1943/1943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - loss: 0.0022 - mae: 0.0323 - val_loss: 0.0030 - val_mae: 0.0387\n",
      "Epoch 68/100\n",
      "\u001b[1m1943/1943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - loss: 0.0023 - mae: 0.0326 - val_loss: 0.0031 - val_mae: 0.0398\n",
      "Epoch 69/100\n",
      "\u001b[1m 503/1943\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0021 - mae: 0.0320"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "import joblib  # For saving models as .pkl\n",
    "\n",
    "# -----------------------------\n",
    "# Output directories\n",
    "# -----------------------------\n",
    "input_folder = \"dataset\"\n",
    "output_models = \"tat_output_models\"\n",
    "output_csv = \"tat_output_csv\"\n",
    "output_graphs = \"tat_output_graphs\"\n",
    "output_logs = \"tat_output_logs\"\n",
    "metrics_file = \"tat_metrics.csv\"\n",
    "\n",
    "os.makedirs(output_models, exist_ok=True)\n",
    "os.makedirs(output_csv, exist_ok=True)\n",
    "os.makedirs(output_graphs, exist_ok=True)\n",
    "os.makedirs(output_logs, exist_ok=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Function to create dataset\n",
    "# -----------------------------\n",
    "def create_dataset(data, look_back=30):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - look_back):\n",
    "        X.append(data[i:i+look_back, 0])\n",
    "        y.append(data[i+look_back, 0])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# -----------------------------\n",
    "# Define Temporal Attention Transformer Model\n",
    "# -----------------------------\n",
    "def build_tat_model(input_shape, d_model=64, num_heads=4, ff_dim=128, dropout_rate=0.2):\n",
    "    inputs = layers.Input(shape=input_shape)  # (look_back, 1)\n",
    "    \n",
    "    # Multi-Head Attention\n",
    "    x = layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)(inputs, inputs)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x + inputs)  # Residual connection\n",
    "    \n",
    "    # Feed-Forward Network\n",
    "    ff = layers.Dense(ff_dim, activation='relu')(x)\n",
    "    ff = layers.Dense(input_shape[1])(ff)\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x + ff)  # Residual connection\n",
    "    \n",
    "    # Global Pooling\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    \n",
    "    # Output\n",
    "    outputs = layers.Dense(1)(x)\n",
    "    \n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=0.001),\n",
    "                  loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# -----------------------------\n",
    "# Function to robustly parse dates\n",
    "# -----------------------------\n",
    "def parse_dates_safe(date_series):\n",
    "    # First try strict ISO format (avoids warning)\n",
    "    try:\n",
    "        return pd.to_datetime(date_series, format=\"%Y-%m-%d\", errors='coerce')\n",
    "    except:\n",
    "        # Fallback flexible parsing\n",
    "        return pd.to_datetime(date_series, errors='coerce', dayfirst=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Metrics storage\n",
    "# -----------------------------\n",
    "metrics_list = []\n",
    "\n",
    "# -----------------------------\n",
    "# Process each CSV file\n",
    "# -----------------------------\n",
    "look_back = 30\n",
    "for file in os.listdir(input_folder):\n",
    "    if file.endswith(\".csv\"):\n",
    "        file_path = os.path.join(input_folder, file)\n",
    "        print(f\"🚀 Processing: {file}\")\n",
    "\n",
    "        # Load CSV\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Robust date parsing\n",
    "        df['Date'] = parse_dates_safe(df['Date'])\n",
    "        df = df.dropna(subset=['Date'])\n",
    "        df = df.sort_values('Date')\n",
    "\n",
    "        # Replace NaN in 'Average Price' with column mean (future-proof)\n",
    "        df['Average Price'] = df['Average Price'].fillna(df['Average Price'].mean())\n",
    "        df['Average Price'] = df['Average Price'].round(2)\n",
    "\n",
    "        # Add moving averages (future-proof fill)\n",
    "        df['MA_7'] = df['Average Price'].rolling(window=7).mean()\n",
    "        df['MA_30'] = df['Average Price'].rolling(window=30).mean()\n",
    "        df['MA_7'] = df['MA_7'].fillna(df['MA_7'].mean())\n",
    "        df['MA_30'] = df['MA_30'].fillna(df['MA_30'].mean())\n",
    "\n",
    "        # Prepare data using MinMaxScaler\n",
    "        values = df[['Average Price']].values.astype('float32')\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        scaled_values = scaler.fit_transform(values)\n",
    "\n",
    "        # Create sequences\n",
    "        X, y = create_dataset(scaled_values, look_back)\n",
    "        X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
    "\n",
    "        # Build model\n",
    "        model = build_tat_model(input_shape=(look_back,1))\n",
    "\n",
    "        # Train model\n",
    "        history = model.fit(X, y, epochs=100, batch_size=16, validation_split=0.2, verbose=1)\n",
    "\n",
    "        # Save training logs\n",
    "        log_file = os.path.join(output_logs, file.replace(\".csv\", \"_tat_training.txt\"))\n",
    "        with open(log_file, \"w\") as f:\n",
    "            f.write(\"Training Loss per Epoch:\\n\")\n",
    "            for i, loss in enumerate(history.history['loss']):\n",
    "                f.write(f\"Epoch {i+1}: Loss={loss}, Val_Loss={history.history['val_loss'][i]}\\n\")\n",
    "\n",
    "        # Predictions\n",
    "        predictions = model.predict(X)\n",
    "        predictions_rescaled = scaler.inverse_transform(predictions)\n",
    "        df['Predicted'] = [np.nan]*look_back + list(predictions_rescaled.flatten())\n",
    "        df['Predicted'] = df['Predicted'].round(2)\n",
    "\n",
    "        # Compute metrics safely\n",
    "        y_true = df['Average Price'].values[look_back:]\n",
    "        y_pred = predictions_rescaled.flatten()\n",
    "\n",
    "        # Avoid divide-by-zero in MAPE\n",
    "        non_zero_idx = y_true != 0\n",
    "        if np.any(non_zero_idx):\n",
    "            mape = round(np.mean(np.abs((y_true[non_zero_idx] - y_pred[non_zero_idx]) / y_true[non_zero_idx])) * 100, 2)\n",
    "            accuracy = round(100 - mape, 2)\n",
    "        else:\n",
    "            mape, accuracy = np.nan, np.nan\n",
    "\n",
    "        mae = round(mean_absolute_error(y_true, y_pred), 2)\n",
    "        rmse = round(np.sqrt(mean_squared_error(y_true, y_pred)), 2)\n",
    "        r2 = round(r2_score(y_true, y_pred), 4)\n",
    "\n",
    "        metrics_list.append([file.replace(\".csv\",\"\"), mae, rmse, r2, mape, accuracy])\n",
    "\n",
    "        # Save model as .pkl\n",
    "        model_file = os.path.join(output_models, file.replace(\".csv\", \"_tat_model.pkl\"))\n",
    "        joblib.dump(model, model_file)\n",
    "\n",
    "        # Save CSV with only Date, Actual, Predicted\n",
    "        save_df = df[['Average Price', 'Predicted']].copy()\n",
    "        save_df.rename(columns={'Average Price':'Actual'}, inplace=True)\n",
    "        save_df['Date'] = df['Date']\n",
    "        save_df = save_df[['Date', 'Actual', 'Predicted']]\n",
    "        updated_csv_path = os.path.join(output_csv, file.replace(\".csv\", \"_tat_updated.csv\"))\n",
    "        save_df.to_csv(updated_csv_path, index=False)\n",
    "\n",
    "        # Save graph\n",
    "        plt.figure(figsize=(12,6))\n",
    "        plt.plot(df['Date'], df['Average Price'], label='Actual', color='blue')\n",
    "        plt.plot(df['Date'], df['Predicted'], label='Predicted', color='red', linestyle='dashed')\n",
    "        plt.plot(df['Date'], df['MA_7'], label='MA 7', color='orange')\n",
    "        plt.plot(df['Date'], df['MA_30'], label='MA 30', color='green')\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Average Price')\n",
    "        plt.title(f'Price Prediction (TAT) - {file}')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        graph_file = os.path.join(output_graphs, file.replace(\".csv\", \"_tat_graph.png\"))\n",
    "        plt.savefig(graph_file, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "        print(f\"✅ Done with {file} | MAE={mae}, RMSE={rmse}, R2={r2}, MAPE={mape}%, Accuracy={accuracy}%\\n\")\n",
    "\n",
    "# Save all metrics\n",
    "metrics_df = pd.DataFrame(metrics_list, columns=['District', 'MAE', 'RMSE', 'R2', 'MAPE(%)', 'Accuracy(%)'])\n",
    "metrics_df.to_csv(metrics_file, index=False)\n",
    "print(f\"📊 Metrics saved to {metrics_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4c6109-0a4b-49c7-b2f6-72fe2b0213ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "TAT+MQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac50db8-0ead-4a07-bf66-d19129a2377a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "import joblib  # for .pkl model saving (best-effort)\n",
    "warnings_imported = False\n",
    "try:\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    warnings_imported = True\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# -----------------------------\n",
    "# Output directories\n",
    "# -----------------------------\n",
    "input_folder = \"dataset\"\n",
    "output_models = \"tat_mqa_output_models\"\n",
    "output_csv = \"tat_mqa_output_csv\"\n",
    "output_graphs = \"tat_mqa_output_graphs\"\n",
    "output_logs = \"tat_mqa_output_logs\"\n",
    "metrics_file = \"tat_mqa_metrics.csv\"\n",
    "\n",
    "os.makedirs(output_models, exist_ok=True)\n",
    "os.makedirs(output_csv, exist_ok=True)\n",
    "os.makedirs(output_graphs, exist_ok=True)\n",
    "os.makedirs(output_logs, exist_ok=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Function to create dataset\n",
    "# -----------------------------\n",
    "def create_dataset(data, look_back=30):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - look_back):\n",
    "        X.append(data[i:i+look_back, 0])\n",
    "        y.append(data[i+look_back, 0])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# -----------------------------\n",
    "# Multi-Query Attention Layer\n",
    "# -----------------------------\n",
    "class MultiQueryAttention(layers.Layer):\n",
    "    def __init__(self, num_heads, key_dim, dropout_rate=0.1, **kwargs):\n",
    "        super(MultiQueryAttention, self).__init__(**kwargs)\n",
    "        self.num_heads = num_heads\n",
    "        self.key_dim = key_dim\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.q_dense = [layers.Dense(key_dim) for _ in range(num_heads)]\n",
    "        self.k_dense = layers.Dense(key_dim)\n",
    "        self.v_dense = layers.Dense(key_dim)\n",
    "        self.dropout = layers.Dropout(dropout_rate)\n",
    "        self.output_dense = layers.Dense(key_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        K = self.k_dense(x)\n",
    "        V = self.v_dense(x)\n",
    "        head_outputs = []\n",
    "\n",
    "        for q_layer in self.q_dense:\n",
    "            Q = q_layer(x)\n",
    "            scores = tf.matmul(Q, K, transpose_b=True) / tf.math.sqrt(tf.cast(self.key_dim, tf.float32))\n",
    "            attention_weights = tf.nn.softmax(scores, axis=-1)\n",
    "            attention_output = tf.matmul(attention_weights, V)\n",
    "            head_outputs.append(attention_output)\n",
    "\n",
    "        concat = tf.concat(head_outputs, axis=-1)\n",
    "        output = self.output_dense(concat)\n",
    "        output = self.dropout(output)\n",
    "        return output\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(MultiQueryAttention, self).get_config()\n",
    "        config.update({\n",
    "            \"num_heads\": self.num_heads,\n",
    "            \"key_dim\": self.key_dim,\n",
    "            \"dropout_rate\": self.dropout_rate\n",
    "        })\n",
    "        return config\n",
    "\n",
    "# -----------------------------\n",
    "# TAT-MQA Model\n",
    "# -----------------------------\n",
    "def build_tat_mqa_model(input_shape, d_model=64, num_heads=4, ff_dim=128, dropout_rate=0.2):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = MultiQueryAttention(num_heads=num_heads, key_dim=d_model, dropout_rate=dropout_rate)(inputs)\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x + inputs)\n",
    "\n",
    "    ff = layers.Dense(ff_dim, activation='relu')(x)\n",
    "    ff = layers.Dense(input_shape[1])(ff)\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x + ff)\n",
    "\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    outputs = layers.Dense(1)(x)\n",
    "\n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=0.001),\n",
    "                  loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# -----------------------------\n",
    "# Function to robustly parse dates\n",
    "# -----------------------------\n",
    "def parse_dates_safe(date_series):\n",
    "    # keep same behavior as you used before: infer_datetime_format True fallback\n",
    "    try:\n",
    "        return pd.to_datetime(date_series, infer_datetime_format=True, errors='coerce')\n",
    "    except:\n",
    "        return pd.to_datetime(date_series, errors='coerce')\n",
    "\n",
    "# -----------------------------\n",
    "# Metrics storage\n",
    "# -----------------------------\n",
    "metrics_list = []\n",
    "\n",
    "# -----------------------------\n",
    "# Process each CSV file\n",
    "# -----------------------------\n",
    "look_back = 30\n",
    "for file in os.listdir(input_folder):\n",
    "    if not file.endswith(\".csv\"):\n",
    "        continue\n",
    "\n",
    "    file_path = os.path.join(input_folder, file)\n",
    "    print(f\"🚀 Processing: {file}\")\n",
    "\n",
    "    # Load CSV\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Robust date parsing\n",
    "    df['Date'] = parse_dates_safe(df['Date'])\n",
    "    df = df.dropna(subset=['Date'])\n",
    "    df = df.sort_values('Date').reset_index(drop=True)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Handle missing Average Price\n",
    "    # -----------------------------\n",
    "    if 'Average Price' not in df.columns:\n",
    "        raise KeyError(\"Input CSV must contain 'Average Price' column.\")\n",
    "    if df['Average Price'].isna().sum() > 0:\n",
    "        mean_val = df['Average Price'].mean()\n",
    "        df['Average Price'].fillna(mean_val, inplace=True)\n",
    "        print(f\"Filled {df['Average Price'].isna().sum()} missing Average Price values with mean {mean_val:.2f}\")\n",
    "\n",
    "    # Round Actual values early\n",
    "    df['Average Price'] = df['Average Price'].astype(float).round(2)\n",
    "\n",
    "    # Moving averages (fill remaining NaNs with column mean to avoid plotting gaps)\n",
    "    df['MA_7'] = df['Average Price'].rolling(window=7).mean()\n",
    "    df['MA_30'] = df['Average Price'].rolling(window=30).mean()\n",
    "    df['MA_7'].fillna(df['MA_7'].mean(), inplace=True)\n",
    "    df['MA_30'].fillna(df['MA_30'].mean(), inplace=True)\n",
    "\n",
    "    # Prepare data\n",
    "    values = df[['Average Price']].values.astype('float32')\n",
    "    if len(values) <= look_back:\n",
    "        # Not enough data for the chosen look_back; skip file with a warning\n",
    "        print(f\"⚠️ Skipping {file} — dataset length ({len(values)}) <= look_back ({look_back})\")\n",
    "        continue\n",
    "\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_values = scaler.fit_transform(values)\n",
    "\n",
    "    X, y = create_dataset(scaled_values, look_back)\n",
    "    X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
    "\n",
    "    # Build and train model\n",
    "    model = build_tat_mqa_model(input_shape=(look_back,1))\n",
    "    model.summary()\n",
    "\n",
    "    history = model.fit(X, y, epochs=100, batch_size=16, validation_split=0.2, verbose=1)\n",
    "\n",
    "    # Save training logs\n",
    "    log_file = os.path.join(output_logs, file.replace(\".csv\", \"_tat_mqa_training.txt\"))\n",
    "    with open(log_file, \"w\") as f:\n",
    "        f.write(\"Training Loss per Epoch:\\n\")\n",
    "        for i, loss in enumerate(history.history['loss']):\n",
    "            val_loss = history.history['val_loss'][i] if 'val_loss' in history.history else None\n",
    "            f.write(f\"Epoch {i+1}: Loss={loss}, Val_Loss={val_loss}\\n\")\n",
    "\n",
    "    # Predictions (rescale)\n",
    "    predictions = model.predict(X)\n",
    "    predictions_rescaled = scaler.inverse_transform(predictions).flatten()\n",
    "    # pad with NaNs at start so predicted series aligns with original df index\n",
    "    padded_preds = np.concatenate([np.full(look_back, np.nan), predictions_rescaled])\n",
    "    df['Predicted'] = np.round(padded_preds, 2)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Compute metrics using only the matched portion (exclude leading NaNs)\n",
    "    # -----------------------------\n",
    "    y_true = df['Average Price'].values[look_back:]\n",
    "    y_pred = predictions_rescaled\n",
    "    mae = round(mean_absolute_error(y_true, y_pred), 2)\n",
    "    rmse = round(np.sqrt(mean_squared_error(y_true, y_pred)), 2)\n",
    "    r2 = round(r2_score(y_true, y_pred), 4)\n",
    "    # MAPE: avoid divide-by-zero by masking zeros\n",
    "    mask = y_true != 0\n",
    "    if mask.sum() == 0:\n",
    "        mape = np.nan\n",
    "        accuracy = np.nan\n",
    "    else:\n",
    "        mape = round(np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100, 2)\n",
    "        accuracy = round(100 - mape, 2)\n",
    "\n",
    "    metrics_list.append([file.replace(\".csv\",\"\"), mae, rmse, r2, mape, accuracy])\n",
    "\n",
    "    print(f\"✅ Done with {file} | MAE={mae}, RMSE={rmse}, R2={r2}, MAPE={mape}%, Accuracy={accuracy}%\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # Save model: native Keras and attempt .pkl (best-effort)\n",
    "    # -----------------------------\n",
    "    keras_model_path = os.path.join(output_models, file.replace(\".csv\", \"_tat_mqa_model.keras\"))\n",
    "    model.save(keras_model_path)\n",
    "    pkl_model_path = os.path.join(output_models, file.replace(\".csv\", \"_tat_mqa_model.pkl\"))\n",
    "    try:\n",
    "        # joblib.dump the Keras model object (may fail on some TF versions)\n",
    "        joblib.dump(model, pkl_model_path)\n",
    "    except Exception as e:\n",
    "        # fallback: save model architecture + weights dict to pickle (best-effort)\n",
    "        try:\n",
    "            model_info = {\n",
    "                \"config\": model.get_config(),\n",
    "                \"weights\": model.get_weights()\n",
    "            }\n",
    "            joblib.dump(model_info, pkl_model_path)\n",
    "        except Exception as e2:\n",
    "            print(f\"⚠️ Could not save .pkl for {file}: {e}; {e2}\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # Save CSV with only Date, Actual, Predicted (Actual renamed)\n",
    "    # -----------------------------\n",
    "    save_df = pd.DataFrame({\n",
    "        'Date': df['Date'],\n",
    "        'Actual': df['Average Price'].round(2),\n",
    "        'Predicted': df['Predicted']\n",
    "    })\n",
    "    updated_csv_path = os.path.join(output_csv, file.replace(\".csv\", \"_tat_mqa_updated.csv\"))\n",
    "    save_df.to_csv(updated_csv_path, index=False)\n",
    "    print(f\"Saved updated CSV with Date, Actual & Predicted: {updated_csv_path}\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # Save graph with Actual, Predicted, MA7, MA30\n",
    "    # -----------------------------\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.plot(df['Date'], df['Average Price'], label='Actual', color='blue')\n",
    "    plt.plot(df['Date'], df['Predicted'], label='Predicted', color='red', linestyle='dashed')\n",
    "    plt.plot(df['Date'], df['MA_7'], label='MA 7', color='orange')\n",
    "    plt.plot(df['Date'], df['MA_30'], label='MA 30', color='green')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Average Price')\n",
    "    plt.title(f'Price Prediction (TAT-MQA) - {file}')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    graph_file = os.path.join(output_graphs, file.replace(\".csv\", \"_tat_mqa_graph.png\"))\n",
    "    plt.savefig(graph_file, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# -----------------------------\n",
    "# Save all metrics\n",
    "# -----------------------------\n",
    "metrics_df = pd.DataFrame(metrics_list, columns=['District', 'MAE', 'RMSE', 'R2', 'MAPE(%)', 'Accuracy(%)'])\n",
    "metrics_df.to_csv(metrics_file, index=False)\n",
    "print(f\"📊 Metrics saved to {metrics_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caed529d-ef14-49c2-aecd-c025f3cfb73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TAT + GQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b73728d-7e32-49f1-878e-0540aef896d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Processing: onion_Bagalkot_daily.csv\n",
      "Epoch 1/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 0.1170 - mae: 0.1838 - val_loss: 0.0042 - val_mae: 0.0567\n",
      "Epoch 2/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0093 - mae: 0.0705 - val_loss: 0.0023 - val_mae: 0.0392\n",
      "Epoch 3/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0061 - mae: 0.0582 - val_loss: 0.0035 - val_mae: 0.0397\n",
      "Epoch 4/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0044 - mae: 0.0475 - val_loss: 0.0017 - val_mae: 0.0279\n",
      "Epoch 5/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0036 - mae: 0.0412 - val_loss: 0.0021 - val_mae: 0.0357\n",
      "Epoch 6/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0026 - mae: 0.0357 - val_loss: 0.0017 - val_mae: 0.0289\n",
      "Epoch 7/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0027 - mae: 0.0354 - val_loss: 0.0020 - val_mae: 0.0350\n",
      "Epoch 8/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0023 - mae: 0.0337 - val_loss: 0.0028 - val_mae: 0.0413\n",
      "Epoch 9/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0022 - mae: 0.0328 - val_loss: 0.0020 - val_mae: 0.0283\n",
      "Epoch 10/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0021 - mae: 0.0310 - val_loss: 0.0027 - val_mae: 0.0424\n",
      "Epoch 11/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0022 - mae: 0.0335 - val_loss: 0.0014 - val_mae: 0.0244\n",
      "Epoch 12/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0018 - mae: 0.0291 - val_loss: 0.0029 - val_mae: 0.0448\n",
      "Epoch 13/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0018 - mae: 0.0289 - val_loss: 0.0014 - val_mae: 0.0231\n",
      "Epoch 14/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0018 - mae: 0.0285 - val_loss: 0.0015 - val_mae: 0.0263\n",
      "Epoch 15/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0018 - mae: 0.0283 - val_loss: 0.0013 - val_mae: 0.0233\n",
      "Epoch 16/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0017 - mae: 0.0267 - val_loss: 0.0020 - val_mae: 0.0324\n",
      "Epoch 17/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0017 - mae: 0.0282 - val_loss: 0.0013 - val_mae: 0.0223\n",
      "Epoch 18/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0018 - mae: 0.0291 - val_loss: 0.0014 - val_mae: 0.0234\n",
      "Epoch 19/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0018 - mae: 0.0284 - val_loss: 0.0013 - val_mae: 0.0227\n",
      "Epoch 20/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0018 - mae: 0.0292 - val_loss: 0.0014 - val_mae: 0.0229\n",
      "Epoch 21/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0018 - mae: 0.0286 - val_loss: 0.0015 - val_mae: 0.0272\n",
      "Epoch 22/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0016 - mae: 0.0273 - val_loss: 0.0017 - val_mae: 0.0288\n",
      "Epoch 23/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0016 - mae: 0.0275 - val_loss: 0.0013 - val_mae: 0.0233\n",
      "Epoch 24/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0018 - mae: 0.0291 - val_loss: 0.0018 - val_mae: 0.0321\n",
      "Epoch 25/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0018 - mae: 0.0282 - val_loss: 0.0023 - val_mae: 0.0373\n",
      "Epoch 26/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0016 - mae: 0.0270 - val_loss: 0.0015 - val_mae: 0.0253\n",
      "Epoch 27/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0015 - mae: 0.0258 - val_loss: 0.0015 - val_mae: 0.0258\n",
      "Epoch 28/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0015 - mae: 0.0260 - val_loss: 0.0014 - val_mae: 0.0233\n",
      "Epoch 29/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0016 - mae: 0.0267 - val_loss: 0.0031 - val_mae: 0.0439\n",
      "Epoch 30/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0018 - mae: 0.0288 - val_loss: 0.0015 - val_mae: 0.0249\n",
      "Epoch 31/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0015 - mae: 0.0264 - val_loss: 0.0017 - val_mae: 0.0278\n",
      "Epoch 32/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0016 - mae: 0.0265 - val_loss: 0.0014 - val_mae: 0.0259\n",
      "Epoch 33/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 0.0014 - val_mae: 0.0234\n",
      "Epoch 34/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0016 - mae: 0.0266 - val_loss: 0.0015 - val_mae: 0.0257\n",
      "Epoch 35/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0014 - mae: 0.0249 - val_loss: 0.0019 - val_mae: 0.0331\n",
      "Epoch 36/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0016 - mae: 0.0278 - val_loss: 0.0014 - val_mae: 0.0223\n",
      "Epoch 37/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0016 - mae: 0.0267 - val_loss: 0.0014 - val_mae: 0.0230\n",
      "Epoch 38/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0015 - mae: 0.0249 - val_loss: 0.0015 - val_mae: 0.0251\n",
      "Epoch 39/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0014 - val_mae: 0.0226\n",
      "Epoch 40/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0014 - mae: 0.0246 - val_loss: 0.0017 - val_mae: 0.0307\n",
      "Epoch 41/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0015 - mae: 0.0260 - val_loss: 0.0014 - val_mae: 0.0238\n",
      "Epoch 42/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0015 - val_mae: 0.0238\n",
      "Epoch 43/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0015 - mae: 0.0261 - val_loss: 0.0014 - val_mae: 0.0247\n",
      "Epoch 44/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0016 - mae: 0.0260 - val_loss: 0.0014 - val_mae: 0.0228\n",
      "Epoch 45/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0015 - mae: 0.0248 - val_loss: 0.0015 - val_mae: 0.0256\n",
      "Epoch 46/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0015 - val_mae: 0.0264\n",
      "Epoch 47/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0013 - mae: 0.0244 - val_loss: 0.0015 - val_mae: 0.0235\n",
      "Epoch 48/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0015 - mae: 0.0253 - val_loss: 0.0017 - val_mae: 0.0281\n",
      "Epoch 49/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0014 - mae: 0.0244 - val_loss: 0.0015 - val_mae: 0.0242\n",
      "Epoch 50/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0014 - mae: 0.0250 - val_loss: 0.0016 - val_mae: 0.0266\n",
      "Epoch 51/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0014 - val_mae: 0.0226\n",
      "Epoch 52/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0013 - mae: 0.0241 - val_loss: 0.0017 - val_mae: 0.0309\n",
      "Epoch 53/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0014 - val_mae: 0.0223\n",
      "Epoch 54/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0014 - mae: 0.0241 - val_loss: 0.0016 - val_mae: 0.0286\n",
      "Epoch 55/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0017 - val_mae: 0.0293\n",
      "Epoch 56/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0014 - mae: 0.0251 - val_loss: 0.0015 - val_mae: 0.0242\n",
      "Epoch 57/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0014 - mae: 0.0247 - val_loss: 0.0017 - val_mae: 0.0266\n",
      "Epoch 58/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0015 - val_mae: 0.0242\n",
      "Epoch 59/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0013 - mae: 0.0240 - val_loss: 0.0016 - val_mae: 0.0263\n",
      "Epoch 60/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0014 - mae: 0.0245 - val_loss: 0.0017 - val_mae: 0.0296\n",
      "Epoch 61/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0013 - mae: 0.0241 - val_loss: 0.0014 - val_mae: 0.0233\n",
      "Epoch 62/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0013 - mae: 0.0242 - val_loss: 0.0016 - val_mae: 0.0236\n",
      "Epoch 63/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0013 - mae: 0.0238 - val_loss: 0.0017 - val_mae: 0.0247\n",
      "Epoch 64/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0015 - mae: 0.0250 - val_loss: 0.0014 - val_mae: 0.0228\n",
      "Epoch 65/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0014 - mae: 0.0244 - val_loss: 0.0014 - val_mae: 0.0224\n",
      "Epoch 66/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0013 - mae: 0.0237 - val_loss: 0.0018 - val_mae: 0.0277\n",
      "Epoch 67/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0015 - mae: 0.0248 - val_loss: 0.0015 - val_mae: 0.0232\n",
      "Epoch 68/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0014 - mae: 0.0245 - val_loss: 0.0017 - val_mae: 0.0306\n",
      "Epoch 69/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0014 - mae: 0.0250 - val_loss: 0.0016 - val_mae: 0.0238\n",
      "Epoch 70/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0014 - mae: 0.0247 - val_loss: 0.0014 - val_mae: 0.0228\n",
      "Epoch 71/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0014 - mae: 0.0247 - val_loss: 0.0014 - val_mae: 0.0233\n",
      "Epoch 72/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0013 - mae: 0.0244 - val_loss: 0.0020 - val_mae: 0.0262\n",
      "Epoch 73/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0243 - val_loss: 0.0015 - val_mae: 0.0254\n",
      "Epoch 74/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0014 - mae: 0.0244 - val_loss: 0.0016 - val_mae: 0.0234\n",
      "Epoch 75/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0014 - mae: 0.0240 - val_loss: 0.0020 - val_mae: 0.0264\n",
      "Epoch 76/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0013 - mae: 0.0237 - val_loss: 0.0015 - val_mae: 0.0231\n",
      "Epoch 77/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0014 - mae: 0.0241 - val_loss: 0.0020 - val_mae: 0.0316\n",
      "Epoch 78/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0015 - mae: 0.0250 - val_loss: 0.0017 - val_mae: 0.0281\n",
      "Epoch 79/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0013 - mae: 0.0238 - val_loss: 0.0014 - val_mae: 0.0224\n",
      "Epoch 80/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0014 - mae: 0.0240 - val_loss: 0.0016 - val_mae: 0.0245\n",
      "Epoch 81/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0013 - mae: 0.0241 - val_loss: 0.0015 - val_mae: 0.0225\n",
      "Epoch 82/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0014 - mae: 0.0243 - val_loss: 0.0017 - val_mae: 0.0249\n",
      "Epoch 83/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0014 - mae: 0.0242 - val_loss: 0.0014 - val_mae: 0.0228\n",
      "Epoch 84/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0014 - mae: 0.0242 - val_loss: 0.0014 - val_mae: 0.0236\n",
      "Epoch 85/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0014 - mae: 0.0245 - val_loss: 0.0016 - val_mae: 0.0250\n",
      "Epoch 86/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0014 - mae: 0.0245 - val_loss: 0.0015 - val_mae: 0.0237\n",
      "Epoch 87/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0015 - mae: 0.0243 - val_loss: 0.0017 - val_mae: 0.0234\n",
      "Epoch 88/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0014 - mae: 0.0245 - val_loss: 0.0016 - val_mae: 0.0260\n",
      "Epoch 89/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0014 - mae: 0.0245 - val_loss: 0.0014 - val_mae: 0.0228\n",
      "Epoch 90/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0014 - mae: 0.0246 - val_loss: 0.0016 - val_mae: 0.0255\n",
      "Epoch 91/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0015 - mae: 0.0248 - val_loss: 0.0016 - val_mae: 0.0237\n",
      "Epoch 92/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0013 - mae: 0.0238 - val_loss: 0.0015 - val_mae: 0.0225\n",
      "Epoch 93/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0014 - mae: 0.0245 - val_loss: 0.0015 - val_mae: 0.0228\n",
      "Epoch 94/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0014 - mae: 0.0241 - val_loss: 0.0015 - val_mae: 0.0227\n",
      "Epoch 95/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0014 - mae: 0.0239 - val_loss: 0.0015 - val_mae: 0.0231\n",
      "Epoch 96/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0014 - mae: 0.0240 - val_loss: 0.0014 - val_mae: 0.0229\n",
      "Epoch 97/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0014 - mae: 0.0242 - val_loss: 0.0016 - val_mae: 0.0236\n",
      "Epoch 98/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0013 - mae: 0.0232 - val_loss: 0.0015 - val_mae: 0.0225\n",
      "Epoch 99/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0013 - mae: 0.0241 - val_loss: 0.0015 - val_mae: 0.0236\n",
      "Epoch 100/100\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0013 - mae: 0.0237 - val_loss: 0.0018 - val_mae: 0.0249\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "✅ Done: onion_Bagalkot_daily.csv | MAE=190.31, RMSE=308.9, R2=0.84, MAPE=18.18%, Accuracy=81.82%\n",
      "🚀 Processing: onion_Bangalore_daily.csv\n",
      "Epoch 1/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - loss: 0.0930 - mae: 0.1564 - val_loss: 0.0048 - val_mae: 0.0466\n",
      "Epoch 2/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0043 - mae: 0.0478 - val_loss: 0.0032 - val_mae: 0.0372\n",
      "Epoch 3/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0031 - mae: 0.0400 - val_loss: 0.0026 - val_mae: 0.0386\n",
      "Epoch 4/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0028 - mae: 0.0370 - val_loss: 0.0029 - val_mae: 0.0360\n",
      "Epoch 5/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0029 - mae: 0.0365 - val_loss: 0.0026 - val_mae: 0.0377\n",
      "Epoch 6/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0027 - mae: 0.0362 - val_loss: 0.0030 - val_mae: 0.0442\n",
      "Epoch 7/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0024 - mae: 0.0343 - val_loss: 0.0023 - val_mae: 0.0328\n",
      "Epoch 8/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0024 - mae: 0.0341 - val_loss: 0.0026 - val_mae: 0.0371\n",
      "Epoch 9/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0025 - mae: 0.0346 - val_loss: 0.0022 - val_mae: 0.0324\n",
      "Epoch 10/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0025 - mae: 0.0334 - val_loss: 0.0020 - val_mae: 0.0315\n",
      "Epoch 11/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0024 - mae: 0.0333 - val_loss: 0.0021 - val_mae: 0.0336\n",
      "Epoch 12/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0023 - mae: 0.0331 - val_loss: 0.0020 - val_mae: 0.0325\n",
      "Epoch 13/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0023 - mae: 0.0328 - val_loss: 0.0021 - val_mae: 0.0339\n",
      "Epoch 14/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0024 - mae: 0.0335 - val_loss: 0.0019 - val_mae: 0.0312\n",
      "Epoch 15/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0024 - mae: 0.0333 - val_loss: 0.0021 - val_mae: 0.0332\n",
      "Epoch 16/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0025 - mae: 0.0329 - val_loss: 0.0021 - val_mae: 0.0331\n",
      "Epoch 17/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - loss: 0.0022 - mae: 0.0325 - val_loss: 0.0021 - val_mae: 0.0335\n",
      "Epoch 18/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0023 - mae: 0.0326 - val_loss: 0.0021 - val_mae: 0.0336\n",
      "Epoch 19/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - loss: 0.0024 - mae: 0.0328 - val_loss: 0.0022 - val_mae: 0.0326\n",
      "Epoch 20/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - loss: 0.0023 - mae: 0.0321 - val_loss: 0.0019 - val_mae: 0.0313\n",
      "Epoch 21/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - loss: 0.0023 - mae: 0.0326 - val_loss: 0.0019 - val_mae: 0.0318\n",
      "Epoch 22/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - loss: 0.0023 - mae: 0.0328 - val_loss: 0.0023 - val_mae: 0.0345\n",
      "Epoch 23/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - loss: 0.0023 - mae: 0.0324 - val_loss: 0.0020 - val_mae: 0.0319\n",
      "Epoch 24/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - loss: 0.0023 - mae: 0.0322 - val_loss: 0.0023 - val_mae: 0.0352\n",
      "Epoch 25/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - loss: 0.0024 - mae: 0.0324 - val_loss: 0.0020 - val_mae: 0.0314\n",
      "Epoch 26/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - loss: 0.0023 - mae: 0.0320 - val_loss: 0.0020 - val_mae: 0.0317\n",
      "Epoch 27/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - loss: 0.0024 - mae: 0.0323 - val_loss: 0.0022 - val_mae: 0.0339\n",
      "Epoch 28/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - loss: 0.0023 - mae: 0.0319 - val_loss: 0.0020 - val_mae: 0.0324\n",
      "Epoch 29/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - loss: 0.0024 - mae: 0.0324 - val_loss: 0.0023 - val_mae: 0.0355\n",
      "Epoch 30/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - loss: 0.0022 - mae: 0.0321 - val_loss: 0.0020 - val_mae: 0.0325\n",
      "Epoch 31/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - loss: 0.0023 - mae: 0.0321 - val_loss: 0.0022 - val_mae: 0.0341\n",
      "Epoch 32/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0022 - mae: 0.0317 - val_loss: 0.0021 - val_mae: 0.0317\n",
      "Epoch 33/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - loss: 0.0022 - mae: 0.0317 - val_loss: 0.0020 - val_mae: 0.0315\n",
      "Epoch 34/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - loss: 0.0021 - mae: 0.0316 - val_loss: 0.0024 - val_mae: 0.0344\n",
      "Epoch 35/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0025 - mae: 0.0323 - val_loss: 0.0020 - val_mae: 0.0318\n",
      "Epoch 36/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0022 - mae: 0.0314 - val_loss: 0.0020 - val_mae: 0.0319\n",
      "Epoch 37/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0023 - mae: 0.0317 - val_loss: 0.0020 - val_mae: 0.0318\n",
      "Epoch 38/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0024 - mae: 0.0320 - val_loss: 0.0022 - val_mae: 0.0335\n",
      "Epoch 39/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - loss: 0.0023 - mae: 0.0317 - val_loss: 0.0022 - val_mae: 0.0329\n",
      "Epoch 40/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - loss: 0.0023 - mae: 0.0322 - val_loss: 0.0022 - val_mae: 0.0327\n",
      "Epoch 41/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - loss: 0.0023 - mae: 0.0321 - val_loss: 0.0026 - val_mae: 0.0356\n",
      "Epoch 42/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0022 - mae: 0.0316 - val_loss: 0.0023 - val_mae: 0.0334\n",
      "Epoch 43/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - loss: 0.0023 - mae: 0.0319 - val_loss: 0.0023 - val_mae: 0.0329\n",
      "Epoch 44/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0022 - mae: 0.0313 - val_loss: 0.0025 - val_mae: 0.0345\n",
      "Epoch 45/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0022 - mae: 0.0319 - val_loss: 0.0023 - val_mae: 0.0326\n",
      "Epoch 46/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0021 - mae: 0.0312 - val_loss: 0.0023 - val_mae: 0.0326\n",
      "Epoch 47/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - loss: 0.0022 - mae: 0.0315 - val_loss: 0.0024 - val_mae: 0.0342\n",
      "Epoch 48/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - loss: 0.0023 - mae: 0.0321 - val_loss: 0.0024 - val_mae: 0.0330\n",
      "Epoch 49/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0022 - mae: 0.0316 - val_loss: 0.0025 - val_mae: 0.0347\n",
      "Epoch 50/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0023 - mae: 0.0322 - val_loss: 0.0023 - val_mae: 0.0329\n",
      "Epoch 51/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - loss: 0.0023 - mae: 0.0321 - val_loss: 0.0023 - val_mae: 0.0328\n",
      "Epoch 52/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - loss: 0.0022 - mae: 0.0318 - val_loss: 0.0025 - val_mae: 0.0350\n",
      "Epoch 53/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0021 - mae: 0.0318 - val_loss: 0.0024 - val_mae: 0.0333\n",
      "Epoch 54/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0022 - mae: 0.0320 - val_loss: 0.0026 - val_mae: 0.0355\n",
      "Epoch 55/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - loss: 0.0022 - mae: 0.0315 - val_loss: 0.0024 - val_mae: 0.0331\n",
      "Epoch 56/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0022 - mae: 0.0316 - val_loss: 0.0023 - val_mae: 0.0328\n",
      "Epoch 57/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0023 - mae: 0.0316 - val_loss: 0.0025 - val_mae: 0.0341\n",
      "Epoch 58/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0024 - mae: 0.0319 - val_loss: 0.0024 - val_mae: 0.0330\n",
      "Epoch 59/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0023 - mae: 0.0322 - val_loss: 0.0031 - val_mae: 0.0375\n",
      "Epoch 60/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - loss: 0.0024 - mae: 0.0324 - val_loss: 0.0025 - val_mae: 0.0344\n",
      "Epoch 61/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0022 - mae: 0.0314 - val_loss: 0.0025 - val_mae: 0.0348\n",
      "Epoch 62/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0023 - mae: 0.0321 - val_loss: 0.0023 - val_mae: 0.0324\n",
      "Epoch 63/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0023 - mae: 0.0320 - val_loss: 0.0025 - val_mae: 0.0334\n",
      "Epoch 64/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0022 - mae: 0.0320 - val_loss: 0.0023 - val_mae: 0.0328\n",
      "Epoch 65/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - loss: 0.0022 - mae: 0.0316 - val_loss: 0.0024 - val_mae: 0.0335\n",
      "Epoch 66/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0021 - mae: 0.0312 - val_loss: 0.0024 - val_mae: 0.0335\n",
      "Epoch 67/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0023 - mae: 0.0320 - val_loss: 0.0025 - val_mae: 0.0345\n",
      "Epoch 68/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - loss: 0.0023 - mae: 0.0320 - val_loss: 0.0024 - val_mae: 0.0332\n",
      "Epoch 69/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0021 - mae: 0.0313 - val_loss: 0.0023 - val_mae: 0.0328\n",
      "Epoch 70/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - loss: 0.0022 - mae: 0.0317 - val_loss: 0.0026 - val_mae: 0.0342\n",
      "Epoch 71/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0022 - mae: 0.0317 - val_loss: 0.0025 - val_mae: 0.0344\n",
      "Epoch 72/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0023 - mae: 0.0318 - val_loss: 0.0023 - val_mae: 0.0328\n",
      "Epoch 73/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0023 - mae: 0.0320 - val_loss: 0.0024 - val_mae: 0.0341\n",
      "Epoch 74/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0023 - mae: 0.0319 - val_loss: 0.0029 - val_mae: 0.0374\n",
      "Epoch 75/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0023 - mae: 0.0321 - val_loss: 0.0025 - val_mae: 0.0343\n",
      "Epoch 76/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0022 - mae: 0.0318 - val_loss: 0.0024 - val_mae: 0.0335\n",
      "Epoch 77/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0022 - mae: 0.0316 - val_loss: 0.0027 - val_mae: 0.0352\n",
      "Epoch 78/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0024 - mae: 0.0324 - val_loss: 0.0023 - val_mae: 0.0328\n",
      "Epoch 79/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0022 - mae: 0.0316 - val_loss: 0.0025 - val_mae: 0.0344\n",
      "Epoch 80/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0023 - mae: 0.0318 - val_loss: 0.0024 - val_mae: 0.0329\n",
      "Epoch 81/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0024 - mae: 0.0321 - val_loss: 0.0023 - val_mae: 0.0330\n",
      "Epoch 82/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0022 - mae: 0.0319 - val_loss: 0.0025 - val_mae: 0.0341\n",
      "Epoch 83/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0021 - mae: 0.0312 - val_loss: 0.0026 - val_mae: 0.0361\n",
      "Epoch 84/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0022 - mae: 0.0315 - val_loss: 0.0027 - val_mae: 0.0353\n",
      "Epoch 85/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0021 - mae: 0.0315 - val_loss: 0.0024 - val_mae: 0.0329\n",
      "Epoch 86/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - loss: 0.0023 - mae: 0.0319 - val_loss: 0.0024 - val_mae: 0.0341\n",
      "Epoch 87/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0022 - mae: 0.0317 - val_loss: 0.0026 - val_mae: 0.0355\n",
      "Epoch 88/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0022 - mae: 0.0317 - val_loss: 0.0026 - val_mae: 0.0350\n",
      "Epoch 89/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0022 - mae: 0.0311 - val_loss: 0.0030 - val_mae: 0.0374\n",
      "Epoch 90/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0021 - mae: 0.0311 - val_loss: 0.0023 - val_mae: 0.0327\n",
      "Epoch 91/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0022 - mae: 0.0313 - val_loss: 0.0026 - val_mae: 0.0361\n",
      "Epoch 92/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0023 - mae: 0.0317 - val_loss: 0.0024 - val_mae: 0.0334\n",
      "Epoch 93/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0021 - mae: 0.0311 - val_loss: 0.0025 - val_mae: 0.0341\n",
      "Epoch 94/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0021 - mae: 0.0309 - val_loss: 0.0027 - val_mae: 0.0356\n",
      "Epoch 95/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - loss: 0.0023 - mae: 0.0319 - val_loss: 0.0024 - val_mae: 0.0332\n",
      "Epoch 96/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0023 - mae: 0.0320 - val_loss: 0.0024 - val_mae: 0.0338\n",
      "Epoch 97/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0023 - mae: 0.0321 - val_loss: 0.0024 - val_mae: 0.0340\n",
      "Epoch 98/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0021 - mae: 0.0313 - val_loss: 0.0023 - val_mae: 0.0329\n",
      "Epoch 99/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0022 - mae: 0.0314 - val_loss: 0.0025 - val_mae: 0.0345\n",
      "Epoch 100/100\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0023 - mae: 0.0316 - val_loss: 0.0024 - val_mae: 0.0329\n",
      "\u001b[1m561/561\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step\n",
      "✅ Done: onion_Bangalore_daily.csv | MAE=383.46, RMSE=575.14, R2=0.68, MAPE=25.3%, Accuracy=74.7%\n",
      "🚀 Processing: onion_Belgaum_daily.csv\n",
      "Epoch 1/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.2422 - mae: 0.2215 - val_loss: 0.0020 - val_mae: 0.0285\n",
      "Epoch 2/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0082 - mae: 0.0665 - val_loss: 0.0037 - val_mae: 0.0564\n",
      "Epoch 3/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0048 - mae: 0.0491 - val_loss: 0.0016 - val_mae: 0.0252\n",
      "Epoch 4/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0039 - mae: 0.0436 - val_loss: 0.0017 - val_mae: 0.0284\n",
      "Epoch 5/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0028 - mae: 0.0370 - val_loss: 0.0019 - val_mae: 0.0288\n",
      "Epoch 6/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0023 - mae: 0.0331 - val_loss: 0.0014 - val_mae: 0.0251\n",
      "Epoch 7/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0021 - mae: 0.0313 - val_loss: 0.0016 - val_mae: 0.0266\n",
      "Epoch 8/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0019 - mae: 0.0298 - val_loss: 0.0023 - val_mae: 0.0357\n",
      "Epoch 9/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0017 - mae: 0.0273 - val_loss: 0.0013 - val_mae: 0.0237\n",
      "Epoch 10/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0016 - mae: 0.0272 - val_loss: 0.0014 - val_mae: 0.0279\n",
      "Epoch 11/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0017 - mae: 0.0271 - val_loss: 0.0020 - val_mae: 0.0300\n",
      "Epoch 12/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0014 - mae: 0.0240 - val_loss: 0.0017 - val_mae: 0.0325\n",
      "Epoch 13/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0014 - val_mae: 0.0253\n",
      "Epoch 14/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0016 - mae: 0.0266 - val_loss: 0.0017 - val_mae: 0.0308\n",
      "Epoch 15/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0016 - mae: 0.0255 - val_loss: 0.0014 - val_mae: 0.0250\n",
      "Epoch 16/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0014 - mae: 0.0242 - val_loss: 0.0013 - val_mae: 0.0246\n",
      "Epoch 17/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0014 - mae: 0.0242 - val_loss: 0.0013 - val_mae: 0.0236\n",
      "Epoch 18/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0016 - mae: 0.0258 - val_loss: 0.0012 - val_mae: 0.0233\n",
      "Epoch 19/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0014 - mae: 0.0239 - val_loss: 0.0014 - val_mae: 0.0266\n",
      "Epoch 20/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0012 - val_mae: 0.0233\n",
      "Epoch 21/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0013 - mae: 0.0234 - val_loss: 0.0016 - val_mae: 0.0323\n",
      "Epoch 22/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0252 - val_loss: 0.0016 - val_mae: 0.0276\n",
      "Epoch 23/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0014 - mae: 0.0250 - val_loss: 0.0013 - val_mae: 0.0258\n",
      "Epoch 24/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0014 - mae: 0.0231 - val_loss: 0.0020 - val_mae: 0.0327\n",
      "Epoch 25/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0014 - mae: 0.0240 - val_loss: 0.0013 - val_mae: 0.0239\n",
      "Epoch 26/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0016 - mae: 0.0262 - val_loss: 0.0013 - val_mae: 0.0242\n",
      "Epoch 27/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0016 - mae: 0.0255 - val_loss: 0.0012 - val_mae: 0.0232\n",
      "Epoch 28/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0017 - mae: 0.0261 - val_loss: 0.0014 - val_mae: 0.0253\n",
      "Epoch 29/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0016 - mae: 0.0254 - val_loss: 0.0012 - val_mae: 0.0234\n",
      "Epoch 30/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0242 - val_loss: 0.0013 - val_mae: 0.0245\n",
      "Epoch 31/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0014 - mae: 0.0228 - val_loss: 0.0021 - val_mae: 0.0384\n",
      "Epoch 32/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0016 - mae: 0.0258 - val_loss: 0.0013 - val_mae: 0.0234\n",
      "Epoch 33/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0237 - val_loss: 0.0012 - val_mae: 0.0234\n",
      "Epoch 34/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0240 - val_loss: 0.0013 - val_mae: 0.0234\n",
      "Epoch 35/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0241 - val_loss: 0.0014 - val_mae: 0.0277\n",
      "Epoch 36/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0017 - mae: 0.0270 - val_loss: 0.0017 - val_mae: 0.0277\n",
      "Epoch 37/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0014 - mae: 0.0235 - val_loss: 0.0013 - val_mae: 0.0234\n",
      "Epoch 38/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0014 - mae: 0.0241 - val_loss: 0.0017 - val_mae: 0.0340\n",
      "Epoch 39/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0016 - mae: 0.0254 - val_loss: 0.0014 - val_mae: 0.0272\n",
      "Epoch 40/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0014 - mae: 0.0229 - val_loss: 0.0012 - val_mae: 0.0235\n",
      "Epoch 41/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0013 - mae: 0.0223 - val_loss: 0.0012 - val_mae: 0.0236\n",
      "Epoch 42/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0247 - val_loss: 0.0012 - val_mae: 0.0230\n",
      "Epoch 43/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0236 - val_loss: 0.0016 - val_mae: 0.0266\n",
      "Epoch 44/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0014 - mae: 0.0230 - val_loss: 0.0016 - val_mae: 0.0317\n",
      "Epoch 45/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0239 - val_loss: 0.0012 - val_mae: 0.0234\n",
      "Epoch 46/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0220 - val_loss: 0.0013 - val_mae: 0.0249\n",
      "Epoch 47/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0013 - mae: 0.0221 - val_loss: 0.0015 - val_mae: 0.0296\n",
      "Epoch 48/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0014 - mae: 0.0232 - val_loss: 0.0012 - val_mae: 0.0229\n",
      "Epoch 49/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0014 - mae: 0.0227 - val_loss: 0.0014 - val_mae: 0.0263\n",
      "Epoch 50/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0014 - mae: 0.0225 - val_loss: 0.0012 - val_mae: 0.0231\n",
      "Epoch 51/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0235 - val_loss: 0.0013 - val_mae: 0.0252\n",
      "Epoch 52/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0013 - mae: 0.0220 - val_loss: 0.0013 - val_mae: 0.0253\n",
      "Epoch 53/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0014 - mae: 0.0230 - val_loss: 0.0012 - val_mae: 0.0229\n",
      "Epoch 54/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0013 - mae: 0.0220 - val_loss: 0.0012 - val_mae: 0.0245\n",
      "Epoch 55/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0014 - mae: 0.0222 - val_loss: 0.0014 - val_mae: 0.0265\n",
      "Epoch 56/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0014 - mae: 0.0231 - val_loss: 0.0012 - val_mae: 0.0242\n",
      "Epoch 57/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0013 - mae: 0.0215 - val_loss: 0.0012 - val_mae: 0.0239\n",
      "Epoch 58/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0208 - val_loss: 0.0015 - val_mae: 0.0252\n",
      "Epoch 59/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0013 - mae: 0.0214 - val_loss: 0.0012 - val_mae: 0.0237\n",
      "Epoch 60/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0013 - mae: 0.0220 - val_loss: 0.0012 - val_mae: 0.0247\n",
      "Epoch 61/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0012 - mae: 0.0212 - val_loss: 0.0016 - val_mae: 0.0305\n",
      "Epoch 62/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0013 - mae: 0.0218 - val_loss: 0.0017 - val_mae: 0.0305\n",
      "Epoch 63/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0013 - mae: 0.0222 - val_loss: 0.0012 - val_mae: 0.0232\n",
      "Epoch 64/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0011 - mae: 0.0210 - val_loss: 0.0015 - val_mae: 0.0254\n",
      "Epoch 65/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0014 - mae: 0.0220 - val_loss: 0.0017 - val_mae: 0.0305\n",
      "Epoch 66/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0013 - mae: 0.0214 - val_loss: 0.0013 - val_mae: 0.0260\n",
      "Epoch 67/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0014 - mae: 0.0218 - val_loss: 0.0017 - val_mae: 0.0332\n",
      "Epoch 68/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0014 - mae: 0.0229 - val_loss: 0.0014 - val_mae: 0.0247\n",
      "Epoch 69/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0013 - mae: 0.0217 - val_loss: 0.0012 - val_mae: 0.0236\n",
      "Epoch 70/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0013 - mae: 0.0212 - val_loss: 0.0012 - val_mae: 0.0242\n",
      "Epoch 71/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0012 - mae: 0.0212 - val_loss: 0.0012 - val_mae: 0.0235\n",
      "Epoch 72/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0012 - mae: 0.0213 - val_loss: 0.0017 - val_mae: 0.0271\n",
      "Epoch 73/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0013 - mae: 0.0214 - val_loss: 0.0012 - val_mae: 0.0237\n",
      "Epoch 74/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0011 - mae: 0.0202 - val_loss: 0.0013 - val_mae: 0.0258\n",
      "Epoch 75/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0213 - val_loss: 0.0013 - val_mae: 0.0240\n",
      "Epoch 76/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0011 - mae: 0.0207 - val_loss: 0.0015 - val_mae: 0.0257\n",
      "Epoch 77/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0012 - mae: 0.0212 - val_loss: 0.0015 - val_mae: 0.0285\n",
      "Epoch 78/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0012 - mae: 0.0212 - val_loss: 0.0014 - val_mae: 0.0285\n",
      "Epoch 79/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0012 - mae: 0.0212 - val_loss: 0.0013 - val_mae: 0.0252\n",
      "Epoch 80/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0212 - val_loss: 0.0012 - val_mae: 0.0237\n",
      "Epoch 81/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0011 - mae: 0.0202 - val_loss: 0.0015 - val_mae: 0.0288\n",
      "Epoch 82/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0210 - val_loss: 0.0013 - val_mae: 0.0245\n",
      "Epoch 83/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0010 - mae: 0.0203 - val_loss: 0.0013 - val_mae: 0.0251\n",
      "Epoch 84/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0011 - mae: 0.0204 - val_loss: 0.0012 - val_mae: 0.0245\n",
      "Epoch 85/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0208 - val_loss: 0.0012 - val_mae: 0.0228\n",
      "Epoch 86/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0011 - mae: 0.0205 - val_loss: 0.0012 - val_mae: 0.0230\n",
      "Epoch 87/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0207 - val_loss: 0.0013 - val_mae: 0.0259\n",
      "Epoch 88/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0013 - mae: 0.0212 - val_loss: 0.0012 - val_mae: 0.0239\n",
      "Epoch 89/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0208 - val_loss: 0.0014 - val_mae: 0.0247\n",
      "Epoch 90/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0212 - val_loss: 0.0013 - val_mae: 0.0241\n",
      "Epoch 91/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0011 - mae: 0.0201 - val_loss: 0.0012 - val_mae: 0.0240\n",
      "Epoch 92/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0011 - mae: 0.0204 - val_loss: 0.0012 - val_mae: 0.0233\n",
      "Epoch 93/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0011 - mae: 0.0199 - val_loss: 0.0012 - val_mae: 0.0228\n",
      "Epoch 94/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0011 - mae: 0.0206 - val_loss: 0.0013 - val_mae: 0.0234\n",
      "Epoch 95/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0011 - mae: 0.0206 - val_loss: 0.0013 - val_mae: 0.0235\n",
      "Epoch 96/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0212 - val_loss: 0.0012 - val_mae: 0.0244\n",
      "Epoch 97/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0011 - mae: 0.0200 - val_loss: 0.0015 - val_mae: 0.0253\n",
      "Epoch 98/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0011 - mae: 0.0200 - val_loss: 0.0012 - val_mae: 0.0229\n",
      "Epoch 99/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0011 - mae: 0.0202 - val_loss: 0.0013 - val_mae: 0.0237\n",
      "Epoch 100/100\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0011 - mae: 0.0209 - val_loss: 0.0012 - val_mae: 0.0231\n",
      "\u001b[1m201/201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "✅ Done: onion_Belgaum_daily.csv | MAE=232.72, RMSE=375.86, R2=0.86, MAPE=17.73%, Accuracy=82.27%\n",
      "🚀 Processing: onion_Bellary_daily.csv\n",
      "Epoch 1/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 14ms/step - loss: 0.1437 - mae: 0.2119 - val_loss: 0.0015 - val_mae: 0.0339\n",
      "Epoch 2/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0049 - mae: 0.0540 - val_loss: 8.8510e-04 - val_mae: 0.0238\n",
      "Epoch 3/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0033 - mae: 0.0423 - val_loss: 0.0027 - val_mae: 0.0455\n",
      "Epoch 4/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0024 - mae: 0.0353 - val_loss: 0.0025 - val_mae: 0.0445\n",
      "Epoch 5/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0020 - mae: 0.0314 - val_loss: 0.0011 - val_mae: 0.0280\n",
      "Epoch 6/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0015 - mae: 0.0268 - val_loss: 0.0016 - val_mae: 0.0353\n",
      "Epoch 7/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 0.0019 - mae: 0.0280 - val_loss: 8.4802e-04 - val_mae: 0.0223\n",
      "Epoch 8/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0013 - mae: 0.0244 - val_loss: 0.0013 - val_mae: 0.0306\n",
      "Epoch 9/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 0.0014 - mae: 0.0228 - val_loss: 9.4885e-04 - val_mae: 0.0217\n",
      "Epoch 10/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0011 - mae: 0.0221 - val_loss: 0.0011 - val_mae: 0.0239\n",
      "Epoch 11/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 0.0011 - mae: 0.0209 - val_loss: 0.0015 - val_mae: 0.0324\n",
      "Epoch 12/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0013 - mae: 0.0248 - val_loss: 0.0023 - val_mae: 0.0412\n",
      "Epoch 13/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0013 - mae: 0.0226 - val_loss: 0.0013 - val_mae: 0.0306\n",
      "Epoch 14/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0013 - mae: 0.0221 - val_loss: 9.0412e-04 - val_mae: 0.0242\n",
      "Epoch 15/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0013 - mae: 0.0215 - val_loss: 0.0018 - val_mae: 0.0368\n",
      "Epoch 16/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 9.7339e-04 - mae: 0.0205 - val_loss: 0.0022 - val_mae: 0.0399\n",
      "Epoch 17/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0011 - mae: 0.0211 - val_loss: 0.0018 - val_mae: 0.0356\n",
      "Epoch 18/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0014 - mae: 0.0235 - val_loss: 9.3692e-04 - val_mae: 0.0248\n",
      "Epoch 19/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 9.5348e-04 - mae: 0.0196 - val_loss: 8.2873e-04 - val_mae: 0.0198\n",
      "Epoch 20/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 9.6700e-04 - mae: 0.0192 - val_loss: 8.5122e-04 - val_mae: 0.0203\n",
      "Epoch 21/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0011 - mae: 0.0202 - val_loss: 8.5843e-04 - val_mae: 0.0228\n",
      "Epoch 22/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 9.0617e-04 - mae: 0.0196 - val_loss: 8.2960e-04 - val_mae: 0.0198\n",
      "Epoch 23/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0015 - mae: 0.0220 - val_loss: 8.3666e-04 - val_mae: 0.0214\n",
      "Epoch 24/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 9.0619e-04 - mae: 0.0195 - val_loss: 0.0011 - val_mae: 0.0268\n",
      "Epoch 25/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0010 - mae: 0.0187 - val_loss: 0.0016 - val_mae: 0.0335\n",
      "Epoch 26/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0011 - mae: 0.0210 - val_loss: 0.0011 - val_mae: 0.0276\n",
      "Epoch 27/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 9.8202e-04 - mae: 0.0189 - val_loss: 8.3403e-04 - val_mae: 0.0214\n",
      "Epoch 28/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 8.0029e-04 - mae: 0.0182 - val_loss: 9.7527e-04 - val_mae: 0.0233\n",
      "Epoch 29/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 9.6552e-04 - mae: 0.0202 - val_loss: 9.9393e-04 - val_mae: 0.0260\n",
      "Epoch 30/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0011 - mae: 0.0202 - val_loss: 8.5199e-04 - val_mae: 0.0223\n",
      "Epoch 31/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0011 - mae: 0.0199 - val_loss: 8.3470e-04 - val_mae: 0.0211\n",
      "Epoch 32/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 9.8482e-04 - mae: 0.0193 - val_loss: 8.2986e-04 - val_mae: 0.0203\n",
      "Epoch 33/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 9.9559e-04 - mae: 0.0184 - val_loss: 8.9265e-04 - val_mae: 0.0226\n",
      "Epoch 34/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0011 - mae: 0.0191 - val_loss: 9.4799e-04 - val_mae: 0.0246\n",
      "Epoch 35/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 9.6729e-04 - mae: 0.0191 - val_loss: 8.5822e-04 - val_mae: 0.0228\n",
      "Epoch 36/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0011 - mae: 0.0185 - val_loss: 8.6590e-04 - val_mae: 0.0210\n",
      "Epoch 37/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 9.9273e-04 - mae: 0.0177 - val_loss: 8.8988e-04 - val_mae: 0.0239\n",
      "Epoch 38/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0011 - mae: 0.0187 - val_loss: 0.0013 - val_mae: 0.0301\n",
      "Epoch 39/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0011 - mae: 0.0192 - val_loss: 8.8261e-04 - val_mae: 0.0223\n",
      "Epoch 40/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 7.6894e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mae: 0.0258\n",
      "Epoch 41/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 9.5820e-04 - mae: 0.0184 - val_loss: 9.2075e-04 - val_mae: 0.0239\n",
      "Epoch 42/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 9.6281e-04 - mae: 0.0185 - val_loss: 9.8599e-04 - val_mae: 0.0252\n",
      "Epoch 43/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 0.0018 - mae: 0.0197 - val_loss: 8.3163e-04 - val_mae: 0.0207\n",
      "Epoch 44/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 9.2339e-04 - mae: 0.0173 - val_loss: 8.4326e-04 - val_mae: 0.0200\n",
      "Epoch 45/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0012 - mae: 0.0185 - val_loss: 0.0010 - val_mae: 0.0256\n",
      "Epoch 46/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 9.7299e-04 - mae: 0.0188 - val_loss: 8.4781e-04 - val_mae: 0.0203\n",
      "Epoch 47/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 8.9757e-04 - mae: 0.0176 - val_loss: 0.0012 - val_mae: 0.0296\n",
      "Epoch 48/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.0010 - mae: 0.0183 - val_loss: 9.7299e-04 - val_mae: 0.0243\n",
      "Epoch 49/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0017 - mae: 0.0198 - val_loss: 8.5737e-04 - val_mae: 0.0225\n",
      "Epoch 50/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 9.4457e-04 - mae: 0.0171 - val_loss: 9.3973e-04 - val_mae: 0.0244\n",
      "Epoch 51/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 0.0011 - mae: 0.0172 - val_loss: 0.0011 - val_mae: 0.0281\n",
      "Epoch 52/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 8.1657e-04 - mae: 0.0176 - val_loss: 8.3369e-04 - val_mae: 0.0204\n",
      "Epoch 53/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 9.5748e-04 - mae: 0.0183 - val_loss: 9.5205e-04 - val_mae: 0.0245\n",
      "Epoch 54/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 7.2763e-04 - mae: 0.0170 - val_loss: 9.8743e-04 - val_mae: 0.0238\n",
      "Epoch 55/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 7.8286e-04 - mae: 0.0171 - val_loss: 8.6790e-04 - val_mae: 0.0221\n",
      "Epoch 56/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 9.9520e-04 - mae: 0.0170 - val_loss: 0.0019 - val_mae: 0.0356\n",
      "Epoch 57/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 8.8660e-04 - mae: 0.0184 - val_loss: 8.4410e-04 - val_mae: 0.0198\n",
      "Epoch 58/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0011 - mae: 0.0186 - val_loss: 8.7026e-04 - val_mae: 0.0224\n",
      "Epoch 59/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 7.9129e-04 - mae: 0.0169 - val_loss: 0.0010 - val_mae: 0.0246\n",
      "Epoch 60/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 8.3054e-04 - mae: 0.0174 - val_loss: 0.0011 - val_mae: 0.0256\n",
      "Epoch 61/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0013 - mae: 0.0179 - val_loss: 9.0037e-04 - val_mae: 0.0235\n",
      "Epoch 62/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 7.1287e-04 - mae: 0.0170 - val_loss: 8.4953e-04 - val_mae: 0.0218\n",
      "Epoch 63/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 0.0010 - mae: 0.0177 - val_loss: 8.4942e-04 - val_mae: 0.0223\n",
      "Epoch 64/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 8.8666e-04 - mae: 0.0173 - val_loss: 9.2477e-04 - val_mae: 0.0233\n",
      "Epoch 65/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0013 - mae: 0.0182 - val_loss: 0.0011 - val_mae: 0.0267\n",
      "Epoch 66/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 8.0208e-04 - mae: 0.0169 - val_loss: 8.8445e-04 - val_mae: 0.0234\n",
      "Epoch 67/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 8.9308e-04 - mae: 0.0173 - val_loss: 8.3966e-04 - val_mae: 0.0206\n",
      "Epoch 68/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.0011 - mae: 0.0172 - val_loss: 8.4589e-04 - val_mae: 0.0210\n",
      "Epoch 69/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0010 - mae: 0.0181 - val_loss: 8.4234e-04 - val_mae: 0.0219\n",
      "Epoch 70/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0011 - mae: 0.0179 - val_loss: 0.0010 - val_mae: 0.0236\n",
      "Epoch 71/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 0.0011 - mae: 0.0177 - val_loss: 8.3281e-04 - val_mae: 0.0209\n",
      "Epoch 72/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 8.9344e-04 - mae: 0.0169 - val_loss: 0.0011 - val_mae: 0.0262\n",
      "Epoch 73/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 9.1638e-04 - mae: 0.0180 - val_loss: 8.7536e-04 - val_mae: 0.0231\n",
      "Epoch 74/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 7.0106e-04 - mae: 0.0165 - val_loss: 0.0012 - val_mae: 0.0279\n",
      "Epoch 75/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 9.1278e-04 - mae: 0.0173 - val_loss: 8.3461e-04 - val_mae: 0.0204\n",
      "Epoch 76/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 9.5437e-04 - mae: 0.0177 - val_loss: 8.4508e-04 - val_mae: 0.0218\n",
      "Epoch 77/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 7.4185e-04 - mae: 0.0167 - val_loss: 8.4899e-04 - val_mae: 0.0205\n",
      "Epoch 78/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 8.6769e-04 - mae: 0.0169 - val_loss: 8.5836e-04 - val_mae: 0.0204\n",
      "Epoch 79/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - loss: 8.8442e-04 - mae: 0.0174 - val_loss: 8.4507e-04 - val_mae: 0.0220\n",
      "Epoch 80/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - loss: 0.0012 - mae: 0.0184 - val_loss: 9.9151e-04 - val_mae: 0.0250\n",
      "Epoch 81/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - loss: 7.6569e-04 - mae: 0.0171 - val_loss: 0.0011 - val_mae: 0.0246\n",
      "Epoch 82/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - loss: 0.0011 - mae: 0.0168 - val_loss: 8.3623e-04 - val_mae: 0.0208\n",
      "Epoch 83/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - loss: 0.0012 - mae: 0.0181 - val_loss: 8.3289e-04 - val_mae: 0.0208\n",
      "Epoch 84/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - loss: 9.5621e-04 - mae: 0.0171 - val_loss: 8.4479e-04 - val_mae: 0.0205\n",
      "Epoch 85/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - loss: 9.8638e-04 - mae: 0.0174 - val_loss: 8.3881e-04 - val_mae: 0.0200\n",
      "Epoch 86/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - loss: 7.2563e-04 - mae: 0.0165 - val_loss: 0.0010 - val_mae: 0.0242\n",
      "Epoch 87/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - loss: 0.0012 - mae: 0.0181 - val_loss: 9.2117e-04 - val_mae: 0.0222\n",
      "Epoch 88/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - loss: 8.3860e-04 - mae: 0.0170 - val_loss: 8.3621e-04 - val_mae: 0.0213\n",
      "Epoch 89/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - loss: 7.9345e-04 - mae: 0.0168 - val_loss: 8.5440e-04 - val_mae: 0.0218\n",
      "Epoch 90/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - loss: 8.5425e-04 - mae: 0.0175 - val_loss: 8.5274e-04 - val_mae: 0.0206\n",
      "Epoch 91/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - loss: 7.6769e-04 - mae: 0.0167 - val_loss: 9.2276e-04 - val_mae: 0.0223\n",
      "Epoch 92/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - loss: 8.3715e-04 - mae: 0.0170 - val_loss: 9.7942e-04 - val_mae: 0.0246\n",
      "Epoch 93/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - loss: 7.8716e-04 - mae: 0.0169 - val_loss: 8.3346e-04 - val_mae: 0.0207\n",
      "Epoch 94/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 25ms/step - loss: 7.8782e-04 - mae: 0.0168 - val_loss: 8.6107e-04 - val_mae: 0.0223\n",
      "Epoch 95/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - loss: 8.0575e-04 - mae: 0.0166 - val_loss: 8.6738e-04 - val_mae: 0.0211\n",
      "Epoch 96/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - loss: 6.7834e-04 - mae: 0.0159 - val_loss: 8.6620e-04 - val_mae: 0.0217\n",
      "Epoch 97/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - loss: 9.1858e-04 - mae: 0.0174 - val_loss: 8.3251e-04 - val_mae: 0.0205\n",
      "Epoch 98/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - loss: 9.0793e-04 - mae: 0.0171 - val_loss: 9.2353e-04 - val_mae: 0.0243\n",
      "Epoch 99/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - loss: 8.4234e-04 - mae: 0.0172 - val_loss: 9.2395e-04 - val_mae: 0.0236\n",
      "Epoch 100/100\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - loss: 7.9867e-04 - mae: 0.0170 - val_loss: 8.7142e-04 - val_mae: 0.0217\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step\n",
      "✅ Done: onion_Bellary_daily.csv | MAE=197.7, RMSE=335.41, R2=0.69, MAPE=14.64%, Accuracy=85.36%\n",
      "🚀 Processing: onion_Bidar_daily.csv\n",
      "Epoch 1/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - loss: 0.0783 - mae: 0.1694 - val_loss: 0.0077 - val_mae: 0.0324\n",
      "Epoch 2/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 23ms/step - loss: 0.0080 - mae: 0.0692 - val_loss: 0.0099 - val_mae: 0.0565\n",
      "Epoch 3/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 23ms/step - loss: 0.0054 - mae: 0.0576 - val_loss: 0.0063 - val_mae: 0.0271\n",
      "Epoch 4/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.0044 - mae: 0.0514 - val_loss: 0.0065 - val_mae: 0.0248\n",
      "Epoch 5/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.0037 - mae: 0.0481 - val_loss: 0.0060 - val_mae: 0.0245\n",
      "Epoch 6/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 23ms/step - loss: 0.0041 - mae: 0.0480 - val_loss: 0.0056 - val_mae: 0.0435\n",
      "Epoch 7/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.0036 - mae: 0.0472 - val_loss: 0.0052 - val_mae: 0.0223\n",
      "Epoch 8/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.0035 - mae: 0.0452 - val_loss: 0.0051 - val_mae: 0.0207\n",
      "Epoch 9/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.0035 - mae: 0.0459 - val_loss: 0.0050 - val_mae: 0.0202\n",
      "Epoch 10/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.0035 - mae: 0.0461 - val_loss: 0.0046 - val_mae: 0.0189\n",
      "Epoch 11/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.0030 - mae: 0.0438 - val_loss: 0.0039 - val_mae: 0.0298\n",
      "Epoch 12/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.0036 - mae: 0.0451 - val_loss: 0.0039 - val_mae: 0.0233\n",
      "Epoch 13/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.0038 - mae: 0.0456 - val_loss: 0.0057 - val_mae: 0.0430\n",
      "Epoch 14/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.0035 - mae: 0.0451 - val_loss: 0.0035 - val_mae: 0.0335\n",
      "Epoch 15/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - loss: 0.0033 - mae: 0.0441 - val_loss: 0.0040 - val_mae: 0.0284\n",
      "Epoch 16/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.0031 - mae: 0.0438 - val_loss: 0.0030 - val_mae: 0.0335\n",
      "Epoch 17/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.0030 - mae: 0.0436 - val_loss: 0.0034 - val_mae: 0.0418\n",
      "Epoch 18/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.0035 - mae: 0.0450 - val_loss: 0.0034 - val_mae: 0.0271\n",
      "Epoch 19/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.0031 - mae: 0.0434 - val_loss: 0.0036 - val_mae: 0.0261\n",
      "Epoch 20/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 23ms/step - loss: 0.0032 - mae: 0.0431 - val_loss: 0.0029 - val_mae: 0.0143\n",
      "Epoch 21/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - loss: 0.0031 - mae: 0.0432 - val_loss: 0.0028 - val_mae: 0.0260\n",
      "Epoch 22/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.0032 - mae: 0.0435 - val_loss: 0.0027 - val_mae: 0.0285\n",
      "Epoch 23/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.0035 - mae: 0.0446 - val_loss: 0.0028 - val_mae: 0.0328\n",
      "Epoch 24/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.0032 - mae: 0.0429 - val_loss: 0.0026 - val_mae: 0.0130\n",
      "Epoch 25/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.0031 - mae: 0.0425 - val_loss: 0.0025 - val_mae: 0.0139\n",
      "Epoch 26/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.0032 - mae: 0.0440 - val_loss: 0.0037 - val_mae: 0.0342\n",
      "Epoch 27/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.0036 - mae: 0.0446 - val_loss: 0.0029 - val_mae: 0.0172\n",
      "Epoch 28/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.0031 - mae: 0.0439 - val_loss: 0.0028 - val_mae: 0.0294\n",
      "Epoch 29/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.0031 - mae: 0.0428 - val_loss: 0.0031 - val_mae: 0.0201\n",
      "Epoch 30/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.0033 - mae: 0.0429 - val_loss: 0.0027 - val_mae: 0.0171\n",
      "Epoch 31/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.0029 - mae: 0.0420 - val_loss: 0.0036 - val_mae: 0.0471\n",
      "Epoch 32/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 23ms/step - loss: 0.0033 - mae: 0.0433 - val_loss: 0.0030 - val_mae: 0.0290\n",
      "Epoch 33/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.0031 - mae: 0.0431 - val_loss: 0.0032 - val_mae: 0.0364\n",
      "Epoch 34/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.0033 - mae: 0.0429 - val_loss: 0.0030 - val_mae: 0.0222\n",
      "Epoch 35/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.0029 - mae: 0.0423 - val_loss: 0.0027 - val_mae: 0.0292\n",
      "Epoch 36/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.0030 - mae: 0.0424 - val_loss: 0.0027 - val_mae: 0.0335\n",
      "Epoch 37/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.0033 - mae: 0.0438 - val_loss: 0.0028 - val_mae: 0.0337\n",
      "Epoch 38/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.0031 - mae: 0.0427 - val_loss: 0.0025 - val_mae: 0.0239\n",
      "Epoch 39/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.0032 - mae: 0.0434 - val_loss: 0.0035 - val_mae: 0.0435\n",
      "Epoch 40/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.0031 - mae: 0.0430 - val_loss: 0.0025 - val_mae: 0.0138\n",
      "Epoch 41/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 21ms/step - loss: 0.0032 - mae: 0.0429 - val_loss: 0.0028 - val_mae: 0.0146\n",
      "Epoch 42/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.0034 - mae: 0.0434 - val_loss: 0.0033 - val_mae: 0.0375\n",
      "Epoch 43/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.0030 - mae: 0.0430 - val_loss: 0.0029 - val_mae: 0.0156\n",
      "Epoch 44/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.0029 - mae: 0.0419 - val_loss: 0.0027 - val_mae: 0.0138\n",
      "Epoch 45/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.0031 - mae: 0.0427 - val_loss: 0.0026 - val_mae: 0.0127\n",
      "Epoch 46/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.0032 - mae: 0.0436 - val_loss: 0.0027 - val_mae: 0.0218\n",
      "Epoch 47/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.0031 - mae: 0.0430 - val_loss: 0.0028 - val_mae: 0.0159\n",
      "Epoch 48/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.0035 - mae: 0.0439 - val_loss: 0.0032 - val_mae: 0.0243\n",
      "Epoch 49/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.0029 - mae: 0.0423 - val_loss: 0.0032 - val_mae: 0.0409\n",
      "Epoch 50/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.0031 - mae: 0.0423 - val_loss: 0.0031 - val_mae: 0.0320\n",
      "Epoch 51/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.0030 - mae: 0.0424 - val_loss: 0.0028 - val_mae: 0.0218\n",
      "Epoch 52/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.0029 - mae: 0.0423 - val_loss: 0.0034 - val_mae: 0.0396\n",
      "Epoch 53/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.0033 - mae: 0.0433 - val_loss: 0.0035 - val_mae: 0.0229\n",
      "Epoch 54/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.0030 - mae: 0.0428 - val_loss: 0.0028 - val_mae: 0.0333\n",
      "Epoch 55/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.0030 - mae: 0.0419 - val_loss: 0.0028 - val_mae: 0.0233\n",
      "Epoch 56/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.0029 - mae: 0.0417 - val_loss: 0.0027 - val_mae: 0.0230\n",
      "Epoch 57/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.0031 - mae: 0.0422 - val_loss: 0.0030 - val_mae: 0.0187\n",
      "Epoch 58/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.0030 - mae: 0.0421 - val_loss: 0.0030 - val_mae: 0.0166\n",
      "Epoch 59/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.0029 - mae: 0.0429 - val_loss: 0.0026 - val_mae: 0.0269\n",
      "Epoch 60/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.0029 - mae: 0.0417 - val_loss: 0.0028 - val_mae: 0.0136\n",
      "Epoch 61/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.0029 - mae: 0.0418 - val_loss: 0.0036 - val_mae: 0.0453\n",
      "Epoch 62/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.0031 - mae: 0.0426 - val_loss: 0.0030 - val_mae: 0.0271\n",
      "Epoch 63/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - loss: 0.0030 - mae: 0.0418 - val_loss: 0.0029 - val_mae: 0.0246\n",
      "Epoch 64/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.0029 - mae: 0.0409 - val_loss: 0.0030 - val_mae: 0.0169\n",
      "Epoch 65/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.0036 - mae: 0.0431 - val_loss: 0.0030 - val_mae: 0.0177\n",
      "Epoch 66/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - loss: 0.0028 - mae: 0.0409 - val_loss: 0.0031 - val_mae: 0.0310\n",
      "Epoch 67/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 23ms/step - loss: 0.0030 - mae: 0.0419 - val_loss: 0.0036 - val_mae: 0.0191\n",
      "Epoch 68/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.0030 - mae: 0.0426 - val_loss: 0.0030 - val_mae: 0.0223\n",
      "Epoch 69/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 23ms/step - loss: 0.0031 - mae: 0.0425 - val_loss: 0.0035 - val_mae: 0.0432\n",
      "Epoch 70/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.0030 - mae: 0.0422 - val_loss: 0.0027 - val_mae: 0.0198\n",
      "Epoch 71/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.0030 - mae: 0.0417 - val_loss: 0.0032 - val_mae: 0.0365\n",
      "Epoch 72/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 23ms/step - loss: 0.0033 - mae: 0.0420 - val_loss: 0.0032 - val_mae: 0.0130\n",
      "Epoch 73/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.0030 - mae: 0.0416 - val_loss: 0.0030 - val_mae: 0.0219\n",
      "Epoch 74/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.0031 - mae: 0.0421 - val_loss: 0.0033 - val_mae: 0.0281\n",
      "Epoch 75/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - loss: 0.0030 - mae: 0.0413 - val_loss: 0.0033 - val_mae: 0.0289\n",
      "Epoch 76/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.0028 - mae: 0.0408 - val_loss: 0.0031 - val_mae: 0.0260\n",
      "Epoch 77/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 23ms/step - loss: 0.0029 - mae: 0.0410 - val_loss: 0.0033 - val_mae: 0.0377\n",
      "Epoch 78/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.0031 - mae: 0.0424 - val_loss: 0.0030 - val_mae: 0.0267\n",
      "Epoch 79/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 21ms/step - loss: 0.0030 - mae: 0.0421 - val_loss: 0.0032 - val_mae: 0.0300\n",
      "Epoch 80/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.0028 - mae: 0.0413 - val_loss: 0.0043 - val_mae: 0.0543\n",
      "Epoch 81/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.0030 - mae: 0.0415 - val_loss: 0.0029 - val_mae: 0.0216\n",
      "Epoch 82/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - loss: 0.0028 - mae: 0.0413 - val_loss: 0.0031 - val_mae: 0.0280\n",
      "Epoch 83/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.0031 - mae: 0.0409 - val_loss: 0.0033 - val_mae: 0.0138\n",
      "Epoch 84/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.0030 - mae: 0.0422 - val_loss: 0.0034 - val_mae: 0.0362\n",
      "Epoch 85/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.0027 - mae: 0.0404 - val_loss: 0.0032 - val_mae: 0.0293\n",
      "Epoch 86/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.0029 - mae: 0.0418 - val_loss: 0.0033 - val_mae: 0.0328\n",
      "Epoch 87/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.0032 - mae: 0.0423 - val_loss: 0.0035 - val_mae: 0.0155\n",
      "Epoch 88/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.0028 - mae: 0.0409 - val_loss: 0.0034 - val_mae: 0.0289\n",
      "Epoch 89/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.0030 - mae: 0.0417 - val_loss: 0.0039 - val_mae: 0.0328\n",
      "Epoch 90/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.0028 - mae: 0.0414 - val_loss: 0.0036 - val_mae: 0.0298\n",
      "Epoch 91/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.0029 - mae: 0.0410 - val_loss: 0.0038 - val_mae: 0.0360\n",
      "Epoch 92/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.0031 - mae: 0.0418 - val_loss: 0.0038 - val_mae: 0.0398\n",
      "Epoch 93/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - loss: 0.0028 - mae: 0.0409 - val_loss: 0.0037 - val_mae: 0.0345\n",
      "Epoch 94/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.0029 - mae: 0.0404 - val_loss: 0.0034 - val_mae: 0.0247\n",
      "Epoch 95/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.0029 - mae: 0.0408 - val_loss: 0.0045 - val_mae: 0.0435\n",
      "Epoch 96/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 23ms/step - loss: 0.0028 - mae: 0.0408 - val_loss: 0.0039 - val_mae: 0.0169\n",
      "Epoch 97/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.0028 - mae: 0.0407 - val_loss: 0.0040 - val_mae: 0.0362\n",
      "Epoch 98/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - loss: 0.0031 - mae: 0.0417 - val_loss: 0.0044 - val_mae: 0.0295\n",
      "Epoch 99/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.0030 - mae: 0.0414 - val_loss: 0.0045 - val_mae: 0.0185\n",
      "Epoch 100/100\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.0034 - mae: 0.0416 - val_loss: 0.0046 - val_mae: 0.0347\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step\n",
      "✅ Done: onion_Bidar_daily.csv | MAE=164.45, RMSE=228.52, R2=0.68, MAPE=17.21%, Accuracy=82.79%\n",
      "🚀 Processing: onion_Bijapur_daily.csv\n",
      "Epoch 1/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 23ms/step - loss: 0.0664 - mae: 0.1539 - val_loss: 0.0016 - val_mae: 0.0316\n",
      "Epoch 2/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - loss: 0.0049 - mae: 0.0532 - val_loss: 0.0014 - val_mae: 0.0268\n",
      "Epoch 3/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0038 - mae: 0.0469 - val_loss: 0.0016 - val_mae: 0.0308\n",
      "Epoch 4/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0032 - mae: 0.0435 - val_loss: 0.0025 - val_mae: 0.0396\n",
      "Epoch 5/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0034 - mae: 0.0443 - val_loss: 0.0013 - val_mae: 0.0241\n",
      "Epoch 6/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0032 - mae: 0.0435 - val_loss: 0.0017 - val_mae: 0.0334\n",
      "Epoch 7/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0028 - mae: 0.0418 - val_loss: 0.0013 - val_mae: 0.0245\n",
      "Epoch 8/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0026 - mae: 0.0405 - val_loss: 0.0013 - val_mae: 0.0236\n",
      "Epoch 9/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0027 - mae: 0.0411 - val_loss: 0.0033 - val_mae: 0.0519\n",
      "Epoch 10/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0029 - mae: 0.0419 - val_loss: 0.0013 - val_mae: 0.0277\n",
      "Epoch 11/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0028 - mae: 0.0413 - val_loss: 0.0013 - val_mae: 0.0256\n",
      "Epoch 12/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 18ms/step - loss: 0.0026 - mae: 0.0404 - val_loss: 0.0011 - val_mae: 0.0217\n",
      "Epoch 13/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0029 - mae: 0.0422 - val_loss: 0.0013 - val_mae: 0.0268\n",
      "Epoch 14/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0027 - mae: 0.0407 - val_loss: 0.0016 - val_mae: 0.0321\n",
      "Epoch 15/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0028 - mae: 0.0411 - val_loss: 0.0012 - val_mae: 0.0219\n",
      "Epoch 16/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0025 - mae: 0.0397 - val_loss: 0.0017 - val_mae: 0.0285\n",
      "Epoch 17/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0025 - mae: 0.0398 - val_loss: 0.0013 - val_mae: 0.0268\n",
      "Epoch 18/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0026 - mae: 0.0406 - val_loss: 0.0020 - val_mae: 0.0364\n",
      "Epoch 19/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0027 - mae: 0.0406 - val_loss: 0.0013 - val_mae: 0.0237\n",
      "Epoch 20/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0025 - mae: 0.0398 - val_loss: 0.0014 - val_mae: 0.0288\n",
      "Epoch 21/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0028 - mae: 0.0404 - val_loss: 0.0012 - val_mae: 0.0221\n",
      "Epoch 22/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0026 - mae: 0.0398 - val_loss: 0.0014 - val_mae: 0.0240\n",
      "Epoch 23/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0025 - mae: 0.0397 - val_loss: 0.0011 - val_mae: 0.0217\n",
      "Epoch 24/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0025 - mae: 0.0395 - val_loss: 0.0021 - val_mae: 0.0330\n",
      "Epoch 25/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0026 - mae: 0.0402 - val_loss: 0.0012 - val_mae: 0.0225\n",
      "Epoch 26/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0027 - mae: 0.0405 - val_loss: 0.0012 - val_mae: 0.0221\n",
      "Epoch 27/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0025 - mae: 0.0397 - val_loss: 0.0012 - val_mae: 0.0221\n",
      "Epoch 28/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0025 - mae: 0.0399 - val_loss: 0.0014 - val_mae: 0.0244\n",
      "Epoch 29/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0026 - mae: 0.0402 - val_loss: 0.0014 - val_mae: 0.0275\n",
      "Epoch 30/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0027 - mae: 0.0406 - val_loss: 0.0013 - val_mae: 0.0286\n",
      "Epoch 31/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0027 - mae: 0.0407 - val_loss: 0.0014 - val_mae: 0.0246\n",
      "Epoch 32/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0024 - mae: 0.0393 - val_loss: 0.0017 - val_mae: 0.0339\n",
      "Epoch 33/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0025 - mae: 0.0395 - val_loss: 0.0013 - val_mae: 0.0239\n",
      "Epoch 34/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0026 - mae: 0.0402 - val_loss: 0.0012 - val_mae: 0.0227\n",
      "Epoch 35/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0025 - mae: 0.0400 - val_loss: 0.0013 - val_mae: 0.0231\n",
      "Epoch 36/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0025 - mae: 0.0398 - val_loss: 0.0018 - val_mae: 0.0317\n",
      "Epoch 37/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0024 - mae: 0.0391 - val_loss: 0.0012 - val_mae: 0.0225\n",
      "Epoch 38/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0024 - mae: 0.0393 - val_loss: 0.0015 - val_mae: 0.0248\n",
      "Epoch 39/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0027 - mae: 0.0403 - val_loss: 0.0015 - val_mae: 0.0308\n",
      "Epoch 40/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0023 - mae: 0.0389 - val_loss: 0.0015 - val_mae: 0.0298\n",
      "Epoch 41/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0026 - mae: 0.0405 - val_loss: 0.0011 - val_mae: 0.0217\n",
      "Epoch 42/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0024 - mae: 0.0392 - val_loss: 0.0014 - val_mae: 0.0255\n",
      "Epoch 43/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0024 - mae: 0.0395 - val_loss: 0.0012 - val_mae: 0.0235\n",
      "Epoch 44/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0025 - mae: 0.0394 - val_loss: 0.0014 - val_mae: 0.0245\n",
      "Epoch 45/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0023 - mae: 0.0391 - val_loss: 0.0012 - val_mae: 0.0243\n",
      "Epoch 46/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0022 - mae: 0.0385 - val_loss: 0.0013 - val_mae: 0.0255\n",
      "Epoch 47/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - loss: 0.0024 - mae: 0.0394 - val_loss: 0.0013 - val_mae: 0.0241\n",
      "Epoch 48/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0024 - mae: 0.0395 - val_loss: 0.0013 - val_mae: 0.0252\n",
      "Epoch 49/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0024 - mae: 0.0384 - val_loss: 0.0014 - val_mae: 0.0287\n",
      "Epoch 50/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0023 - mae: 0.0387 - val_loss: 0.0017 - val_mae: 0.0267\n",
      "Epoch 51/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0025 - mae: 0.0392 - val_loss: 0.0012 - val_mae: 0.0246\n",
      "Epoch 52/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0024 - mae: 0.0392 - val_loss: 0.0014 - val_mae: 0.0298\n",
      "Epoch 53/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0024 - mae: 0.0391 - val_loss: 0.0016 - val_mae: 0.0268\n",
      "Epoch 54/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0023 - mae: 0.0386 - val_loss: 0.0013 - val_mae: 0.0260\n",
      "Epoch 55/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0025 - mae: 0.0393 - val_loss: 0.0012 - val_mae: 0.0239\n",
      "Epoch 56/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0023 - mae: 0.0394 - val_loss: 0.0011 - val_mae: 0.0221\n",
      "Epoch 57/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0024 - mae: 0.0389 - val_loss: 0.0013 - val_mae: 0.0232\n",
      "Epoch 58/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0024 - mae: 0.0393 - val_loss: 0.0012 - val_mae: 0.0222\n",
      "Epoch 59/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0024 - mae: 0.0391 - val_loss: 0.0011 - val_mae: 0.0219\n",
      "Epoch 60/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0023 - mae: 0.0385 - val_loss: 0.0012 - val_mae: 0.0233\n",
      "Epoch 61/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0023 - mae: 0.0388 - val_loss: 0.0013 - val_mae: 0.0284\n",
      "Epoch 62/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0023 - mae: 0.0386 - val_loss: 0.0015 - val_mae: 0.0256\n",
      "Epoch 63/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0022 - mae: 0.0384 - val_loss: 0.0012 - val_mae: 0.0244\n",
      "Epoch 64/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0023 - mae: 0.0390 - val_loss: 0.0012 - val_mae: 0.0248\n",
      "Epoch 65/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0023 - mae: 0.0391 - val_loss: 0.0012 - val_mae: 0.0266\n",
      "Epoch 66/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0022 - mae: 0.0381 - val_loss: 0.0011 - val_mae: 0.0233\n",
      "Epoch 67/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 0.0024 - mae: 0.0399 - val_loss: 0.0013 - val_mae: 0.0235\n",
      "Epoch 68/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0024 - mae: 0.0390 - val_loss: 0.0014 - val_mae: 0.0254\n",
      "Epoch 69/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0024 - mae: 0.0387 - val_loss: 0.0011 - val_mae: 0.0219\n",
      "Epoch 70/100\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0023 - mae: 0.0391 - val_loss: 0.0013 - val_mae: 0.0286\n",
      "Epoch 71/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 0.0125 - mae: 0.0773 - val_loss: 0.0066 - val_mae: 0.0647\n",
      "Epoch 29/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0126 - mae: 0.0776 - val_loss: 0.0069 - val_mae: 0.0661\n",
      "Epoch 30/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0125 - mae: 0.0773 - val_loss: 0.0064 - val_mae: 0.0630\n",
      "Epoch 31/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0125 - mae: 0.0771 - val_loss: 0.0060 - val_mae: 0.0612\n",
      "Epoch 32/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0126 - mae: 0.0776 - val_loss: 0.0082 - val_mae: 0.0701\n",
      "Epoch 33/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0124 - mae: 0.0767 - val_loss: 0.0058 - val_mae: 0.0596\n",
      "Epoch 34/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0125 - mae: 0.0770 - val_loss: 0.0056 - val_mae: 0.0573\n",
      "Epoch 35/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0128 - mae: 0.0782 - val_loss: 0.0056 - val_mae: 0.0580\n",
      "Epoch 36/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0122 - mae: 0.0761 - val_loss: 0.0059 - val_mae: 0.0602\n",
      "Epoch 37/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0126 - mae: 0.0772 - val_loss: 0.0067 - val_mae: 0.0645\n",
      "Epoch 38/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0124 - mae: 0.0768 - val_loss: 0.0061 - val_mae: 0.0615\n",
      "Epoch 39/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0127 - mae: 0.0780 - val_loss: 0.0064 - val_mae: 0.0636\n",
      "Epoch 40/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0127 - mae: 0.0776 - val_loss: 0.0066 - val_mae: 0.0644\n",
      "Epoch 41/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - loss: 0.0126 - mae: 0.0775 - val_loss: 0.0055 - val_mae: 0.0570\n",
      "Epoch 42/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0127 - mae: 0.0775 - val_loss: 0.0074 - val_mae: 0.0680\n",
      "Epoch 43/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0125 - mae: 0.0772 - val_loss: 0.0064 - val_mae: 0.0623\n",
      "Epoch 44/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0123 - mae: 0.0761 - val_loss: 0.0062 - val_mae: 0.0621\n",
      "Epoch 45/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0125 - mae: 0.0769 - val_loss: 0.0055 - val_mae: 0.0570\n",
      "Epoch 46/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0126 - mae: 0.0769 - val_loss: 0.0065 - val_mae: 0.0640\n",
      "Epoch 47/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0128 - mae: 0.0775 - val_loss: 0.0064 - val_mae: 0.0627\n",
      "Epoch 48/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - loss: 0.0127 - mae: 0.0772 - val_loss: 0.0057 - val_mae: 0.0586\n",
      "Epoch 49/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0126 - mae: 0.0773 - val_loss: 0.0056 - val_mae: 0.0580\n",
      "Epoch 50/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0125 - mae: 0.0771 - val_loss: 0.0065 - val_mae: 0.0638\n",
      "Epoch 51/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0123 - mae: 0.0760 - val_loss: 0.0056 - val_mae: 0.0580\n",
      "Epoch 52/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0124 - mae: 0.0763 - val_loss: 0.0060 - val_mae: 0.0610\n",
      "Epoch 53/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - loss: 0.0128 - mae: 0.0781 - val_loss: 0.0057 - val_mae: 0.0590\n",
      "Epoch 54/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - loss: 0.0126 - mae: 0.0769 - val_loss: 0.0056 - val_mae: 0.0573\n",
      "Epoch 55/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0125 - mae: 0.0769 - val_loss: 0.0057 - val_mae: 0.0586\n",
      "Epoch 56/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0123 - mae: 0.0762 - val_loss: 0.0056 - val_mae: 0.0578\n",
      "Epoch 57/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0128 - mae: 0.0774 - val_loss: 0.0059 - val_mae: 0.0601\n",
      "Epoch 58/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0123 - mae: 0.0760 - val_loss: 0.0057 - val_mae: 0.0593\n",
      "Epoch 59/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0122 - mae: 0.0755 - val_loss: 0.0057 - val_mae: 0.0588\n",
      "Epoch 60/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - loss: 0.0122 - mae: 0.0757 - val_loss: 0.0058 - val_mae: 0.0595\n",
      "Epoch 61/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0124 - mae: 0.0764 - val_loss: 0.0056 - val_mae: 0.0580\n",
      "Epoch 62/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - loss: 0.0126 - mae: 0.0773 - val_loss: 0.0056 - val_mae: 0.0569\n",
      "Epoch 63/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0128 - mae: 0.0774 - val_loss: 0.0066 - val_mae: 0.0650\n",
      "Epoch 64/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - loss: 0.0128 - mae: 0.0780 - val_loss: 0.0057 - val_mae: 0.0585\n",
      "Epoch 65/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0126 - mae: 0.0770 - val_loss: 0.0066 - val_mae: 0.0638\n",
      "Epoch 66/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 0.0127 - mae: 0.0774 - val_loss: 0.0058 - val_mae: 0.0595\n",
      "Epoch 67/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - loss: 0.0122 - mae: 0.0759 - val_loss: 0.0064 - val_mae: 0.0633\n",
      "Epoch 68/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - loss: 0.0125 - mae: 0.0767 - val_loss: 0.0066 - val_mae: 0.0643\n",
      "Epoch 69/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - loss: 0.0121 - mae: 0.0756 - val_loss: 0.0067 - val_mae: 0.0653\n",
      "Epoch 70/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0126 - mae: 0.0776 - val_loss: 0.0057 - val_mae: 0.0591\n",
      "Epoch 71/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 0.0129 - mae: 0.0782 - val_loss: 0.0057 - val_mae: 0.0588\n",
      "Epoch 72/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - loss: 0.0130 - mae: 0.0784 - val_loss: 0.0056 - val_mae: 0.0576\n",
      "Epoch 73/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - loss: 0.0124 - mae: 0.0761 - val_loss: 0.0056 - val_mae: 0.0581\n",
      "Epoch 74/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - loss: 0.0125 - mae: 0.0771 - val_loss: 0.0056 - val_mae: 0.0582\n",
      "Epoch 75/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0128 - mae: 0.0776 - val_loss: 0.0056 - val_mae: 0.0562\n",
      "Epoch 76/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - loss: 0.0124 - mae: 0.0766 - val_loss: 0.0062 - val_mae: 0.0624\n",
      "Epoch 77/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0124 - mae: 0.0769 - val_loss: 0.0061 - val_mae: 0.0616\n",
      "Epoch 78/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0128 - mae: 0.0781 - val_loss: 0.0063 - val_mae: 0.0616\n",
      "Epoch 79/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - loss: 0.0125 - mae: 0.0768 - val_loss: 0.0058 - val_mae: 0.0593\n",
      "Epoch 80/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - loss: 0.0122 - mae: 0.0760 - val_loss: 0.0057 - val_mae: 0.0591\n",
      "Epoch 81/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - loss: 0.0122 - mae: 0.0755 - val_loss: 0.0059 - val_mae: 0.0597\n",
      "Epoch 82/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - loss: 0.0131 - mae: 0.0786 - val_loss: 0.0057 - val_mae: 0.0585\n",
      "Epoch 83/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0123 - mae: 0.0762 - val_loss: 0.0056 - val_mae: 0.0570\n",
      "Epoch 84/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - loss: 0.0126 - mae: 0.0769 - val_loss: 0.0060 - val_mae: 0.0612\n",
      "Epoch 85/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - loss: 0.0122 - mae: 0.0759 - val_loss: 0.0057 - val_mae: 0.0584\n",
      "Epoch 86/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - loss: 0.0127 - mae: 0.0775 - val_loss: 0.0059 - val_mae: 0.0600\n",
      "Epoch 87/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0122 - mae: 0.0757 - val_loss: 0.0056 - val_mae: 0.0568\n",
      "Epoch 88/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - loss: 0.0125 - mae: 0.0770 - val_loss: 0.0059 - val_mae: 0.0603\n",
      "Epoch 89/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0124 - mae: 0.0768 - val_loss: 0.0062 - val_mae: 0.0619\n",
      "Epoch 90/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 0.0126 - mae: 0.0774 - val_loss: 0.0057 - val_mae: 0.0585\n",
      "Epoch 91/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 0.0124 - mae: 0.0767 - val_loss: 0.0056 - val_mae: 0.0571\n",
      "Epoch 92/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 0.0124 - mae: 0.0767 - val_loss: 0.0056 - val_mae: 0.0576\n",
      "Epoch 93/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0124 - mae: 0.0766 - val_loss: 0.0057 - val_mae: 0.0567\n",
      "Epoch 94/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - loss: 0.0125 - mae: 0.0772 - val_loss: 0.0056 - val_mae: 0.0566\n",
      "Epoch 95/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - loss: 0.0124 - mae: 0.0766 - val_loss: 0.0056 - val_mae: 0.0569\n",
      "Epoch 96/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - loss: 0.0121 - mae: 0.0758 - val_loss: 0.0056 - val_mae: 0.0566\n",
      "Epoch 97/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - loss: 0.0120 - mae: 0.0754 - val_loss: 0.0057 - val_mae: 0.0573\n",
      "Epoch 98/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0124 - mae: 0.0765 - val_loss: 0.0056 - val_mae: 0.0574\n",
      "Epoch 99/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - loss: 0.0125 - mae: 0.0767 - val_loss: 0.0056 - val_mae: 0.0566\n",
      "Epoch 100/100\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - loss: 0.0124 - mae: 0.0769 - val_loss: 0.0058 - val_mae: 0.0591\n",
      "\u001b[1m677/677\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step\n",
      "✅ Done: onion_Chikmagalur_daily.csv | MAE=515.4, RMSE=738.35, R2=0.45, MAPE=35.08%, Accuracy=64.92%\n",
      "🚀 Processing: onion_Chitradurga_daily.csv\n",
      "Epoch 1/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.1138 - mae: 0.2508 - val_loss: 0.0512 - val_mae: 0.2202\n",
      "Epoch 2/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0515 - mae: 0.1796 - val_loss: 0.0046 - val_mae: 0.0580\n",
      "Epoch 3/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0475 - mae: 0.1701 - val_loss: 0.0019 - val_mae: 0.0385\n",
      "Epoch 4/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0476 - mae: 0.1701 - val_loss: 0.0029 - val_mae: 0.0464\n",
      "Epoch 5/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0476 - mae: 0.1694 - val_loss: 0.0068 - val_mae: 0.0751\n",
      "Epoch 6/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0465 - mae: 0.1675 - val_loss: 0.0012 - val_mae: 0.0304\n",
      "Epoch 7/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0469 - mae: 0.1674 - val_loss: 0.0042 - val_mae: 0.0573\n",
      "Epoch 8/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0484 - mae: 0.1699 - val_loss: 0.0036 - val_mae: 0.0549\n",
      "Epoch 9/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0461 - mae: 0.1650 - val_loss: 0.0013 - val_mae: 0.0318\n",
      "Epoch 10/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0468 - mae: 0.1658 - val_loss: 0.0026 - val_mae: 0.0441\n",
      "Epoch 11/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0470 - mae: 0.1661 - val_loss: 0.0016 - val_mae: 0.0342\n",
      "Epoch 12/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0471 - mae: 0.1657 - val_loss: 8.4235e-04 - val_mae: 0.0227\n",
      "Epoch 13/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0462 - mae: 0.1635 - val_loss: 0.0020 - val_mae: 0.0404\n",
      "Epoch 14/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0457 - mae: 0.1620 - val_loss: 4.3421e-04 - val_mae: 0.0182\n",
      "Epoch 15/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0460 - mae: 0.1624 - val_loss: 6.7194e-04 - val_mae: 0.0224\n",
      "Epoch 16/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0447 - mae: 0.1584 - val_loss: 0.0019 - val_mae: 0.0392\n",
      "Epoch 17/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0464 - mae: 0.1636 - val_loss: 0.0015 - val_mae: 0.0336\n",
      "Epoch 18/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0469 - mae: 0.1651 - val_loss: 8.7562e-04 - val_mae: 0.0256\n",
      "Epoch 19/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0450 - mae: 0.1596 - val_loss: 0.0012 - val_mae: 0.0289\n",
      "Epoch 20/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0450 - mae: 0.1605 - val_loss: 4.1764e-04 - val_mae: 0.0174\n",
      "Epoch 21/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0475 - mae: 0.1661 - val_loss: 1.2310e-04 - val_mae: 0.0082\n",
      "Epoch 22/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0459 - mae: 0.1624 - val_loss: 3.5289e-04 - val_mae: 0.0143\n",
      "Epoch 23/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0449 - mae: 0.1600 - val_loss: 9.7102e-04 - val_mae: 0.0304\n",
      "Epoch 24/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0468 - mae: 0.1629 - val_loss: 0.0019 - val_mae: 0.0400\n",
      "Epoch 25/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0462 - mae: 0.1619 - val_loss: 2.6440e-04 - val_mae: 0.0111\n",
      "Epoch 26/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0455 - mae: 0.1598 - val_loss: 2.0715e-04 - val_mae: 0.0117\n",
      "Epoch 27/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0455 - mae: 0.1610 - val_loss: 1.4553e-04 - val_mae: 0.0079\n",
      "Epoch 28/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0465 - mae: 0.1625 - val_loss: 5.9482e-04 - val_mae: 0.0205\n",
      "Epoch 29/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0446 - mae: 0.1580 - val_loss: 0.0015 - val_mae: 0.0334\n",
      "Epoch 30/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0443 - mae: 0.1575 - val_loss: 2.5620e-04 - val_mae: 0.0134\n",
      "Epoch 31/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0451 - mae: 0.1584 - val_loss: 0.0012 - val_mae: 0.0345\n",
      "Epoch 32/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0438 - mae: 0.1571 - val_loss: 0.0023 - val_mae: 0.0465\n",
      "Epoch 33/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0448 - mae: 0.1588 - val_loss: 0.0036 - val_mae: 0.0593\n",
      "Epoch 34/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0446 - mae: 0.1572 - val_loss: 5.0130e-04 - val_mae: 0.0204\n",
      "Epoch 35/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0442 - mae: 0.1570 - val_loss: 0.0012 - val_mae: 0.0326\n",
      "Epoch 36/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0465 - mae: 0.1621 - val_loss: 2.4367e-04 - val_mae: 0.0130\n",
      "Epoch 37/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0466 - mae: 0.1613 - val_loss: 0.0013 - val_mae: 0.0359\n",
      "Epoch 38/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0453 - mae: 0.1597 - val_loss: 0.0012 - val_mae: 0.0337\n",
      "Epoch 39/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0457 - mae: 0.1608 - val_loss: 9.3133e-04 - val_mae: 0.0299\n",
      "Epoch 40/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0450 - mae: 0.1602 - val_loss: 7.6169e-04 - val_mae: 0.0270\n",
      "Epoch 41/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0457 - mae: 0.1600 - val_loss: 0.0010 - val_mae: 0.0295\n",
      "Epoch 42/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0444 - mae: 0.1579 - val_loss: 0.0021 - val_mae: 0.0449\n",
      "Epoch 43/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0465 - mae: 0.1616 - val_loss: 0.0025 - val_mae: 0.0492\n",
      "Epoch 44/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0436 - mae: 0.1544 - val_loss: 5.4733e-04 - val_mae: 0.0221\n",
      "Epoch 45/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0465 - mae: 0.1608 - val_loss: 0.0015 - val_mae: 0.0386\n",
      "Epoch 46/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0464 - mae: 0.1614 - val_loss: 4.7483e-04 - val_mae: 0.0195\n",
      "Epoch 47/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0458 - mae: 0.1600 - val_loss: 0.0017 - val_mae: 0.0412\n",
      "Epoch 48/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0455 - mae: 0.1588 - val_loss: 9.5653e-04 - val_mae: 0.0304\n",
      "Epoch 49/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0456 - mae: 0.1596 - val_loss: 0.0036 - val_mae: 0.0600\n",
      "Epoch 50/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0454 - mae: 0.1597 - val_loss: 5.6236e-04 - val_mae: 0.0231\n",
      "Epoch 51/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0453 - mae: 0.1584 - val_loss: 5.3537e-04 - val_mae: 0.0224\n",
      "Epoch 52/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0445 - mae: 0.1570 - val_loss: 9.1275e-04 - val_mae: 0.0298\n",
      "Epoch 53/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0437 - mae: 0.1553 - val_loss: 4.1918e-04 - val_mae: 0.0184\n",
      "Epoch 54/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0455 - mae: 0.1591 - val_loss: 1.8701e-04 - val_mae: 0.0120\n",
      "Epoch 55/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0445 - mae: 0.1562 - val_loss: 2.2273e-04 - val_mae: 0.0117\n",
      "Epoch 56/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0444 - mae: 0.1565 - val_loss: 0.0025 - val_mae: 0.0492\n",
      "Epoch 57/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0440 - mae: 0.1550 - val_loss: 8.3678e-05 - val_mae: 0.0069\n",
      "Epoch 58/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0463 - mae: 0.1618 - val_loss: 0.0035 - val_mae: 0.0586\n",
      "Epoch 59/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0455 - mae: 0.1593 - val_loss: 0.0029 - val_mae: 0.0530\n",
      "Epoch 60/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0443 - mae: 0.1564 - val_loss: 9.9178e-04 - val_mae: 0.0311\n",
      "Epoch 61/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0454 - mae: 0.1590 - val_loss: 3.7933e-05 - val_mae: 0.0018\n",
      "Epoch 62/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0452 - mae: 0.1583 - val_loss: 0.0037 - val_mae: 0.0600\n",
      "Epoch 63/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0442 - mae: 0.1563 - val_loss: 1.4126e-04 - val_mae: 0.0105\n",
      "Epoch 64/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0452 - mae: 0.1581 - val_loss: 0.0016 - val_mae: 0.0387\n",
      "Epoch 65/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0456 - mae: 0.1591 - val_loss: 7.4653e-04 - val_mae: 0.0268\n",
      "Epoch 66/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0452 - mae: 0.1584 - val_loss: 4.4535e-05 - val_mae: 0.0039\n",
      "Epoch 67/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0449 - mae: 0.1575 - val_loss: 0.0017 - val_mae: 0.0412\n",
      "Epoch 68/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0440 - mae: 0.1554 - val_loss: 0.0022 - val_mae: 0.0463\n",
      "Epoch 69/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0441 - mae: 0.1554 - val_loss: 3.6897e-04 - val_mae: 0.0185\n",
      "Epoch 70/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0459 - mae: 0.1601 - val_loss: 0.0024 - val_mae: 0.0484\n",
      "Epoch 71/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0443 - mae: 0.1566 - val_loss: 0.0018 - val_mae: 0.0415\n",
      "Epoch 72/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0438 - mae: 0.1552 - val_loss: 3.6232e-04 - val_mae: 0.0159\n",
      "Epoch 73/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0453 - mae: 0.1587 - val_loss: 8.4816e-04 - val_mae: 0.0264\n",
      "Epoch 74/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0452 - mae: 0.1582 - val_loss: 0.0024 - val_mae: 0.0490\n",
      "Epoch 75/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0455 - mae: 0.1585 - val_loss: 2.6755e-04 - val_mae: 0.0154\n",
      "Epoch 76/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0444 - mae: 0.1555 - val_loss: 1.2003e-04 - val_mae: 0.0094\n",
      "Epoch 77/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0436 - mae: 0.1540 - val_loss: 0.0033 - val_mae: 0.0566\n",
      "Epoch 78/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0444 - mae: 0.1571 - val_loss: 0.0027 - val_mae: 0.0512\n",
      "Epoch 79/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0447 - mae: 0.1573 - val_loss: 7.9450e-04 - val_mae: 0.0274\n",
      "Epoch 80/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0448 - mae: 0.1570 - val_loss: 8.0510e-04 - val_mae: 0.0279\n",
      "Epoch 81/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0446 - mae: 0.1577 - val_loss: 1.4470e-04 - val_mae: 0.0106\n",
      "Epoch 82/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0443 - mae: 0.1551 - val_loss: 0.0029 - val_mae: 0.0533\n",
      "Epoch 83/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0444 - mae: 0.1560 - val_loss: 0.0038 - val_mae: 0.0607\n",
      "Epoch 84/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0438 - mae: 0.1549 - val_loss: 5.5890e-04 - val_mae: 0.0218\n",
      "Epoch 85/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0437 - mae: 0.1534 - val_loss: 4.5326e-04 - val_mae: 0.0206\n",
      "Epoch 86/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0446 - mae: 0.1559 - val_loss: 0.0031 - val_mae: 0.0547\n",
      "Epoch 87/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0458 - mae: 0.1603 - val_loss: 3.0917e-04 - val_mae: 0.0167\n",
      "Epoch 88/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0437 - mae: 0.1552 - val_loss: 7.3804e-04 - val_mae: 0.0265\n",
      "Epoch 89/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0450 - mae: 0.1568 - val_loss: 0.0034 - val_mae: 0.0573\n",
      "Epoch 90/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0441 - mae: 0.1550 - val_loss: 2.6030e-04 - val_mae: 0.0133\n",
      "Epoch 91/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0452 - mae: 0.1578 - val_loss: 0.0018 - val_mae: 0.0397\n",
      "Epoch 92/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0453 - mae: 0.1588 - val_loss: 5.0408e-04 - val_mae: 0.0217\n",
      "Epoch 93/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0450 - mae: 0.1574 - val_loss: 0.0015 - val_mae: 0.0380\n",
      "Epoch 94/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0447 - mae: 0.1581 - val_loss: 0.0015 - val_mae: 0.0378\n",
      "Epoch 95/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0444 - mae: 0.1565 - val_loss: 0.0010 - val_mae: 0.0304\n",
      "Epoch 96/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0442 - mae: 0.1557 - val_loss: 8.2626e-04 - val_mae: 0.0281\n",
      "Epoch 97/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0436 - mae: 0.1536 - val_loss: 0.0022 - val_mae: 0.0471\n",
      "Epoch 98/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0447 - mae: 0.1572 - val_loss: 5.6313e-05 - val_mae: 0.0050\n",
      "Epoch 99/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0448 - mae: 0.1585 - val_loss: 9.6992e-04 - val_mae: 0.0283\n",
      "Epoch 100/100\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0452 - mae: 0.1584 - val_loss: 0.0014 - val_mae: 0.0363\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "✅ Done: onion_Chitradurga_daily.csv | MAE=446.58, RMSE=640.14, R2=0.26, MAPE=36.51%, Accuracy=63.49%\n",
      "🚀 Processing: onion_Davangere_daily.csv\n",
      "Epoch 1/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.1193 - mae: 0.1641 - val_loss: 0.0077 - val_mae: 0.0790\n",
      "Epoch 2/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0048 - mae: 0.0542 - val_loss: 0.0039 - val_mae: 0.0491\n",
      "Epoch 3/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0030 - mae: 0.0428 - val_loss: 0.0038 - val_mae: 0.0381\n",
      "Epoch 4/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0020 - mae: 0.0343 - val_loss: 0.0046 - val_mae: 0.0436\n",
      "Epoch 5/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0015 - mae: 0.0294 - val_loss: 0.0031 - val_mae: 0.0429\n",
      "Epoch 6/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0284 - val_loss: 0.0030 - val_mae: 0.0292\n",
      "Epoch 7/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0254 - val_loss: 0.0027 - val_mae: 0.0333\n",
      "Epoch 8/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0253 - val_loss: 0.0023 - val_mae: 0.0256\n",
      "Epoch 9/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0011 - mae: 0.0237 - val_loss: 0.0031 - val_mae: 0.0294\n",
      "Epoch 10/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0248 - val_loss: 0.0026 - val_mae: 0.0314\n",
      "Epoch 11/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0011 - mae: 0.0225 - val_loss: 0.0026 - val_mae: 0.0269\n",
      "Epoch 12/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 9.0604e-04 - mae: 0.0220 - val_loss: 0.0022 - val_mae: 0.0292\n",
      "Epoch 13/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0259 - val_loss: 0.0024 - val_mae: 0.0248\n",
      "Epoch 14/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 9.5290e-04 - mae: 0.0223 - val_loss: 0.0028 - val_mae: 0.0279\n",
      "Epoch 15/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0010 - mae: 0.0223 - val_loss: 0.0026 - val_mae: 0.0267\n",
      "Epoch 16/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 9.4276e-04 - mae: 0.0222 - val_loss: 0.0025 - val_mae: 0.0263\n",
      "Epoch 17/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 8.7966e-04 - mae: 0.0210 - val_loss: 0.0023 - val_mae: 0.0239\n",
      "Epoch 18/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 9.6573e-04 - mae: 0.0227 - val_loss: 0.0026 - val_mae: 0.0267\n",
      "Epoch 19/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 9.6260e-04 - mae: 0.0221 - val_loss: 0.0020 - val_mae: 0.0223\n",
      "Epoch 20/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 9.1017e-04 - mae: 0.0217 - val_loss: 0.0022 - val_mae: 0.0242\n",
      "Epoch 21/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 9.7899e-04 - mae: 0.0224 - val_loss: 0.0019 - val_mae: 0.0254\n",
      "Epoch 22/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 9.8690e-04 - mae: 0.0222 - val_loss: 0.0019 - val_mae: 0.0237\n",
      "Epoch 23/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 9.4834e-04 - mae: 0.0221 - val_loss: 0.0019 - val_mae: 0.0226\n",
      "Epoch 24/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 9.6655e-04 - mae: 0.0216 - val_loss: 0.0019 - val_mae: 0.0231\n",
      "Epoch 25/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 9.4329e-04 - mae: 0.0215 - val_loss: 0.0027 - val_mae: 0.0340\n",
      "Epoch 26/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 9.1181e-04 - mae: 0.0215 - val_loss: 0.0018 - val_mae: 0.0206\n",
      "Epoch 27/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 8.6545e-04 - mae: 0.0211 - val_loss: 0.0017 - val_mae: 0.0225\n",
      "Epoch 28/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 8.9103e-04 - mae: 0.0210 - val_loss: 0.0017 - val_mae: 0.0224\n",
      "Epoch 29/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 8.5149e-04 - mae: 0.0208 - val_loss: 0.0018 - val_mae: 0.0201\n",
      "Epoch 30/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 8.4253e-04 - mae: 0.0208 - val_loss: 0.0018 - val_mae: 0.0241\n",
      "Epoch 31/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 8.7785e-04 - mae: 0.0210 - val_loss: 0.0018 - val_mae: 0.0255\n",
      "Epoch 32/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 9.2076e-04 - mae: 0.0210 - val_loss: 0.0017 - val_mae: 0.0228\n",
      "Epoch 33/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 8.6964e-04 - mae: 0.0206 - val_loss: 0.0017 - val_mae: 0.0202\n",
      "Epoch 34/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 8.3934e-04 - mae: 0.0208 - val_loss: 0.0020 - val_mae: 0.0262\n",
      "Epoch 35/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 9.1691e-04 - mae: 0.0213 - val_loss: 0.0020 - val_mae: 0.0249\n",
      "Epoch 36/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 8.8414e-04 - mae: 0.0211 - val_loss: 0.0017 - val_mae: 0.0207\n",
      "Epoch 37/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 8.4496e-04 - mae: 0.0206 - val_loss: 0.0016 - val_mae: 0.0204\n",
      "Epoch 38/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 8.4981e-04 - mae: 0.0204 - val_loss: 0.0017 - val_mae: 0.0189\n",
      "Epoch 39/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 8.5236e-04 - mae: 0.0207 - val_loss: 0.0017 - val_mae: 0.0221\n",
      "Epoch 40/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 8.2580e-04 - mae: 0.0203 - val_loss: 0.0017 - val_mae: 0.0193\n",
      "Epoch 41/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 8.3957e-04 - mae: 0.0204 - val_loss: 0.0017 - val_mae: 0.0230\n",
      "Epoch 42/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 8.8487e-04 - mae: 0.0209 - val_loss: 0.0016 - val_mae: 0.0190\n",
      "Epoch 43/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 9.1789e-04 - mae: 0.0214 - val_loss: 0.0017 - val_mae: 0.0194\n",
      "Epoch 44/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 8.1795e-04 - mae: 0.0202 - val_loss: 0.0016 - val_mae: 0.0183\n",
      "Epoch 45/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 9.6532e-04 - mae: 0.0204 - val_loss: 0.0017 - val_mae: 0.0201\n",
      "Epoch 46/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 7.9616e-04 - mae: 0.0201 - val_loss: 0.0016 - val_mae: 0.0192\n",
      "Epoch 47/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 8.2938e-04 - mae: 0.0203 - val_loss: 0.0019 - val_mae: 0.0235\n",
      "Epoch 48/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 8.0991e-04 - mae: 0.0205 - val_loss: 0.0018 - val_mae: 0.0240\n",
      "Epoch 49/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 8.0189e-04 - mae: 0.0199 - val_loss: 0.0017 - val_mae: 0.0202\n",
      "Epoch 50/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 9.4986e-04 - mae: 0.0203 - val_loss: 0.0016 - val_mae: 0.0184\n",
      "Epoch 51/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 8.1976e-04 - mae: 0.0203 - val_loss: 0.0017 - val_mae: 0.0193\n",
      "Epoch 52/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 8.1985e-04 - mae: 0.0200 - val_loss: 0.0017 - val_mae: 0.0200\n",
      "Epoch 53/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 8.0444e-04 - mae: 0.0202 - val_loss: 0.0017 - val_mae: 0.0217\n",
      "Epoch 54/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 9.3954e-04 - mae: 0.0207 - val_loss: 0.0019 - val_mae: 0.0213\n",
      "Epoch 55/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 8.3714e-04 - mae: 0.0199 - val_loss: 0.0018 - val_mae: 0.0217\n",
      "Epoch 56/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 8.0020e-04 - mae: 0.0198 - val_loss: 0.0018 - val_mae: 0.0229\n",
      "Epoch 57/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 8.0454e-04 - mae: 0.0199 - val_loss: 0.0017 - val_mae: 0.0195\n",
      "Epoch 58/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 8.5416e-04 - mae: 0.0200 - val_loss: 0.0016 - val_mae: 0.0192\n",
      "Epoch 59/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 7.7762e-04 - mae: 0.0195 - val_loss: 0.0017 - val_mae: 0.0221\n",
      "Epoch 60/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 8.2238e-04 - mae: 0.0201 - val_loss: 0.0016 - val_mae: 0.0189\n",
      "Epoch 61/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 9.2292e-04 - mae: 0.0205 - val_loss: 0.0016 - val_mae: 0.0187\n",
      "Epoch 62/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 8.6300e-04 - mae: 0.0200 - val_loss: 0.0016 - val_mae: 0.0183\n",
      "Epoch 63/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 7.8734e-04 - mae: 0.0197 - val_loss: 0.0016 - val_mae: 0.0185\n",
      "Epoch 64/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 7.8932e-04 - mae: 0.0197 - val_loss: 0.0016 - val_mae: 0.0184\n",
      "Epoch 65/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 8.2988e-04 - mae: 0.0199 - val_loss: 0.0016 - val_mae: 0.0182\n",
      "Epoch 66/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 8.7496e-04 - mae: 0.0199 - val_loss: 0.0017 - val_mae: 0.0203\n",
      "Epoch 67/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 7.9822e-04 - mae: 0.0198 - val_loss: 0.0017 - val_mae: 0.0209\n",
      "Epoch 68/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 8.2320e-04 - mae: 0.0198 - val_loss: 0.0016 - val_mae: 0.0191\n",
      "Epoch 69/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 8.1365e-04 - mae: 0.0198 - val_loss: 0.0016 - val_mae: 0.0183\n",
      "Epoch 70/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 8.3416e-04 - mae: 0.0197 - val_loss: 0.0019 - val_mae: 0.0239\n",
      "Epoch 71/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 8.5227e-04 - mae: 0.0199 - val_loss: 0.0016 - val_mae: 0.0187\n",
      "Epoch 72/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 7.8426e-04 - mae: 0.0198 - val_loss: 0.0016 - val_mae: 0.0190\n",
      "Epoch 73/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 8.3406e-04 - mae: 0.0199 - val_loss: 0.0016 - val_mae: 0.0184\n",
      "Epoch 74/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 8.8122e-04 - mae: 0.0205 - val_loss: 0.0016 - val_mae: 0.0188\n",
      "Epoch 75/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 8.1182e-04 - mae: 0.0196 - val_loss: 0.0016 - val_mae: 0.0182\n",
      "Epoch 76/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 7.7345e-04 - mae: 0.0194 - val_loss: 0.0016 - val_mae: 0.0188\n",
      "Epoch 77/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 8.1577e-04 - mae: 0.0196 - val_loss: 0.0017 - val_mae: 0.0190\n",
      "Epoch 78/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 7.8305e-04 - mae: 0.0195 - val_loss: 0.0016 - val_mae: 0.0187\n",
      "Epoch 79/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 7.5309e-04 - mae: 0.0193 - val_loss: 0.0016 - val_mae: 0.0187\n",
      "Epoch 80/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 7.9375e-04 - mae: 0.0196 - val_loss: 0.0016 - val_mae: 0.0184\n",
      "Epoch 81/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 8.6097e-04 - mae: 0.0200 - val_loss: 0.0016 - val_mae: 0.0190\n",
      "Epoch 82/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 7.8260e-04 - mae: 0.0194 - val_loss: 0.0017 - val_mae: 0.0202\n",
      "Epoch 83/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 7.9653e-04 - mae: 0.0195 - val_loss: 0.0016 - val_mae: 0.0184\n",
      "Epoch 84/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 7.7477e-04 - mae: 0.0197 - val_loss: 0.0016 - val_mae: 0.0186\n",
      "Epoch 85/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 8.2382e-04 - mae: 0.0201 - val_loss: 0.0016 - val_mae: 0.0187\n",
      "Epoch 86/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 9.0007e-04 - mae: 0.0200 - val_loss: 0.0016 - val_mae: 0.0182\n",
      "Epoch 87/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 8.5613e-04 - mae: 0.0199 - val_loss: 0.0016 - val_mae: 0.0190\n",
      "Epoch 88/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 7.6992e-04 - mae: 0.0196 - val_loss: 0.0016 - val_mae: 0.0185\n",
      "Epoch 89/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 7.5259e-04 - mae: 0.0193 - val_loss: 0.0016 - val_mae: 0.0186\n",
      "Epoch 90/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 8.1447e-04 - mae: 0.0199 - val_loss: 0.0017 - val_mae: 0.0196\n",
      "Epoch 91/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 7.9541e-04 - mae: 0.0196 - val_loss: 0.0016 - val_mae: 0.0185\n",
      "Epoch 92/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 7.9748e-04 - mae: 0.0196 - val_loss: 0.0017 - val_mae: 0.0201\n",
      "Epoch 93/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 8.3045e-04 - mae: 0.0195 - val_loss: 0.0016 - val_mae: 0.0182\n",
      "Epoch 94/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 7.1808e-04 - mae: 0.0190 - val_loss: 0.0016 - val_mae: 0.0186\n",
      "Epoch 95/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 7.7956e-04 - mae: 0.0195 - val_loss: 0.0016 - val_mae: 0.0187\n",
      "Epoch 96/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 7.7625e-04 - mae: 0.0197 - val_loss: 0.0017 - val_mae: 0.0194\n",
      "Epoch 97/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 8.9104e-04 - mae: 0.0200 - val_loss: 0.0016 - val_mae: 0.0184\n",
      "Epoch 98/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 7.6202e-04 - mae: 0.0193 - val_loss: 0.0016 - val_mae: 0.0189\n",
      "Epoch 99/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 7.5704e-04 - mae: 0.0193 - val_loss: 0.0016 - val_mae: 0.0184\n",
      "Epoch 100/100\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 8.5900e-04 - mae: 0.0196 - val_loss: 0.0016 - val_mae: 0.0185\n",
      "\u001b[1m309/309\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n",
      "✅ Done: onion_Davangere_daily.csv | MAE=247.49, RMSE=398.68, R2=0.65, MAPE=27.26%, Accuracy=72.74%\n",
      "🚀 Processing: onion_Dharwad_daily.csv\n",
      "Epoch 1/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.2428 - mae: 0.2419 - val_loss: 0.0036 - val_mae: 0.0448\n",
      "Epoch 2/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0113 - mae: 0.0812 - val_loss: 0.0037 - val_mae: 0.0507\n",
      "Epoch 3/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0083 - mae: 0.0687 - val_loss: 0.0038 - val_mae: 0.0525\n",
      "Epoch 4/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0061 - mae: 0.0579 - val_loss: 0.0031 - val_mae: 0.0416\n",
      "Epoch 5/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0051 - mae: 0.0526 - val_loss: 0.0029 - val_mae: 0.0398\n",
      "Epoch 6/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0051 - mae: 0.0506 - val_loss: 0.0028 - val_mae: 0.0380\n",
      "Epoch 7/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0037 - mae: 0.0439 - val_loss: 0.0028 - val_mae: 0.0363\n",
      "Epoch 8/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0037 - mae: 0.0450 - val_loss: 0.0028 - val_mae: 0.0368\n",
      "Epoch 9/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0030 - mae: 0.0393 - val_loss: 0.0031 - val_mae: 0.0377\n",
      "Epoch 10/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0032 - mae: 0.0391 - val_loss: 0.0025 - val_mae: 0.0348\n",
      "Epoch 11/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0029 - mae: 0.0379 - val_loss: 0.0028 - val_mae: 0.0399\n",
      "Epoch 12/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0027 - mae: 0.0355 - val_loss: 0.0032 - val_mae: 0.0383\n",
      "Epoch 13/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0026 - mae: 0.0342 - val_loss: 0.0024 - val_mae: 0.0348\n",
      "Epoch 14/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0028 - mae: 0.0345 - val_loss: 0.0035 - val_mae: 0.0485\n",
      "Epoch 15/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0026 - mae: 0.0354 - val_loss: 0.0021 - val_mae: 0.0313\n",
      "Epoch 16/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0028 - mae: 0.0338 - val_loss: 0.0021 - val_mae: 0.0306\n",
      "Epoch 17/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0022 - mae: 0.0317 - val_loss: 0.0020 - val_mae: 0.0296\n",
      "Epoch 18/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0023 - mae: 0.0324 - val_loss: 0.0025 - val_mae: 0.0336\n",
      "Epoch 19/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0025 - mae: 0.0319 - val_loss: 0.0023 - val_mae: 0.0353\n",
      "Epoch 20/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0024 - mae: 0.0324 - val_loss: 0.0028 - val_mae: 0.0401\n",
      "Epoch 21/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0024 - mae: 0.0328 - val_loss: 0.0023 - val_mae: 0.0351\n",
      "Epoch 22/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0022 - mae: 0.0310 - val_loss: 0.0022 - val_mae: 0.0345\n",
      "Epoch 23/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0026 - mae: 0.0319 - val_loss: 0.0020 - val_mae: 0.0290\n",
      "Epoch 24/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0023 - mae: 0.0317 - val_loss: 0.0027 - val_mae: 0.0390\n",
      "Epoch 25/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0022 - mae: 0.0307 - val_loss: 0.0023 - val_mae: 0.0344\n",
      "Epoch 26/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0024 - mae: 0.0317 - val_loss: 0.0020 - val_mae: 0.0313\n",
      "Epoch 27/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0024 - mae: 0.0316 - val_loss: 0.0034 - val_mae: 0.0475\n",
      "Epoch 28/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0025 - mae: 0.0318 - val_loss: 0.0024 - val_mae: 0.0373\n",
      "Epoch 29/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0025 - mae: 0.0324 - val_loss: 0.0043 - val_mae: 0.0564\n",
      "Epoch 30/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0025 - mae: 0.0338 - val_loss: 0.0027 - val_mae: 0.0399\n",
      "Epoch 31/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0024 - mae: 0.0315 - val_loss: 0.0019 - val_mae: 0.0281\n",
      "Epoch 32/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0026 - mae: 0.0320 - val_loss: 0.0021 - val_mae: 0.0317\n",
      "Epoch 33/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0022 - mae: 0.0307 - val_loss: 0.0020 - val_mae: 0.0303\n",
      "Epoch 34/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0022 - mae: 0.0290 - val_loss: 0.0019 - val_mae: 0.0296\n",
      "Epoch 35/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0022 - mae: 0.0297 - val_loss: 0.0019 - val_mae: 0.0286\n",
      "Epoch 36/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0023 - mae: 0.0319 - val_loss: 0.0021 - val_mae: 0.0331\n",
      "Epoch 37/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0025 - mae: 0.0312 - val_loss: 0.0021 - val_mae: 0.0313\n",
      "Epoch 38/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0023 - mae: 0.0308 - val_loss: 0.0019 - val_mae: 0.0284\n",
      "Epoch 39/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0021 - mae: 0.0286 - val_loss: 0.0023 - val_mae: 0.0351\n",
      "Epoch 40/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0023 - mae: 0.0296 - val_loss: 0.0022 - val_mae: 0.0348\n",
      "Epoch 41/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0025 - mae: 0.0311 - val_loss: 0.0027 - val_mae: 0.0383\n",
      "Epoch 42/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0022 - mae: 0.0287 - val_loss: 0.0020 - val_mae: 0.0300\n",
      "Epoch 43/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0021 - mae: 0.0287 - val_loss: 0.0021 - val_mae: 0.0303\n",
      "Epoch 44/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0022 - mae: 0.0294 - val_loss: 0.0022 - val_mae: 0.0353\n",
      "Epoch 45/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0021 - mae: 0.0285 - val_loss: 0.0037 - val_mae: 0.0487\n",
      "Epoch 46/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0023 - mae: 0.0291 - val_loss: 0.0022 - val_mae: 0.0342\n",
      "Epoch 47/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0021 - mae: 0.0284 - val_loss: 0.0021 - val_mae: 0.0299\n",
      "Epoch 48/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0024 - mae: 0.0309 - val_loss: 0.0021 - val_mae: 0.0309\n",
      "Epoch 49/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0021 - mae: 0.0283 - val_loss: 0.0022 - val_mae: 0.0321\n",
      "Epoch 50/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0022 - mae: 0.0299 - val_loss: 0.0022 - val_mae: 0.0343\n",
      "Epoch 51/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0020 - mae: 0.0276 - val_loss: 0.0019 - val_mae: 0.0283\n",
      "Epoch 52/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0021 - mae: 0.0289 - val_loss: 0.0024 - val_mae: 0.0370\n",
      "Epoch 53/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0024 - mae: 0.0287 - val_loss: 0.0025 - val_mae: 0.0384\n",
      "Epoch 54/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0023 - mae: 0.0294 - val_loss: 0.0019 - val_mae: 0.0289\n",
      "Epoch 55/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0019 - mae: 0.0279 - val_loss: 0.0035 - val_mae: 0.0481\n",
      "Epoch 56/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0022 - mae: 0.0305 - val_loss: 0.0020 - val_mae: 0.0292\n",
      "Epoch 57/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0020 - mae: 0.0286 - val_loss: 0.0023 - val_mae: 0.0356\n",
      "Epoch 58/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0020 - mae: 0.0278 - val_loss: 0.0020 - val_mae: 0.0298\n",
      "Epoch 59/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0021 - mae: 0.0283 - val_loss: 0.0021 - val_mae: 0.0309\n",
      "Epoch 60/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0021 - mae: 0.0283 - val_loss: 0.0019 - val_mae: 0.0288\n",
      "Epoch 61/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0023 - mae: 0.0286 - val_loss: 0.0020 - val_mae: 0.0301\n",
      "Epoch 62/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0021 - mae: 0.0286 - val_loss: 0.0025 - val_mae: 0.0340\n",
      "Epoch 63/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0020 - mae: 0.0279 - val_loss: 0.0021 - val_mae: 0.0327\n",
      "Epoch 64/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0020 - mae: 0.0282 - val_loss: 0.0018 - val_mae: 0.0283\n",
      "Epoch 65/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0023 - mae: 0.0289 - val_loss: 0.0022 - val_mae: 0.0331\n",
      "Epoch 66/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0021 - mae: 0.0278 - val_loss: 0.0020 - val_mae: 0.0308\n",
      "Epoch 67/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0020 - mae: 0.0275 - val_loss: 0.0024 - val_mae: 0.0343\n",
      "Epoch 68/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0019 - mae: 0.0272 - val_loss: 0.0020 - val_mae: 0.0312\n",
      "Epoch 69/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0022 - mae: 0.0284 - val_loss: 0.0022 - val_mae: 0.0339\n",
      "Epoch 70/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0022 - mae: 0.0283 - val_loss: 0.0032 - val_mae: 0.0405\n",
      "Epoch 71/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0022 - mae: 0.0287 - val_loss: 0.0019 - val_mae: 0.0298\n",
      "Epoch 72/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0021 - mae: 0.0278 - val_loss: 0.0022 - val_mae: 0.0321\n",
      "Epoch 73/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0022 - mae: 0.0277 - val_loss: 0.0018 - val_mae: 0.0283\n",
      "Epoch 74/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0019 - mae: 0.0268 - val_loss: 0.0018 - val_mae: 0.0292\n",
      "Epoch 75/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0019 - mae: 0.0276 - val_loss: 0.0024 - val_mae: 0.0366\n",
      "Epoch 76/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0273 - val_loss: 0.0026 - val_mae: 0.0400\n",
      "Epoch 77/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0020 - mae: 0.0293 - val_loss: 0.0019 - val_mae: 0.0296\n",
      "Epoch 78/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0019 - mae: 0.0277 - val_loss: 0.0018 - val_mae: 0.0289\n",
      "Epoch 79/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0020 - mae: 0.0279 - val_loss: 0.0021 - val_mae: 0.0344\n",
      "Epoch 80/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0266 - val_loss: 0.0018 - val_mae: 0.0288\n",
      "Epoch 81/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0020 - mae: 0.0281 - val_loss: 0.0022 - val_mae: 0.0349\n",
      "Epoch 82/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0019 - mae: 0.0267 - val_loss: 0.0024 - val_mae: 0.0350\n",
      "Epoch 83/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0272 - val_loss: 0.0023 - val_mae: 0.0367\n",
      "Epoch 84/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0021 - mae: 0.0276 - val_loss: 0.0024 - val_mae: 0.0360\n",
      "Epoch 85/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0020 - mae: 0.0278 - val_loss: 0.0020 - val_mae: 0.0306\n",
      "Epoch 86/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0270 - val_loss: 0.0021 - val_mae: 0.0323\n",
      "Epoch 87/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0019 - mae: 0.0273 - val_loss: 0.0020 - val_mae: 0.0304\n",
      "Epoch 88/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0019 - mae: 0.0277 - val_loss: 0.0031 - val_mae: 0.0419\n",
      "Epoch 89/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0019 - mae: 0.0273 - val_loss: 0.0026 - val_mae: 0.0369\n",
      "Epoch 90/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0263 - val_loss: 0.0023 - val_mae: 0.0332\n",
      "Epoch 91/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0021 - mae: 0.0284 - val_loss: 0.0025 - val_mae: 0.0357\n",
      "Epoch 92/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0019 - mae: 0.0273 - val_loss: 0.0030 - val_mae: 0.0410\n",
      "Epoch 93/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0021 - mae: 0.0286 - val_loss: 0.0027 - val_mae: 0.0382\n",
      "Epoch 94/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0019 - mae: 0.0267 - val_loss: 0.0024 - val_mae: 0.0354\n",
      "Epoch 95/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0020 - mae: 0.0279 - val_loss: 0.0025 - val_mae: 0.0364\n",
      "Epoch 96/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0019 - mae: 0.0266 - val_loss: 0.0038 - val_mae: 0.0461\n",
      "Epoch 97/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0021 - mae: 0.0279 - val_loss: 0.0022 - val_mae: 0.0324\n",
      "Epoch 98/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0022 - mae: 0.0286 - val_loss: 0.0021 - val_mae: 0.0310\n",
      "Epoch 99/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0017 - mae: 0.0258 - val_loss: 0.0028 - val_mae: 0.0391\n",
      "Epoch 100/100\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0019 - mae: 0.0275 - val_loss: 0.0023 - val_mae: 0.0322\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "✅ Done: onion_Dharwad_daily.csv | MAE=210.83, RMSE=334.4, R2=0.81, MAPE=17.57%, Accuracy=82.43%\n",
      "🚀 Processing: onion_Gadag_daily.csv\n",
      "Epoch 1/100\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.1045 - mae: 0.2124 - val_loss: 0.0149 - val_mae: 0.0952\n",
      "Epoch 2/100\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0144 - mae: 0.0900 - val_loss: 0.0128 - val_mae: 0.1001\n",
      "Epoch 3/100\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0101 - mae: 0.0732 - val_loss: 0.0123 - val_mae: 0.1009\n",
      "Epoch 4/100\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0077 - mae: 0.0639 - val_loss: 0.0064 - val_mae: 0.0512\n",
      "Epoch 5/100\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0061 - mae: 0.0561 - val_loss: 0.0039 - val_mae: 0.0462\n",
      "Epoch 6/100\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0055 - mae: 0.0536 - val_loss: 0.0029 - val_mae: 0.0338\n",
      "Epoch 7/100\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0041 - mae: 0.0438 - val_loss: 0.0080 - val_mae: 0.0754\n",
      "Epoch 8/100\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0036 - mae: 0.0410 - val_loss: 0.0035 - val_mae: 0.0437\n",
      "Epoch 9/100\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0039 - mae: 0.0432 - val_loss: 0.0040 - val_mae: 0.0493\n",
      "Epoch 10/100\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0033 - mae: 0.0379 - val_loss: 0.0029 - val_mae: 0.0347\n",
      "Epoch 11/100\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0035 - mae: 0.0390 - val_loss: 0.0043 - val_mae: 0.0506\n",
      "Epoch 12/100\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0036 - mae: 0.0402 - val_loss: 0.0032 - val_mae: 0.0378\n",
      "Epoch 13/100\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0034 - mae: 0.0380 - val_loss: 0.0070 - val_mae: 0.0713\n",
      "Epoch 14/100\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0037 - mae: 0.0410 - val_loss: 0.0157 - val_mae: 0.1144\n",
      "Epoch 15/100\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0041 - mae: 0.0448 - val_loss: 0.0029 - val_mae: 0.0384\n",
      "Epoch 16/100\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0030 - mae: 0.0362 - val_loss: 0.0039 - val_mae: 0.0446\n",
      "Epoch 17/100\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0034 - mae: 0.0381 - val_loss: 0.0049 - val_mae: 0.0525\n",
      "Epoch 18/100\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0035 - mae: 0.0405 - val_loss: 0.0033 - val_mae: 0.0429\n",
      "Epoch 19/100\n",
      "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22548s\u001b[0m 20s/step - loss: 0.0045 - mae: 0.0459 - val_loss: 0.0059 - val_mae: 0.0509\n",
      "Epoch 74/100\n",
      "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 13ms/step - loss: 0.0045 - mae: 0.0462 - val_loss: 0.0058 - val_mae: 0.0507\n",
      "Epoch 75/100\n",
      "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.0045 - mae: 0.0462 - val_loss: 0.0063 - val_mae: 0.0535\n",
      "Epoch 76/100\n",
      "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.0045 - mae: 0.0461 - val_loss: 0.0058 - val_mae: 0.0500\n",
      "Epoch 77/100\n",
      "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.0045 - mae: 0.0462 - val_loss: 0.0060 - val_mae: 0.0516\n",
      "Epoch 78/100\n",
      "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 11ms/step - loss: 0.0045 - mae: 0.0465 - val_loss: 0.0063 - val_mae: 0.0535\n",
      "Epoch 79/100\n",
      "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.0044 - mae: 0.0461 - val_loss: 0.0066 - val_mae: 0.0546\n",
      "Epoch 80/100\n",
      "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.0046 - mae: 0.0466 - val_loss: 0.0059 - val_mae: 0.0513\n",
      "Epoch 81/100\n",
      "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - loss: 0.0046 - mae: 0.0464 - val_loss: 0.0059 - val_mae: 0.0515\n",
      "Epoch 82/100\n",
      "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 11ms/step - loss: 0.0044 - mae: 0.0461 - val_loss: 0.0062 - val_mae: 0.0527\n",
      "Epoch 83/100\n",
      "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.0045 - mae: 0.0463 - val_loss: 0.0060 - val_mae: 0.0517\n",
      "Epoch 84/100\n",
      "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 11ms/step - loss: 0.0043 - mae: 0.0456 - val_loss: 0.0058 - val_mae: 0.0503\n",
      "Epoch 85/100\n",
      "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 11ms/step - loss: 0.0043 - mae: 0.0459 - val_loss: 0.0060 - val_mae: 0.0520\n",
      "Epoch 86/100\n",
      "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 11ms/step - loss: 0.0045 - mae: 0.0465 - val_loss: 0.0058 - val_mae: 0.0505\n",
      "Epoch 87/100\n",
      "\u001b[1m722/722\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step\n",
      "✅ Done: onion_Hassan_daily.csv | MAE=505.56, RMSE=724.89, R2=0.39, MAPE=41.57%, Accuracy=58.43%\n",
      "🚀 Processing: onion_Haveri_daily.csv\n",
      "Epoch 1/100\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 0.0775 - mae: 0.1624 - val_loss: 0.0037 - val_mae: 0.0486\n",
      "Epoch 2/100\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0118 - mae: 0.0823 - val_loss: 0.0027 - val_mae: 0.0385\n",
      "Epoch 3/100\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - loss: 0.0094 - mae: 0.0727 - val_loss: 0.0062 - val_mae: 0.0695\n",
      "Epoch 4/100\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0091 - mae: 0.0716 - val_loss: 0.0028 - val_mae: 0.0387\n",
      "Epoch 5/100\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - loss: 0.0091 - mae: 0.0724 - val_loss: 0.0056 - val_mae: 0.0651\n",
      "Epoch 6/100\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - loss: 0.0072 - mae: 0.0647 - val_loss: 0.0026 - val_mae: 0.0398\n",
      "Epoch 7/100\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0069 - mae: 0.0621 - val_loss: 0.0038 - val_mae: 0.0513\n",
      "Epoch 8/100\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0073 - mae: 0.0643 - val_loss: 0.0030 - val_mae: 0.0445\n",
      "Epoch 9/100\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - loss: 0.0062 - mae: 0.0579 - val_loss: 0.0028 - val_mae: 0.0419\n",
      "Epoch 30/100\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - loss: 0.0061 - mae: 0.0582 - val_loss: 0.0030 - val_mae: 0.0436\n",
      "Epoch 31/100\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - loss: 0.0062 - mae: 0.0582 - val_loss: 0.0022 - val_mae: 0.0350\n",
      "Epoch 32/100\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - loss: 0.0061 - mae: 0.0583 - val_loss: 0.0022 - val_mae: 0.0352\n",
      "Epoch 33/100\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - loss: 0.0062 - mae: 0.0586 - val_loss: 0.0022 - val_mae: 0.0352\n",
      "Epoch 34/100\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - loss: 0.0064 - mae: 0.0596 - val_loss: 0.0046 - val_mae: 0.0570\n",
      "Epoch 35/100\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - loss: 0.0062 - mae: 0.0587 - val_loss: 0.0032 - val_mae: 0.0453\n",
      "Epoch 36/100\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - loss: 0.0060 - mae: 0.0576 - val_loss: 0.0023 - val_mae: 0.0363\n",
      "Epoch 37/100\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - loss: 0.0060 - mae: 0.0581 - val_loss: 0.0024 - val_mae: 0.0373\n",
      "Epoch 38/100\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - loss: 0.0061 - mae: 0.0580 - val_loss: 0.0023 - val_mae: 0.0360\n",
      "Epoch 39/100\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - loss: 0.0062 - mae: 0.0585 - val_loss: 0.0023 - val_mae: 0.0367\n",
      "Epoch 40/100\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0058 - mae: 0.0571 - val_loss: 0.0029 - val_mae: 0.0428\n",
      "Epoch 41/100\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0059 - mae: 0.0575 - val_loss: 0.0026 - val_mae: 0.0391\n",
      "Epoch 42/100\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0060 - mae: 0.0580 - val_loss: 0.0032 - val_mae: 0.0453\n",
      "Epoch 43/100\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 0.0060 - mae: 0.0576 - val_loss: 0.0024 - val_mae: 0.0371\n",
      "Epoch 64/100\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0062 - mae: 0.0586 - val_loss: 0.0025 - val_mae: 0.0386\n",
      "Epoch 65/100\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0061 - mae: 0.0581 - val_loss: 0.0029 - val_mae: 0.0429\n",
      "Epoch 66/100\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0057 - mae: 0.0567 - val_loss: 0.0023 - val_mae: 0.0358\n",
      "Epoch 67/100\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0061 - mae: 0.0584 - val_loss: 0.0023 - val_mae: 0.0359\n",
      "Epoch 68/100\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0060 - mae: 0.0575 - val_loss: 0.0034 - val_mae: 0.0469\n",
      "Epoch 69/100\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0061 - mae: 0.0582 - val_loss: 0.0022 - val_mae: 0.0352\n",
      "Epoch 70/100\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0060 - mae: 0.0572 - val_loss: 0.0024 - val_mae: 0.0379\n",
      "Epoch 71/100\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0061 - mae: 0.0586 - val_loss: 0.0023 - val_mae: 0.0364\n",
      "Epoch 72/100\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0060 - mae: 0.0582 - val_loss: 0.0038 - val_mae: 0.0506\n",
      "Epoch 73/100\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0061 - mae: 0.0579 - val_loss: 0.0030 - val_mae: 0.0441\n",
      "Epoch 74/100\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0063 - mae: 0.0591 - val_loss: 0.0032 - val_mae: 0.0453\n",
      "Epoch 75/100\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0061 - mae: 0.0581 - val_loss: 0.0027 - val_mae: 0.0404\n",
      "Epoch 76/100\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0058 - mae: 0.0572 - val_loss: 0.0023 - val_mae: 0.0362\n",
      "Epoch 77/100\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0061 - mae: 0.0577 - val_loss: 0.0022 - val_mae: 0.0353\n",
      "Epoch 78/100\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0060 - mae: 0.0575 - val_loss: 0.0024 - val_mae: 0.0376\n",
      "Epoch 79/100\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0058 - mae: 0.0569 - val_loss: 0.0025 - val_mae: 0.0385\n",
      "Epoch 80/100\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0061 - mae: 0.0583 - val_loss: 0.0022 - val_mae: 0.0356\n",
      "Epoch 81/100\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0057 - mae: 0.0567 - val_loss: 0.0025 - val_mae: 0.0390\n",
      "Epoch 92/100\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0059 - mae: 0.0576 - val_loss: 0.0025 - val_mae: 0.0385\n",
      "Epoch 93/100\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0059 - mae: 0.0576 - val_loss: 0.0028 - val_mae: 0.0418\n",
      "Epoch 94/100\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 0.0056 - mae: 0.0566 - val_loss: 0.0033 - val_mae: 0.0462\n",
      "Epoch 95/100\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0060 - mae: 0.0577 - val_loss: 0.0023 - val_mae: 0.0366\n",
      "Epoch 96/100\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0060 - mae: 0.0577 - val_loss: 0.0025 - val_mae: 0.0388\n",
      "Epoch 97/100\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 0.0058 - mae: 0.0575 - val_loss: 0.0026 - val_mae: 0.0394\n",
      "Epoch 98/100\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0059 - mae: 0.0574 - val_loss: 0.0036 - val_mae: 0.0497\n",
      "Epoch 99/100\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0059 - mae: 0.0577 - val_loss: 0.0027 - val_mae: 0.0402\n",
      "Epoch 100/100\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 0.0057 - mae: 0.0563 - val_loss: 0.0023 - val_mae: 0.0362\n",
      "\u001b[1m296/296\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step\n",
      "✅ Done: onion_Haveri_daily.csv | MAE=322.02, RMSE=431.95, R2=0.64, MAPE=27.0%, Accuracy=73.0%\n",
      "🚀 Processing: onion_Kolar_daily.csv\n",
      "Epoch 1/100\n",
      "\u001b[1m1943/1943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 12ms/step - loss: 0.0911 - mae: 0.1145 - val_loss: 8.3291e-04 - val_mae: 0.0195\n",
      "Epoch 2/100\n",
      "\u001b[1m1943/1943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 12ms/step - loss: 0.0019 - mae: 0.0318 - val_loss: 0.0010 - val_mae: 0.0215\n",
      "Epoch 3/100\n",
      "\u001b[1m1943/1943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 12ms/step - loss: 0.0015 - mae: 0.0273 - val_loss: 8.3999e-04 - val_mae: 0.0212\n",
      "Epoch 4/100\n",
      "\u001b[1m1943/1943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 12ms/step - loss: 0.0014 - mae: 0.0266 - val_loss: 8.0529e-04 - val_mae: 0.0193\n",
      "Epoch 5/100\n",
      "\u001b[1m1943/1943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - loss: 0.0014 - mae: 0.0254 - val_loss: 7.5793e-04 - val_mae: 0.0185\n",
      "Epoch 6/100\n",
      "\u001b[1m1943/1943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 12ms/step - loss: 0.0013 - mae: 0.0249 - val_loss: 9.2623e-04 - val_mae: 0.0230\n",
      "Epoch 7/100\n",
      "\u001b[1m1943/1943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 16ms/step - loss: 0.0013 - mae: 0.0238 - val_loss: 6.5337e-04 - val_mae: 0.0173\n",
      "Epoch 16/100\n",
      "\u001b[1m1943/1943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 16ms/step - loss: 0.0011 - mae: 0.0230 - val_loss: 9.2467e-04 - val_mae: 0.0222\n",
      "Epoch 17/100\n",
      "\u001b[1m1943/1943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 14ms/step - loss: 0.0012 - mae: 0.0229 - val_loss: 6.4705e-04 - val_mae: 0.0171\n",
      "Epoch 23/100\n",
      "\u001b[1m1943/1943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 14ms/step - loss: 0.0012 - mae: 0.0229 - val_loss: 6.3850e-04 - val_mae: 0.0169\n",
      "Epoch 24/100\n",
      "\u001b[1m1943/1943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 14ms/step - loss: 0.0012 - mae: 0.0227 - val_loss: 6.5376e-04 - val_mae: 0.0172\n",
      "Epoch 25/100\n",
      "\u001b[1m1943/1943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 12ms/step - loss: 0.0012 - mae: 0.0229 - val_loss: 7.9085e-04 - val_mae: 0.0197\n",
      "Epoch 34/100\n",
      "\u001b[1m1943/1943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 12ms/step - loss: 0.0012 - mae: 0.0229 - val_loss: 6.7978e-04 - val_mae: 0.0176\n",
      "Epoch 35/100\n",
      "\u001b[1m1943/1943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 12ms/step - loss: 0.0011 - mae: 0.0226 - val_loss: 8.0518e-04 - val_mae: 0.0198\n",
      "Epoch 36/100\n",
      "\u001b[1m1943/1943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 15ms/step - loss: 0.0011 - mae: 0.0229 - val_loss: 8.7588e-04 - val_mae: 0.0205\n",
      "Epoch 41/100\n",
      "\u001b[1m1943/1943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 14ms/step - loss: 0.0011 - mae: 0.0224 - val_loss: 0.0010 - val_mae: 0.0228\n",
      "Epoch 42/100\n",
      "\u001b[1m1943/1943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 14ms/step - loss: 0.0011 - mae: 0.0227 - val_loss: 6.9254e-04 - val_mae: 0.0178\n",
      "Epoch 50/100\n",
      "\u001b[1m1943/1943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 14ms/step - loss: 0.0011 - mae: 0.0226 - val_loss: 6.7905e-04 - val_mae: 0.0178\n",
      "Epoch 51/100\n",
      "\u001b[1m1943/1943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 14ms/step - loss: 0.0011 - mae: 0.0224 - val_loss: 6.8878e-04 - val_mae: 0.0176\n",
      "Epoch 61/100\n",
      "\u001b[1m1943/1943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 15ms/step - loss: 0.0012 - mae: 0.0230 - val_loss: 6.4357e-04 - val_mae: 0.0170\n",
      "Epoch 62/100\n",
      "\u001b[1m1943/1943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 14ms/step - loss: 0.0011 - mae: 0.0224 - val_loss: 6.8275e-04 - val_mae: 0.0176\n",
      "Epoch 63/100\n",
      "\u001b[1m1943/1943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - loss: 0.0011 - mae: 0.0226 - val_loss: 6.4229e-04 - val_mae: 0.0170\n",
      "Epoch 73/100\n",
      "\u001b[1m1943/1943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0228 - val_loss: 8.0047e-04 - val_mae: 0.0192\n",
      "Epoch 74/100\n",
      "\u001b[1m1943/1943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - loss: 0.0011 - mae: 0.0224 - val_loss: 9.2673e-04 - val_mae: 0.0210\n",
      "Epoch 75/100\n",
      "\u001b[1m1943/1943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0228 - val_loss: 6.5702e-04 - val_mae: 0.0172\n",
      "Epoch 76/100\n",
      "\u001b[1m1943/1943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0229 - val_loss: 7.4072e-04 - val_mae: 0.0184\n",
      "Epoch 77/100\n",
      "\u001b[1m1943/1943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - loss: 0.0011 - mae: 0.0223 - val_loss: 8.2796e-04 - val_mae: 0.0194\n",
      "Epoch 84/100\n",
      "\u001b[1m1943/1943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - loss: 0.0011 - mae: 0.0226 - val_loss: 8.3468e-04 - val_mae: 0.0196\n",
      "Epoch 85/100\n",
      "\u001b[1m1943/1943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - loss: 0.0011 - mae: 0.0227 - val_loss: 6.4574e-04 - val_mae: 0.0171\n",
      "Epoch 86/100\n",
      "\u001b[1m1943/1943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0229 - val_loss: 7.8489e-04 - val_mae: 0.0190\n",
      "Epoch 87/100\n",
      "\u001b[1m1943/1943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - loss: 0.0011 - mae: 0.0225 - val_loss: 7.1240e-04 - val_mae: 0.0181\n",
      "Epoch 88/100\n",
      "\u001b[1m1943/1943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - loss: 0.0011 - mae: 0.0228 - val_loss: 7.1669e-04 - val_mae: 0.0182\n",
      "Epoch 95/100\n",
      "\u001b[1m1943/1943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0228 - val_loss: 7.2950e-04 - val_mae: 0.0183\n",
      "Epoch 96/100\n",
      "\u001b[1m1943/1943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - loss: 0.0011 - mae: 0.0226 - val_loss: 6.8525e-04 - val_mae: 0.0177\n",
      "Epoch 97/100\n",
      "\u001b[1m1943/1943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - loss: 0.0011 - mae: 0.0224 - val_loss: 6.6153e-04 - val_mae: 0.0173\n",
      "Epoch 98/100\n",
      "\u001b[1m1943/1943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0227 - val_loss: 7.3090e-04 - val_mae: 0.0182\n",
      "Epoch 99/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0032 - mae: 0.0359 - val_loss: 0.0050 - val_mae: 0.0704\n",
      "Epoch 28/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0036 - mae: 0.0366 - val_loss: 0.0035 - val_mae: 0.0588\n",
      "Epoch 29/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0034 - mae: 0.0334 - val_loss: 0.0057 - val_mae: 0.0756\n",
      "Epoch 30/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0036 - mae: 0.0360 - val_loss: 0.0060 - val_mae: 0.0773\n",
      "Epoch 31/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0034 - mae: 0.0347 - val_loss: 0.0063 - val_mae: 0.0793\n",
      "Epoch 32/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0035 - mae: 0.0331 - val_loss: 0.0028 - val_mae: 0.0530\n",
      "Epoch 33/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0033 - mae: 0.0334 - val_loss: 0.0016 - val_mae: 0.0401\n",
      "Epoch 34/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0033 - mae: 0.0331 - val_loss: 0.0044 - val_mae: 0.0661\n",
      "Epoch 35/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0032 - mae: 0.0323 - val_loss: 0.0070 - val_mae: 0.0836\n",
      "Epoch 36/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0032 - mae: 0.0325 - val_loss: 0.0014 - val_mae: 0.0378\n",
      "Epoch 37/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0032 - mae: 0.0341 - val_loss: 0.0034 - val_mae: 0.0580\n",
      "Epoch 38/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0032 - mae: 0.0325 - val_loss: 0.0026 - val_mae: 0.0507\n",
      "Epoch 39/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0033 - mae: 0.0325 - val_loss: 0.0026 - val_mae: 0.0510\n",
      "Epoch 40/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0029 - mae: 0.0305 - val_loss: 0.0016 - val_mae: 0.0391\n",
      "Epoch 41/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0038 - mae: 0.0381 - val_loss: 0.0020 - val_mae: 0.0449\n",
      "Epoch 42/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0031 - mae: 0.0314 - val_loss: 5.9585e-04 - val_mae: 0.0242\n",
      "Epoch 43/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0034 - mae: 0.0370 - val_loss: 0.0046 - val_mae: 0.0677\n",
      "Epoch 44/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0031 - mae: 0.0309 - val_loss: 0.0016 - val_mae: 0.0402\n",
      "Epoch 45/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0028 - mae: 0.0299 - val_loss: 0.0042 - val_mae: 0.0647\n",
      "Epoch 46/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0033 - mae: 0.0327 - val_loss: 0.0019 - val_mae: 0.0436\n",
      "Epoch 47/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0032 - mae: 0.0336 - val_loss: 0.0016 - val_mae: 0.0393\n",
      "Epoch 48/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0032 - mae: 0.0328 - val_loss: 0.0038 - val_mae: 0.0613\n",
      "Epoch 49/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0031 - mae: 0.0319 - val_loss: 0.0018 - val_mae: 0.0420\n",
      "Epoch 50/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0033 - mae: 0.0327 - val_loss: 0.0024 - val_mae: 0.0492\n",
      "Epoch 51/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0030 - mae: 0.0315 - val_loss: 0.0065 - val_mae: 0.0800\n",
      "Epoch 52/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0032 - mae: 0.0339 - val_loss: 0.0115 - val_mae: 0.1067\n",
      "Epoch 53/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0032 - mae: 0.0327 - val_loss: 0.0097 - val_mae: 0.0978\n",
      "Epoch 54/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0030 - mae: 0.0309 - val_loss: 0.0048 - val_mae: 0.0687\n",
      "Epoch 55/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0030 - mae: 0.0315 - val_loss: 0.0044 - val_mae: 0.0662\n",
      "Epoch 56/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0029 - mae: 0.0318 - val_loss: 0.0012 - val_mae: 0.0345\n",
      "Epoch 57/100\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0030 - mae: 0.0317 - val_loss: 0.0019 - val_mae: 0.0430\n",
      "Epoch 58/100\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - loss: 0.0432 - mae: 0.1209 - val_loss: 0.0068 - val_mae: 0.0705\n",
      "Epoch 2/100\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0047 - mae: 0.0554 - val_loss: 0.0040 - val_mae: 0.0561\n",
      "Epoch 3/100\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0043 - mae: 0.0536 - val_loss: 0.0037 - val_mae: 0.0521\n",
      "Epoch 4/100\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0041 - mae: 0.0532 - val_loss: 0.0038 - val_mae: 0.0539\n",
      "Epoch 5/100\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.0041 - mae: 0.0522 - val_loss: 0.0037 - val_mae: 0.0533\n",
      "Epoch 6/100\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0039 - mae: 0.0523 - val_loss: 0.0035 - val_mae: 0.0482\n",
      "Epoch 7/100\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.0039 - mae: 0.0516 - val_loss: 0.0037 - val_mae: 0.0530\n",
      "Epoch 8/100\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0040 - mae: 0.0521 - val_loss: 0.0037 - val_mae: 0.0479\n",
      "Epoch 9/100\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0039 - mae: 0.0513 - val_loss: 0.0034 - val_mae: 0.0489\n",
      "Epoch 10/100\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0037 - mae: 0.0508 - val_loss: 0.0041 - val_mae: 0.0568\n",
      "Epoch 11/100\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0040 - mae: 0.0517 - val_loss: 0.0035 - val_mae: 0.0513\n",
      "Epoch 12/100\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0037 - mae: 0.0505 - val_loss: 0.0036 - val_mae: 0.0529\n",
      "Epoch 31/100\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0036 - mae: 0.0498 - val_loss: 0.0033 - val_mae: 0.0484\n",
      "Epoch 32/100\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0038 - mae: 0.0506 - val_loss: 0.0036 - val_mae: 0.0531\n",
      "Epoch 33/100\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0036 - mae: 0.0506 - val_loss: 0.0032 - val_mae: 0.0474\n",
      "Epoch 34/100\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0036 - mae: 0.0503 - val_loss: 0.0032 - val_mae: 0.0483\n",
      "Epoch 35/100\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0037 - mae: 0.0506 - val_loss: 0.0034 - val_mae: 0.0472\n",
      "Epoch 36/100\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0037 - mae: 0.0509 - val_loss: 0.0032 - val_mae: 0.0473\n",
      "Epoch 37/100\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0036 - mae: 0.0500 - val_loss: 0.0032 - val_mae: 0.0471\n",
      "Epoch 38/100\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0037 - mae: 0.0508 - val_loss: 0.0033 - val_mae: 0.0503\n",
      "Epoch 39/100\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0037 - mae: 0.0502 - val_loss: 0.0034 - val_mae: 0.0512\n",
      "Epoch 40/100\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0038 - mae: 0.0505 - val_loss: 0.0034 - val_mae: 0.0472\n",
      "Epoch 41/100\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0037 - mae: 0.0509 - val_loss: 0.0034 - val_mae: 0.0473\n",
      "Epoch 42/100\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0037 - mae: 0.0506 - val_loss: 0.0033 - val_mae: 0.0470\n",
      "Epoch 62/100\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0035 - mae: 0.0503 - val_loss: 0.0033 - val_mae: 0.0479\n",
      "Epoch 63/100\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0036 - mae: 0.0506 - val_loss: 0.0032 - val_mae: 0.0487\n",
      "Epoch 64/100\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0036 - mae: 0.0501 - val_loss: 0.0035 - val_mae: 0.0520\n",
      "Epoch 65/100\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0037 - mae: 0.0504 - val_loss: 0.0032 - val_mae: 0.0473\n",
      "Epoch 66/100\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0037 - mae: 0.0505 - val_loss: 0.0035 - val_mae: 0.0515\n",
      "Epoch 67/100\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0037 - mae: 0.0508 - val_loss: 0.0033 - val_mae: 0.0500\n",
      "Epoch 68/100\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0037 - mae: 0.0507 - val_loss: 0.0032 - val_mae: 0.0489\n",
      "Epoch 69/100\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0038 - mae: 0.0507 - val_loss: 0.0033 - val_mae: 0.0472\n",
      "Epoch 70/100\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0036 - mae: 0.0505 - val_loss: 0.0032 - val_mae: 0.0479\n",
      "Epoch 71/100\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0036 - mae: 0.0503 - val_loss: 0.0033 - val_mae: 0.0502\n",
      "Epoch 72/100\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.0035 - mae: 0.0503 - val_loss: 0.0033 - val_mae: 0.0495\n",
      "Epoch 73/100\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0037 - mae: 0.0508 - val_loss: 0.0032 - val_mae: 0.0475\n",
      "Epoch 94/100\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0036 - mae: 0.0494 - val_loss: 0.0033 - val_mae: 0.0472\n",
      "Epoch 95/100\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0036 - mae: 0.0508 - val_loss: 0.0032 - val_mae: 0.0486\n",
      "Epoch 96/100\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0037 - mae: 0.0504 - val_loss: 0.0033 - val_mae: 0.0496\n",
      "Epoch 97/100\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0035 - mae: 0.0495 - val_loss: 0.0032 - val_mae: 0.0482\n",
      "Epoch 98/100\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0038 - mae: 0.0509 - val_loss: 0.0032 - val_mae: 0.0483\n",
      "Epoch 99/100\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.0040 - mae: 0.0509 - val_loss: 0.0032 - val_mae: 0.0491\n",
      "Epoch 100/100\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0036 - mae: 0.0506 - val_loss: 0.0034 - val_mae: 0.0508\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step\n",
      "✅ Done: onion_Mandya_daily.csv | MAE=494.2, RMSE=617.93, R2=0.31, MAPE=39.59%, Accuracy=60.41%\n",
      "🚀 Processing: onion_MangaloreDakshin_Kannad_daily.csv\n",
      "Epoch 1/100\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 15ms/step - loss: 0.0514 - mae: 0.1432 - val_loss: 0.0276 - val_mae: 0.1489\n",
      "Epoch 2/100\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0064 - mae: 0.0624 - val_loss: 0.0177 - val_mae: 0.1133\n",
      "Epoch 3/100\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0041 - mae: 0.0479 - val_loss: 0.0128 - val_mae: 0.0831\n",
      "Epoch 4/100\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0035 - mae: 0.0447 - val_loss: 0.0145 - val_mae: 0.0987\n",
      "Epoch 5/100\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0028 - mae: 0.0392 - val_loss: 0.0138 - val_mae: 0.0979\n",
      "Epoch 6/100\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0028 - mae: 0.0381 - val_loss: 0.0142 - val_mae: 0.1007\n",
      "Epoch 7/100\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 7.1531e-04 - mae: 0.0153 - val_loss: 0.0169 - val_mae: 0.0698\n",
      "Epoch 61/100\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 7.7184e-04 - mae: 0.0157 - val_loss: 0.0151 - val_mae: 0.0687\n",
      "Epoch 62/100\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 6.8882e-04 - mae: 0.0140 - val_loss: 0.0152 - val_mae: 0.0731\n",
      "Epoch 63/100\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 7.7026e-04 - mae: 0.0163 - val_loss: 0.0158 - val_mae: 0.0700\n",
      "Epoch 64/100\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 6.9169e-04 - mae: 0.0149 - val_loss: 0.0170 - val_mae: 0.0721\n",
      "Epoch 65/100\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 7.4507e-04 - mae: 0.0164 - val_loss: 0.0170 - val_mae: 0.0731\n",
      "Epoch 66/100\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 6.8345e-04 - mae: 0.0150 - val_loss: 0.0160 - val_mae: 0.0712\n",
      "Epoch 67/100\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 6.1964e-04 - mae: 0.0142 - val_loss: 0.0181 - val_mae: 0.0709\n",
      "Epoch 68/100\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 7.9653e-04 - mae: 0.0172 - val_loss: 0.0200 - val_mae: 0.0769\n",
      "Epoch 69/100\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 7.7131e-04 - mae: 0.0154 - val_loss: 0.0170 - val_mae: 0.0714\n",
      "Epoch 70/100\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 7.2629e-04 - mae: 0.0150 - val_loss: 0.0172 - val_mae: 0.0758\n",
      "Epoch 71/100\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 7.3841e-04 - mae: 0.0153 - val_loss: 0.0186 - val_mae: 0.0749\n",
      "Epoch 72/100\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 6.0392e-04 - mae: 0.0136 - val_loss: 0.0182 - val_mae: 0.0719\n",
      "Epoch 73/100\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 6.9199e-04 - mae: 0.0154 - val_loss: 0.0171 - val_mae: 0.0727\n",
      "Epoch 74/100\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 8.9503e-04 - mae: 0.0151 - val_loss: 0.0170 - val_mae: 0.0732\n",
      "Epoch 75/100\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 7.1102e-04 - mae: 0.0145 - val_loss: 0.0161 - val_mae: 0.0678\n",
      "Epoch 76/100\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 8.7471e-04 - mae: 0.0168 - val_loss: 0.0183 - val_mae: 0.0720\n",
      "Epoch 77/100\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 7.9151e-04 - mae: 0.0156 - val_loss: 0.0192 - val_mae: 0.0759\n",
      "Epoch 78/100\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 7.5405e-04 - mae: 0.0146 - val_loss: 0.0176 - val_mae: 0.0741\n",
      "Epoch 79/100\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 7.9201e-04 - mae: 0.0176 - val_loss: 0.0191 - val_mae: 0.0732\n",
      "Epoch 80/100\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 7.0637e-04 - mae: 0.0141 - val_loss: 0.0185 - val_mae: 0.0748\n",
      "Epoch 81/100\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 8.2141e-04 - mae: 0.0177 - val_loss: 0.0176 - val_mae: 0.0768\n",
      "Epoch 82/100\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 6.9433e-04 - mae: 0.0145 - val_loss: 0.0183 - val_mae: 0.0743\n",
      "Epoch 83/100\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 5.9331e-04 - mae: 0.0137 - val_loss: 0.0189 - val_mae: 0.0753\n",
      "Epoch 84/100\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 7.4770e-04 - mae: 0.0158 - val_loss: 0.0179 - val_mae: 0.0730\n",
      "Epoch 85/100\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 6.2755e-04 - mae: 0.0135 - val_loss: 0.0186 - val_mae: 0.0725\n",
      "Epoch 86/100\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 7.2705e-04 - mae: 0.0140 - val_loss: 0.0201 - val_mae: 0.0784\n",
      "Epoch 87/100\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 5.7390e-04 - mae: 0.0128 - val_loss: 0.0195 - val_mae: 0.0737\n",
      "Epoch 88/100\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 6.5808e-04 - mae: 0.0147 - val_loss: 0.0184 - val_mae: 0.0745\n",
      "Epoch 89/100\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 6.4227e-04 - mae: 0.0141 - val_loss: 0.0208 - val_mae: 0.0833\n",
      "Epoch 90/100\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 7.1654e-04 - mae: 0.0149 - val_loss: 0.0169 - val_mae: 0.0699\n",
      "Epoch 91/100\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 7.3502e-04 - mae: 0.0160 - val_loss: 0.0184 - val_mae: 0.0736\n",
      "Epoch 92/100\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 7.0544e-04 - mae: 0.0142 - val_loss: 0.0164 - val_mae: 0.0691\n",
      "Epoch 93/100\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 6.4280e-04 - mae: 0.0137 - val_loss: 0.0206 - val_mae: 0.0752\n",
      "Epoch 94/100\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 6.7405e-04 - mae: 0.0151 - val_loss: 0.0201 - val_mae: 0.0779\n",
      "Epoch 95/100\n",
      "\u001b[1m901/901\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0235 - val_loss: 9.2232e-04 - val_mae: 0.0204\n",
      "Epoch 15/100\n",
      "\u001b[1m901/901\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0011 - mae: 0.0236 - val_loss: 9.0052e-04 - val_mae: 0.0202\n",
      "Epoch 16/100\n",
      "\u001b[1m901/901\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0011 - mae: 0.0234 - val_loss: 8.9025e-04 - val_mae: 0.0201\n",
      "Epoch 17/100\n",
      "\u001b[1m901/901\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - loss: 0.0012 - mae: 0.0237 - val_loss: 9.5684e-04 - val_mae: 0.0209\n",
      "Epoch 18/100\n",
      "\u001b[1m901/901\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0011 - mae: 0.0232 - val_loss: 8.7732e-04 - val_mae: 0.0198\n",
      "Epoch 19/100\n",
      "\u001b[1m901/901\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - loss: 9.9773e-04 - mae: 0.0235 - val_loss: 8.6948e-04 - val_mae: 0.0198\n",
      "Epoch 20/100\n",
      "\u001b[1m901/901\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0010 - mae: 0.0232 - val_loss: 8.4840e-04 - val_mae: 0.0195\n",
      "Epoch 21/100\n",
      "\u001b[1m901/901\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 8.9931e-04 - mae: 0.0229 - val_loss: 8.5836e-04 - val_mae: 0.0196\n",
      "Epoch 22/100\n",
      "\u001b[1m901/901\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 9.5182e-04 - mae: 0.0230 - val_loss: 8.4200e-04 - val_mae: 0.0195\n",
      "Epoch 23/100\n",
      "\u001b[1m901/901\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - loss: 0.0011 - mae: 0.0229 - val_loss: 8.7587e-04 - val_mae: 0.0200\n",
      "Epoch 42/100\n",
      "\u001b[1m901/901\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 8.7053e-04 - mae: 0.0225 - val_loss: 8.4437e-04 - val_mae: 0.0195\n",
      "Epoch 43/100\n",
      "\u001b[1m901/901\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 9.0495e-04 - mae: 0.0226 - val_loss: 8.9287e-04 - val_mae: 0.0201\n",
      "Epoch 44/100\n",
      "\u001b[1m901/901\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 9.3309e-04 - mae: 0.0228 - val_loss: 8.5186e-04 - val_mae: 0.0197\n",
      "Epoch 45/100\n",
      "\u001b[1m901/901\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 9.1900e-04 - mae: 0.0223 - val_loss: 8.6920e-04 - val_mae: 0.0198\n",
      "Epoch 46/100\n",
      "\u001b[1m901/901\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 9.2599e-04 - mae: 0.0226 - val_loss: 8.4170e-04 - val_mae: 0.0195\n",
      "Epoch 47/100\n",
      "\u001b[1m901/901\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0011 - mae: 0.0229 - val_loss: 8.4684e-04 - val_mae: 0.0195\n",
      "Epoch 48/100\n",
      "\u001b[1m901/901\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 9.4877e-04 - mae: 0.0231 - val_loss: 8.4287e-04 - val_mae: 0.0195\n",
      "Epoch 49/100\n",
      "\u001b[1m901/901\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 9.0471e-04 - mae: 0.0225 - val_loss: 8.4166e-04 - val_mae: 0.0195\n",
      "Epoch 66/100\n",
      "\u001b[1m901/901\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 9.0756e-04 - mae: 0.0223 - val_loss: 8.9491e-04 - val_mae: 0.0203\n",
      "Epoch 67/100\n",
      "\u001b[1m901/901\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 8.8392e-04 - mae: 0.0225 - val_loss: 9.3701e-04 - val_mae: 0.0206\n",
      "Epoch 68/100\n",
      "\u001b[1m901/901\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 8.6249e-04 - mae: 0.0221 - val_loss: 8.6202e-04 - val_mae: 0.0198\n",
      "Epoch 69/100\n",
      "\u001b[1m901/901\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 9.7711e-04 - mae: 0.0228 - val_loss: 8.6776e-04 - val_mae: 0.0197\n",
      "Epoch 70/100\n",
      "\u001b[1m901/901\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 9.1183e-04 - mae: 0.0224 - val_loss: 8.4389e-04 - val_mae: 0.0196\n",
      "Epoch 71/100\n",
      "\u001b[1m901/901\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 8.6990e-04 - mae: 0.0226 - val_loss: 8.7451e-04 - val_mae: 0.0202\n",
      "Epoch 72/100\n",
      "\u001b[1m901/901\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 9.2060e-04 - mae: 0.0224 - val_loss: 8.5133e-04 - val_mae: 0.0196\n",
      "Epoch 73/100\n",
      "\u001b[1m901/901\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - loss: 9.1070e-04 - mae: 0.0226 - val_loss: 8.4835e-04 - val_mae: 0.0195\n",
      "Epoch 91/100\n",
      "\u001b[1m901/901\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 9.3898e-04 - mae: 0.0225 - val_loss: 8.4325e-04 - val_mae: 0.0195\n",
      "Epoch 92/100\n",
      "\u001b[1m901/901\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 9.7081e-04 - mae: 0.0228 - val_loss: 9.1871e-04 - val_mae: 0.0204\n",
      "Epoch 93/100\n",
      "\u001b[1m901/901\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 8.5376e-04 - mae: 0.0222 - val_loss: 8.5235e-04 - val_mae: 0.0195\n",
      "Epoch 94/100\n",
      "\u001b[1m901/901\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 9.3778e-04 - mae: 0.0223 - val_loss: 8.4638e-04 - val_mae: 0.0197\n",
      "Epoch 95/100\n",
      "\u001b[1m901/901\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 9.3544e-04 - mae: 0.0226 - val_loss: 8.5377e-04 - val_mae: 0.0198\n",
      "Epoch 96/100\n",
      "\u001b[1m901/901\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 9.8268e-04 - mae: 0.0226 - val_loss: 8.4918e-04 - val_mae: 0.0195\n",
      "Epoch 97/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0020 - mae: 0.0288 - val_loss: 7.3402e-04 - val_mae: 0.0198\n",
      "Epoch 37/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0020 - mae: 0.0288 - val_loss: 7.3216e-04 - val_mae: 0.0202\n",
      "Epoch 38/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0020 - mae: 0.0294 - val_loss: 8.0958e-04 - val_mae: 0.0211\n",
      "Epoch 39/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0020 - mae: 0.0292 - val_loss: 0.0013 - val_mae: 0.0310\n",
      "Epoch 40/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0284 - val_loss: 7.4963e-04 - val_mae: 0.0207\n",
      "Epoch 41/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0020 - mae: 0.0291 - val_loss: 7.0743e-04 - val_mae: 0.0191\n",
      "Epoch 42/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0278 - val_loss: 8.7432e-04 - val_mae: 0.0232\n",
      "Epoch 43/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0022 - mae: 0.0297 - val_loss: 8.1262e-04 - val_mae: 0.0212\n",
      "Epoch 44/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0274 - val_loss: 6.8898e-04 - val_mae: 0.0192\n",
      "Epoch 45/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0020 - mae: 0.0287 - val_loss: 0.0011 - val_mae: 0.0280\n",
      "Epoch 46/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0019 - mae: 0.0294 - val_loss: 7.2425e-04 - val_mae: 0.0203\n",
      "Epoch 47/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0021 - mae: 0.0300 - val_loss: 0.0011 - val_mae: 0.0264\n",
      "Epoch 48/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0279 - val_loss: 6.9739e-04 - val_mae: 0.0195\n",
      "Epoch 49/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0278 - val_loss: 6.8521e-04 - val_mae: 0.0197\n",
      "Epoch 50/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0019 - mae: 0.0287 - val_loss: 0.0011 - val_mae: 0.0258\n",
      "Epoch 51/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0021 - mae: 0.0284 - val_loss: 6.9096e-04 - val_mae: 0.0189\n",
      "Epoch 52/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0017 - mae: 0.0267 - val_loss: 0.0011 - val_mae: 0.0254\n",
      "Epoch 53/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0019 - mae: 0.0275 - val_loss: 6.7739e-04 - val_mae: 0.0195\n",
      "Epoch 54/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0274 - val_loss: 0.0012 - val_mae: 0.0291\n",
      "Epoch 55/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0019 - mae: 0.0284 - val_loss: 7.8571e-04 - val_mae: 0.0212\n",
      "Epoch 56/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0019 - mae: 0.0283 - val_loss: 7.6748e-04 - val_mae: 0.0208\n",
      "Epoch 57/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0288 - val_loss: 6.5170e-04 - val_mae: 0.0189\n",
      "Epoch 58/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0018 - mae: 0.0272 - val_loss: 7.3670e-04 - val_mae: 0.0200\n",
      "Epoch 59/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0019 - mae: 0.0282 - val_loss: 7.4735e-04 - val_mae: 0.0200\n",
      "Epoch 60/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0019 - mae: 0.0274 - val_loss: 0.0010 - val_mae: 0.0263\n",
      "Epoch 61/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0275 - val_loss: 7.4465e-04 - val_mae: 0.0199\n",
      "Epoch 62/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0019 - mae: 0.0279 - val_loss: 8.4575e-04 - val_mae: 0.0224\n",
      "Epoch 63/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0273 - val_loss: 7.3071e-04 - val_mae: 0.0200\n",
      "Epoch 64/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0275 - val_loss: 7.1794e-04 - val_mae: 0.0199\n",
      "Epoch 65/100\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0018 - mae: 0.0281 - val_loss: 7.8820e-04 - val_mae: 0.0211\n",
      "Epoch 66/100\n",
      "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0016 - mae: 0.0283 - val_loss: 0.0028 - val_mae: 0.0346\n",
      "Epoch 5/100\n",
      "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0268 - val_loss: 0.0030 - val_mae: 0.0355\n",
      "Epoch 6/100\n",
      "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0014 - mae: 0.0262 - val_loss: 0.0031 - val_mae: 0.0352\n",
      "Epoch 7/100\n",
      "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0014 - mae: 0.0261 - val_loss: 0.0030 - val_mae: 0.0383\n",
      "Epoch 8/100\n",
      "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0013 - mae: 0.0253 - val_loss: 0.0027 - val_mae: 0.0352\n",
      "Epoch 9/100\n",
      "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0013 - mae: 0.0252 - val_loss: 0.0032 - val_mae: 0.0357\n",
      "Epoch 10/100\n",
      "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0013 - mae: 0.0249 - val_loss: 0.0029 - val_mae: 0.0387\n",
      "Epoch 11/100\n",
      "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0013 - mae: 0.0257 - val_loss: 0.0026 - val_mae: 0.0329\n",
      "Epoch 12/100\n",
      "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0014 - mae: 0.0266 - val_loss: 0.0032 - val_mae: 0.0354\n",
      "Epoch 13/100\n",
      "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0013 - mae: 0.0245 - val_loss: 0.0029 - val_mae: 0.0342\n",
      "Epoch 14/100\n",
      "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0013 - mae: 0.0250 - val_loss: 0.0028 - val_mae: 0.0337\n",
      "Epoch 15/100\n",
      "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0013 - mae: 0.0249 - val_loss: 0.0026 - val_mae: 0.0336\n",
      "Epoch 16/100\n",
      "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0013 - mae: 0.0247 - val_loss: 0.0031 - val_mae: 0.0354\n",
      "Epoch 17/100\n",
      "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0012 - mae: 0.0237 - val_loss: 0.0025 - val_mae: 0.0324\n",
      "Epoch 18/100\n",
      "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0011 - mae: 0.0219 - val_loss: 0.0027 - val_mae: 0.0326\n",
      "Epoch 49/100\n",
      "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0012 - mae: 0.0223 - val_loss: 0.0026 - val_mae: 0.0317\n",
      "Epoch 50/100\n",
      "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0012 - mae: 0.0224 - val_loss: 0.0026 - val_mae: 0.0323\n",
      "Epoch 51/100\n",
      "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0012 - mae: 0.0223 - val_loss: 0.0027 - val_mae: 0.0319\n",
      "Epoch 52/100\n",
      "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0012 - mae: 0.0221 - val_loss: 0.0026 - val_mae: 0.0325\n",
      "Epoch 53/100\n",
      "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0012 - mae: 0.0223 - val_loss: 0.0026 - val_mae: 0.0325\n",
      "Epoch 54/100\n",
      "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0012 - mae: 0.0222 - val_loss: 0.0026 - val_mae: 0.0322\n",
      "Epoch 55/100\n",
      "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0012 - mae: 0.0220 - val_loss: 0.0026 - val_mae: 0.0327\n",
      "Epoch 56/100\n",
      "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0011 - mae: 0.0221 - val_loss: 0.0028 - val_mae: 0.0342\n",
      "Epoch 57/100\n",
      "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0011 - mae: 0.0221 - val_loss: 0.0028 - val_mae: 0.0325\n",
      "Epoch 58/100\n",
      "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0012 - mae: 0.0225 - val_loss: 0.0026 - val_mae: 0.0320\n",
      "Epoch 59/100\n",
      "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0012 - mae: 0.0220 - val_loss: 0.0026 - val_mae: 0.0323\n",
      "Epoch 60/100\n",
      "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0011 - mae: 0.0218 - val_loss: 0.0027 - val_mae: 0.0333\n",
      "Epoch 61/100\n",
      "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0011 - mae: 0.0219 - val_loss: 0.0026 - val_mae: 0.0323\n",
      "Epoch 62/100\n",
      "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0012 - mae: 0.0220 - val_loss: 0.0027 - val_mae: 0.0323\n",
      "Epoch 63/100\n",
      "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0011 - mae: 0.0217 - val_loss: 0.0026 - val_mae: 0.0329\n",
      "Epoch 64/100\n",
      "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0011 - mae: 0.0217 - val_loss: 0.0027 - val_mae: 0.0323\n",
      "Epoch 65/100\n",
      "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0011 - mae: 0.0216 - val_loss: 0.0030 - val_mae: 0.0342\n",
      "Epoch 99/100\n",
      "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0012 - mae: 0.0221 - val_loss: 0.0029 - val_mae: 0.0331\n",
      "Epoch 100/100\n",
      "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0011 - mae: 0.0213 - val_loss: 0.0031 - val_mae: 0.0335\n",
      "\u001b[1m354/354\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n",
      "✅ Done: onion_Shimoga_daily.csv | MAE=382.74, RMSE=625.33, R2=0.58, MAPE=46.26%, Accuracy=53.74%\n",
      "🚀 Processing: onion_Tumkur_daily.csv\n",
      "Epoch 1/100\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - loss: 0.0833 - mae: 0.1507 - val_loss: 0.0592 - val_mae: 0.1977\n",
      "Epoch 2/100\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0043 - mae: 0.0519 - val_loss: 0.0588 - val_mae: 0.1976\n",
      "Epoch 3/100\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0031 - mae: 0.0435 - val_loss: 0.0611 - val_mae: 0.1984\n",
      "Epoch 4/100\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0028 - mae: 0.0414 - val_loss: 0.0604 - val_mae: 0.1983\n",
      "Epoch 5/100\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0028 - mae: 0.0407 - val_loss: 0.0562 - val_mae: 0.1970\n",
      "Epoch 6/100\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0028 - mae: 0.0412 - val_loss: 0.0628 - val_mae: 0.1992\n",
      "Epoch 7/100\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0392 - val_loss: 0.0630 - val_mae: 0.1995\n",
      "Epoch 8/100\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0026 - mae: 0.0396 - val_loss: 0.0545 - val_mae: 0.1973\n",
      "Epoch 9/100\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0026 - mae: 0.0391 - val_loss: 0.0537 - val_mae: 0.1974\n",
      "Epoch 10/100\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0023 - mae: 0.0364 - val_loss: 0.0462 - val_mae: 0.1988\n",
      "Epoch 33/100\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0022 - mae: 0.0360 - val_loss: 0.0468 - val_mae: 0.1981\n",
      "Epoch 34/100\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0022 - mae: 0.0361 - val_loss: 0.0469 - val_mae: 0.1993\n",
      "Epoch 35/100\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0023 - mae: 0.0364 - val_loss: 0.0462 - val_mae: 0.1987\n",
      "Epoch 36/100\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0023 - mae: 0.0362 - val_loss: 0.0473 - val_mae: 0.1996\n",
      "Epoch 37/100\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0023 - mae: 0.0362 - val_loss: 0.0463 - val_mae: 0.1987\n",
      "Epoch 38/100\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0022 - mae: 0.0356 - val_loss: 0.0467 - val_mae: 0.1982\n",
      "Epoch 39/100\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0022 - mae: 0.0363 - val_loss: 0.0468 - val_mae: 0.1994\n",
      "Epoch 40/100\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0023 - mae: 0.0361 - val_loss: 0.0463 - val_mae: 0.1988\n",
      "Epoch 41/100\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0022 - mae: 0.0359 - val_loss: 0.0463 - val_mae: 0.1988\n",
      "Epoch 42/100\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0023 - mae: 0.0365 - val_loss: 0.0463 - val_mae: 0.1987\n",
      "Epoch 43/100\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0022 - mae: 0.0356 - val_loss: 0.0483 - val_mae: 0.1982\n",
      "Epoch 74/100\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0022 - mae: 0.0356 - val_loss: 0.0495 - val_mae: 0.1980\n",
      "Epoch 75/100\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0023 - mae: 0.0362 - val_loss: 0.0478 - val_mae: 0.1985\n",
      "Epoch 76/100\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0022 - mae: 0.0359 - val_loss: 0.0513 - val_mae: 0.1978\n",
      "Epoch 77/100\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0022 - mae: 0.0354 - val_loss: 0.0486 - val_mae: 0.1983\n",
      "Epoch 78/100\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0021 - mae: 0.0352 - val_loss: 0.0541 - val_mae: 0.1977\n",
      "Epoch 79/100\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0023 - mae: 0.0361 - val_loss: 0.0489 - val_mae: 0.1982\n",
      "Epoch 80/100\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0022 - mae: 0.0356 - val_loss: 0.0486 - val_mae: 0.1982\n",
      "Epoch 81/100\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0022 - mae: 0.0359 - val_loss: 0.0483 - val_mae: 0.1985\n",
      "Epoch 82/100\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0022 - mae: 0.0352 - val_loss: 0.0511 - val_mae: 0.1977\n",
      "Epoch 83/100\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0021 - mae: 0.0353 - val_loss: 0.0492 - val_mae: 0.1982\n",
      "Epoch 84/100\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0022 - mae: 0.0357 - val_loss: 0.0482 - val_mae: 0.1986\n",
      "Epoch 85/100\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.1498 - mae: 0.2145 - val_loss: 0.0149 - val_mae: 0.1099\n",
      "Epoch 2/100\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0095 - mae: 0.0705 - val_loss: 0.0081 - val_mae: 0.0739\n",
      "Epoch 3/100\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0075 - mae: 0.0619 - val_loss: 0.0083 - val_mae: 0.0735\n",
      "Epoch 4/100\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0054 - mae: 0.0505 - val_loss: 0.0099 - val_mae: 0.0626\n",
      "Epoch 5/100\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0041 - mae: 0.0443 - val_loss: 0.0139 - val_mae: 0.0658\n",
      "Epoch 6/100\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0042 - mae: 0.0450 - val_loss: 0.0162 - val_mae: 0.0872\n",
      "Epoch 7/100\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0037 - mae: 0.0430 - val_loss: 0.0114 - val_mae: 0.0577\n",
      "Epoch 8/100\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0030 - mae: 0.0365 - val_loss: 0.0114 - val_mae: 0.0604\n",
      "Epoch 9/100\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0028 - mae: 0.0353 - val_loss: 0.0086 - val_mae: 0.0535\n",
      "Epoch 10/100\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0026 - mae: 0.0338 - val_loss: 0.0083 - val_mae: 0.0521\n",
      "Epoch 11/100\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0028 - mae: 0.0355 - val_loss: 0.0089 - val_mae: 0.0551\n",
      "Epoch 12/100\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0024 - mae: 0.0316 - val_loss: 0.0068 - val_mae: 0.0512\n",
      "Epoch 13/100\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0027 - mae: 0.0343 - val_loss: 0.0064 - val_mae: 0.0480\n",
      "Epoch 14/100\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0027 - mae: 0.0329 - val_loss: 0.0066 - val_mae: 0.0481\n",
      "Epoch 15/100\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0025 - mae: 0.0325 - val_loss: 0.0061 - val_mae: 0.0469\n",
      "Epoch 16/100\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0024 - mae: 0.0305 - val_loss: 0.0063 - val_mae: 0.0473\n",
      "Epoch 17/100\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0026 - mae: 0.0315 - val_loss: 0.0081 - val_mae: 0.0556\n",
      "Epoch 18/100\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0026 - mae: 0.0310 - val_loss: 0.0066 - val_mae: 0.0477\n",
      "Epoch 19/100\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0029 - mae: 0.0349 - val_loss: 0.0065 - val_mae: 0.0537\n",
      "Epoch 20/100\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0024 - mae: 0.0311 - val_loss: 0.0082 - val_mae: 0.0604\n",
      "Epoch 21/100\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0318 - val_loss: 0.0060 - val_mae: 0.0464\n",
      "Epoch 22/100\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0022 - mae: 0.0283 - val_loss: 0.0104 - val_mae: 0.0518\n",
      "Epoch 68/100\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0024 - mae: 0.0290 - val_loss: 0.0091 - val_mae: 0.0509\n",
      "Epoch 69/100\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0021 - mae: 0.0280 - val_loss: 0.0110 - val_mae: 0.0608\n",
      "Epoch 70/100\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0023 - mae: 0.0299 - val_loss: 0.0098 - val_mae: 0.0522\n",
      "Epoch 71/100\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0021 - mae: 0.0277 - val_loss: 0.0101 - val_mae: 0.0515\n",
      "Epoch 72/100\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0023 - mae: 0.0291 - val_loss: 0.0139 - val_mae: 0.0568\n",
      "Epoch 73/100\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0022 - mae: 0.0293 - val_loss: 0.0085 - val_mae: 0.0524\n",
      "Epoch 74/100\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0021 - mae: 0.0285 - val_loss: 0.0113 - val_mae: 0.0535\n",
      "Epoch 75/100\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0020 - mae: 0.0278 - val_loss: 0.0108 - val_mae: 0.0521\n",
      "Epoch 76/100\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0024 - mae: 0.0288 - val_loss: 0.0098 - val_mae: 0.0515\n",
      "Epoch 77/100\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0021 - mae: 0.0279 - val_loss: 0.0103 - val_mae: 0.0531\n",
      "Epoch 78/100\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0023 - mae: 0.0296 - val_loss: 0.0103 - val_mae: 0.0530\n",
      "Epoch 79/100\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0020 - mae: 0.0278 - val_loss: 0.0122 - val_mae: 0.0548\n",
      "Epoch 80/100\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0022 - mae: 0.0289 - val_loss: 0.0100 - val_mae: 0.0520\n",
      "Epoch 81/100\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0021 - mae: 0.0284 - val_loss: 0.0089 - val_mae: 0.0511\n",
      "Epoch 82/100\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0021 - mae: 0.0276 - val_loss: 0.0102 - val_mae: 0.0519\n",
      "Epoch 83/100\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0022 - mae: 0.0291 - val_loss: 0.0102 - val_mae: 0.0524\n",
      "Epoch 84/100\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0020 - mae: 0.0282 - val_loss: 0.0097 - val_mae: 0.0515\n",
      "Epoch 85/100\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0021 - mae: 0.0282 - val_loss: 0.0101 - val_mae: 0.0515\n",
      "Epoch 86/100\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0022 - mae: 0.0285 - val_loss: 0.0159 - val_mae: 0.0612\n",
      "Epoch 87/100\n",
      "\u001b[1m144/355\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0019 - mae: 0.0273"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "import joblib  # For saving models as .pkl\n",
    "\n",
    "# -----------------------------\n",
    "# Suppress Warnings\n",
    "# -----------------------------\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "pd.options.mode.chained_assignment = None  # Avoid SettingWithCopyWarning\n",
    "\n",
    "# -----------------------------\n",
    "# Output directories\n",
    "# -----------------------------\n",
    "input_folder = \"dataset\"\n",
    "output_models = \"tat_gqa_output_models\"\n",
    "output_csv = \"tat_gqa_output_csv\"\n",
    "output_graphs = \"tat_gqa_output_graphs\"\n",
    "output_logs = \"tat_gqa_output_logs\"\n",
    "metrics_file = \"tat_gqa_metrics.csv\"\n",
    "\n",
    "for folder in [output_models, output_csv, output_graphs, output_logs]:\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Function to create dataset\n",
    "# -----------------------------\n",
    "def create_dataset(data, look_back=30):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - look_back):\n",
    "        X.append(data[i:i + look_back, 0])\n",
    "        y.append(data[i + look_back, 0])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# -----------------------------\n",
    "# Grouped Query Attention Layer\n",
    "# -----------------------------\n",
    "class GroupedQueryAttention(layers.Layer):\n",
    "    def __init__(self, num_groups=2, key_dim=64, dropout_rate=0.1, **kwargs):\n",
    "        super(GroupedQueryAttention, self).__init__(**kwargs)\n",
    "        self.num_groups = num_groups\n",
    "        self.key_dim = key_dim\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.k_dense = layers.Dense(key_dim)\n",
    "        self.v_dense = layers.Dense(key_dim)\n",
    "        self.q_dense_groups = [layers.Dense(key_dim) for _ in range(num_groups)]\n",
    "        self.dropout = layers.Dropout(dropout_rate)\n",
    "        self.output_dense = layers.Dense(key_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        K = self.k_dense(x)\n",
    "        V = self.v_dense(x)\n",
    "        group_outputs = []\n",
    "        for q_layer in self.q_dense_groups:\n",
    "            Q = q_layer(x)\n",
    "            scores = tf.matmul(Q, K, transpose_b=True) / tf.math.sqrt(tf.cast(self.key_dim, tf.float32))\n",
    "            attention_weights = tf.nn.softmax(scores, axis=-1)\n",
    "            attn_output = tf.matmul(attention_weights, V)\n",
    "            group_outputs.append(attn_output)\n",
    "        concat = tf.concat(group_outputs, axis=-1)\n",
    "        output = self.output_dense(concat)\n",
    "        output = self.dropout(output)\n",
    "        return output\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(GroupedQueryAttention, self).get_config()\n",
    "        config.update({\n",
    "            \"num_groups\": self.num_groups,\n",
    "            \"key_dim\": self.key_dim,\n",
    "            \"dropout_rate\": self.dropout_rate\n",
    "        })\n",
    "        return config\n",
    "\n",
    "# -----------------------------\n",
    "# TAT-GQA Model\n",
    "# -----------------------------\n",
    "def build_tat_gqa_model(input_shape, d_model=64, num_groups=2, ff_dim=128, dropout_rate=0.2):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = GroupedQueryAttention(num_groups=num_groups, key_dim=d_model, dropout_rate=dropout_rate)(inputs)\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x + inputs)\n",
    "    ff = layers.Dense(ff_dim, activation='relu')(x)\n",
    "    ff = layers.Dense(input_shape[1])(ff)\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x + ff)\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    outputs = layers.Dense(1)(x)\n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=0.001),\n",
    "                  loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# -----------------------------\n",
    "# Metrics storage\n",
    "# -----------------------------\n",
    "metrics_list = []\n",
    "\n",
    "# -----------------------------\n",
    "# Training Configuration\n",
    "# -----------------------------\n",
    "look_back = 30\n",
    "epochs = 100\n",
    "batch_size = 16\n",
    "\n",
    "# -----------------------------\n",
    "# Process each CSV file\n",
    "# -----------------------------\n",
    "for file in os.listdir(input_folder):\n",
    "    if not file.endswith(\".csv\"):\n",
    "        continue\n",
    "\n",
    "    file_path = os.path.join(input_folder, file)\n",
    "    print(f\"🚀 Processing: {file}\")\n",
    "\n",
    "    # Load CSV\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to read {file}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Parse dates safely (no infer_datetime_format)\n",
    "    df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "    df = df.dropna(subset=['Date']).sort_values('Date')\n",
    "\n",
    "    # Check if column exists\n",
    "    if 'Average Price' not in df.columns:\n",
    "        print(f\"⚠️ Skipping {file}: 'Average Price' column not found.\")\n",
    "        continue\n",
    "\n",
    "    # Handle missing price values\n",
    "    df['Average Price'] = df['Average Price'].fillna(df['Average Price'].mean())\n",
    "\n",
    "    # Moving averages (for visualization only)\n",
    "    df['MA_7'] = df['Average Price'].rolling(window=7).mean().fillna(df['Average Price'].mean())\n",
    "    df['MA_30'] = df['Average Price'].rolling(window=30).mean().fillna(df['Average Price'].mean())\n",
    "\n",
    "    # Prepare scaled data\n",
    "    values = df[['Average Price']].astype('float32').values\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_values = scaler.fit_transform(values)\n",
    "    X, y = create_dataset(scaled_values, look_back)\n",
    "    X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
    "\n",
    "    # Build and train model\n",
    "    model = build_tat_gqa_model(input_shape=(look_back, 1))\n",
    "    history = model.fit(\n",
    "        X, y,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_split=0.2,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Save training log\n",
    "    log_file = os.path.join(output_logs, file.replace(\".csv\", \"_tat_gqa_training.txt\"))\n",
    "    with open(log_file, \"w\") as f:\n",
    "        f.write(\"Epoch\\tLoss\\tVal_Loss\\n\")\n",
    "        for i in range(len(history.history['loss'])):\n",
    "            f.write(f\"{i+1}\\t{history.history['loss'][i]:.6f}\\t{history.history['val_loss'][i]:.6f}\\n\")\n",
    "\n",
    "    # Predictions\n",
    "    predictions = model.predict(X)\n",
    "    predictions_rescaled = scaler.inverse_transform(predictions)\n",
    "    df['Predicted'] = [np.nan] * look_back + list(predictions_rescaled.flatten())\n",
    "\n",
    "    # Round values for clean output\n",
    "    df['Average Price'] = df['Average Price'].round(2)\n",
    "    df['Predicted'] = df['Predicted'].round(2)\n",
    "\n",
    "    # Metrics Calculation\n",
    "    y_true = df['Average Price'].values[look_back:]\n",
    "    y_pred = predictions_rescaled.flatten()\n",
    "\n",
    "    # Avoid division by zero or NaN in MAPE\n",
    "    mask = y_true != 0\n",
    "    if np.any(mask):\n",
    "        mape = np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100\n",
    "    else:\n",
    "        mape = 0.0\n",
    "\n",
    "    mae = round(mean_absolute_error(y_true, y_pred), 2)\n",
    "    rmse = round(np.sqrt(mean_squared_error(y_true, y_pred)), 2)\n",
    "    r2 = round(r2_score(y_true, y_pred), 2)\n",
    "    mape = round(mape, 2)\n",
    "    accuracy = round(100 - mape, 2)\n",
    "\n",
    "    metrics_list.append([file.replace(\".csv\", \"\"), mae, rmse, r2, mape, accuracy])\n",
    "\n",
    "    # Save model as .pkl\n",
    "    model_file = os.path.join(output_models, file.replace(\".csv\", \"_tat_gqa_model.pkl\"))\n",
    "    joblib.dump(model, model_file)\n",
    "\n",
    "    # Save predictions to CSV\n",
    "    save_df = df[['Date', 'Average Price', 'Predicted']].rename(columns={'Average Price': 'Actual'})\n",
    "    updated_csv_path = os.path.join(output_csv, file.replace(\".csv\", \"_tat_gqa_updated.csv\"))\n",
    "    save_df.to_csv(updated_csv_path, index=False)\n",
    "\n",
    "    # Plot Graph\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(df['Date'], df['Average Price'], label='Actual', color='blue')\n",
    "    plt.plot(df['Date'], df['MA_7'], label='MA 7', color='orange')\n",
    "    plt.plot(df['Date'], df['MA_30'], label='MA 30', color='green')\n",
    "    plt.plot(df['Date'], df['Predicted'], label='Predicted (TAT-GQA)', color='red', linestyle='dashed')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Price')\n",
    "    plt.title(f'Price Prediction (TAT-GQA) - {file}')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    graph_file = os.path.join(output_graphs, file.replace(\".csv\", \"_tat_gqa_graph.png\"))\n",
    "    plt.savefig(graph_file)\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"✅ Done: {file} | MAE={mae}, RMSE={rmse}, R2={r2}, MAPE={mape}%, Accuracy={accuracy}%\")\n",
    "\n",
    "# -----------------------------\n",
    "# Save Metrics\n",
    "# -----------------------------\n",
    "metrics_df = pd.DataFrame(metrics_list, columns=['District', 'MAE', 'RMSE', 'R2', 'MAPE(%)', 'Accuracy(%)'])\n",
    "metrics_df.to_csv(metrics_file, index=False)\n",
    "print(f\"📊 All metrics saved to: {metrics_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef75fdc2-ef0d-4919-af32-d7719e201198",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TAT+HA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3405e204-2d56-49c4-852c-043c4c90afb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "451/451 - 7s - 16ms/step - loss: 0.0017 - mae: 0.0277 - val_loss: 0.0052 - val_mae: 0.0596\n",
      "Epoch 19/50\n",
      "451/451 - 6s - 14ms/step - loss: 0.0017 - mae: 0.0274 - val_loss: 0.0032 - val_mae: 0.0427\n",
      "Epoch 20/50\n",
      "451/451 - 6s - 13ms/step - loss: 0.0018 - mae: 0.0279 - val_loss: 0.0040 - val_mae: 0.0539\n",
      "Epoch 21/50\n",
      "451/451 - 6s - 14ms/step - loss: 0.0017 - mae: 0.0273 - val_loss: 0.0021 - val_mae: 0.0356\n",
      "Epoch 22/50\n",
      "451/451 - 6s - 13ms/step - loss: 0.0017 - mae: 0.0277 - val_loss: 0.0035 - val_mae: 0.0508\n",
      "Epoch 23/50\n",
      "451/451 - 6s - 14ms/step - loss: 0.0017 - mae: 0.0276 - val_loss: 0.0027 - val_mae: 0.0409\n",
      "Epoch 24/50\n",
      "451/451 - 6s - 14ms/step - loss: 0.0017 - mae: 0.0273 - val_loss: 0.0023 - val_mae: 0.0406\n",
      "Epoch 25/50\n",
      "451/451 - 8s - 17ms/step - loss: 0.0016 - mae: 0.0260 - val_loss: 0.0023 - val_mae: 0.0373\n",
      "Epoch 26/50\n",
      "451/451 - 7s - 15ms/step - loss: 0.0017 - mae: 0.0275 - val_loss: 0.0077 - val_mae: 0.0760\n",
      "Epoch 27/50\n",
      "451/451 - 6s - 14ms/step - loss: 0.0017 - mae: 0.0272 - val_loss: 0.0017 - val_mae: 0.0295\n",
      "Epoch 28/50\n",
      "451/451 - 7s - 15ms/step - loss: 0.0016 - mae: 0.0256 - val_loss: 0.0041 - val_mae: 0.0522\n",
      "Epoch 29/50\n",
      "451/451 - 7s - 16ms/step - loss: 0.0016 - mae: 0.0264 - val_loss: 0.0066 - val_mae: 0.0665\n",
      "Epoch 30/50\n",
      "451/451 - 6s - 14ms/step - loss: 0.0016 - mae: 0.0260 - val_loss: 0.0013 - val_mae: 0.0224\n",
      "Epoch 31/50\n",
      "451/451 - 6s - 13ms/step - loss: 0.0017 - mae: 0.0265 - val_loss: 0.0021 - val_mae: 0.0281\n",
      "Epoch 32/50\n",
      "451/451 - 6s - 14ms/step - loss: 0.0016 - mae: 0.0263 - val_loss: 0.0027 - val_mae: 0.0403\n",
      "Epoch 33/50\n",
      "451/451 - 6s - 13ms/step - loss: 0.0016 - mae: 0.0258 - val_loss: 0.0036 - val_mae: 0.0422\n",
      "Epoch 34/50\n",
      "451/451 - 6s - 14ms/step - loss: 0.0017 - mae: 0.0270 - val_loss: 0.0047 - val_mae: 0.0523\n",
      "Epoch 35/50\n",
      "451/451 - 6s - 14ms/step - loss: 0.0016 - mae: 0.0262 - val_loss: 0.0030 - val_mae: 0.0439\n",
      "Epoch 36/50\n",
      "451/451 - 6s - 13ms/step - loss: 0.0016 - mae: 0.0260 - val_loss: 0.0019 - val_mae: 0.0281\n",
      "Epoch 37/50\n",
      "451/451 - 6s - 13ms/step - loss: 0.0016 - mae: 0.0263 - val_loss: 0.0030 - val_mae: 0.0363\n",
      "Epoch 38/50\n",
      "451/451 - 6s - 14ms/step - loss: 0.0016 - mae: 0.0257 - val_loss: 0.0020 - val_mae: 0.0299\n",
      "Epoch 39/50\n",
      "451/451 - 6s - 13ms/step - loss: 0.0016 - mae: 0.0261 - val_loss: 0.0031 - val_mae: 0.0447\n",
      "Epoch 40/50\n",
      "451/451 - 6s - 14ms/step - loss: 0.0016 - mae: 0.0260 - val_loss: 0.0016 - val_mae: 0.0256\n",
      "Epoch 41/50\n",
      "451/451 - 6s - 13ms/step - loss: 0.0016 - mae: 0.0257 - val_loss: 0.0029 - val_mae: 0.0375\n",
      "Epoch 42/50\n",
      "451/451 - 6s - 13ms/step - loss: 0.0016 - mae: 0.0258 - val_loss: 0.0019 - val_mae: 0.0300\n",
      "Epoch 43/50\n",
      "451/451 - 6s - 13ms/step - loss: 0.0016 - mae: 0.0257 - val_loss: 0.0023 - val_mae: 0.0334\n",
      "Epoch 44/50\n",
      "451/451 - 6s - 14ms/step - loss: 0.0016 - mae: 0.0262 - val_loss: 0.0042 - val_mae: 0.0487\n",
      "Epoch 45/50\n",
      "451/451 - 6s - 14ms/step - loss: 0.0016 - mae: 0.0267 - val_loss: 0.0043 - val_mae: 0.0512\n",
      "Epoch 46/50\n",
      "451/451 - 6s - 14ms/step - loss: 0.0016 - mae: 0.0263 - val_loss: 0.0025 - val_mae: 0.0374\n",
      "Epoch 47/50\n",
      "451/451 - 7s - 15ms/step - loss: 0.0016 - mae: 0.0264 - val_loss: 0.0031 - val_mae: 0.0385\n",
      "Epoch 48/50\n",
      "451/451 - 6s - 14ms/step - loss: 0.0016 - mae: 0.0260 - val_loss: 0.0015 - val_mae: 0.0240\n",
      "Epoch 49/50\n",
      "451/451 - 5s - 12ms/step - loss: 0.0016 - mae: 0.0262 - val_loss: 0.0029 - val_mae: 0.0341\n",
      "Epoch 50/50\n",
      "451/451 - 6s - 13ms/step - loss: 0.0016 - mae: 0.0257 - val_loss: 0.0025 - val_mae: 0.0351\n",
      "✅ Done with onion_Bagalkot_daily.csv | MAE=238.76, RMSE=361.38, R2=0.78, MAPE=22.45%, Accuracy=77.55%\n",
      "\n",
      "🚀 Processing: onion_Bangalore_daily.csv\n",
      "Epoch 1/50\n",
      "897/897 - 42s - 47ms/step - loss: 0.0207 - mae: 0.0726 - val_loss: 0.0043 - val_mae: 0.0411\n",
      "Epoch 2/50\n",
      "897/897 - 27s - 31ms/step - loss: 0.0035 - mae: 0.0418 - val_loss: 0.0041 - val_mae: 0.0457\n",
      "Epoch 3/50\n",
      "897/897 - 31s - 34ms/step - loss: 0.0028 - mae: 0.0367 - val_loss: 0.0026 - val_mae: 0.0362\n",
      "Epoch 4/50\n",
      "897/897 - 28s - 32ms/step - loss: 0.0027 - mae: 0.0364 - val_loss: 0.0026 - val_mae: 0.0358\n",
      "Epoch 5/50\n",
      "897/897 - 31s - 35ms/step - loss: 0.0027 - mae: 0.0355 - val_loss: 0.0021 - val_mae: 0.0334\n",
      "Epoch 6/50\n",
      "897/897 - 31s - 34ms/step - loss: 0.0026 - mae: 0.0351 - val_loss: 0.0020 - val_mae: 0.0329\n",
      "Epoch 7/50\n",
      "897/897 - 31s - 35ms/step - loss: 0.0025 - mae: 0.0342 - val_loss: 0.0027 - val_mae: 0.0342\n",
      "Epoch 8/50\n",
      "897/897 - 31s - 34ms/step - loss: 0.0026 - mae: 0.0351 - val_loss: 0.0023 - val_mae: 0.0353\n",
      "Epoch 9/50\n",
      "897/897 - 32s - 35ms/step - loss: 0.0026 - mae: 0.0345 - val_loss: 0.0022 - val_mae: 0.0328\n",
      "Epoch 10/50\n",
      "897/897 - 32s - 36ms/step - loss: 0.0025 - mae: 0.0341 - val_loss: 0.0020 - val_mae: 0.0321\n",
      "Epoch 11/50\n",
      "897/897 - 30s - 34ms/step - loss: 0.0025 - mae: 0.0336 - val_loss: 0.0021 - val_mae: 0.0341\n",
      "Epoch 12/50\n",
      "897/897 - 33s - 37ms/step - loss: 0.0025 - mae: 0.0338 - val_loss: 0.0022 - val_mae: 0.0344\n",
      "Epoch 13/50\n",
      "897/897 - 32s - 35ms/step - loss: 0.0024 - mae: 0.0337 - val_loss: 0.0035 - val_mae: 0.0440\n",
      "Epoch 14/50\n",
      "897/897 - 32s - 36ms/step - loss: 0.0025 - mae: 0.0340 - val_loss: 0.0020 - val_mae: 0.0325\n",
      "Epoch 15/50\n",
      "897/897 - 30s - 34ms/step - loss: 0.0025 - mae: 0.0334 - val_loss: 0.0019 - val_mae: 0.0317\n",
      "Epoch 16/50\n",
      "897/897 - 33s - 36ms/step - loss: 0.0024 - mae: 0.0331 - val_loss: 0.0021 - val_mae: 0.0337\n",
      "Epoch 17/50\n",
      "897/897 - 34s - 38ms/step - loss: 0.0024 - mae: 0.0332 - val_loss: 0.0021 - val_mae: 0.0330\n",
      "Epoch 18/50\n",
      "897/897 - 36s - 40ms/step - loss: 0.0024 - mae: 0.0331 - val_loss: 0.0020 - val_mae: 0.0325\n",
      "Epoch 19/50\n",
      "897/897 - 37s - 41ms/step - loss: 0.0024 - mae: 0.0330 - val_loss: 0.0020 - val_mae: 0.0317\n",
      "Epoch 20/50\n",
      "897/897 - 29s - 32ms/step - loss: 0.0024 - mae: 0.0331 - val_loss: 0.0020 - val_mae: 0.0321\n",
      "Epoch 21/50\n",
      "897/897 - 36s - 40ms/step - loss: 0.0024 - mae: 0.0331 - val_loss: 0.0028 - val_mae: 0.0347\n",
      "Epoch 22/50\n",
      "897/897 - 36s - 40ms/step - loss: 0.0024 - mae: 0.0332 - val_loss: 0.0020 - val_mae: 0.0314\n",
      "Epoch 23/50\n",
      "897/897 - 33s - 37ms/step - loss: 0.0024 - mae: 0.0327 - val_loss: 0.0021 - val_mae: 0.0339\n",
      "Epoch 24/50\n",
      "897/897 - 36s - 40ms/step - loss: 0.0024 - mae: 0.0328 - val_loss: 0.0025 - val_mae: 0.0375\n",
      "Epoch 25/50\n",
      "897/897 - 37s - 41ms/step - loss: 0.0024 - mae: 0.0327 - val_loss: 0.0019 - val_mae: 0.0322\n",
      "Epoch 26/50\n",
      "897/897 - 36s - 40ms/step - loss: 0.0024 - mae: 0.0324 - val_loss: 0.0024 - val_mae: 0.0376\n",
      "Epoch 27/50\n",
      "897/897 - 36s - 40ms/step - loss: 0.0023 - mae: 0.0324 - val_loss: 0.0023 - val_mae: 0.0350\n",
      "Epoch 28/50\n",
      "897/897 - 37s - 41ms/step - loss: 0.0023 - mae: 0.0324 - val_loss: 0.0021 - val_mae: 0.0344\n",
      "Epoch 29/50\n",
      "897/897 - 37s - 41ms/step - loss: 0.0023 - mae: 0.0323 - val_loss: 0.0020 - val_mae: 0.0314\n",
      "Epoch 30/50\n",
      "897/897 - 37s - 42ms/step - loss: 0.0023 - mae: 0.0323 - val_loss: 0.0020 - val_mae: 0.0320\n",
      "Epoch 31/50\n",
      "897/897 - 36s - 40ms/step - loss: 0.0023 - mae: 0.0323 - val_loss: 0.0024 - val_mae: 0.0368\n",
      "Epoch 32/50\n",
      "897/897 - 34s - 38ms/step - loss: 0.0023 - mae: 0.0323 - val_loss: 0.0023 - val_mae: 0.0356\n",
      "Epoch 33/50\n",
      "897/897 - 37s - 41ms/step - loss: 0.0023 - mae: 0.0325 - val_loss: 0.0020 - val_mae: 0.0322\n",
      "Epoch 34/50\n",
      "897/897 - 37s - 41ms/step - loss: 0.0023 - mae: 0.0321 - val_loss: 0.0020 - val_mae: 0.0320\n",
      "Epoch 35/50\n",
      "897/897 - 37s - 41ms/step - loss: 0.0023 - mae: 0.0322 - val_loss: 0.0019 - val_mae: 0.0318\n",
      "Epoch 36/50\n",
      "897/897 - 36s - 40ms/step - loss: 0.0023 - mae: 0.0321 - val_loss: 0.0019 - val_mae: 0.0319\n",
      "Epoch 37/50\n",
      "897/897 - 36s - 40ms/step - loss: 0.0024 - mae: 0.0323 - val_loss: 0.0020 - val_mae: 0.0324\n",
      "Epoch 38/50\n",
      "897/897 - 37s - 41ms/step - loss: 0.0023 - mae: 0.0320 - val_loss: 0.0019 - val_mae: 0.0324\n",
      "Epoch 39/50\n",
      "897/897 - 36s - 40ms/step - loss: 0.0023 - mae: 0.0321 - val_loss: 0.0021 - val_mae: 0.0338\n",
      "Epoch 40/50\n",
      "897/897 - 36s - 40ms/step - loss: 0.0023 - mae: 0.0321 - val_loss: 0.0021 - val_mae: 0.0324\n",
      "Epoch 41/50\n",
      "897/897 - 37s - 41ms/step - loss: 0.0023 - mae: 0.0321 - val_loss: 0.0020 - val_mae: 0.0322\n",
      "Epoch 42/50\n",
      "897/897 - 36s - 40ms/step - loss: 0.0023 - mae: 0.0321 - val_loss: 0.0020 - val_mae: 0.0326\n",
      "Epoch 43/50\n",
      "897/897 - 37s - 41ms/step - loss: 0.0023 - mae: 0.0320 - val_loss: 0.0019 - val_mae: 0.0317\n",
      "Epoch 44/50\n",
      "897/897 - 36s - 40ms/step - loss: 0.0023 - mae: 0.0322 - val_loss: 0.0020 - val_mae: 0.0322\n",
      "Epoch 45/50\n",
      "897/897 - 32s - 36ms/step - loss: 0.0023 - mae: 0.0321 - val_loss: 0.0019 - val_mae: 0.0314\n",
      "Epoch 46/50\n",
      "897/897 - 36s - 40ms/step - loss: 0.0023 - mae: 0.0320 - val_loss: 0.0023 - val_mae: 0.0362\n",
      "Epoch 47/50\n",
      "897/897 - 36s - 40ms/step - loss: 0.0023 - mae: 0.0321 - val_loss: 0.0020 - val_mae: 0.0332\n",
      "Epoch 48/50\n",
      "897/897 - 35s - 39ms/step - loss: 0.0023 - mae: 0.0319 - val_loss: 0.0021 - val_mae: 0.0337\n",
      "Epoch 49/50\n",
      "897/897 - 34s - 37ms/step - loss: 0.0023 - mae: 0.0320 - val_loss: 0.0020 - val_mae: 0.0327\n",
      "Epoch 50/50\n",
      "897/897 - 36s - 40ms/step - loss: 0.0023 - mae: 0.0318 - val_loss: 0.0022 - val_mae: 0.0348\n",
      "✅ Done with onion_Bangalore_daily.csv | MAE=460.77, RMSE=620.7, R2=0.63, MAPE=29.95%, Accuracy=70.05%\n",
      "\n",
      "🚀 Processing: onion_Belgaum_daily.csv\n",
      "Epoch 1/50\n",
      "321/321 - 19s - 60ms/step - loss: 0.0348 - mae: 0.1021 - val_loss: 0.0026 - val_mae: 0.0412\n",
      "Epoch 2/50\n",
      "321/321 - 11s - 35ms/step - loss: 0.0069 - mae: 0.0576 - val_loss: 0.0048 - val_mae: 0.0653\n",
      "Epoch 3/50\n",
      "321/321 - 12s - 36ms/step - loss: 0.0040 - mae: 0.0428 - val_loss: 0.0015 - val_mae: 0.0286\n",
      "Epoch 4/50\n",
      "321/321 - 11s - 36ms/step - loss: 0.0031 - mae: 0.0361 - val_loss: 0.0018 - val_mae: 0.0345\n",
      "Epoch 5/50\n",
      "321/321 - 11s - 35ms/step - loss: 0.0029 - mae: 0.0346 - val_loss: 0.0021 - val_mae: 0.0366\n",
      "Epoch 6/50\n",
      "321/321 - 12s - 36ms/step - loss: 0.0026 - mae: 0.0322 - val_loss: 0.0021 - val_mae: 0.0363\n",
      "Epoch 7/50\n",
      "321/321 - 12s - 36ms/step - loss: 0.0024 - mae: 0.0308 - val_loss: 0.0030 - val_mae: 0.0423\n",
      "Epoch 8/50\n",
      "321/321 - 9s - 29ms/step - loss: 0.0021 - mae: 0.0291 - val_loss: 0.0043 - val_mae: 0.0569\n",
      "Epoch 9/50\n",
      "321/321 - 11s - 34ms/step - loss: 0.0020 - mae: 0.0273 - val_loss: 0.0028 - val_mae: 0.0426\n",
      "Epoch 10/50\n",
      "321/321 - 12s - 36ms/step - loss: 0.0021 - mae: 0.0292 - val_loss: 0.0028 - val_mae: 0.0444\n",
      "Epoch 11/50\n",
      "321/321 - 11s - 35ms/step - loss: 0.0019 - mae: 0.0282 - val_loss: 0.0023 - val_mae: 0.0369\n",
      "Epoch 12/50\n",
      "321/321 - 11s - 35ms/step - loss: 0.0018 - mae: 0.0252 - val_loss: 0.0022 - val_mae: 0.0341\n",
      "Epoch 13/50\n",
      "321/321 - 11s - 35ms/step - loss: 0.0019 - mae: 0.0275 - val_loss: 0.0014 - val_mae: 0.0268\n",
      "Epoch 14/50\n",
      "321/321 - 12s - 36ms/step - loss: 0.0019 - mae: 0.0277 - val_loss: 0.0014 - val_mae: 0.0282\n",
      "Epoch 15/50\n",
      "321/321 - 12s - 36ms/step - loss: 0.0019 - mae: 0.0270 - val_loss: 0.0020 - val_mae: 0.0353\n",
      "Epoch 16/50\n",
      "321/321 - 11s - 36ms/step - loss: 0.0019 - mae: 0.0266 - val_loss: 0.0025 - val_mae: 0.0408\n",
      "Epoch 17/50\n",
      "321/321 - 11s - 33ms/step - loss: 0.0018 - mae: 0.0263 - val_loss: 0.0012 - val_mae: 0.0231\n",
      "Epoch 18/50\n",
      "321/321 - 12s - 36ms/step - loss: 0.0018 - mae: 0.0254 - val_loss: 0.0013 - val_mae: 0.0244\n",
      "Epoch 19/50\n",
      "321/321 - 12s - 37ms/step - loss: 0.0017 - mae: 0.0251 - val_loss: 0.0018 - val_mae: 0.0328\n",
      "Epoch 20/50\n",
      "321/321 - 11s - 35ms/step - loss: 0.0017 - mae: 0.0257 - val_loss: 0.0012 - val_mae: 0.0227\n",
      "Epoch 21/50\n",
      "321/321 - 11s - 34ms/step - loss: 0.0016 - mae: 0.0242 - val_loss: 0.0013 - val_mae: 0.0239\n",
      "Epoch 22/50\n",
      "321/321 - 11s - 36ms/step - loss: 0.0018 - mae: 0.0254 - val_loss: 0.0019 - val_mae: 0.0341\n",
      "Epoch 23/50\n",
      "321/321 - 12s - 36ms/step - loss: 0.0017 - mae: 0.0250 - val_loss: 0.0029 - val_mae: 0.0460\n",
      "Epoch 24/50\n",
      "321/321 - 11s - 35ms/step - loss: 0.0017 - mae: 0.0251 - val_loss: 0.0014 - val_mae: 0.0274\n",
      "Epoch 25/50\n",
      "321/321 - 12s - 36ms/step - loss: 0.0017 - mae: 0.0250 - val_loss: 0.0038 - val_mae: 0.0527\n",
      "Epoch 26/50\n",
      "321/321 - 11s - 35ms/step - loss: 0.0017 - mae: 0.0256 - val_loss: 0.0024 - val_mae: 0.0421\n",
      "Epoch 27/50\n",
      "321/321 - 11s - 35ms/step - loss: 0.0017 - mae: 0.0247 - val_loss: 0.0063 - val_mae: 0.0722\n",
      "Epoch 28/50\n",
      "321/321 - 11s - 35ms/step - loss: 0.0017 - mae: 0.0243 - val_loss: 0.0020 - val_mae: 0.0349\n",
      "Epoch 29/50\n",
      "321/321 - 12s - 37ms/step - loss: 0.0016 - mae: 0.0234 - val_loss: 0.0035 - val_mae: 0.0503\n",
      "Epoch 30/50\n",
      "321/321 - 11s - 35ms/step - loss: 0.0018 - mae: 0.0251 - val_loss: 0.0016 - val_mae: 0.0303\n",
      "Epoch 31/50\n",
      "321/321 - 11s - 35ms/step - loss: 0.0017 - mae: 0.0252 - val_loss: 0.0026 - val_mae: 0.0440\n",
      "Epoch 32/50\n",
      "321/321 - 12s - 36ms/step - loss: 0.0017 - mae: 0.0246 - val_loss: 0.0034 - val_mae: 0.0505\n",
      "Epoch 33/50\n",
      "321/321 - 11s - 35ms/step - loss: 0.0017 - mae: 0.0246 - val_loss: 0.0061 - val_mae: 0.0677\n",
      "Epoch 34/50\n",
      "321/321 - 12s - 36ms/step - loss: 0.0016 - mae: 0.0230 - val_loss: 0.0017 - val_mae: 0.0317\n",
      "Epoch 35/50\n",
      "321/321 - 11s - 34ms/step - loss: 0.0015 - mae: 0.0234 - val_loss: 0.0015 - val_mae: 0.0274\n",
      "Epoch 36/50\n",
      "321/321 - 11s - 36ms/step - loss: 0.0016 - mae: 0.0241 - val_loss: 0.0014 - val_mae: 0.0280\n",
      "Epoch 37/50\n",
      "321/321 - 11s - 35ms/step - loss: 0.0016 - mae: 0.0236 - val_loss: 0.0019 - val_mae: 0.0353\n",
      "Epoch 38/50\n",
      "321/321 - 11s - 36ms/step - loss: 0.0017 - mae: 0.0245 - val_loss: 0.0012 - val_mae: 0.0244\n",
      "Epoch 39/50\n",
      "321/321 - 12s - 36ms/step - loss: 0.0016 - mae: 0.0231 - val_loss: 0.0015 - val_mae: 0.0279\n",
      "Epoch 40/50\n",
      "321/321 - 11s - 35ms/step - loss: 0.0016 - mae: 0.0237 - val_loss: 0.0012 - val_mae: 0.0234\n",
      "Epoch 41/50\n",
      "321/321 - 11s - 34ms/step - loss: 0.0016 - mae: 0.0231 - val_loss: 0.0018 - val_mae: 0.0327\n",
      "Epoch 42/50\n",
      "321/321 - 11s - 33ms/step - loss: 0.0015 - mae: 0.0226 - val_loss: 0.0025 - val_mae: 0.0397\n",
      "Epoch 43/50\n",
      "321/321 - 11s - 35ms/step - loss: 0.0016 - mae: 0.0228 - val_loss: 0.0044 - val_mae: 0.0532\n",
      "Epoch 44/50\n",
      "321/321 - 11s - 36ms/step - loss: 0.0015 - mae: 0.0223 - val_loss: 0.0028 - val_mae: 0.0420\n",
      "Epoch 45/50\n",
      "321/321 - 11s - 35ms/step - loss: 0.0016 - mae: 0.0229 - val_loss: 0.0012 - val_mae: 0.0230\n",
      "Epoch 46/50\n",
      "321/321 - 11s - 33ms/step - loss: 0.0016 - mae: 0.0232 - val_loss: 0.0035 - val_mae: 0.0498\n",
      "Epoch 47/50\n",
      "321/321 - 11s - 33ms/step - loss: 0.0015 - mae: 0.0226 - val_loss: 0.0040 - val_mae: 0.0537\n",
      "Epoch 48/50\n",
      "321/321 - 11s - 35ms/step - loss: 0.0016 - mae: 0.0232 - val_loss: 0.0027 - val_mae: 0.0427\n",
      "Epoch 49/50\n",
      "321/321 - 11s - 35ms/step - loss: 0.0016 - mae: 0.0233 - val_loss: 0.0025 - val_mae: 0.0416\n",
      "Epoch 50/50\n",
      "321/321 - 12s - 36ms/step - loss: 0.0016 - mae: 0.0229 - val_loss: 0.0016 - val_mae: 0.0279\n",
      "✅ Done with onion_Belgaum_daily.csv | MAE=278.91, RMSE=462.08, R2=0.78, MAPE=22.38%, Accuracy=77.62%\n",
      "\n",
      "🚀 Processing: onion_Bellary_daily.csv\n",
      "Epoch 1/50\n",
      "292/292 - 16s - 54ms/step - loss: 0.0389 - mae: 0.0960 - val_loss: 0.0038 - val_mae: 0.0550\n",
      "Epoch 2/50\n",
      "292/292 - 9s - 32ms/step - loss: 0.0036 - mae: 0.0452 - val_loss: 9.4941e-04 - val_mae: 0.0238\n",
      "Epoch 3/50\n",
      "292/292 - 9s - 32ms/step - loss: 0.0027 - mae: 0.0380 - val_loss: 0.0012 - val_mae: 0.0231\n",
      "Epoch 4/50\n",
      "292/292 - 9s - 30ms/step - loss: 0.0025 - mae: 0.0363 - val_loss: 0.0016 - val_mae: 0.0363\n",
      "Epoch 5/50\n",
      "292/292 - 9s - 30ms/step - loss: 0.0020 - mae: 0.0311 - val_loss: 0.0015 - val_mae: 0.0345\n",
      "Epoch 6/50\n",
      "292/292 - 7s - 26ms/step - loss: 0.0017 - mae: 0.0277 - val_loss: 0.0019 - val_mae: 0.0391\n",
      "Epoch 7/50\n",
      "292/292 - 9s - 30ms/step - loss: 0.0016 - mae: 0.0270 - val_loss: 0.0021 - val_mae: 0.0402\n",
      "Epoch 8/50\n",
      "292/292 - 9s - 32ms/step - loss: 0.0014 - mae: 0.0252 - val_loss: 9.4573e-04 - val_mae: 0.0256\n",
      "Epoch 9/50\n",
      "292/292 - 9s - 31ms/step - loss: 0.0014 - mae: 0.0243 - val_loss: 8.4872e-04 - val_mae: 0.0205\n",
      "Epoch 10/50\n",
      "292/292 - 9s - 32ms/step - loss: 0.0014 - mae: 0.0245 - val_loss: 0.0011 - val_mae: 0.0281\n",
      "Epoch 11/50\n",
      "292/292 - 9s - 32ms/step - loss: 0.0012 - mae: 0.0227 - val_loss: 8.4404e-04 - val_mae: 0.0220\n",
      "Epoch 12/50\n",
      "292/292 - 9s - 32ms/step - loss: 0.0014 - mae: 0.0244 - val_loss: 8.8257e-04 - val_mae: 0.0226\n",
      "Epoch 13/50\n",
      "292/292 - 8s - 27ms/step - loss: 0.0013 - mae: 0.0231 - val_loss: 8.7170e-04 - val_mae: 0.0206\n",
      "Epoch 14/50\n",
      "292/292 - 9s - 30ms/step - loss: 0.0012 - mae: 0.0222 - val_loss: 0.0012 - val_mae: 0.0294\n",
      "Epoch 15/50\n",
      "292/292 - 9s - 31ms/step - loss: 0.0012 - mae: 0.0219 - val_loss: 8.4978e-04 - val_mae: 0.0223\n",
      "Epoch 16/50\n",
      "292/292 - 9s - 30ms/step - loss: 0.0012 - mae: 0.0225 - val_loss: 8.3589e-04 - val_mae: 0.0210\n",
      "Epoch 17/50\n",
      "292/292 - 9s - 30ms/step - loss: 0.0012 - mae: 0.0222 - val_loss: 0.0013 - val_mae: 0.0297\n",
      "Epoch 18/50\n",
      "292/292 - 9s - 31ms/step - loss: 0.0011 - mae: 0.0206 - val_loss: 0.0024 - val_mae: 0.0419\n",
      "Epoch 19/50\n",
      "292/292 - 9s - 32ms/step - loss: 0.0012 - mae: 0.0218 - val_loss: 0.0014 - val_mae: 0.0315\n",
      "Epoch 20/50\n",
      "292/292 - 9s - 30ms/step - loss: 0.0011 - mae: 0.0206 - val_loss: 9.6355e-04 - val_mae: 0.0242\n",
      "Epoch 21/50\n",
      "292/292 - 9s - 31ms/step - loss: 0.0010 - mae: 0.0195 - val_loss: 8.3100e-04 - val_mae: 0.0198\n",
      "Epoch 22/50\n",
      "292/292 - 9s - 29ms/step - loss: 0.0010 - mae: 0.0193 - val_loss: 8.7985e-04 - val_mae: 0.0230\n",
      "Epoch 23/50\n",
      "292/292 - 9s - 29ms/step - loss: 0.0011 - mae: 0.0202 - val_loss: 0.0012 - val_mae: 0.0286\n",
      "Epoch 24/50\n",
      "292/292 - 9s - 31ms/step - loss: 0.0011 - mae: 0.0195 - val_loss: 0.0014 - val_mae: 0.0310\n",
      "Epoch 25/50\n",
      "292/292 - 9s - 32ms/step - loss: 0.0011 - mae: 0.0198 - val_loss: 0.0010 - val_mae: 0.0245\n",
      "Epoch 26/50\n",
      "292/292 - 8s - 29ms/step - loss: 0.0010 - mae: 0.0197 - val_loss: 8.2924e-04 - val_mae: 0.0203\n",
      "Epoch 27/50\n",
      "292/292 - 9s - 31ms/step - loss: 0.0011 - mae: 0.0195 - val_loss: 0.0012 - val_mae: 0.0289\n",
      "Epoch 28/50\n",
      "292/292 - 9s - 31ms/step - loss: 0.0011 - mae: 0.0199 - val_loss: 0.0012 - val_mae: 0.0291\n",
      "Epoch 29/50\n",
      "292/292 - 9s - 32ms/step - loss: 0.0010 - mae: 0.0189 - val_loss: 8.7933e-04 - val_mae: 0.0225\n",
      "Epoch 30/50\n",
      "292/292 - 9s - 32ms/step - loss: 0.0011 - mae: 0.0198 - val_loss: 8.6732e-04 - val_mae: 0.0212\n",
      "Epoch 31/50\n",
      "292/292 - 9s - 31ms/step - loss: 0.0010 - mae: 0.0189 - val_loss: 8.5114e-04 - val_mae: 0.0218\n",
      "Epoch 32/50\n",
      "292/292 - 9s - 31ms/step - loss: 0.0010 - mae: 0.0194 - val_loss: 0.0013 - val_mae: 0.0294\n",
      "Epoch 33/50\n",
      "292/292 - 9s - 30ms/step - loss: 0.0010 - mae: 0.0197 - val_loss: 8.4673e-04 - val_mae: 0.0218\n",
      "Epoch 34/50\n",
      "292/292 - 9s - 30ms/step - loss: 0.0010 - mae: 0.0186 - val_loss: 0.0010 - val_mae: 0.0247\n",
      "Epoch 35/50\n",
      "292/292 - 9s - 31ms/step - loss: 0.0010 - mae: 0.0191 - val_loss: 8.3321e-04 - val_mae: 0.0199\n",
      "Epoch 36/50\n",
      "292/292 - 9s - 30ms/step - loss: 0.0010 - mae: 0.0197 - val_loss: 8.3004e-04 - val_mae: 0.0200\n",
      "Epoch 37/50\n",
      "292/292 - 9s - 31ms/step - loss: 9.8844e-04 - mae: 0.0188 - val_loss: 8.3691e-04 - val_mae: 0.0211\n",
      "Epoch 38/50\n",
      "292/292 - 10s - 33ms/step - loss: 9.7881e-04 - mae: 0.0182 - val_loss: 8.9050e-04 - val_mae: 0.0228\n",
      "Epoch 39/50\n",
      "292/292 - 9s - 31ms/step - loss: 0.0010 - mae: 0.0196 - val_loss: 8.9267e-04 - val_mae: 0.0232\n",
      "Epoch 40/50\n",
      "292/292 - 9s - 30ms/step - loss: 9.7117e-04 - mae: 0.0180 - val_loss: 0.0011 - val_mae: 0.0258\n",
      "Epoch 41/50\n",
      "292/292 - 9s - 31ms/step - loss: 0.0010 - mae: 0.0187 - val_loss: 8.5328e-04 - val_mae: 0.0206\n",
      "Epoch 42/50\n",
      "292/292 - 9s - 30ms/step - loss: 9.5836e-04 - mae: 0.0177 - val_loss: 8.9113e-04 - val_mae: 0.0236\n",
      "Epoch 43/50\n",
      "292/292 - 9s - 32ms/step - loss: 0.0010 - mae: 0.0187 - val_loss: 8.4699e-04 - val_mae: 0.0222\n",
      "Epoch 44/50\n",
      "292/292 - 9s - 31ms/step - loss: 9.9922e-04 - mae: 0.0188 - val_loss: 8.4235e-04 - val_mae: 0.0200\n",
      "Epoch 45/50\n",
      "292/292 - 9s - 29ms/step - loss: 9.8393e-04 - mae: 0.0182 - val_loss: 0.0010 - val_mae: 0.0254\n",
      "Epoch 46/50\n",
      "292/292 - 8s - 29ms/step - loss: 9.8118e-04 - mae: 0.0184 - val_loss: 9.0328e-04 - val_mae: 0.0224\n",
      "Epoch 47/50\n",
      "292/292 - 8s - 28ms/step - loss: 9.6486e-04 - mae: 0.0180 - val_loss: 0.0011 - val_mae: 0.0265\n",
      "Epoch 48/50\n",
      "292/292 - 8s - 27ms/step - loss: 9.8686e-04 - mae: 0.0181 - val_loss: 0.0011 - val_mae: 0.0255\n",
      "Epoch 49/50\n",
      "292/292 - 9s - 30ms/step - loss: 9.6092e-04 - mae: 0.0179 - val_loss: 0.0011 - val_mae: 0.0280\n",
      "Epoch 50/50\n",
      "292/292 - 9s - 30ms/step - loss: 9.6785e-04 - mae: 0.0182 - val_loss: 0.0012 - val_mae: 0.0294\n",
      "✅ Done with onion_Bellary_daily.csv | MAE=293.85, RMSE=392.34, R2=0.57, MAPE=25.78%, Accuracy=74.22%\n",
      "\n",
      "🚀 Processing: onion_Bidar_daily.csv\n",
      "Epoch 1/50\n",
      "378/378 - 17s - 45ms/step - loss: 0.0351 - mae: 0.1160 - val_loss: 0.0082 - val_mae: 0.0293\n",
      "Epoch 2/50\n",
      "378/378 - 11s - 28ms/step - loss: 0.0076 - mae: 0.0682 - val_loss: 0.0082 - val_mae: 0.0624\n",
      "Epoch 3/50\n",
      "378/378 - 11s - 28ms/step - loss: 0.0052 - mae: 0.0562 - val_loss: 0.0073 - val_mae: 0.0566\n",
      "Epoch 4/50\n",
      "378/378 - 11s - 28ms/step - loss: 0.0043 - mae: 0.0507 - val_loss: 0.0098 - val_mae: 0.0612\n",
      "Epoch 5/50\n",
      "378/378 - 11s - 28ms/step - loss: 0.0041 - mae: 0.0495 - val_loss: 0.0063 - val_mae: 0.0234\n",
      "Epoch 6/50\n",
      "378/378 - 10s - 27ms/step - loss: 0.0036 - mae: 0.0461 - val_loss: 0.0065 - val_mae: 0.0597\n",
      "Epoch 7/50\n",
      "378/378 - 11s - 28ms/step - loss: 0.0038 - mae: 0.0473 - val_loss: 0.0058 - val_mae: 0.0447\n",
      "Epoch 8/50\n",
      "378/378 - 10s - 28ms/step - loss: 0.0037 - mae: 0.0471 - val_loss: 0.0056 - val_mae: 0.0330\n",
      "Epoch 9/50\n",
      "378/378 - 10s - 26ms/step - loss: 0.0037 - mae: 0.0468 - val_loss: 0.0073 - val_mae: 0.0426\n",
      "Epoch 10/50\n",
      "378/378 - 10s - 26ms/step - loss: 0.0036 - mae: 0.0462 - val_loss: 0.0070 - val_mae: 0.0403\n",
      "Epoch 11/50\n",
      "378/378 - 11s - 28ms/step - loss: 0.0034 - mae: 0.0442 - val_loss: 0.0056 - val_mae: 0.0526\n",
      "Epoch 12/50\n",
      "378/378 - 10s - 27ms/step - loss: 0.0035 - mae: 0.0456 - val_loss: 0.0050 - val_mae: 0.0360\n",
      "Epoch 13/50\n",
      "378/378 - 10s - 27ms/step - loss: 0.0034 - mae: 0.0451 - val_loss: 0.0057 - val_mae: 0.0561\n",
      "Epoch 14/50\n",
      "378/378 - 10s - 27ms/step - loss: 0.0034 - mae: 0.0450 - val_loss: 0.0047 - val_mae: 0.0376\n",
      "Epoch 15/50\n",
      "378/378 - 10s - 26ms/step - loss: 0.0033 - mae: 0.0439 - val_loss: 0.0051 - val_mae: 0.0510\n",
      "Epoch 16/50\n",
      "378/378 - 10s - 28ms/step - loss: 0.0035 - mae: 0.0458 - val_loss: 0.0048 - val_mae: 0.0249\n",
      "Epoch 17/50\n",
      "378/378 - 11s - 28ms/step - loss: 0.0033 - mae: 0.0445 - val_loss: 0.0041 - val_mae: 0.0280\n",
      "Epoch 18/50\n",
      "378/378 - 10s - 26ms/step - loss: 0.0033 - mae: 0.0437 - val_loss: 0.0043 - val_mae: 0.0292\n",
      "Epoch 19/50\n",
      "378/378 - 10s - 27ms/step - loss: 0.0033 - mae: 0.0447 - val_loss: 0.0054 - val_mae: 0.0589\n",
      "Epoch 20/50\n",
      "378/378 - 10s - 26ms/step - loss: 0.0033 - mae: 0.0443 - val_loss: 0.0051 - val_mae: 0.0267\n",
      "Epoch 21/50\n",
      "378/378 - 10s - 27ms/step - loss: 0.0033 - mae: 0.0446 - val_loss: 0.0040 - val_mae: 0.0180\n",
      "Epoch 22/50\n",
      "378/378 - 10s - 27ms/step - loss: 0.0033 - mae: 0.0440 - val_loss: 0.0045 - val_mae: 0.0222\n",
      "Epoch 23/50\n",
      "378/378 - 10s - 27ms/step - loss: 0.0034 - mae: 0.0447 - val_loss: 0.0038 - val_mae: 0.0248\n",
      "Epoch 24/50\n",
      "378/378 - 10s - 26ms/step - loss: 0.0032 - mae: 0.0436 - val_loss: 0.0037 - val_mae: 0.0206\n",
      "Epoch 25/50\n",
      "378/378 - 10s - 27ms/step - loss: 0.0032 - mae: 0.0430 - val_loss: 0.0032 - val_mae: 0.0164\n",
      "Epoch 26/50\n",
      "378/378 - 10s - 27ms/step - loss: 0.0032 - mae: 0.0436 - val_loss: 0.0042 - val_mae: 0.0238\n",
      "Epoch 27/50\n",
      "378/378 - 10s - 28ms/step - loss: 0.0032 - mae: 0.0436 - val_loss: 0.0036 - val_mae: 0.0306\n",
      "Epoch 28/50\n",
      "378/378 - 10s - 27ms/step - loss: 0.0032 - mae: 0.0429 - val_loss: 0.0031 - val_mae: 0.0315\n",
      "Epoch 29/50\n",
      "378/378 - 10s - 27ms/step - loss: 0.0032 - mae: 0.0430 - val_loss: 0.0040 - val_mae: 0.0180\n",
      "Epoch 30/50\n",
      "378/378 - 10s - 26ms/step - loss: 0.0032 - mae: 0.0436 - val_loss: 0.0036 - val_mae: 0.0292\n",
      "Epoch 31/50\n",
      "378/378 - 10s - 27ms/step - loss: 0.0031 - mae: 0.0429 - val_loss: 0.0039 - val_mae: 0.0474\n",
      "Epoch 32/50\n",
      "378/378 - 10s - 26ms/step - loss: 0.0031 - mae: 0.0430 - val_loss: 0.0038 - val_mae: 0.0448\n",
      "Epoch 33/50\n",
      "378/378 - 11s - 28ms/step - loss: 0.0031 - mae: 0.0428 - val_loss: 0.0042 - val_mae: 0.0178\n",
      "Epoch 34/50\n",
      "378/378 - 10s - 27ms/step - loss: 0.0032 - mae: 0.0431 - val_loss: 0.0049 - val_mae: 0.0199\n",
      "Epoch 35/50\n",
      "378/378 - 11s - 28ms/step - loss: 0.0032 - mae: 0.0433 - val_loss: 0.0052 - val_mae: 0.0303\n",
      "Epoch 36/50\n",
      "378/378 - 11s - 28ms/step - loss: 0.0031 - mae: 0.0429 - val_loss: 0.0043 - val_mae: 0.0263\n",
      "Epoch 37/50\n",
      "378/378 - 11s - 28ms/step - loss: 0.0031 - mae: 0.0428 - val_loss: 0.0039 - val_mae: 0.0251\n",
      "Epoch 38/50\n",
      "378/378 - 10s - 27ms/step - loss: 0.0031 - mae: 0.0424 - val_loss: 0.0039 - val_mae: 0.0249\n",
      "Epoch 39/50\n",
      "378/378 - 10s - 28ms/step - loss: 0.0031 - mae: 0.0426 - val_loss: 0.0040 - val_mae: 0.0237\n",
      "Epoch 40/50\n",
      "378/378 - 10s - 27ms/step - loss: 0.0031 - mae: 0.0421 - val_loss: 0.0038 - val_mae: 0.0188\n",
      "Epoch 41/50\n",
      "378/378 - 11s - 28ms/step - loss: 0.0031 - mae: 0.0421 - val_loss: 0.0048 - val_mae: 0.0198\n",
      "Epoch 42/50\n",
      "378/378 - 11s - 28ms/step - loss: 0.0031 - mae: 0.0422 - val_loss: 0.0046 - val_mae: 0.0213\n",
      "Epoch 43/50\n",
      "378/378 - 21s - 55ms/step - loss: 0.0031 - mae: 0.0420 - val_loss: 0.0046 - val_mae: 0.0189\n",
      "Epoch 44/50\n",
      "378/378 - 11s - 29ms/step - loss: 0.0030 - mae: 0.0421 - val_loss: 0.0041 - val_mae: 0.0192\n",
      "Epoch 45/50\n",
      "378/378 - 11s - 28ms/step - loss: 0.0031 - mae: 0.0422 - val_loss: 0.0033 - val_mae: 0.0151\n",
      "Epoch 46/50\n",
      "378/378 - 11s - 29ms/step - loss: 0.0031 - mae: 0.0419 - val_loss: 0.0045 - val_mae: 0.0193\n",
      "Epoch 47/50\n",
      "378/378 - 10s - 28ms/step - loss: 0.0031 - mae: 0.0422 - val_loss: 0.0046 - val_mae: 0.0188\n",
      "Epoch 48/50\n",
      "378/378 - 11s - 28ms/step - loss: 0.0031 - mae: 0.0423 - val_loss: 0.0042 - val_mae: 0.0218\n",
      "Epoch 49/50\n",
      "378/378 - 11s - 29ms/step - loss: 0.0031 - mae: 0.0420 - val_loss: 0.0025 - val_mae: 0.0168\n",
      "Epoch 50/50\n",
      "378/378 - 11s - 29ms/step - loss: 0.0030 - mae: 0.0423 - val_loss: 0.0039 - val_mae: 0.0299\n",
      "✅ Done with onion_Bidar_daily.csv | MAE=162.45, RMSE=239.86, R2=0.64, MAPE=18.39%, Accuracy=81.61%\n",
      "\n",
      "🚀 Processing: onion_Bijapur_daily.csv\n",
      "Epoch 1/50\n",
      "438/438 - 18s - 41ms/step - loss: 0.0277 - mae: 0.0952 - val_loss: 0.0075 - val_mae: 0.0763\n",
      "Epoch 2/50\n",
      "438/438 - 10s - 23ms/step - loss: 0.0044 - mae: 0.0501 - val_loss: 0.0026 - val_mae: 0.0444\n",
      "Epoch 3/50\n",
      "438/438 - 11s - 24ms/step - loss: 0.0037 - mae: 0.0461 - val_loss: 0.0060 - val_mae: 0.0719\n",
      "Epoch 4/50\n",
      "438/438 - 11s - 24ms/step - loss: 0.0032 - mae: 0.0429 - val_loss: 0.0014 - val_mae: 0.0280\n",
      "Epoch 5/50\n",
      "438/438 - 11s - 25ms/step - loss: 0.0031 - mae: 0.0424 - val_loss: 0.0017 - val_mae: 0.0331\n",
      "Epoch 6/50\n",
      "438/438 - 11s - 25ms/step - loss: 0.0031 - mae: 0.0428 - val_loss: 0.0014 - val_mae: 0.0275\n",
      "Epoch 7/50\n",
      "438/438 - 11s - 26ms/step - loss: 0.0029 - mae: 0.0416 - val_loss: 0.0019 - val_mae: 0.0348\n",
      "Epoch 8/50\n",
      "438/438 - 11s - 26ms/step - loss: 0.0029 - mae: 0.0419 - val_loss: 0.0017 - val_mae: 0.0319\n",
      "Epoch 9/50\n",
      "438/438 - 11s - 25ms/step - loss: 0.0027 - mae: 0.0403 - val_loss: 0.0032 - val_mae: 0.0490\n",
      "Epoch 10/50\n",
      "438/438 - 11s - 25ms/step - loss: 0.0028 - mae: 0.0413 - val_loss: 0.0012 - val_mae: 0.0249\n",
      "Epoch 11/50\n",
      "438/438 - 11s - 25ms/step - loss: 0.0028 - mae: 0.0412 - val_loss: 0.0013 - val_mae: 0.0256\n",
      "Epoch 12/50\n",
      "438/438 - 11s - 25ms/step - loss: 0.0028 - mae: 0.0409 - val_loss: 0.0026 - val_mae: 0.0424\n",
      "Epoch 13/50\n",
      "438/438 - 10s - 24ms/step - loss: 0.0027 - mae: 0.0404 - val_loss: 0.0012 - val_mae: 0.0239\n",
      "Epoch 14/50\n",
      "438/438 - 10s - 22ms/step - loss: 0.0027 - mae: 0.0406 - val_loss: 0.0011 - val_mae: 0.0212\n",
      "Epoch 15/50\n",
      "438/438 - 11s - 24ms/step - loss: 0.0027 - mae: 0.0405 - val_loss: 0.0024 - val_mae: 0.0410\n",
      "Epoch 16/50\n",
      "438/438 - 11s - 25ms/step - loss: 0.0027 - mae: 0.0405 - val_loss: 0.0037 - val_mae: 0.0532\n",
      "Epoch 17/50\n",
      "438/438 - 11s - 26ms/step - loss: 0.0026 - mae: 0.0401 - val_loss: 0.0020 - val_mae: 0.0375\n",
      "Epoch 18/50\n",
      "438/438 - 11s - 25ms/step - loss: 0.0028 - mae: 0.0409 - val_loss: 0.0020 - val_mae: 0.0378\n",
      "Epoch 19/50\n",
      "438/438 - 11s - 25ms/step - loss: 0.0027 - mae: 0.0406 - val_loss: 0.0012 - val_mae: 0.0251\n",
      "Epoch 20/50\n",
      "438/438 - 11s - 26ms/step - loss: 0.0026 - mae: 0.0401 - val_loss: 0.0014 - val_mae: 0.0280\n",
      "Epoch 21/50\n",
      "438/438 - 11s - 26ms/step - loss: 0.0027 - mae: 0.0405 - val_loss: 0.0019 - val_mae: 0.0364\n",
      "Epoch 22/50\n",
      "438/438 - 11s - 26ms/step - loss: 0.0027 - mae: 0.0402 - val_loss: 0.0016 - val_mae: 0.0333\n",
      "Epoch 23/50\n",
      "438/438 - 11s - 25ms/step - loss: 0.0026 - mae: 0.0400 - val_loss: 0.0024 - val_mae: 0.0418\n",
      "Epoch 24/50\n",
      "438/438 - 11s - 26ms/step - loss: 0.0027 - mae: 0.0408 - val_loss: 0.0012 - val_mae: 0.0248\n",
      "Epoch 25/50\n",
      "438/438 - 11s - 24ms/step - loss: 0.0026 - mae: 0.0405 - val_loss: 0.0012 - val_mae: 0.0245\n",
      "Epoch 26/50\n",
      "438/438 - 11s - 25ms/step - loss: 0.0026 - mae: 0.0400 - val_loss: 0.0015 - val_mae: 0.0309\n",
      "Epoch 27/50\n",
      "438/438 - 10s - 23ms/step - loss: 0.0026 - mae: 0.0401 - val_loss: 0.0017 - val_mae: 0.0344\n",
      "Epoch 28/50\n",
      "438/438 - 11s - 26ms/step - loss: 0.0027 - mae: 0.0404 - val_loss: 0.0011 - val_mae: 0.0216\n",
      "Epoch 29/50\n",
      "438/438 - 11s - 25ms/step - loss: 0.0026 - mae: 0.0400 - val_loss: 0.0013 - val_mae: 0.0263\n",
      "Epoch 30/50\n",
      "438/438 - 11s - 25ms/step - loss: 0.0026 - mae: 0.0401 - val_loss: 0.0010 - val_mae: 0.0214\n",
      "Epoch 31/50\n",
      "438/438 - 11s - 25ms/step - loss: 0.0025 - mae: 0.0396 - val_loss: 0.0010 - val_mae: 0.0217\n",
      "Epoch 32/50\n",
      "438/438 - 11s - 24ms/step - loss: 0.0025 - mae: 0.0397 - val_loss: 0.0013 - val_mae: 0.0271\n",
      "Epoch 33/50\n",
      "438/438 - 11s - 25ms/step - loss: 0.0025 - mae: 0.0399 - val_loss: 0.0011 - val_mae: 0.0236\n",
      "Epoch 34/50\n",
      "438/438 - 11s - 25ms/step - loss: 0.0026 - mae: 0.0401 - val_loss: 0.0014 - val_mae: 0.0270\n",
      "Epoch 35/50\n",
      "438/438 - 11s - 26ms/step - loss: 0.0025 - mae: 0.0396 - val_loss: 0.0013 - val_mae: 0.0282\n",
      "Epoch 36/50\n",
      "438/438 - 11s - 25ms/step - loss: 0.0025 - mae: 0.0397 - val_loss: 0.0011 - val_mae: 0.0231\n",
      "Epoch 37/50\n",
      "438/438 - 11s - 25ms/step - loss: 0.0025 - mae: 0.0396 - val_loss: 0.0010 - val_mae: 0.0209\n",
      "Epoch 38/50\n",
      "438/438 - 11s - 25ms/step - loss: 0.0025 - mae: 0.0397 - val_loss: 0.0011 - val_mae: 0.0219\n",
      "Epoch 39/50\n",
      "438/438 - 11s - 25ms/step - loss: 0.0026 - mae: 0.0400 - val_loss: 0.0013 - val_mae: 0.0277\n",
      "Epoch 40/50\n",
      "438/438 - 11s - 26ms/step - loss: 0.0025 - mae: 0.0397 - val_loss: 0.0011 - val_mae: 0.0222\n",
      "Epoch 41/50\n",
      "438/438 - 11s - 25ms/step - loss: 0.0026 - mae: 0.0397 - val_loss: 0.0012 - val_mae: 0.0245\n",
      "Epoch 42/50\n",
      "438/438 - 11s - 25ms/step - loss: 0.0025 - mae: 0.0395 - val_loss: 0.0011 - val_mae: 0.0225\n",
      "Epoch 43/50\n",
      "438/438 - 11s - 25ms/step - loss: 0.0026 - mae: 0.0397 - val_loss: 0.0011 - val_mae: 0.0225\n",
      "Epoch 44/50\n",
      "438/438 - 11s - 25ms/step - loss: 0.0025 - mae: 0.0396 - val_loss: 0.0012 - val_mae: 0.0254\n",
      "Epoch 45/50\n",
      "438/438 - 11s - 25ms/step - loss: 0.0025 - mae: 0.0397 - val_loss: 0.0013 - val_mae: 0.0271\n",
      "Epoch 46/50\n",
      "438/438 - 11s - 25ms/step - loss: 0.0025 - mae: 0.0395 - val_loss: 0.0014 - val_mae: 0.0272\n",
      "Epoch 47/50\n",
      "438/438 - 11s - 26ms/step - loss: 0.0025 - mae: 0.0397 - val_loss: 0.0010 - val_mae: 0.0209\n",
      "Epoch 48/50\n",
      "438/438 - 9s - 22ms/step - loss: 0.0025 - mae: 0.0396 - val_loss: 0.0011 - val_mae: 0.0222\n",
      "Epoch 49/50\n",
      "438/438 - 11s - 25ms/step - loss: 0.0025 - mae: 0.0397 - val_loss: 0.0012 - val_mae: 0.0224\n",
      "Epoch 50/50\n",
      "438/438 - 11s - 25ms/step - loss: 0.0025 - mae: 0.0396 - val_loss: 0.0011 - val_mae: 0.0216\n",
      "✅ Done with onion_Bijapur_daily.csv | MAE=369.82, RMSE=489.29, R2=0.54, MAPE=42.15%, Accuracy=57.85%\n",
      "\n",
      "🚀 Processing: onion_Chamrajnagar_daily.csv\n",
      "Epoch 1/50\n",
      "703/703 - 21s - 30ms/step - loss: 0.0178 - mae: 0.0688 - val_loss: 0.0031 - val_mae: 0.0386\n",
      "Epoch 2/50\n",
      "703/703 - 16s - 22ms/step - loss: 0.0041 - mae: 0.0398 - val_loss: 0.0050 - val_mae: 0.0639\n",
      "Epoch 3/50\n",
      "703/703 - 16s - 22ms/step - loss: 0.0033 - mae: 0.0347 - val_loss: 0.0021 - val_mae: 0.0342\n",
      "Epoch 4/50\n",
      "703/703 - 16s - 22ms/step - loss: 0.0031 - mae: 0.0326 - val_loss: 0.0019 - val_mae: 0.0337\n",
      "Epoch 5/50\n",
      "703/703 - 16s - 22ms/step - loss: 0.0030 - mae: 0.0308 - val_loss: 0.0032 - val_mae: 0.0403\n",
      "Epoch 6/50\n",
      "703/703 - 16s - 22ms/step - loss: 0.0029 - mae: 0.0304 - val_loss: 0.0021 - val_mae: 0.0362\n",
      "Epoch 7/50\n",
      "703/703 - 15s - 21ms/step - loss: 0.0030 - mae: 0.0308 - val_loss: 0.0019 - val_mae: 0.0344\n",
      "Epoch 8/50\n",
      "703/703 - 16s - 22ms/step - loss: 0.0029 - mae: 0.0291 - val_loss: 0.0024 - val_mae: 0.0375\n",
      "Epoch 9/50\n",
      "703/703 - 15s - 22ms/step - loss: 0.0029 - mae: 0.0298 - val_loss: 0.0023 - val_mae: 0.0346\n",
      "Epoch 10/50\n",
      "703/703 - 16s - 22ms/step - loss: 0.0028 - mae: 0.0285 - val_loss: 0.0019 - val_mae: 0.0337\n",
      "Epoch 11/50\n",
      "703/703 - 16s - 22ms/step - loss: 0.0029 - mae: 0.0299 - val_loss: 0.0020 - val_mae: 0.0349\n",
      "Epoch 12/50\n",
      "703/703 - 15s - 22ms/step - loss: 0.0028 - mae: 0.0281 - val_loss: 0.0020 - val_mae: 0.0339\n",
      "Epoch 13/50\n",
      "703/703 - 15s - 21ms/step - loss: 0.0028 - mae: 0.0287 - val_loss: 0.0048 - val_mae: 0.0609\n",
      "Epoch 14/50\n",
      "703/703 - 15s - 22ms/step - loss: 0.0028 - mae: 0.0284 - val_loss: 0.0022 - val_mae: 0.0344\n",
      "Epoch 15/50\n",
      "703/703 - 16s - 22ms/step - loss: 0.0028 - mae: 0.0280 - val_loss: 0.0020 - val_mae: 0.0338\n",
      "Epoch 16/50\n",
      "703/703 - 16s - 22ms/step - loss: 0.0027 - mae: 0.0277 - val_loss: 0.0027 - val_mae: 0.0420\n",
      "Epoch 17/50\n",
      "703/703 - 16s - 22ms/step - loss: 0.0028 - mae: 0.0273 - val_loss: 0.0036 - val_mae: 0.0509\n",
      "Epoch 18/50\n",
      "703/703 - 16s - 22ms/step - loss: 0.0027 - mae: 0.0271 - val_loss: 0.0052 - val_mae: 0.0619\n",
      "Epoch 19/50\n",
      "703/703 - 15s - 21ms/step - loss: 0.0027 - mae: 0.0271 - val_loss: 0.0032 - val_mae: 0.0486\n",
      "Epoch 20/50\n",
      "703/703 - 16s - 22ms/step - loss: 0.0027 - mae: 0.0270 - val_loss: 0.0022 - val_mae: 0.0343\n",
      "Epoch 21/50\n",
      "703/703 - 15s - 22ms/step - loss: 0.0027 - mae: 0.0273 - val_loss: 0.0023 - val_mae: 0.0350\n",
      "Epoch 22/50\n",
      "703/703 - 15s - 22ms/step - loss: 0.0027 - mae: 0.0268 - val_loss: 0.0021 - val_mae: 0.0360\n",
      "Epoch 23/50\n",
      "703/703 - 15s - 22ms/step - loss: 0.0027 - mae: 0.0270 - val_loss: 0.0020 - val_mae: 0.0340\n",
      "Epoch 24/50\n",
      "703/703 - 14s - 20ms/step - loss: 0.0026 - mae: 0.0266 - val_loss: 0.0021 - val_mae: 0.0343\n",
      "Epoch 25/50\n",
      "703/703 - 15s - 21ms/step - loss: 0.0027 - mae: 0.0270 - val_loss: 0.0025 - val_mae: 0.0353\n",
      "Epoch 26/50\n",
      "703/703 - 16s - 22ms/step - loss: 0.0026 - mae: 0.0266 - val_loss: 0.0020 - val_mae: 0.0339\n",
      "Epoch 27/50\n",
      "703/703 - 16s - 22ms/step - loss: 0.0027 - mae: 0.0268 - val_loss: 0.0022 - val_mae: 0.0346\n",
      "Epoch 28/50\n",
      "703/703 - 16s - 22ms/step - loss: 0.0027 - mae: 0.0269 - val_loss: 0.0051 - val_mae: 0.0617\n",
      "Epoch 29/50\n",
      "703/703 - 15s - 21ms/step - loss: 0.0026 - mae: 0.0263 - val_loss: 0.0034 - val_mae: 0.0439\n",
      "Epoch 30/50\n",
      "703/703 - 15s - 22ms/step - loss: 0.0027 - mae: 0.0269 - val_loss: 0.0019 - val_mae: 0.0338\n",
      "Epoch 31/50\n",
      "703/703 - 15s - 21ms/step - loss: 0.0027 - mae: 0.0263 - val_loss: 0.0019 - val_mae: 0.0339\n",
      "Epoch 32/50\n",
      "703/703 - 15s - 21ms/step - loss: 0.0027 - mae: 0.0269 - val_loss: 0.0018 - val_mae: 0.0339\n",
      "Epoch 33/50\n",
      "703/703 - 21s - 30ms/step - loss: 0.0026 - mae: 0.0266 - val_loss: 0.0019 - val_mae: 0.0339\n",
      "Epoch 34/50\n",
      "703/703 - 15s - 22ms/step - loss: 0.0026 - mae: 0.0264 - val_loss: 0.0019 - val_mae: 0.0343\n",
      "Epoch 35/50\n",
      "703/703 - 16s - 22ms/step - loss: 0.0026 - mae: 0.0262 - val_loss: 0.0022 - val_mae: 0.0349\n",
      "Epoch 36/50\n",
      "703/703 - 15s - 22ms/step - loss: 0.0026 - mae: 0.0262 - val_loss: 0.0033 - val_mae: 0.0465\n",
      "Epoch 37/50\n",
      "703/703 - 15s - 22ms/step - loss: 0.0026 - mae: 0.0264 - val_loss: 0.0025 - val_mae: 0.0411\n",
      "Epoch 38/50\n",
      "703/703 - 15s - 22ms/step - loss: 0.0026 - mae: 0.0265 - val_loss: 0.0020 - val_mae: 0.0341\n",
      "Epoch 39/50\n",
      "703/703 - 15s - 22ms/step - loss: 0.0027 - mae: 0.0265 - val_loss: 0.0021 - val_mae: 0.0365\n",
      "Epoch 40/50\n",
      "703/703 - 16s - 22ms/step - loss: 0.0026 - mae: 0.0264 - val_loss: 0.0020 - val_mae: 0.0339\n",
      "Epoch 41/50\n",
      "703/703 - 15s - 22ms/step - loss: 0.0026 - mae: 0.0259 - val_loss: 0.0025 - val_mae: 0.0359\n",
      "Epoch 42/50\n",
      "703/703 - 16s - 22ms/step - loss: 0.0026 - mae: 0.0258 - val_loss: 0.0029 - val_mae: 0.0392\n",
      "Epoch 43/50\n",
      "703/703 - 15s - 22ms/step - loss: 0.0026 - mae: 0.0261 - val_loss: 0.0019 - val_mae: 0.0336\n",
      "Epoch 44/50\n",
      "703/703 - 15s - 22ms/step - loss: 0.0026 - mae: 0.0260 - val_loss: 0.0034 - val_mae: 0.0475\n",
      "Epoch 45/50\n",
      "703/703 - 14s - 21ms/step - loss: 0.0026 - mae: 0.0257 - val_loss: 0.0020 - val_mae: 0.0338\n",
      "Epoch 46/50\n",
      "703/703 - 13s - 19ms/step - loss: 0.0026 - mae: 0.0259 - val_loss: 0.0018 - val_mae: 0.0335\n",
      "Epoch 47/50\n",
      "703/703 - 11s - 15ms/step - loss: 0.0026 - mae: 0.0259 - val_loss: 0.0019 - val_mae: 0.0338\n",
      "Epoch 48/50\n",
      "703/703 - 15s - 21ms/step - loss: 0.0026 - mae: 0.0258 - val_loss: 0.0018 - val_mae: 0.0336\n",
      "Epoch 49/50\n",
      "703/703 - 21s - 29ms/step - loss: 0.0026 - mae: 0.0258 - val_loss: 0.0021 - val_mae: 0.0349\n",
      "Epoch 50/50\n",
      "703/703 - 15s - 22ms/step - loss: 0.0026 - mae: 0.0256 - val_loss: 0.0017 - val_mae: 0.0337\n",
      "✅ Done with onion_Chamrajnagar_daily.csv | MAE=390.74, RMSE=680.03, R2=0.68, MAPE=40.29%, Accuracy=59.71%\n",
      "\n",
      "🚀 Processing: onion_Chikmagalur_daily.csv\n",
      "Epoch 1/50\n",
      "1083/1083 - 22s - 20ms/step - loss: 0.0249 - mae: 0.1150 - val_loss: 0.0197 - val_mae: 0.1101\n",
      "Epoch 2/50\n",
      "1083/1083 - 21s - 19ms/step - loss: 0.0153 - mae: 0.0907 - val_loss: 0.0062 - val_mae: 0.0572\n",
      "Epoch 3/50\n",
      "1083/1083 - 20s - 18ms/step - loss: 0.0140 - mae: 0.0846 - val_loss: 0.0058 - val_mae: 0.0564\n",
      "Epoch 4/50\n",
      "1083/1083 - 15s - 14ms/step - loss: 0.0138 - mae: 0.0835 - val_loss: 0.0062 - val_mae: 0.0625\n",
      "Epoch 5/50\n",
      "1083/1083 - 21s - 19ms/step - loss: 0.0136 - mae: 0.0827 - val_loss: 0.0073 - val_mae: 0.0679\n",
      "Epoch 6/50\n",
      "1083/1083 - 16s - 15ms/step - loss: 0.0135 - mae: 0.0821 - val_loss: 0.0063 - val_mae: 0.0564\n",
      "Epoch 7/50\n",
      "1083/1083 - 16s - 15ms/step - loss: 0.0134 - mae: 0.0815 - val_loss: 0.0063 - val_mae: 0.0627\n",
      "Epoch 8/50\n",
      "1083/1083 - 10s - 10ms/step - loss: 0.0133 - mae: 0.0815 - val_loss: 0.0056 - val_mae: 0.0578\n",
      "Epoch 9/50\n",
      "1083/1083 - 11s - 10ms/step - loss: 0.0133 - mae: 0.0811 - val_loss: 0.0061 - val_mae: 0.0595\n",
      "Epoch 10/50\n",
      "1083/1083 - 11s - 10ms/step - loss: 0.0132 - mae: 0.0808 - val_loss: 0.0057 - val_mae: 0.0562\n",
      "Epoch 11/50\n",
      "1083/1083 - 13s - 12ms/step - loss: 0.0130 - mae: 0.0796 - val_loss: 0.0068 - val_mae: 0.0664\n",
      "Epoch 12/50\n",
      "1083/1083 - 14s - 13ms/step - loss: 0.0130 - mae: 0.0795 - val_loss: 0.0057 - val_mae: 0.0590\n",
      "Epoch 13/50\n",
      "1083/1083 - 11s - 11ms/step - loss: 0.0130 - mae: 0.0797 - val_loss: 0.0065 - val_mae: 0.0631\n",
      "Epoch 14/50\n",
      "1083/1083 - 28s - 26ms/step - loss: 0.0128 - mae: 0.0786 - val_loss: 0.0056 - val_mae: 0.0579\n",
      "Epoch 15/50\n",
      "1083/1083 - 10s - 10ms/step - loss: 0.0128 - mae: 0.0788 - val_loss: 0.0064 - val_mae: 0.0585\n",
      "Epoch 16/50\n",
      "1083/1083 - 11s - 10ms/step - loss: 0.0128 - mae: 0.0785 - val_loss: 0.0058 - val_mae: 0.0594\n",
      "Epoch 17/50\n",
      "1083/1083 - 10s - 9ms/step - loss: 0.0127 - mae: 0.0780 - val_loss: 0.0058 - val_mae: 0.0595\n",
      "Epoch 18/50\n",
      "1083/1083 - 14s - 13ms/step - loss: 0.0128 - mae: 0.0786 - val_loss: 0.0057 - val_mae: 0.0578\n",
      "Epoch 19/50\n",
      "1083/1083 - 17s - 15ms/step - loss: 0.0128 - mae: 0.0784 - val_loss: 0.0057 - val_mae: 0.0561\n",
      "Epoch 20/50\n",
      "1083/1083 - 13s - 12ms/step - loss: 0.0127 - mae: 0.0783 - val_loss: 0.0057 - val_mae: 0.0566\n",
      "Epoch 21/50\n",
      "1083/1083 - 16s - 15ms/step - loss: 0.0128 - mae: 0.0782 - val_loss: 0.0056 - val_mae: 0.0582\n",
      "Epoch 22/50\n",
      "1083/1083 - 11s - 10ms/step - loss: 0.0127 - mae: 0.0781 - val_loss: 0.0062 - val_mae: 0.0561\n",
      "Epoch 23/50\n",
      "1083/1083 - 10s - 9ms/step - loss: 0.0127 - mae: 0.0782 - val_loss: 0.0057 - val_mae: 0.0574\n",
      "Epoch 24/50\n",
      "1083/1083 - 12s - 11ms/step - loss: 0.0127 - mae: 0.0782 - val_loss: 0.0057 - val_mae: 0.0573\n",
      "Epoch 25/50\n",
      "1083/1083 - 14s - 13ms/step - loss: 0.0127 - mae: 0.0778 - val_loss: 0.0057 - val_mae: 0.0583\n",
      "Epoch 26/50\n",
      "1083/1083 - 10s - 9ms/step - loss: 0.0127 - mae: 0.0780 - val_loss: 0.0058 - val_mae: 0.0590\n",
      "Epoch 27/50\n",
      "1083/1083 - 13s - 12ms/step - loss: 0.0127 - mae: 0.0779 - val_loss: 0.0061 - val_mae: 0.0613\n",
      "Epoch 28/50\n",
      "1083/1083 - 11s - 10ms/step - loss: 0.0127 - mae: 0.0777 - val_loss: 0.0056 - val_mae: 0.0575\n",
      "Epoch 29/50\n",
      "1083/1083 - 12s - 11ms/step - loss: 0.0126 - mae: 0.0777 - val_loss: 0.0061 - val_mae: 0.0614\n",
      "Epoch 30/50\n",
      "1083/1083 - 14s - 13ms/step - loss: 0.0127 - mae: 0.0779 - val_loss: 0.0073 - val_mae: 0.0663\n",
      "Epoch 31/50\n",
      "1083/1083 - 12s - 11ms/step - loss: 0.0126 - mae: 0.0775 - val_loss: 0.0059 - val_mae: 0.0600\n",
      "Epoch 32/50\n",
      "1083/1083 - 17s - 16ms/step - loss: 0.0126 - mae: 0.0776 - val_loss: 0.0062 - val_mae: 0.0622\n",
      "Epoch 33/50\n",
      "1083/1083 - 13s - 12ms/step - loss: 0.0126 - mae: 0.0775 - val_loss: 0.0056 - val_mae: 0.0569\n",
      "Epoch 34/50\n",
      "1083/1083 - 17s - 16ms/step - loss: 0.0127 - mae: 0.0776 - val_loss: 0.0060 - val_mae: 0.0611\n",
      "Epoch 35/50\n",
      "1083/1083 - 16s - 15ms/step - loss: 0.0126 - mae: 0.0775 - val_loss: 0.0056 - val_mae: 0.0564\n",
      "Epoch 36/50\n",
      "1083/1083 - 14s - 13ms/step - loss: 0.0126 - mae: 0.0777 - val_loss: 0.0059 - val_mae: 0.0592\n",
      "Epoch 37/50\n",
      "1083/1083 - 10s - 10ms/step - loss: 0.0126 - mae: 0.0777 - val_loss: 0.0080 - val_mae: 0.0690\n",
      "Epoch 38/50\n",
      "1083/1083 - 14s - 13ms/step - loss: 0.0126 - mae: 0.0775 - val_loss: 0.0056 - val_mae: 0.0574\n",
      "Epoch 39/50\n",
      "1083/1083 - 18s - 17ms/step - loss: 0.0127 - mae: 0.0773 - val_loss: 0.0070 - val_mae: 0.0663\n",
      "Epoch 40/50\n",
      "1083/1083 - 19s - 18ms/step - loss: 0.0127 - mae: 0.0776 - val_loss: 0.0063 - val_mae: 0.0621\n",
      "Epoch 41/50\n",
      "1083/1083 - 18s - 17ms/step - loss: 0.0126 - mae: 0.0770 - val_loss: 0.0073 - val_mae: 0.0663\n",
      "Epoch 42/50\n",
      "1083/1083 - 17s - 16ms/step - loss: 0.0126 - mae: 0.0774 - val_loss: 0.0058 - val_mae: 0.0559\n",
      "Epoch 43/50\n",
      "1083/1083 - 18s - 17ms/step - loss: 0.0126 - mae: 0.0771 - val_loss: 0.0064 - val_mae: 0.0627\n",
      "Epoch 44/50\n",
      "1083/1083 - 19s - 17ms/step - loss: 0.0126 - mae: 0.0774 - val_loss: 0.0058 - val_mae: 0.0576\n",
      "Epoch 45/50\n",
      "1083/1083 - 10s - 9ms/step - loss: 0.0126 - mae: 0.0772 - val_loss: 0.0061 - val_mae: 0.0563\n",
      "Epoch 46/50\n",
      "1083/1083 - 19s - 18ms/step - loss: 0.0126 - mae: 0.0772 - val_loss: 0.0074 - val_mae: 0.0681\n",
      "Epoch 47/50\n",
      "1083/1083 - 13s - 12ms/step - loss: 0.0126 - mae: 0.0772 - val_loss: 0.0056 - val_mae: 0.0570\n",
      "Epoch 48/50\n",
      "1083/1083 - 10s - 9ms/step - loss: 0.0125 - mae: 0.0769 - val_loss: 0.0062 - val_mae: 0.0622\n",
      "Epoch 49/50\n",
      "1083/1083 - 10s - 9ms/step - loss: 0.0125 - mae: 0.0770 - val_loss: 0.0063 - val_mae: 0.0624\n",
      "Epoch 50/50\n",
      "1083/1083 - 11s - 10ms/step - loss: 0.0126 - mae: 0.0771 - val_loss: 0.0060 - val_mae: 0.0605\n",
      "✅ Done with onion_Chikmagalur_daily.csv | MAE=520.88, RMSE=741.2, R2=0.45, MAPE=36.91%, Accuracy=63.09%\n",
      "\n",
      "🚀 Processing: onion_Chitradurga_daily.csv\n",
      "Epoch 1/50\n",
      "376/376 - 8s - 23ms/step - loss: 0.0748 - mae: 0.2076 - val_loss: 0.0074 - val_mae: 0.0725\n",
      "Epoch 2/50\n",
      "376/376 - 4s - 10ms/step - loss: 0.0539 - mae: 0.1849 - val_loss: 0.0020 - val_mae: 0.0385\n",
      "Epoch 3/50\n",
      "376/376 - 4s - 11ms/step - loss: 0.0500 - mae: 0.1749 - val_loss: 0.0010 - val_mae: 0.0280\n",
      "Epoch 4/50\n",
      "376/376 - 5s - 12ms/step - loss: 0.0478 - mae: 0.1688 - val_loss: 0.0012 - val_mae: 0.0299\n",
      "Epoch 5/50\n",
      "376/376 - 4s - 9ms/step - loss: 0.0480 - mae: 0.1677 - val_loss: 8.8176e-04 - val_mae: 0.0232\n",
      "Epoch 6/50\n",
      "376/376 - 3s - 9ms/step - loss: 0.0475 - mae: 0.1668 - val_loss: 6.4190e-04 - val_mae: 0.0219\n",
      "Epoch 7/50\n",
      "376/376 - 4s - 10ms/step - loss: 0.0468 - mae: 0.1649 - val_loss: 3.1540e-04 - val_mae: 0.0142\n",
      "Epoch 8/50\n",
      "376/376 - 4s - 10ms/step - loss: 0.0477 - mae: 0.1678 - val_loss: 5.9486e-04 - val_mae: 0.0210\n",
      "Epoch 9/50\n",
      "376/376 - 4s - 11ms/step - loss: 0.0477 - mae: 0.1670 - val_loss: 0.0033 - val_mae: 0.0534\n",
      "Epoch 10/50\n",
      "376/376 - 5s - 12ms/step - loss: 0.0472 - mae: 0.1671 - val_loss: 7.3500e-04 - val_mae: 0.0235\n",
      "Epoch 11/50\n",
      "376/376 - 7s - 17ms/step - loss: 0.0476 - mae: 0.1671 - val_loss: 0.0013 - val_mae: 0.0321\n",
      "Epoch 12/50\n",
      "376/376 - 7s - 19ms/step - loss: 0.0470 - mae: 0.1652 - val_loss: 4.5611e-04 - val_mae: 0.0145\n",
      "Epoch 13/50\n",
      "376/376 - 5s - 14ms/step - loss: 0.0460 - mae: 0.1626 - val_loss: 0.0022 - val_mae: 0.0407\n",
      "Epoch 14/50\n",
      "376/376 - 3s - 9ms/step - loss: 0.0471 - mae: 0.1663 - val_loss: 2.4526e-04 - val_mae: 0.0104\n",
      "Epoch 15/50\n",
      "376/376 - 4s - 10ms/step - loss: 0.0461 - mae: 0.1631 - val_loss: 0.0043 - val_mae: 0.0617\n",
      "Epoch 16/50\n",
      "376/376 - 5s - 14ms/step - loss: 0.0469 - mae: 0.1648 - val_loss: 0.0035 - val_mae: 0.0534\n",
      "Epoch 17/50\n",
      "376/376 - 3s - 9ms/step - loss: 0.0464 - mae: 0.1638 - val_loss: 0.0080 - val_mae: 0.0874\n",
      "Epoch 18/50\n",
      "376/376 - 4s - 10ms/step - loss: 0.0462 - mae: 0.1640 - val_loss: 2.9912e-04 - val_mae: 0.0140\n",
      "Epoch 19/50\n",
      "376/376 - 4s - 11ms/step - loss: 0.0459 - mae: 0.1625 - val_loss: 0.0012 - val_mae: 0.0276\n",
      "Epoch 20/50\n",
      "376/376 - 4s - 11ms/step - loss: 0.0461 - mae: 0.1637 - val_loss: 8.4365e-04 - val_mae: 0.0277\n",
      "Epoch 21/50\n",
      "376/376 - 5s - 13ms/step - loss: 0.0459 - mae: 0.1622 - val_loss: 0.0067 - val_mae: 0.0798\n",
      "Epoch 22/50\n",
      "376/376 - 8s - 22ms/step - loss: 0.0462 - mae: 0.1639 - val_loss: 0.0010 - val_mae: 0.0278\n",
      "Epoch 23/50\n",
      "376/376 - 4s - 12ms/step - loss: 0.0457 - mae: 0.1617 - val_loss: 0.0015 - val_mae: 0.0344\n",
      "Epoch 24/50\n",
      "376/376 - 6s - 15ms/step - loss: 0.0464 - mae: 0.1644 - val_loss: 0.0016 - val_mae: 0.0335\n",
      "Epoch 25/50\n",
      "376/376 - 4s - 10ms/step - loss: 0.0456 - mae: 0.1618 - val_loss: 0.0015 - val_mae: 0.0362\n",
      "Epoch 26/50\n",
      "376/376 - 4s - 10ms/step - loss: 0.0461 - mae: 0.1622 - val_loss: 0.0015 - val_mae: 0.0369\n",
      "Epoch 27/50\n",
      "376/376 - 3s - 9ms/step - loss: 0.0458 - mae: 0.1620 - val_loss: 0.0060 - val_mae: 0.0767\n",
      "Epoch 28/50\n",
      "376/376 - 4s - 11ms/step - loss: 0.0456 - mae: 0.1617 - val_loss: 9.5392e-04 - val_mae: 0.0298\n",
      "Epoch 29/50\n",
      "376/376 - 4s - 11ms/step - loss: 0.0457 - mae: 0.1623 - val_loss: 0.0046 - val_mae: 0.0656\n",
      "Epoch 30/50\n",
      "376/376 - 7s - 17ms/step - loss: 0.0458 - mae: 0.1621 - val_loss: 1.7616e-04 - val_mae: 0.0111\n",
      "Epoch 31/50\n",
      "376/376 - 5s - 13ms/step - loss: 0.0456 - mae: 0.1611 - val_loss: 0.0088 - val_mae: 0.0918\n",
      "Epoch 32/50\n",
      "376/376 - 5s - 12ms/step - loss: 0.0455 - mae: 0.1612 - val_loss: 0.0023 - val_mae: 0.0456\n",
      "Epoch 33/50\n",
      "376/376 - 5s - 13ms/step - loss: 0.0455 - mae: 0.1610 - val_loss: 0.0028 - val_mae: 0.0523\n",
      "Epoch 34/50\n",
      "376/376 - 4s - 10ms/step - loss: 0.0458 - mae: 0.1616 - val_loss: 0.0018 - val_mae: 0.0404\n",
      "Epoch 35/50\n",
      "376/376 - 4s - 10ms/step - loss: 0.0455 - mae: 0.1609 - val_loss: 1.7297e-04 - val_mae: 0.0112\n",
      "Epoch 36/50\n",
      "376/376 - 4s - 10ms/step - loss: 0.0458 - mae: 0.1618 - val_loss: 0.0023 - val_mae: 0.0470\n",
      "Epoch 37/50\n",
      "376/376 - 3s - 9ms/step - loss: 0.0455 - mae: 0.1607 - val_loss: 0.0019 - val_mae: 0.0423\n",
      "Epoch 38/50\n",
      "376/376 - 6s - 16ms/step - loss: 0.0456 - mae: 0.1606 - val_loss: 2.9253e-04 - val_mae: 0.0146\n",
      "Epoch 39/50\n",
      "376/376 - 4s - 10ms/step - loss: 0.0458 - mae: 0.1626 - val_loss: 0.0032 - val_mae: 0.0560\n",
      "Epoch 40/50\n",
      "376/376 - 3s - 9ms/step - loss: 0.0455 - mae: 0.1607 - val_loss: 1.5801e-04 - val_mae: 0.0103\n",
      "Epoch 41/50\n",
      "376/376 - 7s - 18ms/step - loss: 0.0456 - mae: 0.1614 - val_loss: 0.0027 - val_mae: 0.0515\n",
      "Epoch 42/50\n",
      "376/376 - 4s - 10ms/step - loss: 0.0456 - mae: 0.1606 - val_loss: 0.0019 - val_mae: 0.0425\n",
      "Epoch 43/50\n",
      "376/376 - 4s - 10ms/step - loss: 0.0455 - mae: 0.1605 - val_loss: 2.2819e-04 - val_mae: 0.0128\n",
      "Epoch 44/50\n",
      "376/376 - 4s - 10ms/step - loss: 0.0455 - mae: 0.1602 - val_loss: 3.2761e-04 - val_mae: 0.0153\n",
      "Epoch 45/50\n",
      "376/376 - 7s - 18ms/step - loss: 0.0454 - mae: 0.1604 - val_loss: 8.6884e-04 - val_mae: 0.0278\n",
      "Epoch 46/50\n",
      "376/376 - 3s - 9ms/step - loss: 0.0454 - mae: 0.1606 - val_loss: 0.0035 - val_mae: 0.0558\n",
      "Epoch 47/50\n",
      "376/376 - 5s - 12ms/step - loss: 0.0454 - mae: 0.1607 - val_loss: 5.1360e-04 - val_mae: 0.0219\n",
      "Epoch 48/50\n",
      "376/376 - 4s - 11ms/step - loss: 0.0454 - mae: 0.1602 - val_loss: 5.7410e-05 - val_mae: 0.0049\n",
      "Epoch 49/50\n",
      "376/376 - 3s - 9ms/step - loss: 0.0455 - mae: 0.1602 - val_loss: 3.5958e-04 - val_mae: 0.0174\n",
      "Epoch 50/50\n",
      "376/376 - 6s - 17ms/step - loss: 0.0453 - mae: 0.1601 - val_loss: 9.0177e-04 - val_mae: 0.0291\n",
      "✅ Done with onion_Chitradurga_daily.csv | MAE=446.14, RMSE=644.84, R2=0.25, MAPE=37.37%, Accuracy=62.63%\n",
      "\n",
      "🚀 Processing: onion_Davangere_daily.csv\n",
      "Epoch 1/50\n",
      "493/493 - 15s - 31ms/step - loss: 0.0253 - mae: 0.0733 - val_loss: 0.0037 - val_mae: 0.0335\n",
      "Epoch 2/50\n",
      "493/493 - 6s - 11ms/step - loss: 0.0021 - mae: 0.0351 - val_loss: 0.0043 - val_mae: 0.0384\n",
      "Epoch 3/50\n",
      "493/493 - 6s - 13ms/step - loss: 0.0015 - mae: 0.0294 - val_loss: 0.0047 - val_mae: 0.0406\n",
      "Epoch 4/50\n",
      "493/493 - 6s - 11ms/step - loss: 0.0015 - mae: 0.0286 - val_loss: 0.0036 - val_mae: 0.0342\n",
      "Epoch 5/50\n",
      "493/493 - 5s - 11ms/step - loss: 0.0012 - mae: 0.0258 - val_loss: 0.0048 - val_mae: 0.0416\n",
      "Epoch 6/50\n",
      "493/493 - 6s - 12ms/step - loss: 0.0011 - mae: 0.0241 - val_loss: 0.0037 - val_mae: 0.0328\n",
      "Epoch 7/50\n",
      "493/493 - 5s - 11ms/step - loss: 0.0010 - mae: 0.0232 - val_loss: 0.0038 - val_mae: 0.0331\n",
      "Epoch 8/50\n",
      "493/493 - 7s - 14ms/step - loss: 0.0011 - mae: 0.0233 - val_loss: 0.0044 - val_mae: 0.0404\n",
      "Epoch 9/50\n",
      "493/493 - 7s - 14ms/step - loss: 0.0011 - mae: 0.0240 - val_loss: 0.0039 - val_mae: 0.0340\n",
      "Epoch 10/50\n",
      "493/493 - 6s - 11ms/step - loss: 9.9485e-04 - mae: 0.0223 - val_loss: 0.0038 - val_mae: 0.0342\n",
      "Epoch 11/50\n",
      "493/493 - 8s - 15ms/step - loss: 0.0010 - mae: 0.0234 - val_loss: 0.0032 - val_mae: 0.0327\n",
      "Epoch 12/50\n",
      "493/493 - 5s - 11ms/step - loss: 9.8514e-04 - mae: 0.0222 - val_loss: 0.0039 - val_mae: 0.0354\n",
      "Epoch 13/50\n",
      "493/493 - 5s - 10ms/step - loss: 9.3279e-04 - mae: 0.0215 - val_loss: 0.0029 - val_mae: 0.0306\n",
      "Epoch 14/50\n",
      "493/493 - 7s - 14ms/step - loss: 9.6786e-04 - mae: 0.0221 - val_loss: 0.0027 - val_mae: 0.0338\n",
      "Epoch 15/50\n",
      "493/493 - 5s - 11ms/step - loss: 9.3102e-04 - mae: 0.0216 - val_loss: 0.0031 - val_mae: 0.0286\n",
      "Epoch 16/50\n",
      "493/493 - 7s - 15ms/step - loss: 9.6004e-04 - mae: 0.0220 - val_loss: 0.0028 - val_mae: 0.0277\n",
      "Epoch 17/50\n",
      "493/493 - 5s - 11ms/step - loss: 9.2703e-04 - mae: 0.0214 - val_loss: 0.0035 - val_mae: 0.0330\n",
      "Epoch 18/50\n",
      "493/493 - 10s - 20ms/step - loss: 9.2604e-04 - mae: 0.0215 - val_loss: 0.0025 - val_mae: 0.0319\n",
      "Epoch 19/50\n",
      "493/493 - 5s - 10ms/step - loss: 9.6385e-04 - mae: 0.0220 - val_loss: 0.0025 - val_mae: 0.0252\n",
      "Epoch 20/50\n",
      "493/493 - 8s - 16ms/step - loss: 9.0985e-04 - mae: 0.0213 - val_loss: 0.0036 - val_mae: 0.0389\n",
      "Epoch 21/50\n",
      "493/493 - 5s - 10ms/step - loss: 9.1049e-04 - mae: 0.0212 - val_loss: 0.0023 - val_mae: 0.0255\n",
      "Epoch 22/50\n",
      "493/493 - 7s - 14ms/step - loss: 9.1736e-04 - mae: 0.0213 - val_loss: 0.0026 - val_mae: 0.0289\n",
      "Epoch 23/50\n",
      "493/493 - 6s - 11ms/step - loss: 9.2482e-04 - mae: 0.0213 - val_loss: 0.0021 - val_mae: 0.0228\n",
      "Epoch 24/50\n",
      "493/493 - 6s - 12ms/step - loss: 9.0434e-04 - mae: 0.0213 - val_loss: 0.0021 - val_mae: 0.0236\n",
      "Epoch 25/50\n",
      "493/493 - 7s - 13ms/step - loss: 8.8680e-04 - mae: 0.0210 - val_loss: 0.0021 - val_mae: 0.0233\n",
      "Epoch 26/50\n",
      "493/493 - 5s - 11ms/step - loss: 9.0074e-04 - mae: 0.0210 - val_loss: 0.0018 - val_mae: 0.0231\n",
      "Epoch 27/50\n",
      "493/493 - 6s - 12ms/step - loss: 9.2055e-04 - mae: 0.0214 - val_loss: 0.0019 - val_mae: 0.0219\n",
      "Epoch 28/50\n",
      "493/493 - 7s - 13ms/step - loss: 8.9435e-04 - mae: 0.0210 - val_loss: 0.0017 - val_mae: 0.0197\n",
      "Epoch 29/50\n",
      "493/493 - 6s - 12ms/step - loss: 8.9927e-04 - mae: 0.0209 - val_loss: 0.0022 - val_mae: 0.0238\n",
      "Epoch 30/50\n",
      "493/493 - 5s - 10ms/step - loss: 9.1832e-04 - mae: 0.0212 - val_loss: 0.0019 - val_mae: 0.0223\n",
      "Epoch 31/50\n",
      "493/493 - 5s - 11ms/step - loss: 8.9666e-04 - mae: 0.0209 - val_loss: 0.0020 - val_mae: 0.0220\n",
      "Epoch 32/50\n",
      "493/493 - 6s - 11ms/step - loss: 8.7813e-04 - mae: 0.0206 - val_loss: 0.0018 - val_mae: 0.0206\n",
      "Epoch 33/50\n",
      "493/493 - 5s - 11ms/step - loss: 8.9031e-04 - mae: 0.0208 - val_loss: 0.0026 - val_mae: 0.0268\n",
      "Epoch 34/50\n",
      "493/493 - 6s - 13ms/step - loss: 8.9575e-04 - mae: 0.0210 - val_loss: 0.0020 - val_mae: 0.0232\n",
      "Epoch 35/50\n",
      "493/493 - 5s - 10ms/step - loss: 8.9558e-04 - mae: 0.0209 - val_loss: 0.0017 - val_mae: 0.0199\n",
      "Epoch 36/50\n",
      "493/493 - 10s - 20ms/step - loss: 8.9804e-04 - mae: 0.0209 - val_loss: 0.0018 - val_mae: 0.0204\n",
      "Epoch 37/50\n",
      "493/493 - 7s - 14ms/step - loss: 8.7307e-04 - mae: 0.0206 - val_loss: 0.0018 - val_mae: 0.0204\n",
      "Epoch 38/50\n",
      "493/493 - 7s - 14ms/step - loss: 8.9977e-04 - mae: 0.0209 - val_loss: 0.0022 - val_mae: 0.0240\n",
      "Epoch 39/50\n",
      "493/493 - 7s - 15ms/step - loss: 8.7771e-04 - mae: 0.0206 - val_loss: 0.0022 - val_mae: 0.0251\n",
      "Epoch 40/50\n",
      "493/493 - 5s - 11ms/step - loss: 8.9607e-04 - mae: 0.0210 - val_loss: 0.0023 - val_mae: 0.0259\n",
      "Epoch 41/50\n",
      "493/493 - 5s - 11ms/step - loss: 8.7995e-04 - mae: 0.0207 - val_loss: 0.0017 - val_mae: 0.0189\n",
      "Epoch 42/50\n",
      "493/493 - 6s - 12ms/step - loss: 8.8362e-04 - mae: 0.0207 - val_loss: 0.0016 - val_mae: 0.0191\n",
      "Epoch 43/50\n",
      "493/493 - 5s - 11ms/step - loss: 8.7415e-04 - mae: 0.0206 - val_loss: 0.0020 - val_mae: 0.0252\n",
      "Epoch 44/50\n",
      "493/493 - 5s - 10ms/step - loss: 9.0412e-04 - mae: 0.0211 - val_loss: 0.0017 - val_mae: 0.0217\n",
      "Epoch 45/50\n",
      "493/493 - 5s - 11ms/step - loss: 8.6883e-04 - mae: 0.0206 - val_loss: 0.0017 - val_mae: 0.0190\n",
      "Epoch 46/50\n",
      "493/493 - 5s - 11ms/step - loss: 8.8224e-04 - mae: 0.0208 - val_loss: 0.0016 - val_mae: 0.0192\n",
      "Epoch 47/50\n",
      "493/493 - 7s - 14ms/step - loss: 8.8441e-04 - mae: 0.0206 - val_loss: 0.0016 - val_mae: 0.0196\n",
      "Epoch 48/50\n",
      "493/493 - 6s - 13ms/step - loss: 8.8488e-04 - mae: 0.0207 - val_loss: 0.0016 - val_mae: 0.0183\n",
      "Epoch 49/50\n",
      "493/493 - 5s - 10ms/step - loss: 8.7854e-04 - mae: 0.0206 - val_loss: 0.0016 - val_mae: 0.0182\n",
      "Epoch 50/50\n",
      "493/493 - 5s - 11ms/step - loss: 8.6493e-04 - mae: 0.0204 - val_loss: 0.0016 - val_mae: 0.0182\n",
      "✅ Done with onion_Davangere_daily.csv | MAE=248.09, RMSE=396.92, R2=0.65, MAPE=28.48%, Accuracy=71.52%\n",
      "\n",
      "🚀 Processing: onion_Dharwad_daily.csv\n",
      "Epoch 1/50\n",
      "280/280 - 8s - 29ms/step - loss: 0.0652 - mae: 0.1337 - val_loss: 0.0085 - val_mae: 0.0656\n",
      "Epoch 2/50\n",
      "280/280 - 3s - 10ms/step - loss: 0.0094 - mae: 0.0728 - val_loss: 0.0042 - val_mae: 0.0476\n",
      "Epoch 3/50\n",
      "280/280 - 3s - 11ms/step - loss: 0.0064 - mae: 0.0584 - val_loss: 0.0100 - val_mae: 0.0911\n",
      "Epoch 4/50\n",
      "280/280 - 3s - 11ms/step - loss: 0.0051 - mae: 0.0517 - val_loss: 0.0030 - val_mae: 0.0425\n",
      "Epoch 5/50\n",
      "280/280 - 5s - 16ms/step - loss: 0.0042 - mae: 0.0460 - val_loss: 0.0032 - val_mae: 0.0443\n",
      "Epoch 6/50\n",
      "280/280 - 5s - 19ms/step - loss: 0.0040 - mae: 0.0447 - val_loss: 0.0061 - val_mae: 0.0655\n",
      "Epoch 7/50\n",
      "280/280 - 5s - 19ms/step - loss: 0.0034 - mae: 0.0405 - val_loss: 0.0030 - val_mae: 0.0423\n",
      "Epoch 8/50\n",
      "280/280 - 3s - 11ms/step - loss: 0.0032 - mae: 0.0389 - val_loss: 0.0031 - val_mae: 0.0427\n",
      "Epoch 9/50\n",
      "280/280 - 4s - 15ms/step - loss: 0.0031 - mae: 0.0376 - val_loss: 0.0048 - val_mae: 0.0547\n",
      "Epoch 10/50\n",
      "280/280 - 4s - 14ms/step - loss: 0.0030 - mae: 0.0370 - val_loss: 0.0033 - val_mae: 0.0445\n",
      "Epoch 11/50\n",
      "280/280 - 3s - 11ms/step - loss: 0.0027 - mae: 0.0355 - val_loss: 0.0026 - val_mae: 0.0380\n",
      "Epoch 12/50\n",
      "280/280 - 4s - 15ms/step - loss: 0.0026 - mae: 0.0334 - val_loss: 0.0034 - val_mae: 0.0447\n",
      "Epoch 13/50\n",
      "280/280 - 3s - 9ms/step - loss: 0.0029 - mae: 0.0364 - val_loss: 0.0035 - val_mae: 0.0448\n",
      "Epoch 14/50\n",
      "280/280 - 3s - 11ms/step - loss: 0.0026 - mae: 0.0337 - val_loss: 0.0030 - val_mae: 0.0422\n",
      "Epoch 15/50\n",
      "280/280 - 3s - 10ms/step - loss: 0.0025 - mae: 0.0328 - val_loss: 0.0063 - val_mae: 0.0691\n",
      "Epoch 16/50\n",
      "280/280 - 3s - 11ms/step - loss: 0.0026 - mae: 0.0342 - val_loss: 0.0033 - val_mae: 0.0447\n",
      "Epoch 17/50\n",
      "280/280 - 3s - 11ms/step - loss: 0.0026 - mae: 0.0346 - val_loss: 0.0025 - val_mae: 0.0367\n",
      "Epoch 18/50\n",
      "280/280 - 4s - 14ms/step - loss: 0.0024 - mae: 0.0320 - val_loss: 0.0022 - val_mae: 0.0323\n",
      "Epoch 19/50\n",
      "280/280 - 3s - 11ms/step - loss: 0.0025 - mae: 0.0336 - val_loss: 0.0024 - val_mae: 0.0351\n",
      "Epoch 20/50\n",
      "280/280 - 3s - 9ms/step - loss: 0.0024 - mae: 0.0325 - val_loss: 0.0022 - val_mae: 0.0322\n",
      "Epoch 21/50\n",
      "280/280 - 3s - 11ms/step - loss: 0.0026 - mae: 0.0332 - val_loss: 0.0020 - val_mae: 0.0304\n",
      "Epoch 22/50\n",
      "280/280 - 3s - 11ms/step - loss: 0.0023 - mae: 0.0314 - val_loss: 0.0025 - val_mae: 0.0369\n",
      "Epoch 23/50\n",
      "280/280 - 3s - 9ms/step - loss: 0.0024 - mae: 0.0322 - val_loss: 0.0024 - val_mae: 0.0349\n",
      "Epoch 24/50\n",
      "280/280 - 3s - 9ms/step - loss: 0.0024 - mae: 0.0317 - val_loss: 0.0022 - val_mae: 0.0311\n",
      "Epoch 25/50\n",
      "280/280 - 4s - 14ms/step - loss: 0.0024 - mae: 0.0316 - val_loss: 0.0021 - val_mae: 0.0303\n",
      "Epoch 26/50\n",
      "280/280 - 3s - 10ms/step - loss: 0.0024 - mae: 0.0329 - val_loss: 0.0035 - val_mae: 0.0460\n",
      "Epoch 27/50\n",
      "280/280 - 3s - 12ms/step - loss: 0.0026 - mae: 0.0347 - val_loss: 0.0054 - val_mae: 0.0608\n",
      "Epoch 28/50\n",
      "280/280 - 3s - 12ms/step - loss: 0.0024 - mae: 0.0318 - val_loss: 0.0024 - val_mae: 0.0350\n",
      "Epoch 29/50\n",
      "280/280 - 5s - 18ms/step - loss: 0.0023 - mae: 0.0303 - val_loss: 0.0027 - val_mae: 0.0377\n",
      "Epoch 30/50\n",
      "280/280 - 4s - 13ms/step - loss: 0.0025 - mae: 0.0329 - val_loss: 0.0026 - val_mae: 0.0369\n",
      "Epoch 31/50\n",
      "280/280 - 3s - 11ms/step - loss: 0.0025 - mae: 0.0329 - val_loss: 0.0036 - val_mae: 0.0501\n",
      "Epoch 32/50\n",
      "280/280 - 5s - 19ms/step - loss: 0.0024 - mae: 0.0324 - val_loss: 0.0025 - val_mae: 0.0378\n",
      "Epoch 33/50\n",
      "280/280 - 5s - 19ms/step - loss: 0.0023 - mae: 0.0310 - val_loss: 0.0021 - val_mae: 0.0313\n",
      "Epoch 34/50\n",
      "280/280 - 3s - 10ms/step - loss: 0.0023 - mae: 0.0308 - val_loss: 0.0043 - val_mae: 0.0555\n",
      "Epoch 35/50\n",
      "280/280 - 5s - 20ms/step - loss: 0.0023 - mae: 0.0311 - val_loss: 0.0028 - val_mae: 0.0406\n",
      "Epoch 36/50\n",
      "280/280 - 3s - 11ms/step - loss: 0.0022 - mae: 0.0302 - val_loss: 0.0024 - val_mae: 0.0346\n",
      "Epoch 37/50\n",
      "280/280 - 3s - 10ms/step - loss: 0.0025 - mae: 0.0331 - val_loss: 0.0021 - val_mae: 0.0311\n",
      "Epoch 38/50\n",
      "280/280 - 3s - 11ms/step - loss: 0.0023 - mae: 0.0306 - val_loss: 0.0020 - val_mae: 0.0296\n",
      "Epoch 39/50\n",
      "280/280 - 3s - 11ms/step - loss: 0.0023 - mae: 0.0318 - val_loss: 0.0030 - val_mae: 0.0438\n",
      "Epoch 40/50\n",
      "280/280 - 3s - 10ms/step - loss: 0.0022 - mae: 0.0299 - val_loss: 0.0049 - val_mae: 0.0550\n",
      "Epoch 41/50\n",
      "280/280 - 3s - 11ms/step - loss: 0.0022 - mae: 0.0302 - val_loss: 0.0023 - val_mae: 0.0350\n",
      "Epoch 42/50\n",
      "280/280 - 8s - 28ms/step - loss: 0.0023 - mae: 0.0306 - val_loss: 0.0032 - val_mae: 0.0448\n",
      "Epoch 43/50\n",
      "280/280 - 3s - 11ms/step - loss: 0.0022 - mae: 0.0299 - val_loss: 0.0041 - val_mae: 0.0528\n",
      "Epoch 44/50\n",
      "280/280 - 5s - 17ms/step - loss: 0.0024 - mae: 0.0324 - val_loss: 0.0053 - val_mae: 0.0625\n",
      "Epoch 45/50\n",
      "280/280 - 4s - 15ms/step - loss: 0.0023 - mae: 0.0315 - val_loss: 0.0020 - val_mae: 0.0304\n",
      "Epoch 46/50\n",
      "280/280 - 4s - 13ms/step - loss: 0.0023 - mae: 0.0317 - val_loss: 0.0026 - val_mae: 0.0352\n",
      "Epoch 47/50\n",
      "280/280 - 3s - 11ms/step - loss: 0.0023 - mae: 0.0313 - val_loss: 0.0020 - val_mae: 0.0298\n",
      "Epoch 48/50\n",
      "280/280 - 4s - 13ms/step - loss: 0.0023 - mae: 0.0307 - val_loss: 0.0026 - val_mae: 0.0377\n",
      "Epoch 49/50\n",
      "280/280 - 3s - 10ms/step - loss: 0.0023 - mae: 0.0307 - val_loss: 0.0020 - val_mae: 0.0295\n",
      "Epoch 50/50\n",
      "280/280 - 3s - 10ms/step - loss: 0.0022 - mae: 0.0298 - val_loss: 0.0025 - val_mae: 0.0348\n",
      "✅ Done with onion_Dharwad_daily.csv | MAE=241.69, RMSE=374.81, R2=0.76, MAPE=21.59%, Accuracy=78.41%\n",
      "\n",
      "🚀 Processing: onion_Gadag_daily.csv\n",
      "Epoch 1/50\n",
      "256/256 - 7s - 29ms/step - loss: 0.0689 - mae: 0.1569 - val_loss: 0.0338 - val_mae: 0.1665\n",
      "Epoch 2/50\n",
      "256/256 - 4s - 16ms/step - loss: 0.0160 - mae: 0.0952 - val_loss: 0.0095 - val_mae: 0.0801\n",
      "Epoch 3/50\n",
      "256/256 - 5s - 18ms/step - loss: 0.0087 - mae: 0.0691 - val_loss: 0.0089 - val_mae: 0.0734\n",
      "Epoch 4/50\n",
      "256/256 - 3s - 10ms/step - loss: 0.0070 - mae: 0.0611 - val_loss: 0.0075 - val_mae: 0.0681\n",
      "Epoch 5/50\n",
      "256/256 - 3s - 10ms/step - loss: 0.0058 - mae: 0.0557 - val_loss: 0.0057 - val_mae: 0.0553\n",
      "Epoch 6/50\n",
      "256/256 - 2s - 9ms/step - loss: 0.0058 - mae: 0.0553 - val_loss: 0.0035 - val_mae: 0.0376\n",
      "Epoch 7/50\n",
      "256/256 - 3s - 13ms/step - loss: 0.0052 - mae: 0.0527 - val_loss: 0.0046 - val_mae: 0.0559\n",
      "Epoch 8/50\n",
      "256/256 - 4s - 14ms/step - loss: 0.0044 - mae: 0.0471 - val_loss: 0.0035 - val_mae: 0.0429\n",
      "Epoch 9/50\n",
      "256/256 - 3s - 13ms/step - loss: 0.0045 - mae: 0.0476 - val_loss: 0.0033 - val_mae: 0.0374\n",
      "Epoch 10/50\n",
      "256/256 - 4s - 15ms/step - loss: 0.0041 - mae: 0.0444 - val_loss: 0.0036 - val_mae: 0.0396\n",
      "Epoch 11/50\n",
      "256/256 - 3s - 10ms/step - loss: 0.0038 - mae: 0.0424 - val_loss: 0.0041 - val_mae: 0.0467\n",
      "Epoch 12/50\n",
      "256/256 - 3s - 12ms/step - loss: 0.0039 - mae: 0.0438 - val_loss: 0.0031 - val_mae: 0.0391\n",
      "Epoch 13/50\n",
      "256/256 - 2s - 9ms/step - loss: 0.0037 - mae: 0.0415 - val_loss: 0.0041 - val_mae: 0.0439\n",
      "Epoch 14/50\n",
      "256/256 - 3s - 10ms/step - loss: 0.0039 - mae: 0.0434 - val_loss: 0.0031 - val_mae: 0.0303\n",
      "Epoch 15/50\n",
      "256/256 - 3s - 10ms/step - loss: 0.0035 - mae: 0.0411 - val_loss: 0.0032 - val_mae: 0.0372\n",
      "Epoch 16/50\n",
      "256/256 - 4s - 15ms/step - loss: 0.0034 - mae: 0.0395 - val_loss: 0.0028 - val_mae: 0.0275\n",
      "Epoch 17/50\n",
      "256/256 - 2s - 9ms/step - loss: 0.0036 - mae: 0.0406 - val_loss: 0.0033 - val_mae: 0.0375\n",
      "Epoch 18/50\n",
      "256/256 - 3s - 10ms/step - loss: 0.0036 - mae: 0.0402 - val_loss: 0.0028 - val_mae: 0.0274\n",
      "Epoch 19/50\n",
      "256/256 - 3s - 10ms/step - loss: 0.0036 - mae: 0.0409 - val_loss: 0.0029 - val_mae: 0.0327\n",
      "Epoch 20/50\n",
      "256/256 - 3s - 10ms/step - loss: 0.0036 - mae: 0.0414 - val_loss: 0.0082 - val_mae: 0.0786\n",
      "Epoch 21/50\n",
      "256/256 - 2s - 9ms/step - loss: 0.0036 - mae: 0.0409 - val_loss: 0.0033 - val_mae: 0.0309\n",
      "Epoch 22/50\n",
      "256/256 - 2s - 9ms/step - loss: 0.0034 - mae: 0.0386 - val_loss: 0.0038 - val_mae: 0.0483\n",
      "Epoch 23/50\n",
      "256/256 - 3s - 10ms/step - loss: 0.0032 - mae: 0.0369 - val_loss: 0.0045 - val_mae: 0.0488\n",
      "Epoch 24/50\n",
      "256/256 - 3s - 14ms/step - loss: 0.0034 - mae: 0.0389 - val_loss: 0.0030 - val_mae: 0.0315\n",
      "Epoch 25/50\n",
      "256/256 - 3s - 10ms/step - loss: 0.0036 - mae: 0.0406 - val_loss: 0.0061 - val_mae: 0.0600\n",
      "Epoch 26/50\n",
      "256/256 - 3s - 10ms/step - loss: 0.0034 - mae: 0.0395 - val_loss: 0.0029 - val_mae: 0.0258\n",
      "Epoch 27/50\n",
      "256/256 - 3s - 12ms/step - loss: 0.0033 - mae: 0.0378 - val_loss: 0.0061 - val_mae: 0.0675\n",
      "Epoch 28/50\n",
      "256/256 - 3s - 10ms/step - loss: 0.0034 - mae: 0.0385 - val_loss: 0.0035 - val_mae: 0.0479\n",
      "Epoch 29/50\n",
      "256/256 - 3s - 11ms/step - loss: 0.0035 - mae: 0.0401 - val_loss: 0.0098 - val_mae: 0.0921\n",
      "Epoch 30/50\n",
      "256/256 - 2s - 9ms/step - loss: 0.0034 - mae: 0.0387 - val_loss: 0.0031 - val_mae: 0.0296\n",
      "Epoch 31/50\n",
      "256/256 - 4s - 17ms/step - loss: 0.0034 - mae: 0.0380 - val_loss: 0.0036 - val_mae: 0.0498\n",
      "Epoch 32/50\n",
      "256/256 - 3s - 10ms/step - loss: 0.0032 - mae: 0.0374 - val_loss: 0.0038 - val_mae: 0.0523\n",
      "Epoch 33/50\n",
      "256/256 - 2s - 9ms/step - loss: 0.0033 - mae: 0.0385 - val_loss: 0.0035 - val_mae: 0.0350\n",
      "Epoch 34/50\n",
      "256/256 - 3s - 11ms/step - loss: 0.0033 - mae: 0.0379 - val_loss: 0.0028 - val_mae: 0.0274\n",
      "Epoch 35/50\n",
      "256/256 - 3s - 10ms/step - loss: 0.0034 - mae: 0.0384 - val_loss: 0.0029 - val_mae: 0.0262\n",
      "Epoch 36/50\n",
      "256/256 - 3s - 10ms/step - loss: 0.0032 - mae: 0.0370 - val_loss: 0.0063 - val_mae: 0.0654\n",
      "Epoch 37/50\n",
      "256/256 - 3s - 10ms/step - loss: 0.0034 - mae: 0.0383 - val_loss: 0.0035 - val_mae: 0.0449\n",
      "Epoch 38/50\n",
      "256/256 - 4s - 15ms/step - loss: 0.0034 - mae: 0.0383 - val_loss: 0.0053 - val_mae: 0.0570\n",
      "Epoch 39/50\n",
      "256/256 - 2s - 10ms/step - loss: 0.0032 - mae: 0.0375 - val_loss: 0.0041 - val_mae: 0.0505\n",
      "Epoch 40/50\n",
      "256/256 - 4s - 17ms/step - loss: 0.0034 - mae: 0.0384 - val_loss: 0.0046 - val_mae: 0.0584\n",
      "Epoch 41/50\n",
      "256/256 - 3s - 12ms/step - loss: 0.0031 - mae: 0.0367 - val_loss: 0.0097 - val_mae: 0.0890\n",
      "Epoch 42/50\n",
      "256/256 - 3s - 10ms/step - loss: 0.0032 - mae: 0.0359 - val_loss: 0.0053 - val_mae: 0.0627\n",
      "Epoch 43/50\n",
      "256/256 - 2s - 10ms/step - loss: 0.0031 - mae: 0.0354 - val_loss: 0.0034 - val_mae: 0.0472\n",
      "Epoch 44/50\n",
      "256/256 - 3s - 10ms/step - loss: 0.0031 - mae: 0.0362 - val_loss: 0.0054 - val_mae: 0.0670\n",
      "Epoch 45/50\n",
      "256/256 - 3s - 10ms/step - loss: 0.0031 - mae: 0.0364 - val_loss: 0.0068 - val_mae: 0.0770\n",
      "Epoch 46/50\n",
      "256/256 - 3s - 10ms/step - loss: 0.0032 - mae: 0.0367 - val_loss: 0.0042 - val_mae: 0.0555\n",
      "Epoch 47/50\n",
      "256/256 - 3s - 10ms/step - loss: 0.0032 - mae: 0.0371 - val_loss: 0.0045 - val_mae: 0.0559\n",
      "Epoch 48/50\n",
      "256/256 - 3s - 11ms/step - loss: 0.0030 - mae: 0.0350 - val_loss: 0.0044 - val_mae: 0.0512\n",
      "Epoch 49/50\n",
      "256/256 - 2s - 9ms/step - loss: 0.0031 - mae: 0.0359 - val_loss: 0.0075 - val_mae: 0.0791\n",
      "Epoch 50/50\n",
      "256/256 - 3s - 13ms/step - loss: 0.0031 - mae: 0.0358 - val_loss: 0.0096 - val_mae: 0.0869\n",
      "✅ Done with onion_Gadag_daily.csv | MAE=232.45, RMSE=296.38, R2=0.79, MAPE=18.7%, Accuracy=81.3%\n",
      "\n",
      "🚀 Processing: onion_Hassan_daily.csv\n",
      "Epoch 1/50\n",
      "1156/1156 - 20s - 17ms/step - loss: 0.0116 - mae: 0.0719 - val_loss: 0.0070 - val_mae: 0.0601\n",
      "Epoch 2/50\n",
      "1156/1156 - 19s - 17ms/step - loss: 0.0053 - mae: 0.0516 - val_loss: 0.0056 - val_mae: 0.0490\n",
      "Epoch 3/50\n",
      "1156/1156 - 12s - 11ms/step - loss: 0.0051 - mae: 0.0506 - val_loss: 0.0084 - val_mae: 0.0696\n",
      "Epoch 4/50\n",
      "1156/1156 - 21s - 18ms/step - loss: 0.0051 - mae: 0.0501 - val_loss: 0.0057 - val_mae: 0.0495\n",
      "Epoch 5/50\n",
      "1156/1156 - 19s - 16ms/step - loss: 0.0049 - mae: 0.0492 - val_loss: 0.0068 - val_mae: 0.0589\n",
      "Epoch 6/50\n",
      "1156/1156 - 19s - 16ms/step - loss: 0.0048 - mae: 0.0484 - val_loss: 0.0074 - val_mae: 0.0624\n",
      "Epoch 7/50\n",
      "1156/1156 - 19s - 17ms/step - loss: 0.0049 - mae: 0.0488 - val_loss: 0.0060 - val_mae: 0.0526\n",
      "Epoch 8/50\n",
      "1156/1156 - 11s - 10ms/step - loss: 0.0048 - mae: 0.0484 - val_loss: 0.0058 - val_mae: 0.0511\n",
      "Epoch 9/50\n",
      "1156/1156 - 10s - 9ms/step - loss: 0.0048 - mae: 0.0484 - val_loss: 0.0065 - val_mae: 0.0534\n",
      "Epoch 10/50\n",
      "1156/1156 - 13s - 11ms/step - loss: 0.0048 - mae: 0.0479 - val_loss: 0.0074 - val_mae: 0.0628\n",
      "Epoch 11/50\n",
      "1156/1156 - 12s - 11ms/step - loss: 0.0048 - mae: 0.0480 - val_loss: 0.0070 - val_mae: 0.0595\n",
      "Epoch 12/50\n",
      "1156/1156 - 19s - 16ms/step - loss: 0.0047 - mae: 0.0478 - val_loss: 0.0093 - val_mae: 0.0744\n",
      "Epoch 13/50\n",
      "1156/1156 - 10s - 9ms/step - loss: 0.0047 - mae: 0.0473 - val_loss: 0.0098 - val_mae: 0.0778\n",
      "Epoch 14/50\n",
      "1156/1156 - 17s - 15ms/step - loss: 0.0047 - mae: 0.0473 - val_loss: 0.0063 - val_mae: 0.0538\n",
      "Epoch 15/50\n",
      "1156/1156 - 19s - 16ms/step - loss: 0.0047 - mae: 0.0477 - val_loss: 0.0083 - val_mae: 0.0685\n",
      "Epoch 16/50\n",
      "1156/1156 - 20s - 18ms/step - loss: 0.0047 - mae: 0.0475 - val_loss: 0.0067 - val_mae: 0.0578\n",
      "Epoch 17/50\n",
      "1156/1156 - 14s - 12ms/step - loss: 0.0046 - mae: 0.0473 - val_loss: 0.0056 - val_mae: 0.0490\n",
      "Epoch 18/50\n",
      "1156/1156 - 21s - 18ms/step - loss: 0.0047 - mae: 0.0472 - val_loss: 0.0078 - val_mae: 0.0650\n",
      "Epoch 19/50\n",
      "1156/1156 - 20s - 18ms/step - loss: 0.0047 - mae: 0.0471 - val_loss: 0.0077 - val_mae: 0.0641\n",
      "Epoch 20/50\n",
      "1156/1156 - 10s - 9ms/step - loss: 0.0046 - mae: 0.0469 - val_loss: 0.0062 - val_mae: 0.0537\n",
      "Epoch 21/50\n",
      "1156/1156 - 20s - 17ms/step - loss: 0.0046 - mae: 0.0470 - val_loss: 0.0057 - val_mae: 0.0493\n",
      "Epoch 22/50\n",
      "1156/1156 - 11s - 10ms/step - loss: 0.0046 - mae: 0.0471 - val_loss: 0.0083 - val_mae: 0.0660\n",
      "Epoch 23/50\n",
      "1156/1156 - 17s - 14ms/step - loss: 0.0046 - mae: 0.0470 - val_loss: 0.0072 - val_mae: 0.0614\n",
      "Epoch 24/50\n",
      "1156/1156 - 14s - 12ms/step - loss: 0.0046 - mae: 0.0469 - val_loss: 0.0079 - val_mae: 0.0648\n",
      "Epoch 25/50\n",
      "1156/1156 - 12s - 10ms/step - loss: 0.0046 - mae: 0.0468 - val_loss: 0.0095 - val_mae: 0.0734\n",
      "Epoch 26/50\n",
      "1156/1156 - 13s - 12ms/step - loss: 0.0046 - mae: 0.0470 - val_loss: 0.0064 - val_mae: 0.0552\n",
      "Epoch 27/50\n",
      "1156/1156 - 21s - 18ms/step - loss: 0.0046 - mae: 0.0467 - val_loss: 0.0060 - val_mae: 0.0523\n",
      "Epoch 28/50\n",
      "1156/1156 - 16s - 14ms/step - loss: 0.0046 - mae: 0.0469 - val_loss: 0.0060 - val_mae: 0.0525\n",
      "Epoch 29/50\n",
      "1156/1156 - 10s - 9ms/step - loss: 0.0046 - mae: 0.0467 - val_loss: 0.0070 - val_mae: 0.0592\n",
      "Epoch 30/50\n",
      "1156/1156 - 21s - 18ms/step - loss: 0.0046 - mae: 0.0466 - val_loss: 0.0060 - val_mae: 0.0520\n",
      "Epoch 31/50\n",
      "1156/1156 - 21s - 18ms/step - loss: 0.0046 - mae: 0.0466 - val_loss: 0.0060 - val_mae: 0.0523\n",
      "Epoch 32/50\n",
      "1156/1156 - 11s - 9ms/step - loss: 0.0045 - mae: 0.0464 - val_loss: 0.0065 - val_mae: 0.0562\n",
      "Epoch 33/50\n",
      "1156/1156 - 30s - 26ms/step - loss: 0.0046 - mae: 0.0465 - val_loss: 0.0064 - val_mae: 0.0556\n",
      "Epoch 34/50\n",
      "1156/1156 - 18s - 16ms/step - loss: 0.0046 - mae: 0.0465 - val_loss: 0.0075 - val_mae: 0.0628\n",
      "Epoch 35/50\n",
      "1156/1156 - 13s - 12ms/step - loss: 0.0046 - mae: 0.0466 - val_loss: 0.0068 - val_mae: 0.0582\n",
      "Epoch 36/50\n",
      "1156/1156 - 15s - 13ms/step - loss: 0.0046 - mae: 0.0465 - val_loss: 0.0064 - val_mae: 0.0549\n",
      "Epoch 37/50\n",
      "1156/1156 - 14s - 12ms/step - loss: 0.0045 - mae: 0.0465 - val_loss: 0.0072 - val_mae: 0.0586\n",
      "Epoch 38/50\n",
      "1156/1156 - 12s - 10ms/step - loss: 0.0046 - mae: 0.0465 - val_loss: 0.0060 - val_mae: 0.0526\n",
      "Epoch 39/50\n",
      "1156/1156 - 20s - 18ms/step - loss: 0.0045 - mae: 0.0462 - val_loss: 0.0057 - val_mae: 0.0500\n",
      "Epoch 40/50\n",
      "1156/1156 - 12s - 10ms/step - loss: 0.0045 - mae: 0.0463 - val_loss: 0.0057 - val_mae: 0.0492\n",
      "Epoch 41/50\n",
      "1156/1156 - 17s - 15ms/step - loss: 0.0045 - mae: 0.0465 - val_loss: 0.0058 - val_mae: 0.0508\n",
      "Epoch 42/50\n",
      "1156/1156 - 22s - 19ms/step - loss: 0.0045 - mae: 0.0464 - val_loss: 0.0058 - val_mae: 0.0493\n",
      "Epoch 43/50\n",
      "1156/1156 - 18s - 16ms/step - loss: 0.0045 - mae: 0.0465 - val_loss: 0.0059 - val_mae: 0.0515\n",
      "Epoch 44/50\n",
      "1156/1156 - 19s - 16ms/step - loss: 0.0045 - mae: 0.0464 - val_loss: 0.0059 - val_mae: 0.0516\n",
      "Epoch 45/50\n",
      "1156/1156 - 13s - 11ms/step - loss: 0.0046 - mae: 0.0466 - val_loss: 0.0058 - val_mae: 0.0512\n",
      "Epoch 46/50\n",
      "1156/1156 - 16s - 14ms/step - loss: 0.0045 - mae: 0.0464 - val_loss: 0.0068 - val_mae: 0.0575\n",
      "Epoch 47/50\n",
      "1156/1156 - 18s - 16ms/step - loss: 0.0045 - mae: 0.0463 - val_loss: 0.0074 - val_mae: 0.0609\n",
      "Epoch 48/50\n",
      "1156/1156 - 18s - 15ms/step - loss: 0.0045 - mae: 0.0463 - val_loss: 0.0061 - val_mae: 0.0531\n",
      "Epoch 49/50\n",
      "1156/1156 - 17s - 14ms/step - loss: 0.0045 - mae: 0.0464 - val_loss: 0.0057 - val_mae: 0.0498\n",
      "Epoch 50/50\n",
      "1156/1156 - 18s - 16ms/step - loss: 0.0045 - mae: 0.0462 - val_loss: 0.0060 - val_mae: 0.0527\n",
      "✅ Done with onion_Hassan_daily.csv | MAE=509.83, RMSE=707.37, R2=0.42, MAPE=46.26%, Accuracy=53.74%\n",
      "\n",
      "🚀 Processing: onion_Haveri_daily.csv\n",
      "Epoch 1/50\n",
      "474/474 - 11s - 22ms/step - loss: 0.0235 - mae: 0.1002 - val_loss: 0.0113 - val_mae: 0.0992\n",
      "Epoch 2/50\n",
      "474/474 - 6s - 13ms/step - loss: 0.0090 - mae: 0.0714 - val_loss: 0.0072 - val_mae: 0.0754\n",
      "Epoch 3/50\n",
      "474/474 - 7s - 16ms/step - loss: 0.0075 - mae: 0.0650 - val_loss: 0.0057 - val_mae: 0.0656\n",
      "Epoch 4/50\n",
      "474/474 - 5s - 10ms/step - loss: 0.0070 - mae: 0.0632 - val_loss: 0.0049 - val_mae: 0.0597\n",
      "Epoch 5/50\n",
      "474/474 - 5s - 10ms/step - loss: 0.0070 - mae: 0.0627 - val_loss: 0.0037 - val_mae: 0.0509\n",
      "Epoch 6/50\n",
      "474/474 - 5s - 10ms/step - loss: 0.0068 - mae: 0.0617 - val_loss: 0.0065 - val_mae: 0.0701\n",
      "Epoch 7/50\n",
      "474/474 - 4s - 9ms/step - loss: 0.0067 - mae: 0.0612 - val_loss: 0.0052 - val_mae: 0.0615\n",
      "Epoch 8/50\n",
      "474/474 - 7s - 15ms/step - loss: 0.0068 - mae: 0.0615 - val_loss: 0.0023 - val_mae: 0.0357\n",
      "Epoch 9/50\n",
      "474/474 - 5s - 10ms/step - loss: 0.0068 - mae: 0.0617 - val_loss: 0.0032 - val_mae: 0.0461\n",
      "Epoch 10/50\n",
      "474/474 - 4s - 9ms/step - loss: 0.0067 - mae: 0.0612 - val_loss: 0.0028 - val_mae: 0.0413\n",
      "Epoch 11/50\n",
      "474/474 - 6s - 14ms/step - loss: 0.0066 - mae: 0.0602 - val_loss: 0.0025 - val_mae: 0.0385\n",
      "Epoch 12/50\n",
      "474/474 - 6s - 13ms/step - loss: 0.0066 - mae: 0.0603 - val_loss: 0.0022 - val_mae: 0.0351\n",
      "Epoch 13/50\n",
      "474/474 - 7s - 15ms/step - loss: 0.0066 - mae: 0.0605 - val_loss: 0.0065 - val_mae: 0.0698\n",
      "Epoch 14/50\n",
      "474/474 - 4s - 9ms/step - loss: 0.0065 - mae: 0.0601 - val_loss: 0.0033 - val_mae: 0.0468\n",
      "Epoch 15/50\n",
      "474/474 - 5s - 10ms/step - loss: 0.0066 - mae: 0.0606 - val_loss: 0.0034 - val_mae: 0.0473\n",
      "Epoch 16/50\n",
      "474/474 - 4s - 9ms/step - loss: 0.0065 - mae: 0.0599 - val_loss: 0.0024 - val_mae: 0.0378\n",
      "Epoch 17/50\n",
      "474/474 - 9s - 18ms/step - loss: 0.0065 - mae: 0.0597 - val_loss: 0.0068 - val_mae: 0.0716\n",
      "Epoch 18/50\n",
      "474/474 - 8s - 17ms/step - loss: 0.0065 - mae: 0.0599 - val_loss: 0.0040 - val_mae: 0.0524\n",
      "Epoch 19/50\n",
      "474/474 - 5s - 10ms/step - loss: 0.0064 - mae: 0.0598 - val_loss: 0.0068 - val_mae: 0.0719\n",
      "Epoch 20/50\n",
      "474/474 - 4s - 9ms/step - loss: 0.0065 - mae: 0.0596 - val_loss: 0.0024 - val_mae: 0.0380\n",
      "Epoch 21/50\n",
      "474/474 - 5s - 10ms/step - loss: 0.0064 - mae: 0.0592 - val_loss: 0.0046 - val_mae: 0.0564\n",
      "Epoch 22/50\n",
      "474/474 - 5s - 10ms/step - loss: 0.0064 - mae: 0.0599 - val_loss: 0.0026 - val_mae: 0.0397\n",
      "Epoch 23/50\n",
      "474/474 - 6s - 13ms/step - loss: 0.0065 - mae: 0.0598 - val_loss: 0.0028 - val_mae: 0.0421\n",
      "Epoch 24/50\n",
      "474/474 - 9s - 19ms/step - loss: 0.0063 - mae: 0.0592 - val_loss: 0.0041 - val_mae: 0.0530\n",
      "Epoch 25/50\n",
      "474/474 - 4s - 9ms/step - loss: 0.0065 - mae: 0.0603 - val_loss: 0.0022 - val_mae: 0.0349\n",
      "Epoch 26/50\n",
      "474/474 - 6s - 13ms/step - loss: 0.0063 - mae: 0.0592 - val_loss: 0.0043 - val_mae: 0.0551\n",
      "Epoch 27/50\n",
      "474/474 - 6s - 12ms/step - loss: 0.0063 - mae: 0.0592 - val_loss: 0.0031 - val_mae: 0.0454\n",
      "Epoch 28/50\n",
      "474/474 - 6s - 14ms/step - loss: 0.0063 - mae: 0.0590 - val_loss: 0.0042 - val_mae: 0.0536\n",
      "Epoch 29/50\n",
      "474/474 - 7s - 15ms/step - loss: 0.0064 - mae: 0.0593 - val_loss: 0.0025 - val_mae: 0.0384\n",
      "Epoch 30/50\n",
      "474/474 - 4s - 9ms/step - loss: 0.0063 - mae: 0.0589 - val_loss: 0.0053 - val_mae: 0.0621\n",
      "Epoch 31/50\n",
      "474/474 - 5s - 10ms/step - loss: 0.0064 - mae: 0.0592 - val_loss: 0.0026 - val_mae: 0.0402\n",
      "Epoch 32/50\n",
      "474/474 - 6s - 13ms/step - loss: 0.0063 - mae: 0.0591 - val_loss: 0.0039 - val_mae: 0.0512\n",
      "Epoch 33/50\n",
      "474/474 - 5s - 10ms/step - loss: 0.0065 - mae: 0.0599 - val_loss: 0.0022 - val_mae: 0.0354\n",
      "Epoch 34/50\n",
      "474/474 - 7s - 16ms/step - loss: 0.0063 - mae: 0.0590 - val_loss: 0.0022 - val_mae: 0.0353\n",
      "Epoch 35/50\n",
      "474/474 - 4s - 9ms/step - loss: 0.0062 - mae: 0.0583 - val_loss: 0.0030 - val_mae: 0.0435\n",
      "Epoch 36/50\n",
      "474/474 - 8s - 18ms/step - loss: 0.0062 - mae: 0.0585 - val_loss: 0.0022 - val_mae: 0.0349\n",
      "Epoch 37/50\n",
      "474/474 - 5s - 10ms/step - loss: 0.0063 - mae: 0.0588 - val_loss: 0.0023 - val_mae: 0.0358\n",
      "Epoch 38/50\n",
      "474/474 - 5s - 10ms/step - loss: 0.0063 - mae: 0.0589 - val_loss: 0.0028 - val_mae: 0.0416\n",
      "Epoch 39/50\n",
      "474/474 - 9s - 18ms/step - loss: 0.0063 - mae: 0.0587 - val_loss: 0.0022 - val_mae: 0.0350\n",
      "Epoch 40/50\n",
      "474/474 - 6s - 13ms/step - loss: 0.0063 - mae: 0.0590 - val_loss: 0.0022 - val_mae: 0.0351\n",
      "Epoch 41/50\n",
      "474/474 - 5s - 10ms/step - loss: 0.0063 - mae: 0.0587 - val_loss: 0.0029 - val_mae: 0.0428\n",
      "Epoch 42/50\n",
      "474/474 - 9s - 18ms/step - loss: 0.0061 - mae: 0.0580 - val_loss: 0.0022 - val_mae: 0.0350\n",
      "Epoch 43/50\n",
      "474/474 - 5s - 10ms/step - loss: 0.0062 - mae: 0.0581 - val_loss: 0.0033 - val_mae: 0.0463\n",
      "Epoch 44/50\n",
      "474/474 - 5s - 11ms/step - loss: 0.0062 - mae: 0.0588 - val_loss: 0.0024 - val_mae: 0.0375\n",
      "Epoch 45/50\n",
      "474/474 - 6s - 12ms/step - loss: 0.0063 - mae: 0.0587 - val_loss: 0.0024 - val_mae: 0.0371\n",
      "Epoch 46/50\n",
      "474/474 - 7s - 14ms/step - loss: 0.0062 - mae: 0.0586 - val_loss: 0.0023 - val_mae: 0.0364\n",
      "Epoch 47/50\n",
      "474/474 - 4s - 9ms/step - loss: 0.0062 - mae: 0.0582 - val_loss: 0.0028 - val_mae: 0.0423\n",
      "Epoch 48/50\n",
      "474/474 - 8s - 17ms/step - loss: 0.0062 - mae: 0.0582 - val_loss: 0.0026 - val_mae: 0.0394\n",
      "Epoch 49/50\n",
      "474/474 - 6s - 12ms/step - loss: 0.0061 - mae: 0.0580 - val_loss: 0.0026 - val_mae: 0.0392\n",
      "Epoch 50/50\n",
      "474/474 - 4s - 9ms/step - loss: 0.0063 - mae: 0.0585 - val_loss: 0.0026 - val_mae: 0.0396\n",
      "✅ Done with onion_Haveri_daily.csv | MAE=324.63, RMSE=447.02, R2=0.62, MAPE=27.86%, Accuracy=72.14%\n",
      "\n",
      "🚀 Processing: onion_Kolar_daily.csv\n",
      "Epoch 1/50\n",
      "1943/1943 - 35s - 18ms/step - loss: 0.0143 - mae: 0.0547 - val_loss: 8.7287e-04 - val_mae: 0.0195\n",
      "Epoch 2/50\n",
      "1943/1943 - 26s - 13ms/step - loss: 0.0017 - mae: 0.0301 - val_loss: 7.7068e-04 - val_mae: 0.0190\n",
      "Epoch 3/50\n",
      "1943/1943 - 24s - 12ms/step - loss: 0.0015 - mae: 0.0273 - val_loss: 7.3355e-04 - val_mae: 0.0185\n",
      "Epoch 4/50\n",
      "1943/1943 - 22s - 11ms/step - loss: 0.0014 - mae: 0.0260 - val_loss: 7.3544e-04 - val_mae: 0.0188\n",
      "Epoch 5/50\n",
      "1943/1943 - 31s - 16ms/step - loss: 0.0013 - mae: 0.0255 - val_loss: 0.0012 - val_mae: 0.0245\n",
      "Epoch 6/50\n",
      "1943/1943 - 21s - 11ms/step - loss: 0.0013 - mae: 0.0250 - val_loss: 6.4844e-04 - val_mae: 0.0170\n",
      "Epoch 7/50\n",
      "1943/1943 - 32s - 16ms/step - loss: 0.0013 - mae: 0.0246 - val_loss: 6.6633e-04 - val_mae: 0.0173\n",
      "Epoch 8/50\n",
      "1943/1943 - 33s - 17ms/step - loss: 0.0012 - mae: 0.0239 - val_loss: 7.1331e-04 - val_mae: 0.0185\n",
      "Epoch 9/50\n",
      "1943/1943 - 26s - 14ms/step - loss: 0.0012 - mae: 0.0237 - val_loss: 7.3489e-04 - val_mae: 0.0186\n",
      "Epoch 10/50\n",
      "1943/1943 - 24s - 12ms/step - loss: 0.0012 - mae: 0.0237 - val_loss: 7.8731e-04 - val_mae: 0.0189\n",
      "Epoch 11/50\n",
      "1943/1943 - 21s - 11ms/step - loss: 0.0012 - mae: 0.0234 - val_loss: 6.3119e-04 - val_mae: 0.0168\n",
      "Epoch 12/50\n",
      "1943/1943 - 20s - 10ms/step - loss: 0.0012 - mae: 0.0232 - val_loss: 8.9233e-04 - val_mae: 0.0212\n",
      "Epoch 13/50\n",
      "1943/1943 - 33s - 17ms/step - loss: 0.0012 - mae: 0.0232 - val_loss: 6.6692e-04 - val_mae: 0.0174\n",
      "Epoch 14/50\n",
      "1943/1943 - 29s - 15ms/step - loss: 0.0012 - mae: 0.0230 - val_loss: 7.0754e-04 - val_mae: 0.0180\n",
      "Epoch 15/50\n",
      "1943/1943 - 27s - 14ms/step - loss: 0.0012 - mae: 0.0230 - val_loss: 0.0022 - val_mae: 0.0358\n",
      "Epoch 16/50\n",
      "1943/1943 - 27s - 14ms/step - loss: 0.0012 - mae: 0.0230 - val_loss: 6.6844e-04 - val_mae: 0.0177\n",
      "Epoch 17/50\n",
      "1943/1943 - 36s - 18ms/step - loss: 0.0012 - mae: 0.0229 - val_loss: 7.8217e-04 - val_mae: 0.0192\n",
      "Epoch 18/50\n",
      "1943/1943 - 20s - 10ms/step - loss: 0.0012 - mae: 0.0229 - val_loss: 6.7203e-04 - val_mae: 0.0174\n",
      "Epoch 19/50\n",
      "1943/1943 - 31s - 16ms/step - loss: 0.0012 - mae: 0.0229 - val_loss: 6.8691e-04 - val_mae: 0.0180\n",
      "Epoch 20/50\n",
      "1943/1943 - 29s - 15ms/step - loss: 0.0012 - mae: 0.0229 - val_loss: 6.8133e-04 - val_mae: 0.0179\n",
      "Epoch 21/50\n",
      "1943/1943 - 32s - 17ms/step - loss: 0.0012 - mae: 0.0228 - val_loss: 6.5916e-04 - val_mae: 0.0174\n",
      "Epoch 22/50\n",
      "1943/1943 - 28s - 15ms/step - loss: 0.0012 - mae: 0.0229 - val_loss: 6.6419e-04 - val_mae: 0.0175\n",
      "Epoch 23/50\n",
      "1943/1943 - 32s - 17ms/step - loss: 0.0012 - mae: 0.0229 - val_loss: 6.4955e-04 - val_mae: 0.0171\n",
      "Epoch 24/50\n",
      "1943/1943 - 31s - 16ms/step - loss: 0.0012 - mae: 0.0229 - val_loss: 7.5241e-04 - val_mae: 0.0183\n",
      "Epoch 25/50\n",
      "1943/1943 - 32s - 17ms/step - loss: 0.0012 - mae: 0.0229 - val_loss: 7.3698e-04 - val_mae: 0.0182\n",
      "Epoch 26/50\n",
      "1943/1943 - 28s - 14ms/step - loss: 0.0012 - mae: 0.0229 - val_loss: 6.9478e-04 - val_mae: 0.0181\n",
      "Epoch 27/50\n",
      "1943/1943 - 30s - 16ms/step - loss: 0.0012 - mae: 0.0228 - val_loss: 6.5502e-04 - val_mae: 0.0170\n",
      "Epoch 28/50\n",
      "1943/1943 - 28s - 14ms/step - loss: 0.0012 - mae: 0.0228 - val_loss: 7.1383e-04 - val_mae: 0.0184\n",
      "Epoch 29/50\n",
      "1943/1943 - 30s - 15ms/step - loss: 0.0012 - mae: 0.0228 - val_loss: 7.5086e-04 - val_mae: 0.0185\n",
      "Epoch 30/50\n",
      "1943/1943 - 24s - 12ms/step - loss: 0.0012 - mae: 0.0228 - val_loss: 7.7407e-04 - val_mae: 0.0188\n",
      "Epoch 31/50\n",
      "1943/1943 - 27s - 14ms/step - loss: 0.0012 - mae: 0.0228 - val_loss: 7.2559e-04 - val_mae: 0.0180\n",
      "Epoch 32/50\n",
      "1943/1943 - 22s - 11ms/step - loss: 0.0012 - mae: 0.0228 - val_loss: 6.3784e-04 - val_mae: 0.0169\n",
      "Epoch 33/50\n",
      "1943/1943 - 26s - 13ms/step - loss: 0.0011 - mae: 0.0227 - val_loss: 6.5102e-04 - val_mae: 0.0172\n",
      "Epoch 34/50\n",
      "1943/1943 - 20s - 10ms/step - loss: 0.0012 - mae: 0.0229 - val_loss: 6.8927e-04 - val_mae: 0.0176\n",
      "Epoch 35/50\n",
      "1943/1943 - 27s - 14ms/step - loss: 0.0011 - mae: 0.0228 - val_loss: 6.8774e-04 - val_mae: 0.0175\n",
      "Epoch 36/50\n",
      "1943/1943 - 30s - 15ms/step - loss: 0.0011 - mae: 0.0227 - val_loss: 6.4073e-04 - val_mae: 0.0170\n",
      "Epoch 37/50\n",
      "1943/1943 - 26s - 13ms/step - loss: 0.0012 - mae: 0.0228 - val_loss: 6.4676e-04 - val_mae: 0.0170\n",
      "Epoch 38/50\n",
      "1943/1943 - 25s - 13ms/step - loss: 0.0011 - mae: 0.0227 - val_loss: 6.7464e-04 - val_mae: 0.0176\n",
      "Epoch 39/50\n",
      "1943/1943 - 25s - 13ms/step - loss: 0.0012 - mae: 0.0228 - val_loss: 6.6542e-04 - val_mae: 0.0175\n",
      "Epoch 40/50\n",
      "1943/1943 - 26s - 13ms/step - loss: 0.0011 - mae: 0.0227 - val_loss: 6.3477e-04 - val_mae: 0.0169\n",
      "Epoch 41/50\n",
      "1943/1943 - 31s - 16ms/step - loss: 0.0011 - mae: 0.0227 - val_loss: 6.4778e-04 - val_mae: 0.0171\n",
      "Epoch 42/50\n",
      "1943/1943 - 27s - 14ms/step - loss: 0.0011 - mae: 0.0228 - val_loss: 6.4358e-04 - val_mae: 0.0170\n",
      "Epoch 43/50\n",
      "1943/1943 - 35s - 18ms/step - loss: 0.0011 - mae: 0.0228 - val_loss: 6.3452e-04 - val_mae: 0.0169\n",
      "Epoch 44/50\n",
      "1943/1943 - 33s - 17ms/step - loss: 0.0011 - mae: 0.0228 - val_loss: 6.8142e-04 - val_mae: 0.0175\n",
      "Epoch 45/50\n",
      "1943/1943 - 27s - 14ms/step - loss: 0.0011 - mae: 0.0228 - val_loss: 7.5420e-04 - val_mae: 0.0190\n",
      "Epoch 46/50\n",
      "1943/1943 - 19s - 10ms/step - loss: 0.0011 - mae: 0.0227 - val_loss: 6.4181e-04 - val_mae: 0.0170\n",
      "Epoch 47/50\n",
      "1943/1943 - 33s - 17ms/step - loss: 0.0011 - mae: 0.0227 - val_loss: 8.4564e-04 - val_mae: 0.0200\n",
      "Epoch 48/50\n",
      "1943/1943 - 28s - 14ms/step - loss: 0.0011 - mae: 0.0227 - val_loss: 6.4985e-04 - val_mae: 0.0171\n",
      "Epoch 49/50\n",
      "1943/1943 - 27s - 14ms/step - loss: 0.0011 - mae: 0.0228 - val_loss: 7.3612e-04 - val_mae: 0.0182\n",
      "Epoch 50/50\n",
      "1943/1943 - 27s - 14ms/step - loss: 0.0011 - mae: 0.0227 - val_loss: 6.4868e-04 - val_mae: 0.0172\n",
      "✅ Done with onion_Kolar_daily.csv | MAE=543.84, RMSE=773.3, R2=0.51, MAPE=41.18%, Accuracy=58.82%\n",
      "\n",
      "🚀 Processing: onion_MadikeriKodagu_daily.csv\n",
      "Epoch 1/50\n",
      "266/266 - 10s - 37ms/step - loss: 0.1124 - mae: 0.1854 - val_loss: 0.0087 - val_mae: 0.0837\n",
      "Epoch 2/50\n",
      "266/266 - 2s - 9ms/step - loss: 0.0170 - mae: 0.1022 - val_loss: 0.0025 - val_mae: 0.0399\n",
      "Epoch 3/50\n",
      "266/266 - 2s - 9ms/step - loss: 0.0123 - mae: 0.0857 - val_loss: 0.0116 - val_mae: 0.1053\n",
      "Epoch 4/50\n",
      "266/266 - 3s - 12ms/step - loss: 0.0080 - mae: 0.0682 - val_loss: 0.0221 - val_mae: 0.1476\n",
      "Epoch 5/50\n",
      "266/266 - 3s - 10ms/step - loss: 0.0064 - mae: 0.0601 - val_loss: 0.0065 - val_mae: 0.0794\n",
      "Epoch 6/50\n",
      "266/266 - 3s - 10ms/step - loss: 0.0061 - mae: 0.0579 - val_loss: 0.0022 - val_mae: 0.0453\n",
      "Epoch 7/50\n",
      "266/266 - 5s - 18ms/step - loss: 0.0056 - mae: 0.0541 - val_loss: 0.0135 - val_mae: 0.1155\n",
      "Epoch 8/50\n",
      "266/266 - 3s - 10ms/step - loss: 0.0050 - mae: 0.0496 - val_loss: 0.0113 - val_mae: 0.1057\n",
      "Epoch 9/50\n",
      "266/266 - 5s - 18ms/step - loss: 0.0045 - mae: 0.0463 - val_loss: 0.0096 - val_mae: 0.0974\n",
      "Epoch 10/50\n",
      "266/266 - 3s - 11ms/step - loss: 0.0043 - mae: 0.0448 - val_loss: 0.0095 - val_mae: 0.0972\n",
      "Epoch 11/50\n",
      "266/266 - 2s - 9ms/step - loss: 0.0042 - mae: 0.0447 - val_loss: 0.0129 - val_mae: 0.1134\n",
      "Epoch 12/50\n",
      "266/266 - 4s - 16ms/step - loss: 0.0043 - mae: 0.0444 - val_loss: 0.0126 - val_mae: 0.1122\n",
      "Epoch 13/50\n",
      "266/266 - 3s - 12ms/step - loss: 0.0040 - mae: 0.0428 - val_loss: 0.0131 - val_mae: 0.1143\n",
      "Epoch 14/50\n",
      "266/266 - 4s - 14ms/step - loss: 0.0039 - mae: 0.0411 - val_loss: 0.0220 - val_mae: 0.1483\n",
      "Epoch 15/50\n",
      "266/266 - 3s - 11ms/step - loss: 0.0039 - mae: 0.0412 - val_loss: 0.0367 - val_mae: 0.1916\n",
      "Epoch 16/50\n",
      "266/266 - 4s - 13ms/step - loss: 0.0040 - mae: 0.0418 - val_loss: 0.0157 - val_mae: 0.1252\n",
      "Epoch 17/50\n",
      "266/266 - 4s - 16ms/step - loss: 0.0037 - mae: 0.0397 - val_loss: 0.0130 - val_mae: 0.1140\n",
      "Epoch 18/50\n",
      "266/266 - 4s - 15ms/step - loss: 0.0039 - mae: 0.0407 - val_loss: 0.0093 - val_mae: 0.0964\n",
      "Epoch 19/50\n",
      "266/266 - 4s - 13ms/step - loss: 0.0035 - mae: 0.0362 - val_loss: 0.0102 - val_mae: 0.1007\n",
      "Epoch 20/50\n",
      "266/266 - 3s - 10ms/step - loss: 0.0039 - mae: 0.0405 - val_loss: 0.0030 - val_mae: 0.0548\n",
      "Epoch 21/50\n",
      "266/266 - 4s - 13ms/step - loss: 0.0037 - mae: 0.0392 - val_loss: 0.0112 - val_mae: 0.1056\n",
      "Epoch 22/50\n",
      "266/266 - 4s - 15ms/step - loss: 0.0036 - mae: 0.0373 - val_loss: 0.0134 - val_mae: 0.1156\n",
      "Epoch 23/50\n",
      "266/266 - 3s - 11ms/step - loss: 0.0036 - mae: 0.0378 - val_loss: 0.0244 - val_mae: 0.1562\n",
      "Epoch 24/50\n",
      "266/266 - 3s - 10ms/step - loss: 0.0036 - mae: 0.0380 - val_loss: 9.9943e-04 - val_mae: 0.0313\n",
      "Epoch 25/50\n",
      "266/266 - 4s - 16ms/step - loss: 0.0035 - mae: 0.0368 - val_loss: 0.0117 - val_mae: 0.1083\n",
      "Epoch 26/50\n",
      "266/266 - 3s - 10ms/step - loss: 0.0037 - mae: 0.0394 - val_loss: 0.0093 - val_mae: 0.0965\n",
      "Epoch 27/50\n",
      "266/266 - 3s - 12ms/step - loss: 0.0035 - mae: 0.0368 - val_loss: 0.0273 - val_mae: 0.1651\n",
      "Epoch 28/50\n",
      "266/266 - 3s - 12ms/step - loss: 0.0036 - mae: 0.0382 - val_loss: 0.0277 - val_mae: 0.1662\n",
      "Epoch 29/50\n",
      "266/266 - 3s - 10ms/step - loss: 0.0035 - mae: 0.0366 - val_loss: 0.0125 - val_mae: 0.1116\n",
      "Epoch 30/50\n",
      "266/266 - 3s - 10ms/step - loss: 0.0034 - mae: 0.0364 - val_loss: 0.0108 - val_mae: 0.1040\n",
      "Epoch 31/50\n",
      "266/266 - 2s - 9ms/step - loss: 0.0033 - mae: 0.0349 - val_loss: 0.0232 - val_mae: 0.1522\n",
      "Epoch 32/50\n",
      "266/266 - 3s - 10ms/step - loss: 0.0034 - mae: 0.0354 - val_loss: 0.0055 - val_mae: 0.0741\n",
      "Epoch 33/50\n",
      "266/266 - 5s - 19ms/step - loss: 0.0033 - mae: 0.0351 - val_loss: 0.0255 - val_mae: 0.1593\n",
      "Epoch 34/50\n",
      "266/266 - 2s - 9ms/step - loss: 0.0034 - mae: 0.0358 - val_loss: 0.0099 - val_mae: 0.0994\n",
      "Epoch 35/50\n",
      "266/266 - 4s - 16ms/step - loss: 0.0035 - mae: 0.0379 - val_loss: 0.0160 - val_mae: 0.1263\n",
      "Epoch 36/50\n",
      "266/266 - 3s - 11ms/step - loss: 0.0034 - mae: 0.0363 - val_loss: 0.0217 - val_mae: 0.1471\n",
      "Epoch 37/50\n",
      "266/266 - 2s - 9ms/step - loss: 0.0032 - mae: 0.0338 - val_loss: 0.0076 - val_mae: 0.0870\n",
      "Epoch 38/50\n",
      "266/266 - 3s - 12ms/step - loss: 0.0033 - mae: 0.0340 - val_loss: 0.0045 - val_mae: 0.0667\n",
      "Epoch 39/50\n",
      "266/266 - 3s - 10ms/step - loss: 0.0033 - mae: 0.0347 - val_loss: 0.0168 - val_mae: 0.1294\n",
      "Epoch 40/50\n",
      "266/266 - 3s - 10ms/step - loss: 0.0035 - mae: 0.0371 - val_loss: 0.0084 - val_mae: 0.0911\n",
      "Epoch 41/50\n",
      "266/266 - 3s - 10ms/step - loss: 0.0033 - mae: 0.0348 - val_loss: 0.0132 - val_mae: 0.1144\n",
      "Epoch 42/50\n",
      "266/266 - 5s - 20ms/step - loss: 0.0035 - mae: 0.0369 - val_loss: 0.0061 - val_mae: 0.0782\n",
      "Epoch 43/50\n",
      "266/266 - 3s - 10ms/step - loss: 0.0033 - mae: 0.0352 - val_loss: 0.0084 - val_mae: 0.0914\n",
      "Epoch 44/50\n",
      "266/266 - 4s - 13ms/step - loss: 0.0033 - mae: 0.0352 - val_loss: 0.0023 - val_mae: 0.0475\n",
      "Epoch 45/50\n",
      "266/266 - 2s - 9ms/step - loss: 0.0033 - mae: 0.0352 - val_loss: 0.0086 - val_mae: 0.0926\n",
      "Epoch 46/50\n",
      "266/266 - 4s - 14ms/step - loss: 0.0031 - mae: 0.0330 - val_loss: 0.0160 - val_mae: 0.1261\n",
      "Epoch 47/50\n",
      "266/266 - 3s - 13ms/step - loss: 0.0031 - mae: 0.0329 - val_loss: 0.0048 - val_mae: 0.0693\n",
      "Epoch 48/50\n",
      "266/266 - 3s - 10ms/step - loss: 0.0032 - mae: 0.0338 - val_loss: 0.0114 - val_mae: 0.1066\n",
      "Epoch 49/50\n",
      "266/266 - 3s - 10ms/step - loss: 0.0032 - mae: 0.0340 - val_loss: 0.0045 - val_mae: 0.0670\n",
      "Epoch 50/50\n",
      "266/266 - 3s - 10ms/step - loss: 0.0032 - mae: 0.0332 - val_loss: 0.0196 - val_mae: 0.1397\n",
      "✅ Done with onion_MadikeriKodagu_daily.csv | MAE=270.41, RMSE=296.24, R2=0.66, MAPE=22.8%, Accuracy=77.2%\n",
      "\n",
      "🚀 Processing: onion_Mandya_daily.csv\n",
      "Epoch 1/50\n",
      "718/718 - 15s - 20ms/step - loss: 0.0175 - mae: 0.0839 - val_loss: 0.0057 - val_mae: 0.0656\n",
      "Epoch 2/50\n",
      "718/718 - 9s - 13ms/step - loss: 0.0061 - mae: 0.0621 - val_loss: 0.0056 - val_mae: 0.0654\n",
      "Epoch 3/50\n",
      "718/718 - 9s - 12ms/step - loss: 0.0049 - mae: 0.0565 - val_loss: 0.0059 - val_mae: 0.0576\n",
      "Epoch 4/50\n",
      "718/718 - 6s - 9ms/step - loss: 0.0046 - mae: 0.0549 - val_loss: 0.0065 - val_mae: 0.0620\n",
      "Epoch 5/50\n",
      "718/718 - 7s - 9ms/step - loss: 0.0043 - mae: 0.0533 - val_loss: 0.0036 - val_mae: 0.0525\n",
      "Epoch 6/50\n",
      "718/718 - 7s - 10ms/step - loss: 0.0043 - mae: 0.0535 - val_loss: 0.0037 - val_mae: 0.0533\n",
      "Epoch 7/50\n",
      "718/718 - 7s - 10ms/step - loss: 0.0042 - mae: 0.0526 - val_loss: 0.0037 - val_mae: 0.0536\n",
      "Epoch 8/50\n",
      "718/718 - 7s - 10ms/step - loss: 0.0040 - mae: 0.0520 - val_loss: 0.0036 - val_mae: 0.0527\n",
      "Epoch 9/50\n",
      "718/718 - 11s - 16ms/step - loss: 0.0040 - mae: 0.0515 - val_loss: 0.0037 - val_mae: 0.0478\n",
      "Epoch 10/50\n",
      "718/718 - 12s - 17ms/step - loss: 0.0040 - mae: 0.0519 - val_loss: 0.0044 - val_mae: 0.0591\n",
      "Epoch 11/50\n",
      "718/718 - 7s - 10ms/step - loss: 0.0039 - mae: 0.0514 - val_loss: 0.0038 - val_mae: 0.0545\n",
      "Epoch 12/50\n",
      "718/718 - 13s - 17ms/step - loss: 0.0039 - mae: 0.0514 - val_loss: 0.0034 - val_mae: 0.0487\n",
      "Epoch 13/50\n",
      "718/718 - 7s - 10ms/step - loss: 0.0039 - mae: 0.0513 - val_loss: 0.0036 - val_mae: 0.0468\n",
      "Epoch 14/50\n",
      "718/718 - 10s - 14ms/step - loss: 0.0039 - mae: 0.0512 - val_loss: 0.0035 - val_mae: 0.0491\n",
      "Epoch 15/50\n",
      "718/718 - 12s - 17ms/step - loss: 0.0039 - mae: 0.0514 - val_loss: 0.0034 - val_mae: 0.0473\n",
      "Epoch 16/50\n",
      "718/718 - 6s - 9ms/step - loss: 0.0039 - mae: 0.0514 - val_loss: 0.0039 - val_mae: 0.0553\n",
      "Epoch 17/50\n",
      "718/718 - 10s - 13ms/step - loss: 0.0038 - mae: 0.0508 - val_loss: 0.0036 - val_mae: 0.0520\n",
      "Epoch 18/50\n",
      "718/718 - 6s - 9ms/step - loss: 0.0038 - mae: 0.0507 - val_loss: 0.0033 - val_mae: 0.0465\n",
      "Epoch 19/50\n",
      "718/718 - 7s - 9ms/step - loss: 0.0038 - mae: 0.0510 - val_loss: 0.0037 - val_mae: 0.0538\n",
      "Epoch 20/50\n",
      "718/718 - 7s - 9ms/step - loss: 0.0038 - mae: 0.0507 - val_loss: 0.0034 - val_mae: 0.0491\n",
      "Epoch 21/50\n",
      "718/718 - 13s - 18ms/step - loss: 0.0038 - mae: 0.0507 - val_loss: 0.0047 - val_mae: 0.0516\n",
      "Epoch 22/50\n",
      "718/718 - 12s - 17ms/step - loss: 0.0038 - mae: 0.0510 - val_loss: 0.0035 - val_mae: 0.0511\n",
      "Epoch 23/50\n",
      "718/718 - 7s - 10ms/step - loss: 0.0038 - mae: 0.0508 - val_loss: 0.0037 - val_mae: 0.0534\n",
      "Epoch 24/50\n",
      "718/718 - 8s - 11ms/step - loss: 0.0038 - mae: 0.0508 - val_loss: 0.0044 - val_mae: 0.0586\n",
      "Epoch 25/50\n",
      "718/718 - 10s - 14ms/step - loss: 0.0038 - mae: 0.0509 - val_loss: 0.0034 - val_mae: 0.0502\n",
      "Epoch 26/50\n",
      "718/718 - 7s - 10ms/step - loss: 0.0037 - mae: 0.0506 - val_loss: 0.0033 - val_mae: 0.0474\n",
      "Epoch 27/50\n",
      "718/718 - 10s - 14ms/step - loss: 0.0038 - mae: 0.0507 - val_loss: 0.0038 - val_mae: 0.0541\n",
      "Epoch 28/50\n",
      "718/718 - 6s - 9ms/step - loss: 0.0038 - mae: 0.0507 - val_loss: 0.0039 - val_mae: 0.0550\n",
      "Epoch 29/50\n",
      "718/718 - 10s - 15ms/step - loss: 0.0038 - mae: 0.0506 - val_loss: 0.0035 - val_mae: 0.0483\n",
      "Epoch 30/50\n",
      "718/718 - 11s - 15ms/step - loss: 0.0037 - mae: 0.0505 - val_loss: 0.0035 - val_mae: 0.0477\n",
      "Epoch 31/50\n",
      "718/718 - 6s - 9ms/step - loss: 0.0038 - mae: 0.0508 - val_loss: 0.0045 - val_mae: 0.0595\n",
      "Epoch 32/50\n",
      "718/718 - 10s - 14ms/step - loss: 0.0037 - mae: 0.0505 - val_loss: 0.0036 - val_mae: 0.0524\n",
      "Epoch 33/50\n",
      "718/718 - 7s - 9ms/step - loss: 0.0037 - mae: 0.0506 - val_loss: 0.0036 - val_mae: 0.0530\n",
      "Epoch 34/50\n",
      "718/718 - 7s - 10ms/step - loss: 0.0037 - mae: 0.0504 - val_loss: 0.0049 - val_mae: 0.0618\n",
      "Epoch 35/50\n",
      "718/718 - 11s - 16ms/step - loss: 0.0037 - mae: 0.0506 - val_loss: 0.0038 - val_mae: 0.0541\n",
      "Epoch 36/50\n",
      "718/718 - 12s - 17ms/step - loss: 0.0037 - mae: 0.0506 - val_loss: 0.0044 - val_mae: 0.0591\n",
      "Epoch 37/50\n",
      "718/718 - 13s - 18ms/step - loss: 0.0037 - mae: 0.0506 - val_loss: 0.0037 - val_mae: 0.0531\n",
      "Epoch 38/50\n",
      "718/718 - 7s - 10ms/step - loss: 0.0037 - mae: 0.0504 - val_loss: 0.0034 - val_mae: 0.0508\n",
      "Epoch 39/50\n",
      "718/718 - 6s - 9ms/step - loss: 0.0037 - mae: 0.0504 - val_loss: 0.0041 - val_mae: 0.0569\n",
      "Epoch 40/50\n",
      "718/718 - 7s - 10ms/step - loss: 0.0037 - mae: 0.0505 - val_loss: 0.0035 - val_mae: 0.0515\n",
      "Epoch 41/50\n",
      "718/718 - 6s - 9ms/step - loss: 0.0037 - mae: 0.0505 - val_loss: 0.0041 - val_mae: 0.0567\n",
      "Epoch 42/50\n",
      "718/718 - 8s - 11ms/step - loss: 0.0037 - mae: 0.0503 - val_loss: 0.0041 - val_mae: 0.0570\n",
      "Epoch 43/50\n",
      "718/718 - 11s - 16ms/step - loss: 0.0037 - mae: 0.0505 - val_loss: 0.0043 - val_mae: 0.0580\n",
      "Epoch 44/50\n",
      "718/718 - 20s - 27ms/step - loss: 0.0037 - mae: 0.0503 - val_loss: 0.0037 - val_mae: 0.0536\n",
      "Epoch 45/50\n",
      "718/718 - 13s - 18ms/step - loss: 0.0037 - mae: 0.0505 - val_loss: 0.0036 - val_mae: 0.0522\n",
      "Epoch 46/50\n",
      "718/718 - 7s - 10ms/step - loss: 0.0037 - mae: 0.0503 - val_loss: 0.0035 - val_mae: 0.0515\n",
      "Epoch 47/50\n",
      "718/718 - 7s - 10ms/step - loss: 0.0037 - mae: 0.0505 - val_loss: 0.0034 - val_mae: 0.0466\n",
      "Epoch 48/50\n",
      "718/718 - 13s - 18ms/step - loss: 0.0037 - mae: 0.0504 - val_loss: 0.0039 - val_mae: 0.0552\n",
      "Epoch 49/50\n",
      "718/718 - 8s - 10ms/step - loss: 0.0037 - mae: 0.0504 - val_loss: 0.0034 - val_mae: 0.0474\n",
      "Epoch 50/50\n",
      "718/718 - 9s - 12ms/step - loss: 0.0037 - mae: 0.0503 - val_loss: 0.0034 - val_mae: 0.0488\n",
      "✅ Done with onion_Mandya_daily.csv | MAE=533.05, RMSE=620.6, R2=0.31, MAPE=51.16%, Accuracy=48.84%\n",
      "\n",
      "🚀 Processing: onion_MangaloreDakshin_Kannad_daily.csv\n",
      "Epoch 1/50\n",
      "258/258 - 8s - 32ms/step - loss: 0.0277 - mae: 0.1068 - val_loss: 0.0230 - val_mae: 0.1329\n",
      "Epoch 2/50\n",
      "258/258 - 2s - 9ms/step - loss: 0.0048 - mae: 0.0535 - val_loss: 0.0191 - val_mae: 0.1215\n",
      "Epoch 3/50\n",
      "258/258 - 5s - 17ms/step - loss: 0.0023 - mae: 0.0355 - val_loss: 0.0152 - val_mae: 0.1040\n",
      "Epoch 4/50\n",
      "258/258 - 3s - 10ms/step - loss: 0.0021 - mae: 0.0331 - val_loss: 0.0097 - val_mae: 0.0649\n",
      "Epoch 5/50\n",
      "258/258 - 3s - 10ms/step - loss: 0.0017 - mae: 0.0290 - val_loss: 0.0100 - val_mae: 0.0732\n",
      "Epoch 6/50\n",
      "258/258 - 5s - 18ms/step - loss: 0.0015 - mae: 0.0259 - val_loss: 0.0096 - val_mae: 0.0730\n",
      "Epoch 7/50\n",
      "258/258 - 3s - 11ms/step - loss: 0.0015 - mae: 0.0253 - val_loss: 0.0105 - val_mae: 0.0800\n",
      "Epoch 8/50\n",
      "258/258 - 2s - 9ms/step - loss: 0.0015 - mae: 0.0252 - val_loss: 0.0093 - val_mae: 0.0723\n",
      "Epoch 9/50\n",
      "258/258 - 4s - 14ms/step - loss: 0.0013 - mae: 0.0229 - val_loss: 0.0090 - val_mae: 0.0711\n",
      "Epoch 10/50\n",
      "258/258 - 3s - 10ms/step - loss: 0.0013 - mae: 0.0218 - val_loss: 0.0103 - val_mae: 0.0810\n",
      "Epoch 11/50\n",
      "258/258 - 3s - 10ms/step - loss: 0.0015 - mae: 0.0252 - val_loss: 0.0083 - val_mae: 0.0665\n",
      "Epoch 12/50\n",
      "258/258 - 2s - 9ms/step - loss: 0.0013 - mae: 0.0220 - val_loss: 0.0105 - val_mae: 0.0828\n",
      "Epoch 13/50\n",
      "258/258 - 3s - 13ms/step - loss: 0.0014 - mae: 0.0237 - val_loss: 0.0102 - val_mae: 0.0807\n",
      "Epoch 14/50\n",
      "258/258 - 2s - 9ms/step - loss: 0.0012 - mae: 0.0212 - val_loss: 0.0075 - val_mae: 0.0621\n",
      "Epoch 15/50\n",
      "258/258 - 2s - 9ms/step - loss: 0.0012 - mae: 0.0211 - val_loss: 0.0097 - val_mae: 0.0784\n",
      "Epoch 16/50\n",
      "258/258 - 3s - 11ms/step - loss: 0.0012 - mae: 0.0205 - val_loss: 0.0090 - val_mae: 0.0741\n",
      "Epoch 17/50\n",
      "258/258 - 3s - 10ms/step - loss: 0.0012 - mae: 0.0215 - val_loss: 0.0072 - val_mae: 0.0617\n",
      "Epoch 18/50\n",
      "258/258 - 2s - 9ms/step - loss: 0.0012 - mae: 0.0207 - val_loss: 0.0078 - val_mae: 0.0638\n",
      "Epoch 19/50\n",
      "258/258 - 3s - 10ms/step - loss: 0.0012 - mae: 0.0218 - val_loss: 0.0081 - val_mae: 0.0688\n",
      "Epoch 20/50\n",
      "258/258 - 3s - 12ms/step - loss: 0.0011 - mae: 0.0194 - val_loss: 0.0087 - val_mae: 0.0727\n",
      "Epoch 21/50\n",
      "258/258 - 3s - 10ms/step - loss: 0.0011 - mae: 0.0200 - val_loss: 0.0111 - val_mae: 0.0876\n",
      "Epoch 22/50\n",
      "258/258 - 5s - 18ms/step - loss: 0.0012 - mae: 0.0204 - val_loss: 0.0115 - val_mae: 0.0896\n",
      "Epoch 23/50\n",
      "258/258 - 3s - 13ms/step - loss: 0.0012 - mae: 0.0205 - val_loss: 0.0112 - val_mae: 0.0886\n",
      "Epoch 24/50\n",
      "258/258 - 2s - 9ms/step - loss: 0.0013 - mae: 0.0219 - val_loss: 0.0080 - val_mae: 0.0678\n",
      "Epoch 25/50\n",
      "258/258 - 5s - 18ms/step - loss: 0.0012 - mae: 0.0206 - val_loss: 0.0089 - val_mae: 0.0746\n",
      "Epoch 26/50\n",
      "258/258 - 4s - 14ms/step - loss: 0.0012 - mae: 0.0206 - val_loss: 0.0119 - val_mae: 0.0921\n",
      "Epoch 27/50\n",
      "258/258 - 4s - 16ms/step - loss: 0.0011 - mae: 0.0195 - val_loss: 0.0091 - val_mae: 0.0756\n",
      "Epoch 28/50\n",
      "258/258 - 3s - 10ms/step - loss: 0.0012 - mae: 0.0206 - val_loss: 0.0096 - val_mae: 0.0792\n",
      "Epoch 29/50\n",
      "258/258 - 5s - 19ms/step - loss: 0.0011 - mae: 0.0200 - val_loss: 0.0084 - val_mae: 0.0707\n",
      "Epoch 30/50\n",
      "258/258 - 3s - 10ms/step - loss: 0.0012 - mae: 0.0201 - val_loss: 0.0085 - val_mae: 0.0721\n",
      "Epoch 31/50\n",
      "258/258 - 5s - 19ms/step - loss: 0.0011 - mae: 0.0190 - val_loss: 0.0097 - val_mae: 0.0798\n",
      "Epoch 32/50\n",
      "258/258 - 3s - 12ms/step - loss: 0.0010 - mae: 0.0176 - val_loss: 0.0087 - val_mae: 0.0732\n",
      "Epoch 33/50\n",
      "258/258 - 2s - 9ms/step - loss: 0.0011 - mae: 0.0189 - val_loss: 0.0105 - val_mae: 0.0839\n",
      "Epoch 34/50\n",
      "258/258 - 3s - 10ms/step - loss: 0.0011 - mae: 0.0200 - val_loss: 0.0080 - val_mae: 0.0693\n",
      "Epoch 35/50\n",
      "258/258 - 4s - 15ms/step - loss: 0.0012 - mae: 0.0198 - val_loss: 0.0091 - val_mae: 0.0749\n",
      "Epoch 36/50\n",
      "258/258 - 3s - 10ms/step - loss: 0.0010 - mae: 0.0176 - val_loss: 0.0119 - val_mae: 0.0924\n",
      "Epoch 37/50\n",
      "258/258 - 2s - 9ms/step - loss: 0.0011 - mae: 0.0186 - val_loss: 0.0087 - val_mae: 0.0734\n",
      "Epoch 38/50\n",
      "258/258 - 2s - 9ms/step - loss: 0.0011 - mae: 0.0186 - val_loss: 0.0093 - val_mae: 0.0773\n",
      "Epoch 39/50\n",
      "258/258 - 4s - 16ms/step - loss: 0.0010 - mae: 0.0175 - val_loss: 0.0086 - val_mae: 0.0723\n",
      "Epoch 40/50\n",
      "258/258 - 2s - 9ms/step - loss: 0.0010 - mae: 0.0171 - val_loss: 0.0082 - val_mae: 0.0697\n",
      "Epoch 41/50\n",
      "258/258 - 4s - 14ms/step - loss: 0.0011 - mae: 0.0195 - val_loss: 0.0092 - val_mae: 0.0761\n",
      "Epoch 42/50\n",
      "258/258 - 5s - 18ms/step - loss: 0.0011 - mae: 0.0207 - val_loss: 0.0078 - val_mae: 0.0674\n",
      "Epoch 43/50\n",
      "258/258 - 5s - 19ms/step - loss: 9.8015e-04 - mae: 0.0174 - val_loss: 0.0075 - val_mae: 0.0654\n",
      "Epoch 44/50\n",
      "258/258 - 3s - 13ms/step - loss: 9.9235e-04 - mae: 0.0170 - val_loss: 0.0078 - val_mae: 0.0676\n",
      "Epoch 45/50\n",
      "258/258 - 3s - 10ms/step - loss: 0.0010 - mae: 0.0181 - val_loss: 0.0106 - val_mae: 0.0844\n",
      "Epoch 46/50\n",
      "258/258 - 2s - 9ms/step - loss: 9.9689e-04 - mae: 0.0176 - val_loss: 0.0084 - val_mae: 0.0721\n",
      "Epoch 47/50\n",
      "258/258 - 4s - 15ms/step - loss: 0.0010 - mae: 0.0178 - val_loss: 0.0081 - val_mae: 0.0704\n",
      "Epoch 48/50\n",
      "258/258 - 3s - 10ms/step - loss: 9.8539e-04 - mae: 0.0175 - val_loss: 0.0098 - val_mae: 0.0803\n",
      "Epoch 49/50\n",
      "258/258 - 2s - 9ms/step - loss: 9.8836e-04 - mae: 0.0176 - val_loss: 0.0084 - val_mae: 0.0719\n",
      "Epoch 50/50\n",
      "258/258 - 3s - 10ms/step - loss: 9.0349e-04 - mae: 0.0158 - val_loss: 0.0090 - val_mae: 0.0756\n",
      "✅ Done with onion_MangaloreDakshin_Kannad_daily.csv | MAE=270.64, RMSE=347.61, R2=0.84, MAPE=14.07%, Accuracy=85.93%\n",
      "\n",
      "🚀 Processing: onion_Mysore_daily.csv\n",
      "Epoch 1/50\n",
      "901/901 - 15s - 17ms/step - loss: 0.0107 - mae: 0.0531 - val_loss: 0.0011 - val_mae: 0.0220\n",
      "Epoch 2/50\n",
      "901/901 - 9s - 10ms/step - loss: 0.0013 - mae: 0.0272 - val_loss: 0.0015 - val_mae: 0.0257\n",
      "Epoch 3/50\n",
      "901/901 - 11s - 12ms/step - loss: 0.0012 - mae: 0.0255 - val_loss: 0.0012 - val_mae: 0.0221\n",
      "Epoch 4/50\n",
      "901/901 - 15s - 16ms/step - loss: 0.0011 - mae: 0.0249 - val_loss: 0.0012 - val_mae: 0.0229\n",
      "Epoch 5/50\n",
      "901/901 - 15s - 17ms/step - loss: 0.0011 - mae: 0.0245 - val_loss: 0.0011 - val_mae: 0.0217\n",
      "Epoch 6/50\n",
      "901/901 - 15s - 17ms/step - loss: 0.0011 - mae: 0.0241 - val_loss: 0.0010 - val_mae: 0.0213\n",
      "Epoch 7/50\n",
      "901/901 - 10s - 11ms/step - loss: 0.0011 - mae: 0.0243 - val_loss: 0.0011 - val_mae: 0.0232\n",
      "Epoch 8/50\n",
      "901/901 - 8s - 9ms/step - loss: 0.0010 - mae: 0.0240 - val_loss: 0.0010 - val_mae: 0.0215\n",
      "Epoch 9/50\n",
      "901/901 - 13s - 14ms/step - loss: 0.0010 - mae: 0.0237 - val_loss: 0.0011 - val_mae: 0.0221\n",
      "Epoch 10/50\n",
      "901/901 - 12s - 14ms/step - loss: 0.0011 - mae: 0.0244 - val_loss: 9.5115e-04 - val_mae: 0.0210\n",
      "Epoch 11/50\n",
      "901/901 - 18s - 20ms/step - loss: 0.0010 - mae: 0.0239 - val_loss: 0.0014 - val_mae: 0.0269\n",
      "Epoch 12/50\n",
      "901/901 - 15s - 16ms/step - loss: 0.0010 - mae: 0.0239 - val_loss: 9.1696e-04 - val_mae: 0.0204\n",
      "Epoch 13/50\n",
      "901/901 - 14s - 15ms/step - loss: 0.0010 - mae: 0.0234 - val_loss: 8.9048e-04 - val_mae: 0.0200\n",
      "Epoch 14/50\n",
      "901/901 - 9s - 10ms/step - loss: 0.0010 - mae: 0.0237 - val_loss: 9.0161e-04 - val_mae: 0.0202\n",
      "Epoch 15/50\n",
      "901/901 - 9s - 10ms/step - loss: 9.9543e-04 - mae: 0.0234 - val_loss: 8.6444e-04 - val_mae: 0.0196\n",
      "Epoch 16/50\n",
      "901/901 - 16s - 18ms/step - loss: 0.0010 - mae: 0.0235 - val_loss: 0.0010 - val_mae: 0.0219\n",
      "Epoch 17/50\n",
      "901/901 - 13s - 14ms/step - loss: 9.9967e-04 - mae: 0.0234 - val_loss: 8.8291e-04 - val_mae: 0.0199\n",
      "Epoch 18/50\n",
      "901/901 - 11s - 12ms/step - loss: 9.9408e-04 - mae: 0.0233 - val_loss: 9.0247e-04 - val_mae: 0.0201\n",
      "Epoch 19/50\n",
      "901/901 - 9s - 10ms/step - loss: 9.8716e-04 - mae: 0.0233 - val_loss: 8.9651e-04 - val_mae: 0.0203\n",
      "Epoch 20/50\n",
      "901/901 - 11s - 13ms/step - loss: 9.8820e-04 - mae: 0.0233 - val_loss: 9.0563e-04 - val_mae: 0.0202\n",
      "Epoch 21/50\n",
      "901/901 - 10s - 11ms/step - loss: 9.7757e-04 - mae: 0.0233 - val_loss: 9.4278e-04 - val_mae: 0.0207\n",
      "Epoch 22/50\n",
      "901/901 - 18s - 20ms/step - loss: 9.8309e-04 - mae: 0.0232 - val_loss: 9.2870e-04 - val_mae: 0.0208\n",
      "Epoch 23/50\n",
      "901/901 - 14s - 15ms/step - loss: 9.8205e-04 - mae: 0.0232 - val_loss: 9.8421e-04 - val_mae: 0.0212\n",
      "Epoch 24/50\n",
      "901/901 - 9s - 10ms/step - loss: 9.8584e-04 - mae: 0.0232 - val_loss: 8.7492e-04 - val_mae: 0.0198\n",
      "Epoch 25/50\n",
      "901/901 - 9s - 10ms/step - loss: 9.6791e-04 - mae: 0.0230 - val_loss: 0.0011 - val_mae: 0.0219\n",
      "Epoch 26/50\n",
      "901/901 - 10s - 11ms/step - loss: 9.7689e-04 - mae: 0.0231 - val_loss: 0.0011 - val_mae: 0.0224\n",
      "Epoch 27/50\n",
      "901/901 - 10s - 11ms/step - loss: 9.7417e-04 - mae: 0.0232 - val_loss: 8.6802e-04 - val_mae: 0.0198\n",
      "Epoch 28/50\n",
      "901/901 - 10s - 11ms/step - loss: 9.6611e-04 - mae: 0.0229 - val_loss: 0.0012 - val_mae: 0.0235\n",
      "Epoch 29/50\n",
      "901/901 - 11s - 13ms/step - loss: 9.6152e-04 - mae: 0.0229 - val_loss: 8.5864e-04 - val_mae: 0.0197\n",
      "Epoch 30/50\n",
      "901/901 - 12s - 13ms/step - loss: 9.6551e-04 - mae: 0.0230 - val_loss: 8.8594e-04 - val_mae: 0.0199\n",
      "Epoch 31/50\n",
      "901/901 - 8s - 9ms/step - loss: 9.5472e-04 - mae: 0.0228 - val_loss: 0.0015 - val_mae: 0.0262\n",
      "Epoch 32/50\n",
      "901/901 - 11s - 12ms/step - loss: 9.5956e-04 - mae: 0.0229 - val_loss: 8.8396e-04 - val_mae: 0.0198\n",
      "Epoch 33/50\n",
      "901/901 - 8s - 9ms/step - loss: 9.5847e-04 - mae: 0.0228 - val_loss: 0.0011 - val_mae: 0.0221\n",
      "Epoch 34/50\n",
      "901/901 - 10s - 11ms/step - loss: 9.6034e-04 - mae: 0.0229 - val_loss: 8.4945e-04 - val_mae: 0.0196\n",
      "Epoch 35/50\n",
      "901/901 - 12s - 13ms/step - loss: 9.4856e-04 - mae: 0.0228 - val_loss: 8.9317e-04 - val_mae: 0.0200\n",
      "Epoch 36/50\n",
      "901/901 - 12s - 13ms/step - loss: 9.5903e-04 - mae: 0.0228 - val_loss: 8.4408e-04 - val_mae: 0.0195\n",
      "Epoch 37/50\n",
      "901/901 - 14s - 16ms/step - loss: 9.4932e-04 - mae: 0.0227 - val_loss: 0.0011 - val_mae: 0.0222\n",
      "Epoch 38/50\n",
      "901/901 - 16s - 18ms/step - loss: 9.5298e-04 - mae: 0.0228 - val_loss: 8.5791e-04 - val_mae: 0.0198\n",
      "Epoch 39/50\n",
      "901/901 - 17s - 19ms/step - loss: 9.4537e-04 - mae: 0.0227 - val_loss: 8.7327e-04 - val_mae: 0.0199\n",
      "Epoch 40/50\n",
      "901/901 - 13s - 14ms/step - loss: 9.4727e-04 - mae: 0.0227 - val_loss: 9.1003e-04 - val_mae: 0.0202\n",
      "Epoch 41/50\n",
      "901/901 - 15s - 16ms/step - loss: 9.4085e-04 - mae: 0.0226 - val_loss: 9.5445e-04 - val_mae: 0.0214\n",
      "Epoch 42/50\n",
      "901/901 - 16s - 17ms/step - loss: 9.4322e-04 - mae: 0.0226 - val_loss: 8.5601e-04 - val_mae: 0.0196\n",
      "Epoch 43/50\n",
      "901/901 - 19s - 21ms/step - loss: 9.4190e-04 - mae: 0.0227 - val_loss: 9.0231e-04 - val_mae: 0.0204\n",
      "Epoch 44/50\n",
      "901/901 - 9s - 10ms/step - loss: 9.4515e-04 - mae: 0.0226 - val_loss: 8.5730e-04 - val_mae: 0.0197\n",
      "Epoch 45/50\n",
      "901/901 - 17s - 19ms/step - loss: 9.4114e-04 - mae: 0.0226 - val_loss: 9.2437e-04 - val_mae: 0.0205\n",
      "Epoch 46/50\n",
      "901/901 - 9s - 10ms/step - loss: 9.4235e-04 - mae: 0.0226 - val_loss: 8.8445e-04 - val_mae: 0.0202\n",
      "Epoch 47/50\n",
      "901/901 - 15s - 17ms/step - loss: 9.3727e-04 - mae: 0.0226 - val_loss: 8.9448e-04 - val_mae: 0.0203\n",
      "Epoch 48/50\n",
      "901/901 - 18s - 20ms/step - loss: 9.4315e-04 - mae: 0.0227 - val_loss: 8.7140e-04 - val_mae: 0.0202\n",
      "Epoch 49/50\n",
      "901/901 - 9s - 10ms/step - loss: 9.3615e-04 - mae: 0.0226 - val_loss: 8.6934e-04 - val_mae: 0.0199\n",
      "Epoch 50/50\n",
      "901/901 - 9s - 10ms/step - loss: 9.3533e-04 - mae: 0.0226 - val_loss: 8.7190e-04 - val_mae: 0.0200\n",
      "✅ Done with onion_Mysore_daily.csv | MAE=418.64, RMSE=578.16, R2=0.46, MAPE=29.37%, Accuracy=70.63%\n",
      "\n",
      "🚀 Processing: onion_Raichur_daily.csv\n",
      "Epoch 1/50\n",
      "301/301 - 9s - 30ms/step - loss: 0.0546 - mae: 0.1223 - val_loss: 0.0017 - val_mae: 0.0321\n",
      "Epoch 2/50\n",
      "301/301 - 3s - 11ms/step - loss: 0.0057 - mae: 0.0552 - val_loss: 0.0025 - val_mae: 0.0409\n",
      "Epoch 3/50\n",
      "301/301 - 4s - 12ms/step - loss: 0.0037 - mae: 0.0433 - val_loss: 0.0033 - val_mae: 0.0450\n",
      "Epoch 4/50\n",
      "301/301 - 4s - 12ms/step - loss: 0.0037 - mae: 0.0434 - val_loss: 0.0038 - val_mae: 0.0503\n",
      "Epoch 5/50\n",
      "301/301 - 4s - 14ms/step - loss: 0.0029 - mae: 0.0369 - val_loss: 0.0057 - val_mae: 0.0636\n",
      "Epoch 6/50\n",
      "301/301 - 3s - 11ms/step - loss: 0.0027 - mae: 0.0358 - val_loss: 0.0020 - val_mae: 0.0349\n",
      "Epoch 7/50\n",
      "301/301 - 3s - 11ms/step - loss: 0.0027 - mae: 0.0358 - val_loss: 0.0018 - val_mae: 0.0340\n",
      "Epoch 8/50\n",
      "301/301 - 3s - 11ms/step - loss: 0.0029 - mae: 0.0375 - val_loss: 0.0031 - val_mae: 0.0479\n",
      "Epoch 9/50\n",
      "301/301 - 3s - 11ms/step - loss: 0.0027 - mae: 0.0355 - val_loss: 0.0014 - val_mae: 0.0294\n",
      "Epoch 10/50\n",
      "301/301 - 3s - 10ms/step - loss: 0.0026 - mae: 0.0342 - val_loss: 0.0016 - val_mae: 0.0323\n",
      "Epoch 11/50\n",
      "301/301 - 3s - 11ms/step - loss: 0.0024 - mae: 0.0332 - val_loss: 9.9236e-04 - val_mae: 0.0244\n",
      "Epoch 12/50\n",
      "301/301 - 3s - 10ms/step - loss: 0.0024 - mae: 0.0326 - val_loss: 0.0010 - val_mae: 0.0246\n",
      "Epoch 13/50\n",
      "301/301 - 5s - 18ms/step - loss: 0.0023 - mae: 0.0315 - val_loss: 0.0010 - val_mae: 0.0248\n",
      "Epoch 14/50\n",
      "301/301 - 3s - 11ms/step - loss: 0.0024 - mae: 0.0329 - val_loss: 9.4017e-04 - val_mae: 0.0241\n",
      "Epoch 15/50\n",
      "301/301 - 3s - 11ms/step - loss: 0.0023 - mae: 0.0319 - val_loss: 7.2351e-04 - val_mae: 0.0195\n",
      "Epoch 16/50\n",
      "301/301 - 4s - 14ms/step - loss: 0.0023 - mae: 0.0316 - val_loss: 0.0015 - val_mae: 0.0309\n",
      "Epoch 17/50\n",
      "301/301 - 3s - 11ms/step - loss: 0.0023 - mae: 0.0320 - val_loss: 6.8349e-04 - val_mae: 0.0192\n",
      "Epoch 18/50\n",
      "301/301 - 3s - 10ms/step - loss: 0.0025 - mae: 0.0344 - val_loss: 9.6422e-04 - val_mae: 0.0241\n",
      "Epoch 19/50\n",
      "301/301 - 3s - 11ms/step - loss: 0.0024 - mae: 0.0336 - val_loss: 0.0010 - val_mae: 0.0249\n",
      "Epoch 20/50\n",
      "301/301 - 5s - 17ms/step - loss: 0.0021 - mae: 0.0301 - val_loss: 0.0027 - val_mae: 0.0473\n",
      "Epoch 21/50\n",
      "301/301 - 5s - 17ms/step - loss: 0.0021 - mae: 0.0304 - val_loss: 0.0010 - val_mae: 0.0248\n",
      "Epoch 22/50\n",
      "301/301 - 3s - 11ms/step - loss: 0.0023 - mae: 0.0320 - val_loss: 0.0011 - val_mae: 0.0265\n",
      "Epoch 23/50\n",
      "301/301 - 4s - 13ms/step - loss: 0.0023 - mae: 0.0320 - val_loss: 0.0018 - val_mae: 0.0365\n",
      "Epoch 24/50\n",
      "301/301 - 3s - 11ms/step - loss: 0.0022 - mae: 0.0313 - val_loss: 8.8316e-04 - val_mae: 0.0227\n",
      "Epoch 25/50\n",
      "301/301 - 5s - 15ms/step - loss: 0.0022 - mae: 0.0310 - val_loss: 0.0030 - val_mae: 0.0494\n",
      "Epoch 26/50\n",
      "301/301 - 3s - 10ms/step - loss: 0.0022 - mae: 0.0309 - val_loss: 0.0052 - val_mae: 0.0677\n",
      "Epoch 27/50\n",
      "301/301 - 3s - 11ms/step - loss: 0.0022 - mae: 0.0317 - val_loss: 0.0044 - val_mae: 0.0616\n",
      "Epoch 28/50\n",
      "301/301 - 3s - 11ms/step - loss: 0.0023 - mae: 0.0327 - val_loss: 8.0308e-04 - val_mae: 0.0209\n",
      "Epoch 29/50\n",
      "301/301 - 5s - 15ms/step - loss: 0.0021 - mae: 0.0304 - val_loss: 0.0038 - val_mae: 0.0547\n",
      "Epoch 30/50\n",
      "301/301 - 3s - 11ms/step - loss: 0.0022 - mae: 0.0315 - val_loss: 0.0020 - val_mae: 0.0377\n",
      "Epoch 31/50\n",
      "301/301 - 3s - 10ms/step - loss: 0.0021 - mae: 0.0305 - val_loss: 8.4885e-04 - val_mae: 0.0218\n",
      "Epoch 32/50\n",
      "301/301 - 5s - 15ms/step - loss: 0.0022 - mae: 0.0312 - val_loss: 9.5151e-04 - val_mae: 0.0233\n",
      "Epoch 33/50\n",
      "301/301 - 3s - 11ms/step - loss: 0.0022 - mae: 0.0317 - val_loss: 0.0030 - val_mae: 0.0494\n",
      "Epoch 34/50\n",
      "301/301 - 3s - 9ms/step - loss: 0.0023 - mae: 0.0322 - val_loss: 0.0011 - val_mae: 0.0264\n",
      "Epoch 35/50\n",
      "301/301 - 5s - 18ms/step - loss: 0.0020 - mae: 0.0290 - val_loss: 0.0012 - val_mae: 0.0282\n",
      "Epoch 36/50\n",
      "301/301 - 3s - 10ms/step - loss: 0.0022 - mae: 0.0313 - val_loss: 0.0012 - val_mae: 0.0289\n",
      "Epoch 37/50\n",
      "301/301 - 4s - 13ms/step - loss: 0.0021 - mae: 0.0302 - val_loss: 8.0221e-04 - val_mae: 0.0212\n",
      "Epoch 38/50\n",
      "301/301 - 6s - 20ms/step - loss: 0.0022 - mae: 0.0309 - val_loss: 0.0021 - val_mae: 0.0408\n",
      "Epoch 39/50\n",
      "301/301 - 3s - 11ms/step - loss: 0.0021 - mae: 0.0303 - val_loss: 0.0016 - val_mae: 0.0340\n",
      "Epoch 40/50\n",
      "301/301 - 3s - 9ms/step - loss: 0.0021 - mae: 0.0291 - val_loss: 0.0034 - val_mae: 0.0538\n",
      "Epoch 41/50\n",
      "301/301 - 3s - 11ms/step - loss: 0.0021 - mae: 0.0306 - val_loss: 0.0019 - val_mae: 0.0378\n",
      "Epoch 42/50\n",
      "301/301 - 3s - 11ms/step - loss: 0.0020 - mae: 0.0292 - val_loss: 0.0014 - val_mae: 0.0314\n",
      "Epoch 43/50\n",
      "301/301 - 5s - 17ms/step - loss: 0.0022 - mae: 0.0311 - val_loss: 0.0011 - val_mae: 0.0270\n",
      "Epoch 44/50\n",
      "301/301 - 3s - 9ms/step - loss: 0.0022 - mae: 0.0305 - val_loss: 0.0023 - val_mae: 0.0421\n",
      "Epoch 45/50\n",
      "301/301 - 3s - 11ms/step - loss: 0.0021 - mae: 0.0303 - val_loss: 0.0020 - val_mae: 0.0398\n",
      "Epoch 46/50\n",
      "301/301 - 3s - 11ms/step - loss: 0.0020 - mae: 0.0293 - val_loss: 0.0024 - val_mae: 0.0435\n",
      "Epoch 47/50\n",
      "301/301 - 5s - 17ms/step - loss: 0.0021 - mae: 0.0298 - val_loss: 0.0010 - val_mae: 0.0256\n",
      "Epoch 48/50\n",
      "301/301 - 4s - 12ms/step - loss: 0.0021 - mae: 0.0293 - val_loss: 0.0014 - val_mae: 0.0318\n",
      "Epoch 49/50\n",
      "301/301 - 3s - 11ms/step - loss: 0.0021 - mae: 0.0293 - val_loss: 9.9407e-04 - val_mae: 0.0250\n",
      "Epoch 50/50\n",
      "301/301 - 3s - 11ms/step - loss: 0.0021 - mae: 0.0294 - val_loss: 0.0011 - val_mae: 0.0262\n",
      "✅ Done with onion_Raichur_daily.csv | MAE=261.94, RMSE=381.21, R2=0.77, MAPE=26.38%, Accuracy=73.62%\n",
      "\n",
      "🚀 Processing: onion_Shimoga_daily.csv\n",
      "Epoch 1/50\n",
      "565/565 - 15s - 27ms/step - loss: 0.0200 - mae: 0.0798 - val_loss: 0.0035 - val_mae: 0.0374\n",
      "Epoch 2/50\n",
      "565/565 - 10s - 17ms/step - loss: 0.0024 - mae: 0.0365 - val_loss: 0.0031 - val_mae: 0.0396\n",
      "Epoch 3/50\n",
      "565/565 - 8s - 14ms/step - loss: 0.0018 - mae: 0.0304 - val_loss: 0.0036 - val_mae: 0.0369\n",
      "Epoch 4/50\n",
      "565/565 - 9s - 16ms/step - loss: 0.0016 - mae: 0.0281 - val_loss: 0.0034 - val_mae: 0.0454\n",
      "Epoch 5/50\n",
      "565/565 - 11s - 19ms/step - loss: 0.0015 - mae: 0.0278 - val_loss: 0.0027 - val_mae: 0.0339\n",
      "Epoch 6/50\n",
      "565/565 - 12s - 21ms/step - loss: 0.0014 - mae: 0.0260 - val_loss: 0.0032 - val_mae: 0.0347\n",
      "Epoch 7/50\n",
      "565/565 - 12s - 22ms/step - loss: 0.0014 - mae: 0.0257 - val_loss: 0.0028 - val_mae: 0.0347\n",
      "Epoch 8/50\n",
      "565/565 - 12s - 21ms/step - loss: 0.0013 - mae: 0.0244 - val_loss: 0.0030 - val_mae: 0.0411\n",
      "Epoch 9/50\n",
      "565/565 - 12s - 21ms/step - loss: 0.0014 - mae: 0.0254 - val_loss: 0.0034 - val_mae: 0.0372\n",
      "Epoch 10/50\n",
      "565/565 - 12s - 22ms/step - loss: 0.0014 - mae: 0.0261 - val_loss: 0.0026 - val_mae: 0.0338\n",
      "Epoch 11/50\n",
      "565/565 - 13s - 22ms/step - loss: 0.0013 - mae: 0.0244 - val_loss: 0.0025 - val_mae: 0.0333\n",
      "Epoch 12/50\n",
      "565/565 - 12s - 22ms/step - loss: 0.0013 - mae: 0.0244 - val_loss: 0.0026 - val_mae: 0.0329\n",
      "Epoch 13/50\n",
      "565/565 - 12s - 22ms/step - loss: 0.0013 - mae: 0.0246 - val_loss: 0.0026 - val_mae: 0.0357\n",
      "Epoch 14/50\n",
      "565/565 - 12s - 22ms/step - loss: 0.0014 - mae: 0.0254 - val_loss: 0.0029 - val_mae: 0.0338\n",
      "Epoch 15/50\n",
      "565/565 - 12s - 21ms/step - loss: 0.0013 - mae: 0.0237 - val_loss: 0.0026 - val_mae: 0.0326\n",
      "Epoch 16/50\n",
      "565/565 - 12s - 22ms/step - loss: 0.0013 - mae: 0.0237 - val_loss: 0.0026 - val_mae: 0.0351\n",
      "Epoch 17/50\n",
      "565/565 - 12s - 21ms/step - loss: 0.0013 - mae: 0.0241 - val_loss: 0.0035 - val_mae: 0.0390\n",
      "Epoch 18/50\n",
      "565/565 - 12s - 21ms/step - loss: 0.0013 - mae: 0.0238 - val_loss: 0.0026 - val_mae: 0.0322\n",
      "Epoch 19/50\n",
      "565/565 - 13s - 24ms/step - loss: 0.0013 - mae: 0.0239 - val_loss: 0.0024 - val_mae: 0.0317\n",
      "Epoch 20/50\n",
      "565/565 - 12s - 22ms/step - loss: 0.0013 - mae: 0.0240 - val_loss: 0.0025 - val_mae: 0.0328\n",
      "Epoch 21/50\n",
      "565/565 - 13s - 22ms/step - loss: 0.0013 - mae: 0.0238 - val_loss: 0.0028 - val_mae: 0.0336\n",
      "Epoch 22/50\n",
      "565/565 - 13s - 22ms/step - loss: 0.0012 - mae: 0.0237 - val_loss: 0.0026 - val_mae: 0.0324\n",
      "Epoch 23/50\n",
      "565/565 - 12s - 21ms/step - loss: 0.0012 - mae: 0.0233 - val_loss: 0.0025 - val_mae: 0.0319\n",
      "Epoch 24/50\n",
      "565/565 - 12s - 22ms/step - loss: 0.0012 - mae: 0.0234 - val_loss: 0.0024 - val_mae: 0.0326\n",
      "Epoch 25/50\n",
      "565/565 - 12s - 21ms/step - loss: 0.0012 - mae: 0.0232 - val_loss: 0.0025 - val_mae: 0.0325\n",
      "Epoch 26/50\n",
      "565/565 - 12s - 22ms/step - loss: 0.0012 - mae: 0.0233 - val_loss: 0.0032 - val_mae: 0.0357\n",
      "Epoch 27/50\n",
      "565/565 - 12s - 22ms/step - loss: 0.0012 - mae: 0.0230 - val_loss: 0.0027 - val_mae: 0.0332\n",
      "Epoch 28/50\n",
      "565/565 - 12s - 21ms/step - loss: 0.0012 - mae: 0.0228 - val_loss: 0.0026 - val_mae: 0.0341\n",
      "Epoch 29/50\n",
      "565/565 - 13s - 22ms/step - loss: 0.0012 - mae: 0.0229 - val_loss: 0.0030 - val_mae: 0.0344\n",
      "Epoch 30/50\n",
      "565/565 - 12s - 21ms/step - loss: 0.0012 - mae: 0.0227 - val_loss: 0.0024 - val_mae: 0.0313\n",
      "Epoch 31/50\n",
      "565/565 - 12s - 22ms/step - loss: 0.0012 - mae: 0.0228 - val_loss: 0.0032 - val_mae: 0.0360\n",
      "Epoch 32/50\n",
      "565/565 - 12s - 22ms/step - loss: 0.0012 - mae: 0.0224 - val_loss: 0.0033 - val_mae: 0.0367\n",
      "Epoch 33/50\n",
      "565/565 - 14s - 24ms/step - loss: 0.0012 - mae: 0.0229 - val_loss: 0.0026 - val_mae: 0.0343\n",
      "Epoch 34/50\n",
      "565/565 - 13s - 24ms/step - loss: 0.0012 - mae: 0.0224 - val_loss: 0.0033 - val_mae: 0.0370\n",
      "Epoch 35/50\n",
      "565/565 - 12s - 22ms/step - loss: 0.0012 - mae: 0.0225 - val_loss: 0.0025 - val_mae: 0.0320\n",
      "Epoch 36/50\n",
      "565/565 - 12s - 22ms/step - loss: 0.0012 - mae: 0.0225 - val_loss: 0.0025 - val_mae: 0.0325\n",
      "Epoch 37/50\n",
      "565/565 - 12s - 21ms/step - loss: 0.0012 - mae: 0.0224 - val_loss: 0.0027 - val_mae: 0.0331\n",
      "Epoch 38/50\n",
      "565/565 - 12s - 21ms/step - loss: 0.0012 - mae: 0.0225 - val_loss: 0.0031 - val_mae: 0.0354\n",
      "Epoch 39/50\n",
      "565/565 - 12s - 21ms/step - loss: 0.0012 - mae: 0.0225 - val_loss: 0.0026 - val_mae: 0.0325\n",
      "Epoch 40/50\n",
      "565/565 - 12s - 22ms/step - loss: 0.0012 - mae: 0.0224 - val_loss: 0.0029 - val_mae: 0.0336\n",
      "Epoch 41/50\n",
      "565/565 - 12s - 22ms/step - loss: 0.0012 - mae: 0.0221 - val_loss: 0.0036 - val_mae: 0.0385\n",
      "Epoch 42/50\n",
      "565/565 - 12s - 22ms/step - loss: 0.0012 - mae: 0.0224 - val_loss: 0.0025 - val_mae: 0.0318\n",
      "Epoch 43/50\n",
      "565/565 - 12s - 22ms/step - loss: 0.0012 - mae: 0.0226 - val_loss: 0.0025 - val_mae: 0.0322\n",
      "Epoch 44/50\n",
      "565/565 - 12s - 21ms/step - loss: 0.0012 - mae: 0.0223 - val_loss: 0.0025 - val_mae: 0.0320\n",
      "Epoch 45/50\n",
      "565/565 - 12s - 22ms/step - loss: 0.0012 - mae: 0.0221 - val_loss: 0.0024 - val_mae: 0.0308\n",
      "Epoch 46/50\n",
      "565/565 - 12s - 22ms/step - loss: 0.0012 - mae: 0.0223 - val_loss: 0.0025 - val_mae: 0.0321\n",
      "Epoch 47/50\n",
      "565/565 - 12s - 22ms/step - loss: 0.0012 - mae: 0.0224 - val_loss: 0.0027 - val_mae: 0.0332\n",
      "Epoch 48/50\n",
      "565/565 - 12s - 21ms/step - loss: 0.0012 - mae: 0.0223 - val_loss: 0.0024 - val_mae: 0.0317\n",
      "Epoch 49/50\n",
      "565/565 - 12s - 22ms/step - loss: 0.0012 - mae: 0.0222 - val_loss: 0.0024 - val_mae: 0.0316\n",
      "Epoch 50/50\n",
      "565/565 - 12s - 22ms/step - loss: 0.0012 - mae: 0.0221 - val_loss: 0.0024 - val_mae: 0.0318\n",
      "✅ Done with onion_Shimoga_daily.csv | MAE=382.94, RMSE=603.05, R2=0.61, MAPE=46.71%, Accuracy=53.29%\n",
      "\n",
      "🚀 Processing: onion_Tumkur_daily.csv\n",
      "Epoch 1/50\n",
      "687/687 - 25s - 37ms/step - loss: 0.0210 - mae: 0.0851 - val_loss: 0.0608 - val_mae: 0.1981\n",
      "Epoch 2/50\n",
      "687/687 - 20s - 29ms/step - loss: 0.0041 - mae: 0.0498 - val_loss: 0.0564 - val_mae: 0.1968\n",
      "Epoch 3/50\n",
      "687/687 - 15s - 22ms/step - loss: 0.0035 - mae: 0.0466 - val_loss: 0.0647 - val_mae: 0.1998\n",
      "Epoch 4/50\n",
      "687/687 - 15s - 22ms/step - loss: 0.0029 - mae: 0.0421 - val_loss: 0.0540 - val_mae: 0.1969\n",
      "Epoch 5/50\n",
      "687/687 - 21s - 30ms/step - loss: 0.0029 - mae: 0.0415 - val_loss: 0.0615 - val_mae: 0.1987\n",
      "Epoch 6/50\n",
      "687/687 - 15s - 22ms/step - loss: 0.0026 - mae: 0.0397 - val_loss: 0.0594 - val_mae: 0.1981\n",
      "Epoch 7/50\n",
      "687/687 - 15s - 22ms/step - loss: 0.0026 - mae: 0.0396 - val_loss: 0.0572 - val_mae: 0.1976\n",
      "Epoch 8/50\n",
      "687/687 - 15s - 22ms/step - loss: 0.0026 - mae: 0.0392 - val_loss: 0.0566 - val_mae: 0.1975\n",
      "Epoch 9/50\n",
      "687/687 - 16s - 23ms/step - loss: 0.0026 - mae: 0.0394 - val_loss: 0.0566 - val_mae: 0.1976\n",
      "Epoch 10/50\n",
      "687/687 - 20s - 29ms/step - loss: 0.0025 - mae: 0.0389 - val_loss: 0.0537 - val_mae: 0.1974\n",
      "Epoch 11/50\n",
      "687/687 - 16s - 23ms/step - loss: 0.0025 - mae: 0.0387 - val_loss: 0.0525 - val_mae: 0.1976\n",
      "Epoch 12/50\n",
      "687/687 - 15s - 22ms/step - loss: 0.0024 - mae: 0.0376 - val_loss: 0.0470 - val_mae: 0.1980\n",
      "Epoch 13/50\n",
      "687/687 - 15s - 22ms/step - loss: 0.0025 - mae: 0.0381 - val_loss: 0.0495 - val_mae: 0.1974\n",
      "Epoch 14/50\n",
      "687/687 - 16s - 23ms/step - loss: 0.0025 - mae: 0.0382 - val_loss: 0.0503 - val_mae: 0.1975\n",
      "Epoch 15/50\n",
      "687/687 - 15s - 22ms/step - loss: 0.0024 - mae: 0.0379 - val_loss: 0.0485 - val_mae: 0.1980\n",
      "Epoch 16/50\n",
      "687/687 - 15s - 22ms/step - loss: 0.0023 - mae: 0.0368 - val_loss: 0.0477 - val_mae: 0.1980\n",
      "Epoch 17/50\n",
      "687/687 - 15s - 22ms/step - loss: 0.0024 - mae: 0.0372 - val_loss: 0.0513 - val_mae: 0.1978\n",
      "Epoch 18/50\n",
      "687/687 - 15s - 22ms/step - loss: 0.0024 - mae: 0.0374 - val_loss: 0.0500 - val_mae: 0.2007\n",
      "Epoch 19/50\n",
      "687/687 - 15s - 22ms/step - loss: 0.0024 - mae: 0.0373 - val_loss: 0.0475 - val_mae: 0.1979\n",
      "Epoch 20/50\n",
      "687/687 - 16s - 23ms/step - loss: 0.0024 - mae: 0.0372 - val_loss: 0.0465 - val_mae: 0.1986\n",
      "Epoch 21/50\n",
      "687/687 - 15s - 22ms/step - loss: 0.0023 - mae: 0.0368 - val_loss: 0.0494 - val_mae: 0.2005\n",
      "Epoch 22/50\n",
      "687/687 - 15s - 22ms/step - loss: 0.0023 - mae: 0.0368 - val_loss: 0.0469 - val_mae: 0.1982\n",
      "Epoch 23/50\n",
      "687/687 - 21s - 30ms/step - loss: 0.0023 - mae: 0.0368 - val_loss: 0.0490 - val_mae: 0.1976\n",
      "Epoch 24/50\n",
      "687/687 - 15s - 22ms/step - loss: 0.0024 - mae: 0.0371 - val_loss: 0.0463 - val_mae: 0.1989\n",
      "Epoch 25/50\n",
      "687/687 - 16s - 23ms/step - loss: 0.0023 - mae: 0.0367 - val_loss: 0.0713 - val_mae: 0.2114\n",
      "Epoch 26/50\n",
      "687/687 - 15s - 22ms/step - loss: 0.0023 - mae: 0.0371 - val_loss: 0.0499 - val_mae: 0.2008\n",
      "Epoch 27/50\n",
      "687/687 - 15s - 22ms/step - loss: 0.0023 - mae: 0.0369 - val_loss: 0.0488 - val_mae: 0.1977\n",
      "Epoch 28/50\n",
      "687/687 - 15s - 22ms/step - loss: 0.0023 - mae: 0.0367 - val_loss: 0.0465 - val_mae: 0.1991\n",
      "Epoch 29/50\n",
      "687/687 - 15s - 22ms/step - loss: 0.0023 - mae: 0.0369 - val_loss: 0.0466 - val_mae: 0.1992\n",
      "Epoch 30/50\n",
      "687/687 - 15s - 22ms/step - loss: 0.0023 - mae: 0.0366 - val_loss: 0.0474 - val_mae: 0.1998\n",
      "Epoch 31/50\n",
      "687/687 - 15s - 22ms/step - loss: 0.0023 - mae: 0.0369 - val_loss: 0.0468 - val_mae: 0.1984\n",
      "Epoch 32/50\n",
      "687/687 - 15s - 22ms/step - loss: 0.0023 - mae: 0.0366 - val_loss: 0.0464 - val_mae: 0.1989\n",
      "Epoch 33/50\n",
      "687/687 - 16s - 23ms/step - loss: 0.0023 - mae: 0.0368 - val_loss: 0.0487 - val_mae: 0.1978\n",
      "Epoch 34/50\n",
      "687/687 - 15s - 22ms/step - loss: 0.0023 - mae: 0.0368 - val_loss: 0.0477 - val_mae: 0.1979\n",
      "Epoch 35/50\n",
      "687/687 - 15s - 22ms/step - loss: 0.0023 - mae: 0.0364 - val_loss: 0.0480 - val_mae: 0.1979\n",
      "Epoch 36/50\n",
      "687/687 - 15s - 22ms/step - loss: 0.0023 - mae: 0.0366 - val_loss: 0.0471 - val_mae: 0.1992\n",
      "Epoch 37/50\n",
      "687/687 - 15s - 22ms/step - loss: 0.0023 - mae: 0.0365 - val_loss: 0.0474 - val_mae: 0.1982\n",
      "Epoch 38/50\n",
      "687/687 - 15s - 22ms/step - loss: 0.0023 - mae: 0.0364 - val_loss: 0.0480 - val_mae: 0.1980\n",
      "Epoch 39/50\n",
      "687/687 - 15s - 22ms/step - loss: 0.0023 - mae: 0.0364 - val_loss: 0.0491 - val_mae: 0.1980\n",
      "Epoch 40/50\n",
      "687/687 - 15s - 22ms/step - loss: 0.0023 - mae: 0.0365 - val_loss: 0.0542 - val_mae: 0.1974\n",
      "Epoch 41/50\n",
      "687/687 - 15s - 23ms/step - loss: 0.0022 - mae: 0.0362 - val_loss: 0.0483 - val_mae: 0.1991\n",
      "Epoch 42/50\n",
      "687/687 - 15s - 22ms/step - loss: 0.0023 - mae: 0.0365 - val_loss: 0.0485 - val_mae: 0.1983\n",
      "Epoch 43/50\n",
      "687/687 - 21s - 30ms/step - loss: 0.0023 - mae: 0.0364 - val_loss: 0.0486 - val_mae: 0.1980\n",
      "Epoch 44/50\n",
      "687/687 - 15s - 22ms/step - loss: 0.0023 - mae: 0.0361 - val_loss: 0.0491 - val_mae: 0.1995\n",
      "Epoch 45/50\n",
      "687/687 - 15s - 22ms/step - loss: 0.0023 - mae: 0.0363 - val_loss: 0.0487 - val_mae: 0.1982\n",
      "Epoch 46/50\n",
      "687/687 - 15s - 22ms/step - loss: 0.0023 - mae: 0.0361 - val_loss: 0.0486 - val_mae: 0.1988\n",
      "Epoch 47/50\n",
      "687/687 - 15s - 22ms/step - loss: 0.0023 - mae: 0.0361 - val_loss: 0.0489 - val_mae: 0.1983\n",
      "Epoch 48/50\n",
      "687/687 - 15s - 22ms/step - loss: 0.0023 - mae: 0.0362 - val_loss: 0.0487 - val_mae: 0.1986\n",
      "Epoch 49/50\n",
      "687/687 - 15s - 22ms/step - loss: 0.0023 - mae: 0.0361 - val_loss: 0.0513 - val_mae: 0.1976\n",
      "Epoch 50/50\n",
      "687/687 - 16s - 23ms/step - loss: 0.0022 - mae: 0.0360 - val_loss: 0.0490 - val_mae: 0.1986\n",
      "✅ Done with onion_Tumkur_daily.csv | MAE=1116.15, RMSE=1716.72, R2=0.46, MAPE=46.93%, Accuracy=53.07%\n",
      "\n",
      "🚀 Processing: onion_Udupi_daily.csv\n",
      "Epoch 1/50\n",
      "355/355 - 18s - 51ms/step - loss: 0.0598 - mae: 0.1323 - val_loss: 0.0096 - val_mae: 0.0804\n",
      "Epoch 2/50\n",
      "355/355 - 8s - 23ms/step - loss: 0.0104 - mae: 0.0741 - val_loss: 0.0079 - val_mae: 0.0608\n",
      "Epoch 3/50\n",
      "355/355 - 8s - 22ms/step - loss: 0.0059 - mae: 0.0541 - val_loss: 0.0084 - val_mae: 0.0734\n",
      "Epoch 4/50\n",
      "355/355 - 8s - 23ms/step - loss: 0.0048 - mae: 0.0482 - val_loss: 0.0063 - val_mae: 0.0596\n",
      "Epoch 5/50\n",
      "355/355 - 8s - 22ms/step - loss: 0.0045 - mae: 0.0459 - val_loss: 0.0067 - val_mae: 0.0625\n",
      "Epoch 6/50\n",
      "355/355 - 8s - 22ms/step - loss: 0.0037 - mae: 0.0400 - val_loss: 0.0063 - val_mae: 0.0585\n",
      "Epoch 7/50\n",
      "355/355 - 8s - 22ms/step - loss: 0.0035 - mae: 0.0392 - val_loss: 0.0071 - val_mae: 0.0622\n",
      "Epoch 8/50\n",
      "355/355 - 8s - 22ms/step - loss: 0.0033 - mae: 0.0379 - val_loss: 0.0075 - val_mae: 0.0628\n",
      "Epoch 9/50\n",
      "355/355 - 8s - 22ms/step - loss: 0.0032 - mae: 0.0368 - val_loss: 0.0076 - val_mae: 0.0655\n",
      "Epoch 10/50\n",
      "355/355 - 8s - 22ms/step - loss: 0.0033 - mae: 0.0381 - val_loss: 0.0077 - val_mae: 0.0605\n",
      "Epoch 11/50\n",
      "355/355 - 8s - 21ms/step - loss: 0.0030 - mae: 0.0356 - val_loss: 0.0063 - val_mae: 0.0557\n",
      "Epoch 12/50\n",
      "355/355 - 8s - 22ms/step - loss: 0.0030 - mae: 0.0357 - val_loss: 0.0062 - val_mae: 0.0518\n",
      "Epoch 13/50\n",
      "355/355 - 8s - 21ms/step - loss: 0.0028 - mae: 0.0344 - val_loss: 0.0087 - val_mae: 0.0585\n",
      "Epoch 14/50\n",
      "355/355 - 8s - 22ms/step - loss: 0.0029 - mae: 0.0351 - val_loss: 0.0070 - val_mae: 0.0623\n",
      "Epoch 15/50\n",
      "355/355 - 8s - 21ms/step - loss: 0.0027 - mae: 0.0328 - val_loss: 0.0074 - val_mae: 0.0513\n",
      "Epoch 16/50\n",
      "355/355 - 8s - 22ms/step - loss: 0.0028 - mae: 0.0338 - val_loss: 0.0065 - val_mae: 0.0481\n",
      "Epoch 17/50\n",
      "355/355 - 8s - 22ms/step - loss: 0.0026 - mae: 0.0324 - val_loss: 0.0090 - val_mae: 0.0557\n",
      "Epoch 18/50\n",
      "355/355 - 8s - 22ms/step - loss: 0.0029 - mae: 0.0357 - val_loss: 0.0146 - val_mae: 0.0718\n",
      "Epoch 19/50\n",
      "355/355 - 8s - 22ms/step - loss: 0.0026 - mae: 0.0326 - val_loss: 0.0073 - val_mae: 0.0485\n",
      "Epoch 20/50\n",
      "355/355 - 8s - 22ms/step - loss: 0.0027 - mae: 0.0341 - val_loss: 0.0079 - val_mae: 0.0504\n",
      "Epoch 21/50\n",
      "355/355 - 8s - 21ms/step - loss: 0.0027 - mae: 0.0326 - val_loss: 0.0122 - val_mae: 0.0724\n",
      "Epoch 22/50\n",
      "355/355 - 8s - 22ms/step - loss: 0.0026 - mae: 0.0322 - val_loss: 0.0117 - val_mae: 0.0691\n",
      "Epoch 23/50\n",
      "355/355 - 8s - 21ms/step - loss: 0.0025 - mae: 0.0316 - val_loss: 0.0089 - val_mae: 0.0505\n",
      "Epoch 24/50\n",
      "355/355 - 8s - 22ms/step - loss: 0.0026 - mae: 0.0336 - val_loss: 0.0104 - val_mae: 0.0649\n",
      "Epoch 25/50\n",
      "355/355 - 8s - 22ms/step - loss: 0.0026 - mae: 0.0319 - val_loss: 0.0090 - val_mae: 0.0582\n",
      "Epoch 26/50\n",
      "355/355 - 8s - 22ms/step - loss: 0.0027 - mae: 0.0332 - val_loss: 0.0137 - val_mae: 0.0645\n",
      "Epoch 27/50\n",
      "355/355 - 8s - 21ms/step - loss: 0.0026 - mae: 0.0319 - val_loss: 0.0115 - val_mae: 0.0601\n",
      "Epoch 28/50\n",
      "355/355 - 8s - 23ms/step - loss: 0.0025 - mae: 0.0316 - val_loss: 0.0154 - val_mae: 0.0740\n",
      "Epoch 29/50\n",
      "355/355 - 8s - 23ms/step - loss: 0.0025 - mae: 0.0318 - val_loss: 0.0130 - val_mae: 0.0653\n",
      "Epoch 30/50\n",
      "355/355 - 8s - 22ms/step - loss: 0.0025 - mae: 0.0316 - val_loss: 0.0142 - val_mae: 0.0623\n",
      "Epoch 31/50\n",
      "355/355 - 8s - 21ms/step - loss: 0.0024 - mae: 0.0308 - val_loss: 0.0099 - val_mae: 0.0611\n",
      "Epoch 32/50\n",
      "355/355 - 8s - 22ms/step - loss: 0.0023 - mae: 0.0306 - val_loss: 0.0113 - val_mae: 0.0548\n",
      "Epoch 33/50\n",
      "355/355 - 8s - 22ms/step - loss: 0.0026 - mae: 0.0321 - val_loss: 0.0180 - val_mae: 0.0869\n",
      "Epoch 34/50\n",
      "355/355 - 8s - 22ms/step - loss: 0.0026 - mae: 0.0315 - val_loss: 0.0093 - val_mae: 0.0545\n",
      "Epoch 35/50\n",
      "355/355 - 8s - 22ms/step - loss: 0.0024 - mae: 0.0301 - val_loss: 0.0087 - val_mae: 0.0518\n",
      "Epoch 36/50\n",
      "355/355 - 8s - 22ms/step - loss: 0.0025 - mae: 0.0306 - val_loss: 0.0117 - val_mae: 0.0604\n",
      "Epoch 37/50\n",
      "355/355 - 8s - 22ms/step - loss: 0.0024 - mae: 0.0302 - val_loss: 0.0087 - val_mae: 0.0500\n",
      "Epoch 38/50\n",
      "355/355 - 8s - 22ms/step - loss: 0.0024 - mae: 0.0300 - val_loss: 0.0077 - val_mae: 0.0501\n",
      "Epoch 39/50\n",
      "355/355 - 8s - 21ms/step - loss: 0.0026 - mae: 0.0315 - val_loss: 0.0083 - val_mae: 0.0498\n",
      "Epoch 40/50\n",
      "355/355 - 8s - 22ms/step - loss: 0.0024 - mae: 0.0306 - val_loss: 0.0096 - val_mae: 0.0517\n",
      "Epoch 41/50\n",
      "355/355 - 8s - 22ms/step - loss: 0.0023 - mae: 0.0297 - val_loss: 0.0157 - val_mae: 0.0701\n",
      "Epoch 42/50\n",
      "355/355 - 8s - 22ms/step - loss: 0.0024 - mae: 0.0303 - val_loss: 0.0160 - val_mae: 0.0707\n",
      "Epoch 43/50\n",
      "355/355 - 8s - 22ms/step - loss: 0.0025 - mae: 0.0306 - val_loss: 0.0121 - val_mae: 0.0624\n",
      "Epoch 44/50\n",
      "355/355 - 8s - 22ms/step - loss: 0.0025 - mae: 0.0313 - val_loss: 0.0163 - val_mae: 0.0768\n",
      "Epoch 45/50\n",
      "355/355 - 8s - 21ms/step - loss: 0.0024 - mae: 0.0303 - val_loss: 0.0107 - val_mae: 0.0584\n",
      "Epoch 46/50\n",
      "355/355 - 8s - 23ms/step - loss: 0.0024 - mae: 0.0307 - val_loss: 0.0178 - val_mae: 0.0677\n",
      "Epoch 47/50\n",
      "355/355 - 8s - 22ms/step - loss: 0.0024 - mae: 0.0307 - val_loss: 0.0081 - val_mae: 0.0517\n",
      "Epoch 48/50\n",
      "355/355 - 8s - 22ms/step - loss: 0.0024 - mae: 0.0301 - val_loss: 0.0126 - val_mae: 0.0594\n",
      "Epoch 49/50\n",
      "355/355 - 8s - 21ms/step - loss: 0.0024 - mae: 0.0303 - val_loss: 0.0086 - val_mae: 0.0499\n",
      "Epoch 50/50\n",
      "355/355 - 8s - 22ms/step - loss: 0.0024 - mae: 0.0298 - val_loss: 0.0094 - val_mae: 0.0538\n",
      "✅ Done with onion_Udupi_daily.csv | MAE=384.67, RMSE=632.95, R2=0.74, MAPE=22.35%, Accuracy=77.65%\n",
      "\n",
      "📊 Metrics saved to tat_ha_metrics.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import joblib\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "\n",
    "# =========================================================\n",
    "# CLEAN STARTUP – suppress all unnecessary warnings/logs\n",
    "# =========================================================\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # Disable TensorFlow INFO/WARNING logs\n",
    "tf.get_logger().setLevel(\"ERROR\")\n",
    "\n",
    "# =========================================================\n",
    "# Output directories\n",
    "# =========================================================\n",
    "input_folder = \"dataset\"\n",
    "output_models = \"tat_ha_output_models\"\n",
    "output_csv = \"tat_ha_output_csv\"\n",
    "output_graphs = \"tat_ha_output_graphs\"\n",
    "output_logs = \"tat_ha_output_logs\"\n",
    "metrics_file = \"tat_ha_metrics.csv\"\n",
    "\n",
    "os.makedirs(output_models, exist_ok=True)\n",
    "os.makedirs(output_csv, exist_ok=True)\n",
    "os.makedirs(output_graphs, exist_ok=True)\n",
    "os.makedirs(output_logs, exist_ok=True)\n",
    "\n",
    "# =========================================================\n",
    "# Dataset creation\n",
    "# =========================================================\n",
    "def create_dataset(data, look_back=30):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - look_back):\n",
    "        X.append(data[i:i + look_back, 0])\n",
    "        y.append(data[i + look_back, 0])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# =========================================================\n",
    "# Local Attention Layer\n",
    "# =========================================================\n",
    "class LocalAttention(layers.Layer):\n",
    "    def __init__(self, key_dim=64, dropout_rate=0.1, **kwargs):\n",
    "        super(LocalAttention, self).__init__(**kwargs)\n",
    "        self.key_dim = key_dim\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.q_dense = layers.Dense(key_dim)\n",
    "        self.k_dense = layers.Dense(key_dim)\n",
    "        self.v_dense = layers.Dense(key_dim)\n",
    "        self.dropout = layers.Dropout(dropout_rate)\n",
    "\n",
    "    def call(self, x):\n",
    "        Q = self.q_dense(x)\n",
    "        K = self.k_dense(x)\n",
    "        V = self.v_dense(x)\n",
    "        scores = tf.matmul(Q, K, transpose_b=True) / tf.math.sqrt(\n",
    "            tf.cast(tf.shape(K)[-1], tf.float32))\n",
    "        weights = tf.nn.softmax(scores, axis=-1)\n",
    "        output = tf.matmul(weights, V)\n",
    "        return self.dropout(output)\n",
    "\n",
    "# =========================================================\n",
    "# Hierarchical Attention Model\n",
    "# =========================================================\n",
    "def build_tat_ha_model(input_shape, d_model=64, ff_dim=128, dropout_rate=0.2):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    local_attn = LocalAttention(key_dim=d_model, dropout_rate=dropout_rate)(inputs)\n",
    "    local_attn = layers.LayerNormalization(epsilon=1e-6)(local_attn + inputs)\n",
    "\n",
    "    global_attn = layers.MultiHeadAttention(num_heads=4, key_dim=d_model)(local_attn, local_attn)\n",
    "    global_attn = layers.Dropout(dropout_rate)(global_attn)\n",
    "    global_attn = layers.LayerNormalization(epsilon=1e-6)(global_attn + local_attn)\n",
    "\n",
    "    ff = layers.Dense(ff_dim, activation='relu')(global_attn)\n",
    "    ff = layers.Dense(input_shape[1])(ff)\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(ff + global_attn)\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "\n",
    "    outputs = layers.Dense(1)(x)\n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=0.001),\n",
    "                  loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# =========================================================\n",
    "# Metrics list\n",
    "# =========================================================\n",
    "metrics_list = []\n",
    "\n",
    "# =========================================================\n",
    "# Process each CSV file\n",
    "# =========================================================\n",
    "look_back = 30\n",
    "for file in os.listdir(input_folder):\n",
    "    if not file.endswith(\".csv\"):\n",
    "        continue\n",
    "\n",
    "    file_path = os.path.join(input_folder, file)\n",
    "    print(f\"\\n🚀 Processing: {file}\")\n",
    "\n",
    "    # Load CSV\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Safe datetime conversion\n",
    "    df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "    df = df.dropna(subset=['Date']).sort_values('Date')\n",
    "\n",
    "    # Ensure target column exists\n",
    "    if 'Average Price' not in df.columns:\n",
    "        print(f\"⚠️ Skipping {file}: 'Average Price' missing.\")\n",
    "        continue\n",
    "\n",
    "    # Replace inplace warnings (no inplace=True used)\n",
    "    df['Average Price'] = df['Average Price'].fillna(df['Average Price'].mean())\n",
    "    df['MA_7'] = df['Average Price'].rolling(window=7).mean()\n",
    "    df['MA_30'] = df['Average Price'].rolling(window=30).mean()\n",
    "    df['MA_7'] = df['MA_7'].fillna(df['MA_7'].mean())\n",
    "    df['MA_30'] = df['MA_30'].fillna(df['MA_30'].mean())\n",
    "\n",
    "    # Prepare training data\n",
    "    values = df[['Average Price']].values.astype('float32')\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_values = scaler.fit_transform(values)\n",
    "    if len(scaled_values) <= look_back:\n",
    "        print(f\"⚠️ Skipping {file}: not enough data points.\")\n",
    "        continue\n",
    "\n",
    "    X, y = create_dataset(scaled_values, look_back)\n",
    "    X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
    "\n",
    "    # Build and train model (show epochs cleanly)\n",
    "    model = build_tat_ha_model(input_shape=(look_back, 1))\n",
    "    history = model.fit(X, y, epochs=50, batch_size=16, validation_split=0.2, verbose=2)\n",
    "\n",
    "    # Save logs\n",
    "    log_file = os.path.join(output_logs, file.replace(\".csv\", \"_tat_ha_training.txt\"))\n",
    "    with open(log_file, \"w\") as f:\n",
    "        f.write(\"Training Loss per Epoch:\\n\")\n",
    "        for i, loss in enumerate(history.history['loss']):\n",
    "            f.write(f\"Epoch {i + 1}: Loss={loss}, Val_Loss={history.history['val_loss'][i]}\\n\")\n",
    "\n",
    "    # Predictions\n",
    "    predictions = model.predict(X, verbose=0)\n",
    "    predictions_rescaled = scaler.inverse_transform(predictions)\n",
    "    df['Predicted'] = [np.nan] * look_back + list(predictions_rescaled.flatten())\n",
    "\n",
    "    # Round results\n",
    "    df['Average Price'] = df['Average Price'].round(2)\n",
    "    df['Predicted'] = df['Predicted'].round(2)\n",
    "\n",
    "    # Evaluate\n",
    "    y_true = df['Average Price'].values[look_back:]\n",
    "    y_pred = predictions_rescaled.flatten()\n",
    "    valid_idx = ~np.isnan(y_true) & ~np.isnan(y_pred) & (y_true != 0)\n",
    "\n",
    "    if not np.any(valid_idx):\n",
    "        print(f\"⚠️ Skipping metrics for {file}: invalid or zero values.\")\n",
    "        continue\n",
    "\n",
    "    y_true, y_pred = y_true[valid_idx], y_pred[valid_idx]\n",
    "    mae = round(mean_absolute_error(y_true, y_pred), 2)\n",
    "    rmse = round(np.sqrt(mean_squared_error(y_true, y_pred)), 2)\n",
    "    r2 = round(r2_score(y_true, y_pred), 2)\n",
    "    mape = round(np.mean(np.abs((y_true - y_pred) / np.maximum(y_true, 1e-10))) * 100, 2)\n",
    "    accuracy = round(max(0, min(100, 100 - mape)), 2)\n",
    "\n",
    "    metrics_list.append([file.replace(\".csv\", \"\"), mae, rmse, r2, mape, accuracy])\n",
    "\n",
    "    # Save model\n",
    "    model_file = os.path.join(output_models, file.replace(\".csv\", \"_tat_ha_model.pkl\"))\n",
    "    joblib.dump(model, model_file)\n",
    "\n",
    "    # Save updated CSV\n",
    "    save_df = df[['Date', 'Average Price', 'Predicted']].rename(columns={'Average Price': 'Actual'})\n",
    "    updated_csv_path = os.path.join(output_csv, file.replace(\".csv\", \"_tat_ha_updated.csv\"))\n",
    "    save_df.to_csv(updated_csv_path, index=False)\n",
    "\n",
    "    # Plot graph\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(df['Date'], df['Average Price'], label='Actual', color='blue')\n",
    "    plt.plot(df['Date'], df['MA_7'], label='MA 7', color='orange')\n",
    "    plt.plot(df['Date'], df['MA_30'], label='MA 30', color='green')\n",
    "    plt.plot(df['Date'], df['Predicted'], label='Predicted (TAT-HA)', color='red', linestyle='dashed')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Price')\n",
    "    plt.title(f'Price Prediction (TAT-HA) - {file}')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    graph_file = os.path.join(output_graphs, file.replace(\".csv\", \"_tat_ha_graph.png\"))\n",
    "    plt.savefig(graph_file)\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"✅ Done with {file} | MAE={mae}, RMSE={rmse}, R2={r2}, MAPE={mape}%, Accuracy={accuracy}%\")\n",
    "\n",
    "# Save metrics\n",
    "if metrics_list:\n",
    "    metrics_df = pd.DataFrame(metrics_list, columns=['District', 'MAE', 'RMSE', 'R2', 'MAPE(%)', 'Accuracy(%)'])\n",
    "    metrics_df.to_csv(metrics_file, index=False)\n",
    "    print(f\"\\n📊 Metrics saved to {metrics_file}\")\n",
    "else:\n",
    "    print(\"\\n⚠️ No valid data found to save metrics.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3896cf60-11cd-42ee-9847-5e4a39b24ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fe1af4f-4bea-4ef9-b6fe-5a78914961fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== Processing: onion_Bagalkot_daily.csv ==========\n",
      "Epoch 1/20\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0063 - mae: 0.0467 - val_loss: 3.3103e-04 - val_mae: 0.0109\n",
      "Epoch 2/20\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 8.8581e-04 - mae: 0.0193 - val_loss: 3.1775e-04 - val_mae: 0.0099\n",
      "Epoch 3/20\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 9.0507e-04 - mae: 0.0195 - val_loss: 5.8035e-04 - val_mae: 0.0162\n",
      "Epoch 4/20\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 9.4885e-04 - mae: 0.0200 - val_loss: 3.0536e-04 - val_mae: 0.0099\n",
      "Epoch 5/20\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 8.8410e-04 - mae: 0.0193 - val_loss: 3.1434e-04 - val_mae: 0.0106\n",
      "Epoch 6/20\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 8.0755e-04 - mae: 0.0188 - val_loss: 3.1791e-04 - val_mae: 0.0112\n",
      "Epoch 7/20\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 8.1926e-04 - mae: 0.0185 - val_loss: 3.2336e-04 - val_mae: 0.0126\n",
      "Epoch 8/20\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 7.8866e-04 - mae: 0.0188 - val_loss: 2.8355e-04 - val_mae: 0.0100\n",
      "Epoch 9/20\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 8.3442e-04 - mae: 0.0188 - val_loss: 2.8863e-04 - val_mae: 0.0101\n",
      "Epoch 10/20\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 7.4366e-04 - mae: 0.0176 - val_loss: 2.8822e-04 - val_mae: 0.0098\n",
      "Epoch 11/20\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 7.5554e-04 - mae: 0.0176 - val_loss: 5.1114e-04 - val_mae: 0.0154\n",
      "Epoch 12/20\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 8.2029e-04 - mae: 0.0181 - val_loss: 3.1190e-04 - val_mae: 0.0108\n",
      "Epoch 13/20\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 7.3401e-04 - mae: 0.0172 - val_loss: 3.1367e-04 - val_mae: 0.0132\n",
      "Epoch 14/20\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 7.2300e-04 - mae: 0.0168 - val_loss: 2.8970e-04 - val_mae: 0.0098\n",
      "Epoch 15/20\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 7.5085e-04 - mae: 0.0176 - val_loss: 2.7717e-04 - val_mae: 0.0103\n",
      "Epoch 16/20\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 7.0897e-04 - mae: 0.0167 - val_loss: 2.9875e-04 - val_mae: 0.0103\n",
      "Epoch 17/20\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 7.6213e-04 - mae: 0.0173 - val_loss: 3.4905e-04 - val_mae: 0.0136\n",
      "Epoch 18/20\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 7.8392e-04 - mae: 0.0179 - val_loss: 2.7653e-04 - val_mae: 0.0099\n",
      "Epoch 19/20\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 6.7063e-04 - mae: 0.0163 - val_loss: 2.8912e-04 - val_mae: 0.0109\n",
      "Epoch 20/20\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 6.9091e-04 - mae: 0.0170 - val_loss: 3.5899e-04 - val_mae: 0.0122\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
      "✅ Done with onion_Bagalkot_daily.csv | MAE=94.36, RMSE=146.65, R2=0.96, MAPE=6.01%, Accuracy=93.99%\n",
      "\n",
      "========== Processing: onion_Bangalore_daily.csv ==========\n",
      "Epoch 1/20\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 0.0045 - mae: 0.0441 - val_loss: 0.0022 - val_mae: 0.0334\n",
      "Epoch 2/20\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0024 - mae: 0.0326 - val_loss: 0.0021 - val_mae: 0.0324\n",
      "Epoch 3/20\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0024 - mae: 0.0325 - val_loss: 0.0021 - val_mae: 0.0328\n",
      "Epoch 4/20\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0023 - mae: 0.0321 - val_loss: 0.0020 - val_mae: 0.0322\n",
      "Epoch 5/20\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0023 - mae: 0.0322 - val_loss: 0.0019 - val_mae: 0.0316\n",
      "Epoch 6/20\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0024 - mae: 0.0323 - val_loss: 0.0020 - val_mae: 0.0315\n",
      "Epoch 7/20\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0025 - mae: 0.0327 - val_loss: 0.0021 - val_mae: 0.0325\n",
      "Epoch 8/20\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0023 - mae: 0.0319 - val_loss: 0.0020 - val_mae: 0.0324\n",
      "Epoch 9/20\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0025 - mae: 0.0325 - val_loss: 0.0020 - val_mae: 0.0314\n",
      "Epoch 10/20\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0023 - mae: 0.0320 - val_loss: 0.0019 - val_mae: 0.0314\n",
      "Epoch 11/20\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0021 - mae: 0.0311 - val_loss: 0.0019 - val_mae: 0.0314\n",
      "Epoch 12/20\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0023 - mae: 0.0317 - val_loss: 0.0020 - val_mae: 0.0317\n",
      "Epoch 13/20\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0023 - mae: 0.0318 - val_loss: 0.0019 - val_mae: 0.0311\n",
      "Epoch 14/20\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0024 - mae: 0.0320 - val_loss: 0.0020 - val_mae: 0.0323\n",
      "Epoch 15/20\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0023 - mae: 0.0317 - val_loss: 0.0020 - val_mae: 0.0315\n",
      "Epoch 16/20\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0022 - mae: 0.0315 - val_loss: 0.0021 - val_mae: 0.0323\n",
      "Epoch 17/20\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0024 - mae: 0.0320 - val_loss: 0.0019 - val_mae: 0.0308\n",
      "Epoch 18/20\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0023 - mae: 0.0318 - val_loss: 0.0022 - val_mae: 0.0326\n",
      "Epoch 19/20\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0024 - mae: 0.0319 - val_loss: 0.0024 - val_mae: 0.0341\n",
      "Epoch 20/20\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0021 - mae: 0.0310 - val_loss: 0.0020 - val_mae: 0.0310\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "✅ Done with onion_Bangalore_daily.csv | MAE=375.27, RMSE=537.14, R2=0.77, MAPE=17.93%, Accuracy=82.07%\n",
      "\n",
      "========== Processing: onion_Belgaum_daily.csv ==========\n",
      "Epoch 1/20\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 0.0063 - mae: 0.0461 - val_loss: 3.7672e-04 - val_mae: 0.0124\n",
      "Epoch 2/20\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 5.3788e-04 - mae: 0.0133 - val_loss: 3.6004e-04 - val_mae: 0.0119\n",
      "Epoch 3/20\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 6.0274e-04 - mae: 0.0137 - val_loss: 3.3850e-04 - val_mae: 0.0111\n",
      "Epoch 4/20\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 5.9229e-04 - mae: 0.0135 - val_loss: 3.7345e-04 - val_mae: 0.0128\n",
      "Epoch 5/20\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 5.2178e-04 - mae: 0.0135 - val_loss: 3.6895e-04 - val_mae: 0.0123\n",
      "Epoch 6/20\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 5.2804e-04 - mae: 0.0132 - val_loss: 3.2581e-04 - val_mae: 0.0106\n",
      "Epoch 7/20\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 5.3401e-04 - mae: 0.0133 - val_loss: 3.5328e-04 - val_mae: 0.0126\n",
      "Epoch 8/20\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 5.8972e-04 - mae: 0.0140 - val_loss: 3.0347e-04 - val_mae: 0.0103\n",
      "Epoch 9/20\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 5.5040e-04 - mae: 0.0136 - val_loss: 2.9454e-04 - val_mae: 0.0105\n",
      "Epoch 10/20\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 5.2028e-04 - mae: 0.0133 - val_loss: 3.1639e-04 - val_mae: 0.0111\n",
      "Epoch 11/20\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 5.4336e-04 - mae: 0.0136 - val_loss: 3.3061e-04 - val_mae: 0.0116\n",
      "Epoch 12/20\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4.8001e-04 - mae: 0.0132 - val_loss: 2.7660e-04 - val_mae: 0.0099\n",
      "Epoch 13/20\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 4.4442e-04 - mae: 0.0126 - val_loss: 2.9697e-04 - val_mae: 0.0108\n",
      "Epoch 14/20\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 4.9279e-04 - mae: 0.0124 - val_loss: 2.9589e-04 - val_mae: 0.0112\n",
      "Epoch 15/20\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 4.8622e-04 - mae: 0.0124 - val_loss: 2.6245e-04 - val_mae: 0.0094\n",
      "Epoch 16/20\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 4.9335e-04 - mae: 0.0125 - val_loss: 2.5998e-04 - val_mae: 0.0093\n",
      "Epoch 17/20\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 5.0475e-04 - mae: 0.0130 - val_loss: 2.5599e-04 - val_mae: 0.0095\n",
      "Epoch 18/20\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 4.8204e-04 - mae: 0.0123 - val_loss: 3.3664e-04 - val_mae: 0.0132\n",
      "Epoch 19/20\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 4.8231e-04 - mae: 0.0132 - val_loss: 2.7372e-04 - val_mae: 0.0105\n",
      "Epoch 20/20\n",
      "\u001b[1m161/161\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4.9960e-04 - mae: 0.0133 - val_loss: 2.5785e-04 - val_mae: 0.0104\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
      "✅ Done with onion_Belgaum_daily.csv | MAE=118.58, RMSE=183.06, R2=0.94, MAPE=6.55%, Accuracy=93.45%\n",
      "\n",
      "========== Processing: onion_Bellary_daily.csv ==========\n",
      "Epoch 1/20\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 0.0045 - mae: 0.0453 - val_loss: 9.9274e-04 - val_mae: 0.0218\n",
      "Epoch 2/20\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 8.4213e-04 - mae: 0.0149 - val_loss: 8.5351e-04 - val_mae: 0.0200\n",
      "Epoch 3/20\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 7.0470e-04 - mae: 0.0144 - val_loss: 9.1826e-04 - val_mae: 0.0220\n",
      "Epoch 4/20\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6.1468e-04 - mae: 0.0139 - val_loss: 8.5057e-04 - val_mae: 0.0194\n",
      "Epoch 5/20\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5.3974e-04 - mae: 0.0130 - val_loss: 8.5292e-04 - val_mae: 0.0198\n",
      "Epoch 6/20\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 8.2601e-04 - mae: 0.0140 - val_loss: 8.4377e-04 - val_mae: 0.0195\n",
      "Epoch 7/20\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 7.3905e-04 - mae: 0.0134 - val_loss: 8.9240e-04 - val_mae: 0.0209\n",
      "Epoch 8/20\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 7.4063e-04 - mae: 0.0138 - val_loss: 8.4409e-04 - val_mae: 0.0189\n",
      "Epoch 9/20\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0138 - val_loss: 8.4753e-04 - val_mae: 0.0191\n",
      "Epoch 10/20\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5.9733e-04 - mae: 0.0136 - val_loss: 9.1325e-04 - val_mae: 0.0219\n",
      "Epoch 11/20\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 6.7011e-04 - mae: 0.0137 - val_loss: 8.5016e-04 - val_mae: 0.0193\n",
      "Epoch 12/20\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 6.9227e-04 - mae: 0.0139 - val_loss: 8.4476e-04 - val_mae: 0.0192\n",
      "Epoch 13/20\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 7.2574e-04 - mae: 0.0139 - val_loss: 8.4217e-04 - val_mae: 0.0190\n",
      "Epoch 14/20\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5.6749e-04 - mae: 0.0137 - val_loss: 8.5543e-04 - val_mae: 0.0196\n",
      "Epoch 15/20\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 7.8638e-04 - mae: 0.0139 - val_loss: 9.2514e-04 - val_mae: 0.0222\n",
      "Epoch 16/20\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 6.3175e-04 - mae: 0.0140 - val_loss: 9.0216e-04 - val_mae: 0.0214\n",
      "Epoch 17/20\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0011 - mae: 0.0149 - val_loss: 8.4911e-04 - val_mae: 0.0196\n",
      "Epoch 18/20\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 7.7503e-04 - mae: 0.0142 - val_loss: 8.4717e-04 - val_mae: 0.0188\n",
      "Epoch 19/20\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5.5383e-04 - mae: 0.0132 - val_loss: 8.4879e-04 - val_mae: 0.0194\n",
      "Epoch 20/20\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5.9005e-04 - mae: 0.0129 - val_loss: 8.9224e-04 - val_mae: 0.0217\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
      "✅ Done with onion_Bellary_daily.csv | MAE=241.43, RMSE=333.05, R2=0.52, MAPE=15.21%, Accuracy=84.79%\n",
      "\n",
      "========== Processing: onion_Bidar_daily.csv ==========\n",
      "Epoch 1/20\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0117 - mae: 0.0819 - val_loss: 9.7571e-04 - val_mae: 0.0132\n",
      "Epoch 2/20\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0032 - mae: 0.0433 - val_loss: 4.9869e-04 - val_mae: 0.0087\n",
      "Epoch 3/20\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0031 - mae: 0.0417 - val_loss: 5.6435e-04 - val_mae: 0.0096\n",
      "Epoch 4/20\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0029 - mae: 0.0414 - val_loss: 4.1289e-04 - val_mae: 0.0065\n",
      "Epoch 5/20\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0029 - mae: 0.0409 - val_loss: 3.7046e-04 - val_mae: 0.0070\n",
      "Epoch 6/20\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0029 - mae: 0.0406 - val_loss: 5.8272e-04 - val_mae: 0.0132\n",
      "Epoch 7/20\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0029 - mae: 0.0396 - val_loss: 3.3892e-04 - val_mae: 0.0039\n",
      "Epoch 8/20\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0026 - mae: 0.0387 - val_loss: 5.9438e-04 - val_mae: 0.0151\n",
      "Epoch 9/20\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0365 - val_loss: 4.3857e-04 - val_mae: 0.0054\n",
      "Epoch 10/20\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0025 - mae: 0.0360 - val_loss: 4.9629e-04 - val_mae: 0.0093\n",
      "Epoch 11/20\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0026 - mae: 0.0351 - val_loss: 4.5950e-04 - val_mae: 0.0070\n",
      "Epoch 12/20\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0024 - mae: 0.0335 - val_loss: 4.9061e-04 - val_mae: 0.0093\n",
      "Epoch 13/20\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0026 - mae: 0.0345 - val_loss: 4.6754e-04 - val_mae: 0.0043\n",
      "Epoch 14/20\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0022 - mae: 0.0318 - val_loss: 4.6057e-04 - val_mae: 0.0049\n",
      "Epoch 15/20\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0024 - mae: 0.0330 - val_loss: 8.6018e-04 - val_mae: 0.0232\n",
      "Epoch 16/20\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0024 - mae: 0.0324 - val_loss: 5.8772e-04 - val_mae: 0.0084\n",
      "Epoch 17/20\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0026 - mae: 0.0334 - val_loss: 5.6828e-04 - val_mae: 0.0105\n",
      "Epoch 18/20\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0021 - mae: 0.0317 - val_loss: 6.7484e-04 - val_mae: 0.0173\n",
      "Epoch 19/20\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0336 - val_loss: 6.1941e-04 - val_mae: 0.0091\n",
      "Epoch 20/20\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0027 - mae: 0.0328 - val_loss: 4.6460e-04 - val_mae: 0.0056\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
      "✅ Done with onion_Bidar_daily.csv | MAE=22.18, RMSE=85.68, R2=0.95, MAPE=1.28%, Accuracy=98.72%\n",
      "\n",
      "========== Processing: onion_Bijapur_daily.csv ==========\n",
      "Epoch 1/20\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0057 - mae: 0.0573 - val_loss: 5.5513e-04 - val_mae: 0.0168\n",
      "Epoch 2/20\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0023 - mae: 0.0393 - val_loss: 3.1174e-04 - val_mae: 0.0118\n",
      "Epoch 3/20\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0024 - mae: 0.0394 - val_loss: 2.8771e-04 - val_mae: 0.0115\n",
      "Epoch 4/20\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0023 - mae: 0.0390 - val_loss: 4.3855e-04 - val_mae: 0.0168\n",
      "Epoch 5/20\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0023 - mae: 0.0383 - val_loss: 3.4239e-04 - val_mae: 0.0123\n",
      "Epoch 6/20\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0022 - mae: 0.0375 - val_loss: 3.4077e-04 - val_mae: 0.0125\n",
      "Epoch 7/20\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0019 - mae: 0.0355 - val_loss: 5.1766e-04 - val_mae: 0.0166\n",
      "Epoch 8/20\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0019 - mae: 0.0335 - val_loss: 3.8340e-04 - val_mae: 0.0122\n",
      "Epoch 9/20\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0314 - val_loss: 3.7694e-04 - val_mae: 0.0121\n",
      "Epoch 10/20\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 4.0725e-04 - val_mae: 0.0128\n",
      "Epoch 11/20\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0017 - mae: 0.0304 - val_loss: 4.1489e-04 - val_mae: 0.0138\n",
      "Epoch 12/20\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0307 - val_loss: 4.2747e-04 - val_mae: 0.0138\n",
      "Epoch 13/20\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0018 - mae: 0.0297 - val_loss: 5.2911e-04 - val_mae: 0.0168\n",
      "Epoch 14/20\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0017 - mae: 0.0290 - val_loss: 4.4743e-04 - val_mae: 0.0143\n",
      "Epoch 15/20\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0017 - mae: 0.0298 - val_loss: 4.8163e-04 - val_mae: 0.0150\n",
      "Epoch 16/20\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0018 - mae: 0.0302 - val_loss: 4.8760e-04 - val_mae: 0.0151\n",
      "Epoch 17/20\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0018 - mae: 0.0295 - val_loss: 4.3150e-04 - val_mae: 0.0134\n",
      "Epoch 18/20\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0017 - mae: 0.0288 - val_loss: 4.4801e-04 - val_mae: 0.0136\n",
      "Epoch 19/20\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0017 - mae: 0.0287 - val_loss: 4.2645e-04 - val_mae: 0.0136\n",
      "Epoch 20/20\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0017 - mae: 0.0294 - val_loss: 5.1747e-04 - val_mae: 0.0167\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
      "✅ Done with onion_Bijapur_daily.csv | MAE=175.65, RMSE=238.85, R2=0.89, MAPE=16.24%, Accuracy=83.76%\n",
      "\n",
      "========== Processing: onion_Chamrajnagar_daily.csv ==========\n",
      "Epoch 1/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0047 - mae: 0.0364 - val_loss: 0.0018 - val_mae: 0.0334\n",
      "Epoch 2/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0032 - mae: 0.0270 - val_loss: 0.0025 - val_mae: 0.0386\n",
      "Epoch 3/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0029 - mae: 0.0268 - val_loss: 0.0019 - val_mae: 0.0329\n",
      "Epoch 4/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0027 - mae: 0.0250 - val_loss: 0.0016 - val_mae: 0.0313\n",
      "Epoch 5/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0026 - mae: 0.0247 - val_loss: 0.0015 - val_mae: 0.0305\n",
      "Epoch 6/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0024 - mae: 0.0240 - val_loss: 0.0015 - val_mae: 0.0299\n",
      "Epoch 7/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0024 - mae: 0.0240 - val_loss: 0.0015 - val_mae: 0.0303\n",
      "Epoch 8/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0026 - mae: 0.0246 - val_loss: 0.0015 - val_mae: 0.0291\n",
      "Epoch 9/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0023 - mae: 0.0235 - val_loss: 0.0015 - val_mae: 0.0299\n",
      "Epoch 10/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0242 - val_loss: 0.0015 - val_mae: 0.0294\n",
      "Epoch 11/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0238 - val_loss: 0.0016 - val_mae: 0.0299\n",
      "Epoch 12/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0027 - mae: 0.0248 - val_loss: 0.0020 - val_mae: 0.0331\n",
      "Epoch 13/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0026 - mae: 0.0248 - val_loss: 0.0022 - val_mae: 0.0356\n",
      "Epoch 14/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0023 - mae: 0.0238 - val_loss: 0.0019 - val_mae: 0.0322\n",
      "Epoch 15/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0022 - mae: 0.0239 - val_loss: 0.0014 - val_mae: 0.0284\n",
      "Epoch 16/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0243 - val_loss: 0.0015 - val_mae: 0.0294\n",
      "Epoch 17/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0024 - mae: 0.0242 - val_loss: 0.0014 - val_mae: 0.0282\n",
      "Epoch 18/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0025 - mae: 0.0245 - val_loss: 0.0014 - val_mae: 0.0283\n",
      "Epoch 19/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0243 - val_loss: 0.0014 - val_mae: 0.0280\n",
      "Epoch 20/20\n",
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0023 - mae: 0.0238 - val_loss: 0.0017 - val_mae: 0.0304\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "✅ Done with onion_Chamrajnagar_daily.csv | MAE=419.84, RMSE=567.81, R2=0.66, MAPE=15.37%, Accuracy=84.63%\n",
      "\n",
      "========== Processing: onion_Chikmagalur_daily.csv ==========\n",
      "Epoch 1/20\n",
      "\u001b[1m542/542\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0197 - mae: 0.0965 - val_loss: 0.0066 - val_mae: 0.0597\n",
      "Epoch 2/20\n",
      "\u001b[1m542/542\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0140 - mae: 0.0803 - val_loss: 0.0066 - val_mae: 0.0579\n",
      "Epoch 3/20\n",
      "\u001b[1m542/542\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0137 - mae: 0.0786 - val_loss: 0.0062 - val_mae: 0.0580\n",
      "Epoch 4/20\n",
      "\u001b[1m542/542\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0135 - mae: 0.0781 - val_loss: 0.0063 - val_mae: 0.0578\n",
      "Epoch 5/20\n",
      "\u001b[1m542/542\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0139 - mae: 0.0788 - val_loss: 0.0065 - val_mae: 0.0588\n",
      "Epoch 6/20\n",
      "\u001b[1m542/542\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0141 - mae: 0.0798 - val_loss: 0.0062 - val_mae: 0.0588\n",
      "Epoch 7/20\n",
      "\u001b[1m542/542\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0135 - mae: 0.0780 - val_loss: 0.0065 - val_mae: 0.0576\n",
      "Epoch 8/20\n",
      "\u001b[1m542/542\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0134 - mae: 0.0776 - val_loss: 0.0063 - val_mae: 0.0605\n",
      "Epoch 9/20\n",
      "\u001b[1m542/542\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0132 - mae: 0.0775 - val_loss: 0.0063 - val_mae: 0.0590\n",
      "Epoch 10/20\n",
      "\u001b[1m542/542\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0134 - mae: 0.0776 - val_loss: 0.0065 - val_mae: 0.0578\n",
      "Epoch 11/20\n",
      "\u001b[1m542/542\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0130 - mae: 0.0762 - val_loss: 0.0062 - val_mae: 0.0588\n",
      "Epoch 12/20\n",
      "\u001b[1m542/542\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0130 - mae: 0.0762 - val_loss: 0.0064 - val_mae: 0.0610\n",
      "Epoch 13/20\n",
      "\u001b[1m542/542\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0135 - mae: 0.0778 - val_loss: 0.0063 - val_mae: 0.0577\n",
      "Epoch 14/20\n",
      "\u001b[1m542/542\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0138 - mae: 0.0789 - val_loss: 0.0062 - val_mae: 0.0585\n",
      "Epoch 15/20\n",
      "\u001b[1m542/542\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0137 - mae: 0.0789 - val_loss: 0.0063 - val_mae: 0.0600\n",
      "Epoch 16/20\n",
      "\u001b[1m542/542\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0129 - mae: 0.0758 - val_loss: 0.0063 - val_mae: 0.0594\n",
      "Epoch 17/20\n",
      "\u001b[1m542/542\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0129 - mae: 0.0765 - val_loss: 0.0063 - val_mae: 0.0578\n",
      "Epoch 18/20\n",
      "\u001b[1m542/542\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0131 - mae: 0.0771 - val_loss: 0.0063 - val_mae: 0.0599\n",
      "Epoch 19/20\n",
      "\u001b[1m542/542\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0132 - mae: 0.0767 - val_loss: 0.0073 - val_mae: 0.0602\n",
      "Epoch 20/20\n",
      "\u001b[1m542/542\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0133 - mae: 0.0771 - val_loss: 0.0066 - val_mae: 0.0583\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "✅ Done with onion_Chikmagalur_daily.csv | MAE=406.03, RMSE=567.52, R2=0.5, MAPE=19.89%, Accuracy=80.11%\n",
      "\n",
      "========== Processing: onion_Chitradurga_daily.csv ==========\n",
      "Epoch 1/20\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0876 - mae: 0.2252 - val_loss: 0.0023 - val_mae: 0.0398\n",
      "Epoch 2/20\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0494 - mae: 0.1725 - val_loss: 0.0019 - val_mae: 0.0361\n",
      "Epoch 3/20\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0453 - mae: 0.1630 - val_loss: 8.2985e-04 - val_mae: 0.0247\n",
      "Epoch 4/20\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0388 - mae: 0.1439 - val_loss: 6.7345e-04 - val_mae: 0.0211\n",
      "Epoch 5/20\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0384 - mae: 0.1411 - val_loss: 0.0025 - val_mae: 0.0423\n",
      "Epoch 6/20\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0369 - mae: 0.1363 - val_loss: 0.0016 - val_mae: 0.0325\n",
      "Epoch 7/20\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0365 - mae: 0.1335 - val_loss: 6.0187e-04 - val_mae: 0.0205\n",
      "Epoch 8/20\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0351 - mae: 0.1281 - val_loss: 9.9047e-04 - val_mae: 0.0255\n",
      "Epoch 9/20\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0333 - mae: 0.1255 - val_loss: 0.0022 - val_mae: 0.0385\n",
      "Epoch 10/20\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0339 - mae: 0.1245 - val_loss: 0.0018 - val_mae: 0.0328\n",
      "Epoch 11/20\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0319 - mae: 0.1198 - val_loss: 0.0018 - val_mae: 0.0323\n",
      "Epoch 12/20\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0343 - mae: 0.1221 - val_loss: 6.8148e-04 - val_mae: 0.0195\n",
      "Epoch 13/20\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0335 - mae: 0.1200 - val_loss: 6.4456e-04 - val_mae: 0.0206\n",
      "Epoch 14/20\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0314 - mae: 0.1162 - val_loss: 5.4349e-04 - val_mae: 0.0186\n",
      "Epoch 15/20\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0311 - mae: 0.1146 - val_loss: 6.5195e-04 - val_mae: 0.0178\n",
      "Epoch 16/20\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0273 - mae: 0.1043 - val_loss: 4.4469e-04 - val_mae: 0.0155\n",
      "Epoch 17/20\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0281 - mae: 0.1061 - val_loss: 2.9212e-04 - val_mae: 0.0149\n",
      "Epoch 18/20\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0289 - mae: 0.1078 - val_loss: 7.7643e-04 - val_mae: 0.0266\n",
      "Epoch 19/20\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0279 - mae: 0.1069 - val_loss: 0.0013 - val_mae: 0.0346\n",
      "Epoch 20/20\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0265 - mae: 0.1011 - val_loss: 8.7515e-04 - val_mae: 0.0286\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
      "✅ Done with onion_Chitradurga_daily.csv | MAE=96.24, RMSE=99.68, R2=0.9, MAPE=5.46%, Accuracy=94.54%\n",
      "\n",
      "========== Processing: onion_Davangere_daily.csv ==========\n",
      "Epoch 1/20\n",
      "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0257 - val_loss: 0.0013 - val_mae: 0.0136\n",
      "Epoch 2/20\n",
      "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 8.3109e-04 - mae: 0.0201 - val_loss: 0.0014 - val_mae: 0.0146\n",
      "Epoch 3/20\n",
      "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 9.0626e-04 - mae: 0.0201 - val_loss: 0.0016 - val_mae: 0.0174\n",
      "Epoch 4/20\n",
      "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 8.4510e-04 - mae: 0.0198 - val_loss: 0.0016 - val_mae: 0.0167\n",
      "Epoch 5/20\n",
      "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 9.2193e-04 - mae: 0.0197 - val_loss: 0.0016 - val_mae: 0.0160\n",
      "Epoch 6/20\n",
      "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 9.1762e-04 - mae: 0.0192 - val_loss: 0.0016 - val_mae: 0.0146\n",
      "Epoch 7/20\n",
      "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 7.8380e-04 - mae: 0.0185 - val_loss: 0.0017 - val_mae: 0.0152\n",
      "Epoch 8/20\n",
      "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 7.4421e-04 - mae: 0.0184 - val_loss: 0.0018 - val_mae: 0.0159\n",
      "Epoch 9/20\n",
      "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 7.5409e-04 - mae: 0.0181 - val_loss: 0.0030 - val_mae: 0.0222\n",
      "Epoch 10/20\n",
      "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 7.2613e-04 - mae: 0.0178 - val_loss: 0.0022 - val_mae: 0.0199\n",
      "Epoch 11/20\n",
      "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 7.2618e-04 - mae: 0.0181 - val_loss: 0.0027 - val_mae: 0.0205\n",
      "Epoch 12/20\n",
      "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 6.8435e-04 - mae: 0.0177 - val_loss: 0.0024 - val_mae: 0.0194\n",
      "Epoch 13/20\n",
      "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 6.8020e-04 - mae: 0.0175 - val_loss: 0.0033 - val_mae: 0.0265\n",
      "Epoch 14/20\n",
      "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 8.6648e-04 - mae: 0.0190 - val_loss: 0.0038 - val_mae: 0.0218\n",
      "Epoch 15/20\n",
      "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 7.8450e-04 - mae: 0.0183 - val_loss: 0.0047 - val_mae: 0.0242\n",
      "Epoch 16/20\n",
      "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 7.5448e-04 - mae: 0.0179 - val_loss: 0.0037 - val_mae: 0.0261\n",
      "Epoch 17/20\n",
      "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 7.4766e-04 - mae: 0.0180 - val_loss: 0.0032 - val_mae: 0.0187\n",
      "Epoch 18/20\n",
      "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 7.0175e-04 - mae: 0.0176 - val_loss: 0.0040 - val_mae: 0.0264\n",
      "Epoch 19/20\n",
      "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 8.9669e-04 - mae: 0.0186 - val_loss: 0.0063 - val_mae: 0.0251\n",
      "Epoch 20/20\n",
      "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 8.2143e-04 - mae: 0.0182 - val_loss: 0.0045 - val_mae: 0.0219\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 108ms/step\n",
      "✅ Done with onion_Davangere_daily.csv | MAE=279.49, RMSE=857.44, R2=0.13, MAPE=12.69%, Accuracy=87.31%\n",
      "\n",
      "========== Processing: onion_Dharwad_daily.csv ==========\n",
      "Epoch 1/20\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - loss: 0.0097 - mae: 0.0596 - val_loss: 9.4143e-04 - val_mae: 0.0209\n",
      "Epoch 2/20\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 6.1798e-04 - mae: 0.0149 - val_loss: 7.1680e-04 - val_mae: 0.0161\n",
      "Epoch 3/20\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 5.8975e-04 - mae: 0.0142 - val_loss: 8.2980e-04 - val_mae: 0.0186\n",
      "Epoch 4/20\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 6.4304e-04 - mae: 0.0146 - val_loss: 6.9304e-04 - val_mae: 0.0157\n",
      "Epoch 5/20\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 5.3813e-04 - mae: 0.0137 - val_loss: 6.5483e-04 - val_mae: 0.0153\n",
      "Epoch 6/20\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 5.4604e-04 - mae: 0.0137 - val_loss: 6.2844e-04 - val_mae: 0.0151\n",
      "Epoch 7/20\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 4.9884e-04 - mae: 0.0135 - val_loss: 6.2745e-04 - val_mae: 0.0149\n",
      "Epoch 8/20\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 5.1227e-04 - mae: 0.0135 - val_loss: 6.6279e-04 - val_mae: 0.0166\n",
      "Epoch 9/20\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 5.1875e-04 - mae: 0.0132 - val_loss: 6.9449e-04 - val_mae: 0.0177\n",
      "Epoch 10/20\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 5.1057e-04 - mae: 0.0135 - val_loss: 5.8064e-04 - val_mae: 0.0144\n",
      "Epoch 11/20\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 6.0161e-04 - mae: 0.0145 - val_loss: 6.1352e-04 - val_mae: 0.0147\n",
      "Epoch 12/20\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 4.7739e-04 - mae: 0.0127 - val_loss: 5.7246e-04 - val_mae: 0.0149\n",
      "Epoch 13/20\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 4.6408e-04 - mae: 0.0131 - val_loss: 5.8085e-04 - val_mae: 0.0146\n",
      "Epoch 14/20\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 4.4108e-04 - mae: 0.0126 - val_loss: 5.5183e-04 - val_mae: 0.0138\n",
      "Epoch 15/20\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 5.1584e-04 - mae: 0.0132 - val_loss: 5.6962e-04 - val_mae: 0.0140\n",
      "Epoch 16/20\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 5.0966e-04 - mae: 0.0131 - val_loss: 5.7472e-04 - val_mae: 0.0156\n",
      "Epoch 17/20\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 5.5128e-04 - mae: 0.0136 - val_loss: 5.6052e-04 - val_mae: 0.0140\n",
      "Epoch 18/20\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 4.7488e-04 - mae: 0.0121 - val_loss: 5.5165e-04 - val_mae: 0.0139\n",
      "Epoch 19/20\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 4.7278e-04 - mae: 0.0127 - val_loss: 5.4524e-04 - val_mae: 0.0146\n",
      "Epoch 20/20\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 4.4317e-04 - mae: 0.0126 - val_loss: 5.3876e-04 - val_mae: 0.0138\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step\n",
      "✅ Done with onion_Dharwad_daily.csv | MAE=102.83, RMSE=172.69, R2=0.94, MAPE=6.92%, Accuracy=93.08%\n",
      "\n",
      "========== Processing: onion_Gadag_daily.csv ==========\n",
      "Epoch 1/20\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - loss: 0.0296 - mae: 0.1141 - val_loss: 4.4238e-04 - val_mae: 0.0077\n",
      "Epoch 2/20\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 9.6025e-04 - mae: 0.0141 - val_loss: 4.1623e-04 - val_mae: 0.0079\n",
      "Epoch 3/20\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 7.6805e-04 - mae: 0.0145 - val_loss: 5.1464e-04 - val_mae: 0.0119\n",
      "Epoch 4/20\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 7.8225e-04 - mae: 0.0136 - val_loss: 4.3223e-04 - val_mae: 0.0123\n",
      "Epoch 5/20\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 8.2184e-04 - mae: 0.0156 - val_loss: 3.9075e-04 - val_mae: 0.0102\n",
      "Epoch 6/20\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 7.6415e-04 - mae: 0.0135 - val_loss: 4.0529e-04 - val_mae: 0.0117\n",
      "Epoch 7/20\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 7.6181e-04 - mae: 0.0135 - val_loss: 3.2177e-04 - val_mae: 0.0070\n",
      "Epoch 8/20\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 6.1437e-04 - mae: 0.0120 - val_loss: 3.8822e-04 - val_mae: 0.0108\n",
      "Epoch 9/20\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 6.8651e-04 - mae: 0.0126 - val_loss: 3.3331e-04 - val_mae: 0.0084\n",
      "Epoch 10/20\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 6.7794e-04 - mae: 0.0126 - val_loss: 2.9234e-04 - val_mae: 0.0071\n",
      "Epoch 11/20\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 6.4969e-04 - mae: 0.0113 - val_loss: 2.7382e-04 - val_mae: 0.0078\n",
      "Epoch 12/20\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 6.8633e-04 - mae: 0.0116 - val_loss: 2.4598e-04 - val_mae: 0.0054\n",
      "Epoch 13/20\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 6.5124e-04 - mae: 0.0114 - val_loss: 2.7645e-04 - val_mae: 0.0076\n",
      "Epoch 14/20\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 5.1205e-04 - mae: 0.0106 - val_loss: 3.5813e-04 - val_mae: 0.0136\n",
      "Epoch 15/20\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 7.7537e-04 - mae: 0.0168 - val_loss: 2.4799e-04 - val_mae: 0.0067\n",
      "Epoch 16/20\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 7.2346e-04 - mae: 0.0115 - val_loss: 2.9319e-04 - val_mae: 0.0106\n",
      "Epoch 17/20\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 4.6776e-04 - mae: 0.0103 - val_loss: 2.4429e-04 - val_mae: 0.0078\n",
      "Epoch 18/20\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 5.3583e-04 - mae: 0.0105 - val_loss: 2.6095e-04 - val_mae: 0.0098\n",
      "Epoch 19/20\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 5.1600e-04 - mae: 0.0106 - val_loss: 2.2710e-04 - val_mae: 0.0072\n",
      "Epoch 20/20\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 6.7900e-04 - mae: 0.0115 - val_loss: 2.5068e-04 - val_mae: 0.0092\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step\n",
      "✅ Done with onion_Gadag_daily.csv | MAE=31.17, RMSE=53.44, R2=0.99, MAPE=2.07%, Accuracy=97.93%\n",
      "\n",
      "========== Processing: onion_Hassan_daily.csv ==========\n",
      "Epoch 1/20\n",
      "\u001b[1m579/579\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - loss: 0.0076 - mae: 0.0599 - val_loss: 0.0061 - val_mae: 0.0505\n",
      "Epoch 2/20\n",
      "\u001b[1m579/579\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 14ms/step - loss: 0.0048 - mae: 0.0477 - val_loss: 0.0059 - val_mae: 0.0503\n",
      "Epoch 3/20\n",
      "\u001b[1m579/579\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 14ms/step - loss: 0.0049 - mae: 0.0483 - val_loss: 0.0059 - val_mae: 0.0497\n",
      "Epoch 4/20\n",
      "\u001b[1m579/579\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 14ms/step - loss: 0.0048 - mae: 0.0471 - val_loss: 0.0058 - val_mae: 0.0504\n",
      "Epoch 5/20\n",
      "\u001b[1m579/579\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 14ms/step - loss: 0.0048 - mae: 0.0476 - val_loss: 0.0059 - val_mae: 0.0505\n",
      "Epoch 6/20\n",
      "\u001b[1m579/579\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 14ms/step - loss: 0.0050 - mae: 0.0481 - val_loss: 0.0060 - val_mae: 0.0518\n",
      "Epoch 7/20\n",
      "\u001b[1m579/579\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - loss: 0.0048 - mae: 0.0477 - val_loss: 0.0059 - val_mae: 0.0504\n",
      "Epoch 8/20\n",
      "\u001b[1m579/579\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - loss: 0.0048 - mae: 0.0475 - val_loss: 0.0063 - val_mae: 0.0533\n",
      "Epoch 9/20\n",
      "\u001b[1m579/579\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - loss: 0.0051 - mae: 0.0480 - val_loss: 0.0059 - val_mae: 0.0511\n",
      "Epoch 10/20\n",
      "\u001b[1m579/579\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - loss: 0.0048 - mae: 0.0477 - val_loss: 0.0058 - val_mae: 0.0495\n",
      "Epoch 11/20\n",
      "\u001b[1m579/579\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - loss: 0.0050 - mae: 0.0480 - val_loss: 0.0058 - val_mae: 0.0496\n",
      "Epoch 12/20\n",
      "\u001b[1m579/579\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 14ms/step - loss: 0.0047 - mae: 0.0475 - val_loss: 0.0060 - val_mae: 0.0516\n",
      "Epoch 13/20\n",
      "\u001b[1m579/579\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 14ms/step - loss: 0.0048 - mae: 0.0471 - val_loss: 0.0058 - val_mae: 0.0498\n",
      "Epoch 14/20\n",
      "\u001b[1m579/579\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 14ms/step - loss: 0.0048 - mae: 0.0475 - val_loss: 0.0059 - val_mae: 0.0505\n",
      "Epoch 15/20\n",
      "\u001b[1m579/579\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - loss: 0.0050 - mae: 0.0477 - val_loss: 0.0058 - val_mae: 0.0506\n",
      "Epoch 16/20\n",
      "\u001b[1m579/579\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 14ms/step - loss: 0.0047 - mae: 0.0473 - val_loss: 0.0060 - val_mae: 0.0521\n",
      "Epoch 17/20\n",
      "\u001b[1m579/579\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 14ms/step - loss: 0.0046 - mae: 0.0473 - val_loss: 0.0059 - val_mae: 0.0507\n",
      "Epoch 18/20\n",
      "\u001b[1m579/579\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 14ms/step - loss: 0.0048 - mae: 0.0475 - val_loss: 0.0059 - val_mae: 0.0498\n",
      "Epoch 19/20\n",
      "\u001b[1m579/579\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 14ms/step - loss: 0.0046 - mae: 0.0470 - val_loss: 0.0060 - val_mae: 0.0510\n",
      "Epoch 20/20\n",
      "\u001b[1m579/579\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - loss: 0.0048 - mae: 0.0477 - val_loss: 0.0060 - val_mae: 0.0503\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step\n",
      "✅ Done with onion_Hassan_daily.csv | MAE=503.12, RMSE=775.24, R2=0.19, MAPE=29.71%, Accuracy=70.29%\n",
      "\n",
      "========== Processing: onion_Haveri_daily.csv ==========\n",
      "Epoch 1/20\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - loss: 0.0182 - mae: 0.0948 - val_loss: 0.0020 - val_mae: 0.0340\n",
      "Epoch 2/20\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0066 - mae: 0.0606 - val_loss: 0.0018 - val_mae: 0.0320\n",
      "Epoch 3/20\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0061 - mae: 0.0583 - val_loss: 0.0017 - val_mae: 0.0309\n",
      "Epoch 4/20\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 0.0060 - mae: 0.0566 - val_loss: 0.0016 - val_mae: 0.0293\n",
      "Epoch 5/20\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0053 - mae: 0.0521 - val_loss: 0.0016 - val_mae: 0.0277\n",
      "Epoch 6/20\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0049 - mae: 0.0463 - val_loss: 0.0016 - val_mae: 0.0266\n",
      "Epoch 7/20\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0046 - mae: 0.0456 - val_loss: 0.0032 - val_mae: 0.0471\n",
      "Epoch 8/20\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0046 - mae: 0.0457 - val_loss: 0.0017 - val_mae: 0.0285\n",
      "Epoch 9/20\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0044 - mae: 0.0438 - val_loss: 0.0015 - val_mae: 0.0257\n",
      "Epoch 10/20\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0047 - mae: 0.0441 - val_loss: 0.0022 - val_mae: 0.0355\n",
      "Epoch 11/20\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0047 - mae: 0.0453 - val_loss: 0.0015 - val_mae: 0.0254\n",
      "Epoch 12/20\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0045 - mae: 0.0433 - val_loss: 0.0015 - val_mae: 0.0252\n",
      "Epoch 13/20\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0049 - mae: 0.0444 - val_loss: 0.0015 - val_mae: 0.0255\n",
      "Epoch 14/20\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0047 - mae: 0.0446 - val_loss: 0.0016 - val_mae: 0.0263\n",
      "Epoch 15/20\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0047 - mae: 0.0437 - val_loss: 0.0017 - val_mae: 0.0282\n",
      "Epoch 16/20\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0045 - mae: 0.0429 - val_loss: 0.0015 - val_mae: 0.0252\n",
      "Epoch 17/20\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0044 - mae: 0.0431 - val_loss: 0.0019 - val_mae: 0.0314\n",
      "Epoch 18/20\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0047 - mae: 0.0442 - val_loss: 0.0016 - val_mae: 0.0266\n",
      "Epoch 19/20\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0045 - mae: 0.0425 - val_loss: 0.0015 - val_mae: 0.0251\n",
      "Epoch 20/20\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0045 - mae: 0.0431 - val_loss: 0.0017 - val_mae: 0.0279\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
      "✅ Done with onion_Haveri_daily.csv | MAE=167.55, RMSE=246.18, R2=0.56, MAPE=10.28%, Accuracy=89.72%\n",
      "\n",
      "========== Processing: onion_Kolar_daily.csv ==========\n",
      "Epoch 1/20\n",
      "\u001b[1m972/972\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 12ms/step - loss: 0.0017 - mae: 0.0272 - val_loss: 7.8178e-04 - val_mae: 0.0192\n",
      "Epoch 2/20\n",
      "\u001b[1m972/972\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0245 - val_loss: 8.1716e-04 - val_mae: 0.0195\n",
      "Epoch 3/20\n",
      "\u001b[1m972/972\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0246 - val_loss: 9.5515e-04 - val_mae: 0.0215\n",
      "Epoch 4/20\n",
      "\u001b[1m972/972\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - loss: 0.0013 - mae: 0.0247 - val_loss: 7.5309e-04 - val_mae: 0.0184\n",
      "Epoch 5/20\n",
      "\u001b[1m972/972\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0245 - val_loss: 7.3875e-04 - val_mae: 0.0183\n",
      "Epoch 6/20\n",
      "\u001b[1m972/972\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - loss: 0.0014 - mae: 0.0245 - val_loss: 7.6701e-04 - val_mae: 0.0186\n",
      "Epoch 7/20\n",
      "\u001b[1m972/972\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - loss: 0.0013 - mae: 0.0243 - val_loss: 7.9657e-04 - val_mae: 0.0191\n",
      "Epoch 8/20\n",
      "\u001b[1m972/972\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - loss: 0.0013 - mae: 0.0245 - val_loss: 8.2415e-04 - val_mae: 0.0194\n",
      "Epoch 9/20\n",
      "\u001b[1m972/972\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0246 - val_loss: 7.7088e-04 - val_mae: 0.0187\n",
      "Epoch 10/20\n",
      "\u001b[1m972/972\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - loss: 0.0014 - mae: 0.0246 - val_loss: 0.0011 - val_mae: 0.0239\n",
      "Epoch 11/20\n",
      "\u001b[1m972/972\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0244 - val_loss: 7.9045e-04 - val_mae: 0.0190\n",
      "Epoch 12/20\n",
      "\u001b[1m972/972\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - loss: 0.0013 - mae: 0.0247 - val_loss: 8.6184e-04 - val_mae: 0.0202\n",
      "Epoch 13/20\n",
      "\u001b[1m972/972\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - loss: 0.0014 - mae: 0.0245 - val_loss: 8.9778e-04 - val_mae: 0.0209\n",
      "Epoch 14/20\n",
      "\u001b[1m972/972\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - loss: 0.0014 - mae: 0.0248 - val_loss: 9.1689e-04 - val_mae: 0.0209\n",
      "Epoch 15/20\n",
      "\u001b[1m972/972\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - loss: 0.0014 - mae: 0.0246 - val_loss: 8.0246e-04 - val_mae: 0.0192\n",
      "Epoch 16/20\n",
      "\u001b[1m972/972\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - loss: 0.0014 - mae: 0.0245 - val_loss: 7.9473e-04 - val_mae: 0.0190\n",
      "Epoch 17/20\n",
      "\u001b[1m972/972\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - loss: 0.0013 - mae: 0.0243 - val_loss: 8.6862e-04 - val_mae: 0.0203\n",
      "Epoch 18/20\n",
      "\u001b[1m972/972\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0242 - val_loss: 9.5956e-04 - val_mae: 0.0215\n",
      "Epoch 19/20\n",
      "\u001b[1m972/972\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - loss: 0.0013 - mae: 0.0242 - val_loss: 8.2171e-04 - val_mae: 0.0197\n",
      "Epoch 20/20\n",
      "\u001b[1m972/972\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0241 - val_loss: 8.0024e-04 - val_mae: 0.0192\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step\n",
      "✅ Done with onion_Kolar_daily.csv | MAE=439.51, RMSE=647.52, R2=0.53, MAPE=19.13%, Accuracy=80.87%\n",
      "\n",
      "========== Processing: onion_MadikeriKodagu_daily.csv ==========\n",
      "Epoch 1/20\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1288 - mae: 0.2786 - val_loss: 0.0011 - val_mae: 0.0331\n",
      "Epoch 2/20\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0032 - mae: 0.0291 - val_loss: 3.8667e-06 - val_mae: 0.0018\n",
      "Epoch 3/20\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0028 - mae: 0.0231 - val_loss: 4.0220e-06 - val_mae: 0.0019\n",
      "Epoch 4/20\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0029 - mae: 0.0239 - val_loss: 4.6040e-06 - val_mae: 0.0017\n",
      "Epoch 5/20\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0028 - mae: 0.0237 - val_loss: 8.8490e-06 - val_mae: 0.0021\n",
      "Epoch 6/20\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0024 - mae: 0.0213 - val_loss: 2.6280e-05 - val_mae: 0.0044\n",
      "Epoch 7/20\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0027 - mae: 0.0236 - val_loss: 1.2656e-05 - val_mae: 0.0032\n",
      "Epoch 8/20\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0024 - mae: 0.0215 - val_loss: 8.8311e-05 - val_mae: 0.0093\n",
      "Epoch 9/20\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0022 - mae: 0.0203 - val_loss: 1.3025e-05 - val_mae: 0.0032\n",
      "Epoch 10/20\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0025 - mae: 0.0219 - val_loss: 3.0285e-04 - val_mae: 0.0171\n",
      "Epoch 11/20\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0021 - mae: 0.0206 - val_loss: 1.2787e-05 - val_mae: 0.0029\n",
      "Epoch 12/20\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0020 - mae: 0.0191 - val_loss: 3.0574e-05 - val_mae: 0.0051\n",
      "Epoch 13/20\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0021 - mae: 0.0194 - val_loss: 9.6613e-05 - val_mae: 0.0098\n",
      "Epoch 14/20\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0021 - mae: 0.0204 - val_loss: 4.5538e-05 - val_mae: 0.0066\n",
      "Epoch 15/20\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0023 - mae: 0.0214 - val_loss: 2.1932e-05 - val_mae: 0.0042\n",
      "Epoch 16/20\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0023 - mae: 0.0192 - val_loss: 5.8821e-05 - val_mae: 0.0070\n",
      "Epoch 17/20\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0021 - mae: 0.0201 - val_loss: 4.3218e-05 - val_mae: 0.0057\n",
      "Epoch 18/20\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0019 - mae: 0.0167 - val_loss: 7.8005e-05 - val_mae: 0.0087\n",
      "Epoch 19/20\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0020 - mae: 0.0183 - val_loss: 4.5692e-06 - val_mae: 0.0017\n",
      "Epoch 20/20\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0023 - mae: 0.0189 - val_loss: 6.5793e-06 - val_mae: 0.0022\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step\n",
      "✅ Done with onion_MadikeriKodagu_daily.csv | MAE=5.51, RMSE=6.39, R2=1.0, MAPE=0.27%, Accuracy=99.73%\n",
      "\n",
      "========== Processing: onion_Mandya_daily.csv ==========\n",
      "Epoch 1/20\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 0.0050 - mae: 0.0585 - val_loss: 0.0037 - val_mae: 0.0531\n",
      "Epoch 2/20\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0038 - mae: 0.0517 - val_loss: 0.0036 - val_mae: 0.0522\n",
      "Epoch 3/20\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0036 - mae: 0.0492 - val_loss: 0.0031 - val_mae: 0.0473\n",
      "Epoch 4/20\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0036 - mae: 0.0488 - val_loss: 0.0032 - val_mae: 0.0482\n",
      "Epoch 5/20\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0034 - mae: 0.0482 - val_loss: 0.0033 - val_mae: 0.0489\n",
      "Epoch 6/20\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0035 - mae: 0.0478 - val_loss: 0.0040 - val_mae: 0.0537\n",
      "Epoch 7/20\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0034 - mae: 0.0477 - val_loss: 0.0037 - val_mae: 0.0521\n",
      "Epoch 8/20\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0035 - mae: 0.0474 - val_loss: 0.0037 - val_mae: 0.0520\n",
      "Epoch 9/20\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0034 - mae: 0.0477 - val_loss: 0.0034 - val_mae: 0.0503\n",
      "Epoch 10/20\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0033 - mae: 0.0463 - val_loss: 0.0039 - val_mae: 0.0538\n",
      "Epoch 11/20\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0034 - mae: 0.0467 - val_loss: 0.0036 - val_mae: 0.0524\n",
      "Epoch 12/20\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0033 - mae: 0.0467 - val_loss: 0.0034 - val_mae: 0.0501\n",
      "Epoch 13/20\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0032 - mae: 0.0460 - val_loss: 0.0040 - val_mae: 0.0548\n",
      "Epoch 14/20\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0033 - mae: 0.0466 - val_loss: 0.0038 - val_mae: 0.0541\n",
      "Epoch 15/20\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0032 - mae: 0.0459 - val_loss: 0.0039 - val_mae: 0.0538\n",
      "Epoch 16/20\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0031 - mae: 0.0453 - val_loss: 0.0039 - val_mae: 0.0543\n",
      "Epoch 17/20\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0032 - mae: 0.0456 - val_loss: 0.0036 - val_mae: 0.0523\n",
      "Epoch 18/20\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0032 - mae: 0.0454 - val_loss: 0.0033 - val_mae: 0.0498\n",
      "Epoch 19/20\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0030 - mae: 0.0447 - val_loss: 0.0037 - val_mae: 0.0528\n",
      "Epoch 20/20\n",
      "\u001b[1m360/360\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0031 - mae: 0.0450 - val_loss: 0.0035 - val_mae: 0.0515\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
      "✅ Done with onion_Mandya_daily.csv | MAE=525.77, RMSE=605.69, R2=0.24, MAPE=27.17%, Accuracy=72.83%\n",
      "\n",
      "========== Processing: onion_MangaloreDakshin_Kannad_daily.csv ==========\n",
      "Epoch 1/20\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.0454 - mae: 0.1576 - val_loss: 0.0021 - val_mae: 0.0331\n",
      "Epoch 2/20\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 1.9627e-04 - mae: 0.0049 - val_loss: 0.0020 - val_mae: 0.0320\n",
      "Epoch 3/20\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 3.8723e-04 - mae: 0.0067 - val_loss: 0.0020 - val_mae: 0.0320\n",
      "Epoch 4/20\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 2.7693e-04 - mae: 0.0055 - val_loss: 0.0020 - val_mae: 0.0326\n",
      "Epoch 5/20\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 2.2849e-04 - mae: 0.0054 - val_loss: 0.0020 - val_mae: 0.0322\n",
      "Epoch 6/20\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 2.2876e-04 - mae: 0.0048 - val_loss: 0.0020 - val_mae: 0.0324\n",
      "Epoch 7/20\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 2.1658e-04 - mae: 0.0050 - val_loss: 0.0020 - val_mae: 0.0321\n",
      "Epoch 8/20\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 1.8335e-04 - mae: 0.0045 - val_loss: 0.0020 - val_mae: 0.0322\n",
      "Epoch 9/20\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 2.3867e-04 - mae: 0.0051 - val_loss: 0.0020 - val_mae: 0.0320\n",
      "Epoch 10/20\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 1.6944e-04 - mae: 0.0044 - val_loss: 0.0020 - val_mae: 0.0329\n",
      "Epoch 11/20\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 2.3068e-04 - mae: 0.0055 - val_loss: 0.0020 - val_mae: 0.0321\n",
      "Epoch 12/20\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.6427e-04 - mae: 0.0044 - val_loss: 0.0020 - val_mae: 0.0326\n",
      "Epoch 13/20\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 2.3193e-04 - mae: 0.0058 - val_loss: 0.0020 - val_mae: 0.0316\n",
      "Epoch 14/20\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 2.6749e-04 - mae: 0.0051 - val_loss: 0.0020 - val_mae: 0.0323\n",
      "Epoch 15/20\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 1.5466e-04 - mae: 0.0046 - val_loss: 0.0020 - val_mae: 0.0315\n",
      "Epoch 16/20\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 1.5625e-04 - mae: 0.0042 - val_loss: 0.0020 - val_mae: 0.0312\n",
      "Epoch 17/20\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 1.7576e-04 - mae: 0.0045 - val_loss: 0.0020 - val_mae: 0.0314\n",
      "Epoch 18/20\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.6005e-04 - mae: 0.0043 - val_loss: 0.0020 - val_mae: 0.0313\n",
      "Epoch 19/20\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 2.1899e-04 - mae: 0.0052 - val_loss: 0.0020 - val_mae: 0.0310\n",
      "Epoch 20/20\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 1.0752e-04 - mae: 0.0044 - val_loss: 0.0020 - val_mae: 0.0316\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step\n",
      "✅ Done with onion_MangaloreDakshin_Kannad_daily.csv | MAE=174.29, RMSE=247.84, R2=0.92, MAPE=9.58%, Accuracy=90.42%\n",
      "\n",
      "========== Processing: onion_Mysore_daily.csv ==========\n",
      "Epoch 1/20\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 0.0014 - mae: 0.0288 - val_loss: 0.0011 - val_mae: 0.0225\n",
      "Epoch 2/20\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0010 - mae: 0.0241 - val_loss: 0.0011 - val_mae: 0.0226\n",
      "Epoch 3/20\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0011 - mae: 0.0237 - val_loss: 0.0011 - val_mae: 0.0221\n",
      "Epoch 4/20\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 9.6619e-04 - mae: 0.0232 - val_loss: 9.2011e-04 - val_mae: 0.0202\n",
      "Epoch 5/20\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 9.6420e-04 - mae: 0.0230 - val_loss: 0.0011 - val_mae: 0.0222\n",
      "Epoch 6/20\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0010 - mae: 0.0232 - val_loss: 9.0869e-04 - val_mae: 0.0200\n",
      "Epoch 7/20\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 9.6517e-04 - mae: 0.0231 - val_loss: 9.3009e-04 - val_mae: 0.0203\n",
      "Epoch 8/20\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 9.4898e-04 - mae: 0.0225 - val_loss: 9.1699e-04 - val_mae: 0.0201\n",
      "Epoch 9/20\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 9.6828e-04 - mae: 0.0229 - val_loss: 8.9569e-04 - val_mae: 0.0199\n",
      "Epoch 10/20\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0010 - mae: 0.0233 - val_loss: 9.4128e-04 - val_mae: 0.0203\n",
      "Epoch 11/20\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 9.5910e-04 - mae: 0.0227 - val_loss: 9.8779e-04 - val_mae: 0.0210\n",
      "Epoch 12/20\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 9.3223e-04 - mae: 0.0230 - val_loss: 0.0010 - val_mae: 0.0215\n",
      "Epoch 13/20\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0012 - mae: 0.0234 - val_loss: 8.8442e-04 - val_mae: 0.0198\n",
      "Epoch 14/20\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0010 - mae: 0.0229 - val_loss: 9.4986e-04 - val_mae: 0.0205\n",
      "Epoch 15/20\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 9.9316e-04 - mae: 0.0228 - val_loss: 9.3075e-04 - val_mae: 0.0201\n",
      "Epoch 16/20\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 9.8358e-04 - mae: 0.0230 - val_loss: 9.9865e-04 - val_mae: 0.0213\n",
      "Epoch 17/20\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 9.9005e-04 - mae: 0.0228 - val_loss: 9.8282e-04 - val_mae: 0.0207\n",
      "Epoch 18/20\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 9.9756e-04 - mae: 0.0230 - val_loss: 0.0011 - val_mae: 0.0219\n",
      "Epoch 19/20\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 9.1381e-04 - mae: 0.0227 - val_loss: 9.0673e-04 - val_mae: 0.0201\n",
      "Epoch 20/20\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 9.2379e-04 - mae: 0.0226 - val_loss: 8.4962e-04 - val_mae: 0.0192\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
      "✅ Done with onion_Mysore_daily.csv | MAE=368.61, RMSE=559.65, R2=0.46, MAPE=18.22%, Accuracy=81.78%\n",
      "\n",
      "========== Processing: onion_Raichur_daily.csv ==========\n",
      "Epoch 1/20\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 0.0097 - mae: 0.0647 - val_loss: 2.9151e-04 - val_mae: 0.0114\n",
      "Epoch 2/20\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 9.6131e-04 - mae: 0.0186 - val_loss: 2.6424e-04 - val_mae: 0.0106\n",
      "Epoch 3/20\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 9.3435e-04 - mae: 0.0187 - val_loss: 2.8521e-04 - val_mae: 0.0122\n",
      "Epoch 4/20\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 8.8258e-04 - mae: 0.0182 - val_loss: 2.5996e-04 - val_mae: 0.0109\n",
      "Epoch 5/20\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 8.5294e-04 - mae: 0.0187 - val_loss: 3.3257e-04 - val_mae: 0.0143\n",
      "Epoch 6/20\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 8.5645e-04 - mae: 0.0183 - val_loss: 2.4931e-04 - val_mae: 0.0103\n",
      "Epoch 7/20\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 8.5290e-04 - mae: 0.0177 - val_loss: 2.6404e-04 - val_mae: 0.0116\n",
      "Epoch 8/20\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 9.2767e-04 - mae: 0.0193 - val_loss: 2.8548e-04 - val_mae: 0.0124\n",
      "Epoch 9/20\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 8.8512e-04 - mae: 0.0183 - val_loss: 2.4258e-04 - val_mae: 0.0106\n",
      "Epoch 10/20\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 7.7786e-04 - mae: 0.0180 - val_loss: 2.3467e-04 - val_mae: 0.0100\n",
      "Epoch 11/20\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 8.0412e-04 - mae: 0.0175 - val_loss: 2.3748e-04 - val_mae: 0.0101\n",
      "Epoch 12/20\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 8.6128e-04 - mae: 0.0184 - val_loss: 2.6557e-04 - val_mae: 0.0116\n",
      "Epoch 13/20\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 7.8994e-04 - mae: 0.0176 - val_loss: 2.2783e-04 - val_mae: 0.0099\n",
      "Epoch 14/20\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 7.6359e-04 - mae: 0.0176 - val_loss: 2.3097e-04 - val_mae: 0.0102\n",
      "Epoch 15/20\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 7.8739e-04 - mae: 0.0178 - val_loss: 2.4962e-04 - val_mae: 0.0112\n",
      "Epoch 16/20\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 8.4900e-04 - mae: 0.0183 - val_loss: 2.3347e-04 - val_mae: 0.0103\n",
      "Epoch 17/20\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 8.3970e-04 - mae: 0.0180 - val_loss: 2.3087e-04 - val_mae: 0.0102\n",
      "Epoch 18/20\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 8.2914e-04 - mae: 0.0178 - val_loss: 2.4473e-04 - val_mae: 0.0111\n",
      "Epoch 19/20\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 7.6788e-04 - mae: 0.0176 - val_loss: 2.9489e-04 - val_mae: 0.0135\n",
      "Epoch 20/20\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 8.1076e-04 - mae: 0.0183 - val_loss: 2.2230e-04 - val_mae: 0.0097\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
      "✅ Done with onion_Raichur_daily.csv | MAE=82.6, RMSE=127.44, R2=0.95, MAPE=6.41%, Accuracy=93.59%\n",
      "\n",
      "========== Processing: onion_Shimoga_daily.csv ==========\n",
      "Epoch 1/20\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.0024 - mae: 0.0329 - val_loss: 0.0024 - val_mae: 0.0313\n",
      "Epoch 2/20\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0013 - mae: 0.0230 - val_loss: 0.0022 - val_mae: 0.0277\n",
      "Epoch 3/20\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0012 - mae: 0.0224 - val_loss: 0.0022 - val_mae: 0.0252\n",
      "Epoch 4/20\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0011 - mae: 0.0214 - val_loss: 0.0022 - val_mae: 0.0262\n",
      "Epoch 5/20\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0012 - mae: 0.0217 - val_loss: 0.0024 - val_mae: 0.0266\n",
      "Epoch 6/20\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0011 - mae: 0.0204 - val_loss: 0.0026 - val_mae: 0.0264\n",
      "Epoch 7/20\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0011 - mae: 0.0205 - val_loss: 0.0026 - val_mae: 0.0267\n",
      "Epoch 8/20\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0011 - mae: 0.0208 - val_loss: 0.0027 - val_mae: 0.0259\n",
      "Epoch 9/20\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0011 - mae: 0.0198 - val_loss: 0.0029 - val_mae: 0.0284\n",
      "Epoch 10/20\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0010 - mae: 0.0194 - val_loss: 0.0031 - val_mae: 0.0296\n",
      "Epoch 11/20\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0010 - mae: 0.0196 - val_loss: 0.0033 - val_mae: 0.0309\n",
      "Epoch 12/20\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 9.7970e-04 - mae: 0.0191 - val_loss: 0.0047 - val_mae: 0.0416\n",
      "Epoch 13/20\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0010 - mae: 0.0196 - val_loss: 0.0042 - val_mae: 0.0366\n",
      "Epoch 14/20\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 9.8130e-04 - mae: 0.0192 - val_loss: 0.0053 - val_mae: 0.0436\n",
      "Epoch 15/20\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 9.7980e-04 - mae: 0.0193 - val_loss: 0.0045 - val_mae: 0.0377\n",
      "Epoch 16/20\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 9.2697e-04 - mae: 0.0185 - val_loss: 0.0058 - val_mae: 0.0449\n",
      "Epoch 17/20\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 9.2475e-04 - mae: 0.0188 - val_loss: 0.0054 - val_mae: 0.0413\n",
      "Epoch 18/20\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 9.4539e-04 - mae: 0.0185 - val_loss: 0.0074 - val_mae: 0.0499\n",
      "Epoch 19/20\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 9.4623e-04 - mae: 0.0190 - val_loss: 0.0080 - val_mae: 0.0522\n",
      "Epoch 20/20\n",
      "\u001b[1m284/284\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 9.5853e-04 - mae: 0.0192 - val_loss: 0.0103 - val_mae: 0.0564\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
      "✅ Done with onion_Shimoga_daily.csv | MAE=901.77, RMSE=1622.85, R2=-1.13, MAPE=108.07%, Accuracy=-8.07%\n",
      "\n",
      "========== Processing: onion_Tumkur_daily.csv ==========\n",
      "Epoch 1/20\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.0047 - mae: 0.0512 - val_loss: 0.0543 - val_mae: 0.2077\n",
      "Epoch 2/20\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0380 - val_loss: 0.0508 - val_mae: 0.2015\n",
      "Epoch 3/20\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0023 - mae: 0.0365 - val_loss: 0.0460 - val_mae: 0.1880\n",
      "Epoch 4/20\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0022 - mae: 0.0354 - val_loss: 0.0423 - val_mae: 0.1751\n",
      "Epoch 5/20\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0022 - mae: 0.0350 - val_loss: 0.0422 - val_mae: 0.1689\n",
      "Epoch 6/20\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0021 - mae: 0.0338 - val_loss: 0.0399 - val_mae: 0.1639\n",
      "Epoch 7/20\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0021 - mae: 0.0346 - val_loss: 0.0396 - val_mae: 0.1606\n",
      "Epoch 8/20\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0021 - mae: 0.0344 - val_loss: 0.0397 - val_mae: 0.1581\n",
      "Epoch 9/20\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0021 - mae: 0.0338 - val_loss: 0.0401 - val_mae: 0.1572\n",
      "Epoch 10/20\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0020 - mae: 0.0332 - val_loss: 0.0407 - val_mae: 0.1557\n",
      "Epoch 11/20\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0020 - mae: 0.0330 - val_loss: 0.0396 - val_mae: 0.1552\n",
      "Epoch 12/20\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0021 - mae: 0.0340 - val_loss: 0.0403 - val_mae: 0.1505\n",
      "Epoch 13/20\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0021 - mae: 0.0338 - val_loss: 0.0418 - val_mae: 0.1547\n",
      "Epoch 14/20\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0020 - mae: 0.0332 - val_loss: 0.0419 - val_mae: 0.1493\n",
      "Epoch 15/20\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0020 - mae: 0.0332 - val_loss: 0.0415 - val_mae: 0.1484\n",
      "Epoch 16/20\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0020 - mae: 0.0333 - val_loss: 0.0433 - val_mae: 0.1530\n",
      "Epoch 17/20\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0020 - mae: 0.0330 - val_loss: 0.0433 - val_mae: 0.1461\n",
      "Epoch 18/20\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0019 - mae: 0.0323 - val_loss: 0.0424 - val_mae: 0.1466\n",
      "Epoch 19/20\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0019 - mae: 0.0329 - val_loss: 0.0446 - val_mae: 0.1474\n",
      "Epoch 20/20\n",
      "\u001b[1m345/345\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0019 - mae: 0.0326 - val_loss: 0.0476 - val_mae: 0.1526\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "✅ Done with onion_Tumkur_daily.csv | MAE=2418.47, RMSE=3459.81, R2=0.05, MAPE=64.01%, Accuracy=35.99%\n",
      "\n",
      "========== Processing: onion_Udupi_daily.csv ==========\n",
      "Epoch 1/20\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0108 - mae: 0.0635 - val_loss: 0.0018 - val_mae: 0.0190\n",
      "Epoch 2/20\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 8.4113e-04 - mae: 0.0177 - val_loss: 0.0018 - val_mae: 0.0216\n",
      "Epoch 3/20\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 7.9641e-04 - mae: 0.0176 - val_loss: 0.0017 - val_mae: 0.0196\n",
      "Epoch 4/20\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 8.6016e-04 - mae: 0.0181 - val_loss: 0.0017 - val_mae: 0.0179\n",
      "Epoch 5/20\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 8.4447e-04 - mae: 0.0181 - val_loss: 0.0017 - val_mae: 0.0184\n",
      "Epoch 6/20\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 7.6518e-04 - mae: 0.0174 - val_loss: 0.0017 - val_mae: 0.0198\n",
      "Epoch 7/20\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 8.2320e-04 - mae: 0.0180 - val_loss: 0.0018 - val_mae: 0.0223\n",
      "Epoch 8/20\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 7.4832e-04 - mae: 0.0175 - val_loss: 0.0017 - val_mae: 0.0177\n",
      "Epoch 9/20\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 7.6673e-04 - mae: 0.0174 - val_loss: 0.0016 - val_mae: 0.0169\n",
      "Epoch 10/20\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 7.6125e-04 - mae: 0.0173 - val_loss: 0.0017 - val_mae: 0.0216\n",
      "Epoch 11/20\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 7.6240e-04 - mae: 0.0172 - val_loss: 0.0016 - val_mae: 0.0180\n",
      "Epoch 12/20\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 8.0178e-04 - mae: 0.0176 - val_loss: 0.0016 - val_mae: 0.0180\n",
      "Epoch 13/20\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 7.8213e-04 - mae: 0.0173 - val_loss: 0.0016 - val_mae: 0.0193\n",
      "Epoch 14/20\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 8.1356e-04 - mae: 0.0174 - val_loss: 0.0016 - val_mae: 0.0182\n",
      "Epoch 15/20\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 8.1974e-04 - mae: 0.0174 - val_loss: 0.0016 - val_mae: 0.0180\n",
      "Epoch 16/20\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 8.0397e-04 - mae: 0.0176 - val_loss: 0.0016 - val_mae: 0.0182\n",
      "Epoch 17/20\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 8.0526e-04 - mae: 0.0177 - val_loss: 0.0016 - val_mae: 0.0177\n",
      "Epoch 18/20\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 8.0311e-04 - mae: 0.0172 - val_loss: 0.0016 - val_mae: 0.0187\n",
      "Epoch 19/20\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 7.4591e-04 - mae: 0.0174 - val_loss: 0.0015 - val_mae: 0.0168\n",
      "Epoch 20/20\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 7.0244e-04 - mae: 0.0168 - val_loss: 0.0016 - val_mae: 0.0181\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
      "✅ Done with onion_Udupi_daily.csv | MAE=179.14, RMSE=398.72, R2=0.88, MAPE=6.58%, Accuracy=93.42%\n",
      "\n",
      "📊 Metrics saved to output_lstm_csv\\lstm_metrics.csv\n",
      "\n",
      "All districts processed successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "# -----------------------------\n",
    "# 🧹 Clean console output\n",
    "# -----------------------------\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'   # Hide TensorFlow INFO/WARNING/ERROR\n",
    "tf.get_logger().setLevel(\"ERROR\")          # Suppress TF backend logs\n",
    "\n",
    "# -----------------------------\n",
    "# Paths\n",
    "# -----------------------------\n",
    "input_folder = \"dataset\"\n",
    "output_models = \"output_lstm_models\"\n",
    "output_csv = \"output_lstm_csv\"\n",
    "output_graphs = \"output_lstm_graphs\"\n",
    "output_logs = \"output_lstm_logs\"\n",
    "metrics_file = os.path.join(output_csv, \"lstm_metrics.csv\")\n",
    "\n",
    "os.makedirs(output_models, exist_ok=True)\n",
    "os.makedirs(output_csv, exist_ok=True)\n",
    "os.makedirs(output_graphs, exist_ok=True)\n",
    "os.makedirs(output_logs, exist_ok=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Function to create sequences\n",
    "# -----------------------------\n",
    "def create_sequences(data, seq_length=5):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i+seq_length])\n",
    "        y.append(data[i+seq_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# -----------------------------\n",
    "# Metrics storage\n",
    "# -----------------------------\n",
    "metrics_list = []\n",
    "\n",
    "# -----------------------------\n",
    "# Process each CSV\n",
    "# -----------------------------\n",
    "seq_length = 5\n",
    "for file in os.listdir(input_folder):\n",
    "    if file.endswith(\".csv\"):\n",
    "        district_name = file.split(\".\")[0]\n",
    "        print(f\"\\n========== Processing: {file} ==========\")\n",
    "\n",
    "        # Load CSV with multiple date formats\n",
    "        df = pd.read_csv(os.path.join(input_folder, file))\n",
    "        df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "        df = df.dropna(subset=['Date'])\n",
    "        df = df.sort_values('Date')\n",
    "\n",
    "        # Fill missing Average Price\n",
    "        df['Average Price'] = df['Average Price'].fillna(df['Average Price'].mean())\n",
    "\n",
    "        # Moving averages (for plotting only)\n",
    "        df['MA_7'] = df['Average Price'].rolling(window=7).mean().fillna(df['Average Price'].mean())\n",
    "        df['MA_30'] = df['Average Price'].rolling(window=30).mean().fillna(df['Average Price'].mean())\n",
    "\n",
    "        # Scaling\n",
    "        scaler = MinMaxScaler()\n",
    "        prices_scaled = scaler.fit_transform(df['Average Price'].values.reshape(-1, 1))\n",
    "\n",
    "        # Prepare sequences\n",
    "        X, y = create_sequences(prices_scaled, seq_length)\n",
    "\n",
    "        # Train-test split (80%-20%)\n",
    "        split = int(0.8 * len(X))\n",
    "        X_train, X_test = X[:split], X[split:]\n",
    "        y_train, y_test = y[:split], y[split:]\n",
    "\n",
    "        # Build LSTM model\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(50, activation='relu', input_shape=(seq_length, 1)))\n",
    "        model.add(Dense(1))\n",
    "        model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "        # Train model (Epochs will show in console)\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            epochs=20,\n",
    "            batch_size=32,\n",
    "            validation_data=(X_test, y_test),\n",
    "            verbose=1  # 👈 keeps epoch progress in console\n",
    "        )\n",
    "\n",
    "        # Predictions\n",
    "        y_pred_scaled = model.predict(X_test)\n",
    "        y_pred = scaler.inverse_transform(y_pred_scaled)\n",
    "        y_true = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "        # Round Actual & Predicted\n",
    "        y_true_round = np.round(y_true, 2)\n",
    "        y_pred_round = np.round(y_pred, 2)\n",
    "\n",
    "        # Save predictions in CSV (only Date, Actual, Predicted)\n",
    "        df_pred = df.iloc[seq_length + split:].copy()\n",
    "        df_pred = df_pred[['Date']].copy()\n",
    "        df_pred['Actual'] = y_true_round.flatten()\n",
    "        df_pred['Predicted'] = y_pred_round.flatten()\n",
    "        df_pred.to_csv(os.path.join(output_csv, f\"{district_name}_lstm_updated.csv\"), index=False)\n",
    "\n",
    "        # Metrics calculation\n",
    "        mae_val = round(mean_absolute_error(y_true, y_pred), 2)\n",
    "        rmse_val = round(mean_squared_error(y_true, y_pred, squared=False), 2)\n",
    "        r2_val = round(r2_score(y_true, y_pred), 2)\n",
    "        mape_val = round(np.mean(np.abs((y_true - y_pred) / y_true)) * 100, 2)\n",
    "        accuracy_val = round(100 - mape_val, 2)\n",
    "        metrics_list.append([district_name, mae_val, rmse_val, r2_val, mape_val, accuracy_val])\n",
    "\n",
    "        print(f\"✅ Done with {file} | MAE={mae_val}, RMSE={rmse_val}, R2={r2_val}, \"\n",
    "              f\"MAPE={mape_val}%, Accuracy={accuracy_val}%\")\n",
    "\n",
    "        # Save model as .pkl\n",
    "        model_file = os.path.join(output_models, f\"{district_name}_lstm_model.pkl\")\n",
    "        joblib.dump(model, model_file)\n",
    "\n",
    "        # Save prediction graph (with MA7 & MA30 only for graphing)\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(df['Date'], df['Average Price'], label='Actual', color='blue')\n",
    "        plt.plot(df['Date'], df['MA_7'], label='MA 7', color='orange')\n",
    "        plt.plot(df['Date'], df['MA_30'], label='MA 30', color='green')\n",
    "        plt.plot(df_pred['Date'], df_pred['Predicted'], label='Predicted', color='red', linestyle='dashed')\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Average Price')\n",
    "        plt.title(f\"LSTM Predictions for {district_name}\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.savefig(os.path.join(output_graphs, f\"{district_name}_lstm_graph.png\"))\n",
    "        plt.close()\n",
    "\n",
    "        # Save training loss graph\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        plt.plot(history.history['loss'], label='Train Loss')\n",
    "        plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "        plt.title(f\"Training Loss for {district_name}\")\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        plt.savefig(os.path.join(output_graphs, f\"{district_name}_lstm_training_loss.png\"))\n",
    "        plt.close()\n",
    "\n",
    "# Save metrics CSV\n",
    "metrics_df = pd.DataFrame(metrics_list, columns=['District', 'MAE', 'RMSE', 'R2', 'MAPE(%)', 'Accuracy(%)'])\n",
    "metrics_df.to_csv(metrics_file, index=False)\n",
    "print(f\"\\n📊 Metrics saved to {metrics_file}\")\n",
    "print(\"\\nAll districts processed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9075cab3-fc50-4c2d-903b-61c75ed28e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92cbfe4a-043b-4aba-b8a6-d4f1e7f9c5eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Processing: onion_Bagalkot_daily.csv\n",
      "Epoch 1/20\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 18ms/step - loss: 0.0031 - mae: 0.0340 - val_loss: 8.0192e-04 - val_mae: 0.0214\n",
      "Epoch 2/20\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0011 - mae: 0.0225 - val_loss: 4.4707e-04 - val_mae: 0.0123\n",
      "Epoch 3/20\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 0.0011 - mae: 0.0224 - val_loss: 3.7564e-04 - val_mae: 0.0118\n",
      "Epoch 4/20\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - loss: 0.0011 - mae: 0.0220 - val_loss: 3.4057e-04 - val_mae: 0.0121\n",
      "Epoch 5/20\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0010 - mae: 0.0208 - val_loss: 3.5499e-04 - val_mae: 0.0148\n",
      "Epoch 6/20\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - loss: 8.8227e-04 - mae: 0.0195 - val_loss: 4.0540e-04 - val_mae: 0.0147\n",
      "Epoch 7/20\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - loss: 9.6367e-04 - mae: 0.0201 - val_loss: 2.6771e-04 - val_mae: 0.0100\n",
      "Epoch 8/20\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - loss: 8.6980e-04 - mae: 0.0198 - val_loss: 2.9685e-04 - val_mae: 0.0105\n",
      "Epoch 9/20\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 0.0010 - mae: 0.0208 - val_loss: 4.0789e-04 - val_mae: 0.0139\n",
      "Epoch 10/20\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - loss: 8.5626e-04 - mae: 0.0196 - val_loss: 3.5577e-04 - val_mae: 0.0125\n",
      "Epoch 11/20\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 8.6604e-04 - mae: 0.0196 - val_loss: 2.9244e-04 - val_mae: 0.0101\n",
      "Epoch 12/20\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 9.0566e-04 - mae: 0.0192 - val_loss: 7.5533e-04 - val_mae: 0.0202\n",
      "Epoch 13/20\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - loss: 8.9801e-04 - mae: 0.0199 - val_loss: 3.4787e-04 - val_mae: 0.0122\n",
      "Epoch 14/20\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - loss: 8.0468e-04 - mae: 0.0189 - val_loss: 4.2652e-04 - val_mae: 0.0138\n",
      "Epoch 15/20\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 24ms/step - loss: 8.9326e-04 - mae: 0.0196 - val_loss: 3.9120e-04 - val_mae: 0.0151\n",
      "Epoch 16/20\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 8.8545e-04 - mae: 0.0194 - val_loss: 3.1831e-04 - val_mae: 0.0116\n",
      "Epoch 17/20\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - loss: 8.1337e-04 - mae: 0.0190 - val_loss: 3.3241e-04 - val_mae: 0.0123\n",
      "Epoch 18/20\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 8.3433e-04 - mae: 0.0191 - val_loss: 3.0611e-04 - val_mae: 0.0108\n",
      "Epoch 19/20\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - loss: 9.0493e-04 - mae: 0.0196 - val_loss: 3.6761e-04 - val_mae: 0.0151\n",
      "Epoch 20/20\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 7.9901e-04 - mae: 0.0187 - val_loss: 2.9372e-04 - val_mae: 0.0107\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
      "✅ Done with onion_Bagalkot_daily.csv | MAE=82.89, RMSE=132.65, R2=0.97, MAPE=5.56%, Accuracy=94.44%\n",
      "\n",
      "🚀 Processing: onion_Bangalore_daily.csv\n",
      "Epoch 1/20\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 18ms/step - loss: 0.0029 - mae: 0.0366 - val_loss: 0.0019 - val_mae: 0.0299\n",
      "Epoch 2/20\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 19ms/step - loss: 0.0023 - mae: 0.0321 - val_loss: 0.0018 - val_mae: 0.0311\n",
      "Epoch 3/20\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 24ms/step - loss: 0.0023 - mae: 0.0317 - val_loss: 0.0018 - val_mae: 0.0300\n",
      "Epoch 4/20\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 28ms/step - loss: 0.0022 - mae: 0.0308 - val_loss: 0.0019 - val_mae: 0.0309\n",
      "Epoch 5/20\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 24ms/step - loss: 0.0023 - mae: 0.0309 - val_loss: 0.0023 - val_mae: 0.0326\n",
      "Epoch 6/20\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 30ms/step - loss: 0.0021 - mae: 0.0307 - val_loss: 0.0016 - val_mae: 0.0288\n",
      "Epoch 7/20\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 28ms/step - loss: 0.0021 - mae: 0.0303 - val_loss: 0.0020 - val_mae: 0.0304\n",
      "Epoch 8/20\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 28ms/step - loss: 0.0022 - mae: 0.0304 - val_loss: 0.0017 - val_mae: 0.0294\n",
      "Epoch 9/20\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 30ms/step - loss: 0.0021 - mae: 0.0301 - val_loss: 0.0019 - val_mae: 0.0299\n",
      "Epoch 10/20\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 27ms/step - loss: 0.0020 - mae: 0.0300 - val_loss: 0.0016 - val_mae: 0.0284\n",
      "Epoch 11/20\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 28ms/step - loss: 0.0021 - mae: 0.0302 - val_loss: 0.0016 - val_mae: 0.0283\n",
      "Epoch 12/20\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 27ms/step - loss: 0.0021 - mae: 0.0297 - val_loss: 0.0017 - val_mae: 0.0286\n",
      "Epoch 13/20\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 28ms/step - loss: 0.0021 - mae: 0.0299 - val_loss: 0.0017 - val_mae: 0.0290\n",
      "Epoch 14/20\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 29ms/step - loss: 0.0020 - mae: 0.0297 - val_loss: 0.0018 - val_mae: 0.0301\n",
      "Epoch 15/20\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 23ms/step - loss: 0.0021 - mae: 0.0304 - val_loss: 0.0017 - val_mae: 0.0284\n",
      "Epoch 16/20\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 26ms/step - loss: 0.0019 - mae: 0.0297 - val_loss: 0.0017 - val_mae: 0.0283\n",
      "Epoch 17/20\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 17ms/step - loss: 0.0021 - mae: 0.0294 - val_loss: 0.0017 - val_mae: 0.0284\n",
      "Epoch 18/20\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 25ms/step - loss: 0.0020 - mae: 0.0294 - val_loss: 0.0018 - val_mae: 0.0299\n",
      "Epoch 19/20\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 29ms/step - loss: 0.0020 - mae: 0.0296 - val_loss: 0.0018 - val_mae: 0.0289\n",
      "Epoch 20/20\n",
      "\u001b[1m897/897\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 28ms/step - loss: 0.0022 - mae: 0.0300 - val_loss: 0.0018 - val_mae: 0.0294\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step\n",
      "✅ Done with onion_Bangalore_daily.csv | MAE=355.87, RMSE=512.19, R2=0.79, MAPE=16.38%, Accuracy=83.62%\n",
      "\n",
      "🚀 Processing: onion_Belgaum_daily.csv\n",
      "Epoch 1/20\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 28ms/step - loss: 0.0020 - mae: 0.0257 - val_loss: 3.0401e-04 - val_mae: 0.0119\n",
      "Epoch 2/20\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - loss: 8.1124e-04 - mae: 0.0170 - val_loss: 2.9428e-04 - val_mae: 0.0113\n",
      "Epoch 3/20\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - loss: 7.9807e-04 - mae: 0.0173 - val_loss: 2.9980e-04 - val_mae: 0.0121\n",
      "Epoch 4/20\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - loss: 7.7403e-04 - mae: 0.0163 - val_loss: 2.7501e-04 - val_mae: 0.0109\n",
      "Epoch 5/20\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - loss: 6.6371e-04 - mae: 0.0158 - val_loss: 2.3054e-04 - val_mae: 0.0093\n",
      "Epoch 6/20\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - loss: 6.5081e-04 - mae: 0.0156 - val_loss: 2.4289e-04 - val_mae: 0.0104\n",
      "Epoch 7/20\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - loss: 7.4916e-04 - mae: 0.0167 - val_loss: 2.4417e-04 - val_mae: 0.0095\n",
      "Epoch 8/20\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 30ms/step - loss: 6.1635e-04 - mae: 0.0156 - val_loss: 2.2182e-04 - val_mae: 0.0088\n",
      "Epoch 9/20\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - loss: 6.6009e-04 - mae: 0.0156 - val_loss: 3.6758e-04 - val_mae: 0.0137\n",
      "Epoch 10/20\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - loss: 5.6594e-04 - mae: 0.0150 - val_loss: 2.5267e-04 - val_mae: 0.0096\n",
      "Epoch 11/20\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - loss: 5.9406e-04 - mae: 0.0150 - val_loss: 2.6513e-04 - val_mae: 0.0101\n",
      "Epoch 12/20\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - loss: 6.3122e-04 - mae: 0.0155 - val_loss: 2.2348e-04 - val_mae: 0.0093\n",
      "Epoch 13/20\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - loss: 7.0718e-04 - mae: 0.0161 - val_loss: 2.2086e-04 - val_mae: 0.0083\n",
      "Epoch 14/20\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - loss: 5.5666e-04 - mae: 0.0147 - val_loss: 2.4708e-04 - val_mae: 0.0100\n",
      "Epoch 15/20\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - loss: 5.5049e-04 - mae: 0.0141 - val_loss: 3.2574e-04 - val_mae: 0.0118\n",
      "Epoch 16/20\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - loss: 7.9169e-04 - mae: 0.0161 - val_loss: 3.0820e-04 - val_mae: 0.0126\n",
      "Epoch 17/20\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - loss: 7.1921e-04 - mae: 0.0156 - val_loss: 2.5333e-04 - val_mae: 0.0103\n",
      "Epoch 18/20\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - loss: 5.5269e-04 - mae: 0.0152 - val_loss: 2.5944e-04 - val_mae: 0.0099\n",
      "Epoch 19/20\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - loss: 6.7365e-04 - mae: 0.0163 - val_loss: 2.2187e-04 - val_mae: 0.0081\n",
      "Epoch 20/20\n",
      "\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 6.3980e-04 - mae: 0.0152 - val_loss: 2.4343e-04 - val_mae: 0.0097\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step\n",
      "✅ Done with onion_Belgaum_daily.csv | MAE=110.12, RMSE=177.87, R2=0.95, MAPE=5.49%, Accuracy=94.51%\n",
      "\n",
      "🚀 Processing: onion_Bellary_daily.csv\n",
      "Epoch 1/20\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 29ms/step - loss: 0.0016 - mae: 0.0253 - val_loss: 8.2019e-04 - val_mae: 0.0194\n",
      "Epoch 2/20\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - loss: 8.5169e-04 - mae: 0.0180 - val_loss: 0.0011 - val_mae: 0.0256\n",
      "Epoch 3/20\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - loss: 8.9122e-04 - mae: 0.0164 - val_loss: 8.3458e-04 - val_mae: 0.0190\n",
      "Epoch 4/20\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - loss: 7.0373e-04 - mae: 0.0154 - val_loss: 8.5193e-04 - val_mae: 0.0201\n",
      "Epoch 5/20\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - loss: 7.5443e-04 - mae: 0.0155 - val_loss: 8.5014e-04 - val_mae: 0.0214\n",
      "Epoch 6/20\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - loss: 9.1191e-04 - mae: 0.0156 - val_loss: 8.3679e-04 - val_mae: 0.0208\n",
      "Epoch 7/20\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - loss: 6.7772e-04 - mae: 0.0153 - val_loss: 8.5406e-04 - val_mae: 0.0203\n",
      "Epoch 8/20\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - loss: 6.9694e-04 - mae: 0.0154 - val_loss: 7.9427e-04 - val_mae: 0.0186\n",
      "Epoch 9/20\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - loss: 0.0011 - mae: 0.0169 - val_loss: 8.0213e-04 - val_mae: 0.0187\n",
      "Epoch 10/20\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - loss: 7.6659e-04 - mae: 0.0159 - val_loss: 7.8985e-04 - val_mae: 0.0185\n",
      "Epoch 11/20\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - loss: 6.7757e-04 - mae: 0.0149 - val_loss: 8.0408e-04 - val_mae: 0.0193\n",
      "Epoch 12/20\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - loss: 5.5685e-04 - mae: 0.0145 - val_loss: 7.9695e-04 - val_mae: 0.0203\n",
      "Epoch 13/20\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - loss: 0.0010 - mae: 0.0160 - val_loss: 8.6972e-04 - val_mae: 0.0210\n",
      "Epoch 14/20\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - loss: 6.6301e-04 - mae: 0.0145 - val_loss: 7.9607e-04 - val_mae: 0.0206\n",
      "Epoch 15/20\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - loss: 7.2298e-04 - mae: 0.0155 - val_loss: 7.8078e-04 - val_mae: 0.0191\n",
      "Epoch 16/20\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - loss: 6.2999e-04 - mae: 0.0152 - val_loss: 8.7371e-04 - val_mae: 0.0215\n",
      "Epoch 17/20\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - loss: 6.8892e-04 - mae: 0.0152 - val_loss: 7.8616e-04 - val_mae: 0.0185\n",
      "Epoch 18/20\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - loss: 8.2511e-04 - mae: 0.0157 - val_loss: 7.5838e-04 - val_mae: 0.0182\n",
      "Epoch 19/20\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - loss: 8.7170e-04 - mae: 0.0159 - val_loss: 7.7673e-04 - val_mae: 0.0195\n",
      "Epoch 20/20\n",
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - loss: 6.2530e-04 - mae: 0.0144 - val_loss: 7.7414e-04 - val_mae: 0.0180\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step\n",
      "✅ Done with onion_Bellary_daily.csv | MAE=200.72, RMSE=310.23, R2=0.58, MAPE=11.74%, Accuracy=88.26%\n",
      "\n",
      "🚀 Processing: onion_Bidar_daily.csv\n",
      "Epoch 1/20\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 29ms/step - loss: 0.0049 - mae: 0.0546 - val_loss: 7.6719e-04 - val_mae: 0.0203\n",
      "Epoch 2/20\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 32ms/step - loss: 0.0031 - mae: 0.0415 - val_loss: 9.1884e-04 - val_mae: 0.0112\n",
      "Epoch 3/20\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 30ms/step - loss: 0.0024 - mae: 0.0366 - val_loss: 0.0012 - val_mae: 0.0149\n",
      "Epoch 4/20\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 32ms/step - loss: 0.0025 - mae: 0.0362 - val_loss: 0.0015 - val_mae: 0.0150\n",
      "Epoch 5/20\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 31ms/step - loss: 0.0022 - mae: 0.0344 - val_loss: 0.0013 - val_mae: 0.0296\n",
      "Epoch 6/20\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 32ms/step - loss: 0.0028 - mae: 0.0363 - val_loss: 9.9106e-04 - val_mae: 0.0119\n",
      "Epoch 7/20\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 31ms/step - loss: 0.0022 - mae: 0.0329 - val_loss: 0.0010 - val_mae: 0.0107\n",
      "Epoch 8/20\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 31ms/step - loss: 0.0023 - mae: 0.0347 - val_loss: 8.9493e-04 - val_mae: 0.0117\n",
      "Epoch 9/20\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 30ms/step - loss: 0.0024 - mae: 0.0341 - val_loss: 0.0021 - val_mae: 0.0113\n",
      "Epoch 10/20\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 30ms/step - loss: 0.0024 - mae: 0.0331 - val_loss: 0.0014 - val_mae: 0.0156\n",
      "Epoch 11/20\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 31ms/step - loss: 0.0026 - mae: 0.0342 - val_loss: 8.3003e-04 - val_mae: 0.0149\n",
      "Epoch 12/20\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 32ms/step - loss: 0.0022 - mae: 0.0324 - val_loss: 5.9270e-04 - val_mae: 0.0156\n",
      "Epoch 13/20\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 31ms/step - loss: 0.0024 - mae: 0.0334 - val_loss: 0.0013 - val_mae: 0.0144\n",
      "Epoch 14/20\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 32ms/step - loss: 0.0028 - mae: 0.0328 - val_loss: 0.0020 - val_mae: 0.0160\n",
      "Epoch 15/20\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 32ms/step - loss: 0.0023 - mae: 0.0321 - val_loss: 0.0025 - val_mae: 0.0142\n",
      "Epoch 16/20\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 32ms/step - loss: 0.0020 - mae: 0.0310 - val_loss: 0.0017 - val_mae: 0.0178\n",
      "Epoch 17/20\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 33ms/step - loss: 0.0022 - mae: 0.0314 - val_loss: 0.0020 - val_mae: 0.0130\n",
      "Epoch 18/20\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 30ms/step - loss: 0.0020 - mae: 0.0311 - val_loss: 9.5103e-04 - val_mae: 0.0105\n",
      "Epoch 19/20\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 31ms/step - loss: 0.0022 - mae: 0.0323 - val_loss: 0.0017 - val_mae: 0.0115\n",
      "Epoch 20/20\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 32ms/step - loss: 0.0020 - mae: 0.0299 - val_loss: 0.0012 - val_mae: 0.0118\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step\n",
      "✅ Done with onion_Bidar_daily.csv | MAE=47.0, RMSE=137.6, R2=0.87, MAPE=2.45%, Accuracy=97.55%\n",
      "\n",
      "🚀 Processing: onion_Bijapur_daily.csv\n",
      "Epoch 1/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 31ms/step - loss: 0.0038 - mae: 0.0466 - val_loss: 4.9690e-04 - val_mae: 0.0149\n",
      "Epoch 2/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 30ms/step - loss: 0.0021 - mae: 0.0366 - val_loss: 6.0382e-04 - val_mae: 0.0169\n",
      "Epoch 3/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 30ms/step - loss: 0.0020 - mae: 0.0338 - val_loss: 3.8420e-04 - val_mae: 0.0126\n",
      "Epoch 4/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 31ms/step - loss: 0.0020 - mae: 0.0331 - val_loss: 5.5195e-04 - val_mae: 0.0156\n",
      "Epoch 5/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 29ms/step - loss: 0.0019 - mae: 0.0316 - val_loss: 5.4995e-04 - val_mae: 0.0163\n",
      "Epoch 6/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 27ms/step - loss: 0.0018 - mae: 0.0317 - val_loss: 5.2097e-04 - val_mae: 0.0158\n",
      "Epoch 7/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 28ms/step - loss: 0.0019 - mae: 0.0311 - val_loss: 7.4321e-04 - val_mae: 0.0182\n",
      "Epoch 8/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 30ms/step - loss: 0.0019 - mae: 0.0319 - val_loss: 7.5312e-04 - val_mae: 0.0185\n",
      "Epoch 9/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 31ms/step - loss: 0.0017 - mae: 0.0306 - val_loss: 6.9011e-04 - val_mae: 0.0179\n",
      "Epoch 10/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 30ms/step - loss: 0.0018 - mae: 0.0300 - val_loss: 7.4551e-04 - val_mae: 0.0191\n",
      "Epoch 11/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 30ms/step - loss: 0.0018 - mae: 0.0300 - val_loss: 8.4166e-04 - val_mae: 0.0204\n",
      "Epoch 12/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 29ms/step - loss: 0.0018 - mae: 0.0302 - val_loss: 8.3653e-04 - val_mae: 0.0204\n",
      "Epoch 13/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 29ms/step - loss: 0.0016 - mae: 0.0290 - val_loss: 8.1394e-04 - val_mae: 0.0204\n",
      "Epoch 14/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 29ms/step - loss: 0.0017 - mae: 0.0294 - val_loss: 8.1392e-04 - val_mae: 0.0200\n",
      "Epoch 15/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 29ms/step - loss: 0.0016 - mae: 0.0291 - val_loss: 0.0011 - val_mae: 0.0251\n",
      "Epoch 16/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 29ms/step - loss: 0.0016 - mae: 0.0291 - val_loss: 8.3978e-04 - val_mae: 0.0198\n",
      "Epoch 17/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 30ms/step - loss: 0.0017 - mae: 0.0301 - val_loss: 7.8102e-04 - val_mae: 0.0193\n",
      "Epoch 18/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 28ms/step - loss: 0.0016 - mae: 0.0291 - val_loss: 6.7406e-04 - val_mae: 0.0186\n",
      "Epoch 19/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 28ms/step - loss: 0.0015 - mae: 0.0281 - val_loss: 0.0010 - val_mae: 0.0229\n",
      "Epoch 20/20\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 29ms/step - loss: 0.0015 - mae: 0.0287 - val_loss: 8.7812e-04 - val_mae: 0.0206\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step\n",
      "✅ Done with onion_Bijapur_daily.csv | MAE=215.82, RMSE=311.15, R2=0.82, MAPE=16.58%, Accuracy=83.42%\n",
      "\n",
      "🚀 Processing: onion_Chamrajnagar_daily.csv\n",
      "Epoch 1/20\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 29ms/step - loss: 0.0034 - mae: 0.0312 - val_loss: 0.0016 - val_mae: 0.0306\n",
      "Epoch 2/20\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 30ms/step - loss: 0.0028 - mae: 0.0268 - val_loss: 0.0014 - val_mae: 0.0296\n",
      "Epoch 3/20\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 29ms/step - loss: 0.0025 - mae: 0.0256 - val_loss: 0.0014 - val_mae: 0.0286\n",
      "Epoch 4/20\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 29ms/step - loss: 0.0025 - mae: 0.0259 - val_loss: 0.0028 - val_mae: 0.0391\n",
      "Epoch 5/20\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 29ms/step - loss: 0.0024 - mae: 0.0249 - val_loss: 0.0030 - val_mae: 0.0375\n",
      "Epoch 6/20\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 29ms/step - loss: 0.0023 - mae: 0.0249 - val_loss: 0.0020 - val_mae: 0.0322\n",
      "Epoch 7/20\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 29ms/step - loss: 0.0026 - mae: 0.0252 - val_loss: 0.0020 - val_mae: 0.0322\n",
      "Epoch 8/20\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 29ms/step - loss: 0.0021 - mae: 0.0237 - val_loss: 0.0017 - val_mae: 0.0310\n",
      "Epoch 9/20\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 28ms/step - loss: 0.0026 - mae: 0.0258 - val_loss: 0.0016 - val_mae: 0.0293\n",
      "Epoch 10/20\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 28ms/step - loss: 0.0025 - mae: 0.0243 - val_loss: 0.0016 - val_mae: 0.0294\n",
      "Epoch 11/20\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 28ms/step - loss: 0.0023 - mae: 0.0240 - val_loss: 0.0015 - val_mae: 0.0291\n",
      "Epoch 12/20\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 27ms/step - loss: 0.0022 - mae: 0.0239 - val_loss: 0.0016 - val_mae: 0.0298\n",
      "Epoch 13/20\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 28ms/step - loss: 0.0024 - mae: 0.0246 - val_loss: 0.0016 - val_mae: 0.0287\n",
      "Epoch 14/20\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 29ms/step - loss: 0.0022 - mae: 0.0233 - val_loss: 0.0016 - val_mae: 0.0294\n",
      "Epoch 15/20\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 28ms/step - loss: 0.0022 - mae: 0.0238 - val_loss: 0.0018 - val_mae: 0.0306\n",
      "Epoch 16/20\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 28ms/step - loss: 0.0021 - mae: 0.0231 - val_loss: 0.0021 - val_mae: 0.0334\n",
      "Epoch 17/20\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 28ms/step - loss: 0.0020 - mae: 0.0236 - val_loss: 0.0017 - val_mae: 0.0301\n",
      "Epoch 18/20\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 27ms/step - loss: 0.0020 - mae: 0.0228 - val_loss: 0.0016 - val_mae: 0.0293\n",
      "Epoch 19/20\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 24ms/step - loss: 0.0025 - mae: 0.0243 - val_loss: 0.0023 - val_mae: 0.0335\n",
      "Epoch 20/20\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 29ms/step - loss: 0.0019 - mae: 0.0218 - val_loss: 0.0016 - val_mae: 0.0294\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step\n",
      "✅ Done with onion_Chamrajnagar_daily.csv | MAE=405.44, RMSE=553.51, R2=0.68, MAPE=15.67%, Accuracy=84.33%\n",
      "\n",
      "🚀 Processing: onion_Chikmagalur_daily.csv\n",
      "Epoch 1/20\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 29ms/step - loss: 0.0142 - mae: 0.0835 - val_loss: 0.0053 - val_mae: 0.0530\n",
      "Epoch 2/20\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 29ms/step - loss: 0.0115 - mae: 0.0739 - val_loss: 0.0091 - val_mae: 0.0697\n",
      "Epoch 3/20\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 28ms/step - loss: 0.0111 - mae: 0.0722 - val_loss: 0.0059 - val_mae: 0.0565\n",
      "Epoch 4/20\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 29ms/step - loss: 0.0114 - mae: 0.0730 - val_loss: 0.0054 - val_mae: 0.0533\n",
      "Epoch 5/20\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 28ms/step - loss: 0.0111 - mae: 0.0714 - val_loss: 0.0059 - val_mae: 0.0549\n",
      "Epoch 6/20\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 29ms/step - loss: 0.0107 - mae: 0.0707 - val_loss: 0.0055 - val_mae: 0.0546\n",
      "Epoch 7/20\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 29ms/step - loss: 0.0108 - mae: 0.0708 - val_loss: 0.0073 - val_mae: 0.0637\n",
      "Epoch 8/20\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 28ms/step - loss: 0.0106 - mae: 0.0699 - val_loss: 0.0055 - val_mae: 0.0537\n",
      "Epoch 9/20\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 27ms/step - loss: 0.0109 - mae: 0.0710 - val_loss: 0.0055 - val_mae: 0.0538\n",
      "Epoch 10/20\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 28ms/step - loss: 0.0108 - mae: 0.0704 - val_loss: 0.0059 - val_mae: 0.0551\n",
      "Epoch 11/20\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 28ms/step - loss: 0.0107 - mae: 0.0698 - val_loss: 0.0056 - val_mae: 0.0548\n",
      "Epoch 12/20\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 28ms/step - loss: 0.0106 - mae: 0.0699 - val_loss: 0.0054 - val_mae: 0.0538\n",
      "Epoch 13/20\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 28ms/step - loss: 0.0105 - mae: 0.0704 - val_loss: 0.0057 - val_mae: 0.0545\n",
      "Epoch 14/20\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 28ms/step - loss: 0.0104 - mae: 0.0698 - val_loss: 0.0054 - val_mae: 0.0533\n",
      "Epoch 15/20\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 28ms/step - loss: 0.0108 - mae: 0.0707 - val_loss: 0.0055 - val_mae: 0.0551\n",
      "Epoch 16/20\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 28ms/step - loss: 0.0106 - mae: 0.0700 - val_loss: 0.0059 - val_mae: 0.0560\n",
      "Epoch 17/20\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 28ms/step - loss: 0.0106 - mae: 0.0698 - val_loss: 0.0055 - val_mae: 0.0534\n",
      "Epoch 18/20\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 28ms/step - loss: 0.0104 - mae: 0.0694 - val_loss: 0.0053 - val_mae: 0.0537\n",
      "Epoch 19/20\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 27ms/step - loss: 0.0104 - mae: 0.0687 - val_loss: 0.0056 - val_mae: 0.0539\n",
      "Epoch 20/20\n",
      "\u001b[1m1083/1083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 28ms/step - loss: 0.0104 - mae: 0.0689 - val_loss: 0.0063 - val_mae: 0.0567\n",
      "\u001b[1m136/136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step\n",
      "✅ Done with onion_Chikmagalur_daily.csv | MAE=395.5, RMSE=551.73, R2=0.53, MAPE=18.64%, Accuracy=81.36%\n",
      "\n",
      "🚀 Processing: onion_Chitradurga_daily.csv\n",
      "Epoch 1/20\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 27ms/step - loss: 0.0557 - mae: 0.1788 - val_loss: 0.0015 - val_mae: 0.0360\n",
      "Epoch 2/20\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 26ms/step - loss: 0.0365 - mae: 0.1332 - val_loss: 2.7929e-04 - val_mae: 0.0105\n",
      "Epoch 3/20\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - loss: 0.0316 - mae: 0.1216 - val_loss: 6.7666e-04 - val_mae: 0.0222\n",
      "Epoch 4/20\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - loss: 0.0325 - mae: 0.1217 - val_loss: 3.0143e-04 - val_mae: 0.0129\n",
      "Epoch 5/20\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - loss: 0.0303 - mae: 0.1168 - val_loss: 2.1287e-04 - val_mae: 0.0100\n",
      "Epoch 6/20\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 26ms/step - loss: 0.0323 - mae: 0.1186 - val_loss: 0.0027 - val_mae: 0.0461\n",
      "Epoch 7/20\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 28ms/step - loss: 0.0304 - mae: 0.1159 - val_loss: 2.1592e-04 - val_mae: 0.0106\n",
      "Epoch 8/20\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - loss: 0.0310 - mae: 0.1177 - val_loss: 8.8407e-04 - val_mae: 0.0283\n",
      "Epoch 9/20\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - loss: 0.0317 - mae: 0.1181 - val_loss: 0.0029 - val_mae: 0.0509\n",
      "Epoch 10/20\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 28ms/step - loss: 0.0312 - mae: 0.1159 - val_loss: 5.2846e-04 - val_mae: 0.0210\n",
      "Epoch 11/20\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 26ms/step - loss: 0.0308 - mae: 0.1150 - val_loss: 5.4006e-04 - val_mae: 0.0192\n",
      "Epoch 12/20\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - loss: 0.0318 - mae: 0.1155 - val_loss: 1.9205e-04 - val_mae: 0.0067\n",
      "Epoch 13/20\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 26ms/step - loss: 0.0301 - mae: 0.1130 - val_loss: 3.8033e-04 - val_mae: 0.0147\n",
      "Epoch 14/20\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - loss: 0.0317 - mae: 0.1164 - val_loss: 3.6514e-04 - val_mae: 0.0167\n",
      "Epoch 15/20\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - loss: 0.0284 - mae: 0.1080 - val_loss: 0.0011 - val_mae: 0.0322\n",
      "Epoch 16/20\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 25ms/step - loss: 0.0278 - mae: 0.1084 - val_loss: 2.8919e-04 - val_mae: 0.0126\n",
      "Epoch 17/20\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - loss: 0.0271 - mae: 0.1071 - val_loss: 1.1332e-04 - val_mae: 0.0056\n",
      "Epoch 18/20\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 26ms/step - loss: 0.0272 - mae: 0.1066 - val_loss: 2.1994e-04 - val_mae: 0.0123\n",
      "Epoch 19/20\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - loss: 0.0272 - mae: 0.1051 - val_loss: 2.5170e-04 - val_mae: 0.0128\n",
      "Epoch 20/20\n",
      "\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - loss: 0.0253 - mae: 0.1018 - val_loss: 4.6167e-04 - val_mae: 0.0202\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
      "✅ Done with onion_Chitradurga_daily.csv | MAE=68.02, RMSE=72.4, R2=0.95, MAPE=3.9%, Accuracy=96.1%\n",
      "\n",
      "🚀 Processing: onion_Davangere_daily.csv\n",
      "Epoch 1/20\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 27ms/step - loss: 0.0010 - mae: 0.0228 - val_loss: 0.0017 - val_mae: 0.0206\n",
      "Epoch 2/20\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 26ms/step - loss: 8.1371e-04 - mae: 0.0198 - val_loss: 0.0016 - val_mae: 0.0144\n",
      "Epoch 3/20\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 27ms/step - loss: 8.7947e-04 - mae: 0.0194 - val_loss: 0.0022 - val_mae: 0.0221\n",
      "Epoch 4/20\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 25ms/step - loss: 8.0727e-04 - mae: 0.0189 - val_loss: 0.0018 - val_mae: 0.0153\n",
      "Epoch 5/20\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 23ms/step - loss: 7.6921e-04 - mae: 0.0192 - val_loss: 0.0022 - val_mae: 0.0224\n",
      "Epoch 6/20\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 24ms/step - loss: 7.2561e-04 - mae: 0.0184 - val_loss: 0.0019 - val_mae: 0.0160\n",
      "Epoch 7/20\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 24ms/step - loss: 7.8321e-04 - mae: 0.0183 - val_loss: 0.0021 - val_mae: 0.0186\n",
      "Epoch 8/20\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 23ms/step - loss: 7.0364e-04 - mae: 0.0178 - val_loss: 0.0020 - val_mae: 0.0173\n",
      "Epoch 9/20\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - loss: 8.3044e-04 - mae: 0.0185 - val_loss: 0.0020 - val_mae: 0.0176\n",
      "Epoch 10/20\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 23ms/step - loss: 7.4311e-04 - mae: 0.0182 - val_loss: 0.0020 - val_mae: 0.0188\n",
      "Epoch 11/20\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 23ms/step - loss: 6.9525e-04 - mae: 0.0176 - val_loss: 0.0017 - val_mae: 0.0155\n",
      "Epoch 12/20\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 24ms/step - loss: 7.0958e-04 - mae: 0.0180 - val_loss: 0.0020 - val_mae: 0.0223\n",
      "Epoch 13/20\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 24ms/step - loss: 7.4030e-04 - mae: 0.0180 - val_loss: 0.0020 - val_mae: 0.0191\n",
      "Epoch 14/20\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 24ms/step - loss: 7.0806e-04 - mae: 0.0179 - val_loss: 0.0020 - val_mae: 0.0193\n",
      "Epoch 15/20\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - loss: 6.5795e-04 - mae: 0.0175 - val_loss: 0.0018 - val_mae: 0.0179\n",
      "Epoch 16/20\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 23ms/step - loss: 7.8670e-04 - mae: 0.0180 - val_loss: 0.0019 - val_mae: 0.0170\n",
      "Epoch 17/20\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 24ms/step - loss: 6.5029e-04 - mae: 0.0174 - val_loss: 0.0022 - val_mae: 0.0223\n",
      "Epoch 18/20\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 23ms/step - loss: 6.3058e-04 - mae: 0.0170 - val_loss: 0.0017 - val_mae: 0.0168\n",
      "Epoch 19/20\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 25ms/step - loss: 6.7071e-04 - mae: 0.0179 - val_loss: 0.0016 - val_mae: 0.0154\n",
      "Epoch 20/20\n",
      "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 24ms/step - loss: 6.2925e-04 - mae: 0.0171 - val_loss: 0.0016 - val_mae: 0.0161\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n",
      "✅ Done with onion_Davangere_daily.csv | MAE=205.61, RMSE=514.39, R2=0.69, MAPE=12.98%, Accuracy=87.02%\n",
      "\n",
      "🚀 Processing: onion_Dharwad_daily.csv\n",
      "Epoch 1/20\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 25ms/step - loss: 0.0025 - mae: 0.0318 - val_loss: 6.5152e-04 - val_mae: 0.0156\n",
      "Epoch 2/20\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - loss: 7.9837e-04 - mae: 0.0184 - val_loss: 6.8468e-04 - val_mae: 0.0171\n",
      "Epoch 3/20\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - loss: 7.7075e-04 - mae: 0.0173 - val_loss: 6.0224e-04 - val_mae: 0.0152\n",
      "Epoch 4/20\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - loss: 6.8673e-04 - mae: 0.0161 - val_loss: 5.3640e-04 - val_mae: 0.0145\n",
      "Epoch 5/20\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - loss: 7.2812e-04 - mae: 0.0166 - val_loss: 5.7375e-04 - val_mae: 0.0151\n",
      "Epoch 6/20\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - loss: 6.5255e-04 - mae: 0.0158 - val_loss: 5.2697e-04 - val_mae: 0.0136\n",
      "Epoch 7/20\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - loss: 6.9869e-04 - mae: 0.0167 - val_loss: 5.0613e-04 - val_mae: 0.0134\n",
      "Epoch 8/20\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 7.2034e-04 - mae: 0.0167 - val_loss: 5.0323e-04 - val_mae: 0.0130\n",
      "Epoch 9/20\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - loss: 6.3345e-04 - mae: 0.0153 - val_loss: 5.5055e-04 - val_mae: 0.0146\n",
      "Epoch 10/20\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - loss: 5.2748e-04 - mae: 0.0152 - val_loss: 5.0088e-04 - val_mae: 0.0128\n",
      "Epoch 11/20\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - loss: 6.4775e-04 - mae: 0.0160 - val_loss: 5.2339e-04 - val_mae: 0.0145\n",
      "Epoch 12/20\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - loss: 7.4040e-04 - mae: 0.0168 - val_loss: 5.4857e-04 - val_mae: 0.0153\n",
      "Epoch 13/20\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 6.6586e-04 - mae: 0.0166 - val_loss: 5.7125e-04 - val_mae: 0.0145\n",
      "Epoch 14/20\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - loss: 7.7130e-04 - mae: 0.0172 - val_loss: 5.3196e-04 - val_mae: 0.0149\n",
      "Epoch 15/20\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - loss: 5.7423e-04 - mae: 0.0155 - val_loss: 5.5270e-04 - val_mae: 0.0138\n",
      "Epoch 16/20\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - loss: 5.7683e-04 - mae: 0.0153 - val_loss: 4.9389e-04 - val_mae: 0.0130\n",
      "Epoch 17/20\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - loss: 5.7555e-04 - mae: 0.0155 - val_loss: 5.8656e-04 - val_mae: 0.0156\n",
      "Epoch 18/20\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - loss: 6.8099e-04 - mae: 0.0157 - val_loss: 4.9784e-04 - val_mae: 0.0130\n",
      "Epoch 19/20\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - loss: 6.4487e-04 - mae: 0.0155 - val_loss: 6.6462e-04 - val_mae: 0.0171\n",
      "Epoch 20/20\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - loss: 6.0219e-04 - mae: 0.0154 - val_loss: 5.0072e-04 - val_mae: 0.0130\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "✅ Done with onion_Dharwad_daily.csv | MAE=96.56, RMSE=166.48, R2=0.95, MAPE=6.48%, Accuracy=93.52%\n",
      "\n",
      "🚀 Processing: onion_Gadag_daily.csv\n",
      "Epoch 1/20\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 27ms/step - loss: 0.0125 - mae: 0.0660 - val_loss: 4.9188e-04 - val_mae: 0.0124\n",
      "Epoch 2/20\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - loss: 0.0022 - mae: 0.0293 - val_loss: 3.7468e-04 - val_mae: 0.0074\n",
      "Epoch 3/20\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - loss: 0.0018 - mae: 0.0269 - val_loss: 3.6263e-04 - val_mae: 0.0107\n",
      "Epoch 4/20\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - loss: 0.0017 - mae: 0.0245 - val_loss: 5.3220e-04 - val_mae: 0.0181\n",
      "Epoch 5/20\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - loss: 0.0013 - mae: 0.0235 - val_loss: 0.0011 - val_mae: 0.0291\n",
      "Epoch 6/20\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - loss: 0.0015 - mae: 0.0237 - val_loss: 3.3488e-04 - val_mae: 0.0111\n",
      "Epoch 7/20\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - loss: 0.0011 - mae: 0.0207 - val_loss: 6.8971e-04 - val_mae: 0.0207\n",
      "Epoch 8/20\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - loss: 0.0011 - mae: 0.0211 - val_loss: 2.3401e-04 - val_mae: 0.0085\n",
      "Epoch 9/20\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - loss: 0.0011 - mae: 0.0201 - val_loss: 2.2900e-04 - val_mae: 0.0085\n",
      "Epoch 10/20\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - loss: 0.0011 - mae: 0.0214 - val_loss: 2.3991e-04 - val_mae: 0.0067\n",
      "Epoch 11/20\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - loss: 0.0010 - mae: 0.0193 - val_loss: 2.4290e-04 - val_mae: 0.0089\n",
      "Epoch 12/20\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - loss: 0.0011 - mae: 0.0204 - val_loss: 3.2149e-04 - val_mae: 0.0133\n",
      "Epoch 13/20\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - loss: 8.4156e-04 - mae: 0.0188 - val_loss: 7.4868e-04 - val_mae: 0.0216\n",
      "Epoch 14/20\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - loss: 0.0010 - mae: 0.0196 - val_loss: 2.4684e-04 - val_mae: 0.0077\n",
      "Epoch 15/20\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - loss: 9.4146e-04 - mae: 0.0192 - val_loss: 2.3895e-04 - val_mae: 0.0094\n",
      "Epoch 16/20\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - loss: 9.3109e-04 - mae: 0.0192 - val_loss: 2.0723e-04 - val_mae: 0.0059\n",
      "Epoch 17/20\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - loss: 9.5549e-04 - mae: 0.0190 - val_loss: 2.5195e-04 - val_mae: 0.0098\n",
      "Epoch 18/20\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - loss: 9.3232e-04 - mae: 0.0198 - val_loss: 2.1955e-04 - val_mae: 0.0081\n",
      "Epoch 19/20\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - loss: 9.5323e-04 - mae: 0.0189 - val_loss: 3.4028e-04 - val_mae: 0.0125\n",
      "Epoch 20/20\n",
      "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - loss: 9.8763e-04 - mae: 0.0198 - val_loss: 2.4579e-04 - val_mae: 0.0089\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step\n",
      "✅ Done with onion_Gadag_daily.csv | MAE=30.05, RMSE=52.91, R2=0.99, MAPE=1.96%, Accuracy=98.04%\n",
      "\n",
      "🚀 Processing: onion_Hassan_daily.csv\n",
      "Epoch 1/20\n",
      "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 28ms/step - loss: 0.0056 - mae: 0.0516 - val_loss: 0.0055 - val_mae: 0.0472\n",
      "Epoch 2/20\n",
      "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 27ms/step - loss: 0.0043 - mae: 0.0452 - val_loss: 0.0053 - val_mae: 0.0488\n",
      "Epoch 3/20\n",
      "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 27ms/step - loss: 0.0042 - mae: 0.0444 - val_loss: 0.0057 - val_mae: 0.0499\n",
      "Epoch 4/20\n",
      "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 27ms/step - loss: 0.0041 - mae: 0.0439 - val_loss: 0.0061 - val_mae: 0.0528\n",
      "Epoch 5/20\n",
      "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 27ms/step - loss: 0.0043 - mae: 0.0441 - val_loss: 0.0052 - val_mae: 0.0466\n",
      "Epoch 6/20\n",
      "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 27ms/step - loss: 0.0041 - mae: 0.0437 - val_loss: 0.0052 - val_mae: 0.0474\n",
      "Epoch 7/20\n",
      "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 28ms/step - loss: 0.0041 - mae: 0.0446 - val_loss: 0.0055 - val_mae: 0.0489\n",
      "Epoch 8/20\n",
      "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 27ms/step - loss: 0.0041 - mae: 0.0441 - val_loss: 0.0052 - val_mae: 0.0473\n",
      "Epoch 9/20\n",
      "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 27ms/step - loss: 0.0038 - mae: 0.0431 - val_loss: 0.0053 - val_mae: 0.0478\n",
      "Epoch 10/20\n",
      "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 27ms/step - loss: 0.0040 - mae: 0.0438 - val_loss: 0.0052 - val_mae: 0.0476\n",
      "Epoch 11/20\n",
      "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 28ms/step - loss: 0.0041 - mae: 0.0439 - val_loss: 0.0053 - val_mae: 0.0476\n",
      "Epoch 12/20\n",
      "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 27ms/step - loss: 0.0041 - mae: 0.0440 - val_loss: 0.0053 - val_mae: 0.0478\n",
      "Epoch 13/20\n",
      "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 27ms/step - loss: 0.0039 - mae: 0.0437 - val_loss: 0.0053 - val_mae: 0.0476\n",
      "Epoch 14/20\n",
      "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 27ms/step - loss: 0.0039 - mae: 0.0432 - val_loss: 0.0055 - val_mae: 0.0485\n",
      "Epoch 15/20\n",
      "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 27ms/step - loss: 0.0039 - mae: 0.0436 - val_loss: 0.0056 - val_mae: 0.0484\n",
      "Epoch 16/20\n",
      "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 27ms/step - loss: 0.0040 - mae: 0.0441 - val_loss: 0.0054 - val_mae: 0.0480\n",
      "Epoch 17/20\n",
      "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 27ms/step - loss: 0.0039 - mae: 0.0433 - val_loss: 0.0052 - val_mae: 0.0474\n",
      "Epoch 18/20\n",
      "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 27ms/step - loss: 0.0041 - mae: 0.0436 - val_loss: 0.0052 - val_mae: 0.0473\n",
      "Epoch 19/20\n",
      "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 27ms/step - loss: 0.0040 - mae: 0.0436 - val_loss: 0.0052 - val_mae: 0.0471\n",
      "Epoch 20/20\n",
      "\u001b[1m1156/1156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 27ms/step - loss: 0.0038 - mae: 0.0427 - val_loss: 0.0055 - val_mae: 0.0485\n",
      "\u001b[1m145/145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step\n",
      "✅ Done with onion_Hassan_daily.csv | MAE=485.45, RMSE=739.12, R2=0.26, MAPE=27.39%, Accuracy=72.61%\n",
      "\n",
      "🚀 Processing: onion_Haveri_daily.csv\n",
      "Epoch 1/20\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 28ms/step - loss: 0.0088 - mae: 0.0690 - val_loss: 0.0017 - val_mae: 0.0308\n",
      "Epoch 2/20\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 26ms/step - loss: 0.0051 - mae: 0.0488 - val_loss: 0.0015 - val_mae: 0.0263\n",
      "Epoch 3/20\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 27ms/step - loss: 0.0044 - mae: 0.0452 - val_loss: 0.0017 - val_mae: 0.0283\n",
      "Epoch 4/20\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 27ms/step - loss: 0.0047 - mae: 0.0454 - val_loss: 0.0017 - val_mae: 0.0274\n",
      "Epoch 5/20\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 26ms/step - loss: 0.0046 - mae: 0.0454 - val_loss: 0.0017 - val_mae: 0.0286\n",
      "Epoch 6/20\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 26ms/step - loss: 0.0044 - mae: 0.0440 - val_loss: 0.0016 - val_mae: 0.0255\n",
      "Epoch 7/20\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 27ms/step - loss: 0.0047 - mae: 0.0439 - val_loss: 0.0016 - val_mae: 0.0274\n",
      "Epoch 8/20\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 26ms/step - loss: 0.0044 - mae: 0.0442 - val_loss: 0.0017 - val_mae: 0.0272\n",
      "Epoch 9/20\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 26ms/step - loss: 0.0045 - mae: 0.0435 - val_loss: 0.0016 - val_mae: 0.0259\n",
      "Epoch 10/20\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 26ms/step - loss: 0.0045 - mae: 0.0440 - val_loss: 0.0016 - val_mae: 0.0266\n",
      "Epoch 11/20\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 26ms/step - loss: 0.0044 - mae: 0.0428 - val_loss: 0.0017 - val_mae: 0.0271\n",
      "Epoch 12/20\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 27ms/step - loss: 0.0044 - mae: 0.0439 - val_loss: 0.0019 - val_mae: 0.0293\n",
      "Epoch 13/20\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 26ms/step - loss: 0.0042 - mae: 0.0411 - val_loss: 0.0021 - val_mae: 0.0330\n",
      "Epoch 14/20\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 26ms/step - loss: 0.0044 - mae: 0.0426 - val_loss: 0.0016 - val_mae: 0.0269\n",
      "Epoch 15/20\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 26ms/step - loss: 0.0040 - mae: 0.0414 - val_loss: 0.0016 - val_mae: 0.0265\n",
      "Epoch 16/20\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 26ms/step - loss: 0.0041 - mae: 0.0421 - val_loss: 0.0016 - val_mae: 0.0270\n",
      "Epoch 17/20\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 24ms/step - loss: 0.0045 - mae: 0.0430 - val_loss: 0.0016 - val_mae: 0.0260\n",
      "Epoch 18/20\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 25ms/step - loss: 0.0043 - mae: 0.0418 - val_loss: 0.0017 - val_mae: 0.0278\n",
      "Epoch 19/20\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 24ms/step - loss: 0.0045 - mae: 0.0420 - val_loss: 0.0018 - val_mae: 0.0289\n",
      "Epoch 20/20\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 24ms/step - loss: 0.0040 - mae: 0.0411 - val_loss: 0.0016 - val_mae: 0.0268\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step\n",
      "✅ Done with onion_Haveri_daily.csv | MAE=160.72, RMSE=238.55, R2=0.58, MAPE=9.83%, Accuracy=90.17%\n",
      "\n",
      "🚀 Processing: onion_Kolar_daily.csv\n",
      "Epoch 1/20\n",
      "\u001b[1m1943/1943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 26ms/step - loss: 0.0014 - mae: 0.0256 - val_loss: 6.1133e-04 - val_mae: 0.0166\n",
      "Epoch 2/20\n",
      "\u001b[1m1943/1943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 24ms/step - loss: 0.0012 - mae: 0.0236 - val_loss: 8.2272e-04 - val_mae: 0.0198\n",
      "Epoch 3/20\n",
      "\u001b[1m1943/1943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 25ms/step - loss: 0.0011 - mae: 0.0232 - val_loss: 7.4360e-04 - val_mae: 0.0184\n",
      "Epoch 4/20\n",
      "\u001b[1m1943/1943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 23ms/step - loss: 0.0012 - mae: 0.0229 - val_loss: 6.8804e-04 - val_mae: 0.0180\n",
      "Epoch 5/20\n",
      "\u001b[1m1943/1943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 24ms/step - loss: 0.0011 - mae: 0.0224 - val_loss: 6.1195e-04 - val_mae: 0.0166\n",
      "Epoch 6/20\n",
      "\u001b[1m1943/1943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 23ms/step - loss: 0.0011 - mae: 0.0224 - val_loss: 6.2280e-04 - val_mae: 0.0167\n",
      "Epoch 7/20\n",
      "\u001b[1m1943/1943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 23ms/step - loss: 0.0011 - mae: 0.0224 - val_loss: 6.0701e-04 - val_mae: 0.0164\n",
      "Epoch 8/20\n",
      "\u001b[1m1943/1943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 24ms/step - loss: 0.0012 - mae: 0.0228 - val_loss: 6.0133e-04 - val_mae: 0.0162\n",
      "Epoch 9/20\n",
      "\u001b[1m1943/1943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 25ms/step - loss: 0.0012 - mae: 0.0225 - val_loss: 6.4009e-04 - val_mae: 0.0167\n",
      "Epoch 10/20\n",
      "\u001b[1m1943/1943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 25ms/step - loss: 0.0011 - mae: 0.0219 - val_loss: 6.6259e-04 - val_mae: 0.0173\n",
      "Epoch 11/20\n",
      "\u001b[1m1943/1943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 26ms/step - loss: 0.0012 - mae: 0.0223 - val_loss: 6.6736e-04 - val_mae: 0.0177\n",
      "Epoch 12/20\n",
      "\u001b[1m1943/1943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 26ms/step - loss: 0.0011 - mae: 0.0222 - val_loss: 6.0887e-04 - val_mae: 0.0164\n",
      "Epoch 13/20\n",
      "\u001b[1m1943/1943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 26ms/step - loss: 0.0011 - mae: 0.0222 - val_loss: 6.0180e-04 - val_mae: 0.0163\n",
      "Epoch 14/20\n",
      "\u001b[1m1943/1943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 26ms/step - loss: 0.0011 - mae: 0.0221 - val_loss: 6.0777e-04 - val_mae: 0.0163\n",
      "Epoch 15/20\n",
      "\u001b[1m1943/1943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 26ms/step - loss: 0.0011 - mae: 0.0218 - val_loss: 7.1473e-04 - val_mae: 0.0182\n",
      "Epoch 16/20\n",
      "\u001b[1m1943/1943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 26ms/step - loss: 0.0011 - mae: 0.0220 - val_loss: 6.9779e-04 - val_mae: 0.0180\n",
      "Epoch 17/20\n",
      "\u001b[1m1943/1943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 26ms/step - loss: 0.0011 - mae: 0.0221 - val_loss: 6.7417e-04 - val_mae: 0.0177\n",
      "Epoch 18/20\n",
      "\u001b[1m1943/1943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 26ms/step - loss: 0.0011 - mae: 0.0223 - val_loss: 5.9999e-04 - val_mae: 0.0162\n",
      "Epoch 19/20\n",
      "\u001b[1m1943/1943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 26ms/step - loss: 0.0011 - mae: 0.0221 - val_loss: 6.1943e-04 - val_mae: 0.0166\n",
      "Epoch 20/20\n",
      "\u001b[1m1943/1943\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 26ms/step - loss: 0.0011 - mae: 0.0222 - val_loss: 6.0428e-04 - val_mae: 0.0163\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step\n",
      "✅ Done with onion_Kolar_daily.csv | MAE=372.18, RMSE=562.69, R2=0.64, MAPE=16.85%, Accuracy=83.15%\n",
      "\n",
      "🚀 Processing: onion_MadikeriKodagu_daily.csv\n",
      "Epoch 1/20\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 28ms/step - loss: 0.0203 - mae: 0.0971 - val_loss: 2.0362e-04 - val_mae: 0.0142\n",
      "Epoch 2/20\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - loss: 0.0062 - mae: 0.0573 - val_loss: 2.9285e-04 - val_mae: 0.0170\n",
      "Epoch 3/20\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - loss: 0.0051 - mae: 0.0509 - val_loss: 2.5203e-04 - val_mae: 0.0159\n",
      "Epoch 4/20\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - loss: 0.0043 - mae: 0.0466 - val_loss: 6.4159e-04 - val_mae: 0.0251\n",
      "Epoch 5/20\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - loss: 0.0049 - mae: 0.0488 - val_loss: 1.0023e-04 - val_mae: 0.0100\n",
      "Epoch 6/20\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - loss: 0.0042 - mae: 0.0441 - val_loss: 0.0011 - val_mae: 0.0333\n",
      "Epoch 7/20\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - loss: 0.0040 - mae: 0.0432 - val_loss: 0.0020 - val_mae: 0.0448\n",
      "Epoch 8/20\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - loss: 0.0035 - mae: 0.0399 - val_loss: 3.5832e-06 - val_mae: 0.0016\n",
      "Epoch 9/20\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - loss: 0.0034 - mae: 0.0376 - val_loss: 2.0399e-04 - val_mae: 0.0140\n",
      "Epoch 10/20\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - loss: 0.0031 - mae: 0.0354 - val_loss: 2.9104e-04 - val_mae: 0.0166\n",
      "Epoch 11/20\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - loss: 0.0029 - mae: 0.0336 - val_loss: 4.3790e-05 - val_mae: 0.0062\n",
      "Epoch 12/20\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - loss: 0.0030 - mae: 0.0335 - val_loss: 1.2967e-04 - val_mae: 0.0114\n",
      "Epoch 13/20\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - loss: 0.0028 - mae: 0.0328 - val_loss: 1.6175e-04 - val_mae: 0.0124\n",
      "Epoch 14/20\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - loss: 0.0028 - mae: 0.0318 - val_loss: 1.0061e-05 - val_mae: 0.0031\n",
      "Epoch 15/20\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - loss: 0.0026 - mae: 0.0302 - val_loss: 4.7102e-04 - val_mae: 0.0213\n",
      "Epoch 16/20\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - loss: 0.0027 - mae: 0.0309 - val_loss: 2.5158e-04 - val_mae: 0.0157\n",
      "Epoch 17/20\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0026 - mae: 0.0286 - val_loss: 1.0612e-04 - val_mae: 0.0103\n",
      "Epoch 18/20\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - loss: 0.0027 - mae: 0.0295 - val_loss: 1.1133e-04 - val_mae: 0.0105\n",
      "Epoch 19/20\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - loss: 0.0028 - mae: 0.0293 - val_loss: 4.7333e-04 - val_mae: 0.0214\n",
      "Epoch 20/20\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - loss: 0.0023 - mae: 0.0279 - val_loss: 5.1307e-04 - val_mae: 0.0226\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step\n",
      "✅ Done with onion_MadikeriKodagu_daily.csv | MAE=56.35, RMSE=56.45, R2=0.85, MAPE=2.87%, Accuracy=97.13%\n",
      "\n",
      "🚀 Processing: onion_Mandya_daily.csv\n",
      "Epoch 1/20\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 23ms/step - loss: 0.0043 - mae: 0.0528 - val_loss: 0.0039 - val_mae: 0.0533\n",
      "Epoch 2/20\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 23ms/step - loss: 0.0033 - mae: 0.0459 - val_loss: 0.0027 - val_mae: 0.0427\n",
      "Epoch 3/20\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 22ms/step - loss: 0.0032 - mae: 0.0439 - val_loss: 0.0047 - val_mae: 0.0571\n",
      "Epoch 4/20\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 23ms/step - loss: 0.0031 - mae: 0.0443 - val_loss: 0.0029 - val_mae: 0.0451\n",
      "Epoch 5/20\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 23ms/step - loss: 0.0029 - mae: 0.0430 - val_loss: 0.0027 - val_mae: 0.0432\n",
      "Epoch 6/20\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 24ms/step - loss: 0.0030 - mae: 0.0436 - val_loss: 0.0027 - val_mae: 0.0423\n",
      "Epoch 7/20\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 23ms/step - loss: 0.0028 - mae: 0.0420 - val_loss: 0.0030 - val_mae: 0.0458\n",
      "Epoch 8/20\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 24ms/step - loss: 0.0030 - mae: 0.0430 - val_loss: 0.0040 - val_mae: 0.0524\n",
      "Epoch 9/20\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 23ms/step - loss: 0.0029 - mae: 0.0427 - val_loss: 0.0028 - val_mae: 0.0421\n",
      "Epoch 10/20\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 24ms/step - loss: 0.0030 - mae: 0.0424 - val_loss: 0.0029 - val_mae: 0.0427\n",
      "Epoch 11/20\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 23ms/step - loss: 0.0028 - mae: 0.0419 - val_loss: 0.0032 - val_mae: 0.0462\n",
      "Epoch 12/20\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 23ms/step - loss: 0.0027 - mae: 0.0416 - val_loss: 0.0028 - val_mae: 0.0424\n",
      "Epoch 13/20\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 24ms/step - loss: 0.0028 - mae: 0.0420 - val_loss: 0.0027 - val_mae: 0.0428\n",
      "Epoch 14/20\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 24ms/step - loss: 0.0027 - mae: 0.0411 - val_loss: 0.0030 - val_mae: 0.0450\n",
      "Epoch 15/20\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 24ms/step - loss: 0.0027 - mae: 0.0412 - val_loss: 0.0030 - val_mae: 0.0451\n",
      "Epoch 16/20\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 23ms/step - loss: 0.0026 - mae: 0.0409 - val_loss: 0.0026 - val_mae: 0.0428\n",
      "Epoch 17/20\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 24ms/step - loss: 0.0027 - mae: 0.0413 - val_loss: 0.0032 - val_mae: 0.0466\n",
      "Epoch 18/20\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 25ms/step - loss: 0.0026 - mae: 0.0407 - val_loss: 0.0032 - val_mae: 0.0469\n",
      "Epoch 19/20\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 25ms/step - loss: 0.0027 - mae: 0.0416 - val_loss: 0.0033 - val_mae: 0.0483\n",
      "Epoch 20/20\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 25ms/step - loss: 0.0026 - mae: 0.0407 - val_loss: 0.0030 - val_mae: 0.0445\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
      "✅ Done with onion_Mandya_daily.csv | MAE=453.42, RMSE=556.16, R2=0.36, MAPE=26.03%, Accuracy=73.97%\n",
      "\n",
      "🚀 Processing: onion_MangaloreDakshin_Kannad_daily.csv\n",
      "Epoch 1/20\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 27ms/step - loss: 0.0127 - mae: 0.0712 - val_loss: 0.0020 - val_mae: 0.0331\n",
      "Epoch 2/20\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - loss: 0.0014 - mae: 0.0273 - val_loss: 0.0021 - val_mae: 0.0337\n",
      "Epoch 3/20\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - loss: 0.0012 - mae: 0.0252 - val_loss: 0.0019 - val_mae: 0.0319\n",
      "Epoch 4/20\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - loss: 0.0010 - mae: 0.0228 - val_loss: 0.0021 - val_mae: 0.0360\n",
      "Epoch 5/20\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - loss: 9.8980e-04 - mae: 0.0230 - val_loss: 0.0019 - val_mae: 0.0311\n",
      "Epoch 6/20\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - loss: 8.4852e-04 - mae: 0.0210 - val_loss: 0.0019 - val_mae: 0.0312\n",
      "Epoch 7/20\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - loss: 6.9231e-04 - mae: 0.0197 - val_loss: 0.0019 - val_mae: 0.0314\n",
      "Epoch 8/20\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - loss: 6.6753e-04 - mae: 0.0184 - val_loss: 0.0020 - val_mae: 0.0313\n",
      "Epoch 9/20\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - loss: 6.3972e-04 - mae: 0.0182 - val_loss: 0.0021 - val_mae: 0.0311\n",
      "Epoch 10/20\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - loss: 6.3414e-04 - mae: 0.0178 - val_loss: 0.0021 - val_mae: 0.0316\n",
      "Epoch 11/20\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - loss: 4.8862e-04 - mae: 0.0162 - val_loss: 0.0023 - val_mae: 0.0342\n",
      "Epoch 12/20\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - loss: 4.5444e-04 - mae: 0.0161 - val_loss: 0.0023 - val_mae: 0.0344\n",
      "Epoch 13/20\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - loss: 4.4623e-04 - mae: 0.0153 - val_loss: 0.0023 - val_mae: 0.0324\n",
      "Epoch 14/20\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - loss: 4.0067e-04 - mae: 0.0143 - val_loss: 0.0025 - val_mae: 0.0339\n",
      "Epoch 15/20\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - loss: 3.8213e-04 - mae: 0.0142 - val_loss: 0.0026 - val_mae: 0.0348\n",
      "Epoch 16/20\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - loss: 4.8307e-04 - mae: 0.0147 - val_loss: 0.0026 - val_mae: 0.0332\n",
      "Epoch 17/20\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - loss: 3.9963e-04 - mae: 0.0144 - val_loss: 0.0027 - val_mae: 0.0347\n",
      "Epoch 18/20\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - loss: 3.7442e-04 - mae: 0.0136 - val_loss: 0.0027 - val_mae: 0.0342\n",
      "Epoch 19/20\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - loss: 4.0146e-04 - mae: 0.0143 - val_loss: 0.0029 - val_mae: 0.0359\n",
      "Epoch 20/20\n",
      "\u001b[1m258/258\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - loss: 5.9170e-04 - mae: 0.0144 - val_loss: 0.0029 - val_mae: 0.0362\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step\n",
      "✅ Done with onion_MangaloreDakshin_Kannad_daily.csv | MAE=199.19, RMSE=298.9, R2=0.88, MAPE=11.1%, Accuracy=88.9%\n",
      "\n",
      "🚀 Processing: onion_Mysore_daily.csv\n",
      "Epoch 1/20\n",
      "\u001b[1m901/901\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 25ms/step - loss: 0.0011 - mae: 0.0252 - val_loss: 9.0114e-04 - val_mae: 0.0198\n",
      "Epoch 2/20\n",
      "\u001b[1m901/901\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 26ms/step - loss: 0.0010 - mae: 0.0227 - val_loss: 0.0011 - val_mae: 0.0225\n",
      "Epoch 3/20\n",
      "\u001b[1m901/901\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 26ms/step - loss: 8.8639e-04 - mae: 0.0219 - val_loss: 0.0011 - val_mae: 0.0227\n",
      "Epoch 4/20\n",
      "\u001b[1m901/901\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 26ms/step - loss: 9.9361e-04 - mae: 0.0221 - val_loss: 8.8736e-04 - val_mae: 0.0188\n",
      "Epoch 5/20\n",
      "\u001b[1m901/901\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 25ms/step - loss: 8.1978e-04 - mae: 0.0213 - val_loss: 0.0010 - val_mae: 0.0202\n",
      "Epoch 6/20\n",
      "\u001b[1m901/901\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 26ms/step - loss: 8.3120e-04 - mae: 0.0210 - val_loss: 8.7767e-04 - val_mae: 0.0187\n",
      "Epoch 7/20\n",
      "\u001b[1m901/901\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 26ms/step - loss: 9.8481e-04 - mae: 0.0216 - val_loss: 9.7105e-04 - val_mae: 0.0196\n",
      "Epoch 8/20\n",
      "\u001b[1m901/901\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 25ms/step - loss: 9.3510e-04 - mae: 0.0213 - val_loss: 9.4001e-04 - val_mae: 0.0196\n",
      "Epoch 9/20\n",
      "\u001b[1m901/901\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 25ms/step - loss: 9.2555e-04 - mae: 0.0211 - val_loss: 8.9842e-04 - val_mae: 0.0187\n",
      "Epoch 10/20\n",
      "\u001b[1m901/901\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 26ms/step - loss: 8.1526e-04 - mae: 0.0208 - val_loss: 0.0010 - val_mae: 0.0203\n",
      "Epoch 11/20\n",
      "\u001b[1m901/901\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 26ms/step - loss: 8.3652e-04 - mae: 0.0208 - val_loss: 9.4323e-04 - val_mae: 0.0196\n",
      "Epoch 12/20\n",
      "\u001b[1m901/901\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 26ms/step - loss: 7.4225e-04 - mae: 0.0206 - val_loss: 8.4834e-04 - val_mae: 0.0185\n",
      "Epoch 13/20\n",
      "\u001b[1m901/901\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 25ms/step - loss: 9.0040e-04 - mae: 0.0211 - val_loss: 9.2972e-04 - val_mae: 0.0193\n",
      "Epoch 14/20\n",
      "\u001b[1m901/901\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 25ms/step - loss: 7.3412e-04 - mae: 0.0202 - val_loss: 9.2446e-04 - val_mae: 0.0193\n",
      "Epoch 15/20\n",
      "\u001b[1m901/901\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 26ms/step - loss: 9.0051e-04 - mae: 0.0207 - val_loss: 9.9288e-04 - val_mae: 0.0194\n",
      "Epoch 16/20\n",
      "\u001b[1m901/901\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 25ms/step - loss: 8.0823e-04 - mae: 0.0208 - val_loss: 0.0010 - val_mae: 0.0207\n",
      "Epoch 17/20\n",
      "\u001b[1m901/901\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 26ms/step - loss: 8.6613e-04 - mae: 0.0205 - val_loss: 0.0010 - val_mae: 0.0198\n",
      "Epoch 18/20\n",
      "\u001b[1m901/901\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 26ms/step - loss: 9.5962e-04 - mae: 0.0208 - val_loss: 9.3115e-04 - val_mae: 0.0192\n",
      "Epoch 19/20\n",
      "\u001b[1m901/901\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 26ms/step - loss: 9.0831e-04 - mae: 0.0208 - val_loss: 9.5702e-04 - val_mae: 0.0196\n",
      "Epoch 20/20\n",
      "\u001b[1m901/901\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 26ms/step - loss: 7.8058e-04 - mae: 0.0205 - val_loss: 9.2340e-04 - val_mae: 0.0194\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step\n",
      "✅ Done with onion_Mysore_daily.csv | MAE=371.53, RMSE=583.44, R2=0.42, MAPE=19.0%, Accuracy=81.0%\n",
      "\n",
      "🚀 Processing: onion_Raichur_daily.csv\n",
      "Epoch 1/20\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 26ms/step - loss: 0.0030 - mae: 0.0338 - val_loss: 4.3097e-04 - val_mae: 0.0150\n",
      "Epoch 2/20\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - loss: 0.0014 - mae: 0.0248 - val_loss: 2.2373e-04 - val_mae: 0.0099\n",
      "Epoch 3/20\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - loss: 0.0011 - mae: 0.0219 - val_loss: 2.4703e-04 - val_mae: 0.0109\n",
      "Epoch 4/20\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - loss: 0.0011 - mae: 0.0220 - val_loss: 2.9561e-04 - val_mae: 0.0135\n",
      "Epoch 5/20\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - loss: 0.0010 - mae: 0.0211 - val_loss: 2.5648e-04 - val_mae: 0.0109\n",
      "Epoch 6/20\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - loss: 0.0011 - mae: 0.0214 - val_loss: 2.1332e-04 - val_mae: 0.0096\n",
      "Epoch 7/20\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - loss: 0.0010 - mae: 0.0216 - val_loss: 2.4989e-04 - val_mae: 0.0107\n",
      "Epoch 8/20\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - loss: 9.6868e-04 - mae: 0.0202 - val_loss: 2.6991e-04 - val_mae: 0.0125\n",
      "Epoch 9/20\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - loss: 0.0010 - mae: 0.0210 - val_loss: 2.7401e-04 - val_mae: 0.0114\n",
      "Epoch 10/20\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - loss: 0.0011 - mae: 0.0214 - val_loss: 5.1610e-04 - val_mae: 0.0197\n",
      "Epoch 11/20\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - loss: 9.5954e-04 - mae: 0.0213 - val_loss: 4.0229e-04 - val_mae: 0.0157\n",
      "Epoch 12/20\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - loss: 0.0010 - mae: 0.0214 - val_loss: 2.6314e-04 - val_mae: 0.0115\n",
      "Epoch 13/20\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - loss: 9.8166e-04 - mae: 0.0208 - val_loss: 2.4736e-04 - val_mae: 0.0107\n",
      "Epoch 14/20\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - loss: 9.5039e-04 - mae: 0.0205 - val_loss: 5.2067e-04 - val_mae: 0.0160\n",
      "Epoch 15/20\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - loss: 9.6296e-04 - mae: 0.0210 - val_loss: 2.6726e-04 - val_mae: 0.0113\n",
      "Epoch 16/20\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - loss: 9.6257e-04 - mae: 0.0201 - val_loss: 2.5389e-04 - val_mae: 0.0113\n",
      "Epoch 17/20\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - loss: 9.8722e-04 - mae: 0.0200 - val_loss: 2.3140e-04 - val_mae: 0.0101\n",
      "Epoch 18/20\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - loss: 9.9537e-04 - mae: 0.0203 - val_loss: 3.1376e-04 - val_mae: 0.0135\n",
      "Epoch 19/20\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - loss: 8.4981e-04 - mae: 0.0201 - val_loss: 4.9551e-04 - val_mae: 0.0161\n",
      "Epoch 20/20\n",
      "\u001b[1m301/301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - loss: 8.6239e-04 - mae: 0.0196 - val_loss: 4.9216e-04 - val_mae: 0.0190\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step\n",
      "✅ Done with onion_Raichur_daily.csv | MAE=162.11, RMSE=189.62, R2=0.9, MAPE=15.39%, Accuracy=84.61%\n",
      "\n",
      "🚀 Processing: onion_Shimoga_daily.csv\n",
      "Epoch 1/20\n",
      "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 22ms/step - loss: 0.0016 - mae: 0.0264 - val_loss: 0.0026 - val_mae: 0.0285\n",
      "Epoch 2/20\n",
      "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 20ms/step - loss: 0.0011 - mae: 0.0222 - val_loss: 0.0036 - val_mae: 0.0326\n",
      "Epoch 3/20\n",
      "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 0.0011 - mae: 0.0209 - val_loss: 0.0036 - val_mae: 0.0317\n",
      "Epoch 4/20\n",
      "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 21ms/step - loss: 9.2292e-04 - mae: 0.0196 - val_loss: 0.0036 - val_mae: 0.0303\n",
      "Epoch 5/20\n",
      "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 20ms/step - loss: 9.7540e-04 - mae: 0.0201 - val_loss: 0.0042 - val_mae: 0.0319\n",
      "Epoch 6/20\n",
      "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 21ms/step - loss: 8.9589e-04 - mae: 0.0192 - val_loss: 0.0039 - val_mae: 0.0329\n",
      "Epoch 7/20\n",
      "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 21ms/step - loss: 9.3690e-04 - mae: 0.0193 - val_loss: 0.0042 - val_mae: 0.0371\n",
      "Epoch 8/20\n",
      "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 20ms/step - loss: 0.0010 - mae: 0.0201 - val_loss: 0.0045 - val_mae: 0.0353\n",
      "Epoch 9/20\n",
      "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 21ms/step - loss: 9.2952e-04 - mae: 0.0192 - val_loss: 0.0037 - val_mae: 0.0315\n",
      "Epoch 10/20\n",
      "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 21ms/step - loss: 8.8988e-04 - mae: 0.0183 - val_loss: 0.0040 - val_mae: 0.0318\n",
      "Epoch 11/20\n",
      "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - loss: 9.6817e-04 - mae: 0.0193 - val_loss: 0.0037 - val_mae: 0.0317\n",
      "Epoch 12/20\n",
      "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 20ms/step - loss: 8.6153e-04 - mae: 0.0183 - val_loss: 0.0039 - val_mae: 0.0335\n",
      "Epoch 13/20\n",
      "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 21ms/step - loss: 8.5970e-04 - mae: 0.0183 - val_loss: 0.0035 - val_mae: 0.0317\n",
      "Epoch 14/20\n",
      "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 21ms/step - loss: 8.8578e-04 - mae: 0.0186 - val_loss: 0.0038 - val_mae: 0.0335\n",
      "Epoch 15/20\n",
      "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 21ms/step - loss: 9.0416e-04 - mae: 0.0187 - val_loss: 0.0039 - val_mae: 0.0328\n",
      "Epoch 16/20\n",
      "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 21ms/step - loss: 8.9649e-04 - mae: 0.0185 - val_loss: 0.0036 - val_mae: 0.0321\n",
      "Epoch 17/20\n",
      "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 21ms/step - loss: 9.2075e-04 - mae: 0.0191 - val_loss: 0.0041 - val_mae: 0.0342\n",
      "Epoch 18/20\n",
      "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 21ms/step - loss: 9.1651e-04 - mae: 0.0182 - val_loss: 0.0046 - val_mae: 0.0351\n",
      "Epoch 19/20\n",
      "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 21ms/step - loss: 8.3891e-04 - mae: 0.0181 - val_loss: 0.0045 - val_mae: 0.0355\n",
      "Epoch 20/20\n",
      "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 21ms/step - loss: 8.6028e-04 - mae: 0.0182 - val_loss: 0.0041 - val_mae: 0.0349\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step\n",
      "✅ Done with onion_Shimoga_daily.csv | MAE=558.72, RMSE=1026.83, R2=0.15, MAPE=148.82%, Accuracy=-48.82%\n",
      "\n",
      "🚀 Processing: onion_Tumkur_daily.csv\n",
      "Epoch 1/20\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 26ms/step - loss: 0.0030 - mae: 0.0418 - val_loss: 0.0360 - val_mae: 0.1595\n",
      "Epoch 2/20\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 26ms/step - loss: 0.0020 - mae: 0.0340 - val_loss: 0.0332 - val_mae: 0.1470\n",
      "Epoch 3/20\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 26ms/step - loss: 0.0019 - mae: 0.0328 - val_loss: 0.0322 - val_mae: 0.1399\n",
      "Epoch 4/20\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 24ms/step - loss: 0.0018 - mae: 0.0321 - val_loss: 0.0317 - val_mae: 0.1365\n",
      "Epoch 5/20\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 25ms/step - loss: 0.0018 - mae: 0.0317 - val_loss: 0.0330 - val_mae: 0.1368\n",
      "Epoch 6/20\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 26ms/step - loss: 0.0018 - mae: 0.0318 - val_loss: 0.0364 - val_mae: 0.1284\n",
      "Epoch 7/20\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 26ms/step - loss: 0.0018 - mae: 0.0316 - val_loss: 0.0365 - val_mae: 0.1333\n",
      "Epoch 8/20\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 25ms/step - loss: 0.0018 - mae: 0.0321 - val_loss: 0.0384 - val_mae: 0.1387\n",
      "Epoch 9/20\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 25ms/step - loss: 0.0018 - mae: 0.0320 - val_loss: 0.0397 - val_mae: 0.1286\n",
      "Epoch 10/20\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 26ms/step - loss: 0.0018 - mae: 0.0319 - val_loss: 0.0373 - val_mae: 0.1361\n",
      "Epoch 11/20\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 26ms/step - loss: 0.0017 - mae: 0.0308 - val_loss: 0.0427 - val_mae: 0.1315\n",
      "Epoch 12/20\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 25ms/step - loss: 0.0017 - mae: 0.0306 - val_loss: 0.0407 - val_mae: 0.1332\n",
      "Epoch 13/20\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 26ms/step - loss: 0.0018 - mae: 0.0312 - val_loss: 0.0409 - val_mae: 0.1378\n",
      "Epoch 14/20\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 26ms/step - loss: 0.0018 - mae: 0.0317 - val_loss: 0.0434 - val_mae: 0.1447\n",
      "Epoch 15/20\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 25ms/step - loss: 0.0017 - mae: 0.0306 - val_loss: 0.0432 - val_mae: 0.1422\n",
      "Epoch 16/20\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 26ms/step - loss: 0.0017 - mae: 0.0311 - val_loss: 0.0493 - val_mae: 0.1489\n",
      "Epoch 17/20\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 26ms/step - loss: 0.0018 - mae: 0.0314 - val_loss: 0.0445 - val_mae: 0.1461\n",
      "Epoch 18/20\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 26ms/step - loss: 0.0017 - mae: 0.0305 - val_loss: 0.0436 - val_mae: 0.1404\n",
      "Epoch 19/20\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 26ms/step - loss: 0.0018 - mae: 0.0312 - val_loss: 0.0479 - val_mae: 0.1537\n",
      "Epoch 20/20\n",
      "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 26ms/step - loss: 0.0017 - mae: 0.0311 - val_loss: 0.0461 - val_mae: 0.1400\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step\n",
      "✅ Done with onion_Tumkur_daily.csv | MAE=2218.88, RMSE=3402.62, R2=0.09, MAPE=52.98%, Accuracy=47.02%\n",
      "\n",
      "🚀 Processing: onion_Udupi_daily.csv\n",
      "Epoch 1/20\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 25ms/step - loss: 0.0029 - mae: 0.0327 - val_loss: 0.0016 - val_mae: 0.0177\n",
      "Epoch 2/20\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 25ms/step - loss: 0.0013 - mae: 0.0222 - val_loss: 0.0015 - val_mae: 0.0163\n",
      "Epoch 3/20\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.0011 - mae: 0.0205 - val_loss: 0.0017 - val_mae: 0.0196\n",
      "Epoch 4/20\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.0013 - mae: 0.0227 - val_loss: 0.0017 - val_mae: 0.0182\n",
      "Epoch 5/20\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.0011 - mae: 0.0208 - val_loss: 0.0019 - val_mae: 0.0174\n",
      "Epoch 6/20\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 9.6541e-04 - mae: 0.0197 - val_loss: 0.0022 - val_mae: 0.0231\n",
      "Epoch 7/20\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.0011 - mae: 0.0203 - val_loss: 0.0024 - val_mae: 0.0240\n",
      "Epoch 8/20\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 25ms/step - loss: 9.4748e-04 - mae: 0.0197 - val_loss: 0.0024 - val_mae: 0.0194\n",
      "Epoch 9/20\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.0010 - mae: 0.0207 - val_loss: 0.0023 - val_mae: 0.0192\n",
      "Epoch 10/20\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 24ms/step - loss: 9.4666e-04 - mae: 0.0198 - val_loss: 0.0028 - val_mae: 0.0280\n",
      "Epoch 11/20\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 24ms/step - loss: 9.3767e-04 - mae: 0.0192 - val_loss: 0.0022 - val_mae: 0.0200\n",
      "Epoch 12/20\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 25ms/step - loss: 9.0635e-04 - mae: 0.0192 - val_loss: 0.0023 - val_mae: 0.0190\n",
      "Epoch 13/20\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 24ms/step - loss: 8.4917e-04 - mae: 0.0185 - val_loss: 0.0023 - val_mae: 0.0205\n",
      "Epoch 14/20\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 24ms/step - loss: 9.1988e-04 - mae: 0.0189 - val_loss: 0.0022 - val_mae: 0.0184\n",
      "Epoch 15/20\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - loss: 9.7397e-04 - mae: 0.0197 - val_loss: 0.0023 - val_mae: 0.0217\n",
      "Epoch 16/20\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - loss: 0.0010 - mae: 0.0201 - val_loss: 0.0022 - val_mae: 0.0193\n",
      "Epoch 17/20\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 9.5403e-04 - mae: 0.0196 - val_loss: 0.0027 - val_mae: 0.0267\n",
      "Epoch 18/20\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 24ms/step - loss: 9.5279e-04 - mae: 0.0197 - val_loss: 0.0035 - val_mae: 0.0299\n",
      "Epoch 19/20\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 9.8789e-04 - mae: 0.0198 - val_loss: 0.0023 - val_mae: 0.0188\n",
      "Epoch 20/20\n",
      "\u001b[1m355/355\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 24ms/step - loss: 8.0513e-04 - mae: 0.0181 - val_loss: 0.0026 - val_mae: 0.0229\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step\n",
      "✅ Done with onion_Udupi_daily.csv | MAE=226.99, RMSE=503.57, R2=0.81, MAPE=8.35%, Accuracy=91.65%\n",
      "\n",
      "📊 Metrics saved to gru_output_csv\\gru_metrics.csv\n",
      "\n",
      "✅ All districts processed successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")   # 👈 Hide all warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import joblib\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Dense, Dropout\n",
    "\n",
    "# -----------------------------\n",
    "# Output paths\n",
    "# -----------------------------\n",
    "input_folder = \"dataset\"\n",
    "output_models = \"gru_output_models\"\n",
    "output_csv = \"gru_output_csv\"\n",
    "output_graphs = \"gru_output_graphs\"\n",
    "output_logs = \"gru_output_logs\"\n",
    "metrics_file = os.path.join(output_csv, \"gru_metrics.csv\")\n",
    "\n",
    "os.makedirs(output_models, exist_ok=True)\n",
    "os.makedirs(output_csv, exist_ok=True)\n",
    "os.makedirs(output_graphs, exist_ok=True)\n",
    "os.makedirs(output_logs, exist_ok=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Function to create dataset\n",
    "# -----------------------------\n",
    "def create_dataset(data, look_back=30):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - look_back):\n",
    "        X.append(data[i:i + look_back, 0])\n",
    "        y.append(data[i + look_back, 0])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# -----------------------------\n",
    "# Metrics storage\n",
    "# -----------------------------\n",
    "metrics_list = []\n",
    "\n",
    "# -----------------------------\n",
    "# Process each CSV file\n",
    "# -----------------------------\n",
    "look_back = 30\n",
    "for file in os.listdir(input_folder):\n",
    "    if file.endswith(\".csv\"):\n",
    "        district_name = file.split(\".\")[0]\n",
    "        print(f\"\\n🚀 Processing: {file}\")\n",
    "\n",
    "        # Load dataset\n",
    "        df = pd.read_csv(os.path.join(input_folder, file))\n",
    "\n",
    "        # Robust date parsing\n",
    "        df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "        df = df.dropna(subset=['Date'])\n",
    "        df = df.sort_values('Date')\n",
    "\n",
    "        # Handle missing values\n",
    "        df['Average Price'] = df['Average Price'].fillna(df['Average Price'].mean())\n",
    "\n",
    "        # Add moving averages\n",
    "        df['MA_7'] = df['Average Price'].rolling(window=7).mean().fillna(df['Average Price'].mean())\n",
    "        df['MA_30'] = df['Average Price'].rolling(window=30).mean().fillna(df['Average Price'].mean())\n",
    "\n",
    "        # Scale data\n",
    "        values = df[['Average Price']].values\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        scaled_values = scaler.fit_transform(values)\n",
    "\n",
    "        X, y = create_dataset(scaled_values, look_back)\n",
    "        X = X.reshape((X.shape[0], X.shape[1], 1))\n",
    "\n",
    "        # Train-test split\n",
    "        split = int(len(X) * 0.8)\n",
    "        X_train, X_test = X[:split], X[split:]\n",
    "        y_train, y_test = y[:split], y[split:]\n",
    "\n",
    "        # Build GRU model\n",
    "        model = Sequential([\n",
    "            GRU(64, return_sequences=True, input_shape=(look_back, 1)),\n",
    "            Dropout(0.2),\n",
    "            GRU(32),\n",
    "            Dropout(0.2),\n",
    "            Dense(1)\n",
    "        ])\n",
    "        model.compile(optimizer=\"adam\", loss=\"mse\", metrics=['mae'])\n",
    "\n",
    "        # Train model — EPOCHS will display in console\n",
    "        history = model.fit(X_train, y_train, epochs=20, batch_size=16,\n",
    "                            validation_data=(X_test, y_test), verbose=1)\n",
    "\n",
    "        # Save training log\n",
    "        log_file = os.path.join(output_logs, f\"{district_name}_gru_training.txt\")\n",
    "        with open(log_file, \"w\") as f:\n",
    "            f.write(\"Epoch\\tTrain_Loss\\tVal_Loss\\n\")\n",
    "            for i, (loss, val_loss) in enumerate(zip(history.history['loss'], history.history['val_loss'])):\n",
    "                f.write(f\"{i+1}\\t{loss:.6f}\\t{val_loss:.6f}\\n\")\n",
    "\n",
    "        # Predictions\n",
    "        y_pred_scaled = model.predict(X_test)\n",
    "        y_pred = scaler.inverse_transform(y_pred_scaled)\n",
    "        y_true = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "        # Round predictions\n",
    "        y_true_round = np.round(y_true, 2)\n",
    "        y_pred_round = np.round(y_pred, 2)\n",
    "\n",
    "        # Save predictions CSV (only Date, Actual, Predicted)\n",
    "        df_pred = df.iloc[-len(y_true):].copy()\n",
    "        df_pred = df_pred[['Date']].reset_index(drop=True)\n",
    "        df_pred['Actual'] = y_true_round.flatten()\n",
    "        df_pred['Predicted'] = y_pred_round.flatten()\n",
    "        df_pred.to_csv(os.path.join(output_csv, f\"{district_name}_gru_updated.csv\"), index=False)\n",
    "\n",
    "        # Metrics\n",
    "        mae_val = round(mean_absolute_error(y_true, y_pred), 2)\n",
    "        rmse_val = round(mean_squared_error(y_true, y_pred, squared=False), 2)\n",
    "        r2_val = round(r2_score(y_true, y_pred), 2)\n",
    "        mape_val = round(np.mean(np.abs((y_true - y_pred) / y_true)) * 100, 2)\n",
    "        accuracy_val = round(100 - mape_val, 2)\n",
    "        metrics_list.append([district_name, mae_val, rmse_val, r2_val, mape_val, accuracy_val])\n",
    "\n",
    "        print(f\"✅ Done with {file} | MAE={mae_val}, RMSE={rmse_val}, R2={r2_val}, \"\n",
    "              f\"MAPE={mape_val}%, Accuracy={accuracy_val}%\")\n",
    "\n",
    "        # Save model as .pkl\n",
    "        model_file = os.path.join(output_models, f\"{district_name}_gru_model.pkl\")\n",
    "        joblib.dump(model, model_file)\n",
    "\n",
    "        # Save prediction graph (with MA7 & MA30)\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(df['Date'], df['Average Price'], label=\"Actual\", color=\"blue\")\n",
    "        plt.plot(df['Date'], df['MA_7'], label=\"MA_7\", color=\"orange\")\n",
    "        plt.plot(df['Date'], df['MA_30'], label=\"MA_30\", color=\"green\")\n",
    "        plt.plot(df_pred['Date'], df_pred['Predicted'], label=\"Predicted (GRU)\", color=\"red\", linestyle=\"dashed\")\n",
    "        plt.xlabel(\"Date\")\n",
    "        plt.ylabel(\"Average Price\")\n",
    "        plt.title(f\"GRU Predictions - {district_name}\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.savefig(os.path.join(output_graphs, f\"{district_name}_gru_graph.png\"))\n",
    "        plt.close()\n",
    "\n",
    "        # Training loss graph\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        plt.plot(history.history['loss'], label='Train Loss')\n",
    "        plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "        plt.title(f\"GRU Training Loss - {district_name}\")\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        plt.savefig(os.path.join(output_graphs, f\"{district_name}_gru_loss.png\"))\n",
    "        plt.close()\n",
    "\n",
    "# Save metrics CSV\n",
    "metrics_df = pd.DataFrame(metrics_list, columns=['District', 'MAE', 'RMSE', 'R2', 'MAPE(%)', 'Accuracy(%)'])\n",
    "metrics_df.to_csv(metrics_file, index=False)\n",
    "print(\"\\n📊 Metrics saved to\", metrics_file)\n",
    "print(\"\\n✅ All districts processed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c4626c-86c5-4530-b50e-89d55136dae9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
