{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1183ad5a-06f2-48dd-9577-1ea3eb265a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af291f93-163e-4d6a-a105-5af772325eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: prophet in c:\\users\\ravik\\appdata\\roaming\\python\\python312\\site-packages (1.1.7)\n",
      "Requirement already satisfied: cmdstanpy>=1.0.4 in c:\\users\\ravik\\appdata\\roaming\\python\\python312\\site-packages (from prophet) (1.2.5)\n",
      "Requirement already satisfied: numpy>=1.15.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from prophet) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from prophet) (3.9.2)\n",
      "Requirement already satisfied: pandas>=1.0.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from prophet) (2.2.2)\n",
      "Requirement already satisfied: holidays<1,>=0.25 in c:\\users\\ravik\\appdata\\roaming\\python\\python312\\site-packages (from prophet) (0.81)\n",
      "Requirement already satisfied: tqdm>=4.36.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from prophet) (4.66.5)\n",
      "Requirement already satisfied: importlib_resources in c:\\users\\ravik\\appdata\\roaming\\python\\python312\\site-packages (from prophet) (6.5.2)\n",
      "Requirement already satisfied: stanio<2.0.0,>=0.4.0 in c:\\users\\ravik\\appdata\\roaming\\python\\python312\\site-packages (from cmdstanpy>=1.0.4->prophet) (0.5.1)\n",
      "Requirement already satisfied: python-dateutil in c:\\programdata\\anaconda3\\lib\\site-packages (from holidays<1,>=0.25->prophet) (2.9.0.post0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=2.0.0->prophet) (3.1.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=1.0.4->prophet) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=1.0.4->prophet) (2023.3)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm>=4.36.1->prophet) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil->holidays<1,>=0.25->prophet) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b92396a-3f8c-4217-89f9-2a68c0d16c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Processing: tomato_Bangalore_daily.csv ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08:31:48 - cmdstanpy - INFO - Chain [1] start processing\n",
      "08:32:33 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for tomato_Bangalore_daily.csv:\n",
      "  MAE        : 738.43\n",
      "  RMSE       : 1157.81\n",
      "  R²         : 0.3171\n",
      "  MAPE(%)    : 52.34\n",
      "  Accuracy(%) : 47.66\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: prophet_output_csv\\tomato_Bangalore_daily_prophet_updated.csv\n",
      "========== Processing: tomato_Belgaum_daily.csv ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08:32:36 - cmdstanpy - INFO - Chain [1] start processing\n",
      "08:32:39 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for tomato_Belgaum_daily.csv:\n",
      "  MAE        : 629.22\n",
      "  RMSE       : 1079.74\n",
      "  R²         : 0.0828\n",
      "  MAPE(%)    : 72.56\n",
      "  Accuracy(%) : 27.44\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: prophet_output_csv\\tomato_Belgaum_daily_prophet_updated.csv\n",
      "========== Processing: tomato_Bellary_daily.csv ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08:32:41 - cmdstanpy - INFO - Chain [1] start processing\n",
      "08:32:44 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for tomato_Bellary_daily.csv:\n",
      "  MAE        : 334.21\n",
      "  RMSE       : 552.74\n",
      "  R²         : 0.2443\n",
      "  MAPE(%)    : 46.6\n",
      "  Accuracy(%) : 53.4\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: prophet_output_csv\\tomato_Bellary_daily_prophet_updated.csv\n",
      "========== Processing: tomato_Chamrajnagar_daily.csv ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08:32:46 - cmdstanpy - INFO - Chain [1] start processing\n",
      "08:32:58 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for tomato_Chamrajnagar_daily.csv:\n",
      "  MAE        : 826.79\n",
      "  RMSE       : 1121.5\n",
      "  R²         : -1.7907\n",
      "  MAPE(%)    : 158.76\n",
      "  Accuracy(%) : -58.76\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: prophet_output_csv\\tomato_Chamrajnagar_daily_prophet_updated.csv\n",
      "========== Processing: tomato_Chikmagalur_daily.csv ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08:33:01 - cmdstanpy - INFO - Chain [1] start processing\n",
      "08:33:22 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for tomato_Chikmagalur_daily.csv:\n",
      "  MAE        : 650.32\n",
      "  RMSE       : 958.58\n",
      "  R²         : -0.1107\n",
      "  MAPE(%)    : 98.12\n",
      "  Accuracy(%) : 1.88\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: prophet_output_csv\\tomato_Chikmagalur_daily_prophet_updated.csv\n",
      "========== Processing: tomato_Chitradurga_daily.csv ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08:33:24 - cmdstanpy - INFO - Chain [1] start processing\n",
      "08:33:30 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for tomato_Chitradurga_daily.csv:\n",
      "  MAE        : 42.01\n",
      "  RMSE       : 71.59\n",
      "  R²         : 0.9951\n",
      "  MAPE(%)    : 4.35\n",
      "  Accuracy(%) : 95.65\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: prophet_output_csv\\tomato_Chitradurga_daily_prophet_updated.csv\n",
      "========== Processing: tomato_Davangere_daily.csv ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08:33:32 - cmdstanpy - INFO - Chain [1] start processing\n",
      "08:33:42 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for tomato_Davangere_daily.csv:\n",
      "  MAE        : 608.25\n",
      "  RMSE       : 891.76\n",
      "  R²         : 0.3323\n",
      "  MAPE(%)    : 90.94\n",
      "  Accuracy(%) : 9.06\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: prophet_output_csv\\tomato_Davangere_daily_prophet_updated.csv\n",
      "========== Processing: tomato_Dharwad_daily.csv ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08:33:44 - cmdstanpy - INFO - Chain [1] start processing\n",
      "08:33:44 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for tomato_Dharwad_daily.csv:\n",
      "  MAE        : 360.85\n",
      "  RMSE       : 615.55\n",
      "  R²         : 0.4443\n",
      "  MAPE(%)    : 19.53\n",
      "  Accuracy(%) : 80.47\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: prophet_output_csv\\tomato_Dharwad_daily_prophet_updated.csv\n",
      "========== Processing: tomato_Gadag_daily.csv ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08:33:45 - cmdstanpy - INFO - Chain [1] start processing\n",
      "08:33:45 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for tomato_Gadag_daily.csv:\n",
      "  MAE        : 271.46\n",
      "  RMSE       : 469.71\n",
      "  R²         : 0.9528\n",
      "  MAPE(%)    : 7.18\n",
      "  Accuracy(%) : 92.82\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: prophet_output_csv\\tomato_Gadag_daily_prophet_updated.csv\n",
      "========== Processing: tomato_Hassan_daily.csv ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08:33:48 - cmdstanpy - INFO - Chain [1] start processing\n",
      "08:34:12 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for tomato_Hassan_daily.csv:\n",
      "  MAE        : 576.38\n",
      "  RMSE       : 843.77\n",
      "  R²         : 0.2891\n",
      "  MAPE(%)    : 62.2\n",
      "  Accuracy(%) : 37.8\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: prophet_output_csv\\tomato_Hassan_daily_prophet_updated.csv\n",
      "========== Processing: tomato_Haveri_daily.csv ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08:34:14 - cmdstanpy - INFO - Chain [1] start processing\n",
      "08:34:15 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for tomato_Haveri_daily.csv:\n",
      "  MAE        : 823.1\n",
      "  RMSE       : 1163.09\n",
      "  R²         : 0.7064\n",
      "  MAPE(%)    : 62.51\n",
      "  Accuracy(%) : 37.49\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: prophet_output_csv\\tomato_Haveri_daily_prophet_updated.csv\n",
      "========== Processing: tomato_Kalburgi_daily.csv ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08:34:17 - cmdstanpy - INFO - Chain [1] start processing\n",
      "08:34:17 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for tomato_Kalburgi_daily.csv:\n",
      "  MAE        : 871.58\n",
      "  RMSE       : 1247.48\n",
      "  R²         : 0.5066\n",
      "  MAPE(%)    : 72.3\n",
      "  Accuracy(%) : 27.7\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: prophet_output_csv\\tomato_Kalburgi_daily_prophet_updated.csv\n",
      "========== Processing: tomato_Kolar_daily.csv ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08:34:20 - cmdstanpy - INFO - Chain [1] start processing\n",
      "08:35:06 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for tomato_Kolar_daily.csv:\n",
      "  MAE        : 802.27\n",
      "  RMSE       : 1116.25\n",
      "  R²         : -0.4552\n",
      "  MAPE(%)    : 106.99\n",
      "  Accuracy(%) : -6.99\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: prophet_output_csv\\tomato_Kolar_daily_prophet_updated.csv\n",
      "========== Processing: tomato_MadikeriKodagu_daily.csv ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08:35:09 - cmdstanpy - INFO - Chain [1] start processing\n",
      "08:35:10 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for tomato_MadikeriKodagu_daily.csv:\n",
      "  MAE        : 409.16\n",
      "  RMSE       : 517.26\n",
      "  R²         : -0.2196\n",
      "  MAPE(%)    : 64.87\n",
      "  Accuracy(%) : 35.13\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: prophet_output_csv\\tomato_MadikeriKodagu_daily_prophet_updated.csv\n",
      "========== Processing: tomato_Mandya_daily.csv ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08:35:13 - cmdstanpy - INFO - Chain [1] start processing\n",
      "08:35:25 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for tomato_Mandya_daily.csv:\n",
      "  MAE        : 417.08\n",
      "  RMSE       : 592.12\n",
      "  R²         : 0.3644\n",
      "  MAPE(%)    : 104.71\n",
      "  Accuracy(%) : -4.71\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: prophet_output_csv\\tomato_Mandya_daily_prophet_updated.csv\n",
      "========== Processing: tomato_Mysore_daily.csv ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08:35:29 - cmdstanpy - INFO - Chain [1] start processing\n",
      "08:36:01 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for tomato_Mysore_daily.csv:\n",
      "  MAE        : 427.18\n",
      "  RMSE       : 644.07\n",
      "  R²         : 0.4168\n",
      "  MAPE(%)    : 39.81\n",
      "  Accuracy(%) : 60.19\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: prophet_output_csv\\tomato_Mysore_daily_prophet_updated.csv\n",
      "========== Processing: tomato_Shimoga_daily.csv ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08:36:04 - cmdstanpy - INFO - Chain [1] start processing\n",
      "08:36:12 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for tomato_Shimoga_daily.csv:\n",
      "  MAE        : 712.24\n",
      "  RMSE       : 1000.97\n",
      "  R²         : -0.037\n",
      "  MAPE(%)    : 81.31\n",
      "  Accuracy(%) : 18.69\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: prophet_output_csv\\tomato_Shimoga_daily_prophet_updated.csv\n",
      "========== Processing: tomato_Tumkur_daily.csv ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08:36:14 - cmdstanpy - INFO - Chain [1] start processing\n",
      "08:36:21 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for tomato_Tumkur_daily.csv:\n",
      "  MAE        : 707.44\n",
      "  RMSE       : 1227.5\n",
      "  R²         : -3.0274\n",
      "  MAPE(%)    : 75.91\n",
      "  Accuracy(%) : 24.09\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: prophet_output_csv\\tomato_Tumkur_daily_prophet_updated.csv\n",
      "========== Processing: tomato_Udupi_daily.csv ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08:36:23 - cmdstanpy - INFO - Chain [1] start processing\n",
      "08:36:25 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for tomato_Udupi_daily.csv:\n",
      "  MAE        : 658.71\n",
      "  RMSE       : 880.11\n",
      "  R²         : 0.0036\n",
      "  MAPE(%)    : 53.53\n",
      "  Accuracy(%) : 46.47\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: prophet_output_csv\\tomato_Udupi_daily_prophet_updated.csv\n",
      "✅ Multiple CSVs processed! Metrics saved to prophet_metrics.csv. Models, updated CSVs, and graphs saved in respective folders.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from prophet import Prophet\n",
    "import joblib\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "# -----------------------------\n",
    "# Suppress warnings\n",
    "# -----------------------------\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# -----------------------------\n",
    "# Paths\n",
    "# -----------------------------\n",
    "input_folder = \"dataset\"\n",
    "output_models = \"prophet_output_models\"\n",
    "output_csv = \"prophet_output_csv\"\n",
    "output_metrics_csv = \"prophet_metrics.csv\"\n",
    "output_graphs = \"prophet_output_graphs\"\n",
    "\n",
    "os.makedirs(output_models, exist_ok=True)\n",
    "os.makedirs(output_csv, exist_ok=True)\n",
    "os.makedirs(output_graphs, exist_ok=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Prepare metrics storage\n",
    "# -----------------------------\n",
    "metrics_list = []\n",
    "\n",
    "# -----------------------------\n",
    "# Function to robustly parse dates (all formats)\n",
    "# -----------------------------\n",
    "def parse_dates_safe(date_series):\n",
    "    return pd.to_datetime(date_series, errors='coerce', dayfirst=False, infer_datetime_format=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Function to calculate MAPE safely\n",
    "# -----------------------------\n",
    "def mean_absolute_percentage_error_safe(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    # Avoid division by zero\n",
    "    mask = y_true != 0\n",
    "    if mask.sum() == 0:\n",
    "        return np.nan\n",
    "    mape = np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100\n",
    "    # Handle any remaining inf or NaN\n",
    "    if np.isnan(mape) or np.isinf(mape):\n",
    "        return np.nan\n",
    "    return mape\n",
    "\n",
    "# -----------------------------\n",
    "# Process each CSV\n",
    "# -----------------------------\n",
    "for file in os.listdir(input_folder):\n",
    "    if file.endswith(\".csv\"):\n",
    "        file_path = os.path.join(input_folder, file)\n",
    "        print(f\"========== Processing: {file} ==========\")\n",
    "\n",
    "        # Load CSV\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # -----------------------------\n",
    "        # Convert 'Date' column safely\n",
    "        # -----------------------------\n",
    "        df['Date'] = parse_dates_safe(df['Date'])\n",
    "        df = df.sort_values('Date')\n",
    "\n",
    "        # Drop rows with NaT after conversion\n",
    "        df = df.dropna(subset=['Date'])\n",
    "        if df.empty:\n",
    "            print(f\"⚠️ No valid dates found in {file}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        # -----------------------------\n",
    "        # Handle missing values in Average Price\n",
    "        # -----------------------------\n",
    "        if df['Average Price'].isna().sum() > 0:\n",
    "            mean_value = df['Average Price'].mean()\n",
    "            df['Average Price'].fillna(mean_value, inplace=True)\n",
    "            print(f\"Filled {df['Average Price'].isna().sum()} missing values with mean: {mean_value:.2f}\")\n",
    "\n",
    "        # Round actual values\n",
    "        df['Average Price'] = df['Average Price'].round(2)\n",
    "\n",
    "        # -----------------------------\n",
    "        # Prepare data for Prophet\n",
    "        # -----------------------------\n",
    "        prophet_df = df[['Date', 'Average Price']].rename(columns={'Date': 'ds', 'Average Price': 'y'})\n",
    "\n",
    "        # Skip files with less than 2 valid rows (Prophet requirement)\n",
    "        if len(prophet_df) < 2:\n",
    "            print(f\"⚠️ Not enough data points in {file} for Prophet. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        # Build and fit Prophet model\n",
    "        model = Prophet(daily_seasonality=True)\n",
    "        model.fit(prophet_df)\n",
    "\n",
    "        # Predict for existing dates\n",
    "        future = model.make_future_dataframe(periods=0)\n",
    "        forecast = model.predict(future)\n",
    "        df['Predicted'] = forecast['yhat']  # keep full precision for metrics\n",
    "\n",
    "        # -----------------------------\n",
    "        # Handle NaNs in predictions for metrics\n",
    "        # -----------------------------\n",
    "        metrics_df = df.dropna(subset=['Average Price', 'Predicted'])\n",
    "        y_true = metrics_df['Average Price'].values\n",
    "        y_pred = metrics_df['Predicted'].values\n",
    "\n",
    "        # Round predictions for saving\n",
    "        df['Predicted'] = df['Predicted'].round(2)\n",
    "\n",
    "        # Rename Average Price to Actual in main df for plotting\n",
    "        df.rename(columns={'Average Price': 'Actual'}, inplace=True)\n",
    "\n",
    "        # -----------------------------\n",
    "        # Calculate metrics\n",
    "        # -----------------------------\n",
    "        mae = round(mean_absolute_error(y_true, y_pred), 2)\n",
    "        rmse = round(np.sqrt(mean_squared_error(y_true, y_pred)), 2)\n",
    "        r2 = round(r2_score(y_true, y_pred), 4)\n",
    "        mape = round(mean_absolute_percentage_error_safe(y_true, y_pred), 2)\n",
    "        accuracy = round(100 - mape if not np.isnan(mape) else np.nan, 2)\n",
    "\n",
    "        print(f\"Metrics for {file}:\")\n",
    "        print(f\"  MAE        : {mae}\")\n",
    "        print(f\"  RMSE       : {rmse}\")\n",
    "        print(f\"  R²         : {r2}\")\n",
    "        print(f\"  MAPE(%)    : {mape}\")\n",
    "        print(f\"  Accuracy(%) : {accuracy}\\n\")\n",
    "\n",
    "        # Save metrics\n",
    "        metrics_list.append({\n",
    "            'File': file,\n",
    "            'MAE': mae,\n",
    "            'RMSE': rmse,\n",
    "            'R2': r2,\n",
    "            'MAPE(%)': mape,\n",
    "            'Accuracy(%)': accuracy\n",
    "        })\n",
    "\n",
    "        # -----------------------------\n",
    "        # Save model\n",
    "        # -----------------------------\n",
    "        model_file = os.path.join(output_models, file.replace(\".csv\", \"_prophet_model.pkl\"))\n",
    "        joblib.dump(model, model_file)\n",
    "\n",
    "        # -----------------------------\n",
    "        # Save CSV with only Date, Actual, and Predicted\n",
    "        # -----------------------------\n",
    "        save_df = df[['Date', 'Actual', 'Predicted']]\n",
    "        updated_csv_path = os.path.join(output_csv, file.replace(\".csv\", \"_prophet_updated.csv\"))\n",
    "        save_df.to_csv(updated_csv_path, index=False)\n",
    "        print(f\"Saved updated CSV with Date, Actual & Predicted: {updated_csv_path}\")\n",
    "\n",
    "        # -----------------------------\n",
    "        # Add MA7 & MA30 for graphs\n",
    "        # -----------------------------\n",
    "        df['MA7'] = df['Actual'].rolling(7).mean()\n",
    "        df['MA30'] = df['Actual'].rolling(30).mean()\n",
    "\n",
    "        # -----------------------------\n",
    "        # Plot graph\n",
    "        # -----------------------------\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(df['Date'], df['Actual'], label='Actual', color='blue')\n",
    "        plt.plot(df['Date'], df['Predicted'], label='Predicted', color='red')\n",
    "        plt.plot(df['Date'], df['MA7'], label='MA7', color='green', linestyle='--')\n",
    "        plt.plot(df['Date'], df['MA30'], label='MA30', color='orange', linestyle='--')\n",
    "        plt.title(f\"{file} - Actual vs Predicted with Moving Averages\")\n",
    "        plt.xlabel(\"Date\")\n",
    "        plt.ylabel(\"Price\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        graph_path = os.path.join(output_graphs, file.replace(\".csv\", \"_prophet_graph.png\"))\n",
    "        plt.savefig(graph_path, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "# -----------------------------\n",
    "# Save all metrics to CSV\n",
    "# -----------------------------\n",
    "metrics_df = pd.DataFrame(metrics_list)\n",
    "metrics_df.to_csv(output_metrics_csv, index=False)\n",
    "print(f\"✅ Multiple CSVs processed! Metrics saved to {output_metrics_csv}. Models, updated CSVs, and graphs saved in respective folders.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f73669-b8aa-4e76-bce0-e2f36279f812",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21bae03d-1737-4ca4-a857-1274ea05d720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Processing: tomato_Bangalore_daily.csv ==========\n",
      "Metrics for tomato_Bangalore_daily.csv:\n",
      "  MAE        : 417.99\n",
      "  RMSE       : 901.54\n",
      "  R²         : 0.6118\n",
      "  MAPE(%)    : 30.57\n",
      "  Accuracy(%) : 69.43\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: arima_output_csv\\tomato_Bangalore_daily_arima_updated.csv\n",
      "========== Processing: tomato_Belgaum_daily.csv ==========\n",
      "Metrics for tomato_Belgaum_daily.csv:\n",
      "  MAE        : 50.47\n",
      "  RMSE       : 165.19\n",
      "  R²         : 0.9784\n",
      "  MAPE(%)    : 3.45\n",
      "  Accuracy(%) : 96.55\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: arima_output_csv\\tomato_Belgaum_daily_arima_updated.csv\n",
      "========== Processing: tomato_Bellary_daily.csv ==========\n",
      "Metrics for tomato_Bellary_daily.csv:\n",
      "  MAE        : 117.12\n",
      "  RMSE       : 221.25\n",
      "  R²         : 0.873\n",
      "  MAPE(%)    : 13.45\n",
      "  Accuracy(%) : 86.55\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: arima_output_csv\\tomato_Bellary_daily_arima_updated.csv\n",
      "========== Processing: tomato_Chamrajnagar_daily.csv ==========\n",
      "Metrics for tomato_Chamrajnagar_daily.csv:\n",
      "  MAE        : 729.67\n",
      "  RMSE       : 1224.69\n",
      "  R²         : 0.4237\n",
      "  MAPE(%)    : 73.23\n",
      "  Accuracy(%) : 26.77\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: arima_output_csv\\tomato_Chamrajnagar_daily_arima_updated.csv\n",
      "========== Processing: tomato_Chikmagalur_daily.csv ==========\n",
      "Metrics for tomato_Chikmagalur_daily.csv:\n",
      "  MAE        : 428.81\n",
      "  RMSE       : 684.52\n",
      "  R²         : 0.4732\n",
      "  MAPE(%)    : 63.33\n",
      "  Accuracy(%) : 36.67\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: arima_output_csv\\tomato_Chikmagalur_daily_arima_updated.csv\n",
      "========== Processing: tomato_Chitradurga_daily.csv ==========\n",
      "Metrics for tomato_Chitradurga_daily.csv:\n",
      "  MAE        : 4.94\n",
      "  RMSE       : 23.87\n",
      "  R²         : 0.9995\n",
      "  MAPE(%)    : 0.55\n",
      "  Accuracy(%) : 99.45\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: arima_output_csv\\tomato_Chitradurga_daily_arima_updated.csv\n",
      "========== Processing: tomato_Davangere_daily.csv ==========\n",
      "Metrics for tomato_Davangere_daily.csv:\n",
      "  MAE        : 279.27\n",
      "  RMSE       : 433.28\n",
      "  R²         : 0.7854\n",
      "  MAPE(%)    : 37.63\n",
      "  Accuracy(%) : 62.37\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: arima_output_csv\\tomato_Davangere_daily_arima_updated.csv\n",
      "========== Processing: tomato_Dharwad_daily.csv ==========\n",
      "Metrics for tomato_Dharwad_daily.csv:\n",
      "  MAE        : 87.06\n",
      "  RMSE       : 307.52\n",
      "  R²         : 0.8748\n",
      "  MAPE(%)    : 7.45\n",
      "  Accuracy(%) : 92.55\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: arima_output_csv\\tomato_Dharwad_daily_arima_updated.csv\n",
      "========== Processing: tomato_Gadag_daily.csv ==========\n",
      "Metrics for tomato_Gadag_daily.csv:\n",
      "  MAE        : 37.71\n",
      "  RMSE       : 133.2\n",
      "  R²         : 0.9962\n",
      "  MAPE(%)    : 1.43\n",
      "  Accuracy(%) : 98.57\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: arima_output_csv\\tomato_Gadag_daily_arima_updated.csv\n",
      "========== Processing: tomato_Hassan_daily.csv ==========\n",
      "Metrics for tomato_Hassan_daily.csv:\n",
      "  MAE        : 437.88\n",
      "  RMSE       : 639.51\n",
      "  R²         : 0.535\n",
      "  MAPE(%)    : 55.95\n",
      "  Accuracy(%) : 44.05\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: arima_output_csv\\tomato_Hassan_daily_arima_updated.csv\n",
      "========== Processing: tomato_Haveri_daily.csv ==========\n",
      "Metrics for tomato_Haveri_daily.csv:\n",
      "  MAE        : 354.54\n",
      "  RMSE       : 489.36\n",
      "  R²         : 0.9567\n",
      "  MAPE(%)    : 13.96\n",
      "  Accuracy(%) : 86.04\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: arima_output_csv\\tomato_Haveri_daily_arima_updated.csv\n",
      "========== Processing: tomato_Kalburgi_daily.csv ==========\n",
      "Metrics for tomato_Kalburgi_daily.csv:\n",
      "  MAE        : 301.61\n",
      "  RMSE       : 622.83\n",
      "  R²         : 0.877\n",
      "  MAPE(%)    : 17.87\n",
      "  Accuracy(%) : 82.13\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: arima_output_csv\\tomato_Kalburgi_daily_arima_updated.csv\n",
      "========== Processing: tomato_Kolar_daily.csv ==========\n",
      "Metrics for tomato_Kolar_daily.csv:\n",
      "  MAE        : 283.48\n",
      "  RMSE       : 458.29\n",
      "  R²         : 0.7274\n",
      "  MAPE(%)    : 28.25\n",
      "  Accuracy(%) : 71.75\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: arima_output_csv\\tomato_Kolar_daily_arima_updated.csv\n",
      "========== Processing: tomato_MadikeriKodagu_daily.csv ==========\n",
      "Metrics for tomato_MadikeriKodagu_daily.csv:\n",
      "  MAE        : 152.77\n",
      "  RMSE       : 269.29\n",
      "  R²         : 0.5942\n",
      "  MAPE(%)    : 19.47\n",
      "  Accuracy(%) : 80.53\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: arima_output_csv\\tomato_MadikeriKodagu_daily_arima_updated.csv\n",
      "========== Processing: tomato_Mandya_daily.csv ==========\n",
      "Metrics for tomato_Mandya_daily.csv:\n",
      "  MAE        : 357.33\n",
      "  RMSE       : 585.93\n",
      "  R²         : 0.5995\n",
      "  MAPE(%)    : 60.82\n",
      "  Accuracy(%) : 39.18\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: arima_output_csv\\tomato_Mandya_daily_arima_updated.csv\n",
      "========== Processing: tomato_Mysore_daily.csv ==========\n",
      "Metrics for tomato_Mysore_daily.csv:\n",
      "  MAE        : 450.15\n",
      "  RMSE       : 692.59\n",
      "  R²         : 0.3749\n",
      "  MAPE(%)    : 41.57\n",
      "  Accuracy(%) : 58.43\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: arima_output_csv\\tomato_Mysore_daily_arima_updated.csv\n",
      "========== Processing: tomato_Shimoga_daily.csv ==========\n",
      "Metrics for tomato_Shimoga_daily.csv:\n",
      "  MAE        : 289.4\n",
      "  RMSE       : 535.15\n",
      "  R²         : 0.7029\n",
      "  MAPE(%)    : 41.2\n",
      "  Accuracy(%) : 58.8\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: arima_output_csv\\tomato_Shimoga_daily_arima_updated.csv\n",
      "========== Processing: tomato_Tumkur_daily.csv ==========\n",
      "Metrics for tomato_Tumkur_daily.csv:\n",
      "  MAE        : 49.39\n",
      "  RMSE       : 135.45\n",
      "  R²         : 0.9908\n",
      "  MAPE(%)    : 5.89\n",
      "  Accuracy(%) : 94.11\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: arima_output_csv\\tomato_Tumkur_daily_arima_updated.csv\n",
      "========== Processing: tomato_Udupi_daily.csv ==========\n",
      "Metrics for tomato_Udupi_daily.csv:\n",
      "  MAE        : 112.05\n",
      "  RMSE       : 230.02\n",
      "  R²         : 0.9651\n",
      "  MAPE(%)    : 8.01\n",
      "  Accuracy(%) : 91.99\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: arima_output_csv\\tomato_Udupi_daily_arima_updated.csv\n",
      "✅ Multiple CSVs processed! Metrics saved to arima_metrics.csv. Models, updated CSVs, and graphs saved in respective folders.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import joblib\n",
    "import warnings\n",
    "\n",
    "# -----------------------------\n",
    "# Suppress warnings\n",
    "# -----------------------------\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# -----------------------------\n",
    "# Paths\n",
    "# -----------------------------\n",
    "input_folder = \"dataset\"\n",
    "output_models = \"arima_output_models\"\n",
    "output_csv = \"arima_output_csv\"\n",
    "output_metrics_csv = \"arima_metrics.csv\"\n",
    "output_graphs = \"arima_output_graphs\"\n",
    "\n",
    "os.makedirs(output_models, exist_ok=True)\n",
    "os.makedirs(output_csv, exist_ok=True)\n",
    "os.makedirs(output_graphs, exist_ok=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Metrics storage\n",
    "# -----------------------------\n",
    "metrics_list = []\n",
    "\n",
    "# -----------------------------\n",
    "# Robust date parsing (allow all formats)\n",
    "# -----------------------------\n",
    "def parse_dates_safe(date_series):\n",
    "    return pd.to_datetime(date_series, errors='coerce', infer_datetime_format=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Safe MAPE calculation (handle NaN/Inf)\n",
    "# -----------------------------\n",
    "def mean_absolute_percentage_error_safe(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    mask = y_true != 0\n",
    "    if mask.sum() == 0:\n",
    "        return 0.0\n",
    "    mape = np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100\n",
    "    if np.isnan(mape) or np.isinf(mape):\n",
    "        return 0.0\n",
    "    return mape\n",
    "\n",
    "# -----------------------------\n",
    "# Process each CSV\n",
    "# -----------------------------\n",
    "for file in os.listdir(input_folder):\n",
    "    if file.endswith(\".csv\"):\n",
    "        file_path = os.path.join(input_folder, file)\n",
    "        print(f\"========== Processing: {file} ==========\")\n",
    "\n",
    "        # Load CSV\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # -----------------------------\n",
    "        # Convert 'Date' column safely\n",
    "        # -----------------------------\n",
    "        df['Date'] = parse_dates_safe(df['Date'])\n",
    "        df = df.sort_values('Date')\n",
    "\n",
    "        # Drop rows with invalid dates\n",
    "        df = df.dropna(subset=['Date'])\n",
    "        if df.empty:\n",
    "            print(f\"⚠️ No valid dates found in {file}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        # -----------------------------\n",
    "        # Handle missing Average Price\n",
    "        # -----------------------------\n",
    "        if df['Average Price'].isna().sum() > 0:\n",
    "            mean_value = df['Average Price'].mean()\n",
    "            df['Average Price'].fillna(mean_value, inplace=True)\n",
    "            print(f\"Filled {df['Average Price'].isna().sum()} missing values with mean: {mean_value:.2f}\")\n",
    "\n",
    "        df['Average Price'] = df['Average Price'].round(2)\n",
    "\n",
    "        # -----------------------------\n",
    "        # Fit ARIMA model\n",
    "        # -----------------------------\n",
    "        order = (5, 1, 0)\n",
    "        model = ARIMA(df['Average Price'], order=order)\n",
    "        model_fit = model.fit()\n",
    "\n",
    "        # Predict for existing dates\n",
    "        df['Predicted'] = model_fit.predict(start=0, end=len(df)-1)\n",
    "        df['Predicted'] = df['Predicted'].round(2)\n",
    "\n",
    "        # -----------------------------\n",
    "        # Rename Average Price to Actual\n",
    "        # -----------------------------\n",
    "        df.rename(columns={'Average Price': 'Actual'}, inplace=True)\n",
    "\n",
    "        # -----------------------------\n",
    "        # Calculate metrics\n",
    "        # -----------------------------\n",
    "        y_true = df['Actual'].values\n",
    "        y_pred = df['Predicted'].values\n",
    "        mae = round(mean_absolute_error(y_true, y_pred), 2)\n",
    "        rmse = round(np.sqrt(mean_squared_error(y_true, y_pred)), 2)\n",
    "        r2 = round(r2_score(y_true, y_pred), 4)\n",
    "        mape = round(mean_absolute_percentage_error_safe(y_true, y_pred), 2)\n",
    "        accuracy = round(100 - mape, 2)\n",
    "\n",
    "        print(f\"Metrics for {file}:\")\n",
    "        print(f\"  MAE        : {mae}\")\n",
    "        print(f\"  RMSE       : {rmse}\")\n",
    "        print(f\"  R²         : {r2}\")\n",
    "        print(f\"  MAPE(%)    : {mape}\")\n",
    "        print(f\"  Accuracy(%) : {accuracy}\\n\")\n",
    "\n",
    "        # Save metrics\n",
    "        metrics_list.append({\n",
    "            'File': file,\n",
    "            'MAE': mae,\n",
    "            'RMSE': rmse,\n",
    "            'R2': r2,\n",
    "            'MAPE(%)': mape,\n",
    "            'Accuracy(%)': accuracy\n",
    "        })\n",
    "\n",
    "        # -----------------------------\n",
    "        # Save model\n",
    "        # -----------------------------\n",
    "        model_file = os.path.join(output_models, file.replace(\".csv\", \"_arima_model.pkl\"))\n",
    "        joblib.dump(model_fit, model_file)\n",
    "\n",
    "        # -----------------------------\n",
    "        # Save CSV with only Date, Actual, Predicted\n",
    "        # -----------------------------\n",
    "        save_df = df[['Date', 'Actual', 'Predicted']]\n",
    "        updated_csv_path = os.path.join(output_csv, file.replace(\".csv\", \"_arima_updated.csv\"))\n",
    "        save_df.to_csv(updated_csv_path, index=False)\n",
    "        print(f\"Saved updated CSV with Date, Actual & Predicted: {updated_csv_path}\")\n",
    "\n",
    "        # -----------------------------\n",
    "        # Add MA7 & MA30 for graphs\n",
    "        # -----------------------------\n",
    "        df['MA7'] = df['Actual'].rolling(7).mean()\n",
    "        df['MA30'] = df['Actual'].rolling(30).mean()\n",
    "\n",
    "        # -----------------------------\n",
    "        # Plot graph\n",
    "        # -----------------------------\n",
    "        plt.figure(figsize=(12,6))\n",
    "        plt.plot(df['Date'], df['Actual'], label='Actual', color='blue')\n",
    "        plt.plot(df['Date'], df['Predicted'], label='Predicted', color='red')\n",
    "        plt.plot(df['Date'], df['MA7'], label='MA7', color='green', linestyle='--')\n",
    "        plt.plot(df['Date'], df['MA30'], label='MA30', color='orange', linestyle='--')\n",
    "        plt.title(f\"{file} - Actual vs Predicted with Moving Averages\")\n",
    "        plt.xlabel(\"Date\")\n",
    "        plt.ylabel(\"Price\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        graph_path = os.path.join(output_graphs, file.replace(\".csv\", \"_arima_graph.png\"))\n",
    "        plt.savefig(graph_path, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "# -----------------------------\n",
    "# Save all metrics to CSV\n",
    "# -----------------------------\n",
    "metrics_df = pd.DataFrame(metrics_list)\n",
    "metrics_df.to_csv(output_metrics_csv, index=False)\n",
    "print(f\"✅ Multiple CSVs processed! Metrics saved to {output_metrics_csv}. Models, updated CSVs, and graphs saved in respective folders.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1979b14d-61b3-4051-9bac-9137033d71fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SARIMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "029e3fd1-9a66-4700-a306-54e3f99bea9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Processing: tomato_Bangalore_daily.csv ==========\n",
      "Metrics for tomato_Bangalore_daily.csv:\n",
      "  MAE        : 417.62\n",
      "  RMSE       : 877.62\n",
      "  R²         : 0.6322\n",
      "  MAPE(%)    : 30.43\n",
      "  Accuracy(%) : 69.57\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: sarimax_output_csv\\tomato_Bangalore_daily_sarimax_updated.csv\n",
      "========== Processing: tomato_Belgaum_daily.csv ==========\n",
      "Metrics for tomato_Belgaum_daily.csv:\n",
      "  MAE        : 52.25\n",
      "  RMSE       : 165.63\n",
      "  R²         : 0.9783\n",
      "  MAPE(%)    : 3.59\n",
      "  Accuracy(%) : 96.41\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: sarimax_output_csv\\tomato_Belgaum_daily_sarimax_updated.csv\n",
      "========== Processing: tomato_Bellary_daily.csv ==========\n",
      "Metrics for tomato_Bellary_daily.csv:\n",
      "  MAE        : 119.55\n",
      "  RMSE       : 222.12\n",
      "  R²         : 0.872\n",
      "  MAPE(%)    : 13.93\n",
      "  Accuracy(%) : 86.07\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: sarimax_output_csv\\tomato_Bellary_daily_sarimax_updated.csv\n",
      "========== Processing: tomato_Chamrajnagar_daily.csv ==========\n",
      "Metrics for tomato_Chamrajnagar_daily.csv:\n",
      "  MAE        : 734.91\n",
      "  RMSE       : 1189.91\n",
      "  R²         : 0.456\n",
      "  MAPE(%)    : 73.57\n",
      "  Accuracy(%) : 26.43\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: sarimax_output_csv\\tomato_Chamrajnagar_daily_sarimax_updated.csv\n",
      "========== Processing: tomato_Chikmagalur_daily.csv ==========\n",
      "Metrics for tomato_Chikmagalur_daily.csv:\n",
      "  MAE        : 421.03\n",
      "  RMSE       : 667.05\n",
      "  R²         : 0.4998\n",
      "  MAPE(%)    : 62.18\n",
      "  Accuracy(%) : 37.82\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: sarimax_output_csv\\tomato_Chikmagalur_daily_sarimax_updated.csv\n",
      "========== Processing: tomato_Chitradurga_daily.csv ==========\n",
      "Metrics for tomato_Chitradurga_daily.csv:\n",
      "  MAE        : 5.57\n",
      "  RMSE       : 24.77\n",
      "  R²         : 0.9994\n",
      "  MAPE(%)    : 0.75\n",
      "  Accuracy(%) : 99.25\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: sarimax_output_csv\\tomato_Chitradurga_daily_sarimax_updated.csv\n",
      "========== Processing: tomato_Davangere_daily.csv ==========\n",
      "Metrics for tomato_Davangere_daily.csv:\n",
      "  MAE        : 281.31\n",
      "  RMSE       : 435.22\n",
      "  R²         : 0.7835\n",
      "  MAPE(%)    : 38.05\n",
      "  Accuracy(%) : 61.95\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: sarimax_output_csv\\tomato_Davangere_daily_sarimax_updated.csv\n",
      "========== Processing: tomato_Dharwad_daily.csv ==========\n",
      "Metrics for tomato_Dharwad_daily.csv:\n",
      "  MAE        : 121.54\n",
      "  RMSE       : 323.1\n",
      "  R²         : 0.8618\n",
      "  MAPE(%)    : 9.92\n",
      "  Accuracy(%) : 90.08\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: sarimax_output_csv\\tomato_Dharwad_daily_sarimax_updated.csv\n",
      "========== Processing: tomato_Gadag_daily.csv ==========\n",
      "Metrics for tomato_Gadag_daily.csv:\n",
      "  MAE        : 45.43\n",
      "  RMSE       : 139.12\n",
      "  R²         : 0.9959\n",
      "  MAPE(%)    : 1.74\n",
      "  Accuracy(%) : 98.26\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: sarimax_output_csv\\tomato_Gadag_daily_sarimax_updated.csv\n",
      "========== Processing: tomato_Hassan_daily.csv ==========\n",
      "Metrics for tomato_Hassan_daily.csv:\n",
      "  MAE        : 427.07\n",
      "  RMSE       : 630.51\n",
      "  R²         : 0.548\n",
      "  MAPE(%)    : 54.0\n",
      "  Accuracy(%) : 46.0\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: sarimax_output_csv\\tomato_Hassan_daily_sarimax_updated.csv\n",
      "========== Processing: tomato_Haveri_daily.csv ==========\n",
      "Metrics for tomato_Haveri_daily.csv:\n",
      "  MAE        : 377.97\n",
      "  RMSE       : 503.76\n",
      "  R²         : 0.9541\n",
      "  MAPE(%)    : 15.68\n",
      "  Accuracy(%) : 84.32\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: sarimax_output_csv\\tomato_Haveri_daily_sarimax_updated.csv\n",
      "========== Processing: tomato_Kalburgi_daily.csv ==========\n",
      "Metrics for tomato_Kalburgi_daily.csv:\n",
      "  MAE        : 308.02\n",
      "  RMSE       : 609.61\n",
      "  R²         : 0.8822\n",
      "  MAPE(%)    : 19.19\n",
      "  Accuracy(%) : 80.81\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: sarimax_output_csv\\tomato_Kalburgi_daily_sarimax_updated.csv\n",
      "========== Processing: tomato_Kolar_daily.csv ==========\n",
      "Metrics for tomato_Kolar_daily.csv:\n",
      "  MAE        : 270.46\n",
      "  RMSE       : 435.06\n",
      "  R²         : 0.7543\n",
      "  MAPE(%)    : 26.97\n",
      "  Accuracy(%) : 73.03\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: sarimax_output_csv\\tomato_Kolar_daily_sarimax_updated.csv\n",
      "========== Processing: tomato_MadikeriKodagu_daily.csv ==========\n",
      "Metrics for tomato_MadikeriKodagu_daily.csv:\n",
      "  MAE        : 158.04\n",
      "  RMSE       : 262.67\n",
      "  R²         : 0.6139\n",
      "  MAPE(%)    : 20.47\n",
      "  Accuracy(%) : 79.53\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: sarimax_output_csv\\tomato_MadikeriKodagu_daily_sarimax_updated.csv\n",
      "========== Processing: tomato_Mandya_daily.csv ==========\n",
      "Metrics for tomato_Mandya_daily.csv:\n",
      "  MAE        : 362.11\n",
      "  RMSE       : 586.89\n",
      "  R²         : 0.5982\n",
      "  MAPE(%)    : 60.85\n",
      "  Accuracy(%) : 39.15\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: sarimax_output_csv\\tomato_Mandya_daily_sarimax_updated.csv\n",
      "========== Processing: tomato_Mysore_daily.csv ==========\n",
      "Metrics for tomato_Mysore_daily.csv:\n",
      "  MAE        : 429.92\n",
      "  RMSE       : 654.33\n",
      "  R²         : 0.4421\n",
      "  MAPE(%)    : 39.72\n",
      "  Accuracy(%) : 60.28\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: sarimax_output_csv\\tomato_Mysore_daily_sarimax_updated.csv\n",
      "========== Processing: tomato_Shimoga_daily.csv ==========\n",
      "Metrics for tomato_Shimoga_daily.csv:\n",
      "  MAE        : 295.21\n",
      "  RMSE       : 539.8\n",
      "  R²         : 0.6977\n",
      "  MAPE(%)    : 42.03\n",
      "  Accuracy(%) : 57.97\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: sarimax_output_csv\\tomato_Shimoga_daily_sarimax_updated.csv\n",
      "========== Processing: tomato_Tumkur_daily.csv ==========\n",
      "Metrics for tomato_Tumkur_daily.csv:\n",
      "  MAE        : 51.09\n",
      "  RMSE       : 137.62\n",
      "  R²         : 0.9905\n",
      "  MAPE(%)    : 6.22\n",
      "  Accuracy(%) : 93.78\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: sarimax_output_csv\\tomato_Tumkur_daily_sarimax_updated.csv\n",
      "========== Processing: tomato_Udupi_daily.csv ==========\n",
      "Metrics for tomato_Udupi_daily.csv:\n",
      "  MAE        : 114.32\n",
      "  RMSE       : 232.22\n",
      "  R²         : 0.9644\n",
      "  MAPE(%)    : 8.24\n",
      "  Accuracy(%) : 91.76\n",
      "\n",
      "Saved updated CSV with Date, Actual & Predicted: sarimax_output_csv\\tomato_Udupi_daily_sarimax_updated.csv\n",
      "✅ Multiple CSVs processed! Metrics saved to sarimax_metrics.csv. Models, updated CSVs, and graphs saved in respective folders.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import warnings\n",
    "import joblib\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")  # Ignore warnings\n",
    "\n",
    "# -----------------------------\n",
    "# Paths\n",
    "# -----------------------------\n",
    "input_folder = \"dataset\"\n",
    "output_models = \"sarimax_output_models\"\n",
    "output_csv = \"sarimax_output_csv\"\n",
    "output_graphs = \"sarimax_output_graphs\"\n",
    "output_metrics_csv = \"sarimax_metrics.csv\"\n",
    "\n",
    "os.makedirs(output_models, exist_ok=True)\n",
    "os.makedirs(output_csv, exist_ok=True)\n",
    "os.makedirs(output_graphs, exist_ok=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Metrics storage\n",
    "# -----------------------------\n",
    "metrics_list = []\n",
    "\n",
    "# -----------------------------\n",
    "# Robust date parsing (allow all formats)\n",
    "# -----------------------------\n",
    "def parse_dates_safe(date_series):\n",
    "    return pd.to_datetime(date_series, errors='coerce', infer_datetime_format=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Safe MAPE calculation (handle NaN/Inf)\n",
    "# -----------------------------\n",
    "def mean_absolute_percentage_error_safe(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    mask = y_true != 0\n",
    "    if mask.sum() == 0:\n",
    "        return 0.0\n",
    "    mape = np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100\n",
    "    if np.isnan(mape) or np.isinf(mape):\n",
    "        return 0.0\n",
    "    return mape\n",
    "\n",
    "# -----------------------------\n",
    "# Process each CSV\n",
    "# -----------------------------\n",
    "for file in os.listdir(input_folder):\n",
    "    if file.endswith(\".csv\"):\n",
    "        file_path = os.path.join(input_folder, file)\n",
    "        print(f\"========== Processing: {file} ==========\")\n",
    "\n",
    "        # Load CSV\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # -----------------------------\n",
    "        # Convert 'Date' column safely\n",
    "        # -----------------------------\n",
    "        df['Date'] = parse_dates_safe(df['Date'])\n",
    "        df = df.sort_values('Date')\n",
    "        df.set_index('Date', inplace=True)\n",
    "\n",
    "        # Drop rows with invalid dates\n",
    "        df = df.dropna(subset=['Average Price'])\n",
    "        if df.empty:\n",
    "            print(f\"⚠️ No valid data found in {file}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        # Handle missing values\n",
    "        if df['Average Price'].isna().sum() > 0:\n",
    "            mean_value = df['Average Price'].mean()\n",
    "            df['Average Price'].fillna(mean_value, inplace=True)\n",
    "            print(f\"Filled {df['Average Price'].isna().sum()} missing values with mean: {mean_value:.2f}\")\n",
    "\n",
    "        # Round actual values\n",
    "        df['Average Price'] = df['Average Price'].round(2)\n",
    "\n",
    "        # Add moving averages\n",
    "        df['MA_7'] = df['Average Price'].rolling(window=7).mean()\n",
    "        df['MA_30'] = df['Average Price'].rolling(window=30).mean()\n",
    "\n",
    "        # SARIMAX order (tune if needed)\n",
    "        order = (1, 1, 1)\n",
    "        seasonal_order = (1, 1, 1, 7)\n",
    "\n",
    "        # Fit SARIMAX model\n",
    "        model = SARIMAX(df['Average Price'],\n",
    "                        order=order,\n",
    "                        seasonal_order=seasonal_order,\n",
    "                        enforce_stationarity=False,\n",
    "                        enforce_invertibility=False)\n",
    "        model_fit = model.fit(disp=False)\n",
    "\n",
    "        # Save model\n",
    "        model_file = os.path.join(output_models, file.replace(\".csv\", \"_sarimax_model.pkl\"))\n",
    "        joblib.dump(model_fit, model_file)\n",
    "\n",
    "        # Predictions\n",
    "        df['Predicted'] = model_fit.predict(start=0, end=len(df)-1)\n",
    "        df['Predicted'] = df['Predicted'].round(2)  # round predictions\n",
    "\n",
    "        # Rename Average Price to Actual\n",
    "        df.rename(columns={'Average Price': 'Actual'}, inplace=True)\n",
    "\n",
    "        # Calculate metrics\n",
    "        y_true = df['Actual'].values\n",
    "        y_pred = df['Predicted'].values\n",
    "        mae = round(mean_absolute_error(y_true, y_pred), 2)\n",
    "        rmse = round(np.sqrt(mean_squared_error(y_true, y_pred)), 2)\n",
    "        r2 = round(r2_score(y_true, y_pred), 4)\n",
    "        mape = round(mean_absolute_percentage_error_safe(y_true, y_pred), 2)\n",
    "        accuracy = round(100 - mape, 2)\n",
    "\n",
    "        print(f\"Metrics for {file}:\")\n",
    "        print(f\"  MAE        : {mae}\")\n",
    "        print(f\"  RMSE       : {rmse}\")\n",
    "        print(f\"  R²         : {r2}\")\n",
    "        print(f\"  MAPE(%)    : {mape}\")\n",
    "        print(f\"  Accuracy(%) : {accuracy}\\n\")\n",
    "\n",
    "        # Save metrics\n",
    "        metrics_list.append({\n",
    "            'File': file,\n",
    "            'MAE': mae,\n",
    "            'RMSE': rmse,\n",
    "            'R2': r2,\n",
    "            'MAPE(%)': mape,\n",
    "            'Accuracy(%)': accuracy\n",
    "        })\n",
    "\n",
    "        # -----------------------------\n",
    "        # Save updated CSV with only Date, Actual, Predicted\n",
    "        # -----------------------------\n",
    "        save_df = df[['Actual', 'Predicted']].copy()\n",
    "        save_df['Date'] = df.index\n",
    "        save_df = save_df[['Date', 'Actual', 'Predicted']]\n",
    "        updated_csv_path = os.path.join(output_csv, file.replace(\".csv\", \"_sarimax_updated.csv\"))\n",
    "        save_df.to_csv(updated_csv_path, index=False)\n",
    "        print(f\"Saved updated CSV with Date, Actual & Predicted: {updated_csv_path}\")\n",
    "\n",
    "        # -----------------------------\n",
    "        # Plot graph\n",
    "        # -----------------------------\n",
    "        plt.figure(figsize=(12,6))\n",
    "        plt.plot(df.index, df['Actual'], label=\"Actual\", color=\"blue\")\n",
    "        plt.plot(df.index, df['Predicted'], label=\"Predicted\", color=\"red\", linestyle=\"dashed\")\n",
    "        plt.plot(df.index, df['MA_7'], label=\"MA 7\", color=\"orange\")\n",
    "        plt.plot(df.index, df['MA_30'], label=\"MA 30\", color=\"green\")\n",
    "        plt.xlabel(\"Date\")\n",
    "        plt.ylabel(\"Average Price\")\n",
    "        plt.title(f\"Price Prediction (SARIMAX) - {file}\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        graph_file = os.path.join(output_graphs, file.replace(\".csv\", \"_sarimax_graph.png\"))\n",
    "        plt.savefig(graph_file, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "# Save all metrics to CSV\n",
    "metrics_df = pd.DataFrame(metrics_list)\n",
    "metrics_df.to_csv(output_metrics_csv, index=False)\n",
    "print(f\"✅ Multiple CSVs processed! Metrics saved to {output_metrics_csv}. Models, updated CSVs, and graphs saved in respective folders.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1549a23-b17b-4112-b48b-175356965dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TAT+MHA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca202ab-bccc-461c-b291-6f888fc97f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Processing: tomato_Bangalore_daily.csv\n",
      "Epoch 1/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - loss: 0.0024 - mae: 0.0290 - val_loss: 0.0074 - val_mae: 0.0543\n",
      "Epoch 2/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0024 - mae: 0.0286 - val_loss: 0.0078 - val_mae: 0.0561\n",
      "Epoch 3/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 0.0027 - mae: 0.0286 - val_loss: 0.0075 - val_mae: 0.0546\n",
      "Epoch 4/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 0.0022 - mae: 0.0282 - val_loss: 0.0068 - val_mae: 0.0523\n",
      "Epoch 5/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 0.0027 - mae: 0.0293 - val_loss: 0.0072 - val_mae: 0.0537\n",
      "Epoch 6/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 0.0025 - mae: 0.0288 - val_loss: 0.0074 - val_mae: 0.0544\n",
      "Epoch 7/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - loss: 0.0026 - mae: 0.0285 - val_loss: 0.0073 - val_mae: 0.0538\n",
      "Epoch 8/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 0.0024 - mae: 0.0289 - val_loss: 0.0074 - val_mae: 0.0543\n",
      "Epoch 9/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0024 - mae: 0.0289 - val_loss: 0.0076 - val_mae: 0.0552\n",
      "Epoch 10/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 0.0023 - mae: 0.0282 - val_loss: 0.0075 - val_mae: 0.0546\n",
      "Epoch 11/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 0.0025 - mae: 0.0287 - val_loss: 0.0071 - val_mae: 0.0533\n",
      "Epoch 12/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 0.0026 - mae: 0.0292 - val_loss: 0.0074 - val_mae: 0.0543\n",
      "Epoch 13/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 0.0027 - mae: 0.0292 - val_loss: 0.0074 - val_mae: 0.0543\n",
      "Epoch 14/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 0.0024 - mae: 0.0285 - val_loss: 0.0072 - val_mae: 0.0537\n",
      "Epoch 15/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 0.0026 - mae: 0.0289 - val_loss: 0.0078 - val_mae: 0.0561\n",
      "Epoch 16/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 0.0026 - mae: 0.0288 - val_loss: 0.0076 - val_mae: 0.0552\n",
      "Epoch 17/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 0.0025 - mae: 0.0284 - val_loss: 0.0076 - val_mae: 0.0550\n",
      "Epoch 18/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 0.0023 - mae: 0.0281 - val_loss: 0.0070 - val_mae: 0.0528\n",
      "Epoch 19/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 0.0024 - mae: 0.0287 - val_loss: 0.0074 - val_mae: 0.0542\n",
      "Epoch 20/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 0.0025 - mae: 0.0286 - val_loss: 0.0079 - val_mae: 0.0567\n",
      "Epoch 21/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 0.0024 - mae: 0.0284 - val_loss: 0.0073 - val_mae: 0.0538\n",
      "Epoch 22/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 0.0024 - mae: 0.0284 - val_loss: 0.0070 - val_mae: 0.0528\n",
      "Epoch 23/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 0.0026 - mae: 0.0290 - val_loss: 0.0073 - val_mae: 0.0541\n",
      "Epoch 24/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 0.0025 - mae: 0.0286 - val_loss: 0.0077 - val_mae: 0.0556\n",
      "Epoch 25/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0027 - mae: 0.0291 - val_loss: 0.0071 - val_mae: 0.0532\n",
      "Epoch 26/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 0.0025 - mae: 0.0284 - val_loss: 0.0074 - val_mae: 0.0542\n",
      "Epoch 27/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 0.0025 - mae: 0.0287 - val_loss: 0.0073 - val_mae: 0.0540\n",
      "Epoch 28/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 0.0027 - mae: 0.0294 - val_loss: 0.0079 - val_mae: 0.0567\n",
      "Epoch 29/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 0.0027 - mae: 0.0285 - val_loss: 0.0074 - val_mae: 0.0543\n",
      "Epoch 30/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 0.0025 - mae: 0.0287 - val_loss: 0.0075 - val_mae: 0.0546\n",
      "Epoch 31/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 0.0020 - mae: 0.0280 - val_loss: 0.0071 - val_mae: 0.0532\n",
      "Epoch 32/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 0.0023 - mae: 0.0286 - val_loss: 0.0080 - val_mae: 0.0569\n",
      "Epoch 33/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - loss: 0.0023 - mae: 0.0282 - val_loss: 0.0073 - val_mae: 0.0539\n",
      "Epoch 34/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0022 - mae: 0.0281 - val_loss: 0.0069 - val_mae: 0.0525\n",
      "Epoch 35/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0026 - mae: 0.0290 - val_loss: 0.0075 - val_mae: 0.0546\n",
      "Epoch 36/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0023 - mae: 0.0280 - val_loss: 0.0074 - val_mae: 0.0543\n",
      "Epoch 37/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0025 - mae: 0.0285 - val_loss: 0.0071 - val_mae: 0.0531\n",
      "Epoch 38/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0025 - mae: 0.0284 - val_loss: 0.0074 - val_mae: 0.0543\n",
      "Epoch 39/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0023 - mae: 0.0285 - val_loss: 0.0074 - val_mae: 0.0543\n",
      "Epoch 40/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0024 - mae: 0.0285 - val_loss: 0.0075 - val_mae: 0.0549\n",
      "Epoch 41/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0025 - mae: 0.0285 - val_loss: 0.0071 - val_mae: 0.0533\n",
      "Epoch 42/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0285 - val_loss: 0.0075 - val_mae: 0.0546\n",
      "Epoch 43/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0025 - mae: 0.0285 - val_loss: 0.0077 - val_mae: 0.0557\n",
      "Epoch 44/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0023 - mae: 0.0284 - val_loss: 0.0075 - val_mae: 0.0546\n",
      "Epoch 45/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0025 - mae: 0.0285 - val_loss: 0.0077 - val_mae: 0.0556\n",
      "Epoch 46/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0023 - mae: 0.0281 - val_loss: 0.0077 - val_mae: 0.0555\n",
      "Epoch 47/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0285 - val_loss: 0.0071 - val_mae: 0.0534\n",
      "Epoch 48/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - loss: 0.0024 - mae: 0.0282 - val_loss: 0.0075 - val_mae: 0.0547\n",
      "Epoch 49/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0285 - val_loss: 0.0073 - val_mae: 0.0539\n",
      "Epoch 50/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - loss: 0.0026 - mae: 0.0291 - val_loss: 0.0072 - val_mae: 0.0537\n",
      "Epoch 51/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0025 - mae: 0.0294 - val_loss: 0.0075 - val_mae: 0.0546\n",
      "Epoch 52/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0023 - mae: 0.0287 - val_loss: 0.0073 - val_mae: 0.0538\n",
      "Epoch 53/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0027 - mae: 0.0284 - val_loss: 0.0077 - val_mae: 0.0555\n",
      "Epoch 54/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0026 - mae: 0.0289 - val_loss: 0.0077 - val_mae: 0.0555\n",
      "Epoch 55/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0027 - mae: 0.0291 - val_loss: 0.0077 - val_mae: 0.0557\n",
      "Epoch 56/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0024 - mae: 0.0284 - val_loss: 0.0073 - val_mae: 0.0539\n",
      "Epoch 57/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - loss: 0.0024 - mae: 0.0283 - val_loss: 0.0074 - val_mae: 0.0544\n",
      "Epoch 58/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0026 - mae: 0.0287 - val_loss: 0.0075 - val_mae: 0.0546\n",
      "Epoch 59/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0026 - mae: 0.0292 - val_loss: 0.0073 - val_mae: 0.0539\n",
      "Epoch 60/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0022 - mae: 0.0278 - val_loss: 0.0075 - val_mae: 0.0547\n",
      "Epoch 61/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0024 - mae: 0.0286 - val_loss: 0.0074 - val_mae: 0.0545\n",
      "Epoch 62/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0025 - mae: 0.0288 - val_loss: 0.0075 - val_mae: 0.0547\n",
      "Epoch 63/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0025 - mae: 0.0286 - val_loss: 0.0075 - val_mae: 0.0549\n",
      "Epoch 64/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0023 - mae: 0.0282 - val_loss: 0.0076 - val_mae: 0.0551\n",
      "Epoch 65/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0027 - mae: 0.0290 - val_loss: 0.0072 - val_mae: 0.0535\n",
      "Epoch 66/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0025 - mae: 0.0283 - val_loss: 0.0071 - val_mae: 0.0533\n",
      "Epoch 67/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0024 - mae: 0.0287 - val_loss: 0.0075 - val_mae: 0.0548\n",
      "Epoch 68/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0022 - mae: 0.0281 - val_loss: 0.0074 - val_mae: 0.0543\n",
      "Epoch 69/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0024 - mae: 0.0287 - val_loss: 0.0075 - val_mae: 0.0548\n",
      "Epoch 70/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0028 - mae: 0.0293 - val_loss: 0.0072 - val_mae: 0.0535\n",
      "Epoch 71/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0027 - mae: 0.0291 - val_loss: 0.0075 - val_mae: 0.0547\n",
      "Epoch 72/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0024 - mae: 0.0284 - val_loss: 0.0076 - val_mae: 0.0551\n",
      "Epoch 73/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0026 - mae: 0.0287 - val_loss: 0.0076 - val_mae: 0.0552\n",
      "Epoch 74/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0024 - mae: 0.0286 - val_loss: 0.0074 - val_mae: 0.0542\n",
      "Epoch 75/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0027 - mae: 0.0289 - val_loss: 0.0072 - val_mae: 0.0538\n",
      "Epoch 76/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0025 - mae: 0.0283 - val_loss: 0.0074 - val_mae: 0.0542\n",
      "Epoch 77/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0025 - mae: 0.0286 - val_loss: 0.0068 - val_mae: 0.0523\n",
      "Epoch 78/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0026 - mae: 0.0291 - val_loss: 0.0074 - val_mae: 0.0543\n",
      "Epoch 79/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0022 - mae: 0.0280 - val_loss: 0.0068 - val_mae: 0.0524\n",
      "Epoch 80/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0024 - mae: 0.0287 - val_loss: 0.0075 - val_mae: 0.0547\n",
      "Epoch 81/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0028 - mae: 0.0287 - val_loss: 0.0073 - val_mae: 0.0541\n",
      "Epoch 82/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0024 - mae: 0.0283 - val_loss: 0.0074 - val_mae: 0.0544\n",
      "Epoch 83/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0028 - mae: 0.0294 - val_loss: 0.0074 - val_mae: 0.0544\n",
      "Epoch 84/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0026 - mae: 0.0290 - val_loss: 0.0076 - val_mae: 0.0550\n",
      "Epoch 85/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0026 - mae: 0.0292 - val_loss: 0.0076 - val_mae: 0.0550\n",
      "Epoch 86/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0022 - mae: 0.0279 - val_loss: 0.0074 - val_mae: 0.0542\n",
      "Epoch 87/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0025 - mae: 0.0287 - val_loss: 0.0076 - val_mae: 0.0553\n",
      "Epoch 88/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0025 - mae: 0.0283 - val_loss: 0.0079 - val_mae: 0.0566\n",
      "Epoch 89/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0022 - mae: 0.0281 - val_loss: 0.0072 - val_mae: 0.0537\n",
      "Epoch 90/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0026 - mae: 0.0287 - val_loss: 0.0073 - val_mae: 0.0541\n",
      "Epoch 91/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0024 - mae: 0.0279 - val_loss: 0.0072 - val_mae: 0.0537\n",
      "Epoch 92/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0025 - mae: 0.0290 - val_loss: 0.0077 - val_mae: 0.0556\n",
      "Epoch 93/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0024 - mae: 0.0283 - val_loss: 0.0075 - val_mae: 0.0549\n",
      "Epoch 94/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0025 - mae: 0.0287 - val_loss: 0.0071 - val_mae: 0.0531\n",
      "Epoch 95/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0024 - mae: 0.0290 - val_loss: 0.0074 - val_mae: 0.0546\n",
      "Epoch 96/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0026 - mae: 0.0288 - val_loss: 0.0070 - val_mae: 0.0528\n",
      "Epoch 97/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0027 - mae: 0.0288 - val_loss: 0.0074 - val_mae: 0.0543\n",
      "Epoch 98/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0023 - mae: 0.0284 - val_loss: 0.0077 - val_mae: 0.0556\n",
      "Epoch 99/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0021 - mae: 0.0278 - val_loss: 0.0074 - val_mae: 0.0543\n",
      "Epoch 100/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0025 - mae: 0.0289 - val_loss: 0.0074 - val_mae: 0.0543\n",
      "\u001b[1m864/864\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step\n",
      "✅ Done with tomato_Bangalore_daily.csv | MAE=838.35, RMSE=1463.14, R2=-0.0215, MAPE=72.59%, Accuracy=27.41%\n",
      "\n",
      "🚀 Processing: tomato_Belgaum_daily.csv\n",
      "Epoch 1/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0093 - mae: 0.0755 - val_loss: 0.0486 - val_mae: 0.1585\n",
      "Epoch 2/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0057 - mae: 0.0620 - val_loss: 0.0509 - val_mae: 0.1647\n",
      "Epoch 3/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0058 - mae: 0.0630 - val_loss: 0.0464 - val_mae: 0.1529\n",
      "Epoch 4/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0058 - mae: 0.0627 - val_loss: 0.0478 - val_mae: 0.1564\n",
      "Epoch 5/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0060 - mae: 0.0642 - val_loss: 0.0471 - val_mae: 0.1547\n",
      "Epoch 6/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0059 - mae: 0.0639 - val_loss: 0.0463 - val_mae: 0.1525\n",
      "Epoch 7/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0059 - mae: 0.0639 - val_loss: 0.0508 - val_mae: 0.1646\n",
      "Epoch 8/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0060 - mae: 0.0637 - val_loss: 0.0490 - val_mae: 0.1596\n",
      "Epoch 9/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0059 - mae: 0.0635 - val_loss: 0.0471 - val_mae: 0.1548\n",
      "Epoch 10/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0056 - mae: 0.0615 - val_loss: 0.0471 - val_mae: 0.1546\n",
      "Epoch 11/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0055 - mae: 0.0611 - val_loss: 0.0497 - val_mae: 0.1617\n",
      "Epoch 12/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0060 - mae: 0.0641 - val_loss: 0.0495 - val_mae: 0.1610\n",
      "Epoch 13/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0060 - mae: 0.0642 - val_loss: 0.0501 - val_mae: 0.1626\n",
      "Epoch 14/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0058 - mae: 0.0632 - val_loss: 0.0495 - val_mae: 0.1610\n",
      "Epoch 15/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0059 - mae: 0.0632 - val_loss: 0.0488 - val_mae: 0.1591\n",
      "Epoch 16/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0059 - mae: 0.0634 - val_loss: 0.0481 - val_mae: 0.1574\n",
      "Epoch 17/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0059 - mae: 0.0632 - val_loss: 0.0478 - val_mae: 0.1565\n",
      "Epoch 18/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0060 - mae: 0.0639 - val_loss: 0.0479 - val_mae: 0.1567\n",
      "Epoch 19/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0060 - mae: 0.0637 - val_loss: 0.0477 - val_mae: 0.1561\n",
      "Epoch 20/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0059 - mae: 0.0630 - val_loss: 0.0498 - val_mae: 0.1617\n",
      "Epoch 21/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0057 - mae: 0.0620 - val_loss: 0.0473 - val_mae: 0.1552\n",
      "Epoch 22/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0058 - mae: 0.0630 - val_loss: 0.0478 - val_mae: 0.1564\n",
      "Epoch 23/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0060 - mae: 0.0639 - val_loss: 0.0481 - val_mae: 0.1573\n",
      "Epoch 24/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0059 - mae: 0.0629 - val_loss: 0.0489 - val_mae: 0.1594\n",
      "Epoch 25/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0059 - mae: 0.0635 - val_loss: 0.0485 - val_mae: 0.1583\n",
      "Epoch 26/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0057 - mae: 0.0629 - val_loss: 0.0475 - val_mae: 0.1557\n",
      "Epoch 27/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0059 - mae: 0.0637 - val_loss: 0.0484 - val_mae: 0.1581\n",
      "Epoch 28/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0057 - mae: 0.0624 - val_loss: 0.0469 - val_mae: 0.1542\n",
      "Epoch 29/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0057 - mae: 0.0625 - val_loss: 0.0490 - val_mae: 0.1597\n",
      "Epoch 30/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0059 - mae: 0.0637 - val_loss: 0.0505 - val_mae: 0.1637\n",
      "Epoch 31/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0060 - mae: 0.0634 - val_loss: 0.0460 - val_mae: 0.1519\n",
      "Epoch 32/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0059 - mae: 0.0632 - val_loss: 0.0492 - val_mae: 0.1603\n",
      "Epoch 33/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0059 - mae: 0.0636 - val_loss: 0.0494 - val_mae: 0.1607\n",
      "Epoch 34/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0058 - mae: 0.0631 - val_loss: 0.0478 - val_mae: 0.1566\n",
      "Epoch 35/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0058 - mae: 0.0630 - val_loss: 0.0483 - val_mae: 0.1577\n",
      "Epoch 36/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0058 - mae: 0.0632 - val_loss: 0.0481 - val_mae: 0.1573\n",
      "Epoch 37/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0057 - mae: 0.0628 - val_loss: 0.0497 - val_mae: 0.1615\n",
      "Epoch 38/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0059 - mae: 0.0635 - val_loss: 0.0508 - val_mae: 0.1646\n",
      "Epoch 39/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0057 - mae: 0.0625 - val_loss: 0.0472 - val_mae: 0.1549\n",
      "Epoch 40/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0058 - mae: 0.0634 - val_loss: 0.0491 - val_mae: 0.1598\n",
      "Epoch 41/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0058 - mae: 0.0628 - val_loss: 0.0497 - val_mae: 0.1615\n",
      "Epoch 42/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0059 - mae: 0.0632 - val_loss: 0.0480 - val_mae: 0.1570\n",
      "Epoch 43/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0059 - mae: 0.0636 - val_loss: 0.0472 - val_mae: 0.1549\n",
      "Epoch 44/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0058 - mae: 0.0637 - val_loss: 0.0480 - val_mae: 0.1571\n",
      "Epoch 45/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0059 - mae: 0.0635 - val_loss: 0.0487 - val_mae: 0.1588\n",
      "Epoch 46/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0059 - mae: 0.0633 - val_loss: 0.0489 - val_mae: 0.1594\n",
      "Epoch 47/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0059 - mae: 0.0639 - val_loss: 0.0499 - val_mae: 0.1620\n",
      "Epoch 48/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0059 - mae: 0.0630 - val_loss: 0.0493 - val_mae: 0.1604\n",
      "Epoch 49/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0057 - mae: 0.0625 - val_loss: 0.0486 - val_mae: 0.1586\n",
      "Epoch 50/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0057 - mae: 0.0622 - val_loss: 0.0489 - val_mae: 0.1595\n",
      "Epoch 51/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0057 - mae: 0.0624 - val_loss: 0.0471 - val_mae: 0.1547\n",
      "Epoch 52/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0058 - mae: 0.0628 - val_loss: 0.0466 - val_mae: 0.1534\n",
      "Epoch 53/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0059 - mae: 0.0635 - val_loss: 0.0488 - val_mae: 0.1592\n",
      "Epoch 54/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0057 - mae: 0.0628 - val_loss: 0.0475 - val_mae: 0.1557\n",
      "Epoch 55/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0059 - mae: 0.0636 - val_loss: 0.0495 - val_mae: 0.1611\n",
      "Epoch 56/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0058 - mae: 0.0633 - val_loss: 0.0499 - val_mae: 0.1620\n",
      "Epoch 57/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0061 - mae: 0.0638 - val_loss: 0.0505 - val_mae: 0.1638\n",
      "Epoch 58/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0060 - mae: 0.0640 - val_loss: 0.0506 - val_mae: 0.1638\n",
      "Epoch 59/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0058 - mae: 0.0622 - val_loss: 0.0494 - val_mae: 0.1607\n",
      "Epoch 60/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0060 - mae: 0.0636 - val_loss: 0.0487 - val_mae: 0.1588\n",
      "Epoch 61/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0058 - mae: 0.0625 - val_loss: 0.0481 - val_mae: 0.1573\n",
      "Epoch 62/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0057 - mae: 0.0627 - val_loss: 0.0487 - val_mae: 0.1589\n",
      "Epoch 63/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0058 - mae: 0.0629 - val_loss: 0.0480 - val_mae: 0.1571\n",
      "Epoch 64/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0060 - mae: 0.0642 - val_loss: 0.0500 - val_mae: 0.1624\n",
      "Epoch 65/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0058 - mae: 0.0628 - val_loss: 0.0470 - val_mae: 0.1544\n",
      "Epoch 66/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0060 - mae: 0.0639 - val_loss: 0.0481 - val_mae: 0.1574\n",
      "Epoch 67/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0057 - mae: 0.0629 - val_loss: 0.0487 - val_mae: 0.1590\n",
      "Epoch 68/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0059 - mae: 0.0637 - val_loss: 0.0491 - val_mae: 0.1600\n",
      "Epoch 69/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0059 - mae: 0.0635 - val_loss: 0.0503 - val_mae: 0.1631\n",
      "Epoch 70/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0059 - mae: 0.0631 - val_loss: 0.0484 - val_mae: 0.1581\n",
      "Epoch 71/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0056 - mae: 0.0617 - val_loss: 0.0477 - val_mae: 0.1563\n",
      "Epoch 72/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0059 - mae: 0.0632 - val_loss: 0.0477 - val_mae: 0.1563\n",
      "Epoch 73/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0059 - mae: 0.0634 - val_loss: 0.0472 - val_mae: 0.1550\n",
      "Epoch 74/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0060 - mae: 0.0642 - val_loss: 0.0488 - val_mae: 0.1590\n",
      "Epoch 75/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0058 - mae: 0.0635 - val_loss: 0.0476 - val_mae: 0.1560\n",
      "Epoch 76/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0061 - mae: 0.0641 - val_loss: 0.0472 - val_mae: 0.1550\n",
      "Epoch 77/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0061 - mae: 0.0647 - val_loss: 0.0479 - val_mae: 0.1569\n",
      "Epoch 78/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0060 - mae: 0.0641 - val_loss: 0.0469 - val_mae: 0.1541\n",
      "Epoch 79/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0060 - mae: 0.0642 - val_loss: 0.0484 - val_mae: 0.1581\n",
      "Epoch 80/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0058 - mae: 0.0626 - val_loss: 0.0476 - val_mae: 0.1559\n",
      "Epoch 81/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0059 - mae: 0.0633 - val_loss: 0.0498 - val_mae: 0.1618\n",
      "Epoch 82/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0060 - mae: 0.0636 - val_loss: 0.0466 - val_mae: 0.1535\n",
      "Epoch 83/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0057 - mae: 0.0628 - val_loss: 0.0473 - val_mae: 0.1551\n",
      "Epoch 84/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0059 - mae: 0.0634 - val_loss: 0.0468 - val_mae: 0.1538\n",
      "Epoch 85/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0061 - mae: 0.0645 - val_loss: 0.0484 - val_mae: 0.1582\n",
      "Epoch 86/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0060 - mae: 0.0640 - val_loss: 0.0501 - val_mae: 0.1626\n",
      "Epoch 87/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0061 - mae: 0.0640 - val_loss: 0.0500 - val_mae: 0.1623\n",
      "Epoch 88/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0057 - mae: 0.0627 - val_loss: 0.0470 - val_mae: 0.1545\n",
      "Epoch 89/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0058 - mae: 0.0628 - val_loss: 0.0507 - val_mae: 0.1641\n",
      "Epoch 90/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0059 - mae: 0.0635 - val_loss: 0.0493 - val_mae: 0.1605\n",
      "Epoch 91/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0057 - mae: 0.0627 - val_loss: 0.0489 - val_mae: 0.1594\n",
      "Epoch 92/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0058 - mae: 0.0631 - val_loss: 0.0493 - val_mae: 0.1604\n",
      "Epoch 93/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0061 - mae: 0.0645 - val_loss: 0.0483 - val_mae: 0.1578\n",
      "Epoch 94/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0057 - mae: 0.0622 - val_loss: 0.0480 - val_mae: 0.1570\n",
      "Epoch 95/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0058 - mae: 0.0629 - val_loss: 0.0479 - val_mae: 0.1567\n",
      "Epoch 96/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0057 - mae: 0.0621 - val_loss: 0.0475 - val_mae: 0.1558\n",
      "Epoch 97/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0060 - mae: 0.0638 - val_loss: 0.0490 - val_mae: 0.1596\n",
      "Epoch 98/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0060 - mae: 0.0642 - val_loss: 0.0477 - val_mae: 0.1563\n",
      "Epoch 99/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0058 - mae: 0.0631 - val_loss: 0.0479 - val_mae: 0.1568\n",
      "Epoch 100/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0058 - mae: 0.0628 - val_loss: 0.0472 - val_mae: 0.1549\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "✅ Done with tomato_Belgaum_daily.csv | MAE=793.39, RMSE=1152.66, R2=-0.0535, MAPE=61.69%, Accuracy=38.31%\n",
      "\n",
      "🚀 Processing: tomato_Bellary_daily.csv\n",
      "Epoch 1/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0069 - mae: 0.0618 - val_loss: 0.0244 - val_mae: 0.0756\n",
      "Epoch 2/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0042 - mae: 0.0497 - val_loss: 0.0248 - val_mae: 0.0741\n",
      "Epoch 3/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0044 - mae: 0.0501 - val_loss: 0.0248 - val_mae: 0.0742\n",
      "Epoch 4/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0045 - mae: 0.0496 - val_loss: 0.0246 - val_mae: 0.0749\n",
      "Epoch 5/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0041 - mae: 0.0501 - val_loss: 0.0248 - val_mae: 0.0742\n",
      "Epoch 6/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0038 - mae: 0.0483 - val_loss: 0.0246 - val_mae: 0.0747\n",
      "Epoch 7/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0039 - mae: 0.0488 - val_loss: 0.0244 - val_mae: 0.0760\n",
      "Epoch 8/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0041 - mae: 0.0487 - val_loss: 0.0248 - val_mae: 0.0740\n",
      "Epoch 9/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0043 - mae: 0.0496 - val_loss: 0.0246 - val_mae: 0.0747\n",
      "Epoch 10/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0041 - mae: 0.0485 - val_loss: 0.0248 - val_mae: 0.0741\n",
      "Epoch 11/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0039 - mae: 0.0487 - val_loss: 0.0247 - val_mae: 0.0744\n",
      "Epoch 12/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0044 - mae: 0.0493 - val_loss: 0.0245 - val_mae: 0.0752\n",
      "Epoch 13/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0038 - mae: 0.0480 - val_loss: 0.0245 - val_mae: 0.0752\n",
      "Epoch 14/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0038 - mae: 0.0481 - val_loss: 0.0247 - val_mae: 0.0746\n",
      "Epoch 15/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0041 - mae: 0.0492 - val_loss: 0.0247 - val_mae: 0.0745\n",
      "Epoch 16/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0039 - mae: 0.0497 - val_loss: 0.0246 - val_mae: 0.0747\n",
      "Epoch 17/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0042 - mae: 0.0494 - val_loss: 0.0246 - val_mae: 0.0748\n",
      "Epoch 18/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0036 - mae: 0.0477 - val_loss: 0.0245 - val_mae: 0.0752\n",
      "Epoch 19/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0040 - mae: 0.0488 - val_loss: 0.0246 - val_mae: 0.0747\n",
      "Epoch 20/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0041 - mae: 0.0488 - val_loss: 0.0247 - val_mae: 0.0743\n",
      "Epoch 21/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0040 - mae: 0.0484 - val_loss: 0.0246 - val_mae: 0.0747\n",
      "Epoch 22/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0039 - mae: 0.0486 - val_loss: 0.0247 - val_mae: 0.0744\n",
      "Epoch 23/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0036 - mae: 0.0469 - val_loss: 0.0245 - val_mae: 0.0751\n",
      "Epoch 24/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0041 - mae: 0.0496 - val_loss: 0.0246 - val_mae: 0.0748\n",
      "Epoch 25/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0038 - mae: 0.0480 - val_loss: 0.0245 - val_mae: 0.0753\n",
      "Epoch 26/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0039 - mae: 0.0483 - val_loss: 0.0248 - val_mae: 0.0740\n",
      "Epoch 27/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0038 - mae: 0.0480 - val_loss: 0.0244 - val_mae: 0.0758\n",
      "Epoch 28/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0036 - mae: 0.0486 - val_loss: 0.0247 - val_mae: 0.0745\n",
      "Epoch 29/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0039 - mae: 0.0479 - val_loss: 0.0248 - val_mae: 0.0742\n",
      "Epoch 30/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0042 - mae: 0.0491 - val_loss: 0.0249 - val_mae: 0.0739\n",
      "Epoch 31/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0038 - mae: 0.0479 - val_loss: 0.0243 - val_mae: 0.0768\n",
      "Epoch 32/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0040 - mae: 0.0495 - val_loss: 0.0246 - val_mae: 0.0749\n",
      "Epoch 33/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0037 - mae: 0.0485 - val_loss: 0.0246 - val_mae: 0.0749\n",
      "Epoch 34/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0041 - mae: 0.0496 - val_loss: 0.0249 - val_mae: 0.0739\n",
      "Epoch 35/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0043 - mae: 0.0488 - val_loss: 0.0246 - val_mae: 0.0747\n",
      "Epoch 36/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0039 - mae: 0.0479 - val_loss: 0.0245 - val_mae: 0.0754\n",
      "Epoch 37/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0041 - mae: 0.0488 - val_loss: 0.0252 - val_mae: 0.0732\n",
      "Epoch 38/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0039 - mae: 0.0483 - val_loss: 0.0246 - val_mae: 0.0749\n",
      "Epoch 39/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0037 - mae: 0.0477 - val_loss: 0.0245 - val_mae: 0.0754\n",
      "Epoch 40/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0040 - mae: 0.0497 - val_loss: 0.0248 - val_mae: 0.0741\n",
      "Epoch 41/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0042 - mae: 0.0497 - val_loss: 0.0246 - val_mae: 0.0747\n",
      "Epoch 42/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0041 - mae: 0.0485 - val_loss: 0.0247 - val_mae: 0.0743\n",
      "Epoch 43/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0042 - mae: 0.0498 - val_loss: 0.0249 - val_mae: 0.0739\n",
      "Epoch 44/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0038 - mae: 0.0484 - val_loss: 0.0245 - val_mae: 0.0753\n",
      "Epoch 45/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0044 - mae: 0.0497 - val_loss: 0.0247 - val_mae: 0.0743\n",
      "Epoch 46/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0038 - mae: 0.0479 - val_loss: 0.0244 - val_mae: 0.0758\n",
      "Epoch 47/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0043 - mae: 0.0493 - val_loss: 0.0247 - val_mae: 0.0744\n",
      "Epoch 48/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0040 - mae: 0.0486 - val_loss: 0.0246 - val_mae: 0.0747\n",
      "Epoch 49/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0040 - mae: 0.0491 - val_loss: 0.0246 - val_mae: 0.0746\n",
      "Epoch 50/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0040 - mae: 0.0494 - val_loss: 0.0246 - val_mae: 0.0748\n",
      "Epoch 51/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0039 - mae: 0.0486 - val_loss: 0.0251 - val_mae: 0.0734\n",
      "Epoch 52/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0037 - mae: 0.0472 - val_loss: 0.0244 - val_mae: 0.0759\n",
      "Epoch 53/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0039 - mae: 0.0488 - val_loss: 0.0246 - val_mae: 0.0749\n",
      "Epoch 54/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0038 - mae: 0.0481 - val_loss: 0.0246 - val_mae: 0.0751\n",
      "Epoch 55/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0041 - mae: 0.0494 - val_loss: 0.0249 - val_mae: 0.0739\n",
      "Epoch 56/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0039 - mae: 0.0481 - val_loss: 0.0246 - val_mae: 0.0748\n",
      "Epoch 57/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0039 - mae: 0.0486 - val_loss: 0.0249 - val_mae: 0.0738\n",
      "Epoch 58/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0038 - mae: 0.0478 - val_loss: 0.0249 - val_mae: 0.0739\n",
      "Epoch 59/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0043 - mae: 0.0492 - val_loss: 0.0251 - val_mae: 0.0733\n",
      "Epoch 60/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0037 - mae: 0.0475 - val_loss: 0.0246 - val_mae: 0.0750\n",
      "Epoch 61/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0039 - mae: 0.0486 - val_loss: 0.0249 - val_mae: 0.0738\n",
      "Epoch 62/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0040 - mae: 0.0495 - val_loss: 0.0255 - val_mae: 0.0728\n",
      "Epoch 63/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0037 - mae: 0.0472 - val_loss: 0.0247 - val_mae: 0.0744\n",
      "Epoch 64/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0041 - mae: 0.0494 - val_loss: 0.0249 - val_mae: 0.0739\n",
      "Epoch 65/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0039 - mae: 0.0478 - val_loss: 0.0247 - val_mae: 0.0745\n",
      "Epoch 66/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0042 - mae: 0.0489 - val_loss: 0.0245 - val_mae: 0.0753\n",
      "Epoch 67/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0043 - mae: 0.0497 - val_loss: 0.0245 - val_mae: 0.0751\n",
      "Epoch 68/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0038 - mae: 0.0484 - val_loss: 0.0248 - val_mae: 0.0742\n",
      "Epoch 69/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0040 - mae: 0.0485 - val_loss: 0.0246 - val_mae: 0.0747\n",
      "Epoch 70/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0037 - mae: 0.0478 - val_loss: 0.0250 - val_mae: 0.0736\n",
      "Epoch 71/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0037 - mae: 0.0484 - val_loss: 0.0246 - val_mae: 0.0747\n",
      "Epoch 72/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0041 - mae: 0.0485 - val_loss: 0.0247 - val_mae: 0.0744\n",
      "Epoch 73/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0040 - mae: 0.0483 - val_loss: 0.0246 - val_mae: 0.0748\n",
      "Epoch 74/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0039 - mae: 0.0479 - val_loss: 0.0244 - val_mae: 0.0758\n",
      "Epoch 75/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0038 - mae: 0.0484 - val_loss: 0.0248 - val_mae: 0.0741\n",
      "Epoch 76/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0039 - mae: 0.0484 - val_loss: 0.0247 - val_mae: 0.0744\n",
      "Epoch 77/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0044 - mae: 0.0496 - val_loss: 0.0245 - val_mae: 0.0751\n",
      "Epoch 78/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0046 - mae: 0.0494 - val_loss: 0.0248 - val_mae: 0.0740\n",
      "Epoch 79/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0040 - mae: 0.0483 - val_loss: 0.0247 - val_mae: 0.0744\n",
      "Epoch 80/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0040 - mae: 0.0490 - val_loss: 0.0251 - val_mae: 0.0734\n",
      "Epoch 81/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0042 - mae: 0.0491 - val_loss: 0.0249 - val_mae: 0.0738\n",
      "Epoch 82/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0038 - mae: 0.0481 - val_loss: 0.0245 - val_mae: 0.0754\n",
      "Epoch 83/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0038 - mae: 0.0488 - val_loss: 0.0245 - val_mae: 0.0755\n",
      "Epoch 84/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0039 - mae: 0.0486 - val_loss: 0.0246 - val_mae: 0.0750\n",
      "Epoch 85/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0040 - mae: 0.0492 - val_loss: 0.0249 - val_mae: 0.0738\n",
      "Epoch 86/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0039 - mae: 0.0478 - val_loss: 0.0249 - val_mae: 0.0738\n",
      "Epoch 87/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0039 - mae: 0.0479 - val_loss: 0.0246 - val_mae: 0.0747\n",
      "Epoch 88/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0038 - mae: 0.0482 - val_loss: 0.0247 - val_mae: 0.0744\n",
      "Epoch 89/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0040 - mae: 0.0487 - val_loss: 0.0247 - val_mae: 0.0743\n",
      "Epoch 90/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0043 - mae: 0.0496 - val_loss: 0.0250 - val_mae: 0.0736\n",
      "Epoch 91/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0039 - mae: 0.0480 - val_loss: 0.0246 - val_mae: 0.0749\n",
      "Epoch 92/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0039 - mae: 0.0487 - val_loss: 0.0245 - val_mae: 0.0753\n",
      "Epoch 93/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0043 - mae: 0.0494 - val_loss: 0.0244 - val_mae: 0.0759\n",
      "Epoch 94/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0041 - mae: 0.0493 - val_loss: 0.0247 - val_mae: 0.0743\n",
      "Epoch 95/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0038 - mae: 0.0479 - val_loss: 0.0246 - val_mae: 0.0749\n",
      "Epoch 96/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0039 - mae: 0.0486 - val_loss: 0.0247 - val_mae: 0.0745\n",
      "Epoch 97/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0039 - mae: 0.0484 - val_loss: 0.0244 - val_mae: 0.0758\n",
      "Epoch 98/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0043 - mae: 0.0504 - val_loss: 0.0247 - val_mae: 0.0745\n",
      "Epoch 99/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0041 - mae: 0.0487 - val_loss: 0.0249 - val_mae: 0.0738\n",
      "Epoch 100/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0041 - mae: 0.0482 - val_loss: 0.0249 - val_mae: 0.0739\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "✅ Done with tomato_Bellary_daily.csv | MAE=368.47, RMSE=624.67, R2=-0.0085, MAPE=48.93%, Accuracy=51.07%\n",
      "\n",
      "🚀 Processing: tomato_Chamrajnagar_daily.csv\n",
      "Epoch 1/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - loss: 5.1576e-04 - mae: 0.0152 - val_loss: 0.0036 - val_mae: 0.0401\n",
      "Epoch 2/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 5.0045e-04 - mae: 0.0154 - val_loss: 0.0036 - val_mae: 0.0399\n",
      "Epoch 3/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 4.9087e-04 - mae: 0.0151 - val_loss: 0.0037 - val_mae: 0.0403\n",
      "Epoch 4/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 5.1326e-04 - mae: 0.0154 - val_loss: 0.0034 - val_mae: 0.0391\n",
      "Epoch 5/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 5.3199e-04 - mae: 0.0160 - val_loss: 0.0037 - val_mae: 0.0403\n",
      "Epoch 6/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 4.9297e-04 - mae: 0.0151 - val_loss: 0.0037 - val_mae: 0.0405\n",
      "Epoch 7/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 5.1578e-04 - mae: 0.0155 - val_loss: 0.0036 - val_mae: 0.0397\n",
      "Epoch 8/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 5.4126e-04 - mae: 0.0159 - val_loss: 0.0036 - val_mae: 0.0398\n",
      "Epoch 9/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 5.0942e-04 - mae: 0.0154 - val_loss: 0.0035 - val_mae: 0.0397\n",
      "Epoch 10/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 5.1393e-04 - mae: 0.0155 - val_loss: 0.0038 - val_mae: 0.0412\n",
      "Epoch 11/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 5.0671e-04 - mae: 0.0152 - val_loss: 0.0036 - val_mae: 0.0400\n",
      "Epoch 12/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 5.0711e-04 - mae: 0.0154 - val_loss: 0.0035 - val_mae: 0.0397\n",
      "Epoch 13/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 5.0356e-04 - mae: 0.0153 - val_loss: 0.0036 - val_mae: 0.0400\n",
      "Epoch 14/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 5.0417e-04 - mae: 0.0152 - val_loss: 0.0035 - val_mae: 0.0397\n",
      "Epoch 15/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 5.1685e-04 - mae: 0.0155 - val_loss: 0.0033 - val_mae: 0.0387\n",
      "Epoch 16/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 5.0448e-04 - mae: 0.0154 - val_loss: 0.0035 - val_mae: 0.0396\n",
      "Epoch 17/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 5.0584e-04 - mae: 0.0154 - val_loss: 0.0038 - val_mae: 0.0412\n",
      "Epoch 18/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 5.2973e-04 - mae: 0.0158 - val_loss: 0.0036 - val_mae: 0.0399\n",
      "Epoch 19/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 5.1162e-04 - mae: 0.0154 - val_loss: 0.0036 - val_mae: 0.0398\n",
      "Epoch 20/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 5.1543e-04 - mae: 0.0156 - val_loss: 0.0037 - val_mae: 0.0404\n",
      "Epoch 21/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 4.9596e-04 - mae: 0.0152 - val_loss: 0.0037 - val_mae: 0.0406\n",
      "Epoch 22/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 5.0571e-04 - mae: 0.0153 - val_loss: 0.0035 - val_mae: 0.0393\n",
      "Epoch 23/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 5.1369e-04 - mae: 0.0156 - val_loss: 0.0036 - val_mae: 0.0401\n",
      "Epoch 24/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 5.2956e-04 - mae: 0.0158 - val_loss: 0.0037 - val_mae: 0.0402\n",
      "Epoch 25/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 5.0814e-04 - mae: 0.0154 - val_loss: 0.0035 - val_mae: 0.0396\n",
      "Epoch 26/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 5.2355e-04 - mae: 0.0157 - val_loss: 0.0036 - val_mae: 0.0399\n",
      "Epoch 27/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 5.0359e-04 - mae: 0.0152 - val_loss: 0.0037 - val_mae: 0.0403\n",
      "Epoch 28/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 5.1496e-04 - mae: 0.0155 - val_loss: 0.0035 - val_mae: 0.0396\n",
      "Epoch 29/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 5.0042e-04 - mae: 0.0153 - val_loss: 0.0036 - val_mae: 0.0401\n",
      "Epoch 30/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 5.1677e-04 - mae: 0.0156 - val_loss: 0.0035 - val_mae: 0.0392\n",
      "Epoch 31/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 5.0819e-04 - mae: 0.0153 - val_loss: 0.0036 - val_mae: 0.0398\n",
      "Epoch 32/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 5.0061e-04 - mae: 0.0153 - val_loss: 0.0035 - val_mae: 0.0397\n",
      "Epoch 33/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 5.0187e-04 - mae: 0.0152 - val_loss: 0.0037 - val_mae: 0.0404\n",
      "Epoch 34/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 5.2066e-04 - mae: 0.0157 - val_loss: 0.0035 - val_mae: 0.0394\n",
      "Epoch 35/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 5.1503e-04 - mae: 0.0156 - val_loss: 0.0034 - val_mae: 0.0391\n",
      "Epoch 36/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 5.0550e-04 - mae: 0.0154 - val_loss: 0.0036 - val_mae: 0.0400\n",
      "Epoch 37/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 5.1119e-04 - mae: 0.0155 - val_loss: 0.0036 - val_mae: 0.0398\n",
      "Epoch 38/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 5.0497e-04 - mae: 0.0154 - val_loss: 0.0035 - val_mae: 0.0395\n",
      "Epoch 39/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 5.1192e-04 - mae: 0.0155 - val_loss: 0.0035 - val_mae: 0.0397\n",
      "Epoch 40/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 5.1648e-04 - mae: 0.0156 - val_loss: 0.0036 - val_mae: 0.0402\n",
      "Epoch 41/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 4.9354e-04 - mae: 0.0150 - val_loss: 0.0035 - val_mae: 0.0396\n",
      "Epoch 42/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 5.1887e-04 - mae: 0.0157 - val_loss: 0.0035 - val_mae: 0.0393\n",
      "Epoch 43/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 5.2227e-04 - mae: 0.0157 - val_loss: 0.0035 - val_mae: 0.0394\n",
      "Epoch 44/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 5.1157e-04 - mae: 0.0155 - val_loss: 0.0035 - val_mae: 0.0395\n",
      "Epoch 45/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 5.2297e-04 - mae: 0.0157 - val_loss: 0.0034 - val_mae: 0.0391\n",
      "Epoch 46/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 5.0247e-04 - mae: 0.0152 - val_loss: 0.0034 - val_mae: 0.0391\n",
      "Epoch 47/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 5.3141e-04 - mae: 0.0159 - val_loss: 0.0037 - val_mae: 0.0405\n",
      "Epoch 48/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 5.1611e-04 - mae: 0.0155 - val_loss: 0.0035 - val_mae: 0.0394\n",
      "Epoch 49/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 5.1543e-04 - mae: 0.0156 - val_loss: 0.0035 - val_mae: 0.0397\n",
      "Epoch 50/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 5.2613e-04 - mae: 0.0159 - val_loss: 0.0037 - val_mae: 0.0403\n",
      "Epoch 51/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 5.0803e-04 - mae: 0.0154 - val_loss: 0.0036 - val_mae: 0.0397\n",
      "Epoch 52/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 5.2689e-04 - mae: 0.0158 - val_loss: 0.0037 - val_mae: 0.0407\n",
      "Epoch 53/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 5.2537e-04 - mae: 0.0155 - val_loss: 0.0037 - val_mae: 0.0404\n",
      "Epoch 54/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 4.9353e-04 - mae: 0.0150 - val_loss: 0.0034 - val_mae: 0.0392\n",
      "Epoch 55/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 5.0075e-04 - mae: 0.0152 - val_loss: 0.0037 - val_mae: 0.0403\n",
      "Epoch 56/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 5.3560e-04 - mae: 0.0159 - val_loss: 0.0034 - val_mae: 0.0388\n",
      "Epoch 57/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 5.2202e-04 - mae: 0.0158 - val_loss: 0.0035 - val_mae: 0.0397\n",
      "Epoch 58/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 4.9920e-04 - mae: 0.0152 - val_loss: 0.0036 - val_mae: 0.0399\n",
      "Epoch 59/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 5.1412e-04 - mae: 0.0155 - val_loss: 0.0036 - val_mae: 0.0398\n",
      "Epoch 60/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 5.0318e-04 - mae: 0.0153 - val_loss: 0.0036 - val_mae: 0.0400\n",
      "Epoch 61/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 5.0311e-04 - mae: 0.0154 - val_loss: 0.0034 - val_mae: 0.0392\n",
      "Epoch 62/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 5.1299e-04 - mae: 0.0156 - val_loss: 0.0037 - val_mae: 0.0407\n",
      "Epoch 63/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 5.0723e-04 - mae: 0.0152 - val_loss: 0.0037 - val_mae: 0.0405\n",
      "Epoch 64/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 5.2686e-04 - mae: 0.0157 - val_loss: 0.0038 - val_mae: 0.0409\n",
      "Epoch 65/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 5.2151e-04 - mae: 0.0155 - val_loss: 0.0035 - val_mae: 0.0397\n",
      "Epoch 66/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 5.1723e-04 - mae: 0.0156 - val_loss: 0.0036 - val_mae: 0.0400\n",
      "Epoch 67/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 4.9590e-04 - mae: 0.0152 - val_loss: 0.0035 - val_mae: 0.0396\n",
      "Epoch 68/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 5.0459e-04 - mae: 0.0153 - val_loss: 0.0036 - val_mae: 0.0398\n",
      "Epoch 69/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 5.0682e-04 - mae: 0.0155 - val_loss: 0.0035 - val_mae: 0.0395\n",
      "Epoch 70/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 5.1625e-04 - mae: 0.0155 - val_loss: 0.0035 - val_mae: 0.0394\n",
      "Epoch 71/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 5.1161e-04 - mae: 0.0155 - val_loss: 0.0037 - val_mae: 0.0404\n",
      "Epoch 72/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 5.0814e-04 - mae: 0.0154 - val_loss: 0.0036 - val_mae: 0.0399\n",
      "Epoch 73/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 4.8425e-04 - mae: 0.0149 - val_loss: 0.0038 - val_mae: 0.0410\n",
      "Epoch 74/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 5.2649e-04 - mae: 0.0156 - val_loss: 0.0035 - val_mae: 0.0395\n",
      "Epoch 75/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 4.9724e-04 - mae: 0.0152 - val_loss: 0.0035 - val_mae: 0.0393\n",
      "Epoch 76/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 5.0395e-04 - mae: 0.0154 - val_loss: 0.0035 - val_mae: 0.0393\n",
      "Epoch 77/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 5.2508e-04 - mae: 0.0157 - val_loss: 0.0035 - val_mae: 0.0394\n",
      "Epoch 78/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 5.0723e-04 - mae: 0.0154 - val_loss: 0.0035 - val_mae: 0.0393\n",
      "Epoch 79/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 5.1027e-04 - mae: 0.0155 - val_loss: 0.0036 - val_mae: 0.0399\n",
      "Epoch 80/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 5.3443e-04 - mae: 0.0160 - val_loss: 0.0035 - val_mae: 0.0396\n",
      "Epoch 81/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 5.1734e-04 - mae: 0.0155 - val_loss: 0.0038 - val_mae: 0.0409\n",
      "Epoch 82/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 5.0809e-04 - mae: 0.0154 - val_loss: 0.0035 - val_mae: 0.0396\n",
      "Epoch 83/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 5.1385e-04 - mae: 0.0154 - val_loss: 0.0035 - val_mae: 0.0394\n",
      "Epoch 84/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 5.1906e-04 - mae: 0.0157 - val_loss: 0.0037 - val_mae: 0.0404\n",
      "Epoch 85/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 5.2938e-04 - mae: 0.0158 - val_loss: 0.0036 - val_mae: 0.0398\n",
      "Epoch 86/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 5.0540e-04 - mae: 0.0152 - val_loss: 0.0034 - val_mae: 0.0391\n",
      "Epoch 87/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 4.8548e-04 - mae: 0.0151 - val_loss: 0.0037 - val_mae: 0.0405\n",
      "Epoch 88/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 5.0858e-04 - mae: 0.0154 - val_loss: 0.0035 - val_mae: 0.0396\n",
      "Epoch 89/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 5.0618e-04 - mae: 0.0154 - val_loss: 0.0037 - val_mae: 0.0406\n",
      "Epoch 90/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 4.8938e-04 - mae: 0.0150 - val_loss: 0.0036 - val_mae: 0.0400\n",
      "Epoch 91/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 5.2756e-04 - mae: 0.0157 - val_loss: 0.0037 - val_mae: 0.0407\n",
      "Epoch 92/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 5.1881e-04 - mae: 0.0155 - val_loss: 0.0034 - val_mae: 0.0391\n",
      "Epoch 93/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 5.0314e-04 - mae: 0.0154 - val_loss: 0.0036 - val_mae: 0.0398\n",
      "Epoch 94/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 5.2001e-04 - mae: 0.0156 - val_loss: 0.0036 - val_mae: 0.0399\n",
      "Epoch 95/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 4.8899e-04 - mae: 0.0151 - val_loss: 0.0035 - val_mae: 0.0394\n",
      "Epoch 96/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 5.2337e-04 - mae: 0.0158 - val_loss: 0.0035 - val_mae: 0.0397\n",
      "Epoch 97/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 5.0657e-04 - mae: 0.0154 - val_loss: 0.0038 - val_mae: 0.0408\n",
      "Epoch 98/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 5.1020e-04 - mae: 0.0153 - val_loss: 0.0037 - val_mae: 0.0406\n",
      "Epoch 99/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 5.2762e-04 - mae: 0.0158 - val_loss: 0.0035 - val_mae: 0.0396\n",
      "Epoch 100/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 5.1204e-04 - mae: 0.0154 - val_loss: 0.0034 - val_mae: 0.0391\n",
      "\u001b[1m501/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n",
      "✅ Done with tomato_Chamrajnagar_daily.csv | MAE=1040.44, RMSE=1630.15, R2=-0.0194, MAPE=99.89%, Accuracy=0.11%\n",
      "\n",
      "🚀 Processing: tomato_Chikmagalur_daily.csv\n",
      "Epoch 1/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - loss: 0.0045 - mae: 0.0450 - val_loss: 0.0245 - val_mae: 0.1063\n",
      "Epoch 2/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 0.0037 - mae: 0.0418 - val_loss: 0.0242 - val_mae: 0.1051\n",
      "Epoch 3/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0038 - mae: 0.0421 - val_loss: 0.0230 - val_mae: 0.1011\n",
      "Epoch 4/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0037 - mae: 0.0420 - val_loss: 0.0241 - val_mae: 0.1049\n",
      "Epoch 5/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0037 - mae: 0.0420 - val_loss: 0.0229 - val_mae: 0.1005\n",
      "Epoch 6/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 0.0038 - mae: 0.0420 - val_loss: 0.0244 - val_mae: 0.1060\n",
      "Epoch 7/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0038 - mae: 0.0423 - val_loss: 0.0238 - val_mae: 0.1038\n",
      "Epoch 8/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0038 - mae: 0.0421 - val_loss: 0.0233 - val_mae: 0.1021\n",
      "Epoch 9/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0039 - mae: 0.0425 - val_loss: 0.0234 - val_mae: 0.1024\n",
      "Epoch 10/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 0.0037 - mae: 0.0412 - val_loss: 0.0226 - val_mae: 0.0998\n",
      "Epoch 11/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 0.0038 - mae: 0.0423 - val_loss: 0.0230 - val_mae: 0.1010\n",
      "Epoch 12/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0037 - mae: 0.0416 - val_loss: 0.0231 - val_mae: 0.1014\n",
      "Epoch 13/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0039 - mae: 0.0423 - val_loss: 0.0239 - val_mae: 0.1040\n",
      "Epoch 14/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 0.0040 - mae: 0.0427 - val_loss: 0.0235 - val_mae: 0.1028\n",
      "Epoch 15/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 0.0037 - mae: 0.0422 - val_loss: 0.0250 - val_mae: 0.1082\n",
      "Epoch 16/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0038 - mae: 0.0423 - val_loss: 0.0233 - val_mae: 0.1022\n",
      "Epoch 17/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0039 - mae: 0.0426 - val_loss: 0.0224 - val_mae: 0.0989\n",
      "Epoch 18/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0039 - mae: 0.0425 - val_loss: 0.0239 - val_mae: 0.1043\n",
      "Epoch 19/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0036 - mae: 0.0414 - val_loss: 0.0227 - val_mae: 0.0999\n",
      "Epoch 20/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 0.0038 - mae: 0.0423 - val_loss: 0.0244 - val_mae: 0.1059\n",
      "Epoch 21/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0039 - mae: 0.0425 - val_loss: 0.0244 - val_mae: 0.1058\n",
      "Epoch 22/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0039 - mae: 0.0428 - val_loss: 0.0241 - val_mae: 0.1049\n",
      "Epoch 23/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0036 - mae: 0.0416 - val_loss: 0.0241 - val_mae: 0.1049\n",
      "Epoch 24/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 0.0038 - mae: 0.0420 - val_loss: 0.0237 - val_mae: 0.1036\n",
      "Epoch 25/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 0.0037 - mae: 0.0421 - val_loss: 0.0236 - val_mae: 0.1031\n",
      "Epoch 26/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 0.0040 - mae: 0.0426 - val_loss: 0.0235 - val_mae: 0.1026\n",
      "Epoch 27/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0037 - mae: 0.0416 - val_loss: 0.0230 - val_mae: 0.1011\n",
      "Epoch 28/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0037 - mae: 0.0421 - val_loss: 0.0239 - val_mae: 0.1042\n",
      "Epoch 29/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0037 - mae: 0.0417 - val_loss: 0.0239 - val_mae: 0.1041\n",
      "Epoch 30/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 0.0037 - mae: 0.0419 - val_loss: 0.0239 - val_mae: 0.1041\n",
      "Epoch 31/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0038 - mae: 0.0419 - val_loss: 0.0252 - val_mae: 0.1089\n",
      "Epoch 32/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0038 - mae: 0.0421 - val_loss: 0.0231 - val_mae: 0.1013\n",
      "Epoch 33/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 0.0039 - mae: 0.0427 - val_loss: 0.0240 - val_mae: 0.1046\n",
      "Epoch 34/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 0.0038 - mae: 0.0421 - val_loss: 0.0238 - val_mae: 0.1036\n",
      "Epoch 35/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0037 - mae: 0.0419 - val_loss: 0.0235 - val_mae: 0.1029\n",
      "Epoch 36/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0037 - mae: 0.0414 - val_loss: 0.0241 - val_mae: 0.1047\n",
      "Epoch 37/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0038 - mae: 0.0426 - val_loss: 0.0228 - val_mae: 0.1003\n",
      "Epoch 38/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0040 - mae: 0.0431 - val_loss: 0.0234 - val_mae: 0.1024\n",
      "Epoch 39/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0038 - mae: 0.0423 - val_loss: 0.0249 - val_mae: 0.1078\n",
      "Epoch 40/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0038 - mae: 0.0419 - val_loss: 0.0239 - val_mae: 0.1043\n",
      "Epoch 41/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0037 - mae: 0.0418 - val_loss: 0.0235 - val_mae: 0.1027\n",
      "Epoch 42/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 0.0037 - mae: 0.0420 - val_loss: 0.0243 - val_mae: 0.1054\n",
      "Epoch 43/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 0.0039 - mae: 0.0424 - val_loss: 0.0243 - val_mae: 0.1056\n",
      "Epoch 44/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0037 - mae: 0.0419 - val_loss: 0.0245 - val_mae: 0.1063\n",
      "Epoch 45/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 0.0037 - mae: 0.0418 - val_loss: 0.0242 - val_mae: 0.1052\n",
      "Epoch 46/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0039 - mae: 0.0425 - val_loss: 0.0235 - val_mae: 0.1028\n",
      "Epoch 47/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0039 - mae: 0.0427 - val_loss: 0.0241 - val_mae: 0.1049\n",
      "Epoch 48/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 0.0039 - mae: 0.0423 - val_loss: 0.0242 - val_mae: 0.1050\n",
      "Epoch 49/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 0.0036 - mae: 0.0415 - val_loss: 0.0239 - val_mae: 0.1040\n",
      "Epoch 50/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 0.0038 - mae: 0.0426 - val_loss: 0.0237 - val_mae: 0.1036\n",
      "Epoch 51/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0037 - mae: 0.0417 - val_loss: 0.0239 - val_mae: 0.1043\n",
      "Epoch 52/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 0.0037 - mae: 0.0416 - val_loss: 0.0238 - val_mae: 0.1037\n",
      "Epoch 53/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 0.0040 - mae: 0.0428 - val_loss: 0.0233 - val_mae: 0.1020\n",
      "Epoch 54/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0038 - mae: 0.0420 - val_loss: 0.0232 - val_mae: 0.1018\n",
      "Epoch 55/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0036 - mae: 0.0415 - val_loss: 0.0246 - val_mae: 0.1065\n",
      "Epoch 56/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 0.0036 - mae: 0.0414 - val_loss: 0.0230 - val_mae: 0.1008\n",
      "Epoch 57/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0038 - mae: 0.0422 - val_loss: 0.0237 - val_mae: 0.1035\n",
      "Epoch 58/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0037 - mae: 0.0414 - val_loss: 0.0235 - val_mae: 0.1027\n",
      "Epoch 59/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0038 - mae: 0.0420 - val_loss: 0.0231 - val_mae: 0.1012\n",
      "Epoch 60/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0036 - mae: 0.0415 - val_loss: 0.0229 - val_mae: 0.1007\n",
      "Epoch 61/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0039 - mae: 0.0426 - val_loss: 0.0235 - val_mae: 0.1027\n",
      "Epoch 62/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0037 - mae: 0.0419 - val_loss: 0.0232 - val_mae: 0.1015\n",
      "Epoch 63/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0036 - mae: 0.0414 - val_loss: 0.0235 - val_mae: 0.1027\n",
      "Epoch 64/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 0.0038 - mae: 0.0423 - val_loss: 0.0242 - val_mae: 0.1053\n",
      "Epoch 65/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0038 - mae: 0.0422 - val_loss: 0.0235 - val_mae: 0.1027\n",
      "Epoch 66/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0039 - mae: 0.0426 - val_loss: 0.0238 - val_mae: 0.1038\n",
      "Epoch 67/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0038 - mae: 0.0424 - val_loss: 0.0232 - val_mae: 0.1017\n",
      "Epoch 68/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0038 - mae: 0.0420 - val_loss: 0.0234 - val_mae: 0.1025\n",
      "Epoch 69/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0039 - mae: 0.0426 - val_loss: 0.0235 - val_mae: 0.1026\n",
      "Epoch 70/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0038 - mae: 0.0424 - val_loss: 0.0245 - val_mae: 0.1063\n",
      "Epoch 71/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 0.0037 - mae: 0.0416 - val_loss: 0.0238 - val_mae: 0.1039\n",
      "Epoch 72/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0038 - mae: 0.0421 - val_loss: 0.0238 - val_mae: 0.1038\n",
      "Epoch 73/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 0.0039 - mae: 0.0421 - val_loss: 0.0232 - val_mae: 0.1016\n",
      "Epoch 74/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0037 - mae: 0.0418 - val_loss: 0.0239 - val_mae: 0.1042\n",
      "Epoch 75/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0037 - mae: 0.0416 - val_loss: 0.0226 - val_mae: 0.0995\n",
      "Epoch 76/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0039 - mae: 0.0425 - val_loss: 0.0228 - val_mae: 0.1003\n",
      "Epoch 77/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0036 - mae: 0.0420 - val_loss: 0.0238 - val_mae: 0.1037\n",
      "Epoch 78/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0038 - mae: 0.0419 - val_loss: 0.0233 - val_mae: 0.1021\n",
      "Epoch 79/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0039 - mae: 0.0424 - val_loss: 0.0238 - val_mae: 0.1038\n",
      "Epoch 80/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0038 - mae: 0.0421 - val_loss: 0.0235 - val_mae: 0.1028\n",
      "Epoch 81/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0037 - mae: 0.0420 - val_loss: 0.0230 - val_mae: 0.1010\n",
      "Epoch 82/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0037 - mae: 0.0425 - val_loss: 0.0229 - val_mae: 0.1007\n",
      "Epoch 83/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0037 - mae: 0.0423 - val_loss: 0.0240 - val_mae: 0.1045\n",
      "Epoch 84/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0036 - mae: 0.0414 - val_loss: 0.0240 - val_mae: 0.1046\n",
      "Epoch 85/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 0.0037 - mae: 0.0417 - val_loss: 0.0233 - val_mae: 0.1022\n",
      "Epoch 86/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0038 - mae: 0.0421 - val_loss: 0.0233 - val_mae: 0.1021\n",
      "Epoch 87/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0038 - mae: 0.0424 - val_loss: 0.0233 - val_mae: 0.1020\n",
      "Epoch 88/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 0.0039 - mae: 0.0426 - val_loss: 0.0230 - val_mae: 0.1010\n",
      "Epoch 89/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0037 - mae: 0.0416 - val_loss: 0.0234 - val_mae: 0.1025\n",
      "Epoch 90/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0038 - mae: 0.0423 - val_loss: 0.0243 - val_mae: 0.1056\n",
      "Epoch 91/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 0.0039 - mae: 0.0423 - val_loss: 0.0238 - val_mae: 0.1037\n",
      "Epoch 92/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0037 - mae: 0.0418 - val_loss: 0.0233 - val_mae: 0.1020\n",
      "Epoch 93/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0038 - mae: 0.0420 - val_loss: 0.0240 - val_mae: 0.1046\n",
      "Epoch 94/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0037 - mae: 0.0420 - val_loss: 0.0238 - val_mae: 0.1036\n",
      "Epoch 95/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0038 - mae: 0.0421 - val_loss: 0.0248 - val_mae: 0.1074\n",
      "Epoch 96/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0038 - mae: 0.0424 - val_loss: 0.0243 - val_mae: 0.1056\n",
      "Epoch 97/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0037 - mae: 0.0414 - val_loss: 0.0234 - val_mae: 0.1025\n",
      "Epoch 98/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0037 - mae: 0.0419 - val_loss: 0.0239 - val_mae: 0.1042\n",
      "Epoch 99/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 0.0036 - mae: 0.0416 - val_loss: 0.0241 - val_mae: 0.1049\n",
      "Epoch 100/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 0.0037 - mae: 0.0418 - val_loss: 0.0240 - val_mae: 0.1046\n",
      "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step\n",
      "✅ Done with tomato_Chikmagalur_daily.csv | MAE=594.66, RMSE=970.5, R2=-0.058, MAPE=77.03%, Accuracy=22.97%\n",
      "\n",
      "🚀 Processing: tomato_Chitradurga_daily.csv\n",
      "Epoch 1/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0633 - mae: 0.1408 - val_loss: 0.0026 - val_mae: 0.0514\n",
      "Epoch 2/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0472 - mae: 0.1440 - val_loss: 0.0026 - val_mae: 0.0510\n",
      "Epoch 3/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0478 - mae: 0.1465 - val_loss: 0.0023 - val_mae: 0.0479\n",
      "Epoch 4/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0495 - mae: 0.1491 - val_loss: 0.0021 - val_mae: 0.0456\n",
      "Epoch 5/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0479 - mae: 0.1454 - val_loss: 0.0030 - val_mae: 0.0548\n",
      "Epoch 6/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0476 - mae: 0.1454 - val_loss: 0.0021 - val_mae: 0.0461\n",
      "Epoch 7/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0500 - mae: 0.1492 - val_loss: 0.0023 - val_mae: 0.0483\n",
      "Epoch 8/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0486 - mae: 0.1457 - val_loss: 0.0016 - val_mae: 0.0404\n",
      "Epoch 9/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0510 - mae: 0.1499 - val_loss: 0.0013 - val_mae: 0.0356\n",
      "Epoch 10/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0441 - mae: 0.1363 - val_loss: 0.0023 - val_mae: 0.0480\n",
      "Epoch 11/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0472 - mae: 0.1442 - val_loss: 0.0021 - val_mae: 0.0459\n",
      "Epoch 12/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0465 - mae: 0.1399 - val_loss: 0.0025 - val_mae: 0.0500\n",
      "Epoch 13/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0492 - mae: 0.1495 - val_loss: 0.0014 - val_mae: 0.0377\n",
      "Epoch 14/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0481 - mae: 0.1423 - val_loss: 0.0018 - val_mae: 0.0421\n",
      "Epoch 15/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0492 - mae: 0.1471 - val_loss: 0.0024 - val_mae: 0.0492\n",
      "Epoch 16/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0470 - mae: 0.1434 - val_loss: 0.0025 - val_mae: 0.0498\n",
      "Epoch 17/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0456 - mae: 0.1389 - val_loss: 0.0017 - val_mae: 0.0410\n",
      "Epoch 18/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0491 - mae: 0.1460 - val_loss: 0.0013 - val_mae: 0.0366\n",
      "Epoch 19/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0523 - mae: 0.1512 - val_loss: 0.0020 - val_mae: 0.0453\n",
      "Epoch 20/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0458 - mae: 0.1412 - val_loss: 0.0031 - val_mae: 0.0554\n",
      "Epoch 21/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0503 - mae: 0.1506 - val_loss: 0.0014 - val_mae: 0.0377\n",
      "Epoch 22/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0456 - mae: 0.1405 - val_loss: 0.0037 - val_mae: 0.0606\n",
      "Epoch 23/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0481 - mae: 0.1503 - val_loss: 0.0026 - val_mae: 0.0509\n",
      "Epoch 24/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0468 - mae: 0.1429 - val_loss: 0.0032 - val_mae: 0.0564\n",
      "Epoch 25/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0481 - mae: 0.1492 - val_loss: 0.0027 - val_mae: 0.0519\n",
      "Epoch 26/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0484 - mae: 0.1466 - val_loss: 0.0017 - val_mae: 0.0410\n",
      "Epoch 27/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0492 - mae: 0.1479 - val_loss: 0.0031 - val_mae: 0.0559\n",
      "Epoch 28/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0524 - mae: 0.1552 - val_loss: 0.0031 - val_mae: 0.0553\n",
      "Epoch 29/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0492 - mae: 0.1493 - val_loss: 0.0025 - val_mae: 0.0502\n",
      "Epoch 30/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0467 - mae: 0.1424 - val_loss: 0.0031 - val_mae: 0.0558\n",
      "Epoch 31/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0516 - mae: 0.1543 - val_loss: 0.0014 - val_mae: 0.0379\n",
      "Epoch 32/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0468 - mae: 0.1405 - val_loss: 0.0026 - val_mae: 0.0508\n",
      "Epoch 33/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0471 - mae: 0.1452 - val_loss: 0.0035 - val_mae: 0.0593\n",
      "Epoch 34/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0475 - mae: 0.1483 - val_loss: 0.0027 - val_mae: 0.0521\n",
      "Epoch 35/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0474 - mae: 0.1452 - val_loss: 0.0021 - val_mae: 0.0463\n",
      "Epoch 36/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0453 - mae: 0.1397 - val_loss: 0.0018 - val_mae: 0.0420\n",
      "Epoch 37/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0494 - mae: 0.1473 - val_loss: 0.0022 - val_mae: 0.0471\n",
      "Epoch 38/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0495 - mae: 0.1490 - val_loss: 0.0021 - val_mae: 0.0455\n",
      "Epoch 39/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0471 - mae: 0.1430 - val_loss: 0.0021 - val_mae: 0.0457\n",
      "Epoch 40/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0489 - mae: 0.1475 - val_loss: 0.0030 - val_mae: 0.0548\n",
      "Epoch 41/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0479 - mae: 0.1447 - val_loss: 0.0026 - val_mae: 0.0508\n",
      "Epoch 42/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0471 - mae: 0.1423 - val_loss: 0.0029 - val_mae: 0.0539\n",
      "Epoch 43/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0494 - mae: 0.1518 - val_loss: 0.0021 - val_mae: 0.0460\n",
      "Epoch 44/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0497 - mae: 0.1484 - val_loss: 0.0010 - val_mae: 0.0323\n",
      "Epoch 45/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0525 - mae: 0.1524 - val_loss: 0.0025 - val_mae: 0.0495\n",
      "Epoch 46/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0493 - mae: 0.1508 - val_loss: 0.0031 - val_mae: 0.0561\n",
      "Epoch 47/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0480 - mae: 0.1481 - val_loss: 0.0021 - val_mae: 0.0463\n",
      "Epoch 48/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0513 - mae: 0.1504 - val_loss: 0.0018 - val_mae: 0.0420\n",
      "Epoch 49/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0492 - mae: 0.1478 - val_loss: 0.0028 - val_mae: 0.0526\n",
      "Epoch 50/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0482 - mae: 0.1472 - val_loss: 0.0021 - val_mae: 0.0460\n",
      "Epoch 51/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0488 - mae: 0.1454 - val_loss: 0.0027 - val_mae: 0.0520\n",
      "Epoch 52/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0461 - mae: 0.1449 - val_loss: 0.0020 - val_mae: 0.0451\n",
      "Epoch 53/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0526 - mae: 0.1546 - val_loss: 0.0019 - val_mae: 0.0433\n",
      "Epoch 54/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0502 - mae: 0.1496 - val_loss: 0.0014 - val_mae: 0.0372\n",
      "Epoch 55/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0467 - mae: 0.1396 - val_loss: 0.0030 - val_mae: 0.0548\n",
      "Epoch 56/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0471 - mae: 0.1430 - val_loss: 0.0027 - val_mae: 0.0520\n",
      "Epoch 57/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0474 - mae: 0.1454 - val_loss: 0.0041 - val_mae: 0.0639\n",
      "Epoch 58/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0509 - mae: 0.1552 - val_loss: 0.0025 - val_mae: 0.0498\n",
      "Epoch 59/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0490 - mae: 0.1465 - val_loss: 0.0017 - val_mae: 0.0418\n",
      "Epoch 60/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0477 - mae: 0.1447 - val_loss: 0.0026 - val_mae: 0.0510\n",
      "Epoch 61/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0499 - mae: 0.1479 - val_loss: 0.0015 - val_mae: 0.0388\n",
      "Epoch 62/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0458 - mae: 0.1371 - val_loss: 0.0031 - val_mae: 0.0553\n",
      "Epoch 63/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0478 - mae: 0.1466 - val_loss: 0.0022 - val_mae: 0.0472\n",
      "Epoch 64/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0457 - mae: 0.1382 - val_loss: 0.0033 - val_mae: 0.0575\n",
      "Epoch 65/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0465 - mae: 0.1439 - val_loss: 0.0055 - val_mae: 0.0738\n",
      "Epoch 66/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0485 - mae: 0.1531 - val_loss: 0.0031 - val_mae: 0.0554\n",
      "Epoch 67/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0452 - mae: 0.1433 - val_loss: 0.0021 - val_mae: 0.0464\n",
      "Epoch 68/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0453 - mae: 0.1398 - val_loss: 0.0031 - val_mae: 0.0554\n",
      "Epoch 69/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0496 - mae: 0.1508 - val_loss: 0.0029 - val_mae: 0.0539\n",
      "Epoch 70/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0472 - mae: 0.1459 - val_loss: 0.0027 - val_mae: 0.0516\n",
      "Epoch 71/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0462 - mae: 0.1439 - val_loss: 0.0038 - val_mae: 0.0614\n",
      "Epoch 72/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0504 - mae: 0.1490 - val_loss: 0.0022 - val_mae: 0.0470\n",
      "Epoch 73/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0506 - mae: 0.1529 - val_loss: 0.0015 - val_mae: 0.0384\n",
      "Epoch 74/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0464 - mae: 0.1399 - val_loss: 0.0023 - val_mae: 0.0483\n",
      "Epoch 75/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0456 - mae: 0.1398 - val_loss: 0.0020 - val_mae: 0.0443\n",
      "Epoch 76/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0475 - mae: 0.1404 - val_loss: 0.0031 - val_mae: 0.0553\n",
      "Epoch 77/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0495 - mae: 0.1500 - val_loss: 0.0021 - val_mae: 0.0458\n",
      "Epoch 78/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0483 - mae: 0.1440 - val_loss: 0.0027 - val_mae: 0.0519\n",
      "Epoch 79/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0469 - mae: 0.1438 - val_loss: 0.0044 - val_mae: 0.0665\n",
      "Epoch 80/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0479 - mae: 0.1514 - val_loss: 0.0030 - val_mae: 0.0550\n",
      "Epoch 81/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0473 - mae: 0.1457 - val_loss: 0.0027 - val_mae: 0.0518\n",
      "Epoch 82/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0510 - mae: 0.1513 - val_loss: 0.0017 - val_mae: 0.0413\n",
      "Epoch 83/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0488 - mae: 0.1453 - val_loss: 0.0031 - val_mae: 0.0559\n",
      "Epoch 84/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0492 - mae: 0.1497 - val_loss: 0.0015 - val_mae: 0.0388\n",
      "Epoch 85/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0485 - mae: 0.1425 - val_loss: 0.0018 - val_mae: 0.0424\n",
      "Epoch 86/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0474 - mae: 0.1427 - val_loss: 0.0036 - val_mae: 0.0601\n",
      "Epoch 87/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0480 - mae: 0.1481 - val_loss: 0.0025 - val_mae: 0.0501\n",
      "Epoch 88/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0459 - mae: 0.1427 - val_loss: 0.0024 - val_mae: 0.0485\n",
      "Epoch 89/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0496 - mae: 0.1468 - val_loss: 0.0034 - val_mae: 0.0584\n",
      "Epoch 90/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0472 - mae: 0.1449 - val_loss: 0.0026 - val_mae: 0.0509\n",
      "Epoch 91/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0504 - mae: 0.1496 - val_loss: 0.0036 - val_mae: 0.0601\n",
      "Epoch 92/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0480 - mae: 0.1475 - val_loss: 0.0026 - val_mae: 0.0508\n",
      "Epoch 93/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0485 - mae: 0.1474 - val_loss: 0.0037 - val_mae: 0.0608\n",
      "Epoch 94/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0503 - mae: 0.1520 - val_loss: 0.0027 - val_mae: 0.0522\n",
      "Epoch 95/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0468 - mae: 0.1442 - val_loss: 0.0040 - val_mae: 0.0636\n",
      "Epoch 96/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0490 - mae: 0.1492 - val_loss: 0.0025 - val_mae: 0.0500\n",
      "Epoch 97/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0486 - mae: 0.1468 - val_loss: 0.0024 - val_mae: 0.0493\n",
      "Epoch 98/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0485 - mae: 0.1493 - val_loss: 0.0021 - val_mae: 0.0457\n",
      "Epoch 99/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0519 - mae: 0.1530 - val_loss: 0.0018 - val_mae: 0.0420\n",
      "Epoch 100/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0472 - mae: 0.1426 - val_loss: 0.0022 - val_mae: 0.0471\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "✅ Done with tomato_Chitradurga_daily.csv | MAE=647.09, RMSE=1021.3, R2=-0.0014, MAPE=60.65%, Accuracy=39.35%\n",
      "\n",
      "🚀 Processing: tomato_Davangere_daily.csv\n",
      "Epoch 1/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0100 - mae: 0.0733 - val_loss: 0.0329 - val_mae: 0.1028\n",
      "Epoch 2/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0088 - mae: 0.0714 - val_loss: 0.0333 - val_mae: 0.1029\n",
      "Epoch 3/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0088 - mae: 0.0715 - val_loss: 0.0311 - val_mae: 0.1026\n",
      "Epoch 4/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0085 - mae: 0.0711 - val_loss: 0.0318 - val_mae: 0.1025\n",
      "Epoch 5/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0086 - mae: 0.0714 - val_loss: 0.0319 - val_mae: 0.1025\n",
      "Epoch 6/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0087 - mae: 0.0713 - val_loss: 0.0331 - val_mae: 0.1028\n",
      "Epoch 7/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0085 - mae: 0.0708 - val_loss: 0.0326 - val_mae: 0.1027\n",
      "Epoch 8/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0086 - mae: 0.0712 - val_loss: 0.0322 - val_mae: 0.1026\n",
      "Epoch 9/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0089 - mae: 0.0723 - val_loss: 0.0312 - val_mae: 0.1026\n",
      "Epoch 10/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0085 - mae: 0.0716 - val_loss: 0.0325 - val_mae: 0.1026\n",
      "Epoch 11/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0084 - mae: 0.0708 - val_loss: 0.0321 - val_mae: 0.1025\n",
      "Epoch 12/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0088 - mae: 0.0724 - val_loss: 0.0319 - val_mae: 0.1025\n",
      "Epoch 13/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0085 - mae: 0.0706 - val_loss: 0.0321 - val_mae: 0.1025\n",
      "Epoch 14/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0085 - mae: 0.0701 - val_loss: 0.0313 - val_mae: 0.1025\n",
      "Epoch 15/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0087 - mae: 0.0717 - val_loss: 0.0329 - val_mae: 0.1028\n",
      "Epoch 16/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0086 - mae: 0.0707 - val_loss: 0.0323 - val_mae: 0.1026\n",
      "Epoch 17/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0088 - mae: 0.0720 - val_loss: 0.0322 - val_mae: 0.1026\n",
      "Epoch 18/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0084 - mae: 0.0709 - val_loss: 0.0327 - val_mae: 0.1027\n",
      "Epoch 19/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0087 - mae: 0.0708 - val_loss: 0.0307 - val_mae: 0.1029\n",
      "Epoch 20/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0084 - mae: 0.0708 - val_loss: 0.0324 - val_mae: 0.1026\n",
      "Epoch 21/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0081 - mae: 0.0696 - val_loss: 0.0320 - val_mae: 0.1025\n",
      "Epoch 22/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0086 - mae: 0.0714 - val_loss: 0.0323 - val_mae: 0.1026\n",
      "Epoch 23/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0086 - mae: 0.0710 - val_loss: 0.0327 - val_mae: 0.1027\n",
      "Epoch 24/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0085 - mae: 0.0714 - val_loss: 0.0325 - val_mae: 0.1026\n",
      "Epoch 25/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0083 - mae: 0.0705 - val_loss: 0.0333 - val_mae: 0.1029\n",
      "Epoch 26/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0087 - mae: 0.0710 - val_loss: 0.0323 - val_mae: 0.1026\n",
      "Epoch 27/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0090 - mae: 0.0728 - val_loss: 0.0317 - val_mae: 0.1025\n",
      "Epoch 28/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0087 - mae: 0.0713 - val_loss: 0.0314 - val_mae: 0.1025\n",
      "Epoch 29/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0084 - mae: 0.0704 - val_loss: 0.0335 - val_mae: 0.1030\n",
      "Epoch 30/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0091 - mae: 0.0730 - val_loss: 0.0329 - val_mae: 0.1028\n",
      "Epoch 31/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0086 - mae: 0.0713 - val_loss: 0.0320 - val_mae: 0.1025\n",
      "Epoch 32/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0088 - mae: 0.0720 - val_loss: 0.0332 - val_mae: 0.1029\n",
      "Epoch 33/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0088 - mae: 0.0718 - val_loss: 0.0329 - val_mae: 0.1027\n",
      "Epoch 34/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0090 - mae: 0.0722 - val_loss: 0.0331 - val_mae: 0.1028\n",
      "Epoch 35/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0084 - mae: 0.0706 - val_loss: 0.0326 - val_mae: 0.1027\n",
      "Epoch 36/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0082 - mae: 0.0696 - val_loss: 0.0329 - val_mae: 0.1028\n",
      "Epoch 37/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0089 - mae: 0.0726 - val_loss: 0.0319 - val_mae: 0.1025\n",
      "Epoch 38/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0086 - mae: 0.0715 - val_loss: 0.0316 - val_mae: 0.1024\n",
      "Epoch 39/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0087 - mae: 0.0710 - val_loss: 0.0320 - val_mae: 0.1025\n",
      "Epoch 40/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0083 - mae: 0.0699 - val_loss: 0.0316 - val_mae: 0.1024\n",
      "Epoch 41/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0086 - mae: 0.0705 - val_loss: 0.0312 - val_mae: 0.1026\n",
      "Epoch 42/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0088 - mae: 0.0722 - val_loss: 0.0320 - val_mae: 0.1025\n",
      "Epoch 43/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0090 - mae: 0.0732 - val_loss: 0.0327 - val_mae: 0.1027\n",
      "Epoch 44/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0085 - mae: 0.0705 - val_loss: 0.0314 - val_mae: 0.1025\n",
      "Epoch 45/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0087 - mae: 0.0718 - val_loss: 0.0319 - val_mae: 0.1025\n",
      "Epoch 46/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0085 - mae: 0.0713 - val_loss: 0.0327 - val_mae: 0.1027\n",
      "Epoch 47/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0089 - mae: 0.0723 - val_loss: 0.0325 - val_mae: 0.1026\n",
      "Epoch 48/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0084 - mae: 0.0706 - val_loss: 0.0328 - val_mae: 0.1027\n",
      "Epoch 49/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0085 - mae: 0.0702 - val_loss: 0.0313 - val_mae: 0.1026\n",
      "Epoch 50/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0082 - mae: 0.0699 - val_loss: 0.0335 - val_mae: 0.1030\n",
      "Epoch 51/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0084 - mae: 0.0706 - val_loss: 0.0321 - val_mae: 0.1025\n",
      "Epoch 52/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0086 - mae: 0.0712 - val_loss: 0.0335 - val_mae: 0.1030\n",
      "Epoch 53/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0085 - mae: 0.0707 - val_loss: 0.0322 - val_mae: 0.1026\n",
      "Epoch 54/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0089 - mae: 0.0724 - val_loss: 0.0329 - val_mae: 0.1028\n",
      "Epoch 55/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0085 - mae: 0.0706 - val_loss: 0.0323 - val_mae: 0.1026\n",
      "Epoch 56/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0085 - mae: 0.0707 - val_loss: 0.0328 - val_mae: 0.1027\n",
      "Epoch 57/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0087 - mae: 0.0711 - val_loss: 0.0324 - val_mae: 0.1026\n",
      "Epoch 58/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0086 - mae: 0.0715 - val_loss: 0.0319 - val_mae: 0.1025\n",
      "Epoch 59/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0085 - mae: 0.0718 - val_loss: 0.0319 - val_mae: 0.1025\n",
      "Epoch 60/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0087 - mae: 0.0720 - val_loss: 0.0329 - val_mae: 0.1028\n",
      "Epoch 61/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0085 - mae: 0.0708 - val_loss: 0.0325 - val_mae: 0.1026\n",
      "Epoch 62/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0085 - mae: 0.0709 - val_loss: 0.0316 - val_mae: 0.1024\n",
      "Epoch 63/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0095 - mae: 0.0742 - val_loss: 0.0325 - val_mae: 0.1026\n",
      "Epoch 64/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0088 - mae: 0.0721 - val_loss: 0.0319 - val_mae: 0.1025\n",
      "Epoch 65/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0085 - mae: 0.0705 - val_loss: 0.0318 - val_mae: 0.1025\n",
      "Epoch 66/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0085 - mae: 0.0708 - val_loss: 0.0321 - val_mae: 0.1025\n",
      "Epoch 67/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0090 - mae: 0.0726 - val_loss: 0.0337 - val_mae: 0.1032\n",
      "Epoch 68/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0087 - mae: 0.0716 - val_loss: 0.0321 - val_mae: 0.1025\n",
      "Epoch 69/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0085 - mae: 0.0705 - val_loss: 0.0321 - val_mae: 0.1025\n",
      "Epoch 70/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0086 - mae: 0.0709 - val_loss: 0.0316 - val_mae: 0.1024\n",
      "Epoch 71/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0084 - mae: 0.0699 - val_loss: 0.0321 - val_mae: 0.1025\n",
      "Epoch 72/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0087 - mae: 0.0718 - val_loss: 0.0320 - val_mae: 0.1025\n",
      "Epoch 73/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0088 - mae: 0.0715 - val_loss: 0.0318 - val_mae: 0.1025\n",
      "Epoch 74/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0088 - mae: 0.0721 - val_loss: 0.0324 - val_mae: 0.1026\n",
      "Epoch 75/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0090 - mae: 0.0725 - val_loss: 0.0319 - val_mae: 0.1025\n",
      "Epoch 76/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0088 - mae: 0.0706 - val_loss: 0.0307 - val_mae: 0.1029\n",
      "Epoch 77/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0084 - mae: 0.0716 - val_loss: 0.0321 - val_mae: 0.1025\n",
      "Epoch 78/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0088 - mae: 0.0718 - val_loss: 0.0326 - val_mae: 0.1027\n",
      "Epoch 79/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0088 - mae: 0.0718 - val_loss: 0.0337 - val_mae: 0.1032\n",
      "Epoch 80/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0086 - mae: 0.0705 - val_loss: 0.0333 - val_mae: 0.1029\n",
      "Epoch 81/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0085 - mae: 0.0700 - val_loss: 0.0335 - val_mae: 0.1030\n",
      "Epoch 82/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0094 - mae: 0.0737 - val_loss: 0.0328 - val_mae: 0.1027\n",
      "Epoch 83/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0088 - mae: 0.0721 - val_loss: 0.0328 - val_mae: 0.1027\n",
      "Epoch 84/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0088 - mae: 0.0714 - val_loss: 0.0332 - val_mae: 0.1029\n",
      "Epoch 85/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0085 - mae: 0.0710 - val_loss: 0.0316 - val_mae: 0.1024\n",
      "Epoch 86/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0088 - mae: 0.0718 - val_loss: 0.0338 - val_mae: 0.1032\n",
      "Epoch 87/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0083 - mae: 0.0698 - val_loss: 0.0329 - val_mae: 0.1027\n",
      "Epoch 88/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0090 - mae: 0.0723 - val_loss: 0.0333 - val_mae: 0.1029\n",
      "Epoch 89/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0088 - mae: 0.0716 - val_loss: 0.0326 - val_mae: 0.1027\n",
      "Epoch 90/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0085 - mae: 0.0703 - val_loss: 0.0315 - val_mae: 0.1025\n",
      "Epoch 91/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0087 - mae: 0.0715 - val_loss: 0.0322 - val_mae: 0.1026\n",
      "Epoch 92/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0088 - mae: 0.0721 - val_loss: 0.0325 - val_mae: 0.1026\n",
      "Epoch 93/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0088 - mae: 0.0715 - val_loss: 0.0323 - val_mae: 0.1026\n",
      "Epoch 94/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0086 - mae: 0.0711 - val_loss: 0.0321 - val_mae: 0.1025\n",
      "Epoch 95/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0088 - mae: 0.0719 - val_loss: 0.0317 - val_mae: 0.1025\n",
      "Epoch 96/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0086 - mae: 0.0714 - val_loss: 0.0327 - val_mae: 0.1027\n",
      "Epoch 97/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0087 - mae: 0.0720 - val_loss: 0.0320 - val_mae: 0.1025\n",
      "Epoch 98/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0087 - mae: 0.0717 - val_loss: 0.0327 - val_mae: 0.1027\n",
      "Epoch 99/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0088 - mae: 0.0716 - val_loss: 0.0321 - val_mae: 0.1025\n",
      "Epoch 100/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0088 - mae: 0.0720 - val_loss: 0.0330 - val_mae: 0.1028\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n",
      "✅ Done with tomato_Davangere_daily.csv | MAE=625.67, RMSE=948.74, R2=-0.0273, MAPE=90.67%, Accuracy=9.33%\n",
      "\n",
      "🚀 Processing: tomato_Dharwad_daily.csv\n",
      "Epoch 1/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0446 - mae: 0.1970 - val_loss: 0.0955 - val_mae: 0.2278\n",
      "Epoch 2/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0186 - mae: 0.1252 - val_loss: 0.0680 - val_mae: 0.1561\n",
      "Epoch 3/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0085 - mae: 0.0815 - val_loss: 0.0560 - val_mae: 0.1114\n",
      "Epoch 4/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0058 - mae: 0.0558 - val_loss: 0.0528 - val_mae: 0.0959\n",
      "Epoch 5/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0052 - mae: 0.0470 - val_loss: 0.0522 - val_mae: 0.0925\n",
      "Epoch 6/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0049 - mae: 0.0421 - val_loss: 0.0521 - val_mae: 0.0920\n",
      "Epoch 7/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0053 - mae: 0.0455 - val_loss: 0.0519 - val_mae: 0.0911\n",
      "Epoch 8/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0049 - mae: 0.0416 - val_loss: 0.0523 - val_mae: 0.0930\n",
      "Epoch 9/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0057 - mae: 0.0472 - val_loss: 0.0521 - val_mae: 0.0921\n",
      "Epoch 10/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0049 - mae: 0.0433 - val_loss: 0.0520 - val_mae: 0.0917\n",
      "Epoch 11/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0057 - mae: 0.0470 - val_loss: 0.0519 - val_mae: 0.0907\n",
      "Epoch 12/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0051 - mae: 0.0446 - val_loss: 0.0518 - val_mae: 0.0903\n",
      "Epoch 13/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0055 - mae: 0.0437 - val_loss: 0.0520 - val_mae: 0.0912\n",
      "Epoch 14/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0053 - mae: 0.0458 - val_loss: 0.0518 - val_mae: 0.0901\n",
      "Epoch 15/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0045 - mae: 0.0399 - val_loss: 0.0522 - val_mae: 0.0925\n",
      "Epoch 16/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0052 - mae: 0.0443 - val_loss: 0.0520 - val_mae: 0.0915\n",
      "Epoch 17/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0050 - mae: 0.0436 - val_loss: 0.0517 - val_mae: 0.0898\n",
      "Epoch 18/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0056 - mae: 0.0453 - val_loss: 0.0520 - val_mae: 0.0913\n",
      "Epoch 19/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0043 - mae: 0.0374 - val_loss: 0.0529 - val_mae: 0.0962\n",
      "Epoch 20/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0054 - mae: 0.0473 - val_loss: 0.0515 - val_mae: 0.0889\n",
      "Epoch 21/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0054 - mae: 0.0431 - val_loss: 0.0520 - val_mae: 0.0914\n",
      "Epoch 22/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0053 - mae: 0.0450 - val_loss: 0.0521 - val_mae: 0.0922\n",
      "Epoch 23/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0060 - mae: 0.0470 - val_loss: 0.0523 - val_mae: 0.0930\n",
      "Epoch 24/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0047 - mae: 0.0427 - val_loss: 0.0518 - val_mae: 0.0902\n",
      "Epoch 25/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0056 - mae: 0.0470 - val_loss: 0.0517 - val_mae: 0.0895\n",
      "Epoch 26/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0051 - mae: 0.0416 - val_loss: 0.0526 - val_mae: 0.0945\n",
      "Epoch 27/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0052 - mae: 0.0461 - val_loss: 0.0519 - val_mae: 0.0909\n",
      "Epoch 28/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0046 - mae: 0.0413 - val_loss: 0.0518 - val_mae: 0.0901\n",
      "Epoch 29/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0057 - mae: 0.0472 - val_loss: 0.0518 - val_mae: 0.0904\n",
      "Epoch 30/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0055 - mae: 0.0466 - val_loss: 0.0517 - val_mae: 0.0897\n",
      "Epoch 31/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0053 - mae: 0.0444 - val_loss: 0.0516 - val_mae: 0.0890\n",
      "Epoch 32/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0053 - mae: 0.0441 - val_loss: 0.0525 - val_mae: 0.0939\n",
      "Epoch 33/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0056 - mae: 0.0472 - val_loss: 0.0517 - val_mae: 0.0899\n",
      "Epoch 34/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0053 - mae: 0.0408 - val_loss: 0.0534 - val_mae: 0.0988\n",
      "Epoch 35/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0056 - mae: 0.0480 - val_loss: 0.0528 - val_mae: 0.0956\n",
      "Epoch 36/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0056 - mae: 0.0503 - val_loss: 0.0510 - val_mae: 0.0861\n",
      "Epoch 37/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0052 - mae: 0.0419 - val_loss: 0.0523 - val_mae: 0.0931\n",
      "Epoch 38/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0058 - mae: 0.0468 - val_loss: 0.0527 - val_mae: 0.0953\n",
      "Epoch 39/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0051 - mae: 0.0463 - val_loss: 0.0512 - val_mae: 0.0872\n",
      "Epoch 40/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0050 - mae: 0.0411 - val_loss: 0.0527 - val_mae: 0.0954\n",
      "Epoch 41/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0055 - mae: 0.0467 - val_loss: 0.0516 - val_mae: 0.0895\n",
      "Epoch 42/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0052 - mae: 0.0427 - val_loss: 0.0524 - val_mae: 0.0937\n",
      "Epoch 43/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0053 - mae: 0.0456 - val_loss: 0.0523 - val_mae: 0.0929\n",
      "Epoch 44/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0054 - mae: 0.0471 - val_loss: 0.0520 - val_mae: 0.0915\n",
      "Epoch 45/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0052 - mae: 0.0440 - val_loss: 0.0519 - val_mae: 0.0906\n",
      "Epoch 46/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0053 - mae: 0.0442 - val_loss: 0.0521 - val_mae: 0.0918\n",
      "Epoch 47/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0050 - mae: 0.0436 - val_loss: 0.0518 - val_mae: 0.0904\n",
      "Epoch 48/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0061 - mae: 0.0486 - val_loss: 0.0522 - val_mae: 0.0924\n",
      "Epoch 49/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0055 - mae: 0.0490 - val_loss: 0.0515 - val_mae: 0.0885\n",
      "Epoch 50/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0052 - mae: 0.0435 - val_loss: 0.0520 - val_mae: 0.0912\n",
      "Epoch 51/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0048 - mae: 0.0420 - val_loss: 0.0524 - val_mae: 0.0936\n",
      "Epoch 52/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0056 - mae: 0.0461 - val_loss: 0.0524 - val_mae: 0.0937\n",
      "Epoch 53/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0052 - mae: 0.0460 - val_loss: 0.0515 - val_mae: 0.0886\n",
      "Epoch 54/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0048 - mae: 0.0413 - val_loss: 0.0525 - val_mae: 0.0940\n",
      "Epoch 55/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0048 - mae: 0.0427 - val_loss: 0.0518 - val_mae: 0.0902\n",
      "Epoch 56/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0058 - mae: 0.0473 - val_loss: 0.0519 - val_mae: 0.0909\n",
      "Epoch 57/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0053 - mae: 0.0476 - val_loss: 0.0514 - val_mae: 0.0883\n",
      "Epoch 58/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0052 - mae: 0.0418 - val_loss: 0.0521 - val_mae: 0.0918\n",
      "Epoch 59/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0054 - mae: 0.0443 - val_loss: 0.0524 - val_mae: 0.0933\n",
      "Epoch 60/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0050 - mae: 0.0433 - val_loss: 0.0518 - val_mae: 0.0902\n",
      "Epoch 61/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0053 - mae: 0.0447 - val_loss: 0.0525 - val_mae: 0.0942\n",
      "Epoch 62/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0047 - mae: 0.0443 - val_loss: 0.0516 - val_mae: 0.0892\n",
      "Epoch 63/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0053 - mae: 0.0459 - val_loss: 0.0516 - val_mae: 0.0892\n",
      "Epoch 64/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0059 - mae: 0.0472 - val_loss: 0.0517 - val_mae: 0.0899\n",
      "Epoch 65/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0049 - mae: 0.0425 - val_loss: 0.0515 - val_mae: 0.0888\n",
      "Epoch 66/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0050 - mae: 0.0422 - val_loss: 0.0525 - val_mae: 0.0940\n",
      "Epoch 67/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0058 - mae: 0.0478 - val_loss: 0.0523 - val_mae: 0.0933\n",
      "Epoch 68/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0054 - mae: 0.0447 - val_loss: 0.0521 - val_mae: 0.0922\n",
      "Epoch 69/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0046 - mae: 0.0410 - val_loss: 0.0524 - val_mae: 0.0935\n",
      "Epoch 70/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0054 - mae: 0.0476 - val_loss: 0.0518 - val_mae: 0.0904\n",
      "Epoch 71/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0052 - mae: 0.0435 - val_loss: 0.0523 - val_mae: 0.0933\n",
      "Epoch 72/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0051 - mae: 0.0422 - val_loss: 0.0527 - val_mae: 0.0950\n",
      "Epoch 73/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0052 - mae: 0.0448 - val_loss: 0.0519 - val_mae: 0.0909\n",
      "Epoch 74/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0058 - mae: 0.0480 - val_loss: 0.0520 - val_mae: 0.0912\n",
      "Epoch 75/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0056 - mae: 0.0437 - val_loss: 0.0523 - val_mae: 0.0929\n",
      "Epoch 76/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0056 - mae: 0.0449 - val_loss: 0.0520 - val_mae: 0.0912\n",
      "Epoch 77/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0053 - mae: 0.0452 - val_loss: 0.0516 - val_mae: 0.0893\n",
      "Epoch 78/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0051 - mae: 0.0427 - val_loss: 0.0522 - val_mae: 0.0923\n",
      "Epoch 79/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0058 - mae: 0.0469 - val_loss: 0.0527 - val_mae: 0.0950\n",
      "Epoch 80/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0055 - mae: 0.0454 - val_loss: 0.0524 - val_mae: 0.0934\n",
      "Epoch 81/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0054 - mae: 0.0468 - val_loss: 0.0516 - val_mae: 0.0891\n",
      "Epoch 82/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0056 - mae: 0.0461 - val_loss: 0.0515 - val_mae: 0.0887\n",
      "Epoch 83/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0050 - mae: 0.0412 - val_loss: 0.0518 - val_mae: 0.0906\n",
      "Epoch 84/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0052 - mae: 0.0457 - val_loss: 0.0509 - val_mae: 0.0851\n",
      "Epoch 85/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0053 - mae: 0.0424 - val_loss: 0.0516 - val_mae: 0.0894\n",
      "Epoch 86/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0054 - mae: 0.0460 - val_loss: 0.0521 - val_mae: 0.0918\n",
      "Epoch 87/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0058 - mae: 0.0472 - val_loss: 0.0511 - val_mae: 0.0864\n",
      "Epoch 88/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0049 - mae: 0.0403 - val_loss: 0.0517 - val_mae: 0.0900\n",
      "Epoch 89/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0049 - mae: 0.0417 - val_loss: 0.0519 - val_mae: 0.0907\n",
      "Epoch 90/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0048 - mae: 0.0413 - val_loss: 0.0525 - val_mae: 0.0939\n",
      "Epoch 91/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0050 - mae: 0.0442 - val_loss: 0.0527 - val_mae: 0.0953\n",
      "Epoch 92/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0059 - mae: 0.0480 - val_loss: 0.0519 - val_mae: 0.0909\n",
      "Epoch 93/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0052 - mae: 0.0426 - val_loss: 0.0525 - val_mae: 0.0939\n",
      "Epoch 94/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0047 - mae: 0.0434 - val_loss: 0.0520 - val_mae: 0.0913\n",
      "Epoch 95/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0051 - mae: 0.0421 - val_loss: 0.0528 - val_mae: 0.0958\n",
      "Epoch 96/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0050 - mae: 0.0438 - val_loss: 0.0521 - val_mae: 0.0921\n",
      "Epoch 97/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0051 - mae: 0.0417 - val_loss: 0.0533 - val_mae: 0.0982\n",
      "Epoch 98/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0057 - mae: 0.0489 - val_loss: 0.0516 - val_mae: 0.0890\n",
      "Epoch 99/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0051 - mae: 0.0431 - val_loss: 0.0510 - val_mae: 0.0857\n",
      "Epoch 100/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0056 - mae: 0.0449 - val_loss: 0.0524 - val_mae: 0.0934\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "✅ Done with tomato_Dharwad_daily.csv | MAE=397.88, RMSE=868.14, R2=-0.0288, MAPE=27.73%, Accuracy=72.27%\n",
      "\n",
      "🚀 Processing: tomato_Gadag_daily.csv\n",
      "Epoch 1/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - loss: 0.2501 - mae: 0.4548 - val_loss: 0.6735 - val_mae: 0.8133\n",
      "Epoch 2/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1932 - mae: 0.3883 - val_loss: 0.5525 - val_mae: 0.7351\n",
      "Epoch 3/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1444 - mae: 0.3223 - val_loss: 0.4388 - val_mae: 0.6532\n",
      "Epoch 4/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0888 - mae: 0.2416 - val_loss: 0.3430 - val_mae: 0.5753\n",
      "Epoch 5/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0613 - mae: 0.1996 - val_loss: 0.2708 - val_mae: 0.5087\n",
      "Epoch 6/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0507 - mae: 0.1899 - val_loss: 0.2255 - val_mae: 0.4619\n",
      "Epoch 7/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0458 - mae: 0.1842 - val_loss: 0.1993 - val_mae: 0.4327\n",
      "Epoch 8/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0413 - mae: 0.1735 - val_loss: 0.1875 - val_mae: 0.4188\n",
      "Epoch 9/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0427 - mae: 0.1764 - val_loss: 0.1821 - val_mae: 0.4123\n",
      "Epoch 10/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0400 - mae: 0.1717 - val_loss: 0.1804 - val_mae: 0.4103\n",
      "Epoch 11/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0419 - mae: 0.1761 - val_loss: 0.1798 - val_mae: 0.4096\n",
      "Epoch 12/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0418 - mae: 0.1749 - val_loss: 0.1795 - val_mae: 0.4092\n",
      "Epoch 13/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0426 - mae: 0.1781 - val_loss: 0.1790 - val_mae: 0.4086\n",
      "Epoch 14/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0418 - mae: 0.1744 - val_loss: 0.1809 - val_mae: 0.4109\n",
      "Epoch 15/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0417 - mae: 0.1761 - val_loss: 0.1811 - val_mae: 0.4111\n",
      "Epoch 16/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0427 - mae: 0.1793 - val_loss: 0.1777 - val_mae: 0.4070\n",
      "Epoch 17/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0415 - mae: 0.1739 - val_loss: 0.1776 - val_mae: 0.4068\n",
      "Epoch 18/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0434 - mae: 0.1798 - val_loss: 0.1801 - val_mae: 0.4099\n",
      "Epoch 19/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0425 - mae: 0.1770 - val_loss: 0.1812 - val_mae: 0.4112\n",
      "Epoch 20/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0435 - mae: 0.1805 - val_loss: 0.1773 - val_mae: 0.4066\n",
      "Epoch 21/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0401 - mae: 0.1703 - val_loss: 0.1787 - val_mae: 0.4082\n",
      "Epoch 22/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0424 - mae: 0.1768 - val_loss: 0.1776 - val_mae: 0.4068\n",
      "Epoch 23/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0440 - mae: 0.1827 - val_loss: 0.1798 - val_mae: 0.4096\n",
      "Epoch 24/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0426 - mae: 0.1768 - val_loss: 0.1778 - val_mae: 0.4072\n",
      "Epoch 25/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0421 - mae: 0.1770 - val_loss: 0.1802 - val_mae: 0.4101\n",
      "Epoch 26/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0425 - mae: 0.1763 - val_loss: 0.1793 - val_mae: 0.4090\n",
      "Epoch 27/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0437 - mae: 0.1799 - val_loss: 0.1789 - val_mae: 0.4085\n",
      "Epoch 28/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0420 - mae: 0.1787 - val_loss: 0.1808 - val_mae: 0.4107\n",
      "Epoch 29/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0431 - mae: 0.1784 - val_loss: 0.1828 - val_mae: 0.4132\n",
      "Epoch 30/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0441 - mae: 0.1805 - val_loss: 0.1796 - val_mae: 0.4093\n",
      "Epoch 31/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0419 - mae: 0.1756 - val_loss: 0.1794 - val_mae: 0.4090\n",
      "Epoch 32/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0414 - mae: 0.1735 - val_loss: 0.1789 - val_mae: 0.4085\n",
      "Epoch 33/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0423 - mae: 0.1776 - val_loss: 0.1813 - val_mae: 0.4114\n",
      "Epoch 34/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0406 - mae: 0.1729 - val_loss: 0.1795 - val_mae: 0.4092\n",
      "Epoch 35/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0414 - mae: 0.1748 - val_loss: 0.1808 - val_mae: 0.4108\n",
      "Epoch 36/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0420 - mae: 0.1768 - val_loss: 0.1820 - val_mae: 0.4122\n",
      "Epoch 37/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0427 - mae: 0.1766 - val_loss: 0.1814 - val_mae: 0.4114\n",
      "Epoch 38/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0417 - mae: 0.1767 - val_loss: 0.1791 - val_mae: 0.4087\n",
      "Epoch 39/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0403 - mae: 0.1722 - val_loss: 0.1767 - val_mae: 0.4058\n",
      "Epoch 40/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0419 - mae: 0.1769 - val_loss: 0.1789 - val_mae: 0.4084\n",
      "Epoch 41/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0409 - mae: 0.1740 - val_loss: 0.1792 - val_mae: 0.4088\n",
      "Epoch 42/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0408 - mae: 0.1743 - val_loss: 0.1767 - val_mae: 0.4059\n",
      "Epoch 43/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0434 - mae: 0.1802 - val_loss: 0.1817 - val_mae: 0.4118\n",
      "Epoch 44/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0418 - mae: 0.1770 - val_loss: 0.1775 - val_mae: 0.4068\n",
      "Epoch 45/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0426 - mae: 0.1779 - val_loss: 0.1783 - val_mae: 0.4077\n",
      "Epoch 46/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0421 - mae: 0.1777 - val_loss: 0.1792 - val_mae: 0.4088\n",
      "Epoch 47/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0399 - mae: 0.1718 - val_loss: 0.1778 - val_mae: 0.4071\n",
      "Epoch 48/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0423 - mae: 0.1761 - val_loss: 0.1777 - val_mae: 0.4070\n",
      "Epoch 49/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0430 - mae: 0.1800 - val_loss: 0.1805 - val_mae: 0.4104\n",
      "Epoch 50/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0426 - mae: 0.1791 - val_loss: 0.1788 - val_mae: 0.4083\n",
      "Epoch 51/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0418 - mae: 0.1759 - val_loss: 0.1783 - val_mae: 0.4077\n",
      "Epoch 52/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0445 - mae: 0.1828 - val_loss: 0.1787 - val_mae: 0.4082\n",
      "Epoch 53/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0418 - mae: 0.1758 - val_loss: 0.1804 - val_mae: 0.4102\n",
      "Epoch 54/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0427 - mae: 0.1787 - val_loss: 0.1775 - val_mae: 0.4068\n",
      "Epoch 55/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0420 - mae: 0.1754 - val_loss: 0.1784 - val_mae: 0.4079\n",
      "Epoch 56/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0426 - mae: 0.1772 - val_loss: 0.1809 - val_mae: 0.4108\n",
      "Epoch 57/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0424 - mae: 0.1775 - val_loss: 0.1757 - val_mae: 0.4045\n",
      "Epoch 58/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0418 - mae: 0.1761 - val_loss: 0.1785 - val_mae: 0.4080\n",
      "Epoch 59/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0414 - mae: 0.1746 - val_loss: 0.1766 - val_mae: 0.4057\n",
      "Epoch 60/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0416 - mae: 0.1752 - val_loss: 0.1798 - val_mae: 0.4096\n",
      "Epoch 61/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0410 - mae: 0.1722 - val_loss: 0.1778 - val_mae: 0.4071\n",
      "Epoch 62/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0440 - mae: 0.1821 - val_loss: 0.1797 - val_mae: 0.4095\n",
      "Epoch 63/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0421 - mae: 0.1760 - val_loss: 0.1814 - val_mae: 0.4115\n",
      "Epoch 64/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0422 - mae: 0.1778 - val_loss: 0.1812 - val_mae: 0.4112\n",
      "Epoch 65/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0408 - mae: 0.1743 - val_loss: 0.1778 - val_mae: 0.4071\n",
      "Epoch 66/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0423 - mae: 0.1782 - val_loss: 0.1798 - val_mae: 0.4096\n",
      "Epoch 67/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0428 - mae: 0.1781 - val_loss: 0.1805 - val_mae: 0.4104\n",
      "Epoch 68/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0431 - mae: 0.1795 - val_loss: 0.1817 - val_mae: 0.4118\n",
      "Epoch 69/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0418 - mae: 0.1775 - val_loss: 0.1791 - val_mae: 0.4088\n",
      "Epoch 70/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0419 - mae: 0.1770 - val_loss: 0.1772 - val_mae: 0.4064\n",
      "Epoch 71/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0413 - mae: 0.1741 - val_loss: 0.1779 - val_mae: 0.4073\n",
      "Epoch 72/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0421 - mae: 0.1762 - val_loss: 0.1789 - val_mae: 0.4085\n",
      "Epoch 73/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0420 - mae: 0.1781 - val_loss: 0.1828 - val_mae: 0.4131\n",
      "Epoch 74/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0400 - mae: 0.1722 - val_loss: 0.1796 - val_mae: 0.4093\n",
      "Epoch 75/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0416 - mae: 0.1756 - val_loss: 0.1782 - val_mae: 0.4076\n",
      "Epoch 76/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0427 - mae: 0.1782 - val_loss: 0.1804 - val_mae: 0.4103\n",
      "Epoch 77/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0435 - mae: 0.1798 - val_loss: 0.1803 - val_mae: 0.4101\n",
      "Epoch 78/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0441 - mae: 0.1823 - val_loss: 0.1813 - val_mae: 0.4114\n",
      "Epoch 79/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0434 - mae: 0.1798 - val_loss: 0.1776 - val_mae: 0.4069\n",
      "Epoch 80/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0409 - mae: 0.1742 - val_loss: 0.1736 - val_mae: 0.4020\n",
      "Epoch 81/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0432 - mae: 0.1797 - val_loss: 0.1795 - val_mae: 0.4092\n",
      "Epoch 82/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0416 - mae: 0.1753 - val_loss: 0.1819 - val_mae: 0.4120\n",
      "Epoch 83/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0410 - mae: 0.1749 - val_loss: 0.1773 - val_mae: 0.4065\n",
      "Epoch 84/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0408 - mae: 0.1726 - val_loss: 0.1851 - val_mae: 0.4159\n",
      "Epoch 85/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0430 - mae: 0.1790 - val_loss: 0.1783 - val_mae: 0.4078\n",
      "Epoch 86/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0434 - mae: 0.1794 - val_loss: 0.1841 - val_mae: 0.4148\n",
      "Epoch 87/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0440 - mae: 0.1827 - val_loss: 0.1750 - val_mae: 0.4038\n",
      "Epoch 88/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0428 - mae: 0.1782 - val_loss: 0.1751 - val_mae: 0.4039\n",
      "Epoch 89/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0411 - mae: 0.1747 - val_loss: 0.1780 - val_mae: 0.4074\n",
      "Epoch 90/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0410 - mae: 0.1732 - val_loss: 0.1742 - val_mae: 0.4028\n",
      "Epoch 91/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0437 - mae: 0.1825 - val_loss: 0.1836 - val_mae: 0.4142\n",
      "Epoch 92/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0418 - mae: 0.1763 - val_loss: 0.1806 - val_mae: 0.4105\n",
      "Epoch 93/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0416 - mae: 0.1766 - val_loss: 0.1771 - val_mae: 0.4064\n",
      "Epoch 94/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0411 - mae: 0.1739 - val_loss: 0.1782 - val_mae: 0.4077\n",
      "Epoch 95/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0422 - mae: 0.1774 - val_loss: 0.1799 - val_mae: 0.4096\n",
      "Epoch 96/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0428 - mae: 0.1794 - val_loss: 0.1782 - val_mae: 0.4076\n",
      "Epoch 97/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0404 - mae: 0.1741 - val_loss: 0.1780 - val_mae: 0.4073\n",
      "Epoch 98/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0443 - mae: 0.1821 - val_loss: 0.1768 - val_mae: 0.4059\n",
      "Epoch 99/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0413 - mae: 0.1744 - val_loss: 0.1786 - val_mae: 0.4082\n",
      "Epoch 100/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0396 - mae: 0.1699 - val_loss: 0.1807 - val_mae: 0.4106\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "✅ Done with tomato_Gadag_daily.csv | MAE=1869.63, RMSE=2209.22, R2=-0.1115, MAPE=42.7%, Accuracy=57.3%\n",
      "\n",
      "🚀 Processing: tomato_Hassan_daily.csv\n",
      "Epoch 1/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - loss: 0.0027 - mae: 0.0390 - val_loss: 0.0223 - val_mae: 0.1023\n",
      "Epoch 2/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0376 - val_loss: 0.0227 - val_mae: 0.1039\n",
      "Epoch 3/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0375 - val_loss: 0.0223 - val_mae: 0.1023\n",
      "Epoch 4/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0024 - mae: 0.0374 - val_loss: 0.0221 - val_mae: 0.1016\n",
      "Epoch 5/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - loss: 0.0025 - mae: 0.0381 - val_loss: 0.0223 - val_mae: 0.1024\n",
      "Epoch 6/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - loss: 0.0025 - mae: 0.0376 - val_loss: 0.0212 - val_mae: 0.0978\n",
      "Epoch 7/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0381 - val_loss: 0.0220 - val_mae: 0.1012\n",
      "Epoch 8/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0380 - val_loss: 0.0216 - val_mae: 0.0993\n",
      "Epoch 9/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - loss: 0.0025 - mae: 0.0379 - val_loss: 0.0225 - val_mae: 0.1031\n",
      "Epoch 10/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0381 - val_loss: 0.0211 - val_mae: 0.0976\n",
      "Epoch 11/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - loss: 0.0025 - mae: 0.0379 - val_loss: 0.0212 - val_mae: 0.0980\n",
      "Epoch 12/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0376 - val_loss: 0.0226 - val_mae: 0.1036\n",
      "Epoch 13/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0379 - val_loss: 0.0223 - val_mae: 0.1024\n",
      "Epoch 14/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0380 - val_loss: 0.0229 - val_mae: 0.1048\n",
      "Epoch 15/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0378 - val_loss: 0.0212 - val_mae: 0.0980\n",
      "Epoch 16/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0026 - mae: 0.0386 - val_loss: 0.0228 - val_mae: 0.1046\n",
      "Epoch 17/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0375 - val_loss: 0.0213 - val_mae: 0.0983\n",
      "Epoch 18/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0026 - mae: 0.0385 - val_loss: 0.0234 - val_mae: 0.1068\n",
      "Epoch 19/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0376 - val_loss: 0.0217 - val_mae: 0.1001\n",
      "Epoch 20/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0382 - val_loss: 0.0233 - val_mae: 0.1067\n",
      "Epoch 21/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0382 - val_loss: 0.0228 - val_mae: 0.1044\n",
      "Epoch 22/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0382 - val_loss: 0.0228 - val_mae: 0.1043\n",
      "Epoch 23/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0382 - val_loss: 0.0225 - val_mae: 0.1031\n",
      "Epoch 24/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0377 - val_loss: 0.0220 - val_mae: 0.1013\n",
      "Epoch 25/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0380 - val_loss: 0.0224 - val_mae: 0.1030\n",
      "Epoch 26/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0026 - mae: 0.0384 - val_loss: 0.0221 - val_mae: 0.1017\n",
      "Epoch 27/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0378 - val_loss: 0.0232 - val_mae: 0.1060\n",
      "Epoch 28/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0378 - val_loss: 0.0217 - val_mae: 0.0999\n",
      "Epoch 29/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0383 - val_loss: 0.0225 - val_mae: 0.1031\n",
      "Epoch 30/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0380 - val_loss: 0.0229 - val_mae: 0.1051\n",
      "Epoch 31/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0381 - val_loss: 0.0231 - val_mae: 0.1059\n",
      "Epoch 32/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0380 - val_loss: 0.0233 - val_mae: 0.1066\n",
      "Epoch 33/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0376 - val_loss: 0.0225 - val_mae: 0.1031\n",
      "Epoch 34/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0375 - val_loss: 0.0222 - val_mae: 0.1018\n",
      "Epoch 35/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - loss: 0.0025 - mae: 0.0382 - val_loss: 0.0223 - val_mae: 0.1025\n",
      "Epoch 36/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - loss: 0.0025 - mae: 0.0382 - val_loss: 0.0230 - val_mae: 0.1053\n",
      "Epoch 37/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0376 - val_loss: 0.0220 - val_mae: 0.1011\n",
      "Epoch 38/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0026 - mae: 0.0385 - val_loss: 0.0237 - val_mae: 0.1084\n",
      "Epoch 39/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0382 - val_loss: 0.0224 - val_mae: 0.1028\n",
      "Epoch 40/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0383 - val_loss: 0.0227 - val_mae: 0.1041\n",
      "Epoch 41/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0379 - val_loss: 0.0227 - val_mae: 0.1041\n",
      "Epoch 42/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0379 - val_loss: 0.0224 - val_mae: 0.1028\n",
      "Epoch 43/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - loss: 0.0024 - mae: 0.0374 - val_loss: 0.0225 - val_mae: 0.1034\n",
      "Epoch 44/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - loss: 0.0025 - mae: 0.0379 - val_loss: 0.0234 - val_mae: 0.1069\n",
      "Epoch 45/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - loss: 0.0025 - mae: 0.0375 - val_loss: 0.0219 - val_mae: 0.1008\n",
      "Epoch 46/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0380 - val_loss: 0.0221 - val_mae: 0.1015\n",
      "Epoch 47/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0378 - val_loss: 0.0217 - val_mae: 0.0999\n",
      "Epoch 48/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0378 - val_loss: 0.0212 - val_mae: 0.0979\n",
      "Epoch 49/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0383 - val_loss: 0.0231 - val_mae: 0.1059\n",
      "Epoch 50/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0024 - mae: 0.0374 - val_loss: 0.0225 - val_mae: 0.1031\n",
      "Epoch 51/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0379 - val_loss: 0.0227 - val_mae: 0.1040\n",
      "Epoch 52/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0376 - val_loss: 0.0221 - val_mae: 0.1015\n",
      "Epoch 53/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0380 - val_loss: 0.0230 - val_mae: 0.1055\n",
      "Epoch 54/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0378 - val_loss: 0.0233 - val_mae: 0.1064\n",
      "Epoch 55/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0379 - val_loss: 0.0234 - val_mae: 0.1069\n",
      "Epoch 56/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0381 - val_loss: 0.0221 - val_mae: 0.1015\n",
      "Epoch 57/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0378 - val_loss: 0.0221 - val_mae: 0.1017\n",
      "Epoch 58/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0024 - mae: 0.0374 - val_loss: 0.0217 - val_mae: 0.1001\n",
      "Epoch 59/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0026 - mae: 0.0383 - val_loss: 0.0223 - val_mae: 0.1026\n",
      "Epoch 60/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0376 - val_loss: 0.0237 - val_mae: 0.1081\n",
      "Epoch 61/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0378 - val_loss: 0.0225 - val_mae: 0.1034\n",
      "Epoch 62/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0379 - val_loss: 0.0225 - val_mae: 0.1031\n",
      "Epoch 63/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0377 - val_loss: 0.0230 - val_mae: 0.1052\n",
      "Epoch 64/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0379 - val_loss: 0.0223 - val_mae: 0.1024\n",
      "Epoch 65/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0376 - val_loss: 0.0228 - val_mae: 0.1043\n",
      "Epoch 66/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0377 - val_loss: 0.0231 - val_mae: 0.1058\n",
      "Epoch 67/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0378 - val_loss: 0.0217 - val_mae: 0.0998\n",
      "Epoch 68/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0380 - val_loss: 0.0235 - val_mae: 0.1072\n",
      "Epoch 69/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0024 - mae: 0.0373 - val_loss: 0.0221 - val_mae: 0.1016\n",
      "Epoch 70/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0378 - val_loss: 0.0226 - val_mae: 0.1038\n",
      "Epoch 71/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0024 - mae: 0.0375 - val_loss: 0.0226 - val_mae: 0.1037\n",
      "Epoch 72/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0383 - val_loss: 0.0226 - val_mae: 0.1038\n",
      "Epoch 73/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0378 - val_loss: 0.0227 - val_mae: 0.1040\n",
      "Epoch 74/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0381 - val_loss: 0.0217 - val_mae: 0.0997\n",
      "Epoch 75/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - loss: 0.0025 - mae: 0.0384 - val_loss: 0.0223 - val_mae: 0.1025\n",
      "Epoch 76/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0378 - val_loss: 0.0234 - val_mae: 0.1070\n",
      "Epoch 77/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0379 - val_loss: 0.0227 - val_mae: 0.1041\n",
      "Epoch 78/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0378 - val_loss: 0.0223 - val_mae: 0.1022\n",
      "Epoch 79/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0379 - val_loss: 0.0225 - val_mae: 0.1031\n",
      "Epoch 80/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0024 - mae: 0.0375 - val_loss: 0.0218 - val_mae: 0.1003\n",
      "Epoch 81/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0378 - val_loss: 0.0230 - val_mae: 0.1054\n",
      "Epoch 82/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0377 - val_loss: 0.0229 - val_mae: 0.1050\n",
      "Epoch 83/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0378 - val_loss: 0.0222 - val_mae: 0.1019\n",
      "Epoch 84/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0378 - val_loss: 0.0229 - val_mae: 0.1047\n",
      "Epoch 85/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0379 - val_loss: 0.0221 - val_mae: 0.1015\n",
      "Epoch 86/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0379 - val_loss: 0.0226 - val_mae: 0.1036\n",
      "Epoch 87/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0379 - val_loss: 0.0226 - val_mae: 0.1035\n",
      "Epoch 88/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0381 - val_loss: 0.0231 - val_mae: 0.1055\n",
      "Epoch 89/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0378 - val_loss: 0.0224 - val_mae: 0.1027\n",
      "Epoch 90/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0377 - val_loss: 0.0229 - val_mae: 0.1047\n",
      "Epoch 91/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0379 - val_loss: 0.0226 - val_mae: 0.1037\n",
      "Epoch 92/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0024 - mae: 0.0376 - val_loss: 0.0224 - val_mae: 0.1030\n",
      "Epoch 93/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0380 - val_loss: 0.0225 - val_mae: 0.1031\n",
      "Epoch 94/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0379 - val_loss: 0.0221 - val_mae: 0.1016\n",
      "Epoch 95/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - loss: 0.0025 - mae: 0.0377 - val_loss: 0.0220 - val_mae: 0.1011\n",
      "Epoch 96/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0379 - val_loss: 0.0230 - val_mae: 0.1051\n",
      "Epoch 97/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0380 - val_loss: 0.0224 - val_mae: 0.1029\n",
      "Epoch 98/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0024 - mae: 0.0375 - val_loss: 0.0221 - val_mae: 0.1017\n",
      "Epoch 99/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0024 - mae: 0.0376 - val_loss: 0.0226 - val_mae: 0.1038\n",
      "Epoch 100/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0025 - mae: 0.0375 - val_loss: 0.0225 - val_mae: 0.1032\n",
      "\u001b[1m923/923\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step\n",
      "✅ Done with tomato_Hassan_daily.csv | MAE=612.49, RMSE=968.3, R2=-0.0652, MAPE=68.66%, Accuracy=31.34%\n",
      "\n",
      "🚀 Processing: tomato_Haveri_daily.csv\n",
      "Epoch 1/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.1702 - mae: 0.3420 - val_loss: 0.2270 - val_mae: 0.4318\n",
      "Epoch 2/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0635 - mae: 0.2068 - val_loss: 0.1884 - val_mae: 0.4189\n",
      "Epoch 3/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0527 - mae: 0.2008 - val_loss: 0.1846 - val_mae: 0.4171\n",
      "Epoch 4/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0530 - mae: 0.2031 - val_loss: 0.1835 - val_mae: 0.4166\n",
      "Epoch 5/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0525 - mae: 0.2015 - val_loss: 0.1850 - val_mae: 0.4173\n",
      "Epoch 6/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0528 - mae: 0.2020 - val_loss: 0.1842 - val_mae: 0.4169\n",
      "Epoch 7/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0540 - mae: 0.2056 - val_loss: 0.1856 - val_mae: 0.4176\n",
      "Epoch 8/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0529 - mae: 0.2029 - val_loss: 0.1856 - val_mae: 0.4176\n",
      "Epoch 9/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0532 - mae: 0.2029 - val_loss: 0.1861 - val_mae: 0.4179\n",
      "Epoch 10/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0531 - mae: 0.2027 - val_loss: 0.1852 - val_mae: 0.4174\n",
      "Epoch 11/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0537 - mae: 0.2050 - val_loss: 0.1846 - val_mae: 0.4171\n",
      "Epoch 12/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0530 - mae: 0.2010 - val_loss: 0.1840 - val_mae: 0.4168\n",
      "Epoch 13/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0523 - mae: 0.2005 - val_loss: 0.1835 - val_mae: 0.4166\n",
      "Epoch 14/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0513 - mae: 0.1990 - val_loss: 0.1842 - val_mae: 0.4169\n",
      "Epoch 15/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0531 - mae: 0.2044 - val_loss: 0.1830 - val_mae: 0.4163\n",
      "Epoch 16/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0540 - mae: 0.2062 - val_loss: 0.1828 - val_mae: 0.4162\n",
      "Epoch 17/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0512 - mae: 0.1984 - val_loss: 0.1851 - val_mae: 0.4174\n",
      "Epoch 18/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0538 - mae: 0.2036 - val_loss: 0.1884 - val_mae: 0.4189\n",
      "Epoch 19/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0532 - mae: 0.2034 - val_loss: 0.1848 - val_mae: 0.4172\n",
      "Epoch 20/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0531 - mae: 0.2033 - val_loss: 0.1832 - val_mae: 0.4164\n",
      "Epoch 21/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0524 - mae: 0.2014 - val_loss: 0.1851 - val_mae: 0.4174\n",
      "Epoch 22/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0528 - mae: 0.2025 - val_loss: 0.1865 - val_mae: 0.4181\n",
      "Epoch 23/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0523 - mae: 0.2007 - val_loss: 0.1839 - val_mae: 0.4168\n",
      "Epoch 24/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0528 - mae: 0.2022 - val_loss: 0.1868 - val_mae: 0.4182\n",
      "Epoch 25/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0540 - mae: 0.2049 - val_loss: 0.1853 - val_mae: 0.4175\n",
      "Epoch 26/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0534 - mae: 0.2024 - val_loss: 0.1830 - val_mae: 0.4163\n",
      "Epoch 27/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0527 - mae: 0.2028 - val_loss: 0.1841 - val_mae: 0.4169\n",
      "Epoch 28/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0525 - mae: 0.2028 - val_loss: 0.1833 - val_mae: 0.4165\n",
      "Epoch 29/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0541 - mae: 0.2065 - val_loss: 0.1849 - val_mae: 0.4173\n",
      "Epoch 30/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0525 - mae: 0.2010 - val_loss: 0.1861 - val_mae: 0.4179\n",
      "Epoch 31/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0516 - mae: 0.1985 - val_loss: 0.1852 - val_mae: 0.4174\n",
      "Epoch 32/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0536 - mae: 0.2042 - val_loss: 0.1850 - val_mae: 0.4173\n",
      "Epoch 33/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0522 - mae: 0.1999 - val_loss: 0.1837 - val_mae: 0.4167\n",
      "Epoch 34/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0528 - mae: 0.2025 - val_loss: 0.1864 - val_mae: 0.4180\n",
      "Epoch 35/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0544 - mae: 0.2046 - val_loss: 0.1851 - val_mae: 0.4174\n",
      "Epoch 36/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0541 - mae: 0.2051 - val_loss: 0.1837 - val_mae: 0.4167\n",
      "Epoch 37/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0510 - mae: 0.1982 - val_loss: 0.1834 - val_mae: 0.4165\n",
      "Epoch 38/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0531 - mae: 0.2024 - val_loss: 0.1840 - val_mae: 0.4168\n",
      "Epoch 39/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0536 - mae: 0.2038 - val_loss: 0.1842 - val_mae: 0.4169\n",
      "Epoch 40/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0534 - mae: 0.2043 - val_loss: 0.1831 - val_mae: 0.4164\n",
      "Epoch 41/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0541 - mae: 0.2071 - val_loss: 0.1836 - val_mae: 0.4166\n",
      "Epoch 42/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0517 - mae: 0.1995 - val_loss: 0.1823 - val_mae: 0.4159\n",
      "Epoch 43/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0536 - mae: 0.2047 - val_loss: 0.1876 - val_mae: 0.4186\n",
      "Epoch 44/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0543 - mae: 0.2043 - val_loss: 0.1843 - val_mae: 0.4170\n",
      "Epoch 45/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0537 - mae: 0.2034 - val_loss: 0.1889 - val_mae: 0.4191\n",
      "Epoch 46/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0533 - mae: 0.2014 - val_loss: 0.1845 - val_mae: 0.4171\n",
      "Epoch 47/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0539 - mae: 0.2052 - val_loss: 0.1853 - val_mae: 0.4175\n",
      "Epoch 48/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0522 - mae: 0.2007 - val_loss: 0.1835 - val_mae: 0.4166\n",
      "Epoch 49/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0522 - mae: 0.2004 - val_loss: 0.1822 - val_mae: 0.4159\n",
      "Epoch 50/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0539 - mae: 0.2045 - val_loss: 0.1875 - val_mae: 0.4185\n",
      "Epoch 51/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0543 - mae: 0.2045 - val_loss: 0.1860 - val_mae: 0.4178\n",
      "Epoch 52/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0535 - mae: 0.2037 - val_loss: 0.1856 - val_mae: 0.4176\n",
      "Epoch 53/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0533 - mae: 0.2028 - val_loss: 0.1848 - val_mae: 0.4172\n",
      "Epoch 54/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0526 - mae: 0.2017 - val_loss: 0.1847 - val_mae: 0.4172\n",
      "Epoch 55/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0539 - mae: 0.2053 - val_loss: 0.1842 - val_mae: 0.4169\n",
      "Epoch 56/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0526 - mae: 0.2035 - val_loss: 0.1858 - val_mae: 0.4177\n",
      "Epoch 57/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0530 - mae: 0.2024 - val_loss: 0.1866 - val_mae: 0.4181\n",
      "Epoch 58/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0548 - mae: 0.2061 - val_loss: 0.1837 - val_mae: 0.4166\n",
      "Epoch 59/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0529 - mae: 0.2020 - val_loss: 0.1839 - val_mae: 0.4168\n",
      "Epoch 60/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0544 - mae: 0.2063 - val_loss: 0.1845 - val_mae: 0.4171\n",
      "Epoch 61/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0519 - mae: 0.2010 - val_loss: 0.1873 - val_mae: 0.4184\n",
      "Epoch 62/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0525 - mae: 0.2007 - val_loss: 0.1844 - val_mae: 0.4170\n",
      "Epoch 63/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0531 - mae: 0.2040 - val_loss: 0.1845 - val_mae: 0.4171\n",
      "Epoch 64/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0533 - mae: 0.2035 - val_loss: 0.1830 - val_mae: 0.4163\n",
      "Epoch 65/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0533 - mae: 0.2053 - val_loss: 0.1842 - val_mae: 0.4169\n",
      "Epoch 66/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0541 - mae: 0.2048 - val_loss: 0.1825 - val_mae: 0.4160\n",
      "Epoch 67/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0532 - mae: 0.2034 - val_loss: 0.1848 - val_mae: 0.4172\n",
      "Epoch 68/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0546 - mae: 0.2065 - val_loss: 0.1847 - val_mae: 0.4172\n",
      "Epoch 69/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0512 - mae: 0.1985 - val_loss: 0.1848 - val_mae: 0.4172\n",
      "Epoch 70/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0522 - mae: 0.2008 - val_loss: 0.1833 - val_mae: 0.4164\n",
      "Epoch 71/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0541 - mae: 0.2060 - val_loss: 0.1867 - val_mae: 0.4181\n",
      "Epoch 72/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0536 - mae: 0.2027 - val_loss: 0.1842 - val_mae: 0.4169\n",
      "Epoch 73/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0529 - mae: 0.2044 - val_loss: 0.1857 - val_mae: 0.4177\n",
      "Epoch 74/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0528 - mae: 0.2031 - val_loss: 0.1862 - val_mae: 0.4179\n",
      "Epoch 75/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0520 - mae: 0.2000 - val_loss: 0.1832 - val_mae: 0.4164\n",
      "Epoch 76/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0525 - mae: 0.2027 - val_loss: 0.1845 - val_mae: 0.4171\n",
      "Epoch 77/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0530 - mae: 0.2022 - val_loss: 0.1857 - val_mae: 0.4177\n",
      "Epoch 78/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0518 - mae: 0.2003 - val_loss: 0.1870 - val_mae: 0.4183\n",
      "Epoch 79/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0534 - mae: 0.2040 - val_loss: 0.1825 - val_mae: 0.4160\n",
      "Epoch 80/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0522 - mae: 0.2018 - val_loss: 0.1864 - val_mae: 0.4180\n",
      "Epoch 81/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0535 - mae: 0.2035 - val_loss: 0.1850 - val_mae: 0.4173\n",
      "Epoch 82/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0549 - mae: 0.2074 - val_loss: 0.1864 - val_mae: 0.4180\n",
      "Epoch 83/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0522 - mae: 0.2000 - val_loss: 0.1850 - val_mae: 0.4173\n",
      "Epoch 84/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0520 - mae: 0.2002 - val_loss: 0.1852 - val_mae: 0.4174\n",
      "Epoch 85/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0530 - mae: 0.2015 - val_loss: 0.1812 - val_mae: 0.4152\n",
      "Epoch 86/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0535 - mae: 0.2047 - val_loss: 0.1845 - val_mae: 0.4171\n",
      "Epoch 87/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0530 - mae: 0.2024 - val_loss: 0.1871 - val_mae: 0.4183\n",
      "Epoch 88/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0545 - mae: 0.2062 - val_loss: 0.1874 - val_mae: 0.4185\n",
      "Epoch 89/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0529 - mae: 0.2018 - val_loss: 0.1848 - val_mae: 0.4172\n",
      "Epoch 90/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0518 - mae: 0.1992 - val_loss: 0.1837 - val_mae: 0.4167\n",
      "Epoch 91/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0526 - mae: 0.2019 - val_loss: 0.1841 - val_mae: 0.4169\n",
      "Epoch 92/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0538 - mae: 0.2049 - val_loss: 0.1835 - val_mae: 0.4166\n",
      "Epoch 93/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0539 - mae: 0.2050 - val_loss: 0.1842 - val_mae: 0.4169\n",
      "Epoch 94/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0537 - mae: 0.2054 - val_loss: 0.1847 - val_mae: 0.4172\n",
      "Epoch 95/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0537 - mae: 0.2030 - val_loss: 0.1832 - val_mae: 0.4164\n",
      "Epoch 96/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0523 - mae: 0.2016 - val_loss: 0.1849 - val_mae: 0.4173\n",
      "Epoch 97/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0529 - mae: 0.2033 - val_loss: 0.1832 - val_mae: 0.4164\n",
      "Epoch 98/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0519 - mae: 0.2009 - val_loss: 0.1817 - val_mae: 0.4156\n",
      "Epoch 99/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0535 - mae: 0.2046 - val_loss: 0.1844 - val_mae: 0.4170\n",
      "Epoch 100/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0517 - mae: 0.1996 - val_loss: 0.1849 - val_mae: 0.4173\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "✅ Done with tomato_Haveri_daily.csv | MAE=2044.29, RMSE=2345.31, R2=-0.005, MAPE=117.64%, Accuracy=-17.64%\n",
      "\n",
      "🚀 Processing: tomato_Kalburgi_daily.csv\n",
      "Epoch 1/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - loss: 0.0723 - mae: 0.1774 - val_loss: 0.0115 - val_mae: 0.0817\n",
      "Epoch 2/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0489 - mae: 0.1351 - val_loss: 0.0057 - val_mae: 0.0599\n",
      "Epoch 3/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0420 - mae: 0.1445 - val_loss: 0.0056 - val_mae: 0.0645\n",
      "Epoch 4/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0430 - mae: 0.1553 - val_loss: 0.0059 - val_mae: 0.0668\n",
      "Epoch 5/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0383 - mae: 0.1454 - val_loss: 0.0060 - val_mae: 0.0676\n",
      "Epoch 6/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0403 - mae: 0.1529 - val_loss: 0.0061 - val_mae: 0.0684\n",
      "Epoch 7/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0410 - mae: 0.1524 - val_loss: 0.0062 - val_mae: 0.0688\n",
      "Epoch 8/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0390 - mae: 0.1506 - val_loss: 0.0059 - val_mae: 0.0668\n",
      "Epoch 9/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0364 - mae: 0.1438 - val_loss: 0.0063 - val_mae: 0.0692\n",
      "Epoch 10/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0433 - mae: 0.1572 - val_loss: 0.0060 - val_mae: 0.0676\n",
      "Epoch 11/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0374 - mae: 0.1491 - val_loss: 0.0062 - val_mae: 0.0688\n",
      "Epoch 12/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0408 - mae: 0.1526 - val_loss: 0.0060 - val_mae: 0.0679\n",
      "Epoch 13/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0400 - mae: 0.1481 - val_loss: 0.0061 - val_mae: 0.0680\n",
      "Epoch 14/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0396 - mae: 0.1479 - val_loss: 0.0062 - val_mae: 0.0691\n",
      "Epoch 15/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0358 - mae: 0.1436 - val_loss: 0.0062 - val_mae: 0.0691\n",
      "Epoch 16/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0430 - mae: 0.1575 - val_loss: 0.0062 - val_mae: 0.0689\n",
      "Epoch 17/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0385 - mae: 0.1497 - val_loss: 0.0062 - val_mae: 0.0688\n",
      "Epoch 18/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0390 - mae: 0.1511 - val_loss: 0.0065 - val_mae: 0.0706\n",
      "Epoch 19/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0408 - mae: 0.1522 - val_loss: 0.0061 - val_mae: 0.0685\n",
      "Epoch 20/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0374 - mae: 0.1466 - val_loss: 0.0061 - val_mae: 0.0680\n",
      "Epoch 21/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0385 - mae: 0.1473 - val_loss: 0.0062 - val_mae: 0.0688\n",
      "Epoch 22/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0400 - mae: 0.1526 - val_loss: 0.0060 - val_mae: 0.0675\n",
      "Epoch 23/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0437 - mae: 0.1582 - val_loss: 0.0061 - val_mae: 0.0685\n",
      "Epoch 24/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0375 - mae: 0.1446 - val_loss: 0.0061 - val_mae: 0.0684\n",
      "Epoch 25/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0352 - mae: 0.1422 - val_loss: 0.0063 - val_mae: 0.0696\n",
      "Epoch 26/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0365 - mae: 0.1479 - val_loss: 0.0063 - val_mae: 0.0694\n",
      "Epoch 27/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0364 - mae: 0.1445 - val_loss: 0.0062 - val_mae: 0.0690\n",
      "Epoch 28/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0385 - mae: 0.1516 - val_loss: 0.0063 - val_mae: 0.0694\n",
      "Epoch 29/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0405 - mae: 0.1502 - val_loss: 0.0061 - val_mae: 0.0685\n",
      "Epoch 30/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0387 - mae: 0.1481 - val_loss: 0.0061 - val_mae: 0.0684\n",
      "Epoch 31/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0416 - mae: 0.1512 - val_loss: 0.0060 - val_mae: 0.0677\n",
      "Epoch 32/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0397 - mae: 0.1512 - val_loss: 0.0063 - val_mae: 0.0695\n",
      "Epoch 33/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0400 - mae: 0.1542 - val_loss: 0.0061 - val_mae: 0.0682\n",
      "Epoch 34/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0357 - mae: 0.1448 - val_loss: 0.0062 - val_mae: 0.0692\n",
      "Epoch 35/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0343 - mae: 0.1406 - val_loss: 0.0063 - val_mae: 0.0696\n",
      "Epoch 36/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0351 - mae: 0.1438 - val_loss: 0.0063 - val_mae: 0.0694\n",
      "Epoch 37/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0388 - mae: 0.1486 - val_loss: 0.0062 - val_mae: 0.0691\n",
      "Epoch 38/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0382 - mae: 0.1495 - val_loss: 0.0060 - val_mae: 0.0675\n",
      "Epoch 39/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0397 - mae: 0.1502 - val_loss: 0.0061 - val_mae: 0.0681\n",
      "Epoch 40/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0428 - mae: 0.1552 - val_loss: 0.0060 - val_mae: 0.0675\n",
      "Epoch 41/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0398 - mae: 0.1496 - val_loss: 0.0061 - val_mae: 0.0682\n",
      "Epoch 42/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0357 - mae: 0.1460 - val_loss: 0.0062 - val_mae: 0.0686\n",
      "Epoch 43/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0412 - mae: 0.1552 - val_loss: 0.0061 - val_mae: 0.0683\n",
      "Epoch 44/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0358 - mae: 0.1431 - val_loss: 0.0062 - val_mae: 0.0690\n",
      "Epoch 45/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0386 - mae: 0.1502 - val_loss: 0.0060 - val_mae: 0.0678\n",
      "Epoch 46/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0430 - mae: 0.1575 - val_loss: 0.0059 - val_mae: 0.0666\n",
      "Epoch 47/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0355 - mae: 0.1422 - val_loss: 0.0063 - val_mae: 0.0693\n",
      "Epoch 48/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0367 - mae: 0.1468 - val_loss: 0.0063 - val_mae: 0.0692\n",
      "Epoch 49/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0397 - mae: 0.1503 - val_loss: 0.0060 - val_mae: 0.0673\n",
      "Epoch 50/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0438 - mae: 0.1572 - val_loss: 0.0059 - val_mae: 0.0666\n",
      "Epoch 51/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0353 - mae: 0.1389 - val_loss: 0.0063 - val_mae: 0.0696\n",
      "Epoch 52/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0438 - mae: 0.1553 - val_loss: 0.0060 - val_mae: 0.0674\n",
      "Epoch 53/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0383 - mae: 0.1464 - val_loss: 0.0062 - val_mae: 0.0690\n",
      "Epoch 54/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0410 - mae: 0.1552 - val_loss: 0.0062 - val_mae: 0.0691\n",
      "Epoch 55/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0379 - mae: 0.1470 - val_loss: 0.0060 - val_mae: 0.0675\n",
      "Epoch 56/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0375 - mae: 0.1456 - val_loss: 0.0061 - val_mae: 0.0684\n",
      "Epoch 57/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0371 - mae: 0.1468 - val_loss: 0.0061 - val_mae: 0.0680\n",
      "Epoch 58/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0392 - mae: 0.1532 - val_loss: 0.0061 - val_mae: 0.0679\n",
      "Epoch 59/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0397 - mae: 0.1520 - val_loss: 0.0061 - val_mae: 0.0682\n",
      "Epoch 60/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0382 - mae: 0.1470 - val_loss: 0.0061 - val_mae: 0.0680\n",
      "Epoch 61/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0346 - mae: 0.1426 - val_loss: 0.0064 - val_mae: 0.0699\n",
      "Epoch 62/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0401 - mae: 0.1533 - val_loss: 0.0061 - val_mae: 0.0683\n",
      "Epoch 63/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0359 - mae: 0.1438 - val_loss: 0.0060 - val_mae: 0.0676\n",
      "Epoch 64/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0403 - mae: 0.1515 - val_loss: 0.0060 - val_mae: 0.0676\n",
      "Epoch 65/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0390 - mae: 0.1510 - val_loss: 0.0062 - val_mae: 0.0688\n",
      "Epoch 66/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0368 - mae: 0.1471 - val_loss: 0.0062 - val_mae: 0.0690\n",
      "Epoch 67/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0359 - mae: 0.1466 - val_loss: 0.0062 - val_mae: 0.0688\n",
      "Epoch 68/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0401 - mae: 0.1517 - val_loss: 0.0063 - val_mae: 0.0697\n",
      "Epoch 69/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0405 - mae: 0.1491 - val_loss: 0.0060 - val_mae: 0.0678\n",
      "Epoch 70/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0402 - mae: 0.1512 - val_loss: 0.0062 - val_mae: 0.0691\n",
      "Epoch 71/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0372 - mae: 0.1439 - val_loss: 0.0064 - val_mae: 0.0703\n",
      "Epoch 72/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0431 - mae: 0.1574 - val_loss: 0.0061 - val_mae: 0.0682\n",
      "Epoch 73/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0344 - mae: 0.1430 - val_loss: 0.0061 - val_mae: 0.0683\n",
      "Epoch 74/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0370 - mae: 0.1477 - val_loss: 0.0062 - val_mae: 0.0687\n",
      "Epoch 75/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0367 - mae: 0.1483 - val_loss: 0.0063 - val_mae: 0.0696\n",
      "Epoch 76/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0360 - mae: 0.1458 - val_loss: 0.0062 - val_mae: 0.0690\n",
      "Epoch 77/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0395 - mae: 0.1514 - val_loss: 0.0062 - val_mae: 0.0687\n",
      "Epoch 78/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0378 - mae: 0.1469 - val_loss: 0.0061 - val_mae: 0.0680\n",
      "Epoch 79/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0404 - mae: 0.1531 - val_loss: 0.0063 - val_mae: 0.0694\n",
      "Epoch 80/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0380 - mae: 0.1450 - val_loss: 0.0062 - val_mae: 0.0687\n",
      "Epoch 81/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0376 - mae: 0.1476 - val_loss: 0.0063 - val_mae: 0.0693\n",
      "Epoch 82/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0385 - mae: 0.1501 - val_loss: 0.0064 - val_mae: 0.0701\n",
      "Epoch 83/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0389 - mae: 0.1509 - val_loss: 0.0062 - val_mae: 0.0686\n",
      "Epoch 84/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0391 - mae: 0.1527 - val_loss: 0.0061 - val_mae: 0.0683\n",
      "Epoch 85/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0397 - mae: 0.1511 - val_loss: 0.0061 - val_mae: 0.0680\n",
      "Epoch 86/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0352 - mae: 0.1416 - val_loss: 0.0064 - val_mae: 0.0704\n",
      "Epoch 87/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0372 - mae: 0.1492 - val_loss: 0.0064 - val_mae: 0.0704\n",
      "Epoch 88/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0386 - mae: 0.1507 - val_loss: 0.0063 - val_mae: 0.0692\n",
      "Epoch 89/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0368 - mae: 0.1455 - val_loss: 0.0063 - val_mae: 0.0694\n",
      "Epoch 90/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0354 - mae: 0.1444 - val_loss: 0.0064 - val_mae: 0.0702\n",
      "Epoch 91/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0366 - mae: 0.1481 - val_loss: 0.0064 - val_mae: 0.0698\n",
      "Epoch 92/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0375 - mae: 0.1495 - val_loss: 0.0063 - val_mae: 0.0693\n",
      "Epoch 93/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0359 - mae: 0.1470 - val_loss: 0.0062 - val_mae: 0.0691\n",
      "Epoch 94/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0340 - mae: 0.1427 - val_loss: 0.0064 - val_mae: 0.0699\n",
      "Epoch 95/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0401 - mae: 0.1497 - val_loss: 0.0062 - val_mae: 0.0687\n",
      "Epoch 96/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0393 - mae: 0.1508 - val_loss: 0.0061 - val_mae: 0.0681\n",
      "Epoch 97/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0412 - mae: 0.1533 - val_loss: 0.0060 - val_mae: 0.0674\n",
      "Epoch 98/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0346 - mae: 0.1425 - val_loss: 0.0064 - val_mae: 0.0703\n",
      "Epoch 99/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0427 - mae: 0.1599 - val_loss: 0.0061 - val_mae: 0.0681\n",
      "Epoch 100/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0380 - mae: 0.1473 - val_loss: 0.0062 - val_mae: 0.0687\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "✅ Done with tomato_Kalburgi_daily.csv | MAE=1320.35, RMSE=1778.37, R2=-0.0012, MAPE=155.37%, Accuracy=-55.37%\n",
      "\n",
      "🚀 Processing: tomato_Kolar_daily.csv\n",
      "Epoch 1/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 0.0035 - mae: 0.0436 - val_loss: 0.0156 - val_mae: 0.0739\n",
      "Epoch 2/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 0.0035 - mae: 0.0438 - val_loss: 0.0167 - val_mae: 0.0769\n",
      "Epoch 3/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 0.0034 - mae: 0.0431 - val_loss: 0.0172 - val_mae: 0.0783\n",
      "Epoch 4/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 0.0034 - mae: 0.0428 - val_loss: 0.0164 - val_mae: 0.0760\n",
      "Epoch 5/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 0.0035 - mae: 0.0434 - val_loss: 0.0169 - val_mae: 0.0774\n",
      "Epoch 6/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 0.0035 - mae: 0.0432 - val_loss: 0.0182 - val_mae: 0.0818\n",
      "Epoch 7/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 0.0034 - mae: 0.0428 - val_loss: 0.0164 - val_mae: 0.0759\n",
      "Epoch 8/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 0.0035 - mae: 0.0434 - val_loss: 0.0168 - val_mae: 0.0771\n",
      "Epoch 9/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 0.0034 - mae: 0.0429 - val_loss: 0.0171 - val_mae: 0.0782\n",
      "Epoch 10/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 0.0035 - mae: 0.0436 - val_loss: 0.0170 - val_mae: 0.0778\n",
      "Epoch 11/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 0.0035 - mae: 0.0434 - val_loss: 0.0162 - val_mae: 0.0753\n",
      "Epoch 12/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 0.0036 - mae: 0.0438 - val_loss: 0.0158 - val_mae: 0.0745\n",
      "Epoch 13/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 0.0035 - mae: 0.0434 - val_loss: 0.0170 - val_mae: 0.0777\n",
      "Epoch 14/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 0.0035 - mae: 0.0436 - val_loss: 0.0164 - val_mae: 0.0759\n",
      "Epoch 15/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 0.0036 - mae: 0.0437 - val_loss: 0.0171 - val_mae: 0.0781\n",
      "Epoch 16/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 0.0035 - mae: 0.0430 - val_loss: 0.0156 - val_mae: 0.0739\n",
      "Epoch 17/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 0.0035 - mae: 0.0437 - val_loss: 0.0166 - val_mae: 0.0764\n",
      "Epoch 18/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 0.0035 - mae: 0.0432 - val_loss: 0.0174 - val_mae: 0.0790\n",
      "Epoch 19/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 0.0036 - mae: 0.0437 - val_loss: 0.0175 - val_mae: 0.0793\n",
      "Epoch 20/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - loss: 0.0035 - mae: 0.0431 - val_loss: 0.0168 - val_mae: 0.0772\n",
      "Epoch 21/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - loss: 0.0035 - mae: 0.0432 - val_loss: 0.0159 - val_mae: 0.0747\n",
      "Epoch 22/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 0.0035 - mae: 0.0435 - val_loss: 0.0173 - val_mae: 0.0788\n",
      "Epoch 23/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 0.0035 - mae: 0.0434 - val_loss: 0.0167 - val_mae: 0.0769\n",
      "Epoch 24/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - loss: 0.0035 - mae: 0.0436 - val_loss: 0.0163 - val_mae: 0.0755\n",
      "Epoch 25/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 0.0034 - mae: 0.0429 - val_loss: 0.0169 - val_mae: 0.0775\n",
      "Epoch 26/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 0.0035 - mae: 0.0432 - val_loss: 0.0164 - val_mae: 0.0760\n",
      "Epoch 27/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 0.0034 - mae: 0.0433 - val_loss: 0.0162 - val_mae: 0.0755\n",
      "Epoch 28/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - loss: 0.0035 - mae: 0.0437 - val_loss: 0.0167 - val_mae: 0.0770\n",
      "Epoch 29/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 0.0034 - mae: 0.0430 - val_loss: 0.0157 - val_mae: 0.0742\n",
      "Epoch 30/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 0.0035 - mae: 0.0435 - val_loss: 0.0166 - val_mae: 0.0765\n",
      "Epoch 31/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 0.0034 - mae: 0.0430 - val_loss: 0.0162 - val_mae: 0.0753\n",
      "Epoch 32/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 0.0034 - mae: 0.0432 - val_loss: 0.0169 - val_mae: 0.0774\n",
      "Epoch 33/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 0.0035 - mae: 0.0434 - val_loss: 0.0167 - val_mae: 0.0767\n",
      "Epoch 34/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 0.0035 - mae: 0.0433 - val_loss: 0.0167 - val_mae: 0.0767\n",
      "Epoch 35/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 0.0035 - mae: 0.0433 - val_loss: 0.0169 - val_mae: 0.0774\n",
      "Epoch 36/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 0.0035 - mae: 0.0434 - val_loss: 0.0176 - val_mae: 0.0797\n",
      "Epoch 37/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 0.0036 - mae: 0.0439 - val_loss: 0.0160 - val_mae: 0.0748\n",
      "Epoch 38/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - loss: 0.0035 - mae: 0.0433 - val_loss: 0.0163 - val_mae: 0.0755\n",
      "Epoch 39/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 0.0035 - mae: 0.0436 - val_loss: 0.0169 - val_mae: 0.0776\n",
      "Epoch 40/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 0.0036 - mae: 0.0436 - val_loss: 0.0161 - val_mae: 0.0750\n",
      "Epoch 41/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 0.0035 - mae: 0.0431 - val_loss: 0.0168 - val_mae: 0.0770\n",
      "Epoch 42/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - loss: 0.0035 - mae: 0.0433 - val_loss: 0.0163 - val_mae: 0.0755\n",
      "Epoch 43/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 0.0035 - mae: 0.0437 - val_loss: 0.0169 - val_mae: 0.0776\n",
      "Epoch 44/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 0.0035 - mae: 0.0430 - val_loss: 0.0171 - val_mae: 0.0782\n",
      "Epoch 45/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 0.0035 - mae: 0.0431 - val_loss: 0.0167 - val_mae: 0.0768\n",
      "Epoch 46/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 0.0034 - mae: 0.0430 - val_loss: 0.0156 - val_mae: 0.0740\n",
      "Epoch 47/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 0.0035 - mae: 0.0436 - val_loss: 0.0166 - val_mae: 0.0764\n",
      "Epoch 48/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - loss: 0.0035 - mae: 0.0432 - val_loss: 0.0171 - val_mae: 0.0780\n",
      "Epoch 49/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 0.0034 - mae: 0.0428 - val_loss: 0.0160 - val_mae: 0.0750\n",
      "Epoch 50/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 0.0035 - mae: 0.0434 - val_loss: 0.0163 - val_mae: 0.0757\n",
      "Epoch 51/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 0.0035 - mae: 0.0432 - val_loss: 0.0169 - val_mae: 0.0773\n",
      "Epoch 52/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 0.0034 - mae: 0.0432 - val_loss: 0.0169 - val_mae: 0.0773\n",
      "Epoch 53/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 0.0035 - mae: 0.0431 - val_loss: 0.0163 - val_mae: 0.0756\n",
      "Epoch 54/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 0.0035 - mae: 0.0435 - val_loss: 0.0161 - val_mae: 0.0751\n",
      "Epoch 55/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 0.0034 - mae: 0.0428 - val_loss: 0.0160 - val_mae: 0.0749\n",
      "Epoch 56/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 0.0036 - mae: 0.0434 - val_loss: 0.0170 - val_mae: 0.0778\n",
      "Epoch 57/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 0.0035 - mae: 0.0432 - val_loss: 0.0165 - val_mae: 0.0761\n",
      "Epoch 58/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 0.0035 - mae: 0.0431 - val_loss: 0.0159 - val_mae: 0.0748\n",
      "Epoch 59/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 0.0035 - mae: 0.0437 - val_loss: 0.0167 - val_mae: 0.0768\n",
      "Epoch 60/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 0.0035 - mae: 0.0435 - val_loss: 0.0161 - val_mae: 0.0752\n",
      "Epoch 61/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - loss: 0.0035 - mae: 0.0434 - val_loss: 0.0164 - val_mae: 0.0760\n",
      "Epoch 62/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 0.0035 - mae: 0.0431 - val_loss: 0.0167 - val_mae: 0.0767\n",
      "Epoch 63/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 0.0035 - mae: 0.0432 - val_loss: 0.0165 - val_mae: 0.0763\n",
      "Epoch 64/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 0.0035 - mae: 0.0431 - val_loss: 0.0162 - val_mae: 0.0753\n",
      "Epoch 65/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 0.0034 - mae: 0.0432 - val_loss: 0.0165 - val_mae: 0.0762\n",
      "Epoch 66/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 0.0034 - mae: 0.0432 - val_loss: 0.0167 - val_mae: 0.0767\n",
      "Epoch 67/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 0.0035 - mae: 0.0431 - val_loss: 0.0167 - val_mae: 0.0769\n",
      "Epoch 68/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - loss: 0.0034 - mae: 0.0429 - val_loss: 0.0168 - val_mae: 0.0772\n",
      "Epoch 69/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 0.0034 - mae: 0.0427 - val_loss: 0.0167 - val_mae: 0.0768\n",
      "Epoch 70/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 0.0035 - mae: 0.0436 - val_loss: 0.0166 - val_mae: 0.0766\n",
      "Epoch 71/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 0.0034 - mae: 0.0431 - val_loss: 0.0167 - val_mae: 0.0767\n",
      "Epoch 72/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 0.0035 - mae: 0.0432 - val_loss: 0.0167 - val_mae: 0.0769\n",
      "Epoch 73/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 0.0034 - mae: 0.0431 - val_loss: 0.0163 - val_mae: 0.0757\n",
      "Epoch 74/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - loss: 0.0035 - mae: 0.0435 - val_loss: 0.0168 - val_mae: 0.0772\n",
      "Epoch 75/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 0.0036 - mae: 0.0436 - val_loss: 0.0171 - val_mae: 0.0781\n",
      "Epoch 76/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 0.0035 - mae: 0.0434 - val_loss: 0.0166 - val_mae: 0.0766\n",
      "Epoch 77/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 0.0035 - mae: 0.0434 - val_loss: 0.0166 - val_mae: 0.0765\n",
      "Epoch 78/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 0.0034 - mae: 0.0431 - val_loss: 0.0164 - val_mae: 0.0758\n",
      "Epoch 79/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 0.0034 - mae: 0.0431 - val_loss: 0.0163 - val_mae: 0.0756\n",
      "Epoch 80/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 0.0034 - mae: 0.0434 - val_loss: 0.0167 - val_mae: 0.0767\n",
      "Epoch 81/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 0.0034 - mae: 0.0427 - val_loss: 0.0164 - val_mae: 0.0758\n",
      "Epoch 82/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 0.0035 - mae: 0.0430 - val_loss: 0.0163 - val_mae: 0.0757\n",
      "Epoch 83/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 0.0036 - mae: 0.0437 - val_loss: 0.0164 - val_mae: 0.0758\n",
      "Epoch 84/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - loss: 0.0036 - mae: 0.0437 - val_loss: 0.0174 - val_mae: 0.0789\n",
      "Epoch 85/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 0.0035 - mae: 0.0432 - val_loss: 0.0163 - val_mae: 0.0758\n",
      "Epoch 86/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 0.0035 - mae: 0.0434 - val_loss: 0.0166 - val_mae: 0.0766\n",
      "Epoch 87/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - loss: 0.0035 - mae: 0.0436 - val_loss: 0.0165 - val_mae: 0.0761\n",
      "Epoch 88/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 0.0035 - mae: 0.0433 - val_loss: 0.0164 - val_mae: 0.0759\n",
      "Epoch 89/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 0.0035 - mae: 0.0435 - val_loss: 0.0168 - val_mae: 0.0772\n",
      "Epoch 90/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - loss: 0.0036 - mae: 0.0437 - val_loss: 0.0165 - val_mae: 0.0762\n",
      "Epoch 91/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 0.0035 - mae: 0.0435 - val_loss: 0.0160 - val_mae: 0.0748\n",
      "Epoch 92/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 0.0035 - mae: 0.0432 - val_loss: 0.0166 - val_mae: 0.0765\n",
      "Epoch 93/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 0.0035 - mae: 0.0432 - val_loss: 0.0164 - val_mae: 0.0760\n",
      "Epoch 94/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 0.0036 - mae: 0.0435 - val_loss: 0.0159 - val_mae: 0.0746\n",
      "Epoch 95/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 0.0036 - mae: 0.0436 - val_loss: 0.0165 - val_mae: 0.0762\n",
      "Epoch 96/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 0.0035 - mae: 0.0436 - val_loss: 0.0166 - val_mae: 0.0766\n",
      "Epoch 97/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 0.0035 - mae: 0.0437 - val_loss: 0.0168 - val_mae: 0.0771\n",
      "Epoch 98/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 0.0035 - mae: 0.0435 - val_loss: 0.0164 - val_mae: 0.0758\n",
      "Epoch 99/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 0.0035 - mae: 0.0431 - val_loss: 0.0163 - val_mae: 0.0757\n",
      "Epoch 100/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - loss: 0.0034 - mae: 0.0431 - val_loss: 0.0167 - val_mae: 0.0767\n",
      "\u001b[1m1308/1308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step\n",
      "✅ Done with tomato_Kolar_daily.csv | MAE=566.03, RMSE=890.97, R2=-0.0298, MAPE=63.47%, Accuracy=36.53%\n",
      "\n",
      "🚀 Processing: tomato_MadikeriKodagu_daily.csv\n",
      "Epoch 1/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.1415 - mae: 0.2819 - val_loss: 0.0795 - val_mae: 0.2680\n",
      "Epoch 2/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0651 - mae: 0.2021 - val_loss: 0.0517 - val_mae: 0.2100\n",
      "Epoch 3/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0659 - mae: 0.2094 - val_loss: 0.0525 - val_mae: 0.2117\n",
      "Epoch 4/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0675 - mae: 0.2124 - val_loss: 0.0474 - val_mae: 0.1994\n",
      "Epoch 5/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0674 - mae: 0.2133 - val_loss: 0.0490 - val_mae: 0.2033\n",
      "Epoch 6/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0680 - mae: 0.2138 - val_loss: 0.0509 - val_mae: 0.2080\n",
      "Epoch 7/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0673 - mae: 0.2120 - val_loss: 0.0576 - val_mae: 0.2236\n",
      "Epoch 8/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0665 - mae: 0.2100 - val_loss: 0.0487 - val_mae: 0.2026\n",
      "Epoch 9/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0676 - mae: 0.2130 - val_loss: 0.0502 - val_mae: 0.2062\n",
      "Epoch 10/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0667 - mae: 0.2113 - val_loss: 0.0498 - val_mae: 0.2053\n",
      "Epoch 11/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0650 - mae: 0.2088 - val_loss: 0.0543 - val_mae: 0.2160\n",
      "Epoch 12/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0669 - mae: 0.2106 - val_loss: 0.0528 - val_mae: 0.2126\n",
      "Epoch 13/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0681 - mae: 0.2128 - val_loss: 0.0539 - val_mae: 0.2150\n",
      "Epoch 14/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0654 - mae: 0.2075 - val_loss: 0.0478 - val_mae: 0.2004\n",
      "Epoch 15/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0665 - mae: 0.2118 - val_loss: 0.0459 - val_mae: 0.1955\n",
      "Epoch 16/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0657 - mae: 0.2112 - val_loss: 0.0504 - val_mae: 0.2069\n",
      "Epoch 17/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0675 - mae: 0.2120 - val_loss: 0.0522 - val_mae: 0.2112\n",
      "Epoch 18/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0660 - mae: 0.2108 - val_loss: 0.0514 - val_mae: 0.2092\n",
      "Epoch 19/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0634 - mae: 0.2051 - val_loss: 0.0441 - val_mae: 0.1911\n",
      "Epoch 20/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0665 - mae: 0.2118 - val_loss: 0.0555 - val_mae: 0.2188\n",
      "Epoch 21/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0698 - mae: 0.2164 - val_loss: 0.0576 - val_mae: 0.2235\n",
      "Epoch 22/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0684 - mae: 0.2129 - val_loss: 0.0521 - val_mae: 0.2108\n",
      "Epoch 23/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0654 - mae: 0.2083 - val_loss: 0.0546 - val_mae: 0.2168\n",
      "Epoch 24/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0661 - mae: 0.2099 - val_loss: 0.0526 - val_mae: 0.2120\n",
      "Epoch 25/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0654 - mae: 0.2075 - val_loss: 0.0545 - val_mae: 0.2164\n",
      "Epoch 26/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0667 - mae: 0.2107 - val_loss: 0.0518 - val_mae: 0.2101\n",
      "Epoch 27/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0665 - mae: 0.2107 - val_loss: 0.0513 - val_mae: 0.2089\n",
      "Epoch 28/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0673 - mae: 0.2119 - val_loss: 0.0516 - val_mae: 0.2096\n",
      "Epoch 29/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0686 - mae: 0.2140 - val_loss: 0.0564 - val_mae: 0.2208\n",
      "Epoch 30/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0685 - mae: 0.2141 - val_loss: 0.0537 - val_mae: 0.2146\n",
      "Epoch 31/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0659 - mae: 0.2095 - val_loss: 0.0491 - val_mae: 0.2037\n",
      "Epoch 32/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0675 - mae: 0.2126 - val_loss: 0.0508 - val_mae: 0.2076\n",
      "Epoch 33/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0680 - mae: 0.2152 - val_loss: 0.0543 - val_mae: 0.2159\n",
      "Epoch 34/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0696 - mae: 0.2139 - val_loss: 0.0528 - val_mae: 0.2125\n",
      "Epoch 35/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0657 - mae: 0.2086 - val_loss: 0.0453 - val_mae: 0.1941\n",
      "Epoch 36/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0678 - mae: 0.2145 - val_loss: 0.0578 - val_mae: 0.2239\n",
      "Epoch 37/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0646 - mae: 0.2063 - val_loss: 0.0492 - val_mae: 0.2039\n",
      "Epoch 38/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0663 - mae: 0.2112 - val_loss: 0.0523 - val_mae: 0.2113\n",
      "Epoch 39/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0678 - mae: 0.2123 - val_loss: 0.0551 - val_mae: 0.2179\n",
      "Epoch 40/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0661 - mae: 0.2086 - val_loss: 0.0496 - val_mae: 0.2048\n",
      "Epoch 41/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0678 - mae: 0.2127 - val_loss: 0.0496 - val_mae: 0.2049\n",
      "Epoch 42/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0665 - mae: 0.2110 - val_loss: 0.0488 - val_mae: 0.2029\n",
      "Epoch 43/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0663 - mae: 0.2109 - val_loss: 0.0543 - val_mae: 0.2161\n",
      "Epoch 44/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0671 - mae: 0.2111 - val_loss: 0.0532 - val_mae: 0.2136\n",
      "Epoch 45/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0683 - mae: 0.2131 - val_loss: 0.0531 - val_mae: 0.2133\n",
      "Epoch 46/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0694 - mae: 0.2172 - val_loss: 0.0532 - val_mae: 0.2134\n",
      "Epoch 47/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0675 - mae: 0.2121 - val_loss: 0.0513 - val_mae: 0.2090\n",
      "Epoch 48/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0683 - mae: 0.2141 - val_loss: 0.0548 - val_mae: 0.2171\n",
      "Epoch 49/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0659 - mae: 0.2100 - val_loss: 0.0522 - val_mae: 0.2112\n",
      "Epoch 50/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0664 - mae: 0.2106 - val_loss: 0.0537 - val_mae: 0.2147\n",
      "Epoch 51/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0672 - mae: 0.2116 - val_loss: 0.0471 - val_mae: 0.1987\n",
      "Epoch 52/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0665 - mae: 0.2116 - val_loss: 0.0496 - val_mae: 0.2047\n",
      "Epoch 53/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0664 - mae: 0.2107 - val_loss: 0.0507 - val_mae: 0.2074\n",
      "Epoch 54/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0692 - mae: 0.2162 - val_loss: 0.0522 - val_mae: 0.2111\n",
      "Epoch 55/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0678 - mae: 0.2120 - val_loss: 0.0508 - val_mae: 0.2077\n",
      "Epoch 56/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0667 - mae: 0.2109 - val_loss: 0.0489 - val_mae: 0.2032\n",
      "Epoch 57/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0657 - mae: 0.2092 - val_loss: 0.0521 - val_mae: 0.2108\n",
      "Epoch 58/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0670 - mae: 0.2108 - val_loss: 0.0547 - val_mae: 0.2170\n",
      "Epoch 59/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0654 - mae: 0.2075 - val_loss: 0.0533 - val_mae: 0.2137\n",
      "Epoch 60/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0641 - mae: 0.2052 - val_loss: 0.0489 - val_mae: 0.2032\n",
      "Epoch 61/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0652 - mae: 0.2079 - val_loss: 0.0519 - val_mae: 0.2103\n",
      "Epoch 62/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0662 - mae: 0.2105 - val_loss: 0.0516 - val_mae: 0.2096\n",
      "Epoch 63/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0672 - mae: 0.2117 - val_loss: 0.0523 - val_mae: 0.2114\n",
      "Epoch 64/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0675 - mae: 0.2126 - val_loss: 0.0536 - val_mae: 0.2143\n",
      "Epoch 65/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0687 - mae: 0.2133 - val_loss: 0.0477 - val_mae: 0.2001\n",
      "Epoch 66/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0657 - mae: 0.2088 - val_loss: 0.0512 - val_mae: 0.2087\n",
      "Epoch 67/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0681 - mae: 0.2127 - val_loss: 0.0535 - val_mae: 0.2141\n",
      "Epoch 68/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0649 - mae: 0.2072 - val_loss: 0.0532 - val_mae: 0.2134\n",
      "Epoch 69/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0647 - mae: 0.2059 - val_loss: 0.0496 - val_mae: 0.2049\n",
      "Epoch 70/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0698 - mae: 0.2158 - val_loss: 0.0532 - val_mae: 0.2135\n",
      "Epoch 71/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0672 - mae: 0.2107 - val_loss: 0.0465 - val_mae: 0.1971\n",
      "Epoch 72/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0654 - mae: 0.2089 - val_loss: 0.0508 - val_mae: 0.2077\n",
      "Epoch 73/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0658 - mae: 0.2092 - val_loss: 0.0488 - val_mae: 0.2030\n",
      "Epoch 74/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0653 - mae: 0.2082 - val_loss: 0.0519 - val_mae: 0.2104\n",
      "Epoch 75/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0632 - mae: 0.2046 - val_loss: 0.0442 - val_mae: 0.1913\n",
      "Epoch 76/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0680 - mae: 0.2156 - val_loss: 0.0544 - val_mae: 0.2161\n",
      "Epoch 77/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0662 - mae: 0.2088 - val_loss: 0.0500 - val_mae: 0.2059\n",
      "Epoch 78/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0659 - mae: 0.2098 - val_loss: 0.0459 - val_mae: 0.1956\n",
      "Epoch 79/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0677 - mae: 0.2134 - val_loss: 0.0500 - val_mae: 0.2059\n",
      "Epoch 80/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0668 - mae: 0.2107 - val_loss: 0.0536 - val_mae: 0.2143\n",
      "Epoch 81/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0646 - mae: 0.2061 - val_loss: 0.0480 - val_mae: 0.2009\n",
      "Epoch 82/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0665 - mae: 0.2118 - val_loss: 0.0494 - val_mae: 0.2044\n",
      "Epoch 83/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0664 - mae: 0.2105 - val_loss: 0.0466 - val_mae: 0.1974\n",
      "Epoch 84/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0627 - mae: 0.2044 - val_loss: 0.0528 - val_mae: 0.2124\n",
      "Epoch 85/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0645 - mae: 0.2064 - val_loss: 0.0472 - val_mae: 0.1989\n",
      "Epoch 86/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0675 - mae: 0.2142 - val_loss: 0.0537 - val_mae: 0.2147\n",
      "Epoch 87/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0651 - mae: 0.2076 - val_loss: 0.0488 - val_mae: 0.2028\n",
      "Epoch 88/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0658 - mae: 0.2094 - val_loss: 0.0537 - val_mae: 0.2147\n",
      "Epoch 89/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0685 - mae: 0.2127 - val_loss: 0.0463 - val_mae: 0.1965\n",
      "Epoch 90/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0653 - mae: 0.2094 - val_loss: 0.0483 - val_mae: 0.2016\n",
      "Epoch 91/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0678 - mae: 0.2138 - val_loss: 0.0526 - val_mae: 0.2120\n",
      "Epoch 92/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0670 - mae: 0.2103 - val_loss: 0.0553 - val_mae: 0.2182\n",
      "Epoch 93/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0673 - mae: 0.2122 - val_loss: 0.0508 - val_mae: 0.2078\n",
      "Epoch 94/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0663 - mae: 0.2093 - val_loss: 0.0541 - val_mae: 0.2156\n",
      "Epoch 95/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0670 - mae: 0.2128 - val_loss: 0.0537 - val_mae: 0.2147\n",
      "Epoch 96/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0675 - mae: 0.2128 - val_loss: 0.0505 - val_mae: 0.2069\n",
      "Epoch 97/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0667 - mae: 0.2117 - val_loss: 0.0500 - val_mae: 0.2059\n",
      "Epoch 98/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0679 - mae: 0.2111 - val_loss: 0.0507 - val_mae: 0.2076\n",
      "Epoch 99/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0641 - mae: 0.2063 - val_loss: 0.0491 - val_mae: 0.2036\n",
      "Epoch 100/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0673 - mae: 0.2120 - val_loss: 0.0520 - val_mae: 0.2106\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "✅ Done with tomato_MadikeriKodagu_daily.csv | MAE=357.13, RMSE=428.29, R2=-0.0316, MAPE=42.4%, Accuracy=57.6%\n",
      "\n",
      "🚀 Processing: tomato_Mandya_daily.csv\n",
      "Epoch 1/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0020 - mae: 0.0289 - val_loss: 0.0211 - val_mae: 0.0837\n",
      "Epoch 2/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0020 - mae: 0.0286 - val_loss: 0.0215 - val_mae: 0.0851\n",
      "Epoch 3/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0019 - mae: 0.0282 - val_loss: 0.0207 - val_mae: 0.0824\n",
      "Epoch 4/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0020 - mae: 0.0294 - val_loss: 0.0223 - val_mae: 0.0881\n",
      "Epoch 5/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0020 - mae: 0.0284 - val_loss: 0.0213 - val_mae: 0.0844\n",
      "Epoch 6/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0020 - mae: 0.0288 - val_loss: 0.0207 - val_mae: 0.0822\n",
      "Epoch 7/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0020 - mae: 0.0290 - val_loss: 0.0211 - val_mae: 0.0837\n",
      "Epoch 8/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0019 - mae: 0.0286 - val_loss: 0.0205 - val_mae: 0.0815\n",
      "Epoch 9/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0019 - mae: 0.0288 - val_loss: 0.0208 - val_mae: 0.0826\n",
      "Epoch 10/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0019 - mae: 0.0286 - val_loss: 0.0214 - val_mae: 0.0849\n",
      "Epoch 11/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0020 - mae: 0.0291 - val_loss: 0.0209 - val_mae: 0.0831\n",
      "Epoch 12/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0021 - mae: 0.0290 - val_loss: 0.0206 - val_mae: 0.0820\n",
      "Epoch 13/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0020 - mae: 0.0291 - val_loss: 0.0209 - val_mae: 0.0830\n",
      "Epoch 14/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0020 - mae: 0.0295 - val_loss: 0.0209 - val_mae: 0.0831\n",
      "Epoch 15/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0021 - mae: 0.0291 - val_loss: 0.0211 - val_mae: 0.0837\n",
      "Epoch 16/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0021 - mae: 0.0287 - val_loss: 0.0220 - val_mae: 0.0870\n",
      "Epoch 17/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0021 - mae: 0.0294 - val_loss: 0.0217 - val_mae: 0.0860\n",
      "Epoch 18/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0019 - mae: 0.0284 - val_loss: 0.0212 - val_mae: 0.0839\n",
      "Epoch 19/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0019 - mae: 0.0286 - val_loss: 0.0212 - val_mae: 0.0839\n",
      "Epoch 20/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0020 - mae: 0.0288 - val_loss: 0.0211 - val_mae: 0.0837\n",
      "Epoch 21/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0021 - mae: 0.0293 - val_loss: 0.0217 - val_mae: 0.0860\n",
      "Epoch 22/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0019 - mae: 0.0290 - val_loss: 0.0208 - val_mae: 0.0825\n",
      "Epoch 23/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0020 - mae: 0.0287 - val_loss: 0.0204 - val_mae: 0.0811\n",
      "Epoch 24/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0019 - mae: 0.0287 - val_loss: 0.0207 - val_mae: 0.0822\n",
      "Epoch 25/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0020 - mae: 0.0288 - val_loss: 0.0214 - val_mae: 0.0848\n",
      "Epoch 26/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0019 - mae: 0.0291 - val_loss: 0.0212 - val_mae: 0.0842\n",
      "Epoch 27/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0020 - mae: 0.0288 - val_loss: 0.0203 - val_mae: 0.0808\n",
      "Epoch 28/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0019 - mae: 0.0289 - val_loss: 0.0210 - val_mae: 0.0832\n",
      "Epoch 29/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0020 - mae: 0.0285 - val_loss: 0.0212 - val_mae: 0.0839\n",
      "Epoch 30/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0019 - mae: 0.0287 - val_loss: 0.0213 - val_mae: 0.0844\n",
      "Epoch 31/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0019 - mae: 0.0286 - val_loss: 0.0208 - val_mae: 0.0828\n",
      "Epoch 32/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0019 - mae: 0.0286 - val_loss: 0.0215 - val_mae: 0.0852\n",
      "Epoch 33/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0021 - mae: 0.0286 - val_loss: 0.0210 - val_mae: 0.0834\n",
      "Epoch 34/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0019 - mae: 0.0290 - val_loss: 0.0209 - val_mae: 0.0828\n",
      "Epoch 35/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0020 - mae: 0.0291 - val_loss: 0.0208 - val_mae: 0.0825\n",
      "Epoch 36/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0021 - mae: 0.0295 - val_loss: 0.0212 - val_mae: 0.0842\n",
      "Epoch 37/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0021 - mae: 0.0289 - val_loss: 0.0214 - val_mae: 0.0847\n",
      "Epoch 38/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0020 - mae: 0.0288 - val_loss: 0.0209 - val_mae: 0.0830\n",
      "Epoch 39/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - loss: 0.0019 - mae: 0.0287 - val_loss: 0.0203 - val_mae: 0.0809\n",
      "Epoch 40/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0021 - mae: 0.0296 - val_loss: 0.0214 - val_mae: 0.0849\n",
      "Epoch 41/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0018 - mae: 0.0281 - val_loss: 0.0210 - val_mae: 0.0832\n",
      "Epoch 42/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0019 - mae: 0.0281 - val_loss: 0.0209 - val_mae: 0.0832\n",
      "Epoch 43/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0020 - mae: 0.0286 - val_loss: 0.0213 - val_mae: 0.0845\n",
      "Epoch 44/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0019 - mae: 0.0286 - val_loss: 0.0212 - val_mae: 0.0840\n",
      "Epoch 45/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0020 - mae: 0.0289 - val_loss: 0.0216 - val_mae: 0.0854\n",
      "Epoch 46/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0020 - mae: 0.0289 - val_loss: 0.0207 - val_mae: 0.0824\n",
      "Epoch 47/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0019 - mae: 0.0286 - val_loss: 0.0216 - val_mae: 0.0856\n",
      "Epoch 48/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0019 - mae: 0.0289 - val_loss: 0.0211 - val_mae: 0.0836\n",
      "Epoch 49/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0019 - mae: 0.0286 - val_loss: 0.0210 - val_mae: 0.0833\n",
      "Epoch 50/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0018 - mae: 0.0283 - val_loss: 0.0218 - val_mae: 0.0861\n",
      "Epoch 51/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0019 - mae: 0.0287 - val_loss: 0.0212 - val_mae: 0.0840\n",
      "Epoch 52/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0020 - mae: 0.0285 - val_loss: 0.0213 - val_mae: 0.0844\n",
      "Epoch 53/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0019 - mae: 0.0286 - val_loss: 0.0215 - val_mae: 0.0853\n",
      "Epoch 54/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.0022 - mae: 0.0294 - val_loss: 0.0210 - val_mae: 0.0835\n",
      "Epoch 55/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0020 - mae: 0.0293 - val_loss: 0.0210 - val_mae: 0.0832\n",
      "Epoch 56/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0020 - mae: 0.0293 - val_loss: 0.0209 - val_mae: 0.0829\n",
      "Epoch 57/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0020 - mae: 0.0292 - val_loss: 0.0214 - val_mae: 0.0848\n",
      "Epoch 58/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0022 - mae: 0.0296 - val_loss: 0.0208 - val_mae: 0.0826\n",
      "Epoch 59/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0020 - mae: 0.0290 - val_loss: 0.0210 - val_mae: 0.0833\n",
      "Epoch 60/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0020 - mae: 0.0291 - val_loss: 0.0210 - val_mae: 0.0835\n",
      "Epoch 61/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0019 - mae: 0.0285 - val_loss: 0.0210 - val_mae: 0.0835\n",
      "Epoch 62/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0020 - mae: 0.0290 - val_loss: 0.0214 - val_mae: 0.0848\n",
      "Epoch 63/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0020 - mae: 0.0290 - val_loss: 0.0213 - val_mae: 0.0843\n",
      "Epoch 64/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0019 - mae: 0.0286 - val_loss: 0.0214 - val_mae: 0.0849\n",
      "Epoch 65/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0021 - mae: 0.0291 - val_loss: 0.0210 - val_mae: 0.0833\n",
      "Epoch 66/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0019 - mae: 0.0288 - val_loss: 0.0212 - val_mae: 0.0840\n",
      "Epoch 67/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0020 - mae: 0.0287 - val_loss: 0.0211 - val_mae: 0.0837\n",
      "Epoch 68/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0018 - mae: 0.0285 - val_loss: 0.0209 - val_mae: 0.0830\n",
      "Epoch 69/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0020 - mae: 0.0295 - val_loss: 0.0206 - val_mae: 0.0818\n",
      "Epoch 70/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0020 - mae: 0.0291 - val_loss: 0.0208 - val_mae: 0.0827\n",
      "Epoch 71/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0019 - mae: 0.0281 - val_loss: 0.0215 - val_mae: 0.0851\n",
      "Epoch 72/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0020 - mae: 0.0283 - val_loss: 0.0215 - val_mae: 0.0853\n",
      "Epoch 73/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0019 - mae: 0.0288 - val_loss: 0.0212 - val_mae: 0.0842\n",
      "Epoch 74/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0019 - mae: 0.0280 - val_loss: 0.0208 - val_mae: 0.0826\n",
      "Epoch 75/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0019 - mae: 0.0286 - val_loss: 0.0211 - val_mae: 0.0835\n",
      "Epoch 76/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0019 - mae: 0.0288 - val_loss: 0.0211 - val_mae: 0.0838\n",
      "Epoch 77/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0020 - mae: 0.0292 - val_loss: 0.0210 - val_mae: 0.0835\n",
      "Epoch 78/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0021 - mae: 0.0293 - val_loss: 0.0207 - val_mae: 0.0824\n",
      "Epoch 79/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0019 - mae: 0.0286 - val_loss: 0.0212 - val_mae: 0.0841\n",
      "Epoch 80/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0019 - mae: 0.0283 - val_loss: 0.0211 - val_mae: 0.0837\n",
      "Epoch 81/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0018 - mae: 0.0282 - val_loss: 0.0211 - val_mae: 0.0836\n",
      "Epoch 82/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0020 - mae: 0.0291 - val_loss: 0.0216 - val_mae: 0.0855\n",
      "Epoch 83/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0020 - mae: 0.0282 - val_loss: 0.0211 - val_mae: 0.0838\n",
      "Epoch 84/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0020 - mae: 0.0291 - val_loss: 0.0210 - val_mae: 0.0835\n",
      "Epoch 85/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0020 - mae: 0.0288 - val_loss: 0.0209 - val_mae: 0.0830\n",
      "Epoch 86/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0019 - mae: 0.0287 - val_loss: 0.0206 - val_mae: 0.0821\n",
      "Epoch 87/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0022 - mae: 0.0296 - val_loss: 0.0220 - val_mae: 0.0869\n",
      "Epoch 88/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0020 - mae: 0.0288 - val_loss: 0.0212 - val_mae: 0.0839\n",
      "Epoch 89/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0020 - mae: 0.0288 - val_loss: 0.0206 - val_mae: 0.0820\n",
      "Epoch 90/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0019 - mae: 0.0289 - val_loss: 0.0210 - val_mae: 0.0832\n",
      "Epoch 91/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0020 - mae: 0.0293 - val_loss: 0.0214 - val_mae: 0.0848\n",
      "Epoch 92/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0019 - mae: 0.0288 - val_loss: 0.0218 - val_mae: 0.0862\n",
      "Epoch 93/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0019 - mae: 0.0285 - val_loss: 0.0203 - val_mae: 0.0809\n",
      "Epoch 94/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0019 - mae: 0.0284 - val_loss: 0.0215 - val_mae: 0.0852\n",
      "Epoch 95/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0019 - mae: 0.0284 - val_loss: 0.0208 - val_mae: 0.0826\n",
      "Epoch 96/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0019 - mae: 0.0289 - val_loss: 0.0213 - val_mae: 0.0845\n",
      "Epoch 97/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0019 - mae: 0.0287 - val_loss: 0.0204 - val_mae: 0.0812\n",
      "Epoch 98/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0021 - mae: 0.0290 - val_loss: 0.0213 - val_mae: 0.0844\n",
      "Epoch 99/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0022 - mae: 0.0295 - val_loss: 0.0211 - val_mae: 0.0838\n",
      "Epoch 100/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - loss: 0.0020 - mae: 0.0283 - val_loss: 0.0209 - val_mae: 0.0832\n",
      "\u001b[1m545/545\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step\n",
      "✅ Done with tomato_Mandya_daily.csv | MAE=496.5, RMSE=945.97, R2=-0.0422, MAPE=73.78%, Accuracy=26.22%\n",
      "\n",
      "🚀 Processing: tomato_Mysore_daily.csv\n",
      "Epoch 1/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - loss: 0.0024 - mae: 0.0317 - val_loss: 0.0083 - val_mae: 0.0604\n",
      "Epoch 2/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0023 - mae: 0.0305 - val_loss: 0.0093 - val_mae: 0.0664\n",
      "Epoch 3/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0023 - mae: 0.0302 - val_loss: 0.0086 - val_mae: 0.0621\n",
      "Epoch 4/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0023 - mae: 0.0303 - val_loss: 0.0082 - val_mae: 0.0599\n",
      "Epoch 5/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - loss: 0.0022 - mae: 0.0303 - val_loss: 0.0092 - val_mae: 0.0662\n",
      "Epoch 6/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0024 - mae: 0.0305 - val_loss: 0.0085 - val_mae: 0.0616\n",
      "Epoch 7/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - loss: 0.0023 - mae: 0.0304 - val_loss: 0.0088 - val_mae: 0.0633\n",
      "Epoch 8/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0022 - mae: 0.0302 - val_loss: 0.0083 - val_mae: 0.0603\n",
      "Epoch 9/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - loss: 0.0024 - mae: 0.0306 - val_loss: 0.0083 - val_mae: 0.0600\n",
      "Epoch 10/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0022 - mae: 0.0300 - val_loss: 0.0084 - val_mae: 0.0606\n",
      "Epoch 11/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0022 - mae: 0.0300 - val_loss: 0.0082 - val_mae: 0.0598\n",
      "Epoch 12/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0022 - mae: 0.0301 - val_loss: 0.0085 - val_mae: 0.0611\n",
      "Epoch 13/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0023 - mae: 0.0302 - val_loss: 0.0086 - val_mae: 0.0619\n",
      "Epoch 14/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0022 - mae: 0.0302 - val_loss: 0.0088 - val_mae: 0.0637\n",
      "Epoch 15/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - loss: 0.0022 - mae: 0.0302 - val_loss: 0.0078 - val_mae: 0.0573\n",
      "Epoch 16/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - loss: 0.0022 - mae: 0.0303 - val_loss: 0.0086 - val_mae: 0.0621\n",
      "Epoch 17/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0022 - mae: 0.0299 - val_loss: 0.0089 - val_mae: 0.0643\n",
      "Epoch 18/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0023 - mae: 0.0307 - val_loss: 0.0086 - val_mae: 0.0623\n",
      "Epoch 19/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - loss: 0.0022 - mae: 0.0300 - val_loss: 0.0087 - val_mae: 0.0625\n",
      "Epoch 20/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0023 - mae: 0.0306 - val_loss: 0.0087 - val_mae: 0.0630\n",
      "Epoch 21/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0022 - mae: 0.0301 - val_loss: 0.0088 - val_mae: 0.0634\n",
      "Epoch 22/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0021 - mae: 0.0297 - val_loss: 0.0084 - val_mae: 0.0605\n",
      "Epoch 23/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - loss: 0.0022 - mae: 0.0303 - val_loss: 0.0080 - val_mae: 0.0588\n",
      "Epoch 24/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0024 - mae: 0.0308 - val_loss: 0.0081 - val_mae: 0.0590\n",
      "Epoch 25/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0022 - mae: 0.0301 - val_loss: 0.0087 - val_mae: 0.0625\n",
      "Epoch 26/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0022 - mae: 0.0302 - val_loss: 0.0089 - val_mae: 0.0642\n",
      "Epoch 27/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0023 - mae: 0.0305 - val_loss: 0.0084 - val_mae: 0.0605\n",
      "Epoch 28/100\n",
      "\u001b[1m 849/1367\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0023 - mae: 0.0305"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "import joblib  # For saving models as .pkl\n",
    "\n",
    "# -----------------------------\n",
    "# Output directories\n",
    "# -----------------------------\n",
    "input_folder = \"dataset\"\n",
    "output_models = \"tat_output_models\"\n",
    "output_csv = \"tat_output_csv\"\n",
    "output_graphs = \"tat_output_graphs\"\n",
    "output_logs = \"tat_output_logs\"\n",
    "metrics_file = \"tat_metrics.csv\"\n",
    "\n",
    "os.makedirs(output_models, exist_ok=True)\n",
    "os.makedirs(output_csv, exist_ok=True)\n",
    "os.makedirs(output_graphs, exist_ok=True)\n",
    "os.makedirs(output_logs, exist_ok=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Function to create dataset\n",
    "# -----------------------------\n",
    "def create_dataset(data, look_back=30):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - look_back):\n",
    "        X.append(data[i:i+look_back, 0])\n",
    "        y.append(data[i+look_back, 0])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# -----------------------------\n",
    "# Define Temporal Attention Transformer Model\n",
    "# -----------------------------\n",
    "def build_tat_model(input_shape, d_model=64, num_heads=4, ff_dim=128, dropout_rate=0.2):\n",
    "    inputs = layers.Input(shape=input_shape)  # (look_back, 1)\n",
    "    \n",
    "    # Multi-Head Attention\n",
    "    x = layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)(inputs, inputs)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x + inputs)  # Residual connection\n",
    "    \n",
    "    # Feed-Forward Network\n",
    "    ff = layers.Dense(ff_dim, activation='relu')(x)\n",
    "    ff = layers.Dense(input_shape[1])(ff)\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x + ff)  # Residual connection\n",
    "    \n",
    "    # Global Pooling\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    \n",
    "    # Output\n",
    "    outputs = layers.Dense(1)(x)\n",
    "    \n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=0.001),\n",
    "                  loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# -----------------------------\n",
    "# Function to robustly parse dates\n",
    "# -----------------------------\n",
    "def parse_dates_safe(date_series):\n",
    "    # First try strict ISO format (avoids warning)\n",
    "    try:\n",
    "        return pd.to_datetime(date_series, format=\"%Y-%m-%d\", errors='coerce')\n",
    "    except:\n",
    "        # Fallback flexible parsing\n",
    "        return pd.to_datetime(date_series, errors='coerce', dayfirst=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Metrics storage\n",
    "# -----------------------------\n",
    "metrics_list = []\n",
    "\n",
    "# -----------------------------\n",
    "# Process each CSV file\n",
    "# -----------------------------\n",
    "look_back = 30\n",
    "for file in os.listdir(input_folder):\n",
    "    if file.endswith(\".csv\"):\n",
    "        file_path = os.path.join(input_folder, file)\n",
    "        print(f\"🚀 Processing: {file}\")\n",
    "\n",
    "        # Load CSV\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Robust date parsing\n",
    "        df['Date'] = parse_dates_safe(df['Date'])\n",
    "        df = df.dropna(subset=['Date'])\n",
    "        df = df.sort_values('Date')\n",
    "\n",
    "        # Replace NaN in 'Average Price' with column mean (future-proof)\n",
    "        df['Average Price'] = df['Average Price'].fillna(df['Average Price'].mean())\n",
    "        df['Average Price'] = df['Average Price'].round(2)\n",
    "\n",
    "        # Add moving averages (future-proof fill)\n",
    "        df['MA_7'] = df['Average Price'].rolling(window=7).mean()\n",
    "        df['MA_30'] = df['Average Price'].rolling(window=30).mean()\n",
    "        df['MA_7'] = df['MA_7'].fillna(df['MA_7'].mean())\n",
    "        df['MA_30'] = df['MA_30'].fillna(df['MA_30'].mean())\n",
    "\n",
    "        # Prepare data using MinMaxScaler\n",
    "        values = df[['Average Price']].values.astype('float32')\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        scaled_values = scaler.fit_transform(values)\n",
    "\n",
    "        # Create sequences\n",
    "        X, y = create_dataset(scaled_values, look_back)\n",
    "        X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
    "\n",
    "        # Build model\n",
    "        model = build_tat_model(input_shape=(look_back,1))\n",
    "\n",
    "        # Train model\n",
    "        history = model.fit(X, y, epochs=100, batch_size=16, validation_split=0.2, verbose=1)\n",
    "\n",
    "        # Save training logs\n",
    "        log_file = os.path.join(output_logs, file.replace(\".csv\", \"_tat_training.txt\"))\n",
    "        with open(log_file, \"w\") as f:\n",
    "            f.write(\"Training Loss per Epoch:\\n\")\n",
    "            for i, loss in enumerate(history.history['loss']):\n",
    "                f.write(f\"Epoch {i+1}: Loss={loss}, Val_Loss={history.history['val_loss'][i]}\\n\")\n",
    "\n",
    "        # Predictions\n",
    "        predictions = model.predict(X)\n",
    "        predictions_rescaled = scaler.inverse_transform(predictions)\n",
    "        df['Predicted'] = [np.nan]*look_back + list(predictions_rescaled.flatten())\n",
    "        df['Predicted'] = df['Predicted'].round(2)\n",
    "\n",
    "        # Compute metrics safely\n",
    "        y_true = df['Average Price'].values[look_back:]\n",
    "        y_pred = predictions_rescaled.flatten()\n",
    "\n",
    "        # Avoid divide-by-zero in MAPE\n",
    "        non_zero_idx = y_true != 0\n",
    "        if np.any(non_zero_idx):\n",
    "            mape = round(np.mean(np.abs((y_true[non_zero_idx] - y_pred[non_zero_idx]) / y_true[non_zero_idx])) * 100, 2)\n",
    "            accuracy = round(100 - mape, 2)\n",
    "        else:\n",
    "            mape, accuracy = np.nan, np.nan\n",
    "\n",
    "        mae = round(mean_absolute_error(y_true, y_pred), 2)\n",
    "        rmse = round(np.sqrt(mean_squared_error(y_true, y_pred)), 2)\n",
    "        r2 = round(r2_score(y_true, y_pred), 4)\n",
    "\n",
    "        metrics_list.append([file.replace(\".csv\",\"\"), mae, rmse, r2, mape, accuracy])\n",
    "\n",
    "        # Save model as .pkl\n",
    "        model_file = os.path.join(output_models, file.replace(\".csv\", \"_tat_model.pkl\"))\n",
    "        joblib.dump(model, model_file)\n",
    "\n",
    "        # Save CSV with only Date, Actual, Predicted\n",
    "        save_df = df[['Average Price', 'Predicted']].copy()\n",
    "        save_df.rename(columns={'Average Price':'Actual'}, inplace=True)\n",
    "        save_df['Date'] = df['Date']\n",
    "        save_df = save_df[['Date', 'Actual', 'Predicted']]\n",
    "        updated_csv_path = os.path.join(output_csv, file.replace(\".csv\", \"_tat_updated.csv\"))\n",
    "        save_df.to_csv(updated_csv_path, index=False)\n",
    "\n",
    "        # Save graph\n",
    "        plt.figure(figsize=(12,6))\n",
    "        plt.plot(df['Date'], df['Average Price'], label='Actual', color='blue')\n",
    "        plt.plot(df['Date'], df['Predicted'], label='Predicted', color='red', linestyle='dashed')\n",
    "        plt.plot(df['Date'], df['MA_7'], label='MA 7', color='orange')\n",
    "        plt.plot(df['Date'], df['MA_30'], label='MA 30', color='green')\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Average Price')\n",
    "        plt.title(f'Price Prediction (TAT) - {file}')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        graph_file = os.path.join(output_graphs, file.replace(\".csv\", \"_tat_graph.png\"))\n",
    "        plt.savefig(graph_file, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "        print(f\"✅ Done with {file} | MAE={mae}, RMSE={rmse}, R2={r2}, MAPE={mape}%, Accuracy={accuracy}%\\n\")\n",
    "\n",
    "# Save all metrics\n",
    "metrics_df = pd.DataFrame(metrics_list, columns=['District', 'MAE', 'RMSE', 'R2', 'MAPE(%)', 'Accuracy(%)'])\n",
    "metrics_df.to_csv(metrics_file, index=False)\n",
    "print(f\"📊 Metrics saved to {metrics_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acc8bc5-6822-4d45-ad09-e055093f15ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TAT+MQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79b8cbab-b13d-4766-a3e4-3abff522e999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Processing: tomato_Bangalore_daily.csv\n",
      "WARNING:tensorflow:From C:\\Users\\ravik\\AppData\\Roaming\\Python\\Python313\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:232: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_query_attention         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">17,216</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiQueryAttention</span>)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_query_attention[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                               │                           │                 │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ layer_normalization[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dense_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│                               │                           │                 │ dense_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ global_average_pooling1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_query_attention         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │          \u001b[38;5;34m17,216\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "│ (\u001b[38;5;33mMultiQueryAttention\u001b[0m)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add (\u001b[38;5;33mAdd\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ multi_query_attention[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                               │                           │                 │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                  │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │           \u001b[38;5;34m8,320\u001b[0m │ layer_normalization[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │             \u001b[38;5;34m129\u001b[0m │ dense_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_1 (\u001b[38;5;33mAdd\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ layer_normalization[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│                               │                           │                 │ dense_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │              \u001b[38;5;34m65\u001b[0m │ global_average_pooling1d[\u001b[38;5;34m…\u001b[0m │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,986</span> (101.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25,986\u001b[0m (101.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,986</span> (101.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m25,986\u001b[0m (101.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - loss: 0.0184 - mae: 0.0600 - val_loss: 0.0025 - val_mae: 0.0318\n",
      "Epoch 2/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0019 - mae: 0.0266 - val_loss: 0.0022 - val_mae: 0.0314\n",
      "Epoch 3/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0016 - mae: 0.0224 - val_loss: 0.0023 - val_mae: 0.0298\n",
      "Epoch 4/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 12ms/step - loss: 0.0016 - mae: 0.0213 - val_loss: 0.0017 - val_mae: 0.0263\n",
      "Epoch 5/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0015 - mae: 0.0209 - val_loss: 0.0020 - val_mae: 0.0274\n",
      "Epoch 6/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0015 - mae: 0.0207 - val_loss: 0.0018 - val_mae: 0.0270\n",
      "Epoch 7/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0015 - mae: 0.0205 - val_loss: 0.0024 - val_mae: 0.0287\n",
      "Epoch 8/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0015 - mae: 0.0193 - val_loss: 0.0027 - val_mae: 0.0314\n",
      "Epoch 9/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0015 - mae: 0.0195 - val_loss: 0.0017 - val_mae: 0.0286\n",
      "Epoch 10/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0014 - mae: 0.0188 - val_loss: 0.0015 - val_mae: 0.0243\n",
      "Epoch 11/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0014 - mae: 0.0186 - val_loss: 0.0012 - val_mae: 0.0260\n",
      "Epoch 12/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0014 - mae: 0.0187 - val_loss: 0.0017 - val_mae: 0.0252\n",
      "Epoch 13/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0014 - mae: 0.0182 - val_loss: 0.0011 - val_mae: 0.0234\n",
      "Epoch 14/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0014 - mae: 0.0184 - val_loss: 0.0014 - val_mae: 0.0240\n",
      "Epoch 15/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0014 - mae: 0.0181 - val_loss: 0.0013 - val_mae: 0.0264\n",
      "Epoch 16/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0014 - mae: 0.0183 - val_loss: 0.0012 - val_mae: 0.0232\n",
      "Epoch 17/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0014 - mae: 0.0180 - val_loss: 0.0015 - val_mae: 0.0245\n",
      "Epoch 18/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0014 - mae: 0.0178 - val_loss: 0.0012 - val_mae: 0.0233\n",
      "Epoch 19/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0014 - mae: 0.0178 - val_loss: 0.0012 - val_mae: 0.0247\n",
      "Epoch 20/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0014 - mae: 0.0177 - val_loss: 0.0014 - val_mae: 0.0239\n",
      "Epoch 21/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0014 - mae: 0.0175 - val_loss: 0.0012 - val_mae: 0.0247\n",
      "Epoch 22/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0014 - mae: 0.0175 - val_loss: 0.0014 - val_mae: 0.0234\n",
      "Epoch 23/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0014 - mae: 0.0173 - val_loss: 0.0011 - val_mae: 0.0223\n",
      "Epoch 24/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0014 - mae: 0.0173 - val_loss: 0.0012 - val_mae: 0.0253\n",
      "Epoch 25/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0014 - mae: 0.0171 - val_loss: 0.0012 - val_mae: 0.0228\n",
      "Epoch 26/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0014 - mae: 0.0170 - val_loss: 0.0011 - val_mae: 0.0223\n",
      "Epoch 27/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0014 - mae: 0.0171 - val_loss: 0.0011 - val_mae: 0.0221\n",
      "Epoch 28/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0169 - val_loss: 0.0011 - val_mae: 0.0220\n",
      "Epoch 29/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0014 - mae: 0.0170 - val_loss: 0.0014 - val_mae: 0.0237\n",
      "Epoch 30/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0014 - mae: 0.0169 - val_loss: 0.0011 - val_mae: 0.0226\n",
      "Epoch 31/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0014 - mae: 0.0168 - val_loss: 0.0016 - val_mae: 0.0250\n",
      "Epoch 32/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0014 - mae: 0.0169 - val_loss: 0.0013 - val_mae: 0.0236\n",
      "Epoch 33/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0013 - mae: 0.0169 - val_loss: 0.0011 - val_mae: 0.0228\n",
      "Epoch 34/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0013 - mae: 0.0167 - val_loss: 0.0014 - val_mae: 0.0234\n",
      "Epoch 35/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0013 - mae: 0.0168 - val_loss: 0.0016 - val_mae: 0.0248\n",
      "Epoch 36/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0013 - mae: 0.0168 - val_loss: 0.0012 - val_mae: 0.0241\n",
      "Epoch 37/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 11ms/step - loss: 0.0014 - mae: 0.0169 - val_loss: 0.0011 - val_mae: 0.0219\n",
      "Epoch 38/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0013 - mae: 0.0167 - val_loss: 0.0011 - val_mae: 0.0225\n",
      "Epoch 39/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 12ms/step - loss: 0.0013 - mae: 0.0169 - val_loss: 0.0010 - val_mae: 0.0223\n",
      "Epoch 40/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 11ms/step - loss: 0.0014 - mae: 0.0168 - val_loss: 0.0013 - val_mae: 0.0230\n",
      "Epoch 41/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0168 - val_loss: 0.0011 - val_mae: 0.0227\n",
      "Epoch 42/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0013 - mae: 0.0168 - val_loss: 0.0013 - val_mae: 0.0234\n",
      "Epoch 43/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0013 - mae: 0.0168 - val_loss: 0.0012 - val_mae: 0.0228\n",
      "Epoch 44/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0168 - val_loss: 0.0010 - val_mae: 0.0219\n",
      "Epoch 45/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 12ms/step - loss: 0.0013 - mae: 0.0167 - val_loss: 0.0011 - val_mae: 0.0219\n",
      "Epoch 46/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0167 - val_loss: 0.0012 - val_mae: 0.0226\n",
      "Epoch 47/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0167 - val_loss: 0.0013 - val_mae: 0.0232\n",
      "Epoch 48/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0167 - val_loss: 0.0012 - val_mae: 0.0228\n",
      "Epoch 49/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 12ms/step - loss: 0.0013 - mae: 0.0167 - val_loss: 0.0012 - val_mae: 0.0226\n",
      "Epoch 50/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0167 - val_loss: 0.0011 - val_mae: 0.0240\n",
      "Epoch 51/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 12ms/step - loss: 0.0013 - mae: 0.0167 - val_loss: 0.0010 - val_mae: 0.0223\n",
      "Epoch 52/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0167 - val_loss: 0.0010 - val_mae: 0.0219\n",
      "Epoch 53/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0166 - val_loss: 0.0010 - val_mae: 0.0219\n",
      "Epoch 54/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0013 - mae: 0.0166 - val_loss: 0.0010 - val_mae: 0.0220\n",
      "Epoch 55/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0167 - val_loss: 0.0012 - val_mae: 0.0248\n",
      "Epoch 56/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0165 - val_loss: 0.0011 - val_mae: 0.0223\n",
      "Epoch 57/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0167 - val_loss: 0.0010 - val_mae: 0.0218\n",
      "Epoch 58/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0168 - val_loss: 0.0013 - val_mae: 0.0238\n",
      "Epoch 59/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0166 - val_loss: 0.0011 - val_mae: 0.0226\n",
      "Epoch 60/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0167 - val_loss: 0.0010 - val_mae: 0.0221\n",
      "Epoch 61/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0166 - val_loss: 0.0012 - val_mae: 0.0230\n",
      "Epoch 62/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0167 - val_loss: 0.0011 - val_mae: 0.0223\n",
      "Epoch 63/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0166 - val_loss: 0.0010 - val_mae: 0.0222\n",
      "Epoch 64/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0167 - val_loss: 0.0013 - val_mae: 0.0238\n",
      "Epoch 65/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0166 - val_loss: 0.0016 - val_mae: 0.0264\n",
      "Epoch 66/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0165 - val_loss: 0.0011 - val_mae: 0.0233\n",
      "Epoch 67/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0167 - val_loss: 0.0011 - val_mae: 0.0220\n",
      "Epoch 68/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0165 - val_loss: 0.0011 - val_mae: 0.0227\n",
      "Epoch 69/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0166 - val_loss: 0.0012 - val_mae: 0.0239\n",
      "Epoch 70/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0168 - val_loss: 0.0011 - val_mae: 0.0234\n",
      "Epoch 71/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0166 - val_loss: 0.0010 - val_mae: 0.0223\n",
      "Epoch 72/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0013 - mae: 0.0166 - val_loss: 0.0013 - val_mae: 0.0232\n",
      "Epoch 73/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0164 - val_loss: 0.0013 - val_mae: 0.0250\n",
      "Epoch 74/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0166 - val_loss: 0.0012 - val_mae: 0.0231\n",
      "Epoch 75/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0166 - val_loss: 0.0013 - val_mae: 0.0235\n",
      "Epoch 76/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0165 - val_loss: 0.0011 - val_mae: 0.0223\n",
      "Epoch 77/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0166 - val_loss: 0.0013 - val_mae: 0.0243\n",
      "Epoch 78/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0165 - val_loss: 0.0011 - val_mae: 0.0226\n",
      "Epoch 79/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0165 - val_loss: 0.0013 - val_mae: 0.0246\n",
      "Epoch 80/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0165 - val_loss: 0.0013 - val_mae: 0.0245\n",
      "Epoch 81/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0165 - val_loss: 0.0012 - val_mae: 0.0224\n",
      "Epoch 82/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0166 - val_loss: 0.0012 - val_mae: 0.0244\n",
      "Epoch 83/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0165 - val_loss: 0.0013 - val_mae: 0.0270\n",
      "Epoch 84/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0166 - val_loss: 0.0014 - val_mae: 0.0252\n",
      "Epoch 85/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0165 - val_loss: 0.0012 - val_mae: 0.0226\n",
      "Epoch 86/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0166 - val_loss: 0.0015 - val_mae: 0.0246\n",
      "Epoch 87/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0165 - val_loss: 0.0011 - val_mae: 0.0234\n",
      "Epoch 88/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0165 - val_loss: 0.0012 - val_mae: 0.0232\n",
      "Epoch 89/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0165 - val_loss: 0.0014 - val_mae: 0.0266\n",
      "Epoch 90/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0165 - val_loss: 0.0014 - val_mae: 0.0253\n",
      "Epoch 91/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0164 - val_loss: 0.0012 - val_mae: 0.0249\n",
      "Epoch 92/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0165 - val_loss: 0.0012 - val_mae: 0.0255\n",
      "Epoch 93/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0166 - val_loss: 0.0016 - val_mae: 0.0276\n",
      "Epoch 94/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0013 - mae: 0.0165 - val_loss: 0.0014 - val_mae: 0.0266\n",
      "Epoch 95/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0164 - val_loss: 0.0011 - val_mae: 0.0239\n",
      "Epoch 96/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0166 - val_loss: 0.0011 - val_mae: 0.0229\n",
      "Epoch 97/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0013 - mae: 0.0166 - val_loss: 0.0016 - val_mae: 0.0273\n",
      "Epoch 98/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0013 - mae: 0.0165 - val_loss: 0.0013 - val_mae: 0.0245\n",
      "Epoch 99/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0164 - val_loss: 0.0014 - val_mae: 0.0270\n",
      "Epoch 100/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0165 - val_loss: 0.0014 - val_mae: 0.0277\n",
      "\u001b[1m864/864\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step\n",
      "✅ Done with tomato_Bangalore_daily.csv | MAE=700.57, RMSE=1033.19, R2=0.4906, MAPE=64.89%, Accuracy=35.11%\n",
      "Saved updated CSV with Date, Actual & Predicted: tat_mqa_output_csv\\tomato_Bangalore_daily_tat_mqa_updated.csv\n",
      "🚀 Processing: tomato_Belgaum_daily.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_query_attention_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">17,216</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiQueryAttention</span>)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_query_attention_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                               │                           │                 │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_2         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ layer_normalization_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dense_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                               │                           │                 │ dense_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_3         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_1    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ global_average_pooling1d_… │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_query_attention_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │          \u001b[38;5;34m17,216\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "│ (\u001b[38;5;33mMultiQueryAttention\u001b[0m)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_2 (\u001b[38;5;33mAdd\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ multi_query_attention_1[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                               │                           │                 │ input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_2         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │           \u001b[38;5;34m8,320\u001b[0m │ layer_normalization_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │             \u001b[38;5;34m129\u001b[0m │ dense_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_3 (\u001b[38;5;33mAdd\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                               │                           │                 │ dense_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_3         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ add_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_1    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │              \u001b[38;5;34m65\u001b[0m │ global_average_pooling1d_… │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,986</span> (101.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25,986\u001b[0m (101.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,986</span> (101.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m25,986\u001b[0m (101.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - loss: 0.0761 - mae: 0.1221 - val_loss: 0.0281 - val_mae: 0.1099\n",
      "Epoch 2/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0063 - mae: 0.0632 - val_loss: 0.0368 - val_mae: 0.1324\n",
      "Epoch 3/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0052 - mae: 0.0571 - val_loss: 0.0255 - val_mae: 0.1047\n",
      "Epoch 4/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0041 - mae: 0.0511 - val_loss: 0.0226 - val_mae: 0.1010\n",
      "Epoch 5/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0033 - mae: 0.0446 - val_loss: 0.0254 - val_mae: 0.1043\n",
      "Epoch 6/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0027 - mae: 0.0406 - val_loss: 0.0218 - val_mae: 0.0987\n",
      "Epoch 7/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0022 - mae: 0.0363 - val_loss: 0.0231 - val_mae: 0.1007\n",
      "Epoch 8/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0324 - val_loss: 0.0297 - val_mae: 0.1145\n",
      "Epoch 9/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0016 - mae: 0.0300 - val_loss: 0.0200 - val_mae: 0.0942\n",
      "Epoch 10/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0014 - mae: 0.0283 - val_loss: 0.0221 - val_mae: 0.0965\n",
      "Epoch 11/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0012 - mae: 0.0255 - val_loss: 0.0220 - val_mae: 0.0964\n",
      "Epoch 12/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0012 - mae: 0.0267 - val_loss: 0.0187 - val_mae: 0.0891\n",
      "Epoch 13/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 8.3241e-04 - mae: 0.0216 - val_loss: 0.0187 - val_mae: 0.0883\n",
      "Epoch 14/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 7.2390e-04 - mae: 0.0197 - val_loss: 0.0162 - val_mae: 0.0819\n",
      "Epoch 15/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 6.0860e-04 - mae: 0.0181 - val_loss: 0.0168 - val_mae: 0.0837\n",
      "Epoch 16/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 4.5229e-04 - mae: 0.0153 - val_loss: 0.0158 - val_mae: 0.0806\n",
      "Epoch 17/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 3.5603e-04 - mae: 0.0134 - val_loss: 0.0125 - val_mae: 0.0722\n",
      "Epoch 18/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 3.4628e-04 - mae: 0.0134 - val_loss: 0.0120 - val_mae: 0.0757\n",
      "Epoch 19/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 2.4290e-04 - mae: 0.0109 - val_loss: 0.0121 - val_mae: 0.0697\n",
      "Epoch 20/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 2.2622e-04 - mae: 0.0104 - val_loss: 0.0135 - val_mae: 0.0758\n",
      "Epoch 21/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 1.8036e-04 - mae: 0.0090 - val_loss: 0.0157 - val_mae: 0.0858\n",
      "Epoch 22/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 2.1532e-04 - mae: 0.0099 - val_loss: 0.0120 - val_mae: 0.0705\n",
      "Epoch 23/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 2.3142e-04 - mae: 0.0107 - val_loss: 0.0118 - val_mae: 0.0705\n",
      "Epoch 24/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 2.1454e-04 - mae: 0.0102 - val_loss: 0.0119 - val_mae: 0.0716\n",
      "Epoch 25/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 1.5900e-04 - mae: 0.0079 - val_loss: 0.0127 - val_mae: 0.0789\n",
      "Epoch 26/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 2.0948e-04 - mae: 0.0099 - val_loss: 0.0131 - val_mae: 0.0729\n",
      "Epoch 27/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 1.9987e-04 - mae: 0.0099 - val_loss: 0.0127 - val_mae: 0.0701\n",
      "Epoch 28/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 1.7835e-04 - mae: 0.0090 - val_loss: 0.0120 - val_mae: 0.0718\n",
      "Epoch 29/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 1.8552e-04 - mae: 0.0093 - val_loss: 0.0123 - val_mae: 0.0716\n",
      "Epoch 30/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 1.8956e-04 - mae: 0.0095 - val_loss: 0.0123 - val_mae: 0.0753\n",
      "Epoch 31/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 1.7935e-04 - mae: 0.0090 - val_loss: 0.0123 - val_mae: 0.0724\n",
      "Epoch 32/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 1.9377e-04 - mae: 0.0094 - val_loss: 0.0124 - val_mae: 0.0735\n",
      "Epoch 33/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 1.5827e-04 - mae: 0.0080 - val_loss: 0.0124 - val_mae: 0.0750\n",
      "Epoch 34/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 1.8697e-04 - mae: 0.0094 - val_loss: 0.0126 - val_mae: 0.0749\n",
      "Epoch 35/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 1.7441e-04 - mae: 0.0089 - val_loss: 0.0125 - val_mae: 0.0728\n",
      "Epoch 36/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 1.6732e-04 - mae: 0.0085 - val_loss: 0.0128 - val_mae: 0.0705\n",
      "Epoch 37/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 1.6957e-04 - mae: 0.0087 - val_loss: 0.0128 - val_mae: 0.0722\n",
      "Epoch 38/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 1.5015e-04 - mae: 0.0077 - val_loss: 0.0127 - val_mae: 0.0724\n",
      "Epoch 39/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 1.9208e-04 - mae: 0.0095 - val_loss: 0.0131 - val_mae: 0.0796\n",
      "Epoch 40/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 1.7472e-04 - mae: 0.0083 - val_loss: 0.0127 - val_mae: 0.0750\n",
      "Epoch 41/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 1.5551e-04 - mae: 0.0080 - val_loss: 0.0127 - val_mae: 0.0748\n",
      "Epoch 42/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 1.3794e-04 - mae: 0.0072 - val_loss: 0.0128 - val_mae: 0.0729\n",
      "Epoch 43/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 1.3994e-04 - mae: 0.0073 - val_loss: 0.0137 - val_mae: 0.0724\n",
      "Epoch 44/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 1.5112e-04 - mae: 0.0078 - val_loss: 0.0131 - val_mae: 0.0712\n",
      "Epoch 45/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 1.4672e-04 - mae: 0.0078 - val_loss: 0.0131 - val_mae: 0.0722\n",
      "Epoch 46/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 1.3412e-04 - mae: 0.0069 - val_loss: 0.0130 - val_mae: 0.0755\n",
      "Epoch 47/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 1.4003e-04 - mae: 0.0074 - val_loss: 0.0130 - val_mae: 0.0736\n",
      "Epoch 48/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 1.3804e-04 - mae: 0.0072 - val_loss: 0.0131 - val_mae: 0.0764\n",
      "Epoch 49/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 1.5725e-04 - mae: 0.0082 - val_loss: 0.0136 - val_mae: 0.0710\n",
      "Epoch 50/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 1.2920e-04 - mae: 0.0068 - val_loss: 0.0134 - val_mae: 0.0717\n",
      "Epoch 51/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 1.3645e-04 - mae: 0.0070 - val_loss: 0.0133 - val_mae: 0.0768\n",
      "Epoch 52/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 1.3828e-04 - mae: 0.0074 - val_loss: 0.0135 - val_mae: 0.0729\n",
      "Epoch 53/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 1.2838e-04 - mae: 0.0066 - val_loss: 0.0137 - val_mae: 0.0715\n",
      "Epoch 54/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 1.3955e-04 - mae: 0.0073 - val_loss: 0.0141 - val_mae: 0.0727\n",
      "Epoch 55/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 1.3329e-04 - mae: 0.0071 - val_loss: 0.0137 - val_mae: 0.0743\n",
      "Epoch 56/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 1.3706e-04 - mae: 0.0068 - val_loss: 0.0140 - val_mae: 0.0731\n",
      "Epoch 57/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 1.2978e-04 - mae: 0.0067 - val_loss: 0.0142 - val_mae: 0.0717\n",
      "Epoch 58/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 1.3662e-04 - mae: 0.0074 - val_loss: 0.0136 - val_mae: 0.0737\n",
      "Epoch 59/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 1.5321e-04 - mae: 0.0077 - val_loss: 0.0141 - val_mae: 0.0727\n",
      "Epoch 60/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.2672e-04 - mae: 0.0068 - val_loss: 0.0138 - val_mae: 0.0728\n",
      "Epoch 61/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.3670e-04 - mae: 0.0072 - val_loss: 0.0139 - val_mae: 0.0732\n",
      "Epoch 62/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 1.2748e-04 - mae: 0.0066 - val_loss: 0.0138 - val_mae: 0.0731\n",
      "Epoch 63/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.3052e-04 - mae: 0.0070 - val_loss: 0.0143 - val_mae: 0.0718\n",
      "Epoch 64/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 1.2172e-04 - mae: 0.0065 - val_loss: 0.0139 - val_mae: 0.0730\n",
      "Epoch 65/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 1.2896e-04 - mae: 0.0069 - val_loss: 0.0140 - val_mae: 0.0725\n",
      "Epoch 66/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 1.1936e-04 - mae: 0.0063 - val_loss: 0.0139 - val_mae: 0.0743\n",
      "Epoch 67/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 1.1910e-04 - mae: 0.0064 - val_loss: 0.0146 - val_mae: 0.0728\n",
      "Epoch 68/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 1.2068e-04 - mae: 0.0065 - val_loss: 0.0145 - val_mae: 0.0718\n",
      "Epoch 69/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 1.2459e-04 - mae: 0.0066 - val_loss: 0.0141 - val_mae: 0.0731\n",
      "Epoch 70/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 1.2751e-04 - mae: 0.0067 - val_loss: 0.0136 - val_mae: 0.0745\n",
      "Epoch 71/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.2904e-04 - mae: 0.0066 - val_loss: 0.0146 - val_mae: 0.0726\n",
      "Epoch 72/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 1.1798e-04 - mae: 0.0063 - val_loss: 0.0139 - val_mae: 0.0738\n",
      "Epoch 73/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.2009e-04 - mae: 0.0062 - val_loss: 0.0143 - val_mae: 0.0735\n",
      "Epoch 74/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 1.1971e-04 - mae: 0.0061 - val_loss: 0.0147 - val_mae: 0.0721\n",
      "Epoch 75/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 1.2511e-04 - mae: 0.0066 - val_loss: 0.0143 - val_mae: 0.0730\n",
      "Epoch 76/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 1.2494e-04 - mae: 0.0065 - val_loss: 0.0145 - val_mae: 0.0728\n",
      "Epoch 77/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 1.2571e-04 - mae: 0.0065 - val_loss: 0.0143 - val_mae: 0.0734\n",
      "Epoch 78/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 1.2153e-04 - mae: 0.0061 - val_loss: 0.0145 - val_mae: 0.0724\n",
      "Epoch 79/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 1.1716e-04 - mae: 0.0063 - val_loss: 0.0143 - val_mae: 0.0736\n",
      "Epoch 80/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.2190e-04 - mae: 0.0064 - val_loss: 0.0138 - val_mae: 0.0745\n",
      "Epoch 81/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.2520e-04 - mae: 0.0066 - val_loss: 0.0142 - val_mae: 0.0726\n",
      "Epoch 82/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 1.1904e-04 - mae: 0.0062 - val_loss: 0.0142 - val_mae: 0.0733\n",
      "Epoch 83/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.2065e-04 - mae: 0.0064 - val_loss: 0.0140 - val_mae: 0.0743\n",
      "Epoch 84/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 1.2500e-04 - mae: 0.0065 - val_loss: 0.0141 - val_mae: 0.0738\n",
      "Epoch 85/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.2096e-04 - mae: 0.0063 - val_loss: 0.0139 - val_mae: 0.0752\n",
      "Epoch 86/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.1531e-04 - mae: 0.0061 - val_loss: 0.0144 - val_mae: 0.0730\n",
      "Epoch 87/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.1547e-04 - mae: 0.0060 - val_loss: 0.0145 - val_mae: 0.0726\n",
      "Epoch 88/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.1202e-04 - mae: 0.0057 - val_loss: 0.0143 - val_mae: 0.0733\n",
      "Epoch 89/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.1455e-04 - mae: 0.0058 - val_loss: 0.0140 - val_mae: 0.0743\n",
      "Epoch 90/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 1.1854e-04 - mae: 0.0063 - val_loss: 0.0142 - val_mae: 0.0735\n",
      "Epoch 91/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.2010e-04 - mae: 0.0063 - val_loss: 0.0143 - val_mae: 0.0726\n",
      "Epoch 92/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 1.1515e-04 - mae: 0.0059 - val_loss: 0.0143 - val_mae: 0.0732\n",
      "Epoch 93/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.1556e-04 - mae: 0.0060 - val_loss: 0.0142 - val_mae: 0.0729\n",
      "Epoch 94/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 1.2507e-04 - mae: 0.0068 - val_loss: 0.0142 - val_mae: 0.0743\n",
      "Epoch 95/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.1585e-04 - mae: 0.0060 - val_loss: 0.0143 - val_mae: 0.0731\n",
      "Epoch 96/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.1431e-04 - mae: 0.0058 - val_loss: 0.0137 - val_mae: 0.0745\n",
      "Epoch 97/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.1363e-04 - mae: 0.0059 - val_loss: 0.0140 - val_mae: 0.0736\n",
      "Epoch 98/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.1267e-04 - mae: 0.0059 - val_loss: 0.0141 - val_mae: 0.0737\n",
      "Epoch 99/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.1732e-04 - mae: 0.0060 - val_loss: 0.0139 - val_mae: 0.0744\n",
      "Epoch 100/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.0948e-04 - mae: 0.0055 - val_loss: 0.0143 - val_mae: 0.0726\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step   \n",
      "✅ Done with tomato_Belgaum_daily.csv | MAE=227.07, RMSE=532.93, R2=0.7748, MAPE=10.97%, Accuracy=89.03%\n",
      "Saved updated CSV with Date, Actual & Predicted: tat_mqa_output_csv\\tomato_Belgaum_daily_tat_mqa_updated.csv\n",
      "🚀 Processing: tomato_Bellary_daily.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_query_attention_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">17,216</span> │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiQueryAttention</span>)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_query_attention_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                               │                           │                 │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_4         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ layer_normalization_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dense_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                               │                           │                 │ dense_28[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_5         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_2    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ global_average_pooling1d_… │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_query_attention_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │          \u001b[38;5;34m17,216\u001b[0m │ input_layer_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "│ (\u001b[38;5;33mMultiQueryAttention\u001b[0m)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_4 (\u001b[38;5;33mAdd\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ multi_query_attention_2[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                               │                           │                 │ input_layer_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_4         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ add_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_27 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │           \u001b[38;5;34m8,320\u001b[0m │ layer_normalization_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_28 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │             \u001b[38;5;34m129\u001b[0m │ dense_27[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_5 (\u001b[38;5;33mAdd\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                               │                           │                 │ dense_28[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_5         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ add_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_2    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_29 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │              \u001b[38;5;34m65\u001b[0m │ global_average_pooling1d_… │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,986</span> (101.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25,986\u001b[0m (101.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,986</span> (101.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m25,986\u001b[0m (101.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 0.0500 - mae: 0.1088 - val_loss: 0.0171 - val_mae: 0.0533\n",
      "Epoch 2/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0046 - mae: 0.0509 - val_loss: 0.0156 - val_mae: 0.0594\n",
      "Epoch 3/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0036 - mae: 0.0448 - val_loss: 0.0158 - val_mae: 0.0625\n",
      "Epoch 4/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0030 - mae: 0.0398 - val_loss: 0.0151 - val_mae: 0.0743\n",
      "Epoch 5/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0027 - mae: 0.0378 - val_loss: 0.0156 - val_mae: 0.0483\n",
      "Epoch 6/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0023 - mae: 0.0343 - val_loss: 0.0153 - val_mae: 0.0479\n",
      "Epoch 7/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0023 - mae: 0.0342 - val_loss: 0.0143 - val_mae: 0.0477\n",
      "Epoch 8/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0021 - mae: 0.0330 - val_loss: 0.0149 - val_mae: 0.0484\n",
      "Epoch 9/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0022 - mae: 0.0328 - val_loss: 0.0143 - val_mae: 0.0509\n",
      "Epoch 10/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0020 - mae: 0.0317 - val_loss: 0.0131 - val_mae: 0.0612\n",
      "Epoch 11/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0021 - mae: 0.0316 - val_loss: 0.0142 - val_mae: 0.0468\n",
      "Epoch 12/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0019 - mae: 0.0300 - val_loss: 0.0138 - val_mae: 0.0459\n",
      "Epoch 13/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0019 - mae: 0.0299 - val_loss: 0.0122 - val_mae: 0.0531\n",
      "Epoch 14/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0019 - mae: 0.0303 - val_loss: 0.0123 - val_mae: 0.0585\n",
      "Epoch 15/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0019 - mae: 0.0301 - val_loss: 0.0109 - val_mae: 0.0422\n",
      "Epoch 16/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0019 - mae: 0.0301 - val_loss: 0.0117 - val_mae: 0.0429\n",
      "Epoch 17/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0019 - mae: 0.0298 - val_loss: 0.0116 - val_mae: 0.0428\n",
      "Epoch 18/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0019 - mae: 0.0293 - val_loss: 0.0112 - val_mae: 0.0439\n",
      "Epoch 19/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0018 - mae: 0.0285 - val_loss: 0.0112 - val_mae: 0.0421\n",
      "Epoch 20/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0019 - mae: 0.0296 - val_loss: 0.0100 - val_mae: 0.0451\n",
      "Epoch 21/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0019 - mae: 0.0301 - val_loss: 0.0100 - val_mae: 0.0404\n",
      "Epoch 22/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0019 - mae: 0.0301 - val_loss: 0.0097 - val_mae: 0.0487\n",
      "Epoch 23/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0018 - mae: 0.0284 - val_loss: 0.0107 - val_mae: 0.0451\n",
      "Epoch 24/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0018 - mae: 0.0287 - val_loss: 0.0087 - val_mae: 0.0549\n",
      "Epoch 25/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0018 - mae: 0.0285 - val_loss: 0.0074 - val_mae: 0.0370\n",
      "Epoch 26/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0018 - mae: 0.0284 - val_loss: 0.0093 - val_mae: 0.0463\n",
      "Epoch 27/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0018 - mae: 0.0288 - val_loss: 0.0062 - val_mae: 0.0360\n",
      "Epoch 28/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0018 - mae: 0.0284 - val_loss: 0.0079 - val_mae: 0.0430\n",
      "Epoch 29/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0018 - mae: 0.0289 - val_loss: 0.0081 - val_mae: 0.0424\n",
      "Epoch 30/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0018 - mae: 0.0286 - val_loss: 0.0078 - val_mae: 0.0372\n",
      "Epoch 31/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0018 - mae: 0.0292 - val_loss: 0.0079 - val_mae: 0.0380\n",
      "Epoch 32/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0018 - mae: 0.0286 - val_loss: 0.0074 - val_mae: 0.0377\n",
      "Epoch 33/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0018 - mae: 0.0283 - val_loss: 0.0063 - val_mae: 0.0485\n",
      "Epoch 34/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0018 - mae: 0.0289 - val_loss: 0.0081 - val_mae: 0.0403\n",
      "Epoch 35/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0018 - mae: 0.0289 - val_loss: 0.0064 - val_mae: 0.0379\n",
      "Epoch 36/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0017 - mae: 0.0277 - val_loss: 0.0067 - val_mae: 0.0368\n",
      "Epoch 37/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0018 - mae: 0.0284 - val_loss: 0.0060 - val_mae: 0.0335\n",
      "Epoch 38/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0018 - mae: 0.0279 - val_loss: 0.0064 - val_mae: 0.0461\n",
      "Epoch 39/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0018 - mae: 0.0286 - val_loss: 0.0067 - val_mae: 0.0347\n",
      "Epoch 40/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0017 - mae: 0.0278 - val_loss: 0.0060 - val_mae: 0.0337\n",
      "Epoch 41/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0017 - mae: 0.0278 - val_loss: 0.0064 - val_mae: 0.0407\n",
      "Epoch 42/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0017 - mae: 0.0277 - val_loss: 0.0062 - val_mae: 0.0337\n",
      "Epoch 43/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0017 - mae: 0.0277 - val_loss: 0.0068 - val_mae: 0.0379\n",
      "Epoch 44/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0017 - mae: 0.0277 - val_loss: 0.0066 - val_mae: 0.0353\n",
      "Epoch 45/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0017 - mae: 0.0273 - val_loss: 0.0064 - val_mae: 0.0351\n",
      "Epoch 46/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0018 - mae: 0.0281 - val_loss: 0.0069 - val_mae: 0.0490\n",
      "Epoch 47/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0017 - mae: 0.0277 - val_loss: 0.0057 - val_mae: 0.0332\n",
      "Epoch 48/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0017 - mae: 0.0274 - val_loss: 0.0055 - val_mae: 0.0326\n",
      "Epoch 49/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0017 - mae: 0.0279 - val_loss: 0.0066 - val_mae: 0.0448\n",
      "Epoch 50/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0018 - mae: 0.0290 - val_loss: 0.0077 - val_mae: 0.0366\n",
      "Epoch 51/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0017 - mae: 0.0275 - val_loss: 0.0062 - val_mae: 0.0345\n",
      "Epoch 52/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0017 - mae: 0.0275 - val_loss: 0.0064 - val_mae: 0.0394\n",
      "Epoch 53/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0017 - mae: 0.0275 - val_loss: 0.0057 - val_mae: 0.0340\n",
      "Epoch 54/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0017 - mae: 0.0277 - val_loss: 0.0076 - val_mae: 0.0387\n",
      "Epoch 55/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0017 - mae: 0.0274 - val_loss: 0.0063 - val_mae: 0.0350\n",
      "Epoch 56/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0017 - mae: 0.0273 - val_loss: 0.0062 - val_mae: 0.0438\n",
      "Epoch 57/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0017 - mae: 0.0275 - val_loss: 0.0068 - val_mae: 0.0521\n",
      "Epoch 58/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0017 - mae: 0.0276 - val_loss: 0.0066 - val_mae: 0.0464\n",
      "Epoch 59/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0017 - mae: 0.0270 - val_loss: 0.0060 - val_mae: 0.0355\n",
      "Epoch 60/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0017 - mae: 0.0272 - val_loss: 0.0077 - val_mae: 0.0475\n",
      "Epoch 61/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0017 - mae: 0.0270 - val_loss: 0.0071 - val_mae: 0.0352\n",
      "Epoch 62/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0017 - mae: 0.0267 - val_loss: 0.0071 - val_mae: 0.0399\n",
      "Epoch 63/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0017 - mae: 0.0272 - val_loss: 0.0063 - val_mae: 0.0354\n",
      "Epoch 64/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0018 - mae: 0.0284 - val_loss: 0.0068 - val_mae: 0.0390\n",
      "Epoch 65/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0017 - mae: 0.0267 - val_loss: 0.0067 - val_mae: 0.0384\n",
      "Epoch 66/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0017 - mae: 0.0269 - val_loss: 0.0056 - val_mae: 0.0371\n",
      "Epoch 67/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0017 - mae: 0.0271 - val_loss: 0.0067 - val_mae: 0.0407\n",
      "Epoch 68/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0017 - mae: 0.0269 - val_loss: 0.0066 - val_mae: 0.0362\n",
      "Epoch 69/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0017 - mae: 0.0272 - val_loss: 0.0073 - val_mae: 0.0353\n",
      "Epoch 70/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0017 - mae: 0.0269 - val_loss: 0.0065 - val_mae: 0.0363\n",
      "Epoch 71/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0017 - mae: 0.0267 - val_loss: 0.0063 - val_mae: 0.0352\n",
      "Epoch 72/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0017 - mae: 0.0271 - val_loss: 0.0063 - val_mae: 0.0409\n",
      "Epoch 73/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0017 - mae: 0.0269 - val_loss: 0.0069 - val_mae: 0.0467\n",
      "Epoch 74/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0017 - mae: 0.0273 - val_loss: 0.0073 - val_mae: 0.0359\n",
      "Epoch 75/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0017 - mae: 0.0271 - val_loss: 0.0066 - val_mae: 0.0366\n",
      "Epoch 76/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0017 - mae: 0.0270 - val_loss: 0.0066 - val_mae: 0.0385\n",
      "Epoch 77/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0017 - mae: 0.0267 - val_loss: 0.0069 - val_mae: 0.0422\n",
      "Epoch 78/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0017 - mae: 0.0272 - val_loss: 0.0064 - val_mae: 0.0354\n",
      "Epoch 79/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0017 - mae: 0.0270 - val_loss: 0.0072 - val_mae: 0.0402\n",
      "Epoch 80/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0016 - mae: 0.0267 - val_loss: 0.0064 - val_mae: 0.0387\n",
      "Epoch 81/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0017 - mae: 0.0269 - val_loss: 0.0068 - val_mae: 0.0346\n",
      "Epoch 82/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0017 - mae: 0.0267 - val_loss: 0.0071 - val_mae: 0.0400\n",
      "Epoch 83/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0016 - mae: 0.0266 - val_loss: 0.0070 - val_mae: 0.0436\n",
      "Epoch 84/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0017 - mae: 0.0267 - val_loss: 0.0076 - val_mae: 0.0449\n",
      "Epoch 85/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0016 - mae: 0.0267 - val_loss: 0.0074 - val_mae: 0.0408\n",
      "Epoch 86/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0017 - mae: 0.0269 - val_loss: 0.0069 - val_mae: 0.0430\n",
      "Epoch 87/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0016 - mae: 0.0265 - val_loss: 0.0067 - val_mae: 0.0358\n",
      "Epoch 88/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0016 - mae: 0.0268 - val_loss: 0.0072 - val_mae: 0.0418\n",
      "Epoch 89/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0017 - mae: 0.0268 - val_loss: 0.0076 - val_mae: 0.0405\n",
      "Epoch 90/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0016 - mae: 0.0265 - val_loss: 0.0065 - val_mae: 0.0363\n",
      "Epoch 91/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0016 - mae: 0.0267 - val_loss: 0.0072 - val_mae: 0.0362\n",
      "Epoch 92/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0017 - mae: 0.0269 - val_loss: 0.0080 - val_mae: 0.0376\n",
      "Epoch 93/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0016 - mae: 0.0265 - val_loss: 0.0076 - val_mae: 0.0419\n",
      "Epoch 94/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0016 - mae: 0.0267 - val_loss: 0.0075 - val_mae: 0.0449\n",
      "Epoch 95/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0016 - mae: 0.0265 - val_loss: 0.0073 - val_mae: 0.0357\n",
      "Epoch 96/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0016 - mae: 0.0267 - val_loss: 0.0073 - val_mae: 0.0423\n",
      "Epoch 97/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0016 - mae: 0.0266 - val_loss: 0.0074 - val_mae: 0.0354\n",
      "Epoch 98/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0016 - mae: 0.0267 - val_loss: 0.0080 - val_mae: 0.0397\n",
      "Epoch 99/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0016 - mae: 0.0268 - val_loss: 0.0075 - val_mae: 0.0369\n",
      "Epoch 100/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0016 - mae: 0.0266 - val_loss: 0.0084 - val_mae: 0.0465\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step   \n",
      "✅ Done with tomato_Bellary_daily.csv | MAE=247.63, RMSE=393.12, R2=0.6006, MAPE=36.42%, Accuracy=63.58%\n",
      "Saved updated CSV with Date, Actual & Predicted: tat_mqa_output_csv\\tomato_Bellary_daily_tat_mqa_updated.csv\n",
      "🚀 Processing: tomato_Chamrajnagar_daily.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_query_attention_3       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">17,216</span> │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiQueryAttention</span>)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_query_attention_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                               │                           │                 │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_6         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ layer_normalization_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dense_37[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                               │                           │                 │ dense_38[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_7         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_3    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ global_average_pooling1d_… │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3 (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_query_attention_3       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │          \u001b[38;5;34m17,216\u001b[0m │ input_layer_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "│ (\u001b[38;5;33mMultiQueryAttention\u001b[0m)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_6 (\u001b[38;5;33mAdd\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ multi_query_attention_3[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                               │                           │                 │ input_layer_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_6         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ add_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_37 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │           \u001b[38;5;34m8,320\u001b[0m │ layer_normalization_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_38 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │             \u001b[38;5;34m129\u001b[0m │ dense_37[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_7 (\u001b[38;5;33mAdd\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                               │                           │                 │ dense_38[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_7         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ add_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_3    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_39 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │              \u001b[38;5;34m65\u001b[0m │ global_average_pooling1d_… │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,986</span> (101.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25,986\u001b[0m (101.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,986</span> (101.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m25,986\u001b[0m (101.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.0578 - mae: 0.0920 - val_loss: 0.0023 - val_mae: 0.0335\n",
      "Epoch 2/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 0.0027 - mae: 0.0413 - val_loss: 0.0021 - val_mae: 0.0356\n",
      "Epoch 3/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 0.0013 - mae: 0.0282 - val_loss: 0.0019 - val_mae: 0.0338\n",
      "Epoch 4/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 8.2545e-04 - mae: 0.0222 - val_loss: 0.0020 - val_mae: 0.0324\n",
      "Epoch 5/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 6.4333e-04 - mae: 0.0192 - val_loss: 0.0021 - val_mae: 0.0329\n",
      "Epoch 6/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 5.8943e-04 - mae: 0.0184 - val_loss: 0.0023 - val_mae: 0.0340\n",
      "Epoch 7/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 5.2252e-04 - mae: 0.0170 - val_loss: 0.0020 - val_mae: 0.0371\n",
      "Epoch 8/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 4.8980e-04 - mae: 0.0163 - val_loss: 0.0019 - val_mae: 0.0350\n",
      "Epoch 9/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 4.8232e-04 - mae: 0.0161 - val_loss: 0.0037 - val_mae: 0.0533\n",
      "Epoch 10/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 5.0952e-04 - mae: 0.0167 - val_loss: 0.0019 - val_mae: 0.0323\n",
      "Epoch 11/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 4.8163e-04 - mae: 0.0163 - val_loss: 0.0020 - val_mae: 0.0325\n",
      "Epoch 12/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 4.6351e-04 - mae: 0.0157 - val_loss: 0.0019 - val_mae: 0.0323\n",
      "Epoch 13/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 4.5893e-04 - mae: 0.0156 - val_loss: 0.0024 - val_mae: 0.0335\n",
      "Epoch 14/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 4.3656e-04 - mae: 0.0149 - val_loss: 0.0028 - val_mae: 0.0359\n",
      "Epoch 15/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 4.4946e-04 - mae: 0.0152 - val_loss: 0.0019 - val_mae: 0.0344\n",
      "Epoch 16/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 4.3851e-04 - mae: 0.0150 - val_loss: 0.0019 - val_mae: 0.0354\n",
      "Epoch 17/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 4.2510e-04 - mae: 0.0146 - val_loss: 0.0018 - val_mae: 0.0329\n",
      "Epoch 18/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 4.3058e-04 - mae: 0.0147 - val_loss: 0.0019 - val_mae: 0.0320\n",
      "Epoch 19/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 4.0652e-04 - mae: 0.0140 - val_loss: 0.0021 - val_mae: 0.0319\n",
      "Epoch 20/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 4.0915e-04 - mae: 0.0140 - val_loss: 0.0020 - val_mae: 0.0319\n",
      "Epoch 21/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 4.0817e-04 - mae: 0.0140 - val_loss: 0.0021 - val_mae: 0.0322\n",
      "Epoch 22/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 4.1185e-04 - mae: 0.0141 - val_loss: 0.0020 - val_mae: 0.0322\n",
      "Epoch 23/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 4.1129e-04 - mae: 0.0142 - val_loss: 0.0021 - val_mae: 0.0320\n",
      "Epoch 24/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 4.0475e-04 - mae: 0.0139 - val_loss: 0.0021 - val_mae: 0.0321\n",
      "Epoch 25/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 4.1664e-04 - mae: 0.0142 - val_loss: 0.0020 - val_mae: 0.0319\n",
      "Epoch 26/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 4.0407e-04 - mae: 0.0139 - val_loss: 0.0018 - val_mae: 0.0341\n",
      "Epoch 27/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 4.1168e-04 - mae: 0.0141 - val_loss: 0.0019 - val_mae: 0.0323\n",
      "Epoch 28/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 4.0443e-04 - mae: 0.0139 - val_loss: 0.0019 - val_mae: 0.0336\n",
      "Epoch 29/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 4.0307e-04 - mae: 0.0138 - val_loss: 0.0021 - val_mae: 0.0320\n",
      "Epoch 30/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 4.0502e-04 - mae: 0.0139 - val_loss: 0.0022 - val_mae: 0.0331\n",
      "Epoch 31/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 4.0574e-04 - mae: 0.0139 - val_loss: 0.0020 - val_mae: 0.0321\n",
      "Epoch 32/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 3.9888e-04 - mae: 0.0137 - val_loss: 0.0019 - val_mae: 0.0319\n",
      "Epoch 33/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 4.0785e-04 - mae: 0.0140 - val_loss: 0.0020 - val_mae: 0.0321\n",
      "Epoch 34/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 4.0102e-04 - mae: 0.0140 - val_loss: 0.0019 - val_mae: 0.0321\n",
      "Epoch 35/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 4.0604e-04 - mae: 0.0140 - val_loss: 0.0019 - val_mae: 0.0332\n",
      "Epoch 36/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 4.0036e-04 - mae: 0.0138 - val_loss: 0.0019 - val_mae: 0.0329\n",
      "Epoch 37/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 4.0461e-04 - mae: 0.0139 - val_loss: 0.0020 - val_mae: 0.0323\n",
      "Epoch 38/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 4.0077e-04 - mae: 0.0138 - val_loss: 0.0019 - val_mae: 0.0327\n",
      "Epoch 39/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 3.9649e-04 - mae: 0.0136 - val_loss: 0.0019 - val_mae: 0.0325\n",
      "Epoch 40/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 3.9692e-04 - mae: 0.0136 - val_loss: 0.0019 - val_mae: 0.0333\n",
      "Epoch 41/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 3.9684e-04 - mae: 0.0137 - val_loss: 0.0020 - val_mae: 0.0324\n",
      "Epoch 42/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 3.9927e-04 - mae: 0.0137 - val_loss: 0.0019 - val_mae: 0.0331\n",
      "Epoch 43/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 3.9886e-04 - mae: 0.0137 - val_loss: 0.0019 - val_mae: 0.0331\n",
      "Epoch 44/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 3.8999e-04 - mae: 0.0134 - val_loss: 0.0019 - val_mae: 0.0324\n",
      "Epoch 45/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 3.9091e-04 - mae: 0.0135 - val_loss: 0.0021 - val_mae: 0.0326\n",
      "Epoch 46/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 3.9320e-04 - mae: 0.0135 - val_loss: 0.0019 - val_mae: 0.0329\n",
      "Epoch 47/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 3.9079e-04 - mae: 0.0134 - val_loss: 0.0019 - val_mae: 0.0341\n",
      "Epoch 48/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 3.8883e-04 - mae: 0.0135 - val_loss: 0.0020 - val_mae: 0.0328\n",
      "Epoch 49/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 3.8864e-04 - mae: 0.0133 - val_loss: 0.0019 - val_mae: 0.0331\n",
      "Epoch 50/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 3.8704e-04 - mae: 0.0133 - val_loss: 0.0019 - val_mae: 0.0333\n",
      "Epoch 51/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 3.8838e-04 - mae: 0.0133 - val_loss: 0.0019 - val_mae: 0.0326\n",
      "Epoch 52/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 3.8762e-04 - mae: 0.0133 - val_loss: 0.0020 - val_mae: 0.0327\n",
      "Epoch 53/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 3.8513e-04 - mae: 0.0133 - val_loss: 0.0019 - val_mae: 0.0330\n",
      "Epoch 54/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 3.8596e-04 - mae: 0.0132 - val_loss: 0.0019 - val_mae: 0.0327\n",
      "Epoch 55/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 3.8308e-04 - mae: 0.0131 - val_loss: 0.0019 - val_mae: 0.0328\n",
      "Epoch 56/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 3.8400e-04 - mae: 0.0131 - val_loss: 0.0020 - val_mae: 0.0329\n",
      "Epoch 57/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 3.8215e-04 - mae: 0.0131 - val_loss: 0.0019 - val_mae: 0.0330\n",
      "Epoch 58/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 3.8210e-04 - mae: 0.0131 - val_loss: 0.0019 - val_mae: 0.0331\n",
      "Epoch 59/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 3.8244e-04 - mae: 0.0131 - val_loss: 0.0020 - val_mae: 0.0331\n",
      "Epoch 60/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 3.8076e-04 - mae: 0.0130 - val_loss: 0.0019 - val_mae: 0.0336\n",
      "Epoch 61/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 3.8123e-04 - mae: 0.0131 - val_loss: 0.0020 - val_mae: 0.0329\n",
      "Epoch 62/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 3.8024e-04 - mae: 0.0130 - val_loss: 0.0020 - val_mae: 0.0335\n",
      "Epoch 63/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 3.7962e-04 - mae: 0.0130 - val_loss: 0.0021 - val_mae: 0.0333\n",
      "Epoch 64/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 3.8048e-04 - mae: 0.0130 - val_loss: 0.0019 - val_mae: 0.0334\n",
      "Epoch 65/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 3.7846e-04 - mae: 0.0130 - val_loss: 0.0021 - val_mae: 0.0333\n",
      "Epoch 66/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 3.8103e-04 - mae: 0.0131 - val_loss: 0.0021 - val_mae: 0.0332\n",
      "Epoch 67/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 3.8099e-04 - mae: 0.0130 - val_loss: 0.0019 - val_mae: 0.0334\n",
      "Epoch 68/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 3.7880e-04 - mae: 0.0130 - val_loss: 0.0020 - val_mae: 0.0334\n",
      "Epoch 69/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 3.7937e-04 - mae: 0.0130 - val_loss: 0.0022 - val_mae: 0.0336\n",
      "Epoch 70/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 3.8066e-04 - mae: 0.0130 - val_loss: 0.0020 - val_mae: 0.0335\n",
      "Epoch 71/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 3.7964e-04 - mae: 0.0130 - val_loss: 0.0020 - val_mae: 0.0332\n",
      "Epoch 72/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 3.8004e-04 - mae: 0.0130 - val_loss: 0.0021 - val_mae: 0.0333\n",
      "Epoch 73/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 3.7832e-04 - mae: 0.0130 - val_loss: 0.0020 - val_mae: 0.0332\n",
      "Epoch 74/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 3.7794e-04 - mae: 0.0129 - val_loss: 0.0021 - val_mae: 0.0332\n",
      "Epoch 75/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 3.8005e-04 - mae: 0.0130 - val_loss: 0.0020 - val_mae: 0.0332\n",
      "Epoch 76/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 3.7944e-04 - mae: 0.0130 - val_loss: 0.0021 - val_mae: 0.0335\n",
      "Epoch 77/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 3.7773e-04 - mae: 0.0129 - val_loss: 0.0019 - val_mae: 0.0332\n",
      "Epoch 78/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 3.7866e-04 - mae: 0.0130 - val_loss: 0.0021 - val_mae: 0.0334\n",
      "Epoch 79/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 3.7760e-04 - mae: 0.0129 - val_loss: 0.0020 - val_mae: 0.0332\n",
      "Epoch 80/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 3.7725e-04 - mae: 0.0129 - val_loss: 0.0019 - val_mae: 0.0335\n",
      "Epoch 81/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 3.7843e-04 - mae: 0.0129 - val_loss: 0.0021 - val_mae: 0.0333\n",
      "Epoch 82/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 3.7506e-04 - mae: 0.0129 - val_loss: 0.0021 - val_mae: 0.0334\n",
      "Epoch 83/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 3.7743e-04 - mae: 0.0129 - val_loss: 0.0020 - val_mae: 0.0331\n",
      "Epoch 84/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 3.7758e-04 - mae: 0.0129 - val_loss: 0.0021 - val_mae: 0.0334\n",
      "Epoch 85/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 3.7707e-04 - mae: 0.0130 - val_loss: 0.0020 - val_mae: 0.0332\n",
      "Epoch 86/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 3.7681e-04 - mae: 0.0128 - val_loss: 0.0020 - val_mae: 0.0335\n",
      "Epoch 87/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 3.7862e-04 - mae: 0.0130 - val_loss: 0.0022 - val_mae: 0.0338\n",
      "Epoch 88/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 3.7772e-04 - mae: 0.0129 - val_loss: 0.0021 - val_mae: 0.0335\n",
      "Epoch 89/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 3.7795e-04 - mae: 0.0130 - val_loss: 0.0020 - val_mae: 0.0335\n",
      "Epoch 90/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 3.7790e-04 - mae: 0.0129 - val_loss: 0.0022 - val_mae: 0.0337\n",
      "Epoch 91/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 3.7931e-04 - mae: 0.0130 - val_loss: 0.0020 - val_mae: 0.0335\n",
      "Epoch 92/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 3.7836e-04 - mae: 0.0130 - val_loss: 0.0021 - val_mae: 0.0335\n",
      "Epoch 93/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 3.7735e-04 - mae: 0.0130 - val_loss: 0.0022 - val_mae: 0.0336\n",
      "Epoch 94/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 3.7685e-04 - mae: 0.0129 - val_loss: 0.0021 - val_mae: 0.0335\n",
      "Epoch 95/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 3.7884e-04 - mae: 0.0130 - val_loss: 0.0021 - val_mae: 0.0335\n",
      "Epoch 96/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 3.7732e-04 - mae: 0.0129 - val_loss: 0.0020 - val_mae: 0.0334\n",
      "Epoch 97/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 3.7816e-04 - mae: 0.0129 - val_loss: 0.0022 - val_mae: 0.0337\n",
      "Epoch 98/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 3.7813e-04 - mae: 0.0129 - val_loss: 0.0020 - val_mae: 0.0338\n",
      "Epoch 99/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 3.7782e-04 - mae: 0.0129 - val_loss: 0.0020 - val_mae: 0.0338\n",
      "Epoch 100/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 3.7713e-04 - mae: 0.0129 - val_loss: 0.0020 - val_mae: 0.0335\n",
      "\u001b[1m501/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step\n",
      "✅ Done with tomato_Chamrajnagar_daily.csv | MAE=842.92, RMSE=1306.91, R2=0.3448, MAPE=85.96%, Accuracy=14.04%\n",
      "Saved updated CSV with Date, Actual & Predicted: tat_mqa_output_csv\\tomato_Chamrajnagar_daily_tat_mqa_updated.csv\n",
      "🚀 Processing: tomato_Chikmagalur_daily.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_query_attention_4       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">17,216</span> │ input_layer_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiQueryAttention</span>)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_query_attention_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                               │                           │                 │ input_layer_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_8         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_47 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ layer_normalization_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dense_47[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                               │                           │                 │ dense_48[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_9         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_4    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ global_average_pooling1d_… │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_query_attention_4       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │          \u001b[38;5;34m17,216\u001b[0m │ input_layer_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "│ (\u001b[38;5;33mMultiQueryAttention\u001b[0m)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_8 (\u001b[38;5;33mAdd\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ multi_query_attention_4[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                               │                           │                 │ input_layer_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_8         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ add_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_47 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │           \u001b[38;5;34m8,320\u001b[0m │ layer_normalization_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_48 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │             \u001b[38;5;34m129\u001b[0m │ dense_47[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_9 (\u001b[38;5;33mAdd\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                               │                           │                 │ dense_48[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_9         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ add_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_4    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_49 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │              \u001b[38;5;34m65\u001b[0m │ global_average_pooling1d_… │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,986</span> (101.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25,986\u001b[0m (101.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,986</span> (101.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m25,986\u001b[0m (101.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - loss: 0.0166 - mae: 0.0704 - val_loss: 0.0146 - val_mae: 0.0776\n",
      "Epoch 2/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 13ms/step - loss: 0.0034 - mae: 0.0418 - val_loss: 0.0115 - val_mae: 0.0752\n",
      "Epoch 3/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.0031 - mae: 0.0388 - val_loss: 0.0137 - val_mae: 0.0777\n",
      "Epoch 4/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.0029 - mae: 0.0376 - val_loss: 0.0107 - val_mae: 0.0719\n",
      "Epoch 5/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - loss: 0.0029 - mae: 0.0374 - val_loss: 0.0148 - val_mae: 0.0836\n",
      "Epoch 6/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.0028 - mae: 0.0364 - val_loss: 0.0124 - val_mae: 0.0739\n",
      "Epoch 7/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 11ms/step - loss: 0.0027 - mae: 0.0355 - val_loss: 0.0105 - val_mae: 0.0685\n",
      "Epoch 8/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.0027 - mae: 0.0354 - val_loss: 0.0098 - val_mae: 0.0660\n",
      "Epoch 9/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 11ms/step - loss: 0.0027 - mae: 0.0347 - val_loss: 0.0099 - val_mae: 0.0669\n",
      "Epoch 10/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0026 - mae: 0.0344 - val_loss: 0.0092 - val_mae: 0.0644\n",
      "Epoch 11/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 11ms/step - loss: 0.0026 - mae: 0.0339 - val_loss: 0.0089 - val_mae: 0.0637\n",
      "Epoch 12/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.0026 - mae: 0.0341 - val_loss: 0.0101 - val_mae: 0.0677\n",
      "Epoch 13/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.0026 - mae: 0.0339 - val_loss: 0.0091 - val_mae: 0.0639\n",
      "Epoch 14/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 11ms/step - loss: 0.0026 - mae: 0.0337 - val_loss: 0.0088 - val_mae: 0.0630\n",
      "Epoch 15/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.0026 - mae: 0.0337 - val_loss: 0.0089 - val_mae: 0.0647\n",
      "Epoch 16/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.0026 - mae: 0.0336 - val_loss: 0.0088 - val_mae: 0.0629\n",
      "Epoch 17/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.0026 - mae: 0.0336 - val_loss: 0.0095 - val_mae: 0.0651\n",
      "Epoch 18/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.0026 - mae: 0.0335 - val_loss: 0.0087 - val_mae: 0.0628\n",
      "Epoch 19/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.0026 - mae: 0.0335 - val_loss: 0.0090 - val_mae: 0.0634\n",
      "Epoch 20/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.0026 - mae: 0.0335 - val_loss: 0.0088 - val_mae: 0.0641\n",
      "Epoch 21/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.0026 - mae: 0.0334 - val_loss: 0.0090 - val_mae: 0.0638\n",
      "Epoch 22/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 11ms/step - loss: 0.0026 - mae: 0.0333 - val_loss: 0.0093 - val_mae: 0.0645\n",
      "Epoch 23/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 11ms/step - loss: 0.0026 - mae: 0.0334 - val_loss: 0.0087 - val_mae: 0.0629\n",
      "Epoch 24/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0026 - mae: 0.0334 - val_loss: 0.0096 - val_mae: 0.0653\n",
      "Epoch 25/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.0026 - mae: 0.0333 - val_loss: 0.0095 - val_mae: 0.0648\n",
      "Epoch 26/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.0026 - mae: 0.0334 - val_loss: 0.0087 - val_mae: 0.0632\n",
      "Epoch 27/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.0026 - mae: 0.0335 - val_loss: 0.0087 - val_mae: 0.0628\n",
      "Epoch 28/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.0026 - mae: 0.0334 - val_loss: 0.0088 - val_mae: 0.0629\n",
      "Epoch 29/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.0025 - mae: 0.0333 - val_loss: 0.0092 - val_mae: 0.0641\n",
      "Epoch 30/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.0026 - mae: 0.0333 - val_loss: 0.0091 - val_mae: 0.0636\n",
      "Epoch 31/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.0025 - mae: 0.0332 - val_loss: 0.0097 - val_mae: 0.0655\n",
      "Epoch 32/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.0026 - mae: 0.0333 - val_loss: 0.0090 - val_mae: 0.0632\n",
      "Epoch 33/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.0026 - mae: 0.0332 - val_loss: 0.0093 - val_mae: 0.0644\n",
      "Epoch 34/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.0026 - mae: 0.0333 - val_loss: 0.0088 - val_mae: 0.0628\n",
      "Epoch 35/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 11ms/step - loss: 0.0026 - mae: 0.0333 - val_loss: 0.0093 - val_mae: 0.0644\n",
      "Epoch 36/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.0025 - mae: 0.0332 - val_loss: 0.0096 - val_mae: 0.0651\n",
      "Epoch 37/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.0026 - mae: 0.0333 - val_loss: 0.0091 - val_mae: 0.0635\n",
      "Epoch 38/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.0026 - mae: 0.0333 - val_loss: 0.0091 - val_mae: 0.0637\n",
      "Epoch 39/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.0026 - mae: 0.0333 - val_loss: 0.0090 - val_mae: 0.0632\n",
      "Epoch 40/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.0026 - mae: 0.0333 - val_loss: 0.0093 - val_mae: 0.0642\n",
      "Epoch 41/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.0026 - mae: 0.0333 - val_loss: 0.0092 - val_mae: 0.0640\n",
      "Epoch 42/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.0026 - mae: 0.0333 - val_loss: 0.0088 - val_mae: 0.0628\n",
      "Epoch 43/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.0026 - mae: 0.0333 - val_loss: 0.0092 - val_mae: 0.0638\n",
      "Epoch 44/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.0026 - mae: 0.0332 - val_loss: 0.0090 - val_mae: 0.0633\n",
      "Epoch 45/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.0026 - mae: 0.0333 - val_loss: 0.0088 - val_mae: 0.0629\n",
      "Epoch 46/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.0025 - mae: 0.0331 - val_loss: 0.0092 - val_mae: 0.0637\n",
      "Epoch 47/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.0025 - mae: 0.0332 - val_loss: 0.0088 - val_mae: 0.0634\n",
      "Epoch 48/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 11ms/step - loss: 0.0025 - mae: 0.0332 - val_loss: 0.0093 - val_mae: 0.0641\n",
      "Epoch 49/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.0025 - mae: 0.0332 - val_loss: 0.0093 - val_mae: 0.0641\n",
      "Epoch 50/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.0025 - mae: 0.0332 - val_loss: 0.0089 - val_mae: 0.0631\n",
      "Epoch 51/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.0025 - mae: 0.0331 - val_loss: 0.0091 - val_mae: 0.0637\n",
      "Epoch 52/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.0026 - mae: 0.0333 - val_loss: 0.0093 - val_mae: 0.0640\n",
      "Epoch 53/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.0025 - mae: 0.0332 - val_loss: 0.0093 - val_mae: 0.0639\n",
      "Epoch 54/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 11ms/step - loss: 0.0025 - mae: 0.0332 - val_loss: 0.0096 - val_mae: 0.0647\n",
      "Epoch 55/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 11ms/step - loss: 0.0025 - mae: 0.0332 - val_loss: 0.0115 - val_mae: 0.0706\n",
      "Epoch 56/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 11ms/step - loss: 0.0025 - mae: 0.0332 - val_loss: 0.0093 - val_mae: 0.0640\n",
      "Epoch 57/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 11ms/step - loss: 0.0025 - mae: 0.0332 - val_loss: 0.0096 - val_mae: 0.0645\n",
      "Epoch 58/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 11ms/step - loss: 0.0025 - mae: 0.0332 - val_loss: 0.0095 - val_mae: 0.0643\n",
      "Epoch 59/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 11ms/step - loss: 0.0025 - mae: 0.0333 - val_loss: 0.0107 - val_mae: 0.0670\n",
      "Epoch 60/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 11ms/step - loss: 0.0025 - mae: 0.0332 - val_loss: 0.0101 - val_mae: 0.0657\n",
      "Epoch 61/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 11ms/step - loss: 0.0025 - mae: 0.0333 - val_loss: 0.0102 - val_mae: 0.0660\n",
      "Epoch 62/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 11ms/step - loss: 0.0025 - mae: 0.0332 - val_loss: 0.0104 - val_mae: 0.0664\n",
      "Epoch 63/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 11ms/step - loss: 0.0026 - mae: 0.0333 - val_loss: 0.0097 - val_mae: 0.0648\n",
      "Epoch 64/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 11ms/step - loss: 0.0025 - mae: 0.0332 - val_loss: 0.0100 - val_mae: 0.0653\n",
      "Epoch 65/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 11ms/step - loss: 0.0025 - mae: 0.0331 - val_loss: 0.0096 - val_mae: 0.0646\n",
      "Epoch 66/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 11ms/step - loss: 0.0025 - mae: 0.0332 - val_loss: 0.0099 - val_mae: 0.0651\n",
      "Epoch 67/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 11ms/step - loss: 0.0025 - mae: 0.0333 - val_loss: 0.0101 - val_mae: 0.0659\n",
      "Epoch 68/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 11ms/step - loss: 0.0025 - mae: 0.0332 - val_loss: 0.0106 - val_mae: 0.0676\n",
      "Epoch 69/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 11ms/step - loss: 0.0025 - mae: 0.0332 - val_loss: 0.0103 - val_mae: 0.0660\n",
      "Epoch 70/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 11ms/step - loss: 0.0025 - mae: 0.0332 - val_loss: 0.0101 - val_mae: 0.0656\n",
      "Epoch 71/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 11ms/step - loss: 0.0025 - mae: 0.0332 - val_loss: 0.0099 - val_mae: 0.0652\n",
      "Epoch 72/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 11ms/step - loss: 0.0025 - mae: 0.0332 - val_loss: 0.0107 - val_mae: 0.0672\n",
      "Epoch 73/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 11ms/step - loss: 0.0025 - mae: 0.0332 - val_loss: 0.0102 - val_mae: 0.0664\n",
      "Epoch 74/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 11ms/step - loss: 0.0025 - mae: 0.0332 - val_loss: 0.0103 - val_mae: 0.0661\n",
      "Epoch 75/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 11ms/step - loss: 0.0025 - mae: 0.0332 - val_loss: 0.0101 - val_mae: 0.0657\n",
      "Epoch 76/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - loss: 0.0025 - mae: 0.0332 - val_loss: 0.0102 - val_mae: 0.0659\n",
      "Epoch 77/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 11ms/step - loss: 0.0025 - mae: 0.0332 - val_loss: 0.0102 - val_mae: 0.0659\n",
      "Epoch 78/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 11ms/step - loss: 0.0025 - mae: 0.0332 - val_loss: 0.0105 - val_mae: 0.0665\n",
      "Epoch 79/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0025 - mae: 0.0331 - val_loss: 0.0108 - val_mae: 0.0680\n",
      "Epoch 80/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0025 - mae: 0.0331 - val_loss: 0.0101 - val_mae: 0.0658\n",
      "Epoch 81/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 0.0025 - mae: 0.0332 - val_loss: 0.0097 - val_mae: 0.0648\n",
      "Epoch 82/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0025 - mae: 0.0331 - val_loss: 0.0107 - val_mae: 0.0674\n",
      "Epoch 83/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 0.0025 - mae: 0.0332 - val_loss: 0.0098 - val_mae: 0.0651\n",
      "Epoch 84/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 0.0025 - mae: 0.0332 - val_loss: 0.0106 - val_mae: 0.0673\n",
      "Epoch 85/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0025 - mae: 0.0332 - val_loss: 0.0107 - val_mae: 0.0670\n",
      "Epoch 86/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 0.0025 - mae: 0.0331 - val_loss: 0.0103 - val_mae: 0.0660\n",
      "Epoch 87/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0025 - mae: 0.0331 - val_loss: 0.0098 - val_mae: 0.0650\n",
      "Epoch 88/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0025 - mae: 0.0331 - val_loss: 0.0105 - val_mae: 0.0665\n",
      "Epoch 89/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0025 - mae: 0.0331 - val_loss: 0.0104 - val_mae: 0.0663\n",
      "Epoch 90/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 0.0025 - mae: 0.0331 - val_loss: 0.0098 - val_mae: 0.0650\n",
      "Epoch 91/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 13ms/step - loss: 0.0025 - mae: 0.0332 - val_loss: 0.0106 - val_mae: 0.0674\n",
      "Epoch 92/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 13ms/step - loss: 0.0025 - mae: 0.0332 - val_loss: 0.0100 - val_mae: 0.0654\n",
      "Epoch 93/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 14ms/step - loss: 0.0025 - mae: 0.0331 - val_loss: 0.0100 - val_mae: 0.0653\n",
      "Epoch 94/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 14ms/step - loss: 0.0025 - mae: 0.0332 - val_loss: 0.0105 - val_mae: 0.0665\n",
      "Epoch 95/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 13ms/step - loss: 0.0025 - mae: 0.0332 - val_loss: 0.0095 - val_mae: 0.0646\n",
      "Epoch 96/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 13ms/step - loss: 0.0025 - mae: 0.0332 - val_loss: 0.0095 - val_mae: 0.0647\n",
      "Epoch 97/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 14ms/step - loss: 0.0025 - mae: 0.0331 - val_loss: 0.0097 - val_mae: 0.0649\n",
      "Epoch 98/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 14ms/step - loss: 0.0025 - mae: 0.0332 - val_loss: 0.0100 - val_mae: 0.0657\n",
      "Epoch 99/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 14ms/step - loss: 0.0025 - mae: 0.0332 - val_loss: 0.0096 - val_mae: 0.0652\n",
      "Epoch 100/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 14ms/step - loss: 0.0025 - mae: 0.0331 - val_loss: 0.0098 - val_mae: 0.0651\n",
      "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step\n",
      "✅ Done with tomato_Chikmagalur_daily.csv | MAE=434.89, RMSE=693.84, R2=0.4592, MAPE=62.9%, Accuracy=37.1%\n",
      "Saved updated CSV with Date, Actual & Predicted: tat_mqa_output_csv\\tomato_Chikmagalur_daily_tat_mqa_updated.csv\n",
      "🚀 Processing: tomato_Chitradurga_daily.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_query_attention_5       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">17,216</span> │ input_layer_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiQueryAttention</span>)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_query_attention_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                               │                           │                 │ input_layer_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_10        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_57 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ layer_normalization_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_58 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dense_57[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                               │                           │                 │ dense_58[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_11        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_5    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_59 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ global_average_pooling1d_… │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_5 (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_query_attention_5       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │          \u001b[38;5;34m17,216\u001b[0m │ input_layer_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "│ (\u001b[38;5;33mMultiQueryAttention\u001b[0m)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_10 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ multi_query_attention_5[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                               │                           │                 │ input_layer_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_10        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ add_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_57 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │           \u001b[38;5;34m8,320\u001b[0m │ layer_normalization_10[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_58 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │             \u001b[38;5;34m129\u001b[0m │ dense_57[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_11 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_10[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                               │                           │                 │ dense_58[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_11        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ add_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_5    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_11[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_59 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │              \u001b[38;5;34m65\u001b[0m │ global_average_pooling1d_… │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,986</span> (101.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25,986\u001b[0m (101.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,986</span> (101.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m25,986\u001b[0m (101.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 18ms/step - loss: 0.0639 - mae: 0.1633 - val_loss: 0.0045 - val_mae: 0.0668\n",
      "Epoch 2/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 0.0183 - mae: 0.1062 - val_loss: 0.0062 - val_mae: 0.0790\n",
      "Epoch 3/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 0.0115 - mae: 0.0846 - val_loss: 0.0016 - val_mae: 0.0403\n",
      "Epoch 4/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0051 - mae: 0.0537 - val_loss: 5.9544e-04 - val_mae: 0.0244\n",
      "Epoch 5/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 0.0024 - mae: 0.0352 - val_loss: 0.0012 - val_mae: 0.0349\n",
      "Epoch 6/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0020 - mae: 0.0317 - val_loss: 2.1154e-04 - val_mae: 0.0145\n",
      "Epoch 7/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - loss: 0.0012 - mae: 0.0244 - val_loss: 2.7286e-04 - val_mae: 0.0165\n",
      "Epoch 8/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 0.0013 - mae: 0.0244 - val_loss: 2.1239e-04 - val_mae: 0.0146\n",
      "Epoch 9/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 9.6313e-04 - mae: 0.0213 - val_loss: 1.4705e-04 - val_mae: 0.0121\n",
      "Epoch 10/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 0.0010 - mae: 0.0228 - val_loss: 9.0063e-04 - val_mae: 0.0300\n",
      "Epoch 11/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 7.9567e-04 - mae: 0.0190 - val_loss: 0.0011 - val_mae: 0.0336\n",
      "Epoch 12/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 8.3925e-04 - mae: 0.0200 - val_loss: 1.7075e-06 - val_mae: 0.0013\n",
      "Epoch 13/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 8.6125e-04 - mae: 0.0202 - val_loss: 7.3439e-05 - val_mae: 0.0086\n",
      "Epoch 14/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 9.9340e-04 - mae: 0.0224 - val_loss: 7.1267e-05 - val_mae: 0.0084\n",
      "Epoch 15/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 6.7809e-04 - mae: 0.0178 - val_loss: 1.3188e-07 - val_mae: 3.6316e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 6.3292e-04 - mae: 0.0167 - val_loss: 8.4264e-07 - val_mae: 9.1796e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 9.0144e-04 - mae: 0.0202 - val_loss: 1.1592e-05 - val_mae: 0.0034\n",
      "Epoch 18/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 7.7801e-04 - mae: 0.0187 - val_loss: 1.0877e-05 - val_mae: 0.0033\n",
      "Epoch 19/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 9.4486e-04 - mae: 0.0209 - val_loss: 2.8801e-04 - val_mae: 0.0170\n",
      "Epoch 20/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 7.8863e-04 - mae: 0.0193 - val_loss: 6.7184e-05 - val_mae: 0.0082\n",
      "Epoch 21/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 7.3776e-04 - mae: 0.0184 - val_loss: 4.9126e-05 - val_mae: 0.0070\n",
      "Epoch 22/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 6.7111e-04 - mae: 0.0175 - val_loss: 0.0012 - val_mae: 0.0348\n",
      "Epoch 23/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 7.2461e-04 - mae: 0.0186 - val_loss: 3.4656e-06 - val_mae: 0.0019\n",
      "Epoch 24/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 6.9897e-04 - mae: 0.0182 - val_loss: 2.3598e-05 - val_mae: 0.0049\n",
      "Epoch 25/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 7.6337e-04 - mae: 0.0188 - val_loss: 6.8565e-07 - val_mae: 8.2804e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 6.8258e-04 - mae: 0.0177 - val_loss: 3.3226e-04 - val_mae: 0.0182\n",
      "Epoch 27/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - loss: 9.1848e-04 - mae: 0.0211 - val_loss: 3.0386e-05 - val_mae: 0.0055\n",
      "Epoch 28/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 6.2055e-04 - mae: 0.0166 - val_loss: 1.0312e-04 - val_mae: 0.0102\n",
      "Epoch 29/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 6.3402e-04 - mae: 0.0163 - val_loss: 3.2341e-06 - val_mae: 0.0018\n",
      "Epoch 30/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 6.3139e-04 - mae: 0.0171 - val_loss: 2.8778e-05 - val_mae: 0.0054\n",
      "Epoch 31/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 7.0251e-04 - mae: 0.0182 - val_loss: 5.4665e-05 - val_mae: 0.0074\n",
      "Epoch 32/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 6.2852e-04 - mae: 0.0169 - val_loss: 9.3213e-05 - val_mae: 0.0097\n",
      "Epoch 33/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 5.8335e-04 - mae: 0.0162 - val_loss: 1.3413e-07 - val_mae: 3.6624e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 6.9240e-04 - mae: 0.0176 - val_loss: 1.4041e-04 - val_mae: 0.0118\n",
      "Epoch 35/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 6.3047e-04 - mae: 0.0167 - val_loss: 5.7565e-04 - val_mae: 0.0240\n",
      "Epoch 36/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 6.5422e-04 - mae: 0.0174 - val_loss: 3.7197e-05 - val_mae: 0.0061\n",
      "Epoch 37/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 5.7519e-04 - mae: 0.0157 - val_loss: 0.0011 - val_mae: 0.0325\n",
      "Epoch 38/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 7.6548e-04 - mae: 0.0198 - val_loss: 1.2551e-04 - val_mae: 0.0112\n",
      "Epoch 39/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 6.4906e-04 - mae: 0.0176 - val_loss: 3.4599e-04 - val_mae: 0.0186\n",
      "Epoch 40/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 6.3415e-04 - mae: 0.0170 - val_loss: 2.0921e-04 - val_mae: 0.0145\n",
      "Epoch 41/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 5.9210e-04 - mae: 0.0162 - val_loss: 2.8605e-07 - val_mae: 5.3483e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 6.4975e-04 - mae: 0.0178 - val_loss: 5.7921e-04 - val_mae: 0.0241\n",
      "Epoch 43/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 6.8498e-04 - mae: 0.0184 - val_loss: 4.7974e-05 - val_mae: 0.0069\n",
      "Epoch 44/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 6.3588e-04 - mae: 0.0167 - val_loss: 8.7721e-07 - val_mae: 9.3660e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 6.0849e-04 - mae: 0.0164 - val_loss: 1.4354e-04 - val_mae: 0.0120\n",
      "Epoch 46/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 5.8535e-04 - mae: 0.0159 - val_loss: 5.0236e-04 - val_mae: 0.0224\n",
      "Epoch 47/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 6.7424e-04 - mae: 0.0178 - val_loss: 7.4288e-06 - val_mae: 0.0027\n",
      "Epoch 48/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 6.3590e-04 - mae: 0.0175 - val_loss: 1.0946e-04 - val_mae: 0.0105\n",
      "Epoch 49/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 5.7136e-04 - mae: 0.0160 - val_loss: 4.3189e-05 - val_mae: 0.0066\n",
      "Epoch 50/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 5.4947e-04 - mae: 0.0152 - val_loss: 2.6706e-06 - val_mae: 0.0016\n",
      "Epoch 51/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 5.9664e-04 - mae: 0.0164 - val_loss: 3.2671e-06 - val_mae: 0.0018\n",
      "Epoch 52/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 6.6377e-04 - mae: 0.0172 - val_loss: 1.3007e-05 - val_mae: 0.0036\n",
      "Epoch 53/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 5.4630e-04 - mae: 0.0158 - val_loss: 7.7552e-05 - val_mae: 0.0088\n",
      "Epoch 54/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 5.6691e-04 - mae: 0.0159 - val_loss: 5.9312e-06 - val_mae: 0.0024\n",
      "Epoch 55/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 7.0375e-04 - mae: 0.0182 - val_loss: 4.4166e-04 - val_mae: 0.0210\n",
      "Epoch 56/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 5.3756e-04 - mae: 0.0152 - val_loss: 1.0236e-04 - val_mae: 0.0101\n",
      "Epoch 57/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 6.1294e-04 - mae: 0.0165 - val_loss: 7.2785e-06 - val_mae: 0.0027\n",
      "Epoch 58/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 5.3074e-04 - mae: 0.0149 - val_loss: 7.2386e-04 - val_mae: 0.0269\n",
      "Epoch 59/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 5.8072e-04 - mae: 0.0159 - val_loss: 3.8850e-05 - val_mae: 0.0062\n",
      "Epoch 60/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 5.1693e-04 - mae: 0.0148 - val_loss: 2.8290e-04 - val_mae: 0.0168\n",
      "Epoch 61/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 5.3341e-04 - mae: 0.0150 - val_loss: 8.2890e-05 - val_mae: 0.0091\n",
      "Epoch 62/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 5.6836e-04 - mae: 0.0153 - val_loss: 1.6079e-04 - val_mae: 0.0127\n",
      "Epoch 63/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 5.9128e-04 - mae: 0.0163 - val_loss: 4.0658e-05 - val_mae: 0.0064\n",
      "Epoch 64/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 5.7223e-04 - mae: 0.0162 - val_loss: 5.6723e-04 - val_mae: 0.0238\n",
      "Epoch 65/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 5.6958e-04 - mae: 0.0156 - val_loss: 6.8515e-05 - val_mae: 0.0083\n",
      "Epoch 66/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 5.3952e-04 - mae: 0.0152 - val_loss: 6.8893e-05 - val_mae: 0.0083\n",
      "Epoch 67/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 5.4430e-04 - mae: 0.0150 - val_loss: 4.4077e-05 - val_mae: 0.0066\n",
      "Epoch 68/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 6.0524e-04 - mae: 0.0167 - val_loss: 5.9634e-05 - val_mae: 0.0077\n",
      "Epoch 69/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 5.7173e-04 - mae: 0.0161 - val_loss: 4.9777e-06 - val_mae: 0.0022\n",
      "Epoch 70/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 5.5817e-04 - mae: 0.0159 - val_loss: 3.0629e-04 - val_mae: 0.0175\n",
      "Epoch 71/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 5.5956e-04 - mae: 0.0158 - val_loss: 5.8469e-05 - val_mae: 0.0076\n",
      "Epoch 72/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 5.3265e-04 - mae: 0.0151 - val_loss: 1.4991e-04 - val_mae: 0.0122\n",
      "Epoch 73/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 5.4719e-04 - mae: 0.0153 - val_loss: 2.0602e-04 - val_mae: 0.0144\n",
      "Epoch 74/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 5.5592e-04 - mae: 0.0154 - val_loss: 8.7976e-04 - val_mae: 0.0297\n",
      "Epoch 75/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 5.2941e-04 - mae: 0.0151 - val_loss: 3.4152e-04 - val_mae: 0.0185\n",
      "Epoch 76/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 5.6528e-04 - mae: 0.0154 - val_loss: 4.3628e-05 - val_mae: 0.0066\n",
      "Epoch 77/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 5.2520e-04 - mae: 0.0149 - val_loss: 4.2862e-05 - val_mae: 0.0065\n",
      "Epoch 78/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 5.2667e-04 - mae: 0.0154 - val_loss: 2.0433e-05 - val_mae: 0.0045\n",
      "Epoch 79/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 5.8968e-04 - mae: 0.0164 - val_loss: 2.2445e-05 - val_mae: 0.0047\n",
      "Epoch 80/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 6.3203e-04 - mae: 0.0171 - val_loss: 2.3783e-04 - val_mae: 0.0154\n",
      "Epoch 81/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 6.1473e-04 - mae: 0.0174 - val_loss: 1.8142e-08 - val_mae: 1.3469e-04\n",
      "Epoch 82/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 5.0664e-04 - mae: 0.0149 - val_loss: 2.4766e-06 - val_mae: 0.0016\n",
      "Epoch 83/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 5.2498e-04 - mae: 0.0151 - val_loss: 2.1544e-04 - val_mae: 0.0147\n",
      "Epoch 84/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 5.2305e-04 - mae: 0.0147 - val_loss: 8.8890e-05 - val_mae: 0.0094\n",
      "Epoch 85/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 5.5065e-04 - mae: 0.0156 - val_loss: 4.1970e-05 - val_mae: 0.0065\n",
      "Epoch 86/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 5.5097e-04 - mae: 0.0160 - val_loss: 2.7756e-05 - val_mae: 0.0053\n",
      "Epoch 87/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 5.7127e-04 - mae: 0.0158 - val_loss: 7.0696e-04 - val_mae: 0.0266\n",
      "Epoch 88/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 5.3031e-04 - mae: 0.0152 - val_loss: 2.8280e-04 - val_mae: 0.0168\n",
      "Epoch 89/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 4.9813e-04 - mae: 0.0144 - val_loss: 2.1927e-04 - val_mae: 0.0148\n",
      "Epoch 90/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 5.3748e-04 - mae: 0.0151 - val_loss: 2.8987e-06 - val_mae: 0.0017\n",
      "Epoch 91/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 5.7887e-04 - mae: 0.0158 - val_loss: 4.8230e-05 - val_mae: 0.0069\n",
      "Epoch 92/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 5.4551e-04 - mae: 0.0155 - val_loss: 8.5577e-07 - val_mae: 9.2508e-04\n",
      "Epoch 93/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 5.8460e-04 - mae: 0.0165 - val_loss: 3.9300e-04 - val_mae: 0.0198\n",
      "Epoch 94/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 5.2209e-04 - mae: 0.0153 - val_loss: 2.7895e-04 - val_mae: 0.0167\n",
      "Epoch 95/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 5.1463e-04 - mae: 0.0147 - val_loss: 2.2524e-06 - val_mae: 0.0015\n",
      "Epoch 96/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 4.8131e-04 - mae: 0.0138 - val_loss: 3.2378e-04 - val_mae: 0.0180\n",
      "Epoch 97/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 5.2882e-04 - mae: 0.0155 - val_loss: 0.0015 - val_mae: 0.0381\n",
      "Epoch 98/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 5.2432e-04 - mae: 0.0150 - val_loss: 3.8799e-04 - val_mae: 0.0197\n",
      "Epoch 99/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 5.0874e-04 - mae: 0.0146 - val_loss: 3.2724e-05 - val_mae: 0.0057\n",
      "Epoch 100/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - loss: 5.7230e-04 - mae: 0.0166 - val_loss: 2.1485e-04 - val_mae: 0.0147\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step   \n",
      "✅ Done with tomato_Chitradurga_daily.csv | MAE=114.5, RMSE=157.55, R2=0.9762, MAPE=11.27%, Accuracy=88.73%\n",
      "Saved updated CSV with Date, Actual & Predicted: tat_mqa_output_csv\\tomato_Chitradurga_daily_tat_mqa_updated.csv\n",
      "🚀 Processing: tomato_Davangere_daily.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_query_attention_6       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">17,216</span> │ input_layer_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiQueryAttention</span>)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_query_attention_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                               │                           │                 │ input_layer_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_12        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_67 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ layer_normalization_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_68 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dense_67[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                               │                           │                 │ dense_68[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_13        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_6    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_69 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ global_average_pooling1d_… │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_6 (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_query_attention_6       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │          \u001b[38;5;34m17,216\u001b[0m │ input_layer_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "│ (\u001b[38;5;33mMultiQueryAttention\u001b[0m)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_12 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ multi_query_attention_6[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                               │                           │                 │ input_layer_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_12        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ add_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_67 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │           \u001b[38;5;34m8,320\u001b[0m │ layer_normalization_12[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_68 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │             \u001b[38;5;34m129\u001b[0m │ dense_67[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_13 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_12[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                               │                           │                 │ dense_68[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_13        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ add_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_6    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_13[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_69 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │              \u001b[38;5;34m65\u001b[0m │ global_average_pooling1d_… │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,986</span> (101.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25,986\u001b[0m (101.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,986</span> (101.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m25,986\u001b[0m (101.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 15ms/step - loss: 0.0336 - mae: 0.1030 - val_loss: 0.0193 - val_mae: 0.1077\n",
      "Epoch 2/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - loss: 0.0071 - mae: 0.0648 - val_loss: 0.0188 - val_mae: 0.0777\n",
      "Epoch 3/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0058 - mae: 0.0574 - val_loss: 0.0170 - val_mae: 0.0947\n",
      "Epoch 4/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0049 - mae: 0.0524 - val_loss: 0.0165 - val_mae: 0.0729\n",
      "Epoch 5/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 0.0045 - mae: 0.0494 - val_loss: 0.0157 - val_mae: 0.0752\n",
      "Epoch 6/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0042 - mae: 0.0483 - val_loss: 0.0164 - val_mae: 0.0738\n",
      "Epoch 7/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0042 - mae: 0.0479 - val_loss: 0.0125 - val_mae: 0.0762\n",
      "Epoch 8/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0040 - mae: 0.0465 - val_loss: 0.0123 - val_mae: 0.0697\n",
      "Epoch 9/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - loss: 0.0039 - mae: 0.0453 - val_loss: 0.0116 - val_mae: 0.0674\n",
      "Epoch 10/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0039 - mae: 0.0465 - val_loss: 0.0102 - val_mae: 0.0638\n",
      "Epoch 11/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0037 - mae: 0.0441 - val_loss: 0.0112 - val_mae: 0.0647\n",
      "Epoch 12/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0037 - mae: 0.0441 - val_loss: 0.0102 - val_mae: 0.0675\n",
      "Epoch 13/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0037 - mae: 0.0439 - val_loss: 0.0099 - val_mae: 0.0637\n",
      "Epoch 14/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0037 - mae: 0.0442 - val_loss: 0.0099 - val_mae: 0.0616\n",
      "Epoch 15/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 0.0036 - mae: 0.0438 - val_loss: 0.0099 - val_mae: 0.0628\n",
      "Epoch 16/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0036 - mae: 0.0436 - val_loss: 0.0101 - val_mae: 0.0634\n",
      "Epoch 17/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 0.0036 - mae: 0.0432 - val_loss: 0.0105 - val_mae: 0.0619\n",
      "Epoch 18/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0037 - mae: 0.0440 - val_loss: 0.0105 - val_mae: 0.0707\n",
      "Epoch 19/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0037 - mae: 0.0441 - val_loss: 0.0107 - val_mae: 0.0716\n",
      "Epoch 20/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0036 - mae: 0.0435 - val_loss: 0.0100 - val_mae: 0.0612\n",
      "Epoch 21/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0036 - mae: 0.0441 - val_loss: 0.0100 - val_mae: 0.0624\n",
      "Epoch 22/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0035 - mae: 0.0428 - val_loss: 0.0104 - val_mae: 0.0641\n",
      "Epoch 23/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0035 - mae: 0.0430 - val_loss: 0.0104 - val_mae: 0.0619\n",
      "Epoch 24/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0036 - mae: 0.0439 - val_loss: 0.0124 - val_mae: 0.0825\n",
      "Epoch 25/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0036 - mae: 0.0433 - val_loss: 0.0099 - val_mae: 0.0650\n",
      "Epoch 26/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0035 - mae: 0.0425 - val_loss: 0.0098 - val_mae: 0.0625\n",
      "Epoch 27/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0035 - mae: 0.0433 - val_loss: 0.0098 - val_mae: 0.0621\n",
      "Epoch 28/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0035 - mae: 0.0431 - val_loss: 0.0112 - val_mae: 0.0786\n",
      "Epoch 29/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0035 - mae: 0.0429 - val_loss: 0.0107 - val_mae: 0.0641\n",
      "Epoch 30/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - loss: 0.0035 - mae: 0.0432 - val_loss: 0.0098 - val_mae: 0.0636\n",
      "Epoch 31/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0035 - mae: 0.0423 - val_loss: 0.0111 - val_mae: 0.0661\n",
      "Epoch 32/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0035 - mae: 0.0423 - val_loss: 0.0104 - val_mae: 0.0671\n",
      "Epoch 33/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0035 - mae: 0.0425 - val_loss: 0.0106 - val_mae: 0.0646\n",
      "Epoch 34/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0035 - mae: 0.0425 - val_loss: 0.0111 - val_mae: 0.0758\n",
      "Epoch 35/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0036 - mae: 0.0432 - val_loss: 0.0104 - val_mae: 0.0640\n",
      "Epoch 36/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - loss: 0.0035 - mae: 0.0427 - val_loss: 0.0106 - val_mae: 0.0651\n",
      "Epoch 37/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0035 - mae: 0.0422 - val_loss: 0.0099 - val_mae: 0.0637\n",
      "Epoch 38/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - loss: 0.0035 - mae: 0.0425 - val_loss: 0.0099 - val_mae: 0.0655\n",
      "Epoch 39/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0034 - mae: 0.0419 - val_loss: 0.0100 - val_mae: 0.0637\n",
      "Epoch 40/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0034 - mae: 0.0421 - val_loss: 0.0103 - val_mae: 0.0688\n",
      "Epoch 41/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0035 - mae: 0.0428 - val_loss: 0.0099 - val_mae: 0.0616\n",
      "Epoch 42/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - loss: 0.0034 - mae: 0.0423 - val_loss: 0.0099 - val_mae: 0.0641\n",
      "Epoch 43/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0035 - mae: 0.0423 - val_loss: 0.0099 - val_mae: 0.0624\n",
      "Epoch 44/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0034 - mae: 0.0421 - val_loss: 0.0100 - val_mae: 0.0620\n",
      "Epoch 45/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0035 - mae: 0.0423 - val_loss: 0.0099 - val_mae: 0.0645\n",
      "Epoch 46/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0034 - mae: 0.0420 - val_loss: 0.0103 - val_mae: 0.0628\n",
      "Epoch 47/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0035 - mae: 0.0424 - val_loss: 0.0104 - val_mae: 0.0662\n",
      "Epoch 48/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0035 - mae: 0.0423 - val_loss: 0.0099 - val_mae: 0.0620\n",
      "Epoch 49/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0034 - mae: 0.0422 - val_loss: 0.0105 - val_mae: 0.0714\n",
      "Epoch 50/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0035 - mae: 0.0423 - val_loss: 0.0102 - val_mae: 0.0630\n",
      "Epoch 51/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0034 - mae: 0.0422 - val_loss: 0.0101 - val_mae: 0.0631\n",
      "Epoch 52/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0035 - mae: 0.0425 - val_loss: 0.0099 - val_mae: 0.0625\n",
      "Epoch 53/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - loss: 0.0034 - mae: 0.0419 - val_loss: 0.0100 - val_mae: 0.0660\n",
      "Epoch 54/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0034 - mae: 0.0417 - val_loss: 0.0099 - val_mae: 0.0625\n",
      "Epoch 55/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0035 - mae: 0.0425 - val_loss: 0.0101 - val_mae: 0.0653\n",
      "Epoch 56/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - loss: 0.0034 - mae: 0.0418 - val_loss: 0.0102 - val_mae: 0.0668\n",
      "Epoch 57/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0034 - mae: 0.0422 - val_loss: 0.0100 - val_mae: 0.0644\n",
      "Epoch 58/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - loss: 0.0034 - mae: 0.0420 - val_loss: 0.0104 - val_mae: 0.0622\n",
      "Epoch 59/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0034 - mae: 0.0420 - val_loss: 0.0101 - val_mae: 0.0619\n",
      "Epoch 60/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0034 - mae: 0.0421 - val_loss: 0.0101 - val_mae: 0.0635\n",
      "Epoch 61/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0034 - mae: 0.0419 - val_loss: 0.0102 - val_mae: 0.0638\n",
      "Epoch 62/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0034 - mae: 0.0422 - val_loss: 0.0100 - val_mae: 0.0629\n",
      "Epoch 63/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0034 - mae: 0.0418 - val_loss: 0.0103 - val_mae: 0.0621\n",
      "Epoch 64/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0034 - mae: 0.0417 - val_loss: 0.0102 - val_mae: 0.0648\n",
      "Epoch 65/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0034 - mae: 0.0422 - val_loss: 0.0101 - val_mae: 0.0653\n",
      "Epoch 66/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0034 - mae: 0.0418 - val_loss: 0.0101 - val_mae: 0.0633\n",
      "Epoch 67/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0034 - mae: 0.0419 - val_loss: 0.0103 - val_mae: 0.0657\n",
      "Epoch 68/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0034 - mae: 0.0421 - val_loss: 0.0102 - val_mae: 0.0635\n",
      "Epoch 69/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0034 - mae: 0.0415 - val_loss: 0.0105 - val_mae: 0.0672\n",
      "Epoch 70/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0034 - mae: 0.0419 - val_loss: 0.0105 - val_mae: 0.0665\n",
      "Epoch 71/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0034 - mae: 0.0416 - val_loss: 0.0104 - val_mae: 0.0651\n",
      "Epoch 72/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0034 - mae: 0.0419 - val_loss: 0.0104 - val_mae: 0.0643\n",
      "Epoch 73/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0034 - mae: 0.0417 - val_loss: 0.0105 - val_mae: 0.0655\n",
      "Epoch 74/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0034 - mae: 0.0415 - val_loss: 0.0106 - val_mae: 0.0678\n",
      "Epoch 75/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0034 - mae: 0.0420 - val_loss: 0.0105 - val_mae: 0.0653\n",
      "Epoch 76/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0034 - mae: 0.0415 - val_loss: 0.0106 - val_mae: 0.0673\n",
      "Epoch 77/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0034 - mae: 0.0416 - val_loss: 0.0106 - val_mae: 0.0681\n",
      "Epoch 78/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - loss: 0.0034 - mae: 0.0417 - val_loss: 0.0105 - val_mae: 0.0659\n",
      "Epoch 79/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0034 - mae: 0.0414 - val_loss: 0.0110 - val_mae: 0.0718\n",
      "Epoch 80/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0034 - mae: 0.0416 - val_loss: 0.0105 - val_mae: 0.0642\n",
      "Epoch 81/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - loss: 0.0034 - mae: 0.0417 - val_loss: 0.0105 - val_mae: 0.0656\n",
      "Epoch 82/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0034 - mae: 0.0415 - val_loss: 0.0107 - val_mae: 0.0672\n",
      "Epoch 83/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0034 - mae: 0.0415 - val_loss: 0.0105 - val_mae: 0.0632\n",
      "Epoch 84/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0034 - mae: 0.0415 - val_loss: 0.0111 - val_mae: 0.0697\n",
      "Epoch 85/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0034 - mae: 0.0414 - val_loss: 0.0108 - val_mae: 0.0680\n",
      "Epoch 86/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - loss: 0.0034 - mae: 0.0414 - val_loss: 0.0110 - val_mae: 0.0707\n",
      "Epoch 87/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0034 - mae: 0.0415 - val_loss: 0.0106 - val_mae: 0.0647\n",
      "Epoch 88/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0034 - mae: 0.0416 - val_loss: 0.0109 - val_mae: 0.0667\n",
      "Epoch 89/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0034 - mae: 0.0418 - val_loss: 0.0107 - val_mae: 0.0629\n",
      "Epoch 90/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0034 - mae: 0.0416 - val_loss: 0.0106 - val_mae: 0.0686\n",
      "Epoch 91/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0034 - mae: 0.0414 - val_loss: 0.0106 - val_mae: 0.0665\n",
      "Epoch 92/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0034 - mae: 0.0413 - val_loss: 0.0109 - val_mae: 0.0692\n",
      "Epoch 93/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0034 - mae: 0.0417 - val_loss: 0.0112 - val_mae: 0.0717\n",
      "Epoch 94/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0034 - mae: 0.0415 - val_loss: 0.0107 - val_mae: 0.0662\n",
      "Epoch 95/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - loss: 0.0034 - mae: 0.0412 - val_loss: 0.0104 - val_mae: 0.0649\n",
      "Epoch 96/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0034 - mae: 0.0414 - val_loss: 0.0105 - val_mae: 0.0632\n",
      "Epoch 97/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0034 - mae: 0.0414 - val_loss: 0.0111 - val_mae: 0.0632\n",
      "Epoch 98/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - loss: 0.0034 - mae: 0.0414 - val_loss: 0.0105 - val_mae: 0.0666\n",
      "Epoch 99/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0033 - mae: 0.0412 - val_loss: 0.0103 - val_mae: 0.0640\n",
      "Epoch 100/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0034 - mae: 0.0413 - val_loss: 0.0102 - val_mae: 0.0643\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step\n",
      "✅ Done with tomato_Davangere_daily.csv | MAE=377.63, RMSE=564.49, R2=0.6363, MAPE=52.97%, Accuracy=47.03%\n",
      "Saved updated CSV with Date, Actual & Predicted: tat_mqa_output_csv\\tomato_Davangere_daily_tat_mqa_updated.csv\n",
      "🚀 Processing: tomato_Dharwad_daily.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_7\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_7\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_query_attention_7       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">17,216</span> │ input_layer_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiQueryAttention</span>)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_query_attention_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                               │                           │                 │ input_layer_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_14        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_77 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ layer_normalization_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_78 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dense_77[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                               │                           │                 │ dense_78[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_15        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_7    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_79 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ global_average_pooling1d_… │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_7 (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_query_attention_7       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │          \u001b[38;5;34m17,216\u001b[0m │ input_layer_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "│ (\u001b[38;5;33mMultiQueryAttention\u001b[0m)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_14 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ multi_query_attention_7[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                               │                           │                 │ input_layer_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_14        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ add_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_77 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │           \u001b[38;5;34m8,320\u001b[0m │ layer_normalization_14[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_78 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │             \u001b[38;5;34m129\u001b[0m │ dense_77[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_15 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_14[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                               │                           │                 │ dense_78[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_15        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ add_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_7    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_15[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_79 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │              \u001b[38;5;34m65\u001b[0m │ global_average_pooling1d_… │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,986</span> (101.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25,986\u001b[0m (101.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,986</span> (101.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m25,986\u001b[0m (101.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 31ms/step - loss: 0.0806 - mae: 0.1880 - val_loss: 0.0385 - val_mae: 0.1441\n",
      "Epoch 2/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0101 - mae: 0.0769 - val_loss: 0.0390 - val_mae: 0.0875\n",
      "Epoch 3/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0077 - mae: 0.0678 - val_loss: 0.0394 - val_mae: 0.0956\n",
      "Epoch 4/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0069 - mae: 0.0647 - val_loss: 0.0392 - val_mae: 0.0901\n",
      "Epoch 5/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0077 - mae: 0.0679 - val_loss: 0.0403 - val_mae: 0.0871\n",
      "Epoch 6/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0054 - mae: 0.0541 - val_loss: 0.0408 - val_mae: 0.0774\n",
      "Epoch 7/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0053 - mae: 0.0526 - val_loss: 0.0427 - val_mae: 0.0749\n",
      "Epoch 8/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0051 - mae: 0.0525 - val_loss: 0.0365 - val_mae: 0.1296\n",
      "Epoch 9/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0047 - mae: 0.0479 - val_loss: 0.0390 - val_mae: 0.0935\n",
      "Epoch 10/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0042 - mae: 0.0437 - val_loss: 0.0433 - val_mae: 0.0786\n",
      "Epoch 11/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0042 - mae: 0.0435 - val_loss: 0.0406 - val_mae: 0.0911\n",
      "Epoch 12/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0037 - mae: 0.0403 - val_loss: 0.0423 - val_mae: 0.0738\n",
      "Epoch 13/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0040 - mae: 0.0412 - val_loss: 0.0414 - val_mae: 0.0824\n",
      "Epoch 14/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0037 - mae: 0.0392 - val_loss: 0.0410 - val_mae: 0.0867\n",
      "Epoch 15/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0036 - mae: 0.0376 - val_loss: 0.0402 - val_mae: 0.0903\n",
      "Epoch 16/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0039 - mae: 0.0408 - val_loss: 0.0500 - val_mae: 0.1107\n",
      "Epoch 17/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0038 - mae: 0.0397 - val_loss: 0.0405 - val_mae: 0.0883\n",
      "Epoch 18/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0034 - mae: 0.0347 - val_loss: 0.0377 - val_mae: 0.1057\n",
      "Epoch 19/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0034 - mae: 0.0348 - val_loss: 0.0415 - val_mae: 0.0811\n",
      "Epoch 20/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0034 - mae: 0.0358 - val_loss: 0.0392 - val_mae: 0.0950\n",
      "Epoch 21/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0035 - mae: 0.0373 - val_loss: 0.0389 - val_mae: 0.0968\n",
      "Epoch 22/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0036 - mae: 0.0384 - val_loss: 0.0385 - val_mae: 0.1062\n",
      "Epoch 23/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0035 - mae: 0.0367 - val_loss: 0.0401 - val_mae: 0.0859\n",
      "Epoch 24/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0033 - mae: 0.0332 - val_loss: 0.0384 - val_mae: 0.1004\n",
      "Epoch 25/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0033 - mae: 0.0349 - val_loss: 0.0409 - val_mae: 0.0871\n",
      "Epoch 26/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0032 - mae: 0.0341 - val_loss: 0.0392 - val_mae: 0.0953\n",
      "Epoch 27/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0032 - mae: 0.0325 - val_loss: 0.0389 - val_mae: 0.0979\n",
      "Epoch 28/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0033 - mae: 0.0329 - val_loss: 0.0406 - val_mae: 0.0886\n",
      "Epoch 29/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0031 - mae: 0.0310 - val_loss: 0.0392 - val_mae: 0.0978\n",
      "Epoch 30/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0033 - mae: 0.0336 - val_loss: 0.0395 - val_mae: 0.0968\n",
      "Epoch 31/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0032 - mae: 0.0310 - val_loss: 0.0380 - val_mae: 0.1068\n",
      "Epoch 32/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0031 - mae: 0.0294 - val_loss: 0.0382 - val_mae: 0.1082\n",
      "Epoch 33/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0033 - mae: 0.0329 - val_loss: 0.0413 - val_mae: 0.0823\n",
      "Epoch 34/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0033 - mae: 0.0346 - val_loss: 0.0403 - val_mae: 0.0908\n",
      "Epoch 35/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0031 - mae: 0.0311 - val_loss: 0.0396 - val_mae: 0.0962\n",
      "Epoch 36/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0034 - mae: 0.0352 - val_loss: 0.0381 - val_mae: 0.1042\n",
      "Epoch 37/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0033 - mae: 0.0342 - val_loss: 0.0373 - val_mae: 0.1117\n",
      "Epoch 38/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0030 - mae: 0.0299 - val_loss: 0.0413 - val_mae: 0.0778\n",
      "Epoch 39/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0030 - mae: 0.0305 - val_loss: 0.0394 - val_mae: 0.0964\n",
      "Epoch 40/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0030 - mae: 0.0288 - val_loss: 0.0386 - val_mae: 0.1044\n",
      "Epoch 41/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0032 - mae: 0.0308 - val_loss: 0.0396 - val_mae: 0.0894\n",
      "Epoch 42/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0033 - mae: 0.0336 - val_loss: 0.0403 - val_mae: 0.0901\n",
      "Epoch 43/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0031 - mae: 0.0328 - val_loss: 0.0373 - val_mae: 0.1188\n",
      "Epoch 44/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0031 - mae: 0.0316 - val_loss: 0.0383 - val_mae: 0.1053\n",
      "Epoch 45/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0031 - mae: 0.0306 - val_loss: 0.0407 - val_mae: 0.0796\n",
      "Epoch 46/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0030 - mae: 0.0309 - val_loss: 0.0384 - val_mae: 0.1009\n",
      "Epoch 47/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0034 - mae: 0.0364 - val_loss: 0.0370 - val_mae: 0.1240\n",
      "Epoch 48/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0031 - mae: 0.0318 - val_loss: 0.0387 - val_mae: 0.1043\n",
      "Epoch 49/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0031 - mae: 0.0308 - val_loss: 0.0371 - val_mae: 0.1161\n",
      "Epoch 50/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0033 - mae: 0.0337 - val_loss: 0.0382 - val_mae: 0.1051\n",
      "Epoch 51/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0030 - mae: 0.0289 - val_loss: 0.0405 - val_mae: 0.0812\n",
      "Epoch 52/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0030 - mae: 0.0295 - val_loss: 0.0404 - val_mae: 0.0832\n",
      "Epoch 53/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0031 - mae: 0.0293 - val_loss: 0.0391 - val_mae: 0.0972\n",
      "Epoch 54/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0033 - mae: 0.0350 - val_loss: 0.0378 - val_mae: 0.1018\n",
      "Epoch 55/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0032 - mae: 0.0319 - val_loss: 0.0374 - val_mae: 0.1130\n",
      "Epoch 56/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0031 - mae: 0.0303 - val_loss: 0.0405 - val_mae: 0.0851\n",
      "Epoch 57/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0034 - mae: 0.0345 - val_loss: 0.0394 - val_mae: 0.0907\n",
      "Epoch 58/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0030 - mae: 0.0283 - val_loss: 0.0399 - val_mae: 0.0859\n",
      "Epoch 59/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0031 - mae: 0.0308 - val_loss: 0.0384 - val_mae: 0.0926\n",
      "Epoch 60/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0031 - mae: 0.0283 - val_loss: 0.0420 - val_mae: 0.0756\n",
      "Epoch 61/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0031 - mae: 0.0314 - val_loss: 0.0449 - val_mae: 0.0898\n",
      "Epoch 62/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0030 - mae: 0.0288 - val_loss: 0.0393 - val_mae: 0.0891\n",
      "Epoch 63/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0029 - mae: 0.0273 - val_loss: 0.0398 - val_mae: 0.0880\n",
      "Epoch 64/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0032 - mae: 0.0329 - val_loss: 0.0383 - val_mae: 0.1067\n",
      "Epoch 65/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0031 - mae: 0.0299 - val_loss: 0.0417 - val_mae: 0.0751\n",
      "Epoch 66/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0032 - mae: 0.0322 - val_loss: 0.0433 - val_mae: 0.0793\n",
      "Epoch 67/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0031 - mae: 0.0307 - val_loss: 0.0391 - val_mae: 0.0963\n",
      "Epoch 68/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0030 - mae: 0.0298 - val_loss: 0.0413 - val_mae: 0.0813\n",
      "Epoch 69/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0030 - mae: 0.0287 - val_loss: 0.0399 - val_mae: 0.0852\n",
      "Epoch 70/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0031 - mae: 0.0311 - val_loss: 0.0408 - val_mae: 0.0843\n",
      "Epoch 71/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0031 - mae: 0.0306 - val_loss: 0.0418 - val_mae: 0.0743\n",
      "Epoch 72/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0032 - mae: 0.0331 - val_loss: 0.0369 - val_mae: 0.1110\n",
      "Epoch 73/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0032 - mae: 0.0315 - val_loss: 0.0385 - val_mae: 0.0948\n",
      "Epoch 74/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0032 - mae: 0.0335 - val_loss: 0.0414 - val_mae: 0.0808\n",
      "Epoch 75/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0031 - mae: 0.0319 - val_loss: 0.0385 - val_mae: 0.0965\n",
      "Epoch 76/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0031 - mae: 0.0308 - val_loss: 0.0380 - val_mae: 0.0991\n",
      "Epoch 77/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0028 - mae: 0.0250 - val_loss: 0.0384 - val_mae: 0.0972\n",
      "Epoch 78/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0029 - mae: 0.0268 - val_loss: 0.0429 - val_mae: 0.0770\n",
      "Epoch 79/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0032 - mae: 0.0313 - val_loss: 0.0390 - val_mae: 0.0935\n",
      "Epoch 80/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0031 - mae: 0.0295 - val_loss: 0.0382 - val_mae: 0.0960\n",
      "Epoch 81/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0030 - mae: 0.0323 - val_loss: 0.0387 - val_mae: 0.0936\n",
      "Epoch 82/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0033 - mae: 0.0328 - val_loss: 0.0374 - val_mae: 0.1043\n",
      "Epoch 83/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0030 - mae: 0.0290 - val_loss: 0.0392 - val_mae: 0.0910\n",
      "Epoch 84/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0031 - mae: 0.0287 - val_loss: 0.0420 - val_mae: 0.0758\n",
      "Epoch 85/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0029 - mae: 0.0264 - val_loss: 0.0384 - val_mae: 0.0941\n",
      "Epoch 86/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0029 - mae: 0.0251 - val_loss: 0.0417 - val_mae: 0.0743\n",
      "Epoch 87/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0030 - mae: 0.0277 - val_loss: 0.0380 - val_mae: 0.0966\n",
      "Epoch 88/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0034 - mae: 0.0355 - val_loss: 0.0393 - val_mae: 0.0913\n",
      "Epoch 89/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0029 - mae: 0.0272 - val_loss: 0.0406 - val_mae: 0.0849\n",
      "Epoch 90/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0029 - mae: 0.0277 - val_loss: 0.0375 - val_mae: 0.1064\n",
      "Epoch 91/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0030 - mae: 0.0271 - val_loss: 0.0400 - val_mae: 0.0862\n",
      "Epoch 92/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0028 - mae: 0.0264 - val_loss: 0.0395 - val_mae: 0.0894\n",
      "Epoch 93/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0032 - mae: 0.0328 - val_loss: 0.0419 - val_mae: 0.0737\n",
      "Epoch 94/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0029 - mae: 0.0261 - val_loss: 0.0386 - val_mae: 0.0980\n",
      "Epoch 95/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0030 - mae: 0.0292 - val_loss: 0.0401 - val_mae: 0.0868\n",
      "Epoch 96/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0030 - mae: 0.0298 - val_loss: 0.0395 - val_mae: 0.0878\n",
      "Epoch 97/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0030 - mae: 0.0281 - val_loss: 0.0384 - val_mae: 0.0981\n",
      "Epoch 98/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0029 - mae: 0.0264 - val_loss: 0.0386 - val_mae: 0.0939\n",
      "Epoch 99/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0030 - mae: 0.0284 - val_loss: 0.0411 - val_mae: 0.0811\n",
      "Epoch 100/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0031 - mae: 0.0316 - val_loss: 0.0413 - val_mae: 0.0748\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step  \n",
      "✅ Done with tomato_Dharwad_daily.csv | MAE=222.27, RMSE=733.02, R2=0.2665, MAPE=12.07%, Accuracy=87.93%\n",
      "Saved updated CSV with Date, Actual & Predicted: tat_mqa_output_csv\\tomato_Dharwad_daily_tat_mqa_updated.csv\n",
      "🚀 Processing: tomato_Gadag_daily.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_8\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_8\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_query_attention_8       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">17,216</span> │ input_layer_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiQueryAttention</span>)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_query_attention_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                               │                           │                 │ input_layer_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_16        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_87 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ layer_normalization_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_88 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dense_87[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                               │                           │                 │ dense_88[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_17        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_8    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_89 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ global_average_pooling1d_… │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_8 (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_query_attention_8       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │          \u001b[38;5;34m17,216\u001b[0m │ input_layer_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "│ (\u001b[38;5;33mMultiQueryAttention\u001b[0m)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_16 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ multi_query_attention_8[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                               │                           │                 │ input_layer_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_16        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ add_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_87 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │           \u001b[38;5;34m8,320\u001b[0m │ layer_normalization_16[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_88 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │             \u001b[38;5;34m129\u001b[0m │ dense_87[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_17 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_16[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                               │                           │                 │ dense_88[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_17        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ add_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_8    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_17[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_89 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │              \u001b[38;5;34m65\u001b[0m │ global_average_pooling1d_… │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,986</span> (101.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25,986\u001b[0m (101.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,986</span> (101.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m25,986\u001b[0m (101.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 28ms/step - loss: 0.1327 - mae: 0.2574 - val_loss: 0.0278 - val_mae: 0.1593\n",
      "Epoch 2/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0218 - mae: 0.1203 - val_loss: 0.0693 - val_mae: 0.2530\n",
      "Epoch 3/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0205 - mae: 0.1166 - val_loss: 0.0377 - val_mae: 0.1871\n",
      "Epoch 4/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0187 - mae: 0.1124 - val_loss: 0.0489 - val_mae: 0.2132\n",
      "Epoch 5/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0161 - mae: 0.1017 - val_loss: 0.0516 - val_mae: 0.2190\n",
      "Epoch 6/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0143 - mae: 0.0946 - val_loss: 0.0424 - val_mae: 0.1987\n",
      "Epoch 7/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0120 - mae: 0.0853 - val_loss: 0.0244 - val_mae: 0.1498\n",
      "Epoch 8/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0107 - mae: 0.0794 - val_loss: 0.0163 - val_mae: 0.1189\n",
      "Epoch 9/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0090 - mae: 0.0724 - val_loss: 0.0158 - val_mae: 0.1174\n",
      "Epoch 10/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0082 - mae: 0.0677 - val_loss: 0.0157 - val_mae: 0.1176\n",
      "Epoch 11/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0082 - mae: 0.0652 - val_loss: 0.0146 - val_mae: 0.1125\n",
      "Epoch 12/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0082 - mae: 0.0667 - val_loss: 0.0107 - val_mae: 0.0896\n",
      "Epoch 13/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0067 - mae: 0.0573 - val_loss: 0.0170 - val_mae: 0.1256\n",
      "Epoch 14/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0064 - mae: 0.0561 - val_loss: 0.0091 - val_mae: 0.0775\n",
      "Epoch 15/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0055 - mae: 0.0487 - val_loss: 0.0080 - val_mae: 0.0588\n",
      "Epoch 16/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0056 - mae: 0.0490 - val_loss: 0.0078 - val_mae: 0.0586\n",
      "Epoch 17/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0051 - mae: 0.0445 - val_loss: 0.0076 - val_mae: 0.0484\n",
      "Epoch 18/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0047 - mae: 0.0432 - val_loss: 0.0075 - val_mae: 0.0512\n",
      "Epoch 19/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0050 - mae: 0.0439 - val_loss: 0.0077 - val_mae: 0.0407\n",
      "Epoch 20/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0047 - mae: 0.0421 - val_loss: 0.0072 - val_mae: 0.0557\n",
      "Epoch 21/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0049 - mae: 0.0446 - val_loss: 0.0098 - val_mae: 0.0535\n",
      "Epoch 22/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0042 - mae: 0.0352 - val_loss: 0.0094 - val_mae: 0.0516\n",
      "Epoch 23/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0040 - mae: 0.0343 - val_loss: 0.0085 - val_mae: 0.0422\n",
      "Epoch 24/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0040 - mae: 0.0356 - val_loss: 0.0078 - val_mae: 0.0359\n",
      "Epoch 25/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0039 - mae: 0.0325 - val_loss: 0.0138 - val_mae: 0.0862\n",
      "Epoch 26/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0042 - mae: 0.0364 - val_loss: 0.0158 - val_mae: 0.0980\n",
      "Epoch 27/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0048 - mae: 0.0441 - val_loss: 0.0069 - val_mae: 0.0320\n",
      "Epoch 28/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0044 - mae: 0.0397 - val_loss: 0.0123 - val_mae: 0.0771\n",
      "Epoch 29/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0037 - mae: 0.0321 - val_loss: 0.0190 - val_mae: 0.1134\n",
      "Epoch 30/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0038 - mae: 0.0318 - val_loss: 0.0083 - val_mae: 0.0448\n",
      "Epoch 31/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0039 - mae: 0.0349 - val_loss: 0.0100 - val_mae: 0.0604\n",
      "Epoch 32/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0037 - mae: 0.0336 - val_loss: 0.0117 - val_mae: 0.0744\n",
      "Epoch 33/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0034 - mae: 0.0284 - val_loss: 0.0138 - val_mae: 0.0874\n",
      "Epoch 34/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0036 - mae: 0.0305 - val_loss: 0.0155 - val_mae: 0.0974\n",
      "Epoch 35/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0040 - mae: 0.0363 - val_loss: 0.0208 - val_mae: 0.1216\n",
      "Epoch 36/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0037 - mae: 0.0326 - val_loss: 0.0190 - val_mae: 0.1139\n",
      "Epoch 37/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0035 - mae: 0.0288 - val_loss: 0.0145 - val_mae: 0.0921\n",
      "Epoch 38/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0039 - mae: 0.0357 - val_loss: 0.0100 - val_mae: 0.0625\n",
      "Epoch 39/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0038 - mae: 0.0315 - val_loss: 0.0093 - val_mae: 0.0578\n",
      "Epoch 40/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0035 - mae: 0.0304 - val_loss: 0.0130 - val_mae: 0.0839\n",
      "Epoch 41/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0038 - mae: 0.0332 - val_loss: 0.0328 - val_mae: 0.1642\n",
      "Epoch 42/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0037 - mae: 0.0332 - val_loss: 0.0148 - val_mae: 0.0942\n",
      "Epoch 43/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0037 - mae: 0.0335 - val_loss: 0.0193 - val_mae: 0.1163\n",
      "Epoch 44/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0034 - mae: 0.0289 - val_loss: 0.0093 - val_mae: 0.0588\n",
      "Epoch 45/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0036 - mae: 0.0306 - val_loss: 0.0205 - val_mae: 0.1211\n",
      "Epoch 46/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0036 - mae: 0.0310 - val_loss: 0.0108 - val_mae: 0.0706\n",
      "Epoch 47/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0034 - mae: 0.0287 - val_loss: 0.0137 - val_mae: 0.0891\n",
      "Epoch 48/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0036 - mae: 0.0321 - val_loss: 0.0165 - val_mae: 0.1042\n",
      "Epoch 49/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0034 - mae: 0.0282 - val_loss: 0.0132 - val_mae: 0.0866\n",
      "Epoch 50/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0035 - mae: 0.0282 - val_loss: 0.0160 - val_mae: 0.1017\n",
      "Epoch 51/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0034 - mae: 0.0285 - val_loss: 0.0269 - val_mae: 0.1462\n",
      "Epoch 52/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0038 - mae: 0.0350 - val_loss: 0.0215 - val_mae: 0.1265\n",
      "Epoch 53/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0034 - mae: 0.0285 - val_loss: 0.0167 - val_mae: 0.1057\n",
      "Epoch 54/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0033 - mae: 0.0256 - val_loss: 0.0165 - val_mae: 0.1054\n",
      "Epoch 55/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0040 - mae: 0.0384 - val_loss: 0.0249 - val_mae: 0.1399\n",
      "Epoch 56/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0036 - mae: 0.0314 - val_loss: 0.0093 - val_mae: 0.0612\n",
      "Epoch 57/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0039 - mae: 0.0354 - val_loss: 0.0082 - val_mae: 0.0522\n",
      "Epoch 58/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0035 - mae: 0.0303 - val_loss: 0.0148 - val_mae: 0.0976\n",
      "Epoch 59/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0034 - mae: 0.0278 - val_loss: 0.0175 - val_mae: 0.1107\n",
      "Epoch 60/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0035 - mae: 0.0289 - val_loss: 0.0146 - val_mae: 0.0969\n",
      "Epoch 61/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0035 - mae: 0.0290 - val_loss: 0.0203 - val_mae: 0.1232\n",
      "Epoch 62/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0033 - mae: 0.0282 - val_loss: 0.0211 - val_mae: 0.1267\n",
      "Epoch 63/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0035 - mae: 0.0306 - val_loss: 0.0176 - val_mae: 0.1123\n",
      "Epoch 64/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0034 - mae: 0.0293 - val_loss: 0.0106 - val_mae: 0.0746\n",
      "Epoch 65/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0037 - mae: 0.0334 - val_loss: 0.0152 - val_mae: 0.1011\n",
      "Epoch 66/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0034 - mae: 0.0290 - val_loss: 0.0116 - val_mae: 0.0819\n",
      "Epoch 67/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0035 - mae: 0.0289 - val_loss: 0.0220 - val_mae: 0.1313\n",
      "Epoch 68/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0033 - mae: 0.0287 - val_loss: 0.0102 - val_mae: 0.0739\n",
      "Epoch 69/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0035 - mae: 0.0300 - val_loss: 0.0120 - val_mae: 0.0852\n",
      "Epoch 70/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0033 - mae: 0.0263 - val_loss: 0.0155 - val_mae: 0.1042\n",
      "Epoch 71/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0036 - mae: 0.0330 - val_loss: 0.0177 - val_mae: 0.1141\n",
      "Epoch 72/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0038 - mae: 0.0358 - val_loss: 0.0109 - val_mae: 0.0795\n",
      "Epoch 73/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0033 - mae: 0.0296 - val_loss: 0.0117 - val_mae: 0.0847\n",
      "Epoch 74/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0033 - mae: 0.0288 - val_loss: 0.0157 - val_mae: 0.1061\n",
      "Epoch 75/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0034 - mae: 0.0293 - val_loss: 0.0115 - val_mae: 0.0843\n",
      "Epoch 76/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0034 - mae: 0.0304 - val_loss: 0.0215 - val_mae: 0.1312\n",
      "Epoch 77/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0033 - mae: 0.0284 - val_loss: 0.0109 - val_mae: 0.0811\n",
      "Epoch 78/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0032 - mae: 0.0244 - val_loss: 0.0145 - val_mae: 0.1017\n",
      "Epoch 79/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0035 - mae: 0.0323 - val_loss: 0.0093 - val_mae: 0.0714\n",
      "Epoch 80/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0033 - mae: 0.0291 - val_loss: 0.0142 - val_mae: 0.1009\n",
      "Epoch 81/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0032 - mae: 0.0266 - val_loss: 0.0068 - val_mae: 0.0515\n",
      "Epoch 82/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0034 - mae: 0.0293 - val_loss: 0.0130 - val_mae: 0.0952\n",
      "Epoch 83/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0036 - mae: 0.0315 - val_loss: 0.0294 - val_mae: 0.1600\n",
      "Epoch 84/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0034 - mae: 0.0329 - val_loss: 0.0190 - val_mae: 0.1228\n",
      "Epoch 85/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0033 - mae: 0.0289 - val_loss: 0.0266 - val_mae: 0.1513\n",
      "Epoch 86/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0031 - mae: 0.0278 - val_loss: 0.0071 - val_mae: 0.0574\n",
      "Epoch 87/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0035 - mae: 0.0334 - val_loss: 0.0123 - val_mae: 0.0923\n",
      "Epoch 88/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0033 - mae: 0.0276 - val_loss: 0.0276 - val_mae: 0.1550\n",
      "Epoch 89/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0033 - mae: 0.0292 - val_loss: 0.0066 - val_mae: 0.0534\n",
      "Epoch 90/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0033 - mae: 0.0282 - val_loss: 0.0105 - val_mae: 0.0840\n",
      "Epoch 91/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0033 - mae: 0.0291 - val_loss: 0.0220 - val_mae: 0.1368\n",
      "Epoch 92/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0035 - mae: 0.0317 - val_loss: 0.0199 - val_mae: 0.1284\n",
      "Epoch 93/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0032 - mae: 0.0286 - val_loss: 0.0146 - val_mae: 0.1061\n",
      "Epoch 94/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0034 - mae: 0.0319 - val_loss: 0.0083 - val_mae: 0.0707\n",
      "Epoch 95/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0034 - mae: 0.0303 - val_loss: 0.0107 - val_mae: 0.0867\n",
      "Epoch 96/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0036 - mae: 0.0325 - val_loss: 0.0034 - val_mae: 0.0222\n",
      "Epoch 97/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0035 - mae: 0.0330 - val_loss: 0.0148 - val_mae: 0.1081\n",
      "Epoch 98/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0036 - mae: 0.0326 - val_loss: 0.0126 - val_mae: 0.0977\n",
      "Epoch 99/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0031 - mae: 0.0260 - val_loss: 0.0088 - val_mae: 0.0756\n",
      "Epoch 100/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0032 - mae: 0.0293 - val_loss: 0.0158 - val_mae: 0.1135\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step  \n",
      "✅ Done with tomato_Gadag_daily.csv | MAE=673.57, RMSE=781.71, R2=0.8608, MAPE=15.21%, Accuracy=84.79%\n",
      "Saved updated CSV with Date, Actual & Predicted: tat_mqa_output_csv\\tomato_Gadag_daily_tat_mqa_updated.csv\n",
      "🚀 Processing: tomato_Hassan_daily.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_9\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_9\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_query_attention_9       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">17,216</span> │ input_layer_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiQueryAttention</span>)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_query_attention_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                               │                           │                 │ input_layer_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_18        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_97 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ layer_normalization_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_98 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dense_97[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                               │                           │                 │ dense_98[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_19        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_9    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_99 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ global_average_pooling1d_… │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_9 (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_query_attention_9       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │          \u001b[38;5;34m17,216\u001b[0m │ input_layer_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "│ (\u001b[38;5;33mMultiQueryAttention\u001b[0m)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_18 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ multi_query_attention_9[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                               │                           │                 │ input_layer_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_18        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ add_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_97 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │           \u001b[38;5;34m8,320\u001b[0m │ layer_normalization_18[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_98 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │             \u001b[38;5;34m129\u001b[0m │ dense_97[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_19 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_18[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                               │                           │                 │ dense_98[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_19        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ add_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_9    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_19[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_99 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │              \u001b[38;5;34m65\u001b[0m │ global_average_pooling1d_… │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,986</span> (101.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25,986\u001b[0m (101.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,986</span> (101.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m25,986\u001b[0m (101.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 13ms/step - loss: 0.0109 - mae: 0.0572 - val_loss: 0.0095 - val_mae: 0.0711\n",
      "Epoch 2/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 13ms/step - loss: 0.0023 - mae: 0.0367 - val_loss: 0.0093 - val_mae: 0.0604\n",
      "Epoch 3/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - loss: 0.0021 - mae: 0.0346 - val_loss: 0.0097 - val_mae: 0.0619\n",
      "Epoch 4/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - loss: 0.0021 - mae: 0.0343 - val_loss: 0.0086 - val_mae: 0.0586\n",
      "Epoch 5/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - loss: 0.0020 - mae: 0.0332 - val_loss: 0.0108 - val_mae: 0.0667\n",
      "Epoch 6/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - loss: 0.0019 - mae: 0.0327 - val_loss: 0.0090 - val_mae: 0.0604\n",
      "Epoch 7/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - loss: 0.0019 - mae: 0.0320 - val_loss: 0.0087 - val_mae: 0.0599\n",
      "Epoch 8/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - loss: 0.0018 - mae: 0.0315 - val_loss: 0.0065 - val_mae: 0.0545\n",
      "Epoch 9/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - loss: 0.0018 - mae: 0.0313 - val_loss: 0.0059 - val_mae: 0.0543\n",
      "Epoch 10/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - loss: 0.0018 - mae: 0.0310 - val_loss: 0.0059 - val_mae: 0.0529\n",
      "Epoch 11/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 13ms/step - loss: 0.0018 - mae: 0.0311 - val_loss: 0.0076 - val_mae: 0.0613\n",
      "Epoch 12/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - loss: 0.0018 - mae: 0.0309 - val_loss: 0.0059 - val_mae: 0.0528\n",
      "Epoch 13/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - loss: 0.0018 - mae: 0.0308 - val_loss: 0.0059 - val_mae: 0.0538\n",
      "Epoch 14/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - loss: 0.0018 - mae: 0.0309 - val_loss: 0.0058 - val_mae: 0.0527\n",
      "Epoch 15/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - loss: 0.0018 - mae: 0.0308 - val_loss: 0.0060 - val_mae: 0.0531\n",
      "Epoch 16/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - loss: 0.0018 - mae: 0.0309 - val_loss: 0.0059 - val_mae: 0.0533\n",
      "Epoch 17/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - loss: 0.0018 - mae: 0.0308 - val_loss: 0.0060 - val_mae: 0.0531\n",
      "Epoch 18/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - loss: 0.0018 - mae: 0.0308 - val_loss: 0.0062 - val_mae: 0.0538\n",
      "Epoch 19/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - loss: 0.0018 - mae: 0.0307 - val_loss: 0.0060 - val_mae: 0.0541\n",
      "Epoch 20/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - loss: 0.0018 - mae: 0.0308 - val_loss: 0.0058 - val_mae: 0.0528\n",
      "Epoch 21/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - loss: 0.0018 - mae: 0.0307 - val_loss: 0.0059 - val_mae: 0.0529\n",
      "Epoch 22/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - loss: 0.0018 - mae: 0.0307 - val_loss: 0.0059 - val_mae: 0.0532\n",
      "Epoch 23/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - loss: 0.0018 - mae: 0.0307 - val_loss: 0.0058 - val_mae: 0.0529\n",
      "Epoch 24/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 13ms/step - loss: 0.0018 - mae: 0.0308 - val_loss: 0.0060 - val_mae: 0.0547\n",
      "Epoch 25/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0059 - val_mae: 0.0532\n",
      "Epoch 26/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - loss: 0.0018 - mae: 0.0307 - val_loss: 0.0060 - val_mae: 0.0532\n",
      "Epoch 27/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - loss: 0.0018 - mae: 0.0307 - val_loss: 0.0058 - val_mae: 0.0530\n",
      "Epoch 28/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0063 - val_mae: 0.0540\n",
      "Epoch 29/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0018 - mae: 0.0307 - val_loss: 0.0058 - val_mae: 0.0529\n",
      "Epoch 30/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0307 - val_loss: 0.0058 - val_mae: 0.0529\n",
      "Epoch 31/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0061 - val_mae: 0.0535\n",
      "Epoch 32/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0061 - val_mae: 0.0534\n",
      "Epoch 33/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0307 - val_loss: 0.0058 - val_mae: 0.0529\n",
      "Epoch 34/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0063 - val_mae: 0.0540\n",
      "Epoch 35/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - loss: 0.0018 - mae: 0.0307 - val_loss: 0.0060 - val_mae: 0.0532\n",
      "Epoch 36/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0061 - val_mae: 0.0535\n",
      "Epoch 37/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - loss: 0.0018 - mae: 0.0307 - val_loss: 0.0059 - val_mae: 0.0538\n",
      "Epoch 38/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0059 - val_mae: 0.0529\n",
      "Epoch 39/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0058 - val_mae: 0.0530\n",
      "Epoch 40/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0059 - val_mae: 0.0539\n",
      "Epoch 41/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0060 - val_mae: 0.0532\n",
      "Epoch 42/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0061 - val_mae: 0.0536\n",
      "Epoch 43/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0059 - val_mae: 0.0541\n",
      "Epoch 44/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0058 - val_mae: 0.0535\n",
      "Epoch 45/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0065 - val_mae: 0.0545\n",
      "Epoch 46/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0060 - val_mae: 0.0534\n",
      "Epoch 47/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0059 - val_mae: 0.0545\n",
      "Epoch 48/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0059 - val_mae: 0.0531\n",
      "Epoch 49/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0058 - val_mae: 0.0530\n",
      "Epoch 50/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0059 - val_mae: 0.0533\n",
      "Epoch 51/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0058 - val_mae: 0.0536\n",
      "Epoch 52/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0060 - val_mae: 0.0533\n",
      "Epoch 53/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - loss: 0.0018 - mae: 0.0305 - val_loss: 0.0061 - val_mae: 0.0536\n",
      "Epoch 54/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0061 - val_mae: 0.0556\n",
      "Epoch 55/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0061 - val_mae: 0.0535\n",
      "Epoch 56/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - loss: 0.0018 - mae: 0.0305 - val_loss: 0.0059 - val_mae: 0.0533\n",
      "Epoch 57/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0061 - val_mae: 0.0535\n",
      "Epoch 58/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0062 - val_mae: 0.0538\n",
      "Epoch 59/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - loss: 0.0018 - mae: 0.0305 - val_loss: 0.0060 - val_mae: 0.0533\n",
      "Epoch 60/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0063 - val_mae: 0.0563\n",
      "Epoch 61/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - loss: 0.0018 - mae: 0.0305 - val_loss: 0.0060 - val_mae: 0.0533\n",
      "Epoch 62/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0059 - val_mae: 0.0535\n",
      "Epoch 63/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - loss: 0.0018 - mae: 0.0305 - val_loss: 0.0062 - val_mae: 0.0537\n",
      "Epoch 64/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0059 - val_mae: 0.0539\n",
      "Epoch 65/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - loss: 0.0018 - mae: 0.0305 - val_loss: 0.0059 - val_mae: 0.0532\n",
      "Epoch 66/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0059 - val_mae: 0.0542\n",
      "Epoch 67/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - loss: 0.0018 - mae: 0.0305 - val_loss: 0.0060 - val_mae: 0.0534\n",
      "Epoch 68/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - loss: 0.0018 - mae: 0.0305 - val_loss: 0.0061 - val_mae: 0.0535\n",
      "Epoch 69/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - loss: 0.0018 - mae: 0.0305 - val_loss: 0.0059 - val_mae: 0.0534\n",
      "Epoch 70/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - loss: 0.0018 - mae: 0.0305 - val_loss: 0.0059 - val_mae: 0.0533\n",
      "Epoch 71/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 11ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0058 - val_mae: 0.0532\n",
      "Epoch 72/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0305 - val_loss: 0.0061 - val_mae: 0.0536\n",
      "Epoch 73/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - loss: 0.0018 - mae: 0.0305 - val_loss: 0.0059 - val_mae: 0.0534\n",
      "Epoch 74/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0059 - val_mae: 0.0535\n",
      "Epoch 75/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - loss: 0.0018 - mae: 0.0305 - val_loss: 0.0059 - val_mae: 0.0542\n",
      "Epoch 76/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0061 - val_mae: 0.0536\n",
      "Epoch 77/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0061 - val_mae: 0.0538\n",
      "Epoch 78/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0061 - val_mae: 0.0536\n",
      "Epoch 79/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - loss: 0.0018 - mae: 0.0305 - val_loss: 0.0060 - val_mae: 0.0534\n",
      "Epoch 80/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - loss: 0.0018 - mae: 0.0305 - val_loss: 0.0059 - val_mae: 0.0537\n",
      "Epoch 81/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - loss: 0.0018 - mae: 0.0305 - val_loss: 0.0059 - val_mae: 0.0534\n",
      "Epoch 82/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - loss: 0.0018 - mae: 0.0305 - val_loss: 0.0060 - val_mae: 0.0546\n",
      "Epoch 83/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0060 - val_mae: 0.0546\n",
      "Epoch 84/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - loss: 0.0018 - mae: 0.0305 - val_loss: 0.0062 - val_mae: 0.0538\n",
      "Epoch 85/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - loss: 0.0018 - mae: 0.0305 - val_loss: 0.0059 - val_mae: 0.0535\n",
      "Epoch 86/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - loss: 0.0018 - mae: 0.0305 - val_loss: 0.0068 - val_mae: 0.0553\n",
      "Epoch 87/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 11ms/step - loss: 0.0018 - mae: 0.0305 - val_loss: 0.0059 - val_mae: 0.0535\n",
      "Epoch 88/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - loss: 0.0018 - mae: 0.0305 - val_loss: 0.0063 - val_mae: 0.0540\n",
      "Epoch 89/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0062 - val_mae: 0.0538\n",
      "Epoch 90/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - loss: 0.0018 - mae: 0.0305 - val_loss: 0.0059 - val_mae: 0.0534\n",
      "Epoch 91/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - loss: 0.0018 - mae: 0.0305 - val_loss: 0.0060 - val_mae: 0.0534\n",
      "Epoch 92/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - loss: 0.0018 - mae: 0.0305 - val_loss: 0.0060 - val_mae: 0.0544\n",
      "Epoch 93/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 11ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0060 - val_mae: 0.0537\n",
      "Epoch 94/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - loss: 0.0018 - mae: 0.0305 - val_loss: 0.0060 - val_mae: 0.0534\n",
      "Epoch 95/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 11ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0062 - val_mae: 0.0537\n",
      "Epoch 96/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 11ms/step - loss: 0.0018 - mae: 0.0305 - val_loss: 0.0060 - val_mae: 0.0535\n",
      "Epoch 97/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 11ms/step - loss: 0.0018 - mae: 0.0305 - val_loss: 0.0061 - val_mae: 0.0535\n",
      "Epoch 98/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 11ms/step - loss: 0.0018 - mae: 0.0305 - val_loss: 0.0064 - val_mae: 0.0542\n",
      "Epoch 99/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 11ms/step - loss: 0.0018 - mae: 0.0305 - val_loss: 0.0061 - val_mae: 0.0535\n",
      "Epoch 100/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - loss: 0.0018 - mae: 0.0305 - val_loss: 0.0060 - val_mae: 0.0535\n",
      "\u001b[1m923/923\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step\n",
      "✅ Done with tomato_Hassan_daily.csv | MAE=415.0, RMSE=620.3, R2=0.5629, MAPE=47.7%, Accuracy=52.3%\n",
      "Saved updated CSV with Date, Actual & Predicted: tat_mqa_output_csv\\tomato_Hassan_daily_tat_mqa_updated.csv\n",
      "🚀 Processing: tomato_Haveri_daily.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_10\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_10\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_query_attention_10      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">17,216</span> │ input_layer_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiQueryAttention</span>)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_query_attention_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                               │                           │                 │ input_layer_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_20        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_107 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ layer_normalization_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_108 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dense_107[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                               │                           │                 │ dense_108[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_21        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_10   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_109 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ global_average_pooling1d_… │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_10 (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_query_attention_10      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │          \u001b[38;5;34m17,216\u001b[0m │ input_layer_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mMultiQueryAttention\u001b[0m)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_20 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ multi_query_attention_10[\u001b[38;5;34m…\u001b[0m │\n",
       "│                               │                           │                 │ input_layer_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_20        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ add_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_107 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │           \u001b[38;5;34m8,320\u001b[0m │ layer_normalization_20[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_108 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │             \u001b[38;5;34m129\u001b[0m │ dense_107[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_21 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_20[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                               │                           │                 │ dense_108[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_21        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ add_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_10   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_21[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_109 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │              \u001b[38;5;34m65\u001b[0m │ global_average_pooling1d_… │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,986</span> (101.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25,986\u001b[0m (101.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,986</span> (101.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m25,986\u001b[0m (101.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - loss: 0.0754 - mae: 0.1931 - val_loss: 0.2280 - val_mae: 0.4112\n",
      "Epoch 2/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0235 - mae: 0.1218 - val_loss: 0.1700 - val_mae: 0.3486\n",
      "Epoch 3/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0183 - mae: 0.1064 - val_loss: 0.1197 - val_mae: 0.3102\n",
      "Epoch 4/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0140 - mae: 0.0952 - val_loss: 0.0629 - val_mae: 0.2232\n",
      "Epoch 5/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0113 - mae: 0.0856 - val_loss: 0.0460 - val_mae: 0.1806\n",
      "Epoch 6/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0099 - mae: 0.0816 - val_loss: 0.0265 - val_mae: 0.1508\n",
      "Epoch 7/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0086 - mae: 0.0768 - val_loss: 0.0142 - val_mae: 0.0829\n",
      "Epoch 8/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0085 - mae: 0.0766 - val_loss: 0.0143 - val_mae: 0.0884\n",
      "Epoch 9/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0072 - mae: 0.0725 - val_loss: 0.0108 - val_mae: 0.0892\n",
      "Epoch 10/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0070 - mae: 0.0714 - val_loss: 0.0111 - val_mae: 0.0783\n",
      "Epoch 11/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0070 - mae: 0.0716 - val_loss: 0.0093 - val_mae: 0.0640\n",
      "Epoch 12/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0064 - mae: 0.0690 - val_loss: 0.0060 - val_mae: 0.0517\n",
      "Epoch 13/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0063 - mae: 0.0689 - val_loss: 0.0097 - val_mae: 0.0737\n",
      "Epoch 14/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0061 - mae: 0.0676 - val_loss: 0.0070 - val_mae: 0.0535\n",
      "Epoch 15/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0064 - mae: 0.0689 - val_loss: 0.0058 - val_mae: 0.0548\n",
      "Epoch 16/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0059 - mae: 0.0667 - val_loss: 0.0085 - val_mae: 0.0662\n",
      "Epoch 17/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0062 - mae: 0.0680 - val_loss: 0.0049 - val_mae: 0.0432\n",
      "Epoch 18/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0062 - mae: 0.0672 - val_loss: 0.0074 - val_mae: 0.0477\n",
      "Epoch 19/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0059 - mae: 0.0671 - val_loss: 0.0092 - val_mae: 0.0614\n",
      "Epoch 20/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0062 - mae: 0.0681 - val_loss: 0.0161 - val_mae: 0.0972\n",
      "Epoch 21/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0060 - mae: 0.0675 - val_loss: 0.0093 - val_mae: 0.0627\n",
      "Epoch 22/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0062 - mae: 0.0677 - val_loss: 0.0107 - val_mae: 0.0732\n",
      "Epoch 23/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0059 - mae: 0.0672 - val_loss: 0.0070 - val_mae: 0.0478\n",
      "Epoch 24/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0059 - mae: 0.0670 - val_loss: 0.0048 - val_mae: 0.0420\n",
      "Epoch 25/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0063 - mae: 0.0685 - val_loss: 0.0080 - val_mae: 0.0589\n",
      "Epoch 26/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0058 - mae: 0.0678 - val_loss: 0.0062 - val_mae: 0.0398\n",
      "Epoch 27/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0060 - mae: 0.0673 - val_loss: 0.0094 - val_mae: 0.0659\n",
      "Epoch 28/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0061 - mae: 0.0683 - val_loss: 0.0091 - val_mae: 0.0611\n",
      "Epoch 29/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0063 - mae: 0.0683 - val_loss: 0.0173 - val_mae: 0.0995\n",
      "Epoch 30/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0059 - mae: 0.0682 - val_loss: 0.0082 - val_mae: 0.0564\n",
      "Epoch 31/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0060 - mae: 0.0676 - val_loss: 0.0062 - val_mae: 0.0422\n",
      "Epoch 32/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0059 - mae: 0.0669 - val_loss: 0.0063 - val_mae: 0.0411\n",
      "Epoch 33/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0062 - mae: 0.0681 - val_loss: 0.0058 - val_mae: 0.0429\n",
      "Epoch 34/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0060 - mae: 0.0676 - val_loss: 0.0102 - val_mae: 0.0707\n",
      "Epoch 35/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0060 - mae: 0.0674 - val_loss: 0.0059 - val_mae: 0.0419\n",
      "Epoch 36/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0058 - mae: 0.0670 - val_loss: 0.0063 - val_mae: 0.0439\n",
      "Epoch 37/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0063 - mae: 0.0680 - val_loss: 0.0081 - val_mae: 0.0566\n",
      "Epoch 38/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0059 - mae: 0.0672 - val_loss: 0.0097 - val_mae: 0.0653\n",
      "Epoch 39/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0060 - mae: 0.0682 - val_loss: 0.0075 - val_mae: 0.0573\n",
      "Epoch 40/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0059 - mae: 0.0676 - val_loss: 0.0060 - val_mae: 0.0467\n",
      "Epoch 41/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0056 - mae: 0.0662 - val_loss: 0.0116 - val_mae: 0.0767\n",
      "Epoch 42/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0060 - mae: 0.0673 - val_loss: 0.0108 - val_mae: 0.0724\n",
      "Epoch 43/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0059 - mae: 0.0672 - val_loss: 0.0104 - val_mae: 0.0717\n",
      "Epoch 44/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0061 - mae: 0.0678 - val_loss: 0.0081 - val_mae: 0.0585\n",
      "Epoch 45/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0058 - mae: 0.0670 - val_loss: 0.0095 - val_mae: 0.0621\n",
      "Epoch 46/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0059 - mae: 0.0672 - val_loss: 0.0085 - val_mae: 0.0558\n",
      "Epoch 47/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0057 - mae: 0.0664 - val_loss: 0.0093 - val_mae: 0.0625\n",
      "Epoch 48/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0059 - mae: 0.0672 - val_loss: 0.0119 - val_mae: 0.0766\n",
      "Epoch 49/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0056 - mae: 0.0665 - val_loss: 0.0095 - val_mae: 0.0647\n",
      "Epoch 50/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0059 - mae: 0.0673 - val_loss: 0.0059 - val_mae: 0.0409\n",
      "Epoch 51/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0058 - mae: 0.0665 - val_loss: 0.0101 - val_mae: 0.0661\n",
      "Epoch 52/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0059 - mae: 0.0673 - val_loss: 0.0138 - val_mae: 0.0874\n",
      "Epoch 53/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0057 - mae: 0.0667 - val_loss: 0.0104 - val_mae: 0.0700\n",
      "Epoch 54/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0058 - mae: 0.0663 - val_loss: 0.0095 - val_mae: 0.0660\n",
      "Epoch 55/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0057 - mae: 0.0663 - val_loss: 0.0075 - val_mae: 0.0489\n",
      "Epoch 56/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0060 - mae: 0.0675 - val_loss: 0.0112 - val_mae: 0.0776\n",
      "Epoch 57/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0059 - mae: 0.0673 - val_loss: 0.0086 - val_mae: 0.0565\n",
      "Epoch 58/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0056 - mae: 0.0661 - val_loss: 0.0140 - val_mae: 0.0860\n",
      "Epoch 59/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0057 - mae: 0.0667 - val_loss: 0.0206 - val_mae: 0.1219\n",
      "Epoch 60/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0058 - mae: 0.0667 - val_loss: 0.0130 - val_mae: 0.0811\n",
      "Epoch 61/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0058 - mae: 0.0664 - val_loss: 0.0146 - val_mae: 0.0905\n",
      "Epoch 62/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0061 - mae: 0.0678 - val_loss: 0.0179 - val_mae: 0.1076\n",
      "Epoch 63/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0059 - mae: 0.0676 - val_loss: 0.0057 - val_mae: 0.0600\n",
      "Epoch 64/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0059 - mae: 0.0672 - val_loss: 0.0172 - val_mae: 0.0969\n",
      "Epoch 65/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0056 - mae: 0.0667 - val_loss: 0.0063 - val_mae: 0.0402\n",
      "Epoch 66/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0057 - mae: 0.0668 - val_loss: 0.0198 - val_mae: 0.1124\n",
      "Epoch 67/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0059 - mae: 0.0674 - val_loss: 0.0093 - val_mae: 0.0608\n",
      "Epoch 68/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0057 - mae: 0.0666 - val_loss: 0.0160 - val_mae: 0.0988\n",
      "Epoch 69/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0056 - mae: 0.0666 - val_loss: 0.0138 - val_mae: 0.0879\n",
      "Epoch 70/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0058 - mae: 0.0671 - val_loss: 0.0163 - val_mae: 0.0927\n",
      "Epoch 71/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0057 - mae: 0.0669 - val_loss: 0.0170 - val_mae: 0.0992\n",
      "Epoch 72/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0057 - mae: 0.0665 - val_loss: 0.0083 - val_mae: 0.0576\n",
      "Epoch 73/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0056 - mae: 0.0662 - val_loss: 0.0150 - val_mae: 0.0886\n",
      "Epoch 74/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0057 - mae: 0.0666 - val_loss: 0.0116 - val_mae: 0.0795\n",
      "Epoch 75/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0058 - mae: 0.0670 - val_loss: 0.0103 - val_mae: 0.0677\n",
      "Epoch 76/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0057 - mae: 0.0669 - val_loss: 0.0166 - val_mae: 0.1048\n",
      "Epoch 77/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0057 - mae: 0.0666 - val_loss: 0.0163 - val_mae: 0.1031\n",
      "Epoch 78/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0057 - mae: 0.0663 - val_loss: 0.0086 - val_mae: 0.0597\n",
      "Epoch 79/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0056 - mae: 0.0665 - val_loss: 0.0127 - val_mae: 0.0826\n",
      "Epoch 80/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0057 - mae: 0.0666 - val_loss: 0.0128 - val_mae: 0.0809\n",
      "Epoch 81/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0056 - mae: 0.0667 - val_loss: 0.0139 - val_mae: 0.0910\n",
      "Epoch 82/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0058 - mae: 0.0670 - val_loss: 0.0119 - val_mae: 0.0819\n",
      "Epoch 83/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0056 - mae: 0.0663 - val_loss: 0.0096 - val_mae: 0.0632\n",
      "Epoch 84/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0056 - mae: 0.0661 - val_loss: 0.0109 - val_mae: 0.0735\n",
      "Epoch 85/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0057 - mae: 0.0668 - val_loss: 0.0134 - val_mae: 0.0860\n",
      "Epoch 86/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0056 - mae: 0.0664 - val_loss: 0.0074 - val_mae: 0.0501\n",
      "Epoch 87/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0058 - mae: 0.0672 - val_loss: 0.0169 - val_mae: 0.1022\n",
      "Epoch 88/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0056 - mae: 0.0659 - val_loss: 0.0083 - val_mae: 0.0567\n",
      "Epoch 89/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0055 - mae: 0.0660 - val_loss: 0.0096 - val_mae: 0.0632\n",
      "Epoch 90/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0056 - mae: 0.0657 - val_loss: 0.0199 - val_mae: 0.1170\n",
      "Epoch 91/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0059 - mae: 0.0678 - val_loss: 0.0084 - val_mae: 0.0603\n",
      "Epoch 92/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0057 - mae: 0.0660 - val_loss: 0.0118 - val_mae: 0.0768\n",
      "Epoch 93/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0058 - mae: 0.0672 - val_loss: 0.0086 - val_mae: 0.0562\n",
      "Epoch 94/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0056 - mae: 0.0661 - val_loss: 0.0118 - val_mae: 0.0761\n",
      "Epoch 95/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0056 - mae: 0.0663 - val_loss: 0.0157 - val_mae: 0.1014\n",
      "Epoch 96/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0055 - mae: 0.0662 - val_loss: 0.0095 - val_mae: 0.0661\n",
      "Epoch 97/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0057 - mae: 0.0662 - val_loss: 0.0108 - val_mae: 0.0709\n",
      "Epoch 98/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0055 - mae: 0.0658 - val_loss: 0.0131 - val_mae: 0.0826\n",
      "Epoch 99/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0055 - mae: 0.0654 - val_loss: 0.0130 - val_mae: 0.0887\n",
      "Epoch 100/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0056 - mae: 0.0664 - val_loss: 0.0098 - val_mae: 0.0677\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step   \n",
      "✅ Done with tomato_Haveri_daily.csv | MAE=564.91, RMSE=702.4, R2=0.9099, MAPE=26.76%, Accuracy=73.24%\n",
      "Saved updated CSV with Date, Actual & Predicted: tat_mqa_output_csv\\tomato_Haveri_daily_tat_mqa_updated.csv\n",
      "🚀 Processing: tomato_Kalburgi_daily.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_11\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_11\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_query_attention_11      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">17,216</span> │ input_layer_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiQueryAttention</span>)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_query_attention_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                               │                           │                 │ input_layer_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_22        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_117 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ layer_normalization_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_118 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dense_117[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                               │                           │                 │ dense_118[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_23        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_11   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_119 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ global_average_pooling1d_… │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_11 (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_query_attention_11      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │          \u001b[38;5;34m17,216\u001b[0m │ input_layer_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mMultiQueryAttention\u001b[0m)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_22 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ multi_query_attention_11[\u001b[38;5;34m…\u001b[0m │\n",
       "│                               │                           │                 │ input_layer_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_22        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ add_22[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_117 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │           \u001b[38;5;34m8,320\u001b[0m │ layer_normalization_22[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_118 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │             \u001b[38;5;34m129\u001b[0m │ dense_117[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_23 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_22[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                               │                           │                 │ dense_118[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_23        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ add_23[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_11   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_23[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_119 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │              \u001b[38;5;34m65\u001b[0m │ global_average_pooling1d_… │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,986</span> (101.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25,986\u001b[0m (101.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,986</span> (101.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m25,986\u001b[0m (101.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - loss: 0.4748 - mae: 0.3333 - val_loss: 0.0078 - val_mae: 0.0741\n",
      "Epoch 2/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0353 - mae: 0.1423 - val_loss: 0.0150 - val_mae: 0.1075\n",
      "Epoch 3/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0374 - mae: 0.1494 - val_loss: 0.0065 - val_mae: 0.0621\n",
      "Epoch 4/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0375 - mae: 0.1471 - val_loss: 0.0108 - val_mae: 0.0870\n",
      "Epoch 5/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0359 - mae: 0.1423 - val_loss: 0.0128 - val_mae: 0.0981\n",
      "Epoch 6/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0336 - mae: 0.1402 - val_loss: 0.0044 - val_mae: 0.0542\n",
      "Epoch 7/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0309 - mae: 0.1338 - val_loss: 0.0079 - val_mae: 0.0742\n",
      "Epoch 8/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0328 - mae: 0.1365 - val_loss: 0.0038 - val_mae: 0.0512\n",
      "Epoch 9/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0338 - mae: 0.1424 - val_loss: 0.0079 - val_mae: 0.0722\n",
      "Epoch 10/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0320 - mae: 0.1328 - val_loss: 0.0054 - val_mae: 0.0616\n",
      "Epoch 11/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0326 - mae: 0.1357 - val_loss: 0.0148 - val_mae: 0.1075\n",
      "Epoch 12/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0285 - mae: 0.1265 - val_loss: 0.0070 - val_mae: 0.0667\n",
      "Epoch 13/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0275 - mae: 0.1237 - val_loss: 0.0298 - val_mae: 0.1605\n",
      "Epoch 14/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0271 - mae: 0.1241 - val_loss: 0.0172 - val_mae: 0.1165\n",
      "Epoch 15/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0277 - mae: 0.1255 - val_loss: 0.0151 - val_mae: 0.1069\n",
      "Epoch 16/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0263 - mae: 0.1212 - val_loss: 0.0104 - val_mae: 0.0867\n",
      "Epoch 17/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0259 - mae: 0.1213 - val_loss: 0.0062 - val_mae: 0.0632\n",
      "Epoch 18/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0285 - mae: 0.1286 - val_loss: 0.0056 - val_mae: 0.0613\n",
      "Epoch 19/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0246 - mae: 0.1159 - val_loss: 0.0142 - val_mae: 0.1015\n",
      "Epoch 20/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0266 - mae: 0.1209 - val_loss: 0.0369 - val_mae: 0.1808\n",
      "Epoch 21/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0261 - mae: 0.1222 - val_loss: 0.0066 - val_mae: 0.0644\n",
      "Epoch 22/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0245 - mae: 0.1169 - val_loss: 0.0119 - val_mae: 0.0926\n",
      "Epoch 23/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0258 - mae: 0.1197 - val_loss: 0.0118 - val_mae: 0.0899\n",
      "Epoch 24/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0257 - mae: 0.1206 - val_loss: 0.0061 - val_mae: 0.0624\n",
      "Epoch 25/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0213 - mae: 0.1085 - val_loss: 0.0225 - val_mae: 0.1344\n",
      "Epoch 26/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0230 - mae: 0.1134 - val_loss: 0.0226 - val_mae: 0.1353\n",
      "Epoch 27/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0215 - mae: 0.1093 - val_loss: 0.0244 - val_mae: 0.1420\n",
      "Epoch 28/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0215 - mae: 0.1083 - val_loss: 0.0138 - val_mae: 0.0996\n",
      "Epoch 29/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0210 - mae: 0.1072 - val_loss: 0.0234 - val_mae: 0.1372\n",
      "Epoch 30/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0205 - mae: 0.1070 - val_loss: 0.0100 - val_mae: 0.0814\n",
      "Epoch 31/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0191 - mae: 0.1019 - val_loss: 0.0205 - val_mae: 0.1232\n",
      "Epoch 32/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0191 - mae: 0.1018 - val_loss: 0.0092 - val_mae: 0.0786\n",
      "Epoch 33/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0204 - mae: 0.1048 - val_loss: 0.0152 - val_mae: 0.1066\n",
      "Epoch 34/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0179 - mae: 0.0996 - val_loss: 0.0095 - val_mae: 0.0793\n",
      "Epoch 35/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0189 - mae: 0.1004 - val_loss: 0.0108 - val_mae: 0.0865\n",
      "Epoch 36/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0189 - mae: 0.0992 - val_loss: 0.0214 - val_mae: 0.1258\n",
      "Epoch 37/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0191 - mae: 0.1015 - val_loss: 0.0136 - val_mae: 0.0984\n",
      "Epoch 38/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0197 - mae: 0.1015 - val_loss: 0.0222 - val_mae: 0.1307\n",
      "Epoch 39/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0176 - mae: 0.0957 - val_loss: 0.0238 - val_mae: 0.1334\n",
      "Epoch 40/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0176 - mae: 0.0948 - val_loss: 0.0427 - val_mae: 0.1907\n",
      "Epoch 41/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0182 - mae: 0.0993 - val_loss: 0.0146 - val_mae: 0.1019\n",
      "Epoch 42/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0170 - mae: 0.0948 - val_loss: 0.0061 - val_mae: 0.0631\n",
      "Epoch 43/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0202 - mae: 0.1022 - val_loss: 0.0509 - val_mae: 0.2082\n",
      "Epoch 44/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0184 - mae: 0.0999 - val_loss: 0.0418 - val_mae: 0.1870\n",
      "Epoch 45/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0175 - mae: 0.0959 - val_loss: 0.0101 - val_mae: 0.0827\n",
      "Epoch 46/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0162 - mae: 0.0913 - val_loss: 0.0204 - val_mae: 0.1188\n",
      "Epoch 47/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0190 - mae: 0.1000 - val_loss: 0.0089 - val_mae: 0.0755\n",
      "Epoch 48/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0164 - mae: 0.0916 - val_loss: 0.0106 - val_mae: 0.0829\n",
      "Epoch 49/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0169 - mae: 0.0927 - val_loss: 0.0088 - val_mae: 0.0746\n",
      "Epoch 50/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0171 - mae: 0.0929 - val_loss: 0.0213 - val_mae: 0.1258\n",
      "Epoch 51/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0158 - mae: 0.0879 - val_loss: 0.0207 - val_mae: 0.1248\n",
      "Epoch 52/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0167 - mae: 0.0909 - val_loss: 0.0288 - val_mae: 0.1494\n",
      "Epoch 53/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0164 - mae: 0.0909 - val_loss: 0.0076 - val_mae: 0.0675\n",
      "Epoch 54/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0168 - mae: 0.0914 - val_loss: 0.0072 - val_mae: 0.0650\n",
      "Epoch 55/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0180 - mae: 0.0959 - val_loss: 0.0175 - val_mae: 0.1113\n",
      "Epoch 56/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0159 - mae: 0.0898 - val_loss: 0.0180 - val_mae: 0.1156\n",
      "Epoch 57/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0160 - mae: 0.0912 - val_loss: 0.0169 - val_mae: 0.1101\n",
      "Epoch 58/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0167 - mae: 0.0905 - val_loss: 0.0312 - val_mae: 0.1554\n",
      "Epoch 59/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0166 - mae: 0.0916 - val_loss: 0.0244 - val_mae: 0.1372\n",
      "Epoch 60/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0162 - mae: 0.0902 - val_loss: 0.0065 - val_mae: 0.0623\n",
      "Epoch 61/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0164 - mae: 0.0894 - val_loss: 0.0069 - val_mae: 0.0634\n",
      "Epoch 62/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0163 - mae: 0.0904 - val_loss: 0.0102 - val_mae: 0.0801\n",
      "Epoch 63/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0166 - mae: 0.0903 - val_loss: 0.0198 - val_mae: 0.1219\n",
      "Epoch 64/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0162 - mae: 0.0900 - val_loss: 0.0162 - val_mae: 0.1052\n",
      "Epoch 65/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0162 - mae: 0.0902 - val_loss: 0.0151 - val_mae: 0.0983\n",
      "Epoch 66/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0160 - mae: 0.0895 - val_loss: 0.0177 - val_mae: 0.1135\n",
      "Epoch 67/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0153 - mae: 0.0869 - val_loss: 0.0115 - val_mae: 0.0882\n",
      "Epoch 68/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0158 - mae: 0.0882 - val_loss: 0.0092 - val_mae: 0.0777\n",
      "Epoch 69/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0163 - mae: 0.0924 - val_loss: 0.0101 - val_mae: 0.0783\n",
      "Epoch 70/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0170 - mae: 0.0927 - val_loss: 0.0215 - val_mae: 0.1240\n",
      "Epoch 71/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0173 - mae: 0.0950 - val_loss: 0.0080 - val_mae: 0.0699\n",
      "Epoch 72/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0149 - mae: 0.0853 - val_loss: 0.0068 - val_mae: 0.0632\n",
      "Epoch 73/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0162 - mae: 0.0886 - val_loss: 0.0112 - val_mae: 0.0863\n",
      "Epoch 74/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0154 - mae: 0.0883 - val_loss: 0.0102 - val_mae: 0.0806\n",
      "Epoch 75/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0153 - mae: 0.0858 - val_loss: 0.0080 - val_mae: 0.0701\n",
      "Epoch 76/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0156 - mae: 0.0854 - val_loss: 0.0121 - val_mae: 0.0887\n",
      "Epoch 77/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0152 - mae: 0.0843 - val_loss: 0.0107 - val_mae: 0.0832\n",
      "Epoch 78/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0156 - mae: 0.0883 - val_loss: 0.0158 - val_mae: 0.1061\n",
      "Epoch 79/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0169 - mae: 0.0938 - val_loss: 0.0055 - val_mae: 0.0573\n",
      "Epoch 80/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0163 - mae: 0.0888 - val_loss: 0.0060 - val_mae: 0.0594\n",
      "Epoch 81/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0153 - mae: 0.0862 - val_loss: 0.0172 - val_mae: 0.1120\n",
      "Epoch 82/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0171 - mae: 0.0925 - val_loss: 0.0118 - val_mae: 0.0901\n",
      "Epoch 83/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0157 - mae: 0.0883 - val_loss: 0.0101 - val_mae: 0.0796\n",
      "Epoch 84/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0159 - mae: 0.0877 - val_loss: 0.0137 - val_mae: 0.0965\n",
      "Epoch 85/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0152 - mae: 0.0852 - val_loss: 0.0151 - val_mae: 0.1033\n",
      "Epoch 86/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0157 - mae: 0.0877 - val_loss: 0.0177 - val_mae: 0.1094\n",
      "Epoch 87/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0156 - mae: 0.0876 - val_loss: 0.0077 - val_mae: 0.0668\n",
      "Epoch 88/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0150 - mae: 0.0859 - val_loss: 0.0137 - val_mae: 0.0956\n",
      "Epoch 89/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0151 - mae: 0.0849 - val_loss: 0.0093 - val_mae: 0.0746\n",
      "Epoch 90/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0156 - mae: 0.0883 - val_loss: 0.0081 - val_mae: 0.0709\n",
      "Epoch 91/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0152 - mae: 0.0863 - val_loss: 0.0077 - val_mae: 0.0674\n",
      "Epoch 92/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0153 - mae: 0.0848 - val_loss: 0.0056 - val_mae: 0.0581\n",
      "Epoch 93/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0162 - mae: 0.0888 - val_loss: 0.0083 - val_mae: 0.0707\n",
      "Epoch 94/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0161 - mae: 0.0895 - val_loss: 0.0305 - val_mae: 0.1556\n",
      "Epoch 95/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0181 - mae: 0.0977 - val_loss: 0.0121 - val_mae: 0.0897\n",
      "Epoch 96/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0157 - mae: 0.0861 - val_loss: 0.0114 - val_mae: 0.0844\n",
      "Epoch 97/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0150 - mae: 0.0850 - val_loss: 0.0079 - val_mae: 0.0676\n",
      "Epoch 98/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0161 - mae: 0.0914 - val_loss: 0.0115 - val_mae: 0.0877\n",
      "Epoch 99/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0159 - mae: 0.0867 - val_loss: 0.0132 - val_mae: 0.0962\n",
      "Epoch 100/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0152 - mae: 0.0858 - val_loss: 0.0098 - val_mae: 0.0766\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step \n",
      "✅ Done with tomato_Kalburgi_daily.csv | MAE=828.24, RMSE=1162.94, R2=0.5719, MAPE=71.55%, Accuracy=28.45%\n",
      "Saved updated CSV with Date, Actual & Predicted: tat_mqa_output_csv\\tomato_Kalburgi_daily_tat_mqa_updated.csv\n",
      "🚀 Processing: tomato_Kolar_daily.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_12\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_12\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_query_attention_12      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">17,216</span> │ input_layer_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiQueryAttention</span>)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_query_attention_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                               │                           │                 │ input_layer_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_24        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_127 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ layer_normalization_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_128 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dense_127[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                               │                           │                 │ dense_128[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_25        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_12   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_129 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ global_average_pooling1d_… │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_12 (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_query_attention_12      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │          \u001b[38;5;34m17,216\u001b[0m │ input_layer_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mMultiQueryAttention\u001b[0m)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_24 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ multi_query_attention_12[\u001b[38;5;34m…\u001b[0m │\n",
       "│                               │                           │                 │ input_layer_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_24        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ add_24[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_127 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │           \u001b[38;5;34m8,320\u001b[0m │ layer_normalization_24[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_128 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │             \u001b[38;5;34m129\u001b[0m │ dense_127[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_25 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_24[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                               │                           │                 │ dense_128[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_25        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ add_25[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_12   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_25[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_129 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │              \u001b[38;5;34m65\u001b[0m │ global_average_pooling1d_… │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,986</span> (101.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25,986\u001b[0m (101.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,986</span> (101.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m25,986\u001b[0m (101.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 12ms/step - loss: 0.0140 - mae: 0.0530 - val_loss: 0.0089 - val_mae: 0.0537\n",
      "Epoch 2/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - loss: 0.0016 - mae: 0.0288 - val_loss: 0.0067 - val_mae: 0.0509\n",
      "Epoch 3/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 12ms/step - loss: 0.0013 - mae: 0.0258 - val_loss: 0.0047 - val_mae: 0.0433\n",
      "Epoch 4/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 12ms/step - loss: 0.0012 - mae: 0.0235 - val_loss: 0.0039 - val_mae: 0.0424\n",
      "Epoch 5/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 12ms/step - loss: 0.0011 - mae: 0.0226 - val_loss: 0.0039 - val_mae: 0.0431\n",
      "Epoch 6/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 12ms/step - loss: 0.0011 - mae: 0.0222 - val_loss: 0.0036 - val_mae: 0.0421\n",
      "Epoch 7/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 12ms/step - loss: 0.0010 - mae: 0.0216 - val_loss: 0.0036 - val_mae: 0.0384\n",
      "Epoch 8/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 12ms/step - loss: 0.0010 - mae: 0.0216 - val_loss: 0.0036 - val_mae: 0.0384\n",
      "Epoch 9/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 12ms/step - loss: 0.0010 - mae: 0.0214 - val_loss: 0.0037 - val_mae: 0.0429\n",
      "Epoch 10/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 12ms/step - loss: 0.0010 - mae: 0.0213 - val_loss: 0.0037 - val_mae: 0.0429\n",
      "Epoch 11/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 12ms/step - loss: 0.0010 - mae: 0.0213 - val_loss: 0.0038 - val_mae: 0.0423\n",
      "Epoch 12/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 12ms/step - loss: 0.0010 - mae: 0.0211 - val_loss: 0.0039 - val_mae: 0.0434\n",
      "Epoch 13/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 12ms/step - loss: 9.9472e-04 - mae: 0.0209 - val_loss: 0.0037 - val_mae: 0.0404\n",
      "Epoch 14/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 12ms/step - loss: 9.9330e-04 - mae: 0.0209 - val_loss: 0.0040 - val_mae: 0.0463\n",
      "Epoch 15/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 12ms/step - loss: 9.9141e-04 - mae: 0.0208 - val_loss: 0.0039 - val_mae: 0.0444\n",
      "Epoch 16/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 12ms/step - loss: 9.8612e-04 - mae: 0.0208 - val_loss: 0.0038 - val_mae: 0.0404\n",
      "Epoch 17/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 12ms/step - loss: 9.8309e-04 - mae: 0.0207 - val_loss: 0.0041 - val_mae: 0.0465\n",
      "Epoch 18/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 12ms/step - loss: 9.8904e-04 - mae: 0.0207 - val_loss: 0.0039 - val_mae: 0.0429\n",
      "Epoch 19/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 12ms/step - loss: 9.7569e-04 - mae: 0.0206 - val_loss: 0.0037 - val_mae: 0.0411\n",
      "Epoch 20/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 12ms/step - loss: 9.7056e-04 - mae: 0.0205 - val_loss: 0.0039 - val_mae: 0.0415\n",
      "Epoch 21/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 12ms/step - loss: 9.7291e-04 - mae: 0.0205 - val_loss: 0.0036 - val_mae: 0.0396\n",
      "Epoch 22/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 12ms/step - loss: 9.7425e-04 - mae: 0.0205 - val_loss: 0.0036 - val_mae: 0.0408\n",
      "Epoch 23/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 12ms/step - loss: 9.7061e-04 - mae: 0.0205 - val_loss: 0.0037 - val_mae: 0.0410\n",
      "Epoch 24/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 12ms/step - loss: 9.7105e-04 - mae: 0.0204 - val_loss: 0.0038 - val_mae: 0.0427\n",
      "Epoch 25/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 12ms/step - loss: 9.7046e-04 - mae: 0.0204 - val_loss: 0.0037 - val_mae: 0.0402\n",
      "Epoch 26/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 12ms/step - loss: 9.7217e-04 - mae: 0.0205 - val_loss: 0.0036 - val_mae: 0.0406\n",
      "Epoch 27/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 12ms/step - loss: 9.6628e-04 - mae: 0.0204 - val_loss: 0.0036 - val_mae: 0.0401\n",
      "Epoch 28/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 12ms/step - loss: 9.6510e-04 - mae: 0.0204 - val_loss: 0.0037 - val_mae: 0.0387\n",
      "Epoch 29/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 12ms/step - loss: 9.6561e-04 - mae: 0.0204 - val_loss: 0.0036 - val_mae: 0.0398\n",
      "Epoch 30/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 12ms/step - loss: 9.6786e-04 - mae: 0.0204 - val_loss: 0.0036 - val_mae: 0.0393\n",
      "Epoch 31/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 12ms/step - loss: 9.6385e-04 - mae: 0.0204 - val_loss: 0.0036 - val_mae: 0.0398\n",
      "Epoch 32/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 12ms/step - loss: 9.6546e-04 - mae: 0.0204 - val_loss: 0.0037 - val_mae: 0.0426\n",
      "Epoch 33/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 12ms/step - loss: 9.6248e-04 - mae: 0.0203 - val_loss: 0.0036 - val_mae: 0.0405\n",
      "Epoch 34/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 12ms/step - loss: 9.6722e-04 - mae: 0.0204 - val_loss: 0.0042 - val_mae: 0.0428\n",
      "Epoch 35/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 12ms/step - loss: 9.6166e-04 - mae: 0.0203 - val_loss: 0.0036 - val_mae: 0.0393\n",
      "Epoch 36/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 12ms/step - loss: 9.6453e-04 - mae: 0.0203 - val_loss: 0.0036 - val_mae: 0.0392\n",
      "Epoch 37/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 12ms/step - loss: 9.6072e-04 - mae: 0.0203 - val_loss: 0.0037 - val_mae: 0.0420\n",
      "Epoch 38/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 12ms/step - loss: 9.6797e-04 - mae: 0.0204 - val_loss: 0.0038 - val_mae: 0.0415\n",
      "Epoch 39/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 12ms/step - loss: 9.6395e-04 - mae: 0.0204 - val_loss: 0.0036 - val_mae: 0.0406\n",
      "Epoch 40/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 12ms/step - loss: 9.6214e-04 - mae: 0.0203 - val_loss: 0.0036 - val_mae: 0.0388\n",
      "Epoch 41/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 11ms/step - loss: 9.6565e-04 - mae: 0.0204 - val_loss: 0.0037 - val_mae: 0.0415\n",
      "Epoch 42/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 11ms/step - loss: 9.6144e-04 - mae: 0.0203 - val_loss: 0.0036 - val_mae: 0.0396\n",
      "Epoch 43/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 12ms/step - loss: 9.6127e-04 - mae: 0.0203 - val_loss: 0.0040 - val_mae: 0.0414\n",
      "Epoch 44/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 12ms/step - loss: 9.6016e-04 - mae: 0.0203 - val_loss: 0.0036 - val_mae: 0.0394\n",
      "Epoch 45/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 12ms/step - loss: 9.5945e-04 - mae: 0.0203 - val_loss: 0.0036 - val_mae: 0.0395\n",
      "Epoch 46/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 12ms/step - loss: 9.5771e-04 - mae: 0.0203 - val_loss: 0.0037 - val_mae: 0.0425\n",
      "Epoch 47/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 12ms/step - loss: 9.6206e-04 - mae: 0.0203 - val_loss: 0.0036 - val_mae: 0.0395\n",
      "Epoch 48/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 11ms/step - loss: 9.5759e-04 - mae: 0.0203 - val_loss: 0.0036 - val_mae: 0.0390\n",
      "Epoch 49/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 11ms/step - loss: 9.6077e-04 - mae: 0.0203 - val_loss: 0.0036 - val_mae: 0.0396\n",
      "Epoch 50/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 11ms/step - loss: 9.6517e-04 - mae: 0.0203 - val_loss: 0.0037 - val_mae: 0.0415\n",
      "Epoch 51/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 12ms/step - loss: 9.6127e-04 - mae: 0.0203 - val_loss: 0.0036 - val_mae: 0.0394\n",
      "Epoch 52/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 12ms/step - loss: 9.6010e-04 - mae: 0.0203 - val_loss: 0.0037 - val_mae: 0.0395\n",
      "Epoch 53/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 12ms/step - loss: 9.5833e-04 - mae: 0.0203 - val_loss: 0.0036 - val_mae: 0.0398\n",
      "Epoch 54/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 12ms/step - loss: 9.6150e-04 - mae: 0.0203 - val_loss: 0.0036 - val_mae: 0.0382\n",
      "Epoch 55/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 11ms/step - loss: 9.6109e-04 - mae: 0.0203 - val_loss: 0.0036 - val_mae: 0.0387\n",
      "Epoch 56/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 12ms/step - loss: 9.5815e-04 - mae: 0.0202 - val_loss: 0.0036 - val_mae: 0.0393\n",
      "Epoch 57/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 12ms/step - loss: 9.6008e-04 - mae: 0.0202 - val_loss: 0.0036 - val_mae: 0.0388\n",
      "Epoch 58/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 11ms/step - loss: 9.6115e-04 - mae: 0.0203 - val_loss: 0.0036 - val_mae: 0.0396\n",
      "Epoch 59/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 11ms/step - loss: 9.5883e-04 - mae: 0.0202 - val_loss: 0.0038 - val_mae: 0.0408\n",
      "Epoch 60/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 12ms/step - loss: 9.5804e-04 - mae: 0.0203 - val_loss: 0.0036 - val_mae: 0.0408\n",
      "Epoch 61/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - loss: 9.5997e-04 - mae: 0.0203 - val_loss: 0.0036 - val_mae: 0.0397\n",
      "Epoch 62/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 11ms/step - loss: 9.5623e-04 - mae: 0.0202 - val_loss: 0.0036 - val_mae: 0.0390\n",
      "Epoch 63/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 11ms/step - loss: 9.5723e-04 - mae: 0.0202 - val_loss: 0.0036 - val_mae: 0.0393\n",
      "Epoch 64/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 11ms/step - loss: 9.5746e-04 - mae: 0.0202 - val_loss: 0.0036 - val_mae: 0.0400\n",
      "Epoch 65/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 11ms/step - loss: 9.5972e-04 - mae: 0.0203 - val_loss: 0.0037 - val_mae: 0.0390\n",
      "Epoch 66/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 11ms/step - loss: 9.6053e-04 - mae: 0.0203 - val_loss: 0.0036 - val_mae: 0.0386\n",
      "Epoch 67/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 11ms/step - loss: 9.5876e-04 - mae: 0.0203 - val_loss: 0.0036 - val_mae: 0.0387\n",
      "Epoch 68/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 11ms/step - loss: 9.5943e-04 - mae: 0.0203 - val_loss: 0.0036 - val_mae: 0.0385\n",
      "Epoch 69/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 11ms/step - loss: 9.5757e-04 - mae: 0.0203 - val_loss: 0.0036 - val_mae: 0.0391\n",
      "Epoch 70/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 11ms/step - loss: 9.5919e-04 - mae: 0.0202 - val_loss: 0.0036 - val_mae: 0.0394\n",
      "Epoch 71/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 11ms/step - loss: 9.6216e-04 - mae: 0.0203 - val_loss: 0.0037 - val_mae: 0.0387\n",
      "Epoch 72/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 11ms/step - loss: 9.6046e-04 - mae: 0.0203 - val_loss: 0.0037 - val_mae: 0.0403\n",
      "Epoch 73/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 11ms/step - loss: 9.5932e-04 - mae: 0.0203 - val_loss: 0.0036 - val_mae: 0.0385\n",
      "Epoch 74/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - loss: 9.5620e-04 - mae: 0.0202 - val_loss: 0.0037 - val_mae: 0.0386\n",
      "Epoch 75/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 11ms/step - loss: 9.5902e-04 - mae: 0.0202 - val_loss: 0.0036 - val_mae: 0.0385\n",
      "Epoch 76/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - loss: 9.5822e-04 - mae: 0.0203 - val_loss: 0.0036 - val_mae: 0.0395\n",
      "Epoch 77/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 11ms/step - loss: 9.5779e-04 - mae: 0.0202 - val_loss: 0.0037 - val_mae: 0.0390\n",
      "Epoch 78/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - loss: 9.5878e-04 - mae: 0.0202 - val_loss: 0.0038 - val_mae: 0.0405\n",
      "Epoch 79/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - loss: 9.5705e-04 - mae: 0.0202 - val_loss: 0.0036 - val_mae: 0.0399\n",
      "Epoch 80/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - loss: 9.6002e-04 - mae: 0.0203 - val_loss: 0.0037 - val_mae: 0.0382\n",
      "Epoch 81/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - loss: 9.5783e-04 - mae: 0.0202 - val_loss: 0.0036 - val_mae: 0.0383\n",
      "Epoch 82/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - loss: 9.5992e-04 - mae: 0.0203 - val_loss: 0.0038 - val_mae: 0.0384\n",
      "Epoch 83/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - loss: 9.6062e-04 - mae: 0.0202 - val_loss: 0.0037 - val_mae: 0.0382\n",
      "Epoch 84/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - loss: 9.5713e-04 - mae: 0.0202 - val_loss: 0.0036 - val_mae: 0.0384\n",
      "Epoch 85/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - loss: 9.5640e-04 - mae: 0.0202 - val_loss: 0.0039 - val_mae: 0.0400\n",
      "Epoch 86/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - loss: 9.5854e-04 - mae: 0.0203 - val_loss: 0.0037 - val_mae: 0.0391\n",
      "Epoch 87/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - loss: 9.5509e-04 - mae: 0.0202 - val_loss: 0.0036 - val_mae: 0.0386\n",
      "Epoch 88/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 11ms/step - loss: 9.5539e-04 - mae: 0.0202 - val_loss: 0.0036 - val_mae: 0.0391\n",
      "Epoch 89/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - loss: 9.5930e-04 - mae: 0.0203 - val_loss: 0.0036 - val_mae: 0.0388\n",
      "Epoch 90/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - loss: 9.5539e-04 - mae: 0.0202 - val_loss: 0.0036 - val_mae: 0.0396\n",
      "Epoch 91/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 10ms/step - loss: 9.5669e-04 - mae: 0.0202 - val_loss: 0.0037 - val_mae: 0.0407\n",
      "Epoch 92/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - loss: 9.5800e-04 - mae: 0.0202 - val_loss: 0.0036 - val_mae: 0.0387\n",
      "Epoch 93/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - loss: 9.5725e-04 - mae: 0.0202 - val_loss: 0.0038 - val_mae: 0.0413\n",
      "Epoch 94/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - loss: 9.5732e-04 - mae: 0.0202 - val_loss: 0.0036 - val_mae: 0.0398\n",
      "Epoch 95/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - loss: 9.5767e-04 - mae: 0.0202 - val_loss: 0.0036 - val_mae: 0.0387\n",
      "Epoch 96/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - loss: 9.5712e-04 - mae: 0.0203 - val_loss: 0.0036 - val_mae: 0.0383\n",
      "Epoch 97/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - loss: 9.5764e-04 - mae: 0.0202 - val_loss: 0.0036 - val_mae: 0.0389\n",
      "Epoch 98/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - loss: 9.5599e-04 - mae: 0.0202 - val_loss: 0.0036 - val_mae: 0.0386\n",
      "Epoch 99/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - loss: 9.5499e-04 - mae: 0.0202 - val_loss: 0.0037 - val_mae: 0.0402\n",
      "Epoch 100/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 11ms/step - loss: 9.5517e-04 - mae: 0.0202 - val_loss: 0.0036 - val_mae: 0.0392\n",
      "\u001b[1m1308/1308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step\n",
      "✅ Done with tomato_Kolar_daily.csv | MAE=280.49, RMSE=444.15, R2=0.7441, MAPE=27.12%, Accuracy=72.88%\n",
      "Saved updated CSV with Date, Actual & Predicted: tat_mqa_output_csv\\tomato_Kolar_daily_tat_mqa_updated.csv\n",
      "🚀 Processing: tomato_MadikeriKodagu_daily.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_13\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_13\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_query_attention_13      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">17,216</span> │ input_layer_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiQueryAttention</span>)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_query_attention_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                               │                           │                 │ input_layer_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_26        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_137 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ layer_normalization_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_138 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dense_137[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                               │                           │                 │ dense_138[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_27        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_13   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_139 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ global_average_pooling1d_… │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_13 (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_query_attention_13      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │          \u001b[38;5;34m17,216\u001b[0m │ input_layer_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mMultiQueryAttention\u001b[0m)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_26 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ multi_query_attention_13[\u001b[38;5;34m…\u001b[0m │\n",
       "│                               │                           │                 │ input_layer_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_26        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ add_26[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_137 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │           \u001b[38;5;34m8,320\u001b[0m │ layer_normalization_26[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_138 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │             \u001b[38;5;34m129\u001b[0m │ dense_137[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_27 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_26[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                               │                           │                 │ dense_138[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_27        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ add_27[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_13   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_27[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_139 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │              \u001b[38;5;34m65\u001b[0m │ global_average_pooling1d_… │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,986</span> (101.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25,986\u001b[0m (101.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,986</span> (101.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m25,986\u001b[0m (101.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 14ms/step - loss: 0.0892 - mae: 0.2133 - val_loss: 0.0072 - val_mae: 0.0685\n",
      "Epoch 2/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0507 - mae: 0.1801 - val_loss: 0.0043 - val_mae: 0.0552\n",
      "Epoch 3/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0480 - mae: 0.1734 - val_loss: 0.0042 - val_mae: 0.0549\n",
      "Epoch 4/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0469 - mae: 0.1702 - val_loss: 0.0064 - val_mae: 0.0643\n",
      "Epoch 5/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0466 - mae: 0.1711 - val_loss: 0.0091 - val_mae: 0.0791\n",
      "Epoch 6/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0460 - mae: 0.1693 - val_loss: 0.0034 - val_mae: 0.0479\n",
      "Epoch 7/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0461 - mae: 0.1697 - val_loss: 0.0029 - val_mae: 0.0449\n",
      "Epoch 8/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0455 - mae: 0.1674 - val_loss: 0.0026 - val_mae: 0.0422\n",
      "Epoch 9/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0451 - mae: 0.1674 - val_loss: 0.0071 - val_mae: 0.0719\n",
      "Epoch 10/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0446 - mae: 0.1655 - val_loss: 0.0020 - val_mae: 0.0363\n",
      "Epoch 11/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0434 - mae: 0.1628 - val_loss: 0.0162 - val_mae: 0.1195\n",
      "Epoch 12/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0439 - mae: 0.1632 - val_loss: 0.0017 - val_mae: 0.0328\n",
      "Epoch 13/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0433 - mae: 0.1620 - val_loss: 0.0027 - val_mae: 0.0408\n",
      "Epoch 14/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0429 - mae: 0.1614 - val_loss: 0.0023 - val_mae: 0.0368\n",
      "Epoch 15/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0427 - mae: 0.1613 - val_loss: 0.0031 - val_mae: 0.0446\n",
      "Epoch 16/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0433 - mae: 0.1628 - val_loss: 0.0015 - val_mae: 0.0288\n",
      "Epoch 17/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0429 - mae: 0.1616 - val_loss: 0.0015 - val_mae: 0.0281\n",
      "Epoch 18/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0433 - mae: 0.1618 - val_loss: 0.0149 - val_mae: 0.1172\n",
      "Epoch 19/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0439 - mae: 0.1640 - val_loss: 0.0013 - val_mae: 0.0260\n",
      "Epoch 20/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0425 - mae: 0.1604 - val_loss: 0.0036 - val_mae: 0.0508\n",
      "Epoch 21/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0421 - mae: 0.1593 - val_loss: 0.0030 - val_mae: 0.0462\n",
      "Epoch 22/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0427 - mae: 0.1610 - val_loss: 0.0046 - val_mae: 0.0611\n",
      "Epoch 23/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0421 - mae: 0.1594 - val_loss: 8.5880e-04 - val_mae: 0.0160\n",
      "Epoch 24/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0418 - mae: 0.1586 - val_loss: 7.9767e-04 - val_mae: 0.0149\n",
      "Epoch 25/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0421 - mae: 0.1593 - val_loss: 0.0019 - val_mae: 0.0332\n",
      "Epoch 26/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0428 - mae: 0.1610 - val_loss: 9.9824e-04 - val_mae: 0.0181\n",
      "Epoch 27/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0418 - mae: 0.1580 - val_loss: 0.0011 - val_mae: 0.0208\n",
      "Epoch 28/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0419 - mae: 0.1585 - val_loss: 0.0030 - val_mae: 0.0516\n",
      "Epoch 29/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0422 - mae: 0.1593 - val_loss: 0.0031 - val_mae: 0.0490\n",
      "Epoch 30/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0420 - mae: 0.1589 - val_loss: 0.0012 - val_mae: 0.0232\n",
      "Epoch 31/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0416 - mae: 0.1579 - val_loss: 0.0086 - val_mae: 0.0891\n",
      "Epoch 32/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0419 - mae: 0.1585 - val_loss: 0.0035 - val_mae: 0.0533\n",
      "Epoch 33/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0415 - mae: 0.1585 - val_loss: 0.0085 - val_mae: 0.0886\n",
      "Epoch 34/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0421 - mae: 0.1590 - val_loss: 0.0099 - val_mae: 0.0962\n",
      "Epoch 35/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0417 - mae: 0.1586 - val_loss: 0.0049 - val_mae: 0.0652\n",
      "Epoch 36/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0412 - mae: 0.1572 - val_loss: 0.0019 - val_mae: 0.0352\n",
      "Epoch 37/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0413 - mae: 0.1578 - val_loss: 0.0038 - val_mae: 0.0558\n",
      "Epoch 38/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0412 - mae: 0.1575 - val_loss: 0.0010 - val_mae: 0.0204\n",
      "Epoch 39/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0408 - mae: 0.1567 - val_loss: 0.0047 - val_mae: 0.0638\n",
      "Epoch 40/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0413 - mae: 0.1577 - val_loss: 0.0056 - val_mae: 0.0706\n",
      "Epoch 41/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0408 - mae: 0.1561 - val_loss: 7.4949e-04 - val_mae: 0.0193\n",
      "Epoch 42/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0411 - mae: 0.1571 - val_loss: 7.1166e-04 - val_mae: 0.0176\n",
      "Epoch 43/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0411 - mae: 0.1576 - val_loss: 0.0205 - val_mae: 0.1392\n",
      "Epoch 44/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0410 - mae: 0.1569 - val_loss: 0.0024 - val_mae: 0.0422\n",
      "Epoch 45/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0406 - mae: 0.1554 - val_loss: 0.0019 - val_mae: 0.0363\n",
      "Epoch 46/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0407 - mae: 0.1560 - val_loss: 0.0112 - val_mae: 0.1024\n",
      "Epoch 47/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0406 - mae: 0.1557 - val_loss: 0.0020 - val_mae: 0.0360\n",
      "Epoch 48/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0408 - mae: 0.1571 - val_loss: 0.0049 - val_mae: 0.0648\n",
      "Epoch 49/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0406 - mae: 0.1565 - val_loss: 0.0055 - val_mae: 0.0682\n",
      "Epoch 50/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0410 - mae: 0.1576 - val_loss: 0.0027 - val_mae: 0.0461\n",
      "Epoch 51/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0408 - mae: 0.1571 - val_loss: 0.0045 - val_mae: 0.0629\n",
      "Epoch 52/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0405 - mae: 0.1555 - val_loss: 0.0024 - val_mae: 0.0429\n",
      "Epoch 53/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0407 - mae: 0.1567 - val_loss: 0.0065 - val_mae: 0.0760\n",
      "Epoch 54/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0404 - mae: 0.1558 - val_loss: 0.0092 - val_mae: 0.0917\n",
      "Epoch 55/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0403 - mae: 0.1555 - val_loss: 5.9607e-04 - val_mae: 0.0085\n",
      "Epoch 56/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0407 - mae: 0.1564 - val_loss: 0.0045 - val_mae: 0.0626\n",
      "Epoch 57/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0408 - mae: 0.1567 - val_loss: 0.0027 - val_mae: 0.0442\n",
      "Epoch 58/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0404 - mae: 0.1559 - val_loss: 0.0086 - val_mae: 0.0893\n",
      "Epoch 59/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0409 - mae: 0.1570 - val_loss: 0.0016 - val_mae: 0.0324\n",
      "Epoch 60/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0404 - mae: 0.1557 - val_loss: 0.0090 - val_mae: 0.0918\n",
      "Epoch 61/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0408 - mae: 0.1566 - val_loss: 0.0068 - val_mae: 0.0785\n",
      "Epoch 62/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0407 - mae: 0.1560 - val_loss: 0.0022 - val_mae: 0.0406\n",
      "Epoch 63/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0407 - mae: 0.1562 - val_loss: 0.0169 - val_mae: 0.1252\n",
      "Epoch 64/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0405 - mae: 0.1562 - val_loss: 0.0013 - val_mae: 0.0259\n",
      "Epoch 65/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0407 - mae: 0.1560 - val_loss: 0.0025 - val_mae: 0.0438\n",
      "Epoch 66/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0404 - mae: 0.1555 - val_loss: 0.0082 - val_mae: 0.0864\n",
      "Epoch 67/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0404 - mae: 0.1554 - val_loss: 0.0068 - val_mae: 0.0788\n",
      "Epoch 68/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0403 - mae: 0.1556 - val_loss: 0.0048 - val_mae: 0.0653\n",
      "Epoch 69/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0405 - mae: 0.1564 - val_loss: 0.0020 - val_mae: 0.0382\n",
      "Epoch 70/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0404 - mae: 0.1554 - val_loss: 0.0059 - val_mae: 0.0723\n",
      "Epoch 71/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0404 - mae: 0.1559 - val_loss: 0.0031 - val_mae: 0.0494\n",
      "Epoch 72/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0404 - mae: 0.1553 - val_loss: 0.0032 - val_mae: 0.0510\n",
      "Epoch 73/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0406 - mae: 0.1562 - val_loss: 0.0076 - val_mae: 0.0836\n",
      "Epoch 74/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0406 - mae: 0.1565 - val_loss: 0.0014 - val_mae: 0.0286\n",
      "Epoch 75/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0403 - mae: 0.1558 - val_loss: 0.0032 - val_mae: 0.0514\n",
      "Epoch 76/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0404 - mae: 0.1555 - val_loss: 0.0132 - val_mae: 0.1116\n",
      "Epoch 77/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0404 - mae: 0.1559 - val_loss: 0.0087 - val_mae: 0.0897\n",
      "Epoch 78/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0404 - mae: 0.1556 - val_loss: 0.0118 - val_mae: 0.1049\n",
      "Epoch 79/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0404 - mae: 0.1556 - val_loss: 0.0022 - val_mae: 0.0406\n",
      "Epoch 80/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0404 - mae: 0.1556 - val_loss: 0.0076 - val_mae: 0.0835\n",
      "Epoch 81/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0403 - mae: 0.1560 - val_loss: 0.0085 - val_mae: 0.0887\n",
      "Epoch 82/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0405 - mae: 0.1560 - val_loss: 0.0029 - val_mae: 0.0473\n",
      "Epoch 83/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0401 - mae: 0.1549 - val_loss: 0.0054 - val_mae: 0.0693\n",
      "Epoch 84/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0403 - mae: 0.1551 - val_loss: 0.0049 - val_mae: 0.0653\n",
      "Epoch 85/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0403 - mae: 0.1554 - val_loss: 5.7314e-04 - val_mae: 0.0126\n",
      "Epoch 86/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0405 - mae: 0.1558 - val_loss: 0.0023 - val_mae: 0.0397\n",
      "Epoch 87/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0401 - mae: 0.1550 - val_loss: 0.0049 - val_mae: 0.0654\n",
      "Epoch 88/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0403 - mae: 0.1552 - val_loss: 0.0074 - val_mae: 0.0819\n",
      "Epoch 89/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0404 - mae: 0.1559 - val_loss: 0.0011 - val_mae: 0.0230\n",
      "Epoch 90/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0405 - mae: 0.1553 - val_loss: 0.0027 - val_mae: 0.0454\n",
      "Epoch 91/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0404 - mae: 0.1558 - val_loss: 0.0085 - val_mae: 0.0888\n",
      "Epoch 92/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0403 - mae: 0.1555 - val_loss: 0.0079 - val_mae: 0.0854\n",
      "Epoch 93/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0404 - mae: 0.1557 - val_loss: 0.0053 - val_mae: 0.0688\n",
      "Epoch 94/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0406 - mae: 0.1558 - val_loss: 0.0074 - val_mae: 0.0823\n",
      "Epoch 95/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0403 - mae: 0.1554 - val_loss: 0.0156 - val_mae: 0.1213\n",
      "Epoch 96/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0401 - mae: 0.1547 - val_loss: 0.0086 - val_mae: 0.0892\n",
      "Epoch 97/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0404 - mae: 0.1556 - val_loss: 7.3390e-04 - val_mae: 0.0196\n",
      "Epoch 98/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0402 - mae: 0.1556 - val_loss: 0.0039 - val_mae: 0.0572\n",
      "Epoch 99/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0404 - mae: 0.1563 - val_loss: 0.0024 - val_mae: 0.0430\n",
      "Epoch 100/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0404 - mae: 0.1558 - val_loss: 0.0017 - val_mae: 0.0325\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step   \n",
      "✅ Done with tomato_MadikeriKodagu_daily.csv | MAE=225.66, RMSE=308.7, R2=0.4641, MAPE=30.04%, Accuracy=69.96%\n",
      "Saved updated CSV with Date, Actual & Predicted: tat_mqa_output_csv\\tomato_MadikeriKodagu_daily_tat_mqa_updated.csv\n",
      "🚀 Processing: tomato_Mandya_daily.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_14\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_14\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_query_attention_14      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">17,216</span> │ input_layer_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiQueryAttention</span>)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_query_attention_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                               │                           │                 │ input_layer_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_28        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_28[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_147 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ layer_normalization_28[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_148 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dense_147[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_28[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                               │                           │                 │ dense_148[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_29        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_29[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_14   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_29[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_149 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ global_average_pooling1d_… │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_14 (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_query_attention_14      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │          \u001b[38;5;34m17,216\u001b[0m │ input_layer_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mMultiQueryAttention\u001b[0m)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_28 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ multi_query_attention_14[\u001b[38;5;34m…\u001b[0m │\n",
       "│                               │                           │                 │ input_layer_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_28        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ add_28[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_147 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │           \u001b[38;5;34m8,320\u001b[0m │ layer_normalization_28[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_148 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │             \u001b[38;5;34m129\u001b[0m │ dense_147[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_29 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_28[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                               │                           │                 │ dense_148[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_29        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ add_29[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_14   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_29[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_149 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │              \u001b[38;5;34m65\u001b[0m │ global_average_pooling1d_… │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,986</span> (101.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25,986\u001b[0m (101.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,986</span> (101.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m25,986\u001b[0m (101.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 12ms/step - loss: 0.0340 - mae: 0.0876 - val_loss: 0.0116 - val_mae: 0.0802\n",
      "Epoch 2/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - loss: 0.0032 - mae: 0.0428 - val_loss: 0.0138 - val_mae: 0.0638\n",
      "Epoch 3/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - loss: 0.0022 - mae: 0.0346 - val_loss: 0.0134 - val_mae: 0.0644\n",
      "Epoch 4/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - loss: 0.0019 - mae: 0.0309 - val_loss: 0.0137 - val_mae: 0.0643\n",
      "Epoch 5/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - loss: 0.0018 - mae: 0.0298 - val_loss: 0.0144 - val_mae: 0.0680\n",
      "Epoch 6/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - loss: 0.0017 - mae: 0.0294 - val_loss: 0.0123 - val_mae: 0.0605\n",
      "Epoch 7/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - loss: 0.0017 - mae: 0.0288 - val_loss: 0.0113 - val_mae: 0.0610\n",
      "Epoch 8/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - loss: 0.0016 - mae: 0.0284 - val_loss: 0.0122 - val_mae: 0.0607\n",
      "Epoch 9/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - loss: 0.0017 - mae: 0.0291 - val_loss: 0.0110 - val_mae: 0.0631\n",
      "Epoch 10/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - loss: 0.0017 - mae: 0.0283 - val_loss: 0.0101 - val_mae: 0.0623\n",
      "Epoch 11/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - loss: 0.0016 - mae: 0.0273 - val_loss: 0.0108 - val_mae: 0.0575\n",
      "Epoch 12/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - loss: 0.0016 - mae: 0.0274 - val_loss: 0.0095 - val_mae: 0.0572\n",
      "Epoch 13/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - loss: 0.0016 - mae: 0.0274 - val_loss: 0.0102 - val_mae: 0.0579\n",
      "Epoch 14/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - loss: 0.0016 - mae: 0.0271 - val_loss: 0.0100 - val_mae: 0.0567\n",
      "Epoch 15/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - loss: 0.0016 - mae: 0.0270 - val_loss: 0.0096 - val_mae: 0.0557\n",
      "Epoch 16/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - loss: 0.0015 - mae: 0.0267 - val_loss: 0.0089 - val_mae: 0.0540\n",
      "Epoch 17/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - loss: 0.0015 - mae: 0.0267 - val_loss: 0.0084 - val_mae: 0.0535\n",
      "Epoch 18/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - loss: 0.0015 - mae: 0.0266 - val_loss: 0.0077 - val_mae: 0.0523\n",
      "Epoch 19/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - loss: 0.0015 - mae: 0.0265 - val_loss: 0.0082 - val_mae: 0.0530\n",
      "Epoch 20/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - loss: 0.0015 - mae: 0.0263 - val_loss: 0.0070 - val_mae: 0.0525\n",
      "Epoch 21/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - loss: 0.0015 - mae: 0.0264 - val_loss: 0.0067 - val_mae: 0.0506\n",
      "Epoch 22/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - loss: 0.0015 - mae: 0.0264 - val_loss: 0.0082 - val_mae: 0.0533\n",
      "Epoch 23/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - loss: 0.0015 - mae: 0.0262 - val_loss: 0.0063 - val_mae: 0.0508\n",
      "Epoch 24/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - loss: 0.0015 - mae: 0.0264 - val_loss: 0.0065 - val_mae: 0.0533\n",
      "Epoch 25/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - loss: 0.0015 - mae: 0.0262 - val_loss: 0.0083 - val_mae: 0.0533\n",
      "Epoch 26/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - loss: 0.0015 - mae: 0.0264 - val_loss: 0.0083 - val_mae: 0.0542\n",
      "Epoch 27/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - loss: 0.0015 - mae: 0.0260 - val_loss: 0.0078 - val_mae: 0.0529\n",
      "Epoch 28/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - loss: 0.0015 - mae: 0.0260 - val_loss: 0.0076 - val_mae: 0.0517\n",
      "Epoch 29/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - loss: 0.0015 - mae: 0.0259 - val_loss: 0.0070 - val_mae: 0.0509\n",
      "Epoch 30/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - loss: 0.0015 - mae: 0.0260 - val_loss: 0.0066 - val_mae: 0.0517\n",
      "Epoch 31/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - loss: 0.0015 - mae: 0.0259 - val_loss: 0.0083 - val_mae: 0.0530\n",
      "Epoch 32/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - loss: 0.0015 - mae: 0.0258 - val_loss: 0.0074 - val_mae: 0.0514\n",
      "Epoch 33/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - loss: 0.0015 - mae: 0.0259 - val_loss: 0.0070 - val_mae: 0.0515\n",
      "Epoch 34/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - loss: 0.0015 - mae: 0.0257 - val_loss: 0.0086 - val_mae: 0.0535\n",
      "Epoch 35/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - loss: 0.0015 - mae: 0.0258 - val_loss: 0.0079 - val_mae: 0.0524\n",
      "Epoch 36/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - loss: 0.0015 - mae: 0.0257 - val_loss: 0.0067 - val_mae: 0.0515\n",
      "Epoch 37/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 0.0066 - val_mae: 0.0517\n",
      "Epoch 38/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - loss: 0.0015 - mae: 0.0257 - val_loss: 0.0068 - val_mae: 0.0535\n",
      "Epoch 39/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - loss: 0.0015 - mae: 0.0258 - val_loss: 0.0081 - val_mae: 0.0526\n",
      "Epoch 40/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - loss: 0.0015 - mae: 0.0257 - val_loss: 0.0069 - val_mae: 0.0566\n",
      "Epoch 41/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0072 - val_mae: 0.0512\n",
      "Epoch 42/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0076 - val_mae: 0.0518\n",
      "Epoch 43/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 0.0091 - val_mae: 0.0550\n",
      "Epoch 44/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 0.0068 - val_mae: 0.0508\n",
      "Epoch 45/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 0.0067 - val_mae: 0.0514\n",
      "Epoch 46/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 0.0079 - val_mae: 0.0522\n",
      "Epoch 47/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 0.0076 - val_mae: 0.0518\n",
      "Epoch 48/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0069 - val_mae: 0.0572\n",
      "Epoch 49/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0075 - val_mae: 0.0520\n",
      "Epoch 50/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 0.0070 - val_mae: 0.0525\n",
      "Epoch 51/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0070 - val_mae: 0.0534\n",
      "Epoch 52/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 0.0076 - val_mae: 0.0522\n",
      "Epoch 53/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0082 - val_mae: 0.0527\n",
      "Epoch 54/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0076 - val_mae: 0.0528\n",
      "Epoch 55/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 0.0077 - val_mae: 0.0522\n",
      "Epoch 56/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0081 - val_mae: 0.0526\n",
      "Epoch 57/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 0.0077 - val_mae: 0.0539\n",
      "Epoch 58/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 0.0073 - val_mae: 0.0568\n",
      "Epoch 59/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 0.0081 - val_mae: 0.0529\n",
      "Epoch 60/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0077 - val_mae: 0.0533\n",
      "Epoch 61/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0089 - val_mae: 0.0540\n",
      "Epoch 62/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 0.0083 - val_mae: 0.0533\n",
      "Epoch 63/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 0.0099 - val_mae: 0.0559\n",
      "Epoch 64/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 0.0085 - val_mae: 0.0541\n",
      "Epoch 65/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0091 - val_mae: 0.0542\n",
      "Epoch 66/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0095 - val_mae: 0.0548\n",
      "Epoch 67/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0095 - val_mae: 0.0550\n",
      "Epoch 68/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 0.0090 - val_mae: 0.0547\n",
      "Epoch 69/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0089 - val_mae: 0.0555\n",
      "Epoch 70/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0109 - val_mae: 0.0575\n",
      "Epoch 71/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0096 - val_mae: 0.0568\n",
      "Epoch 72/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0097 - val_mae: 0.0595\n",
      "Epoch 73/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 0.0095 - val_mae: 0.0565\n",
      "Epoch 74/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0108 - val_mae: 0.0570\n",
      "Epoch 75/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0115 - val_mae: 0.0583\n",
      "Epoch 76/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0106 - val_mae: 0.0577\n",
      "Epoch 77/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0112 - val_mae: 0.0579\n",
      "Epoch 78/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0109 - val_mae: 0.0581\n",
      "Epoch 79/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0113 - val_mae: 0.0592\n",
      "Epoch 80/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 0.0122 - val_mae: 0.0596\n",
      "Epoch 81/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0118 - val_mae: 0.0591\n",
      "Epoch 82/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0108 - val_mae: 0.0574\n",
      "Epoch 83/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0122 - val_mae: 0.0599\n",
      "Epoch 84/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 0.0122 - val_mae: 0.0596\n",
      "Epoch 85/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0123 - val_mae: 0.0603\n",
      "Epoch 86/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0121 - val_mae: 0.0598\n",
      "Epoch 87/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0113 - val_mae: 0.0578\n",
      "Epoch 88/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0122 - val_mae: 0.0597\n",
      "Epoch 89/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0116 - val_mae: 0.0584\n",
      "Epoch 90/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0125 - val_mae: 0.0609\n",
      "Epoch 91/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0121 - val_mae: 0.0599\n",
      "Epoch 92/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0121 - val_mae: 0.0594\n",
      "Epoch 93/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0114 - val_mae: 0.0597\n",
      "Epoch 94/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0115 - val_mae: 0.0585\n",
      "Epoch 95/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0118 - val_mae: 0.0598\n",
      "Epoch 96/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 0.0113 - val_mae: 0.0580\n",
      "Epoch 97/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0109 - val_mae: 0.0596\n",
      "Epoch 98/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0122 - val_mae: 0.0602\n",
      "Epoch 99/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0122 - val_mae: 0.0597\n",
      "Epoch 100/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0117 - val_mae: 0.0603\n",
      "\u001b[1m545/545\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step\n",
      "✅ Done with tomato_Mandya_daily.csv | MAE=414.39, RMSE=737.84, R2=0.366, MAPE=70.89%, Accuracy=29.11%\n",
      "Saved updated CSV with Date, Actual & Predicted: tat_mqa_output_csv\\tomato_Mandya_daily_tat_mqa_updated.csv\n",
      "🚀 Processing: tomato_Mysore_daily.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_15\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_15\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_query_attention_15      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">17,216</span> │ input_layer_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiQueryAttention</span>)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_query_attention_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                               │                           │                 │ input_layer_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_30        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_30[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_157 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ layer_normalization_30[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_158 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dense_157[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_30[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                               │                           │                 │ dense_158[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_31        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_31[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_15   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_31[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_159 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ global_average_pooling1d_… │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_15 (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_query_attention_15      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │          \u001b[38;5;34m17,216\u001b[0m │ input_layer_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mMultiQueryAttention\u001b[0m)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_30 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ multi_query_attention_15[\u001b[38;5;34m…\u001b[0m │\n",
       "│                               │                           │                 │ input_layer_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_30        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ add_30[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_157 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │           \u001b[38;5;34m8,320\u001b[0m │ layer_normalization_30[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_158 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │             \u001b[38;5;34m129\u001b[0m │ dense_157[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_31 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_30[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                               │                           │                 │ dense_158[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_31        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ add_31[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_15   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_31[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_159 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │              \u001b[38;5;34m65\u001b[0m │ global_average_pooling1d_… │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,986</span> (101.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25,986\u001b[0m (101.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,986</span> (101.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m25,986\u001b[0m (101.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 12ms/step - loss: 0.0256 - mae: 0.0780 - val_loss: 0.0045 - val_mae: 0.0426\n",
      "Epoch 2/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - loss: 0.0023 - mae: 0.0355 - val_loss: 0.0040 - val_mae: 0.0422\n",
      "Epoch 3/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - loss: 0.0019 - mae: 0.0307 - val_loss: 0.0042 - val_mae: 0.0423\n",
      "Epoch 4/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - loss: 0.0018 - mae: 0.0298 - val_loss: 0.0039 - val_mae: 0.0432\n",
      "Epoch 5/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - loss: 0.0018 - mae: 0.0294 - val_loss: 0.0039 - val_mae: 0.0448\n",
      "Epoch 6/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 12ms/step - loss: 0.0018 - mae: 0.0294 - val_loss: 0.0039 - val_mae: 0.0426\n",
      "Epoch 7/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - loss: 0.0017 - mae: 0.0285 - val_loss: 0.0043 - val_mae: 0.0436\n",
      "Epoch 8/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0017 - mae: 0.0283 - val_loss: 0.0043 - val_mae: 0.0444\n",
      "Epoch 9/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - loss: 0.0016 - mae: 0.0277 - val_loss: 0.0066 - val_mae: 0.0577\n",
      "Epoch 10/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - loss: 0.0016 - mae: 0.0278 - val_loss: 0.0038 - val_mae: 0.0426\n",
      "Epoch 11/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 12ms/step - loss: 0.0016 - mae: 0.0275 - val_loss: 0.0038 - val_mae: 0.0428\n",
      "Epoch 12/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - loss: 0.0016 - mae: 0.0276 - val_loss: 0.0037 - val_mae: 0.0429\n",
      "Epoch 13/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - loss: 0.0016 - mae: 0.0271 - val_loss: 0.0052 - val_mae: 0.0485\n",
      "Epoch 14/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - loss: 0.0016 - mae: 0.0270 - val_loss: 0.0039 - val_mae: 0.0426\n",
      "Epoch 15/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - loss: 0.0016 - mae: 0.0269 - val_loss: 0.0041 - val_mae: 0.0474\n",
      "Epoch 16/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 12ms/step - loss: 0.0016 - mae: 0.0267 - val_loss: 0.0042 - val_mae: 0.0437\n",
      "Epoch 17/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0266 - val_loss: 0.0040 - val_mae: 0.0469\n",
      "Epoch 18/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0265 - val_loss: 0.0038 - val_mae: 0.0425\n",
      "Epoch 19/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 12ms/step - loss: 0.0016 - mae: 0.0267 - val_loss: 0.0038 - val_mae: 0.0429\n",
      "Epoch 20/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - loss: 0.0015 - mae: 0.0264 - val_loss: 0.0038 - val_mae: 0.0430\n",
      "Epoch 21/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - loss: 0.0015 - mae: 0.0264 - val_loss: 0.0038 - val_mae: 0.0432\n",
      "Epoch 22/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - loss: 0.0015 - mae: 0.0264 - val_loss: 0.0038 - val_mae: 0.0440\n",
      "Epoch 23/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - loss: 0.0015 - mae: 0.0265 - val_loss: 0.0038 - val_mae: 0.0430\n",
      "Epoch 24/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - loss: 0.0015 - mae: 0.0263 - val_loss: 0.0038 - val_mae: 0.0428\n",
      "Epoch 25/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 12ms/step - loss: 0.0015 - mae: 0.0262 - val_loss: 0.0038 - val_mae: 0.0444\n",
      "Epoch 26/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - loss: 0.0015 - mae: 0.0262 - val_loss: 0.0040 - val_mae: 0.0462\n",
      "Epoch 27/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - loss: 0.0015 - mae: 0.0262 - val_loss: 0.0039 - val_mae: 0.0448\n",
      "Epoch 28/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - loss: 0.0015 - mae: 0.0261 - val_loss: 0.0038 - val_mae: 0.0442\n",
      "Epoch 29/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - loss: 0.0015 - mae: 0.0263 - val_loss: 0.0038 - val_mae: 0.0430\n",
      "Epoch 30/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - loss: 0.0015 - mae: 0.0260 - val_loss: 0.0038 - val_mae: 0.0428\n",
      "Epoch 31/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - loss: 0.0015 - mae: 0.0260 - val_loss: 0.0039 - val_mae: 0.0444\n",
      "Epoch 32/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - loss: 0.0015 - mae: 0.0260 - val_loss: 0.0039 - val_mae: 0.0456\n",
      "Epoch 33/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 12ms/step - loss: 0.0015 - mae: 0.0259 - val_loss: 0.0043 - val_mae: 0.0492\n",
      "Epoch 34/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 12ms/step - loss: 0.0015 - mae: 0.0259 - val_loss: 0.0038 - val_mae: 0.0426\n",
      "Epoch 35/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 12ms/step - loss: 0.0015 - mae: 0.0257 - val_loss: 0.0038 - val_mae: 0.0435\n",
      "Epoch 36/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - loss: 0.0015 - mae: 0.0257 - val_loss: 0.0038 - val_mae: 0.0440\n",
      "Epoch 37/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - loss: 0.0015 - mae: 0.0257 - val_loss: 0.0040 - val_mae: 0.0460\n",
      "Epoch 38/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 12ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 0.0040 - val_mae: 0.0457\n",
      "Epoch 39/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 12ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 0.0038 - val_mae: 0.0443\n",
      "Epoch 40/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 12ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 0.0039 - val_mae: 0.0454\n",
      "Epoch 41/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 12ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 0.0039 - val_mae: 0.0445\n",
      "Epoch 42/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 12ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0046 - val_mae: 0.0497\n",
      "Epoch 43/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 12ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0042 - val_mae: 0.0473\n",
      "Epoch 44/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0039 - val_mae: 0.0450\n",
      "Epoch 45/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 0.0039 - val_mae: 0.0445\n",
      "Epoch 46/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 12ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0041 - val_mae: 0.0467\n",
      "Epoch 47/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 12ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0038 - val_mae: 0.0442\n",
      "Epoch 48/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 12ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0038 - val_mae: 0.0440\n",
      "Epoch 49/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 12ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0038 - val_mae: 0.0432\n",
      "Epoch 50/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 12ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0039 - val_mae: 0.0447\n",
      "Epoch 51/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0039 - val_mae: 0.0453\n",
      "Epoch 52/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0039 - val_mae: 0.0426\n",
      "Epoch 53/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0038 - val_mae: 0.0437\n",
      "Epoch 54/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0037 - val_mae: 0.0431\n",
      "Epoch 55/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0038 - val_mae: 0.0437\n",
      "Epoch 56/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0038 - val_mae: 0.0439\n",
      "Epoch 57/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0037 - val_mae: 0.0431\n",
      "Epoch 58/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0038 - val_mae: 0.0447\n",
      "Epoch 59/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0041 - val_mae: 0.0465\n",
      "Epoch 60/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0039 - val_mae: 0.0443\n",
      "Epoch 61/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0039 - val_mae: 0.0452\n",
      "Epoch 62/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0038 - val_mae: 0.0433\n",
      "Epoch 63/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 11ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0038 - val_mae: 0.0426\n",
      "Epoch 64/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0039 - val_mae: 0.0449\n",
      "Epoch 65/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0037 - val_mae: 0.0428\n",
      "Epoch 66/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0039 - val_mae: 0.0450\n",
      "Epoch 67/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0037 - val_mae: 0.0429\n",
      "Epoch 68/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0038 - val_mae: 0.0427\n",
      "Epoch 69/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0043 - val_mae: 0.0474\n",
      "Epoch 70/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0039 - val_mae: 0.0446\n",
      "Epoch 71/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0039 - val_mae: 0.0456\n",
      "Epoch 72/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 11ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0041 - val_mae: 0.0470\n",
      "Epoch 73/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0042 - val_mae: 0.0468\n",
      "Epoch 74/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0039 - val_mae: 0.0428\n",
      "Epoch 75/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0038 - val_mae: 0.0444\n",
      "Epoch 76/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0041 - val_mae: 0.0463\n",
      "Epoch 77/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0038 - val_mae: 0.0430\n",
      "Epoch 78/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0253 - val_loss: 0.0039 - val_mae: 0.0445\n",
      "Epoch 79/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 10ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0042 - val_mae: 0.0480\n",
      "Epoch 80/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0038 - val_mae: 0.0426\n",
      "Epoch 81/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0253 - val_loss: 0.0038 - val_mae: 0.0440\n",
      "Epoch 82/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0038 - val_mae: 0.0433\n",
      "Epoch 83/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0038 - val_mae: 0.0427\n",
      "Epoch 84/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0038 - val_mae: 0.0425\n",
      "Epoch 85/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0038 - val_mae: 0.0435\n",
      "Epoch 86/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0039 - val_mae: 0.0428\n",
      "Epoch 87/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 11ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0038 - val_mae: 0.0442\n",
      "Epoch 88/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0040 - val_mae: 0.0458\n",
      "Epoch 89/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0038 - val_mae: 0.0438\n",
      "Epoch 90/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0015 - mae: 0.0253 - val_loss: 0.0038 - val_mae: 0.0440\n",
      "Epoch 91/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0038 - val_mae: 0.0426\n",
      "Epoch 92/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0039 - val_mae: 0.0445\n",
      "Epoch 93/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0039 - val_mae: 0.0454\n",
      "Epoch 94/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0038 - val_mae: 0.0429\n",
      "Epoch 95/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0038 - val_mae: 0.0440\n",
      "Epoch 96/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0042 - val_mae: 0.0469\n",
      "Epoch 97/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0015 - mae: 0.0253 - val_loss: 0.0038 - val_mae: 0.0439\n",
      "Epoch 98/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0038 - val_mae: 0.0431\n",
      "Epoch 99/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0037 - val_mae: 0.0428\n",
      "Epoch 100/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0039 - val_mae: 0.0427\n",
      "\u001b[1m855/855\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step\n",
      "✅ Done with tomato_Mysore_daily.csv | MAE=426.33, RMSE=669.73, R2=0.4159, MAPE=38.01%, Accuracy=61.99%\n",
      "Saved updated CSV with Date, Actual & Predicted: tat_mqa_output_csv\\tomato_Mysore_daily_tat_mqa_updated.csv\n",
      "🚀 Processing: tomato_Shimoga_daily.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_16\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_16\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_query_attention_16      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">17,216</span> │ input_layer_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiQueryAttention</span>)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_query_attention_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                               │                           │                 │ input_layer_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_32        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_32[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_167 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ layer_normalization_32[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_168 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dense_167[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_32[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                               │                           │                 │ dense_168[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_33        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_33[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_16   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_33[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_169 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ global_average_pooling1d_… │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_16 (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_query_attention_16      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │          \u001b[38;5;34m17,216\u001b[0m │ input_layer_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mMultiQueryAttention\u001b[0m)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_32 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ multi_query_attention_16[\u001b[38;5;34m…\u001b[0m │\n",
       "│                               │                           │                 │ input_layer_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_32        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ add_32[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_167 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │           \u001b[38;5;34m8,320\u001b[0m │ layer_normalization_32[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_168 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │             \u001b[38;5;34m129\u001b[0m │ dense_167[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_33 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_32[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                               │                           │                 │ dense_168[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_33        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ add_33[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_16   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_33[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_169 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │              \u001b[38;5;34m65\u001b[0m │ global_average_pooling1d_… │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,986</span> (101.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25,986\u001b[0m (101.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,986</span> (101.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m25,986\u001b[0m (101.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 15ms/step - loss: 0.0266 - mae: 0.0799 - val_loss: 0.0052 - val_mae: 0.0453\n",
      "Epoch 2/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - loss: 0.0024 - mae: 0.0376 - val_loss: 0.0055 - val_mae: 0.0422\n",
      "Epoch 3/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - loss: 0.0016 - mae: 0.0300 - val_loss: 0.0055 - val_mae: 0.0423\n",
      "Epoch 4/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - loss: 0.0013 - mae: 0.0253 - val_loss: 0.0053 - val_mae: 0.0503\n",
      "Epoch 5/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - loss: 0.0012 - mae: 0.0240 - val_loss: 0.0060 - val_mae: 0.0462\n",
      "Epoch 6/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - loss: 0.0011 - mae: 0.0228 - val_loss: 0.0057 - val_mae: 0.0463\n",
      "Epoch 7/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - loss: 0.0011 - mae: 0.0219 - val_loss: 0.0072 - val_mae: 0.0520\n",
      "Epoch 8/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - loss: 9.9003e-04 - mae: 0.0211 - val_loss: 0.0064 - val_mae: 0.0479\n",
      "Epoch 9/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - loss: 9.4330e-04 - mae: 0.0201 - val_loss: 0.0082 - val_mae: 0.0542\n",
      "Epoch 10/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - loss: 9.8175e-04 - mae: 0.0209 - val_loss: 0.0073 - val_mae: 0.0499\n",
      "Epoch 11/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - loss: 9.6542e-04 - mae: 0.0204 - val_loss: 0.0072 - val_mae: 0.0481\n",
      "Epoch 12/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - loss: 9.7849e-04 - mae: 0.0208 - val_loss: 0.0080 - val_mae: 0.0532\n",
      "Epoch 13/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - loss: 9.5687e-04 - mae: 0.0205 - val_loss: 0.0073 - val_mae: 0.0485\n",
      "Epoch 14/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - loss: 9.7685e-04 - mae: 0.0207 - val_loss: 0.0075 - val_mae: 0.0497\n",
      "Epoch 15/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - loss: 9.9426e-04 - mae: 0.0212 - val_loss: 0.0085 - val_mae: 0.0566\n",
      "Epoch 16/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - loss: 9.4801e-04 - mae: 0.0200 - val_loss: 0.0074 - val_mae: 0.0495\n",
      "Epoch 17/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 9.5790e-04 - mae: 0.0201 - val_loss: 0.0084 - val_mae: 0.0561\n",
      "Epoch 18/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 9.8804e-04 - mae: 0.0206 - val_loss: 0.0072 - val_mae: 0.0486\n",
      "Epoch 19/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 9.4880e-04 - mae: 0.0198 - val_loss: 0.0076 - val_mae: 0.0504\n",
      "Epoch 20/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - loss: 9.5388e-04 - mae: 0.0201 - val_loss: 0.0069 - val_mae: 0.0501\n",
      "Epoch 21/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 9.1686e-04 - mae: 0.0194 - val_loss: 0.0071 - val_mae: 0.0486\n",
      "Epoch 22/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - loss: 9.2739e-04 - mae: 0.0195 - val_loss: 0.0071 - val_mae: 0.0497\n",
      "Epoch 23/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - loss: 9.2821e-04 - mae: 0.0195 - val_loss: 0.0071 - val_mae: 0.0483\n",
      "Epoch 24/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 9.3284e-04 - mae: 0.0198 - val_loss: 0.0078 - val_mae: 0.0522\n",
      "Epoch 25/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 9.0652e-04 - mae: 0.0194 - val_loss: 0.0069 - val_mae: 0.0483\n",
      "Epoch 26/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 9.4182e-04 - mae: 0.0199 - val_loss: 0.0076 - val_mae: 0.0526\n",
      "Epoch 27/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - loss: 9.1491e-04 - mae: 0.0192 - val_loss: 0.0071 - val_mae: 0.0483\n",
      "Epoch 28/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 9.1906e-04 - mae: 0.0194 - val_loss: 0.0068 - val_mae: 0.0491\n",
      "Epoch 29/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 9.0541e-04 - mae: 0.0190 - val_loss: 0.0071 - val_mae: 0.0488\n",
      "Epoch 30/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - loss: 9.3927e-04 - mae: 0.0198 - val_loss: 0.0074 - val_mae: 0.0505\n",
      "Epoch 31/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 8.7288e-04 - mae: 0.0183 - val_loss: 0.0068 - val_mae: 0.0485\n",
      "Epoch 32/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - loss: 8.8942e-04 - mae: 0.0189 - val_loss: 0.0073 - val_mae: 0.0499\n",
      "Epoch 33/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 8.7253e-04 - mae: 0.0184 - val_loss: 0.0070 - val_mae: 0.0482\n",
      "Epoch 34/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 8.9143e-04 - mae: 0.0187 - val_loss: 0.0071 - val_mae: 0.0491\n",
      "Epoch 35/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - loss: 8.7986e-04 - mae: 0.0184 - val_loss: 0.0071 - val_mae: 0.0492\n",
      "Epoch 36/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 8.8303e-04 - mae: 0.0184 - val_loss: 0.0070 - val_mae: 0.0475\n",
      "Epoch 37/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - loss: 8.7920e-04 - mae: 0.0184 - val_loss: 0.0070 - val_mae: 0.0481\n",
      "Epoch 38/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 8.7471e-04 - mae: 0.0184 - val_loss: 0.0072 - val_mae: 0.0504\n",
      "Epoch 39/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 8.6966e-04 - mae: 0.0181 - val_loss: 0.0069 - val_mae: 0.0491\n",
      "Epoch 40/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 8.8246e-04 - mae: 0.0187 - val_loss: 0.0069 - val_mae: 0.0483\n",
      "Epoch 41/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - loss: 8.6345e-04 - mae: 0.0181 - val_loss: 0.0071 - val_mae: 0.0503\n",
      "Epoch 42/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 8.6864e-04 - mae: 0.0182 - val_loss: 0.0070 - val_mae: 0.0481\n",
      "Epoch 43/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 8.6358e-04 - mae: 0.0183 - val_loss: 0.0070 - val_mae: 0.0482\n",
      "Epoch 44/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - loss: 8.7727e-04 - mae: 0.0183 - val_loss: 0.0071 - val_mae: 0.0494\n",
      "Epoch 45/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 8.6215e-04 - mae: 0.0181 - val_loss: 0.0071 - val_mae: 0.0494\n",
      "Epoch 46/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 8.7250e-04 - mae: 0.0183 - val_loss: 0.0071 - val_mae: 0.0496\n",
      "Epoch 47/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 8.6454e-04 - mae: 0.0183 - val_loss: 0.0074 - val_mae: 0.0513\n",
      "Epoch 48/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 8.6371e-04 - mae: 0.0181 - val_loss: 0.0069 - val_mae: 0.0490\n",
      "Epoch 49/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 8.6267e-04 - mae: 0.0181 - val_loss: 0.0071 - val_mae: 0.0494\n",
      "Epoch 50/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - loss: 8.7280e-04 - mae: 0.0183 - val_loss: 0.0072 - val_mae: 0.0509\n",
      "Epoch 51/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 8.5653e-04 - mae: 0.0180 - val_loss: 0.0074 - val_mae: 0.0519\n",
      "Epoch 52/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 8.6923e-04 - mae: 0.0181 - val_loss: 0.0070 - val_mae: 0.0496\n",
      "Epoch 53/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 8.6802e-04 - mae: 0.0183 - val_loss: 0.0068 - val_mae: 0.0486\n",
      "Epoch 54/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 8.7267e-04 - mae: 0.0183 - val_loss: 0.0069 - val_mae: 0.0494\n",
      "Epoch 55/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 8.5915e-04 - mae: 0.0181 - val_loss: 0.0072 - val_mae: 0.0510\n",
      "Epoch 56/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 8.5735e-04 - mae: 0.0180 - val_loss: 0.0069 - val_mae: 0.0491\n",
      "Epoch 57/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 8.6387e-04 - mae: 0.0181 - val_loss: 0.0073 - val_mae: 0.0521\n",
      "Epoch 58/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 8.6024e-04 - mae: 0.0181 - val_loss: 0.0073 - val_mae: 0.0526\n",
      "Epoch 59/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 8.6939e-04 - mae: 0.0182 - val_loss: 0.0069 - val_mae: 0.0493\n",
      "Epoch 60/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 8.5787e-04 - mae: 0.0181 - val_loss: 0.0070 - val_mae: 0.0501\n",
      "Epoch 61/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 8.5015e-04 - mae: 0.0178 - val_loss: 0.0067 - val_mae: 0.0488\n",
      "Epoch 62/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 8.6629e-04 - mae: 0.0181 - val_loss: 0.0069 - val_mae: 0.0496\n",
      "Epoch 63/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 8.6217e-04 - mae: 0.0181 - val_loss: 0.0070 - val_mae: 0.0504\n",
      "Epoch 64/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 8.5491e-04 - mae: 0.0179 - val_loss: 0.0072 - val_mae: 0.0516\n",
      "Epoch 65/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 8.4983e-04 - mae: 0.0178 - val_loss: 0.0069 - val_mae: 0.0502\n",
      "Epoch 66/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 8.5065e-04 - mae: 0.0180 - val_loss: 0.0067 - val_mae: 0.0484\n",
      "Epoch 67/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 8.6045e-04 - mae: 0.0180 - val_loss: 0.0071 - val_mae: 0.0508\n",
      "Epoch 68/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 8.5250e-04 - mae: 0.0179 - val_loss: 0.0070 - val_mae: 0.0502\n",
      "Epoch 69/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 8.5337e-04 - mae: 0.0179 - val_loss: 0.0069 - val_mae: 0.0494\n",
      "Epoch 70/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 8.5514e-04 - mae: 0.0180 - val_loss: 0.0069 - val_mae: 0.0502\n",
      "Epoch 71/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 8.4900e-04 - mae: 0.0178 - val_loss: 0.0071 - val_mae: 0.0504\n",
      "Epoch 72/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 8.5137e-04 - mae: 0.0179 - val_loss: 0.0072 - val_mae: 0.0510\n",
      "Epoch 73/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 8.5808e-04 - mae: 0.0180 - val_loss: 0.0073 - val_mae: 0.0518\n",
      "Epoch 74/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 8.5403e-04 - mae: 0.0179 - val_loss: 0.0071 - val_mae: 0.0509\n",
      "Epoch 75/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 8.5494e-04 - mae: 0.0178 - val_loss: 0.0068 - val_mae: 0.0497\n",
      "Epoch 76/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 8.4525e-04 - mae: 0.0178 - val_loss: 0.0069 - val_mae: 0.0494\n",
      "Epoch 77/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 8.4835e-04 - mae: 0.0178 - val_loss: 0.0071 - val_mae: 0.0507\n",
      "Epoch 78/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 8.4750e-04 - mae: 0.0180 - val_loss: 0.0070 - val_mae: 0.0500\n",
      "Epoch 79/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 8.5085e-04 - mae: 0.0179 - val_loss: 0.0073 - val_mae: 0.0518\n",
      "Epoch 80/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 8.4375e-04 - mae: 0.0178 - val_loss: 0.0071 - val_mae: 0.0505\n",
      "Epoch 81/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 8.5735e-04 - mae: 0.0180 - val_loss: 0.0072 - val_mae: 0.0513\n",
      "Epoch 82/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 8.4573e-04 - mae: 0.0178 - val_loss: 0.0071 - val_mae: 0.0505\n",
      "Epoch 83/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 8.4452e-04 - mae: 0.0179 - val_loss: 0.0075 - val_mae: 0.0531\n",
      "Epoch 84/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 8.4633e-04 - mae: 0.0179 - val_loss: 0.0073 - val_mae: 0.0523\n",
      "Epoch 85/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 8.5300e-04 - mae: 0.0179 - val_loss: 0.0075 - val_mae: 0.0527\n",
      "Epoch 86/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 8.5162e-04 - mae: 0.0179 - val_loss: 0.0075 - val_mae: 0.0530\n",
      "Epoch 87/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 8.4721e-04 - mae: 0.0179 - val_loss: 0.0074 - val_mae: 0.0507\n",
      "Epoch 88/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 8.4768e-04 - mae: 0.0179 - val_loss: 0.0074 - val_mae: 0.0513\n",
      "Epoch 89/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 8.4674e-04 - mae: 0.0178 - val_loss: 0.0076 - val_mae: 0.0524\n",
      "Epoch 90/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 8.4240e-04 - mae: 0.0179 - val_loss: 0.0077 - val_mae: 0.0532\n",
      "Epoch 91/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 8.4136e-04 - mae: 0.0178 - val_loss: 0.0073 - val_mae: 0.0514\n",
      "Epoch 92/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 8.4412e-04 - mae: 0.0178 - val_loss: 0.0077 - val_mae: 0.0531\n",
      "Epoch 93/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 8.5041e-04 - mae: 0.0180 - val_loss: 0.0078 - val_mae: 0.0543\n",
      "Epoch 94/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 8.3995e-04 - mae: 0.0178 - val_loss: 0.0080 - val_mae: 0.0544\n",
      "Epoch 95/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 8.4514e-04 - mae: 0.0178 - val_loss: 0.0076 - val_mae: 0.0523\n",
      "Epoch 96/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 8.5114e-04 - mae: 0.0179 - val_loss: 0.0079 - val_mae: 0.0531\n",
      "Epoch 97/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 8.4691e-04 - mae: 0.0178 - val_loss: 0.0078 - val_mae: 0.0536\n",
      "Epoch 98/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 8.4860e-04 - mae: 0.0179 - val_loss: 0.0077 - val_mae: 0.0531\n",
      "Epoch 99/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 8.5081e-04 - mae: 0.0179 - val_loss: 0.0075 - val_mae: 0.0516\n",
      "Epoch 100/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 8.4531e-04 - mae: 0.0178 - val_loss: 0.0080 - val_mae: 0.0532\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step\n",
      "✅ Done with tomato_Shimoga_daily.csv | MAE=433.89, RMSE=831.4, R2=0.2844, MAPE=57.35%, Accuracy=42.65%\n",
      "Saved updated CSV with Date, Actual & Predicted: tat_mqa_output_csv\\tomato_Shimoga_daily_tat_mqa_updated.csv\n",
      "🚀 Processing: tomato_Tumkur_daily.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_17\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_17\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_query_attention_17      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">17,216</span> │ input_layer_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiQueryAttention</span>)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_query_attention_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                               │                           │                 │ input_layer_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_34        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_34[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_177 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ layer_normalization_34[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_178 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dense_177[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_34[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                               │                           │                 │ dense_178[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_35        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_35[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_17   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_35[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_179 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ global_average_pooling1d_… │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_17 (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_query_attention_17      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │          \u001b[38;5;34m17,216\u001b[0m │ input_layer_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mMultiQueryAttention\u001b[0m)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_34 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ multi_query_attention_17[\u001b[38;5;34m…\u001b[0m │\n",
       "│                               │                           │                 │ input_layer_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_34        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ add_34[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_177 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │           \u001b[38;5;34m8,320\u001b[0m │ layer_normalization_34[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_178 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │             \u001b[38;5;34m129\u001b[0m │ dense_177[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_35 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_34[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                               │                           │                 │ dense_178[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_35        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ add_35[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_17   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_35[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_179 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │              \u001b[38;5;34m65\u001b[0m │ global_average_pooling1d_… │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,986</span> (101.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25,986\u001b[0m (101.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,986</span> (101.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m25,986\u001b[0m (101.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - loss: 0.0454 - mae: 0.1023 - val_loss: 0.0504 - val_mae: 0.1695\n",
      "Epoch 2/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0033 - mae: 0.0454 - val_loss: 0.0525 - val_mae: 0.1722\n",
      "Epoch 3/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0025 - mae: 0.0386 - val_loss: 0.0552 - val_mae: 0.1765\n",
      "Epoch 4/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0018 - mae: 0.0320 - val_loss: 0.0395 - val_mae: 0.1542\n",
      "Epoch 5/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0013 - mae: 0.0267 - val_loss: 0.0478 - val_mae: 0.1639\n",
      "Epoch 6/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 9.8128e-04 - mae: 0.0224 - val_loss: 0.0464 - val_mae: 0.1607\n",
      "Epoch 7/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 8.1929e-04 - mae: 0.0203 - val_loss: 0.0420 - val_mae: 0.1527\n",
      "Epoch 8/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 7.6410e-04 - mae: 0.0191 - val_loss: 0.0403 - val_mae: 0.1488\n",
      "Epoch 9/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 6.8657e-04 - mae: 0.0178 - val_loss: 0.0369 - val_mae: 0.1415\n",
      "Epoch 10/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 6.3189e-04 - mae: 0.0168 - val_loss: 0.0392 - val_mae: 0.1466\n",
      "Epoch 11/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 6.1014e-04 - mae: 0.0168 - val_loss: 0.0274 - val_mae: 0.1271\n",
      "Epoch 12/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 5.3037e-04 - mae: 0.0150 - val_loss: 0.0278 - val_mae: 0.1229\n",
      "Epoch 13/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 5.3353e-04 - mae: 0.0151 - val_loss: 0.0250 - val_mae: 0.1195\n",
      "Epoch 14/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 5.0355e-04 - mae: 0.0145 - val_loss: 0.0250 - val_mae: 0.1190\n",
      "Epoch 15/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 4.9458e-04 - mae: 0.0144 - val_loss: 0.0245 - val_mae: 0.1152\n",
      "Epoch 16/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 4.8779e-04 - mae: 0.0143 - val_loss: 0.0206 - val_mae: 0.1080\n",
      "Epoch 17/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 4.6821e-04 - mae: 0.0140 - val_loss: 0.0227 - val_mae: 0.1106\n",
      "Epoch 18/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 4.7271e-04 - mae: 0.0143 - val_loss: 0.0102 - val_mae: 0.0767\n",
      "Epoch 19/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 4.4734e-04 - mae: 0.0134 - val_loss: 0.0154 - val_mae: 0.0907\n",
      "Epoch 20/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 4.8814e-04 - mae: 0.0148 - val_loss: 0.0182 - val_mae: 0.1005\n",
      "Epoch 21/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 4.2140e-04 - mae: 0.0131 - val_loss: 0.0164 - val_mae: 0.0957\n",
      "Epoch 22/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 4.1473e-04 - mae: 0.0127 - val_loss: 0.0043 - val_mae: 0.0386\n",
      "Epoch 23/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 4.5171e-04 - mae: 0.0142 - val_loss: 0.0141 - val_mae: 0.0907\n",
      "Epoch 24/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 4.3130e-04 - mae: 0.0133 - val_loss: 0.0155 - val_mae: 0.0928\n",
      "Epoch 25/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 4.3880e-04 - mae: 0.0135 - val_loss: 0.0128 - val_mae: 0.0850\n",
      "Epoch 26/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 4.1697e-04 - mae: 0.0131 - val_loss: 0.0103 - val_mae: 0.0782\n",
      "Epoch 27/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 4.5128e-04 - mae: 0.0142 - val_loss: 0.0088 - val_mae: 0.0721\n",
      "Epoch 28/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 4.0829e-04 - mae: 0.0127 - val_loss: 0.0085 - val_mae: 0.0681\n",
      "Epoch 29/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 4.4390e-04 - mae: 0.0138 - val_loss: 0.0045 - val_mae: 0.0431\n",
      "Epoch 30/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 4.1786e-04 - mae: 0.0129 - val_loss: 0.0064 - val_mae: 0.0572\n",
      "Epoch 31/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 4.1810e-04 - mae: 0.0131 - val_loss: 0.0152 - val_mae: 0.0958\n",
      "Epoch 32/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 4.2737e-04 - mae: 0.0133 - val_loss: 0.0065 - val_mae: 0.0603\n",
      "Epoch 33/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 4.4334e-04 - mae: 0.0140 - val_loss: 0.0104 - val_mae: 0.0778\n",
      "Epoch 34/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 4.2348e-04 - mae: 0.0131 - val_loss: 0.0035 - val_mae: 0.0227\n",
      "Epoch 35/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 4.1628e-04 - mae: 0.0130 - val_loss: 0.0113 - val_mae: 0.0813\n",
      "Epoch 36/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 3.8716e-04 - mae: 0.0121 - val_loss: 0.0072 - val_mae: 0.0627\n",
      "Epoch 37/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 4.2140e-04 - mae: 0.0132 - val_loss: 0.0068 - val_mae: 0.0592\n",
      "Epoch 38/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 4.0608e-04 - mae: 0.0128 - val_loss: 0.0057 - val_mae: 0.0526\n",
      "Epoch 39/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 4.0515e-04 - mae: 0.0127 - val_loss: 0.0069 - val_mae: 0.0618\n",
      "Epoch 40/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 4.0159e-04 - mae: 0.0127 - val_loss: 0.0091 - val_mae: 0.0731\n",
      "Epoch 41/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 3.9306e-04 - mae: 0.0126 - val_loss: 0.0042 - val_mae: 0.0234\n",
      "Epoch 42/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 4.0654e-04 - mae: 0.0128 - val_loss: 0.0041 - val_mae: 0.0371\n",
      "Epoch 43/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 4.1625e-04 - mae: 0.0134 - val_loss: 0.0043 - val_mae: 0.0389\n",
      "Epoch 44/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 4.0902e-04 - mae: 0.0125 - val_loss: 0.0045 - val_mae: 0.0414\n",
      "Epoch 45/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 3.9832e-04 - mae: 0.0124 - val_loss: 0.0049 - val_mae: 0.0481\n",
      "Epoch 46/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 3.8972e-04 - mae: 0.0125 - val_loss: 0.0048 - val_mae: 0.0453\n",
      "Epoch 47/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 3.8187e-04 - mae: 0.0118 - val_loss: 0.0055 - val_mae: 0.0521\n",
      "Epoch 48/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 3.8067e-04 - mae: 0.0119 - val_loss: 0.0039 - val_mae: 0.0292\n",
      "Epoch 49/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 3.8469e-04 - mae: 0.0118 - val_loss: 0.0040 - val_mae: 0.0187\n",
      "Epoch 50/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 3.8904e-04 - mae: 0.0121 - val_loss: 0.0040 - val_mae: 0.0342\n",
      "Epoch 51/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 3.7721e-04 - mae: 0.0119 - val_loss: 0.0043 - val_mae: 0.0199\n",
      "Epoch 52/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 4.0071e-04 - mae: 0.0126 - val_loss: 0.0052 - val_mae: 0.0309\n",
      "Epoch 53/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 3.7440e-04 - mae: 0.0115 - val_loss: 0.0041 - val_mae: 0.0185\n",
      "Epoch 54/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 3.8023e-04 - mae: 0.0117 - val_loss: 0.0058 - val_mae: 0.0541\n",
      "Epoch 55/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 3.8584e-04 - mae: 0.0119 - val_loss: 0.0041 - val_mae: 0.0371\n",
      "Epoch 56/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 3.7762e-04 - mae: 0.0119 - val_loss: 0.0041 - val_mae: 0.0242\n",
      "Epoch 57/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 3.6920e-04 - mae: 0.0114 - val_loss: 0.0057 - val_mae: 0.0534\n",
      "Epoch 58/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 3.6835e-04 - mae: 0.0113 - val_loss: 0.0037 - val_mae: 0.0240\n",
      "Epoch 59/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 3.9367e-04 - mae: 0.0122 - val_loss: 0.0047 - val_mae: 0.0462\n",
      "Epoch 60/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 3.6518e-04 - mae: 0.0113 - val_loss: 0.0043 - val_mae: 0.0414\n",
      "Epoch 61/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 3.7589e-04 - mae: 0.0117 - val_loss: 0.0040 - val_mae: 0.0361\n",
      "Epoch 62/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 3.7682e-04 - mae: 0.0117 - val_loss: 0.0042 - val_mae: 0.0394\n",
      "Epoch 63/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 3.7421e-04 - mae: 0.0114 - val_loss: 0.0038 - val_mae: 0.0198\n",
      "Epoch 64/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 3.8376e-04 - mae: 0.0118 - val_loss: 0.0059 - val_mae: 0.0363\n",
      "Epoch 65/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 3.6887e-04 - mae: 0.0114 - val_loss: 0.0058 - val_mae: 0.0553\n",
      "Epoch 66/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 3.6371e-04 - mae: 0.0113 - val_loss: 0.0052 - val_mae: 0.0365\n",
      "Epoch 67/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 3.7604e-04 - mae: 0.0115 - val_loss: 0.0036 - val_mae: 0.0235\n",
      "Epoch 68/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 3.7323e-04 - mae: 0.0115 - val_loss: 0.0036 - val_mae: 0.0199\n",
      "Epoch 69/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 3.7156e-04 - mae: 0.0118 - val_loss: 0.0037 - val_mae: 0.0181\n",
      "Epoch 70/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 3.7240e-04 - mae: 0.0114 - val_loss: 0.0040 - val_mae: 0.0218\n",
      "Epoch 71/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 3.5853e-04 - mae: 0.0109 - val_loss: 0.0044 - val_mae: 0.0450\n",
      "Epoch 72/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 3.6310e-04 - mae: 0.0115 - val_loss: 0.0033 - val_mae: 0.0271\n",
      "Epoch 73/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 3.5414e-04 - mae: 0.0110 - val_loss: 0.0071 - val_mae: 0.0640\n",
      "Epoch 74/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 3.6928e-04 - mae: 0.0114 - val_loss: 0.0034 - val_mae: 0.0208\n",
      "Epoch 75/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 3.5895e-04 - mae: 0.0110 - val_loss: 0.0031 - val_mae: 0.0182\n",
      "Epoch 76/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 3.7033e-04 - mae: 0.0114 - val_loss: 0.0033 - val_mae: 0.0308\n",
      "Epoch 77/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 3.6227e-04 - mae: 0.0113 - val_loss: 0.0032 - val_mae: 0.0259\n",
      "Epoch 78/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 3.6368e-04 - mae: 0.0110 - val_loss: 0.0031 - val_mae: 0.0170\n",
      "Epoch 79/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 3.6086e-04 - mae: 0.0109 - val_loss: 0.0031 - val_mae: 0.0242\n",
      "Epoch 80/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 3.5972e-04 - mae: 0.0111 - val_loss: 0.0037 - val_mae: 0.0386\n",
      "Epoch 81/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 3.5493e-04 - mae: 0.0109 - val_loss: 0.0030 - val_mae: 0.0259\n",
      "Epoch 82/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 3.5744e-04 - mae: 0.0110 - val_loss: 0.0033 - val_mae: 0.0333\n",
      "Epoch 83/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 3.5844e-04 - mae: 0.0107 - val_loss: 0.0037 - val_mae: 0.0392\n",
      "Epoch 84/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 3.7173e-04 - mae: 0.0111 - val_loss: 0.0040 - val_mae: 0.0436\n",
      "Epoch 85/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 3.6502e-04 - mae: 0.0112 - val_loss: 0.0036 - val_mae: 0.0387\n",
      "Epoch 86/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 3.6879e-04 - mae: 0.0114 - val_loss: 0.0045 - val_mae: 0.0488\n",
      "Epoch 87/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 3.5613e-04 - mae: 0.0107 - val_loss: 0.0031 - val_mae: 0.0198\n",
      "Epoch 88/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 3.6278e-04 - mae: 0.0112 - val_loss: 0.0034 - val_mae: 0.0377\n",
      "Epoch 89/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 3.6671e-04 - mae: 0.0112 - val_loss: 0.0054 - val_mae: 0.0548\n",
      "Epoch 90/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 3.6268e-04 - mae: 0.0111 - val_loss: 0.0030 - val_mae: 0.0320\n",
      "Epoch 91/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 3.5750e-04 - mae: 0.0109 - val_loss: 0.0033 - val_mae: 0.0369\n",
      "Epoch 92/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 3.6093e-04 - mae: 0.0108 - val_loss: 0.0036 - val_mae: 0.0404\n",
      "Epoch 93/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 3.6069e-04 - mae: 0.0110 - val_loss: 0.0039 - val_mae: 0.0439\n",
      "Epoch 94/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 3.5986e-04 - mae: 0.0110 - val_loss: 0.0075 - val_mae: 0.0688\n",
      "Epoch 95/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 3.6392e-04 - mae: 0.0112 - val_loss: 0.0038 - val_mae: 0.0437\n",
      "Epoch 96/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 3.5929e-04 - mae: 0.0110 - val_loss: 0.0026 - val_mae: 0.0168\n",
      "Epoch 97/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 3.5898e-04 - mae: 0.0109 - val_loss: 0.0026 - val_mae: 0.0166\n",
      "Epoch 98/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 3.6237e-04 - mae: 0.0111 - val_loss: 0.0029 - val_mae: 0.0336\n",
      "Epoch 99/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 3.5638e-04 - mae: 0.0109 - val_loss: 0.0041 - val_mae: 0.0473\n",
      "Epoch 100/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 3.5218e-04 - mae: 0.0107 - val_loss: 0.0026 - val_mae: 0.0197\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step   \n",
      "✅ Done with tomato_Tumkur_daily.csv | MAE=132.68, RMSE=321.25, R2=0.9484, MAPE=13.67%, Accuracy=86.33%\n",
      "Saved updated CSV with Date, Actual & Predicted: tat_mqa_output_csv\\tomato_Tumkur_daily_tat_mqa_updated.csv\n",
      "🚀 Processing: tomato_Udupi_daily.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_18\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_18\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_query_attention_18      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">17,216</span> │ input_layer_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiQueryAttention</span>)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_query_attention_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                               │                           │                 │ input_layer_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_36        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_36[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_187 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ layer_normalization_36[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_188 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dense_187[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_36[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                               │                           │                 │ dense_188[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_37        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_37[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_18   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_37[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_189 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ global_average_pooling1d_… │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_18 (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_query_attention_18      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │          \u001b[38;5;34m17,216\u001b[0m │ input_layer_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mMultiQueryAttention\u001b[0m)         │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_36 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ multi_query_attention_18[\u001b[38;5;34m…\u001b[0m │\n",
       "│                               │                           │                 │ input_layer_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_36        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ add_36[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_187 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │           \u001b[38;5;34m8,320\u001b[0m │ layer_normalization_36[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_188 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │             \u001b[38;5;34m129\u001b[0m │ dense_187[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_37 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_36[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                               │                           │                 │ dense_188[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_37        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ add_37[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_18   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_37[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_189 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │              \u001b[38;5;34m65\u001b[0m │ global_average_pooling1d_… │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,986</span> (101.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25,986\u001b[0m (101.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,986</span> (101.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m25,986\u001b[0m (101.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - loss: 0.0448 - mae: 0.1147 - val_loss: 0.0294 - val_mae: 0.1127\n",
      "Epoch 2/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0071 - mae: 0.0648 - val_loss: 0.0329 - val_mae: 0.1104\n",
      "Epoch 3/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0050 - mae: 0.0532 - val_loss: 0.0314 - val_mae: 0.1067\n",
      "Epoch 4/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0048 - mae: 0.0521 - val_loss: 0.0254 - val_mae: 0.1129\n",
      "Epoch 5/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0037 - mae: 0.0444 - val_loss: 0.0290 - val_mae: 0.1037\n",
      "Epoch 6/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0034 - mae: 0.0423 - val_loss: 0.0251 - val_mae: 0.0993\n",
      "Epoch 7/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0030 - mae: 0.0393 - val_loss: 0.0241 - val_mae: 0.0986\n",
      "Epoch 8/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0029 - mae: 0.0391 - val_loss: 0.0213 - val_mae: 0.0931\n",
      "Epoch 9/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0027 - mae: 0.0371 - val_loss: 0.0255 - val_mae: 0.1042\n",
      "Epoch 10/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0025 - mae: 0.0354 - val_loss: 0.0210 - val_mae: 0.0946\n",
      "Epoch 11/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0023 - mae: 0.0341 - val_loss: 0.0202 - val_mae: 0.0940\n",
      "Epoch 12/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0025 - mae: 0.0358 - val_loss: 0.0219 - val_mae: 0.1034\n",
      "Epoch 13/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0024 - mae: 0.0342 - val_loss: 0.0203 - val_mae: 0.0953\n",
      "Epoch 14/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0025 - mae: 0.0360 - val_loss: 0.0200 - val_mae: 0.0931\n",
      "Epoch 15/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0022 - mae: 0.0326 - val_loss: 0.0206 - val_mae: 0.0933\n",
      "Epoch 16/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0022 - mae: 0.0332 - val_loss: 0.0210 - val_mae: 0.0960\n",
      "Epoch 17/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0024 - mae: 0.0354 - val_loss: 0.0199 - val_mae: 0.0931\n",
      "Epoch 18/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0022 - mae: 0.0331 - val_loss: 0.0209 - val_mae: 0.1015\n",
      "Epoch 19/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0023 - mae: 0.0338 - val_loss: 0.0223 - val_mae: 0.1018\n",
      "Epoch 20/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0022 - mae: 0.0333 - val_loss: 0.0201 - val_mae: 0.0967\n",
      "Epoch 21/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0022 - mae: 0.0321 - val_loss: 0.0196 - val_mae: 0.0927\n",
      "Epoch 22/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0023 - mae: 0.0338 - val_loss: 0.0195 - val_mae: 0.0920\n",
      "Epoch 23/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0022 - mae: 0.0327 - val_loss: 0.0220 - val_mae: 0.0998\n",
      "Epoch 24/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0023 - mae: 0.0342 - val_loss: 0.0198 - val_mae: 0.0946\n",
      "Epoch 25/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0023 - mae: 0.0347 - val_loss: 0.0208 - val_mae: 0.0949\n",
      "Epoch 26/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0022 - mae: 0.0327 - val_loss: 0.0191 - val_mae: 0.0930\n",
      "Epoch 27/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0023 - mae: 0.0338 - val_loss: 0.0197 - val_mae: 0.0962\n",
      "Epoch 28/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0022 - mae: 0.0332 - val_loss: 0.0191 - val_mae: 0.0916\n",
      "Epoch 29/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0023 - mae: 0.0336 - val_loss: 0.0200 - val_mae: 0.0958\n",
      "Epoch 30/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0022 - mae: 0.0322 - val_loss: 0.0202 - val_mae: 0.0947\n",
      "Epoch 31/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0022 - mae: 0.0327 - val_loss: 0.0193 - val_mae: 0.0933\n",
      "Epoch 32/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0023 - mae: 0.0335 - val_loss: 0.0193 - val_mae: 0.0928\n",
      "Epoch 33/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0022 - mae: 0.0329 - val_loss: 0.0194 - val_mae: 0.0945\n",
      "Epoch 34/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0022 - mae: 0.0329 - val_loss: 0.0209 - val_mae: 0.0961\n",
      "Epoch 35/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0021 - mae: 0.0321 - val_loss: 0.0195 - val_mae: 0.0924\n",
      "Epoch 36/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0022 - mae: 0.0326 - val_loss: 0.0198 - val_mae: 0.0964\n",
      "Epoch 37/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0022 - mae: 0.0321 - val_loss: 0.0193 - val_mae: 0.0932\n",
      "Epoch 38/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0022 - mae: 0.0325 - val_loss: 0.0193 - val_mae: 0.0932\n",
      "Epoch 39/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0021 - mae: 0.0326 - val_loss: 0.0192 - val_mae: 0.0929\n",
      "Epoch 40/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0021 - mae: 0.0322 - val_loss: 0.0199 - val_mae: 0.0934\n",
      "Epoch 41/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0023 - mae: 0.0333 - val_loss: 0.0197 - val_mae: 0.0939\n",
      "Epoch 42/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0021 - mae: 0.0322 - val_loss: 0.0192 - val_mae: 0.0926\n",
      "Epoch 43/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0021 - mae: 0.0317 - val_loss: 0.0207 - val_mae: 0.0942\n",
      "Epoch 44/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0021 - mae: 0.0318 - val_loss: 0.0190 - val_mae: 0.0920\n",
      "Epoch 45/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0021 - mae: 0.0319 - val_loss: 0.0211 - val_mae: 0.0990\n",
      "Epoch 46/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0021 - mae: 0.0321 - val_loss: 0.0215 - val_mae: 0.0976\n",
      "Epoch 47/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0021 - mae: 0.0311 - val_loss: 0.0195 - val_mae: 0.0958\n",
      "Epoch 48/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0021 - mae: 0.0320 - val_loss: 0.0211 - val_mae: 0.0960\n",
      "Epoch 49/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0021 - mae: 0.0316 - val_loss: 0.0192 - val_mae: 0.0966\n",
      "Epoch 50/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0021 - mae: 0.0320 - val_loss: 0.0196 - val_mae: 0.0928\n",
      "Epoch 51/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0021 - mae: 0.0318 - val_loss: 0.0215 - val_mae: 0.0994\n",
      "Epoch 52/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0022 - mae: 0.0325 - val_loss: 0.0206 - val_mae: 0.0957\n",
      "Epoch 53/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0021 - mae: 0.0319 - val_loss: 0.0192 - val_mae: 0.0924\n",
      "Epoch 54/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0021 - mae: 0.0316 - val_loss: 0.0196 - val_mae: 0.0943\n",
      "Epoch 55/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0022 - mae: 0.0323 - val_loss: 0.0196 - val_mae: 0.0936\n",
      "Epoch 56/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0021 - mae: 0.0316 - val_loss: 0.0188 - val_mae: 0.0918\n",
      "Epoch 57/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0021 - mae: 0.0315 - val_loss: 0.0193 - val_mae: 0.0929\n",
      "Epoch 58/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0021 - mae: 0.0313 - val_loss: 0.0191 - val_mae: 0.0922\n",
      "Epoch 59/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0021 - mae: 0.0317 - val_loss: 0.0186 - val_mae: 0.0916\n",
      "Epoch 60/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0021 - mae: 0.0311 - val_loss: 0.0187 - val_mae: 0.0915\n",
      "Epoch 61/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0021 - mae: 0.0312 - val_loss: 0.0186 - val_mae: 0.0924\n",
      "Epoch 62/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0021 - mae: 0.0312 - val_loss: 0.0191 - val_mae: 0.0922\n",
      "Epoch 63/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0021 - mae: 0.0309 - val_loss: 0.0190 - val_mae: 0.0920\n",
      "Epoch 64/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0021 - mae: 0.0313 - val_loss: 0.0198 - val_mae: 0.0942\n",
      "Epoch 65/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0021 - mae: 0.0315 - val_loss: 0.0200 - val_mae: 0.0937\n",
      "Epoch 66/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0021 - mae: 0.0311 - val_loss: 0.0193 - val_mae: 0.0941\n",
      "Epoch 67/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0020 - mae: 0.0309 - val_loss: 0.0200 - val_mae: 0.0945\n",
      "Epoch 68/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0020 - mae: 0.0312 - val_loss: 0.0204 - val_mae: 0.0942\n",
      "Epoch 69/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0021 - mae: 0.0313 - val_loss: 0.0191 - val_mae: 0.0932\n",
      "Epoch 70/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0021 - mae: 0.0313 - val_loss: 0.0190 - val_mae: 0.0925\n",
      "Epoch 71/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0020 - mae: 0.0310 - val_loss: 0.0224 - val_mae: 0.0981\n",
      "Epoch 72/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0020 - mae: 0.0309 - val_loss: 0.0199 - val_mae: 0.0933\n",
      "Epoch 73/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0020 - mae: 0.0309 - val_loss: 0.0199 - val_mae: 0.0938\n",
      "Epoch 74/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0020 - mae: 0.0311 - val_loss: 0.0189 - val_mae: 0.0920\n",
      "Epoch 75/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0020 - mae: 0.0307 - val_loss: 0.0218 - val_mae: 0.0993\n",
      "Epoch 76/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0020 - mae: 0.0308 - val_loss: 0.0202 - val_mae: 0.0939\n",
      "Epoch 77/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0020 - mae: 0.0309 - val_loss: 0.0212 - val_mae: 0.0967\n",
      "Epoch 78/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0020 - mae: 0.0308 - val_loss: 0.0224 - val_mae: 0.0962\n",
      "Epoch 79/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0021 - mae: 0.0314 - val_loss: 0.0197 - val_mae: 0.0952\n",
      "Epoch 80/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0020 - mae: 0.0308 - val_loss: 0.0188 - val_mae: 0.0918\n",
      "Epoch 81/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0020 - mae: 0.0306 - val_loss: 0.0200 - val_mae: 0.0933\n",
      "Epoch 82/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0020 - mae: 0.0308 - val_loss: 0.0204 - val_mae: 0.0961\n",
      "Epoch 83/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0020 - mae: 0.0305 - val_loss: 0.0225 - val_mae: 0.0974\n",
      "Epoch 84/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0020 - mae: 0.0308 - val_loss: 0.0202 - val_mae: 0.0937\n",
      "Epoch 85/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0020 - mae: 0.0310 - val_loss: 0.0200 - val_mae: 0.0933\n",
      "Epoch 86/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0020 - mae: 0.0309 - val_loss: 0.0198 - val_mae: 0.0932\n",
      "Epoch 87/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0020 - mae: 0.0306 - val_loss: 0.0230 - val_mae: 0.1005\n",
      "Epoch 88/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0020 - mae: 0.0310 - val_loss: 0.0198 - val_mae: 0.0931\n",
      "Epoch 89/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0020 - mae: 0.0306 - val_loss: 0.0210 - val_mae: 0.0987\n",
      "Epoch 90/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0020 - mae: 0.0311 - val_loss: 0.0223 - val_mae: 0.0997\n",
      "Epoch 91/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0020 - mae: 0.0305 - val_loss: 0.0228 - val_mae: 0.1004\n",
      "Epoch 92/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0020 - mae: 0.0305 - val_loss: 0.0236 - val_mae: 0.0997\n",
      "Epoch 93/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0020 - mae: 0.0302 - val_loss: 0.0210 - val_mae: 0.0958\n",
      "Epoch 94/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0020 - mae: 0.0302 - val_loss: 0.0200 - val_mae: 0.0934\n",
      "Epoch 95/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0019 - mae: 0.0299 - val_loss: 0.0218 - val_mae: 0.0956\n",
      "Epoch 96/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0020 - mae: 0.0305 - val_loss: 0.0225 - val_mae: 0.0967\n",
      "Epoch 97/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0020 - mae: 0.0301 - val_loss: 0.0212 - val_mae: 0.0957\n",
      "Epoch 98/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0019 - mae: 0.0301 - val_loss: 0.0213 - val_mae: 0.0960\n",
      "Epoch 99/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0019 - mae: 0.0302 - val_loss: 0.0206 - val_mae: 0.0952\n",
      "Epoch 100/100\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0019 - mae: 0.0300 - val_loss: 0.0223 - val_mae: 0.0964\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step   \n",
      "✅ Done with tomato_Udupi_daily.csv | MAE=430.43, RMSE=744.98, R2=0.6352, MAPE=26.52%, Accuracy=73.48%\n",
      "Saved updated CSV with Date, Actual & Predicted: tat_mqa_output_csv\\tomato_Udupi_daily_tat_mqa_updated.csv\n",
      "📊 Metrics saved to tat_mqa_metrics.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "import joblib  # for .pkl model saving (best-effort)\n",
    "warnings_imported = False\n",
    "try:\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    warnings_imported = True\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# -----------------------------\n",
    "# Output directories\n",
    "# -----------------------------\n",
    "input_folder = \"dataset\"\n",
    "output_models = \"tat_mqa_output_models\"\n",
    "output_csv = \"tat_mqa_output_csv\"\n",
    "output_graphs = \"tat_mqa_output_graphs\"\n",
    "output_logs = \"tat_mqa_output_logs\"\n",
    "metrics_file = \"tat_mqa_metrics.csv\"\n",
    "\n",
    "os.makedirs(output_models, exist_ok=True)\n",
    "os.makedirs(output_csv, exist_ok=True)\n",
    "os.makedirs(output_graphs, exist_ok=True)\n",
    "os.makedirs(output_logs, exist_ok=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Function to create dataset\n",
    "# -----------------------------\n",
    "def create_dataset(data, look_back=30):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - look_back):\n",
    "        X.append(data[i:i+look_back, 0])\n",
    "        y.append(data[i+look_back, 0])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# -----------------------------\n",
    "# Multi-Query Attention Layer\n",
    "# -----------------------------\n",
    "class MultiQueryAttention(layers.Layer):\n",
    "    def __init__(self, num_heads, key_dim, dropout_rate=0.1, **kwargs):\n",
    "        super(MultiQueryAttention, self).__init__(**kwargs)\n",
    "        self.num_heads = num_heads\n",
    "        self.key_dim = key_dim\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.q_dense = [layers.Dense(key_dim) for _ in range(num_heads)]\n",
    "        self.k_dense = layers.Dense(key_dim)\n",
    "        self.v_dense = layers.Dense(key_dim)\n",
    "        self.dropout = layers.Dropout(dropout_rate)\n",
    "        self.output_dense = layers.Dense(key_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        K = self.k_dense(x)\n",
    "        V = self.v_dense(x)\n",
    "        head_outputs = []\n",
    "\n",
    "        for q_layer in self.q_dense:\n",
    "            Q = q_layer(x)\n",
    "            scores = tf.matmul(Q, K, transpose_b=True) / tf.math.sqrt(tf.cast(self.key_dim, tf.float32))\n",
    "            attention_weights = tf.nn.softmax(scores, axis=-1)\n",
    "            attention_output = tf.matmul(attention_weights, V)\n",
    "            head_outputs.append(attention_output)\n",
    "\n",
    "        concat = tf.concat(head_outputs, axis=-1)\n",
    "        output = self.output_dense(concat)\n",
    "        output = self.dropout(output)\n",
    "        return output\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(MultiQueryAttention, self).get_config()\n",
    "        config.update({\n",
    "            \"num_heads\": self.num_heads,\n",
    "            \"key_dim\": self.key_dim,\n",
    "            \"dropout_rate\": self.dropout_rate\n",
    "        })\n",
    "        return config\n",
    "\n",
    "# -----------------------------\n",
    "# TAT-MQA Model\n",
    "# -----------------------------\n",
    "def build_tat_mqa_model(input_shape, d_model=64, num_heads=4, ff_dim=128, dropout_rate=0.2):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = MultiQueryAttention(num_heads=num_heads, key_dim=d_model, dropout_rate=dropout_rate)(inputs)\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x + inputs)\n",
    "\n",
    "    ff = layers.Dense(ff_dim, activation='relu')(x)\n",
    "    ff = layers.Dense(input_shape[1])(ff)\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x + ff)\n",
    "\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    outputs = layers.Dense(1)(x)\n",
    "\n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=0.001),\n",
    "                  loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# -----------------------------\n",
    "# Function to robustly parse dates\n",
    "# -----------------------------\n",
    "def parse_dates_safe(date_series):\n",
    "    # keep same behavior as you used before: infer_datetime_format True fallback\n",
    "    try:\n",
    "        return pd.to_datetime(date_series, infer_datetime_format=True, errors='coerce')\n",
    "    except:\n",
    "        return pd.to_datetime(date_series, errors='coerce')\n",
    "\n",
    "# -----------------------------\n",
    "# Metrics storage\n",
    "# -----------------------------\n",
    "metrics_list = []\n",
    "\n",
    "# -----------------------------\n",
    "# Process each CSV file\n",
    "# -----------------------------\n",
    "look_back = 30\n",
    "for file in os.listdir(input_folder):\n",
    "    if not file.endswith(\".csv\"):\n",
    "        continue\n",
    "\n",
    "    file_path = os.path.join(input_folder, file)\n",
    "    print(f\"🚀 Processing: {file}\")\n",
    "\n",
    "    # Load CSV\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Robust date parsing\n",
    "    df['Date'] = parse_dates_safe(df['Date'])\n",
    "    df = df.dropna(subset=['Date'])\n",
    "    df = df.sort_values('Date').reset_index(drop=True)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Handle missing Average Price\n",
    "    # -----------------------------\n",
    "    if 'Average Price' not in df.columns:\n",
    "        raise KeyError(\"Input CSV must contain 'Average Price' column.\")\n",
    "    if df['Average Price'].isna().sum() > 0:\n",
    "        mean_val = df['Average Price'].mean()\n",
    "        df['Average Price'].fillna(mean_val, inplace=True)\n",
    "        print(f\"Filled {df['Average Price'].isna().sum()} missing Average Price values with mean {mean_val:.2f}\")\n",
    "\n",
    "    # Round Actual values early\n",
    "    df['Average Price'] = df['Average Price'].astype(float).round(2)\n",
    "\n",
    "    # Moving averages (fill remaining NaNs with column mean to avoid plotting gaps)\n",
    "    df['MA_7'] = df['Average Price'].rolling(window=7).mean()\n",
    "    df['MA_30'] = df['Average Price'].rolling(window=30).mean()\n",
    "    df['MA_7'].fillna(df['MA_7'].mean(), inplace=True)\n",
    "    df['MA_30'].fillna(df['MA_30'].mean(), inplace=True)\n",
    "\n",
    "    # Prepare data\n",
    "    values = df[['Average Price']].values.astype('float32')\n",
    "    if len(values) <= look_back:\n",
    "        # Not enough data for the chosen look_back; skip file with a warning\n",
    "        print(f\"⚠️ Skipping {file} — dataset length ({len(values)}) <= look_back ({look_back})\")\n",
    "        continue\n",
    "\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_values = scaler.fit_transform(values)\n",
    "\n",
    "    X, y = create_dataset(scaled_values, look_back)\n",
    "    X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
    "\n",
    "    # Build and train model\n",
    "    model = build_tat_mqa_model(input_shape=(look_back,1))\n",
    "    model.summary()\n",
    "\n",
    "    history = model.fit(X, y, epochs=100, batch_size=16, validation_split=0.2, verbose=1)\n",
    "\n",
    "    # Save training logs\n",
    "    log_file = os.path.join(output_logs, file.replace(\".csv\", \"_tat_mqa_training.txt\"))\n",
    "    with open(log_file, \"w\") as f:\n",
    "        f.write(\"Training Loss per Epoch:\\n\")\n",
    "        for i, loss in enumerate(history.history['loss']):\n",
    "            val_loss = history.history['val_loss'][i] if 'val_loss' in history.history else None\n",
    "            f.write(f\"Epoch {i+1}: Loss={loss}, Val_Loss={val_loss}\\n\")\n",
    "\n",
    "    # Predictions (rescale)\n",
    "    predictions = model.predict(X)\n",
    "    predictions_rescaled = scaler.inverse_transform(predictions).flatten()\n",
    "    # pad with NaNs at start so predicted series aligns with original df index\n",
    "    padded_preds = np.concatenate([np.full(look_back, np.nan), predictions_rescaled])\n",
    "    df['Predicted'] = np.round(padded_preds, 2)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Compute metrics using only the matched portion (exclude leading NaNs)\n",
    "    # -----------------------------\n",
    "    y_true = df['Average Price'].values[look_back:]\n",
    "    y_pred = predictions_rescaled\n",
    "    mae = round(mean_absolute_error(y_true, y_pred), 2)\n",
    "    rmse = round(np.sqrt(mean_squared_error(y_true, y_pred)), 2)\n",
    "    r2 = round(r2_score(y_true, y_pred), 4)\n",
    "    # MAPE: avoid divide-by-zero by masking zeros\n",
    "    mask = y_true != 0\n",
    "    if mask.sum() == 0:\n",
    "        mape = np.nan\n",
    "        accuracy = np.nan\n",
    "    else:\n",
    "        mape = round(np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100, 2)\n",
    "        accuracy = round(100 - mape, 2)\n",
    "\n",
    "    metrics_list.append([file.replace(\".csv\",\"\"), mae, rmse, r2, mape, accuracy])\n",
    "\n",
    "    print(f\"✅ Done with {file} | MAE={mae}, RMSE={rmse}, R2={r2}, MAPE={mape}%, Accuracy={accuracy}%\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # Save model: native Keras and attempt .pkl (best-effort)\n",
    "    # -----------------------------\n",
    "    keras_model_path = os.path.join(output_models, file.replace(\".csv\", \"_tat_mqa_model.keras\"))\n",
    "    model.save(keras_model_path)\n",
    "    pkl_model_path = os.path.join(output_models, file.replace(\".csv\", \"_tat_mqa_model.pkl\"))\n",
    "    try:\n",
    "        # joblib.dump the Keras model object (may fail on some TF versions)\n",
    "        joblib.dump(model, pkl_model_path)\n",
    "    except Exception as e:\n",
    "        # fallback: save model architecture + weights dict to pickle (best-effort)\n",
    "        try:\n",
    "            model_info = {\n",
    "                \"config\": model.get_config(),\n",
    "                \"weights\": model.get_weights()\n",
    "            }\n",
    "            joblib.dump(model_info, pkl_model_path)\n",
    "        except Exception as e2:\n",
    "            print(f\"⚠️ Could not save .pkl for {file}: {e}; {e2}\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # Save CSV with only Date, Actual, Predicted (Actual renamed)\n",
    "    # -----------------------------\n",
    "    save_df = pd.DataFrame({\n",
    "        'Date': df['Date'],\n",
    "        'Actual': df['Average Price'].round(2),\n",
    "        'Predicted': df['Predicted']\n",
    "    })\n",
    "    updated_csv_path = os.path.join(output_csv, file.replace(\".csv\", \"_tat_mqa_updated.csv\"))\n",
    "    save_df.to_csv(updated_csv_path, index=False)\n",
    "    print(f\"Saved updated CSV with Date, Actual & Predicted: {updated_csv_path}\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # Save graph with Actual, Predicted, MA7, MA30\n",
    "    # -----------------------------\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.plot(df['Date'], df['Average Price'], label='Actual', color='blue')\n",
    "    plt.plot(df['Date'], df['Predicted'], label='Predicted', color='red', linestyle='dashed')\n",
    "    plt.plot(df['Date'], df['MA_7'], label='MA 7', color='orange')\n",
    "    plt.plot(df['Date'], df['MA_30'], label='MA 30', color='green')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Average Price')\n",
    "    plt.title(f'Price Prediction (TAT-MQA) - {file}')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    graph_file = os.path.join(output_graphs, file.replace(\".csv\", \"_tat_mqa_graph.png\"))\n",
    "    plt.savefig(graph_file, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# -----------------------------\n",
    "# Save all metrics\n",
    "# -----------------------------\n",
    "metrics_df = pd.DataFrame(metrics_list, columns=['District', 'MAE', 'RMSE', 'R2', 'MAPE(%)', 'Accuracy(%)'])\n",
    "metrics_df.to_csv(metrics_file, index=False)\n",
    "print(f\"📊 Metrics saved to {metrics_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dadbf96-f5f8-4f6a-94f6-f64efae95850",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TAT+GQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c6be32-8768-4aea-9961-0059568b7516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Processing: tomato_Bangalore_daily.csv\n",
      "Epoch 1/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - loss: 0.0272 - mae: 0.0799 - val_loss: 0.0023 - val_mae: 0.0302\n",
      "Epoch 2/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0024 - mae: 0.0308 - val_loss: 0.0024 - val_mae: 0.0400\n",
      "Epoch 3/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0017 - mae: 0.0241 - val_loss: 0.0023 - val_mae: 0.0337\n",
      "Epoch 4/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0017 - mae: 0.0225 - val_loss: 0.0024 - val_mae: 0.0326\n",
      "Epoch 5/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0016 - mae: 0.0218 - val_loss: 0.0015 - val_mae: 0.0250\n",
      "Epoch 6/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0016 - mae: 0.0216 - val_loss: 0.0027 - val_mae: 0.0306\n",
      "Epoch 7/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0015 - mae: 0.0205 - val_loss: 0.0018 - val_mae: 0.0320\n",
      "Epoch 8/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0199 - val_loss: 0.0017 - val_mae: 0.0260\n",
      "Epoch 9/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0015 - mae: 0.0195 - val_loss: 0.0013 - val_mae: 0.0238\n",
      "Epoch 10/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0014 - mae: 0.0187 - val_loss: 0.0016 - val_mae: 0.0322\n",
      "Epoch 11/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - loss: 0.0014 - mae: 0.0181 - val_loss: 0.0014 - val_mae: 0.0291\n",
      "Epoch 12/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0014 - mae: 0.0182 - val_loss: 0.0011 - val_mae: 0.0227\n",
      "Epoch 13/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - loss: 0.0014 - mae: 0.0177 - val_loss: 0.0017 - val_mae: 0.0254\n",
      "Epoch 14/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0014 - mae: 0.0176 - val_loss: 0.0013 - val_mae: 0.0257\n",
      "Epoch 15/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0014 - mae: 0.0177 - val_loss: 0.0016 - val_mae: 0.0249\n",
      "Epoch 16/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0014 - mae: 0.0175 - val_loss: 0.0014 - val_mae: 0.0236\n",
      "Epoch 17/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0014 - mae: 0.0172 - val_loss: 0.0012 - val_mae: 0.0226\n",
      "Epoch 18/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0014 - mae: 0.0173 - val_loss: 0.0014 - val_mae: 0.0237\n",
      "Epoch 19/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0014 - mae: 0.0172 - val_loss: 0.0012 - val_mae: 0.0228\n",
      "Epoch 20/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0014 - mae: 0.0169 - val_loss: 0.0012 - val_mae: 0.0231\n",
      "Epoch 21/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0014 - mae: 0.0169 - val_loss: 0.0013 - val_mae: 0.0248\n",
      "Epoch 22/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0014 - mae: 0.0171 - val_loss: 0.0014 - val_mae: 0.0237\n",
      "Epoch 23/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0014 - mae: 0.0170 - val_loss: 0.0015 - val_mae: 0.0248\n",
      "Epoch 24/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0014 - mae: 0.0170 - val_loss: 0.0011 - val_mae: 0.0232\n",
      "Epoch 25/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0014 - mae: 0.0170 - val_loss: 0.0017 - val_mae: 0.0252\n",
      "Epoch 26/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0014 - mae: 0.0171 - val_loss: 0.0016 - val_mae: 0.0244\n",
      "Epoch 27/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0014 - mae: 0.0169 - val_loss: 0.0014 - val_mae: 0.0242\n",
      "Epoch 28/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0014 - mae: 0.0169 - val_loss: 0.0011 - val_mae: 0.0227\n",
      "Epoch 29/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0014 - mae: 0.0171 - val_loss: 0.0015 - val_mae: 0.0245\n",
      "Epoch 30/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0169 - val_loss: 0.0011 - val_mae: 0.0225\n",
      "Epoch 31/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0014 - mae: 0.0169 - val_loss: 0.0011 - val_mae: 0.0228\n",
      "Epoch 32/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0014 - mae: 0.0169 - val_loss: 0.0013 - val_mae: 0.0229\n",
      "Epoch 33/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0013 - mae: 0.0169 - val_loss: 0.0014 - val_mae: 0.0235\n",
      "Epoch 34/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0170 - val_loss: 0.0011 - val_mae: 0.0219\n",
      "Epoch 35/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0168 - val_loss: 0.0011 - val_mae: 0.0227\n",
      "Epoch 36/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0014 - mae: 0.0169 - val_loss: 0.0011 - val_mae: 0.0219\n",
      "Epoch 37/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0169 - val_loss: 0.0011 - val_mae: 0.0222\n",
      "Epoch 38/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0168 - val_loss: 0.0012 - val_mae: 0.0227\n",
      "Epoch 39/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0168 - val_loss: 0.0011 - val_mae: 0.0226\n",
      "Epoch 40/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0168 - val_loss: 0.0011 - val_mae: 0.0230\n",
      "Epoch 41/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0168 - val_loss: 0.0010 - val_mae: 0.0217\n",
      "Epoch 42/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0168 - val_loss: 0.0012 - val_mae: 0.0227\n",
      "Epoch 43/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0167 - val_loss: 0.0012 - val_mae: 0.0228\n",
      "Epoch 44/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0013 - mae: 0.0167 - val_loss: 0.0011 - val_mae: 0.0219\n",
      "Epoch 45/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0168 - val_loss: 0.0011 - val_mae: 0.0218\n",
      "Epoch 46/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0167 - val_loss: 0.0010 - val_mae: 0.0220\n",
      "Epoch 47/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0013 - mae: 0.0167 - val_loss: 0.0012 - val_mae: 0.0225\n",
      "Epoch 48/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0166 - val_loss: 0.0010 - val_mae: 0.0222\n",
      "Epoch 49/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0013 - mae: 0.0167 - val_loss: 0.0012 - val_mae: 0.0227\n",
      "Epoch 50/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0167 - val_loss: 0.0012 - val_mae: 0.0225\n",
      "Epoch 51/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0167 - val_loss: 0.0010 - val_mae: 0.0215\n",
      "Epoch 52/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0168 - val_loss: 0.0011 - val_mae: 0.0248\n",
      "Epoch 53/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0167 - val_loss: 0.0010 - val_mae: 0.0215\n",
      "Epoch 54/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0013 - mae: 0.0167 - val_loss: 0.0010 - val_mae: 0.0216\n",
      "Epoch 55/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 12ms/step - loss: 0.0013 - mae: 0.0166 - val_loss: 9.9490e-04 - val_mae: 0.0216\n",
      "Epoch 56/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0167 - val_loss: 0.0011 - val_mae: 0.0220\n",
      "Epoch 57/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0166 - val_loss: 0.0010 - val_mae: 0.0222\n",
      "Epoch 58/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0167 - val_loss: 0.0012 - val_mae: 0.0236\n",
      "Epoch 59/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0013 - mae: 0.0167 - val_loss: 0.0012 - val_mae: 0.0225\n",
      "Epoch 60/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0165 - val_loss: 0.0011 - val_mae: 0.0224\n",
      "Epoch 61/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0167 - val_loss: 0.0010 - val_mae: 0.0218\n",
      "Epoch 62/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0166 - val_loss: 0.0012 - val_mae: 0.0229\n",
      "Epoch 63/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0169 - val_loss: 0.0014 - val_mae: 0.0242\n",
      "Epoch 64/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0013 - mae: 0.0168 - val_loss: 0.0012 - val_mae: 0.0225\n",
      "Epoch 65/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0165 - val_loss: 0.0010 - val_mae: 0.0216\n",
      "Epoch 66/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0013 - mae: 0.0165 - val_loss: 0.0010 - val_mae: 0.0223\n",
      "Epoch 67/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0168 - val_loss: 0.0010 - val_mae: 0.0218\n",
      "Epoch 68/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0166 - val_loss: 0.0012 - val_mae: 0.0235\n",
      "Epoch 69/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0165 - val_loss: 0.0010 - val_mae: 0.0225\n",
      "Epoch 70/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0166 - val_loss: 0.0012 - val_mae: 0.0225\n",
      "Epoch 71/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0166 - val_loss: 0.0013 - val_mae: 0.0230\n",
      "Epoch 72/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0165 - val_loss: 0.0010 - val_mae: 0.0216\n",
      "Epoch 73/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0013 - mae: 0.0166 - val_loss: 0.0011 - val_mae: 0.0221\n",
      "Epoch 74/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0013 - mae: 0.0165 - val_loss: 0.0010 - val_mae: 0.0216\n",
      "Epoch 75/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0013 - mae: 0.0165 - val_loss: 0.0010 - val_mae: 0.0217\n",
      "Epoch 76/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - loss: 0.0013 - mae: 0.0166 - val_loss: 0.0012 - val_mae: 0.0235\n",
      "Epoch 77/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - loss: 0.0013 - mae: 0.0166 - val_loss: 0.0010 - val_mae: 0.0216\n",
      "Epoch 78/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0165 - val_loss: 0.0010 - val_mae: 0.0217\n",
      "Epoch 79/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0166 - val_loss: 0.0010 - val_mae: 0.0217\n",
      "Epoch 80/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - loss: 0.0013 - mae: 0.0166 - val_loss: 0.0011 - val_mae: 0.0218\n",
      "Epoch 81/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0165 - val_loss: 0.0010 - val_mae: 0.0223\n",
      "Epoch 82/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0166 - val_loss: 0.0011 - val_mae: 0.0232\n",
      "Epoch 83/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.0013 - mae: 0.0166 - val_loss: 0.0011 - val_mae: 0.0231\n",
      "Epoch 84/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0165 - val_loss: 0.0012 - val_mae: 0.0237\n",
      "Epoch 85/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0166 - val_loss: 0.0011 - val_mae: 0.0229\n",
      "Epoch 86/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0165 - val_loss: 0.0011 - val_mae: 0.0229\n",
      "Epoch 87/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0166 - val_loss: 0.0010 - val_mae: 0.0217\n",
      "Epoch 88/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0166 - val_loss: 0.0010 - val_mae: 0.0217\n",
      "Epoch 89/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0166 - val_loss: 0.0010 - val_mae: 0.0218\n",
      "Epoch 90/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0165 - val_loss: 0.0011 - val_mae: 0.0233\n",
      "Epoch 91/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0165 - val_loss: 0.0011 - val_mae: 0.0227\n",
      "Epoch 92/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0165 - val_loss: 0.0011 - val_mae: 0.0233\n",
      "Epoch 93/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0165 - val_loss: 0.0011 - val_mae: 0.0235\n",
      "Epoch 94/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0164 - val_loss: 0.0011 - val_mae: 0.0230\n",
      "Epoch 95/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0165 - val_loss: 0.0011 - val_mae: 0.0227\n",
      "Epoch 96/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0165 - val_loss: 0.0011 - val_mae: 0.0222\n",
      "Epoch 97/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0165 - val_loss: 0.0012 - val_mae: 0.0228\n",
      "Epoch 98/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0165 - val_loss: 0.0011 - val_mae: 0.0238\n",
      "Epoch 99/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0165 - val_loss: 0.0013 - val_mae: 0.0249\n",
      "Epoch 100/100\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - loss: 0.0013 - mae: 0.0165 - val_loss: 0.0013 - val_mae: 0.0248\n",
      "\u001b[1m864/864\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step\n",
      "✅ Done: tomato_Bangalore_daily.csv | MAE=564.06, RMSE=956.37, R2=0.56, MAPE=44.78%, Accuracy=55.22%\n",
      "🚀 Processing: tomato_Belgaum_daily.csv\n",
      "Epoch 1/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 0.0858 - mae: 0.1300 - val_loss: 0.0195 - val_mae: 0.0956\n",
      "Epoch 2/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0059 - mae: 0.0604 - val_loss: 0.0226 - val_mae: 0.0983\n",
      "Epoch 3/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0045 - mae: 0.0528 - val_loss: 0.0217 - val_mae: 0.0964\n",
      "Epoch 4/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0034 - mae: 0.0459 - val_loss: 0.0223 - val_mae: 0.0978\n",
      "Epoch 5/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0026 - mae: 0.0403 - val_loss: 0.0228 - val_mae: 0.0982\n",
      "Epoch 6/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0021 - mae: 0.0355 - val_loss: 0.0194 - val_mae: 0.0926\n",
      "Epoch 7/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0018 - mae: 0.0333 - val_loss: 0.0209 - val_mae: 0.0947\n",
      "Epoch 8/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0015 - mae: 0.0290 - val_loss: 0.0207 - val_mae: 0.0939\n",
      "Epoch 9/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0012 - mae: 0.0264 - val_loss: 0.0189 - val_mae: 0.0904\n",
      "Epoch 10/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0011 - mae: 0.0245 - val_loss: 0.0191 - val_mae: 0.0901\n",
      "Epoch 11/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 9.3297e-04 - mae: 0.0228 - val_loss: 0.0205 - val_mae: 0.0932\n",
      "Epoch 12/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 8.5836e-04 - mae: 0.0219 - val_loss: 0.0165 - val_mae: 0.0840\n",
      "Epoch 13/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 7.2997e-04 - mae: 0.0200 - val_loss: 0.0149 - val_mae: 0.0801\n",
      "Epoch 14/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 6.2893e-04 - mae: 0.0184 - val_loss: 0.0155 - val_mae: 0.0803\n",
      "Epoch 15/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 5.2712e-04 - mae: 0.0169 - val_loss: 0.0143 - val_mae: 0.0766\n",
      "Epoch 16/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 4.4227e-04 - mae: 0.0151 - val_loss: 0.0135 - val_mae: 0.0742\n",
      "Epoch 17/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 3.4825e-04 - mae: 0.0131 - val_loss: 0.0126 - val_mae: 0.0728\n",
      "Epoch 18/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 3.5093e-04 - mae: 0.0137 - val_loss: 0.0123 - val_mae: 0.0706\n",
      "Epoch 19/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 2.7724e-04 - mae: 0.0119 - val_loss: 0.0127 - val_mae: 0.0714\n",
      "Epoch 20/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 2.1991e-04 - mae: 0.0102 - val_loss: 0.0121 - val_mae: 0.0695\n",
      "Epoch 21/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 2.1144e-04 - mae: 0.0101 - val_loss: 0.0117 - val_mae: 0.0737\n",
      "Epoch 22/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 2.1374e-04 - mae: 0.0102 - val_loss: 0.0119 - val_mae: 0.0699\n",
      "Epoch 23/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.8907e-04 - mae: 0.0093 - val_loss: 0.0118 - val_mae: 0.0708\n",
      "Epoch 24/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.7657e-04 - mae: 0.0089 - val_loss: 0.0119 - val_mae: 0.0733\n",
      "Epoch 25/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 1.9256e-04 - mae: 0.0097 - val_loss: 0.0119 - val_mae: 0.0732\n",
      "Epoch 26/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 2.2108e-04 - mae: 0.0101 - val_loss: 0.0126 - val_mae: 0.0710\n",
      "Epoch 27/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 1.8096e-04 - mae: 0.0089 - val_loss: 0.0120 - val_mae: 0.0705\n",
      "Epoch 28/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.9003e-04 - mae: 0.0092 - val_loss: 0.0120 - val_mae: 0.0737\n",
      "Epoch 29/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.7534e-04 - mae: 0.0089 - val_loss: 0.0121 - val_mae: 0.0709\n",
      "Epoch 30/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.5691e-04 - mae: 0.0080 - val_loss: 0.0124 - val_mae: 0.0764\n",
      "Epoch 31/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.8507e-04 - mae: 0.0091 - val_loss: 0.0124 - val_mae: 0.0714\n",
      "Epoch 32/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.8272e-04 - mae: 0.0091 - val_loss: 0.0122 - val_mae: 0.0729\n",
      "Epoch 33/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.7479e-04 - mae: 0.0089 - val_loss: 0.0131 - val_mae: 0.0715\n",
      "Epoch 34/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.7222e-04 - mae: 0.0087 - val_loss: 0.0125 - val_mae: 0.0709\n",
      "Epoch 35/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.3804e-04 - mae: 0.0072 - val_loss: 0.0125 - val_mae: 0.0742\n",
      "Epoch 36/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.6300e-04 - mae: 0.0084 - val_loss: 0.0124 - val_mae: 0.0722\n",
      "Epoch 37/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.6253e-04 - mae: 0.0083 - val_loss: 0.0126 - val_mae: 0.0731\n",
      "Epoch 38/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 1.7552e-04 - mae: 0.0089 - val_loss: 0.0128 - val_mae: 0.0719\n",
      "Epoch 39/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.6535e-04 - mae: 0.0085 - val_loss: 0.0126 - val_mae: 0.0735\n",
      "Epoch 40/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.6283e-04 - mae: 0.0085 - val_loss: 0.0132 - val_mae: 0.0710\n",
      "Epoch 41/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.3618e-04 - mae: 0.0072 - val_loss: 0.0128 - val_mae: 0.0743\n",
      "Epoch 42/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.5577e-04 - mae: 0.0081 - val_loss: 0.0130 - val_mae: 0.0728\n",
      "Epoch 43/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 1.4435e-04 - mae: 0.0077 - val_loss: 0.0132 - val_mae: 0.0708\n",
      "Epoch 44/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.7855e-04 - mae: 0.0090 - val_loss: 0.0134 - val_mae: 0.0713\n",
      "Epoch 45/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.3145e-04 - mae: 0.0069 - val_loss: 0.0133 - val_mae: 0.0745\n",
      "Epoch 46/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.4561e-04 - mae: 0.0076 - val_loss: 0.0134 - val_mae: 0.0719\n",
      "Epoch 47/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.3729e-04 - mae: 0.0070 - val_loss: 0.0135 - val_mae: 0.0721\n",
      "Epoch 48/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.4400e-04 - mae: 0.0077 - val_loss: 0.0133 - val_mae: 0.0737\n",
      "Epoch 49/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.3153e-04 - mae: 0.0069 - val_loss: 0.0134 - val_mae: 0.0733\n",
      "Epoch 50/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.4491e-04 - mae: 0.0077 - val_loss: 0.0136 - val_mae: 0.0727\n",
      "Epoch 51/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.3876e-04 - mae: 0.0072 - val_loss: 0.0133 - val_mae: 0.0732\n",
      "Epoch 52/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.3507e-04 - mae: 0.0072 - val_loss: 0.0136 - val_mae: 0.0723\n",
      "Epoch 53/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.2854e-04 - mae: 0.0066 - val_loss: 0.0135 - val_mae: 0.0726\n",
      "Epoch 54/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.4356e-04 - mae: 0.0077 - val_loss: 0.0136 - val_mae: 0.0730\n",
      "Epoch 55/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.3264e-04 - mae: 0.0071 - val_loss: 0.0136 - val_mae: 0.0749\n",
      "Epoch 56/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.2512e-04 - mae: 0.0066 - val_loss: 0.0139 - val_mae: 0.0720\n",
      "Epoch 57/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.2593e-04 - mae: 0.0065 - val_loss: 0.0140 - val_mae: 0.0810\n",
      "Epoch 58/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.4181e-04 - mae: 0.0076 - val_loss: 0.0140 - val_mae: 0.0741\n",
      "Epoch 59/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.2635e-04 - mae: 0.0067 - val_loss: 0.0140 - val_mae: 0.0731\n",
      "Epoch 60/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 1.3892e-04 - mae: 0.0073 - val_loss: 0.0148 - val_mae: 0.0718\n",
      "Epoch 61/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.3051e-04 - mae: 0.0068 - val_loss: 0.0143 - val_mae: 0.0730\n",
      "Epoch 62/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.2587e-04 - mae: 0.0066 - val_loss: 0.0140 - val_mae: 0.0746\n",
      "Epoch 63/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.3792e-04 - mae: 0.0073 - val_loss: 0.0140 - val_mae: 0.0738\n",
      "Epoch 64/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.2756e-04 - mae: 0.0068 - val_loss: 0.0145 - val_mae: 0.0727\n",
      "Epoch 65/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.2581e-04 - mae: 0.0069 - val_loss: 0.0143 - val_mae: 0.0736\n",
      "Epoch 66/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.2556e-04 - mae: 0.0065 - val_loss: 0.0145 - val_mae: 0.0728\n",
      "Epoch 67/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.2503e-04 - mae: 0.0066 - val_loss: 0.0143 - val_mae: 0.0734\n",
      "Epoch 68/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.2734e-04 - mae: 0.0067 - val_loss: 0.0143 - val_mae: 0.0742\n",
      "Epoch 69/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.1799e-04 - mae: 0.0062 - val_loss: 0.0146 - val_mae: 0.0729\n",
      "Epoch 70/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 1.3800e-04 - mae: 0.0071 - val_loss: 0.0147 - val_mae: 0.0732\n",
      "Epoch 71/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.2710e-04 - mae: 0.0067 - val_loss: 0.0146 - val_mae: 0.0734\n",
      "Epoch 72/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.3236e-04 - mae: 0.0068 - val_loss: 0.0145 - val_mae: 0.0735\n",
      "Epoch 73/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.2811e-04 - mae: 0.0069 - val_loss: 0.0154 - val_mae: 0.0728\n",
      "Epoch 74/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.2558e-04 - mae: 0.0066 - val_loss: 0.0149 - val_mae: 0.0730\n",
      "Epoch 75/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.2505e-04 - mae: 0.0066 - val_loss: 0.0147 - val_mae: 0.0738\n",
      "Epoch 76/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.2635e-04 - mae: 0.0069 - val_loss: 0.0153 - val_mae: 0.0733\n",
      "Epoch 77/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.3286e-04 - mae: 0.0071 - val_loss: 0.0153 - val_mae: 0.0729\n",
      "Epoch 78/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.2438e-04 - mae: 0.0064 - val_loss: 0.0149 - val_mae: 0.0733\n",
      "Epoch 79/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.2676e-04 - mae: 0.0067 - val_loss: 0.0153 - val_mae: 0.0731\n",
      "Epoch 80/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.1829e-04 - mae: 0.0061 - val_loss: 0.0150 - val_mae: 0.0729\n",
      "Epoch 81/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.1942e-04 - mae: 0.0063 - val_loss: 0.0150 - val_mae: 0.0740\n",
      "Epoch 82/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.2234e-04 - mae: 0.0064 - val_loss: 0.0154 - val_mae: 0.0728\n",
      "Epoch 83/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.3201e-04 - mae: 0.0069 - val_loss: 0.0153 - val_mae: 0.0732\n",
      "Epoch 84/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.2482e-04 - mae: 0.0067 - val_loss: 0.0153 - val_mae: 0.0731\n",
      "Epoch 85/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.2154e-04 - mae: 0.0064 - val_loss: 0.0160 - val_mae: 0.0741\n",
      "Epoch 86/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.1395e-04 - mae: 0.0061 - val_loss: 0.0154 - val_mae: 0.0730\n",
      "Epoch 87/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.2127e-04 - mae: 0.0062 - val_loss: 0.0149 - val_mae: 0.0742\n",
      "Epoch 88/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.1639e-04 - mae: 0.0065 - val_loss: 0.0153 - val_mae: 0.0734\n",
      "Epoch 89/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.2199e-04 - mae: 0.0063 - val_loss: 0.0148 - val_mae: 0.0746\n",
      "Epoch 90/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 1.1674e-04 - mae: 0.0061 - val_loss: 0.0153 - val_mae: 0.0734\n",
      "Epoch 91/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.1775e-04 - mae: 0.0060 - val_loss: 0.0149 - val_mae: 0.0751\n",
      "Epoch 92/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.1905e-04 - mae: 0.0064 - val_loss: 0.0146 - val_mae: 0.0757\n",
      "Epoch 93/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.2005e-04 - mae: 0.0062 - val_loss: 0.0148 - val_mae: 0.0743\n",
      "Epoch 94/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.2360e-04 - mae: 0.0064 - val_loss: 0.0152 - val_mae: 0.0746\n",
      "Epoch 95/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.2505e-04 - mae: 0.0065 - val_loss: 0.0151 - val_mae: 0.0740\n",
      "Epoch 96/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.2082e-04 - mae: 0.0063 - val_loss: 0.0157 - val_mae: 0.0730\n",
      "Epoch 97/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.1849e-04 - mae: 0.0062 - val_loss: 0.0152 - val_mae: 0.0733\n",
      "Epoch 98/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.1437e-04 - mae: 0.0059 - val_loss: 0.0149 - val_mae: 0.0748\n",
      "Epoch 99/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 1.2467e-04 - mae: 0.0065 - val_loss: 0.0149 - val_mae: 0.0750\n",
      "Epoch 100/100\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 1.2451e-04 - mae: 0.0067 - val_loss: 0.0150 - val_mae: 0.0736\n",
      "\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step   \n",
      "✅ Done: tomato_Belgaum_daily.csv | MAE=284.46, RMSE=559.71, R2=0.75, MAPE=16.89%, Accuracy=83.11%\n",
      "🚀 Processing: tomato_Bellary_daily.csv\n",
      "Epoch 1/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0372 - mae: 0.1109 - val_loss: 0.0145 - val_mae: 0.0630\n",
      "Epoch 2/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0054 - mae: 0.0558 - val_loss: 0.0148 - val_mae: 0.0494\n",
      "Epoch 3/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0035 - mae: 0.0442 - val_loss: 0.0147 - val_mae: 0.0649\n",
      "Epoch 4/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0029 - mae: 0.0396 - val_loss: 0.0149 - val_mae: 0.0589\n",
      "Epoch 5/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0026 - mae: 0.0366 - val_loss: 0.0147 - val_mae: 0.0578\n",
      "Epoch 6/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0024 - mae: 0.0352 - val_loss: 0.0149 - val_mae: 0.0489\n",
      "Epoch 7/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0022 - mae: 0.0335 - val_loss: 0.0146 - val_mae: 0.0498\n",
      "Epoch 8/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0022 - mae: 0.0331 - val_loss: 0.0142 - val_mae: 0.0467\n",
      "Epoch 9/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0021 - mae: 0.0320 - val_loss: 0.0148 - val_mae: 0.0484\n",
      "Epoch 10/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0021 - mae: 0.0326 - val_loss: 0.0138 - val_mae: 0.0588\n",
      "Epoch 11/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0020 - mae: 0.0318 - val_loss: 0.0136 - val_mae: 0.0556\n",
      "Epoch 12/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0020 - mae: 0.0312 - val_loss: 0.0145 - val_mae: 0.0465\n",
      "Epoch 13/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0019 - mae: 0.0303 - val_loss: 0.0135 - val_mae: 0.0458\n",
      "Epoch 14/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0019 - mae: 0.0301 - val_loss: 0.0135 - val_mae: 0.0459\n",
      "Epoch 15/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0020 - mae: 0.0309 - val_loss: 0.0124 - val_mae: 0.0459\n",
      "Epoch 16/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0020 - mae: 0.0313 - val_loss: 0.0133 - val_mae: 0.0497\n",
      "Epoch 17/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0019 - mae: 0.0298 - val_loss: 0.0114 - val_mae: 0.0472\n",
      "Epoch 18/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0293 - val_loss: 0.0114 - val_mae: 0.0522\n",
      "Epoch 19/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0019 - mae: 0.0295 - val_loss: 0.0107 - val_mae: 0.0505\n",
      "Epoch 20/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0019 - mae: 0.0296 - val_loss: 0.0113 - val_mae: 0.0430\n",
      "Epoch 21/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0019 - mae: 0.0296 - val_loss: 0.0118 - val_mae: 0.0463\n",
      "Epoch 22/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0284 - val_loss: 0.0102 - val_mae: 0.0478\n",
      "Epoch 23/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0020 - mae: 0.0309 - val_loss: 0.0095 - val_mae: 0.0454\n",
      "Epoch 24/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0287 - val_loss: 0.0099 - val_mae: 0.0411\n",
      "Epoch 25/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0020 - mae: 0.0305 - val_loss: 0.0084 - val_mae: 0.0392\n",
      "Epoch 26/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0282 - val_loss: 0.0082 - val_mae: 0.0459\n",
      "Epoch 27/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0019 - mae: 0.0293 - val_loss: 0.0078 - val_mae: 0.0385\n",
      "Epoch 28/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0289 - val_loss: 0.0077 - val_mae: 0.0368\n",
      "Epoch 29/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0288 - val_loss: 0.0074 - val_mae: 0.0361\n",
      "Epoch 30/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0017 - mae: 0.0278 - val_loss: 0.0078 - val_mae: 0.0372\n",
      "Epoch 31/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0284 - val_loss: 0.0070 - val_mae: 0.0373\n",
      "Epoch 32/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0018 - mae: 0.0282 - val_loss: 0.0073 - val_mae: 0.0396\n",
      "Epoch 33/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0280 - val_loss: 0.0072 - val_mae: 0.0436\n",
      "Epoch 34/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0017 - mae: 0.0279 - val_loss: 0.0062 - val_mae: 0.0401\n",
      "Epoch 35/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0282 - val_loss: 0.0066 - val_mae: 0.0354\n",
      "Epoch 36/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0018 - mae: 0.0284 - val_loss: 0.0067 - val_mae: 0.0353\n",
      "Epoch 37/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0017 - mae: 0.0276 - val_loss: 0.0066 - val_mae: 0.0376\n",
      "Epoch 38/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0018 - mae: 0.0286 - val_loss: 0.0061 - val_mae: 0.0466\n",
      "Epoch 39/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0282 - val_loss: 0.0069 - val_mae: 0.0405\n",
      "Epoch 40/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0017 - mae: 0.0277 - val_loss: 0.0062 - val_mae: 0.0407\n",
      "Epoch 41/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0287 - val_loss: 0.0065 - val_mae: 0.0379\n",
      "Epoch 42/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0282 - val_loss: 0.0068 - val_mae: 0.0439\n",
      "Epoch 43/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0017 - mae: 0.0274 - val_loss: 0.0066 - val_mae: 0.0421\n",
      "Epoch 44/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0017 - mae: 0.0276 - val_loss: 0.0061 - val_mae: 0.0343\n",
      "Epoch 45/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0017 - mae: 0.0274 - val_loss: 0.0074 - val_mae: 0.0378\n",
      "Epoch 46/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0017 - mae: 0.0278 - val_loss: 0.0058 - val_mae: 0.0401\n",
      "Epoch 47/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0017 - mae: 0.0271 - val_loss: 0.0054 - val_mae: 0.0335\n",
      "Epoch 48/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0017 - mae: 0.0274 - val_loss: 0.0064 - val_mae: 0.0364\n",
      "Epoch 49/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0017 - mae: 0.0274 - val_loss: 0.0059 - val_mae: 0.0423\n",
      "Epoch 50/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0017 - mae: 0.0280 - val_loss: 0.0069 - val_mae: 0.0390\n",
      "Epoch 51/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0017 - mae: 0.0269 - val_loss: 0.0066 - val_mae: 0.0352\n",
      "Epoch 52/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0017 - mae: 0.0275 - val_loss: 0.0058 - val_mae: 0.0468\n",
      "Epoch 53/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0017 - mae: 0.0273 - val_loss: 0.0061 - val_mae: 0.0459\n",
      "Epoch 54/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0017 - mae: 0.0276 - val_loss: 0.0056 - val_mae: 0.0418\n",
      "Epoch 55/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0017 - mae: 0.0276 - val_loss: 0.0058 - val_mae: 0.0345\n",
      "Epoch 56/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0017 - mae: 0.0274 - val_loss: 0.0063 - val_mae: 0.0368\n",
      "Epoch 57/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0017 - mae: 0.0273 - val_loss: 0.0059 - val_mae: 0.0334\n",
      "Epoch 58/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0017 - mae: 0.0275 - val_loss: 0.0065 - val_mae: 0.0397\n",
      "Epoch 59/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0017 - mae: 0.0272 - val_loss: 0.0064 - val_mae: 0.0375\n",
      "Epoch 60/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0017 - mae: 0.0267 - val_loss: 0.0063 - val_mae: 0.0382\n",
      "Epoch 61/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0017 - mae: 0.0270 - val_loss: 0.0071 - val_mae: 0.0358\n",
      "Epoch 62/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0017 - mae: 0.0267 - val_loss: 0.0063 - val_mae: 0.0367\n",
      "Epoch 63/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0017 - mae: 0.0268 - val_loss: 0.0065 - val_mae: 0.0385\n",
      "Epoch 64/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0017 - mae: 0.0268 - val_loss: 0.0072 - val_mae: 0.0365\n",
      "Epoch 65/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0017 - mae: 0.0271 - val_loss: 0.0063 - val_mae: 0.0392\n",
      "Epoch 66/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0017 - mae: 0.0270 - val_loss: 0.0065 - val_mae: 0.0353\n",
      "Epoch 67/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0017 - mae: 0.0265 - val_loss: 0.0076 - val_mae: 0.0413\n",
      "Epoch 68/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0017 - mae: 0.0267 - val_loss: 0.0066 - val_mae: 0.0353\n",
      "Epoch 69/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0017 - mae: 0.0275 - val_loss: 0.0071 - val_mae: 0.0414\n",
      "Epoch 70/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0017 - mae: 0.0264 - val_loss: 0.0071 - val_mae: 0.0377\n",
      "Epoch 71/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0017 - mae: 0.0266 - val_loss: 0.0065 - val_mae: 0.0387\n",
      "Epoch 72/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0016 - mae: 0.0266 - val_loss: 0.0073 - val_mae: 0.0414\n",
      "Epoch 73/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0017 - mae: 0.0272 - val_loss: 0.0071 - val_mae: 0.0431\n",
      "Epoch 74/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0017 - mae: 0.0271 - val_loss: 0.0075 - val_mae: 0.0385\n",
      "Epoch 75/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0017 - mae: 0.0266 - val_loss: 0.0072 - val_mae: 0.0356\n",
      "Epoch 76/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0016 - mae: 0.0266 - val_loss: 0.0074 - val_mae: 0.0411\n",
      "Epoch 77/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0017 - mae: 0.0266 - val_loss: 0.0072 - val_mae: 0.0390\n",
      "Epoch 78/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0017 - mae: 0.0271 - val_loss: 0.0076 - val_mae: 0.0372\n",
      "Epoch 79/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0017 - mae: 0.0268 - val_loss: 0.0070 - val_mae: 0.0366\n",
      "Epoch 80/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0016 - mae: 0.0265 - val_loss: 0.0072 - val_mae: 0.0383\n",
      "Epoch 81/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0016 - mae: 0.0267 - val_loss: 0.0071 - val_mae: 0.0403\n",
      "Epoch 82/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0016 - mae: 0.0264 - val_loss: 0.0068 - val_mae: 0.0362\n",
      "Epoch 83/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0016 - mae: 0.0265 - val_loss: 0.0079 - val_mae: 0.0428\n",
      "Epoch 84/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0016 - mae: 0.0266 - val_loss: 0.0082 - val_mae: 0.0407\n",
      "Epoch 85/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0016 - mae: 0.0267 - val_loss: 0.0079 - val_mae: 0.0403\n",
      "Epoch 86/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0016 - mae: 0.0266 - val_loss: 0.0079 - val_mae: 0.0377\n",
      "Epoch 87/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0016 - mae: 0.0265 - val_loss: 0.0079 - val_mae: 0.0436\n",
      "Epoch 88/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0016 - mae: 0.0266 - val_loss: 0.0081 - val_mae: 0.0373\n",
      "Epoch 89/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0016 - mae: 0.0265 - val_loss: 0.0081 - val_mae: 0.0373\n",
      "Epoch 90/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0016 - mae: 0.0267 - val_loss: 0.0089 - val_mae: 0.0443\n",
      "Epoch 91/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0016 - mae: 0.0266 - val_loss: 0.0085 - val_mae: 0.0381\n",
      "Epoch 92/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0016 - mae: 0.0266 - val_loss: 0.0092 - val_mae: 0.0391\n",
      "Epoch 93/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0016 - mae: 0.0266 - val_loss: 0.0084 - val_mae: 0.0379\n",
      "Epoch 94/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0016 - mae: 0.0264 - val_loss: 0.0094 - val_mae: 0.0458\n",
      "Epoch 95/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0016 - mae: 0.0267 - val_loss: 0.0089 - val_mae: 0.0453\n",
      "Epoch 96/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0016 - mae: 0.0265 - val_loss: 0.0085 - val_mae: 0.0487\n",
      "Epoch 97/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0016 - mae: 0.0268 - val_loss: 0.0090 - val_mae: 0.0420\n",
      "Epoch 98/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0016 - mae: 0.0262 - val_loss: 0.0085 - val_mae: 0.0379\n",
      "Epoch 99/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0016 - mae: 0.0265 - val_loss: 0.0091 - val_mae: 0.0415\n",
      "Epoch 100/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0016 - mae: 0.0264 - val_loss: 0.0102 - val_mae: 0.0503\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step   \n",
      "✅ Done: tomato_Bellary_daily.csv | MAE=256.41, RMSE=415.08, R2=0.55, MAPE=37.88%, Accuracy=62.12%\n",
      "🚀 Processing: tomato_Chamrajnagar_daily.csv\n",
      "Epoch 1/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 14ms/step - loss: 0.0567 - mae: 0.0860 - val_loss: 0.0019 - val_mae: 0.0333\n",
      "Epoch 2/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - loss: 0.0026 - mae: 0.0398 - val_loss: 0.0024 - val_mae: 0.0423\n",
      "Epoch 3/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - loss: 0.0012 - mae: 0.0272 - val_loss: 0.0020 - val_mae: 0.0321\n",
      "Epoch 4/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - loss: 8.1302e-04 - mae: 0.0220 - val_loss: 0.0019 - val_mae: 0.0343\n",
      "Epoch 5/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - loss: 6.5243e-04 - mae: 0.0194 - val_loss: 0.0019 - val_mae: 0.0330\n",
      "Epoch 6/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - loss: 5.5412e-04 - mae: 0.0175 - val_loss: 0.0020 - val_mae: 0.0321\n",
      "Epoch 7/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 5.0101e-04 - mae: 0.0164 - val_loss: 0.0020 - val_mae: 0.0324\n",
      "Epoch 8/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - loss: 4.8494e-04 - mae: 0.0161 - val_loss: 0.0019 - val_mae: 0.0352\n",
      "Epoch 9/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 4.7869e-04 - mae: 0.0160 - val_loss: 0.0019 - val_mae: 0.0346\n",
      "Epoch 10/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 4.7022e-04 - mae: 0.0158 - val_loss: 0.0021 - val_mae: 0.0321\n",
      "Epoch 11/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - loss: 4.5289e-04 - mae: 0.0153 - val_loss: 0.0020 - val_mae: 0.0323\n",
      "Epoch 12/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - loss: 4.4007e-04 - mae: 0.0151 - val_loss: 0.0020 - val_mae: 0.0331\n",
      "Epoch 13/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 4.4250e-04 - mae: 0.0151 - val_loss: 0.0021 - val_mae: 0.0328\n",
      "Epoch 14/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - loss: 4.3393e-04 - mae: 0.0149 - val_loss: 0.0020 - val_mae: 0.0372\n",
      "Epoch 15/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 4.4245e-04 - mae: 0.0150 - val_loss: 0.0019 - val_mae: 0.0322\n",
      "Epoch 16/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - loss: 4.2139e-04 - mae: 0.0144 - val_loss: 0.0020 - val_mae: 0.0315\n",
      "Epoch 17/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - loss: 4.3379e-04 - mae: 0.0148 - val_loss: 0.0019 - val_mae: 0.0323\n",
      "Epoch 18/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 4.2076e-04 - mae: 0.0144 - val_loss: 0.0018 - val_mae: 0.0335\n",
      "Epoch 19/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - loss: 4.2507e-04 - mae: 0.0145 - val_loss: 0.0019 - val_mae: 0.0315\n",
      "Epoch 20/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - loss: 4.0824e-04 - mae: 0.0141 - val_loss: 0.0020 - val_mae: 0.0316\n",
      "Epoch 21/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - loss: 4.1371e-04 - mae: 0.0141 - val_loss: 0.0018 - val_mae: 0.0318\n",
      "Epoch 22/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - loss: 4.0921e-04 - mae: 0.0141 - val_loss: 0.0019 - val_mae: 0.0323\n",
      "Epoch 23/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 4.1734e-04 - mae: 0.0144 - val_loss: 0.0020 - val_mae: 0.0320\n",
      "Epoch 24/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - loss: 4.1266e-04 - mae: 0.0143 - val_loss: 0.0023 - val_mae: 0.0327\n",
      "Epoch 25/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - loss: 4.1335e-04 - mae: 0.0141 - val_loss: 0.0019 - val_mae: 0.0324\n",
      "Epoch 26/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - loss: 4.1360e-04 - mae: 0.0141 - val_loss: 0.0019 - val_mae: 0.0329\n",
      "Epoch 27/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - loss: 4.1303e-04 - mae: 0.0142 - val_loss: 0.0021 - val_mae: 0.0323\n",
      "Epoch 28/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 4.0507e-04 - mae: 0.0140 - val_loss: 0.0020 - val_mae: 0.0318\n",
      "Epoch 29/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 4.0689e-04 - mae: 0.0139 - val_loss: 0.0020 - val_mae: 0.0319\n",
      "Epoch 30/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 4.1093e-04 - mae: 0.0141 - val_loss: 0.0020 - val_mae: 0.0320\n",
      "Epoch 31/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 4.0539e-04 - mae: 0.0139 - val_loss: 0.0019 - val_mae: 0.0321\n",
      "Epoch 32/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - loss: 4.0707e-04 - mae: 0.0140 - val_loss: 0.0020 - val_mae: 0.0326\n",
      "Epoch 33/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 4.1192e-04 - mae: 0.0142 - val_loss: 0.0020 - val_mae: 0.0321\n",
      "Epoch 34/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 4.0790e-04 - mae: 0.0140 - val_loss: 0.0021 - val_mae: 0.0323\n",
      "Epoch 35/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - loss: 4.0483e-04 - mae: 0.0141 - val_loss: 0.0022 - val_mae: 0.0327\n",
      "Epoch 36/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - loss: 4.1076e-04 - mae: 0.0142 - val_loss: 0.0021 - val_mae: 0.0326\n",
      "Epoch 37/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - loss: 4.0697e-04 - mae: 0.0140 - val_loss: 0.0019 - val_mae: 0.0327\n",
      "Epoch 38/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 4.0834e-04 - mae: 0.0141 - val_loss: 0.0019 - val_mae: 0.0342\n",
      "Epoch 39/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 4.0752e-04 - mae: 0.0140 - val_loss: 0.0019 - val_mae: 0.0352\n",
      "Epoch 40/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 3.9821e-04 - mae: 0.0137 - val_loss: 0.0020 - val_mae: 0.0325\n",
      "Epoch 41/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 4.0547e-04 - mae: 0.0140 - val_loss: 0.0021 - val_mae: 0.0325\n",
      "Epoch 42/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 4.0104e-04 - mae: 0.0139 - val_loss: 0.0019 - val_mae: 0.0331\n",
      "Epoch 43/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 4.0180e-04 - mae: 0.0138 - val_loss: 0.0019 - val_mae: 0.0341\n",
      "Epoch 44/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 4.0514e-04 - mae: 0.0139 - val_loss: 0.0020 - val_mae: 0.0358\n",
      "Epoch 45/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 4.0157e-04 - mae: 0.0138 - val_loss: 0.0019 - val_mae: 0.0326\n",
      "Epoch 46/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 4.0134e-04 - mae: 0.0138 - val_loss: 0.0020 - val_mae: 0.0331\n",
      "Epoch 47/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 4.0024e-04 - mae: 0.0137 - val_loss: 0.0019 - val_mae: 0.0340\n",
      "Epoch 48/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 3.9235e-04 - mae: 0.0135 - val_loss: 0.0020 - val_mae: 0.0330\n",
      "Epoch 49/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 3.9524e-04 - mae: 0.0136 - val_loss: 0.0019 - val_mae: 0.0331\n",
      "Epoch 50/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 3.9122e-04 - mae: 0.0135 - val_loss: 0.0020 - val_mae: 0.0327\n",
      "Epoch 51/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 3.9235e-04 - mae: 0.0136 - val_loss: 0.0019 - val_mae: 0.0330\n",
      "Epoch 52/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 3.9456e-04 - mae: 0.0136 - val_loss: 0.0021 - val_mae: 0.0329\n",
      "Epoch 53/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 3.9483e-04 - mae: 0.0136 - val_loss: 0.0022 - val_mae: 0.0336\n",
      "Epoch 54/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - loss: 3.9345e-04 - mae: 0.0136 - val_loss: 0.0020 - val_mae: 0.0328\n",
      "Epoch 55/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 3.8953e-04 - mae: 0.0134 - val_loss: 0.0019 - val_mae: 0.0330\n",
      "Epoch 56/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 3.8753e-04 - mae: 0.0133 - val_loss: 0.0020 - val_mae: 0.0327\n",
      "Epoch 57/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - loss: 3.8871e-04 - mae: 0.0134 - val_loss: 0.0019 - val_mae: 0.0353\n",
      "Epoch 58/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 3.9040e-04 - mae: 0.0134 - val_loss: 0.0019 - val_mae: 0.0329\n",
      "Epoch 59/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 3.8652e-04 - mae: 0.0133 - val_loss: 0.0019 - val_mae: 0.0330\n",
      "Epoch 60/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - loss: 3.8581e-04 - mae: 0.0132 - val_loss: 0.0019 - val_mae: 0.0330\n",
      "Epoch 61/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - loss: 3.8754e-04 - mae: 0.0134 - val_loss: 0.0019 - val_mae: 0.0328\n",
      "Epoch 62/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - loss: 3.8507e-04 - mae: 0.0132 - val_loss: 0.0019 - val_mae: 0.0329\n",
      "Epoch 63/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - loss: 3.8508e-04 - mae: 0.0132 - val_loss: 0.0019 - val_mae: 0.0329\n",
      "Epoch 64/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - loss: 3.8345e-04 - mae: 0.0131 - val_loss: 0.0019 - val_mae: 0.0330\n",
      "Epoch 65/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 3.8292e-04 - mae: 0.0131 - val_loss: 0.0019 - val_mae: 0.0328\n",
      "Epoch 66/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - loss: 3.8261e-04 - mae: 0.0131 - val_loss: 0.0020 - val_mae: 0.0328\n",
      "Epoch 67/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 3.8226e-04 - mae: 0.0131 - val_loss: 0.0019 - val_mae: 0.0333\n",
      "Epoch 68/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - loss: 3.8169e-04 - mae: 0.0131 - val_loss: 0.0019 - val_mae: 0.0328\n",
      "Epoch 69/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 3.7998e-04 - mae: 0.0130 - val_loss: 0.0019 - val_mae: 0.0337\n",
      "Epoch 70/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 3.8314e-04 - mae: 0.0132 - val_loss: 0.0021 - val_mae: 0.0331\n",
      "Epoch 71/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - loss: 3.8064e-04 - mae: 0.0130 - val_loss: 0.0019 - val_mae: 0.0347\n",
      "Epoch 72/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 3.8031e-04 - mae: 0.0130 - val_loss: 0.0019 - val_mae: 0.0331\n",
      "Epoch 73/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - loss: 3.8224e-04 - mae: 0.0131 - val_loss: 0.0020 - val_mae: 0.0329\n",
      "Epoch 74/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 3.8076e-04 - mae: 0.0130 - val_loss: 0.0019 - val_mae: 0.0329\n",
      "Epoch 75/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 3.7950e-04 - mae: 0.0130 - val_loss: 0.0019 - val_mae: 0.0336\n",
      "Epoch 76/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 3.8113e-04 - mae: 0.0131 - val_loss: 0.0019 - val_mae: 0.0330\n",
      "Epoch 77/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - loss: 3.7989e-04 - mae: 0.0130 - val_loss: 0.0020 - val_mae: 0.0328\n",
      "Epoch 78/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - loss: 3.7981e-04 - mae: 0.0131 - val_loss: 0.0020 - val_mae: 0.0330\n",
      "Epoch 79/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 3.7953e-04 - mae: 0.0130 - val_loss: 0.0019 - val_mae: 0.0335\n",
      "Epoch 80/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 3.7840e-04 - mae: 0.0129 - val_loss: 0.0022 - val_mae: 0.0335\n",
      "Epoch 81/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - loss: 3.7931e-04 - mae: 0.0129 - val_loss: 0.0020 - val_mae: 0.0329\n",
      "Epoch 82/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 3.7942e-04 - mae: 0.0130 - val_loss: 0.0020 - val_mae: 0.0329\n",
      "Epoch 83/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 3.7874e-04 - mae: 0.0130 - val_loss: 0.0020 - val_mae: 0.0330\n",
      "Epoch 84/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 3.7899e-04 - mae: 0.0129 - val_loss: 0.0020 - val_mae: 0.0330\n",
      "Epoch 85/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 3.7833e-04 - mae: 0.0130 - val_loss: 0.0021 - val_mae: 0.0331\n",
      "Epoch 86/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 3.7768e-04 - mae: 0.0129 - val_loss: 0.0019 - val_mae: 0.0330\n",
      "Epoch 87/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 3.7836e-04 - mae: 0.0130 - val_loss: 0.0021 - val_mae: 0.0331\n",
      "Epoch 88/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 3.8128e-04 - mae: 0.0131 - val_loss: 0.0019 - val_mae: 0.0334\n",
      "Epoch 89/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 3.8099e-04 - mae: 0.0130 - val_loss: 0.0020 - val_mae: 0.0330\n",
      "Epoch 90/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 3.7746e-04 - mae: 0.0129 - val_loss: 0.0020 - val_mae: 0.0330\n",
      "Epoch 91/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 3.7941e-04 - mae: 0.0130 - val_loss: 0.0020 - val_mae: 0.0331\n",
      "Epoch 92/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 3.7680e-04 - mae: 0.0129 - val_loss: 0.0020 - val_mae: 0.0331\n",
      "Epoch 93/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 3.7867e-04 - mae: 0.0130 - val_loss: 0.0020 - val_mae: 0.0332\n",
      "Epoch 94/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 3.7914e-04 - mae: 0.0130 - val_loss: 0.0019 - val_mae: 0.0339\n",
      "Epoch 95/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - loss: 3.7879e-04 - mae: 0.0130 - val_loss: 0.0020 - val_mae: 0.0331\n",
      "Epoch 96/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 3.7677e-04 - mae: 0.0129 - val_loss: 0.0021 - val_mae: 0.0333\n",
      "Epoch 97/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 3.7857e-04 - mae: 0.0130 - val_loss: 0.0022 - val_mae: 0.0335\n",
      "Epoch 98/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 3.7937e-04 - mae: 0.0130 - val_loss: 0.0021 - val_mae: 0.0334\n",
      "Epoch 99/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 3.7849e-04 - mae: 0.0129 - val_loss: 0.0020 - val_mae: 0.0332\n",
      "Epoch 100/100\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - loss: 3.7733e-04 - mae: 0.0129 - val_loss: 0.0019 - val_mae: 0.0336\n",
      "\u001b[1m501/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step\n",
      "✅ Done: tomato_Chamrajnagar_daily.csv | MAE=867.78, RMSE=1298.24, R2=0.35, MAPE=99.94%, Accuracy=0.06%\n",
      "🚀 Processing: tomato_Chikmagalur_daily.csv\n",
      "Epoch 1/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - loss: 0.0121 - mae: 0.0649 - val_loss: 0.0112 - val_mae: 0.0744\n",
      "Epoch 2/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0034 - mae: 0.0413 - val_loss: 0.0177 - val_mae: 0.0949\n",
      "Epoch 3/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0030 - mae: 0.0381 - val_loss: 0.0104 - val_mae: 0.0734\n",
      "Epoch 4/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0028 - mae: 0.0367 - val_loss: 0.0111 - val_mae: 0.0703\n",
      "Epoch 5/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0028 - mae: 0.0367 - val_loss: 0.0119 - val_mae: 0.0730\n",
      "Epoch 6/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0027 - mae: 0.0354 - val_loss: 0.0109 - val_mae: 0.0694\n",
      "Epoch 7/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0027 - mae: 0.0352 - val_loss: 0.0101 - val_mae: 0.0669\n",
      "Epoch 8/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0027 - mae: 0.0349 - val_loss: 0.0107 - val_mae: 0.0691\n",
      "Epoch 9/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0026 - mae: 0.0343 - val_loss: 0.0102 - val_mae: 0.0677\n",
      "Epoch 10/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 0.0026 - mae: 0.0340 - val_loss: 0.0097 - val_mae: 0.0659\n",
      "Epoch 11/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0026 - mae: 0.0340 - val_loss: 0.0090 - val_mae: 0.0633\n",
      "Epoch 12/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0026 - mae: 0.0339 - val_loss: 0.0090 - val_mae: 0.0634\n",
      "Epoch 13/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 0.0026 - mae: 0.0339 - val_loss: 0.0097 - val_mae: 0.0655\n",
      "Epoch 14/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0026 - mae: 0.0336 - val_loss: 0.0088 - val_mae: 0.0630\n",
      "Epoch 15/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0026 - mae: 0.0338 - val_loss: 0.0088 - val_mae: 0.0634\n",
      "Epoch 16/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0026 - mae: 0.0336 - val_loss: 0.0088 - val_mae: 0.0630\n",
      "Epoch 17/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0026 - mae: 0.0336 - val_loss: 0.0087 - val_mae: 0.0634\n",
      "Epoch 18/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0026 - mae: 0.0335 - val_loss: 0.0090 - val_mae: 0.0632\n",
      "Epoch 19/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0026 - mae: 0.0334 - val_loss: 0.0088 - val_mae: 0.0630\n",
      "Epoch 20/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0026 - mae: 0.0335 - val_loss: 0.0098 - val_mae: 0.0665\n",
      "Epoch 21/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0026 - mae: 0.0334 - val_loss: 0.0096 - val_mae: 0.0656\n",
      "Epoch 22/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 0.0026 - mae: 0.0334 - val_loss: 0.0096 - val_mae: 0.0660\n",
      "Epoch 23/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0026 - mae: 0.0333 - val_loss: 0.0088 - val_mae: 0.0638\n",
      "Epoch 24/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 0.0026 - mae: 0.0335 - val_loss: 0.0090 - val_mae: 0.0633\n",
      "Epoch 25/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 0.0026 - mae: 0.0334 - val_loss: 0.0093 - val_mae: 0.0647\n",
      "Epoch 26/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 0.0026 - mae: 0.0334 - val_loss: 0.0094 - val_mae: 0.0646\n",
      "Epoch 27/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 0.0026 - mae: 0.0335 - val_loss: 0.0103 - val_mae: 0.0673\n",
      "Epoch 28/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0026 - mae: 0.0333 - val_loss: 0.0091 - val_mae: 0.0637\n",
      "Epoch 29/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0026 - mae: 0.0334 - val_loss: 0.0095 - val_mae: 0.0651\n",
      "Epoch 30/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0026 - mae: 0.0333 - val_loss: 0.0094 - val_mae: 0.0646\n",
      "Epoch 31/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0026 - mae: 0.0333 - val_loss: 0.0087 - val_mae: 0.0628\n",
      "Epoch 32/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0026 - mae: 0.0333 - val_loss: 0.0088 - val_mae: 0.0630\n",
      "Epoch 33/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0026 - mae: 0.0333 - val_loss: 0.0093 - val_mae: 0.0643\n",
      "Epoch 34/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 0.0025 - mae: 0.0332 - val_loss: 0.0089 - val_mae: 0.0633\n",
      "Epoch 35/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0026 - mae: 0.0333 - val_loss: 0.0089 - val_mae: 0.0632\n",
      "Epoch 36/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0026 - mae: 0.0332 - val_loss: 0.0099 - val_mae: 0.0657\n",
      "Epoch 37/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 0.0025 - mae: 0.0332 - val_loss: 0.0101 - val_mae: 0.0660\n",
      "Epoch 38/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0026 - mae: 0.0332 - val_loss: 0.0092 - val_mae: 0.0637\n",
      "Epoch 39/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0025 - mae: 0.0333 - val_loss: 0.0093 - val_mae: 0.0639\n",
      "Epoch 40/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0025 - mae: 0.0332 - val_loss: 0.0101 - val_mae: 0.0660\n",
      "Epoch 41/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0026 - mae: 0.0332 - val_loss: 0.0098 - val_mae: 0.0652\n",
      "Epoch 42/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 0.0026 - mae: 0.0333 - val_loss: 0.0101 - val_mae: 0.0657\n",
      "Epoch 43/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 0.0025 - mae: 0.0332 - val_loss: 0.0100 - val_mae: 0.0654\n",
      "Epoch 44/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0025 - mae: 0.0333 - val_loss: 0.0094 - val_mae: 0.0644\n",
      "Epoch 45/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0025 - mae: 0.0333 - val_loss: 0.0105 - val_mae: 0.0665\n",
      "Epoch 46/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0025 - mae: 0.0332 - val_loss: 0.0102 - val_mae: 0.0661\n",
      "Epoch 47/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0026 - mae: 0.0333 - val_loss: 0.0094 - val_mae: 0.0653\n",
      "Epoch 48/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0025 - mae: 0.0333 - val_loss: 0.0096 - val_mae: 0.0650\n",
      "Epoch 49/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 0.0026 - mae: 0.0333 - val_loss: 0.0105 - val_mae: 0.0665\n",
      "Epoch 50/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 0.0026 - mae: 0.0332 - val_loss: 0.0098 - val_mae: 0.0655\n",
      "Epoch 51/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 0.0026 - mae: 0.0333 - val_loss: 0.0104 - val_mae: 0.0663\n",
      "Epoch 52/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 0.0025 - mae: 0.0332 - val_loss: 0.0103 - val_mae: 0.0659\n",
      "Epoch 53/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0025 - mae: 0.0332 - val_loss: 0.0099 - val_mae: 0.0653\n",
      "Epoch 54/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 0.0025 - mae: 0.0334 - val_loss: 0.0108 - val_mae: 0.0676\n",
      "Epoch 55/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 0.0025 - mae: 0.0333 - val_loss: 0.0097 - val_mae: 0.0650\n",
      "Epoch 56/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 0.0025 - mae: 0.0332 - val_loss: 0.0099 - val_mae: 0.0651\n",
      "Epoch 57/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 0.0025 - mae: 0.0332 - val_loss: 0.0094 - val_mae: 0.0665\n",
      "Epoch 58/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0025 - mae: 0.0332 - val_loss: 0.0100 - val_mae: 0.0662\n",
      "Epoch 59/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - loss: 0.0026 - mae: 0.0333 - val_loss: 0.0103 - val_mae: 0.0661\n",
      "Epoch 60/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 0.0026 - mae: 0.0333 - val_loss: 0.0099 - val_mae: 0.0653\n",
      "Epoch 61/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0025 - mae: 0.0332 - val_loss: 0.0098 - val_mae: 0.0650\n",
      "Epoch 62/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 0.0025 - mae: 0.0332 - val_loss: 0.0103 - val_mae: 0.0662\n",
      "Epoch 63/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 0.0025 - mae: 0.0331 - val_loss: 0.0102 - val_mae: 0.0658\n",
      "Epoch 64/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0025 - mae: 0.0333 - val_loss: 0.0106 - val_mae: 0.0668\n",
      "Epoch 65/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 0.0025 - mae: 0.0331 - val_loss: 0.0096 - val_mae: 0.0649\n",
      "Epoch 66/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0025 - mae: 0.0332 - val_loss: 0.0096 - val_mae: 0.0652\n",
      "Epoch 67/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0025 - mae: 0.0332 - val_loss: 0.0098 - val_mae: 0.0648\n",
      "Epoch 68/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0025 - mae: 0.0331 - val_loss: 0.0098 - val_mae: 0.0650\n",
      "Epoch 69/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0025 - mae: 0.0332 - val_loss: 0.0099 - val_mae: 0.0651\n",
      "Epoch 70/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0025 - mae: 0.0331 - val_loss: 0.0099 - val_mae: 0.0653\n",
      "Epoch 71/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0025 - mae: 0.0332 - val_loss: 0.0102 - val_mae: 0.0658\n",
      "Epoch 72/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 0.0025 - mae: 0.0332 - val_loss: 0.0100 - val_mae: 0.0653\n",
      "Epoch 73/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 0.0025 - mae: 0.0332 - val_loss: 0.0111 - val_mae: 0.0683\n",
      "Epoch 74/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0025 - mae: 0.0333 - val_loss: 0.0099 - val_mae: 0.0654\n",
      "Epoch 75/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0025 - mae: 0.0331 - val_loss: 0.0103 - val_mae: 0.0660\n",
      "Epoch 76/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0025 - mae: 0.0332 - val_loss: 0.0103 - val_mae: 0.0663\n",
      "Epoch 77/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0025 - mae: 0.0332 - val_loss: 0.0105 - val_mae: 0.0664\n",
      "Epoch 78/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0025 - mae: 0.0331 - val_loss: 0.0105 - val_mae: 0.0667\n",
      "Epoch 79/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0025 - mae: 0.0331 - val_loss: 0.0100 - val_mae: 0.0654\n",
      "Epoch 80/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 0.0025 - mae: 0.0331 - val_loss: 0.0099 - val_mae: 0.0651\n",
      "Epoch 81/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 0.0025 - mae: 0.0332 - val_loss: 0.0094 - val_mae: 0.0648\n",
      "Epoch 82/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0025 - mae: 0.0331 - val_loss: 0.0102 - val_mae: 0.0659\n",
      "Epoch 83/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 0.0025 - mae: 0.0332 - val_loss: 0.0097 - val_mae: 0.0653\n",
      "Epoch 84/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0025 - mae: 0.0332 - val_loss: 0.0096 - val_mae: 0.0645\n",
      "Epoch 85/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0025 - mae: 0.0332 - val_loss: 0.0100 - val_mae: 0.0655\n",
      "Epoch 86/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0025 - mae: 0.0331 - val_loss: 0.0097 - val_mae: 0.0650\n",
      "Epoch 87/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0025 - mae: 0.0332 - val_loss: 0.0104 - val_mae: 0.0664\n",
      "Epoch 88/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - loss: 0.0025 - mae: 0.0332 - val_loss: 0.0106 - val_mae: 0.0669\n",
      "Epoch 89/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0025 - mae: 0.0331 - val_loss: 0.0098 - val_mae: 0.0654\n",
      "Epoch 90/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - loss: 0.0025 - mae: 0.0332 - val_loss: 0.0103 - val_mae: 0.0661\n",
      "Epoch 91/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0025 - mae: 0.0331 - val_loss: 0.0096 - val_mae: 0.0646\n",
      "Epoch 92/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 0.0025 - mae: 0.0332 - val_loss: 0.0106 - val_mae: 0.0670\n",
      "Epoch 93/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0025 - mae: 0.0331 - val_loss: 0.0102 - val_mae: 0.0660\n",
      "Epoch 94/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0025 - mae: 0.0332 - val_loss: 0.0105 - val_mae: 0.0667\n",
      "Epoch 95/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 0.0025 - mae: 0.0332 - val_loss: 0.0102 - val_mae: 0.0664\n",
      "Epoch 96/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 0.0025 - mae: 0.0331 - val_loss: 0.0102 - val_mae: 0.0660\n",
      "Epoch 97/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0025 - mae: 0.0332 - val_loss: 0.0098 - val_mae: 0.0651\n",
      "Epoch 98/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 0.0025 - mae: 0.0332 - val_loss: 0.0096 - val_mae: 0.0647\n",
      "Epoch 99/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 0.0025 - mae: 0.0331 - val_loss: 0.0099 - val_mae: 0.0653\n",
      "Epoch 100/100\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - loss: 0.0025 - mae: 0.0332 - val_loss: 0.0099 - val_mae: 0.0655\n",
      "\u001b[1m728/728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step\n",
      "✅ Done: tomato_Chikmagalur_daily.csv | MAE=447.09, RMSE=702.78, R2=0.45, MAPE=60.26%, Accuracy=39.74%\n",
      "🚀 Processing: tomato_Chitradurga_daily.csv\n",
      "Epoch 1/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 0.0744 - mae: 0.1827 - val_loss: 0.0128 - val_mae: 0.1134\n",
      "Epoch 2/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0219 - mae: 0.1156 - val_loss: 0.0079 - val_mae: 0.0889\n",
      "Epoch 3/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0142 - mae: 0.0929 - val_loss: 0.0080 - val_mae: 0.0894\n",
      "Epoch 4/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0088 - mae: 0.0720 - val_loss: 8.8959e-04 - val_mae: 0.0298\n",
      "Epoch 5/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0042 - mae: 0.0477 - val_loss: 3.6200e-04 - val_mae: 0.0190\n",
      "Epoch 6/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0026 - mae: 0.0360 - val_loss: 1.6156e-07 - val_mae: 4.0194e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0021 - mae: 0.0320 - val_loss: 1.0264e-04 - val_mae: 0.0101\n",
      "Epoch 8/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0260 - val_loss: 8.7508e-05 - val_mae: 0.0094\n",
      "Epoch 9/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0014 - mae: 0.0257 - val_loss: 2.1806e-04 - val_mae: 0.0148\n",
      "Epoch 10/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0012 - mae: 0.0238 - val_loss: 1.0645e-04 - val_mae: 0.0103\n",
      "Epoch 11/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0011 - mae: 0.0224 - val_loss: 1.6537e-04 - val_mae: 0.0129\n",
      "Epoch 12/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 8.7523e-04 - mae: 0.0197 - val_loss: 2.1460e-04 - val_mae: 0.0146\n",
      "Epoch 13/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0010 - mae: 0.0213 - val_loss: 8.6170e-06 - val_mae: 0.0029\n",
      "Epoch 14/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 8.7588e-04 - mae: 0.0204 - val_loss: 7.1796e-05 - val_mae: 0.0085\n",
      "Epoch 15/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 9.0586e-04 - mae: 0.0206 - val_loss: 3.6647e-06 - val_mae: 0.0019\n",
      "Epoch 16/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0011 - mae: 0.0224 - val_loss: 8.7802e-04 - val_mae: 0.0296\n",
      "Epoch 17/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 9.0105e-04 - mae: 0.0198 - val_loss: 8.2840e-04 - val_mae: 0.0288\n",
      "Epoch 18/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 8.6154e-04 - mae: 0.0203 - val_loss: 5.7912e-05 - val_mae: 0.0076\n",
      "Epoch 19/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 7.8643e-04 - mae: 0.0194 - val_loss: 2.7326e-05 - val_mae: 0.0052\n",
      "Epoch 20/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 8.2652e-04 - mae: 0.0193 - val_loss: 2.5756e-04 - val_mae: 0.0160\n",
      "Epoch 21/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 9.2867e-04 - mae: 0.0208 - val_loss: 1.5368e-05 - val_mae: 0.0039\n",
      "Epoch 22/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0010 - mae: 0.0217 - val_loss: 6.8047e-05 - val_mae: 0.0082\n",
      "Epoch 23/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 8.0489e-04 - mae: 0.0191 - val_loss: 4.8266e-04 - val_mae: 0.0220\n",
      "Epoch 24/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 8.4526e-04 - mae: 0.0201 - val_loss: 0.0013 - val_mae: 0.0363\n",
      "Epoch 25/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 8.1885e-04 - mae: 0.0194 - val_loss: 2.8855e-04 - val_mae: 0.0170\n",
      "Epoch 26/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 7.1132e-04 - mae: 0.0178 - val_loss: 3.4962e-05 - val_mae: 0.0059\n",
      "Epoch 27/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 7.7362e-04 - mae: 0.0187 - val_loss: 5.4654e-04 - val_mae: 0.0234\n",
      "Epoch 28/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 6.4969e-04 - mae: 0.0166 - val_loss: 1.0911e-04 - val_mae: 0.0104\n",
      "Epoch 29/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 7.0972e-04 - mae: 0.0177 - val_loss: 3.3248e-05 - val_mae: 0.0058\n",
      "Epoch 30/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 8.0523e-04 - mae: 0.0199 - val_loss: 1.1195e-05 - val_mae: 0.0033\n",
      "Epoch 31/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 7.6402e-04 - mae: 0.0191 - val_loss: 7.3986e-05 - val_mae: 0.0086\n",
      "Epoch 32/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 7.9058e-04 - mae: 0.0184 - val_loss: 1.4802e-04 - val_mae: 0.0122\n",
      "Epoch 33/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 7.1995e-04 - mae: 0.0182 - val_loss: 4.2686e-05 - val_mae: 0.0065\n",
      "Epoch 34/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 6.4821e-04 - mae: 0.0168 - val_loss: 8.3935e-05 - val_mae: 0.0092\n",
      "Epoch 35/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 6.8176e-04 - mae: 0.0177 - val_loss: 9.1041e-04 - val_mae: 0.0302\n",
      "Epoch 36/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 6.9326e-04 - mae: 0.0184 - val_loss: 1.0576e-04 - val_mae: 0.0103\n",
      "Epoch 37/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 6.6726e-04 - mae: 0.0173 - val_loss: 1.6640e-04 - val_mae: 0.0129\n",
      "Epoch 38/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 6.8077e-04 - mae: 0.0179 - val_loss: 1.3251e-05 - val_mae: 0.0036\n",
      "Epoch 39/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 6.2751e-04 - mae: 0.0168 - val_loss: 2.1790e-05 - val_mae: 0.0047\n",
      "Epoch 40/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 6.3997e-04 - mae: 0.0168 - val_loss: 1.4699e-04 - val_mae: 0.0121\n",
      "Epoch 41/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 7.0837e-04 - mae: 0.0185 - val_loss: 2.0317e-07 - val_mae: 4.5075e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 6.1057e-04 - mae: 0.0163 - val_loss: 1.3446e-04 - val_mae: 0.0116\n",
      "Epoch 43/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 5.9026e-04 - mae: 0.0156 - val_loss: 4.6136e-05 - val_mae: 0.0068\n",
      "Epoch 44/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 6.2509e-04 - mae: 0.0164 - val_loss: 9.5708e-05 - val_mae: 0.0098\n",
      "Epoch 45/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 5.6951e-04 - mae: 0.0152 - val_loss: 9.8418e-06 - val_mae: 0.0031\n",
      "Epoch 46/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 6.0763e-04 - mae: 0.0162 - val_loss: 3.2632e-04 - val_mae: 0.0181\n",
      "Epoch 47/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 6.3416e-04 - mae: 0.0165 - val_loss: 1.2762e-04 - val_mae: 0.0113\n",
      "Epoch 48/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 5.8237e-04 - mae: 0.0162 - val_loss: 1.1306e-04 - val_mae: 0.0106\n",
      "Epoch 49/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 5.7743e-04 - mae: 0.0159 - val_loss: 1.7341e-04 - val_mae: 0.0132\n",
      "Epoch 50/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 6.0283e-04 - mae: 0.0163 - val_loss: 2.3713e-04 - val_mae: 0.0154\n",
      "Epoch 51/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 5.6870e-04 - mae: 0.0158 - val_loss: 1.8072e-06 - val_mae: 0.0013\n",
      "Epoch 52/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 5.9712e-04 - mae: 0.0166 - val_loss: 0.0012 - val_mae: 0.0341\n",
      "Epoch 53/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 6.0739e-04 - mae: 0.0164 - val_loss: 6.4808e-06 - val_mae: 0.0025\n",
      "Epoch 54/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 5.6881e-04 - mae: 0.0160 - val_loss: 6.5780e-04 - val_mae: 0.0256\n",
      "Epoch 55/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 6.5508e-04 - mae: 0.0181 - val_loss: 4.8109e-04 - val_mae: 0.0219\n",
      "Epoch 56/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 5.8537e-04 - mae: 0.0159 - val_loss: 5.0267e-05 - val_mae: 0.0071\n",
      "Epoch 57/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 6.3313e-04 - mae: 0.0175 - val_loss: 7.2908e-04 - val_mae: 0.0270\n",
      "Epoch 58/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 5.4650e-04 - mae: 0.0154 - val_loss: 2.4900e-05 - val_mae: 0.0050\n",
      "Epoch 59/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 6.3482e-04 - mae: 0.0175 - val_loss: 1.6043e-05 - val_mae: 0.0040\n",
      "Epoch 60/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 5.0924e-04 - mae: 0.0145 - val_loss: 4.4373e-06 - val_mae: 0.0021\n",
      "Epoch 61/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 6.3690e-04 - mae: 0.0171 - val_loss: 6.8905e-04 - val_mae: 0.0262\n",
      "Epoch 62/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 5.7947e-04 - mae: 0.0163 - val_loss: 5.2427e-04 - val_mae: 0.0229\n",
      "Epoch 63/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 5.5491e-04 - mae: 0.0159 - val_loss: 1.7508e-07 - val_mae: 4.1842e-04\n",
      "Epoch 64/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 5.9558e-04 - mae: 0.0164 - val_loss: 0.0016 - val_mae: 0.0395\n",
      "Epoch 65/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 5.7131e-04 - mae: 0.0162 - val_loss: 4.3422e-05 - val_mae: 0.0066\n",
      "Epoch 66/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 5.1201e-04 - mae: 0.0146 - val_loss: 3.1446e-04 - val_mae: 0.0177\n",
      "Epoch 67/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 5.6946e-04 - mae: 0.0160 - val_loss: 9.5996e-05 - val_mae: 0.0098\n",
      "Epoch 68/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 5.4178e-04 - mae: 0.0154 - val_loss: 3.7585e-07 - val_mae: 6.1306e-04\n",
      "Epoch 69/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 5.6883e-04 - mae: 0.0160 - val_loss: 3.1930e-05 - val_mae: 0.0057\n",
      "Epoch 70/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 5.6023e-04 - mae: 0.0158 - val_loss: 2.3970e-04 - val_mae: 0.0155\n",
      "Epoch 71/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 5.3797e-04 - mae: 0.0151 - val_loss: 3.3488e-04 - val_mae: 0.0183\n",
      "Epoch 72/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 5.4002e-04 - mae: 0.0157 - val_loss: 3.7046e-06 - val_mae: 0.0019\n",
      "Epoch 73/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 5.1696e-04 - mae: 0.0148 - val_loss: 8.6892e-05 - val_mae: 0.0093\n",
      "Epoch 74/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 5.1805e-04 - mae: 0.0146 - val_loss: 9.6596e-05 - val_mae: 0.0098\n",
      "Epoch 75/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 5.8716e-04 - mae: 0.0162 - val_loss: 1.5599e-04 - val_mae: 0.0125\n",
      "Epoch 76/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 5.6114e-04 - mae: 0.0158 - val_loss: 3.0119e-06 - val_mae: 0.0017\n",
      "Epoch 77/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 5.1699e-04 - mae: 0.0145 - val_loss: 1.9529e-04 - val_mae: 0.0140\n",
      "Epoch 78/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 5.3775e-04 - mae: 0.0152 - val_loss: 2.4146e-08 - val_mae: 1.5539e-04\n",
      "Epoch 79/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 5.9900e-04 - mae: 0.0158 - val_loss: 2.7018e-05 - val_mae: 0.0052\n",
      "Epoch 80/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 5.9862e-04 - mae: 0.0161 - val_loss: 4.6844e-04 - val_mae: 0.0216\n",
      "Epoch 81/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 5.1625e-04 - mae: 0.0151 - val_loss: 7.5575e-04 - val_mae: 0.0275\n",
      "Epoch 82/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 5.2944e-04 - mae: 0.0150 - val_loss: 4.8333e-04 - val_mae: 0.0220\n",
      "Epoch 83/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 5.7946e-04 - mae: 0.0162 - val_loss: 8.6989e-04 - val_mae: 0.0295\n",
      "Epoch 84/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 5.8274e-04 - mae: 0.0165 - val_loss: 7.4706e-04 - val_mae: 0.0273\n",
      "Epoch 85/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 5.2179e-04 - mae: 0.0150 - val_loss: 8.0285e-04 - val_mae: 0.0283\n",
      "Epoch 86/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 4.9506e-04 - mae: 0.0147 - val_loss: 2.4123e-04 - val_mae: 0.0155\n",
      "Epoch 87/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 5.1968e-04 - mae: 0.0149 - val_loss: 4.2463e-04 - val_mae: 0.0206\n",
      "Epoch 88/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 5.2163e-04 - mae: 0.0152 - val_loss: 7.3340e-06 - val_mae: 0.0027\n",
      "Epoch 89/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 5.3794e-04 - mae: 0.0152 - val_loss: 9.2116e-05 - val_mae: 0.0096\n",
      "Epoch 90/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 4.9791e-04 - mae: 0.0146 - val_loss: 9.6719e-05 - val_mae: 0.0098\n",
      "Epoch 91/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 6.5285e-04 - mae: 0.0163 - val_loss: 1.9677e-04 - val_mae: 0.0140\n",
      "Epoch 92/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 5.1060e-04 - mae: 0.0144 - val_loss: 4.3045e-04 - val_mae: 0.0207\n",
      "Epoch 93/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 5.4563e-04 - mae: 0.0149 - val_loss: 7.2046e-06 - val_mae: 0.0027\n",
      "Epoch 94/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 4.7370e-04 - mae: 0.0136 - val_loss: 3.3410e-05 - val_mae: 0.0058\n",
      "Epoch 95/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 5.1958e-04 - mae: 0.0149 - val_loss: 4.9326e-04 - val_mae: 0.0222\n",
      "Epoch 96/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 5.1057e-04 - mae: 0.0150 - val_loss: 1.6840e-04 - val_mae: 0.0130\n",
      "Epoch 97/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 5.2166e-04 - mae: 0.0147 - val_loss: 6.7343e-05 - val_mae: 0.0082\n",
      "Epoch 98/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 4.8688e-04 - mae: 0.0143 - val_loss: 2.9394e-04 - val_mae: 0.0171\n",
      "Epoch 99/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 5.0908e-04 - mae: 0.0145 - val_loss: 5.7653e-04 - val_mae: 0.0240\n",
      "Epoch 100/100\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 5.2501e-04 - mae: 0.0150 - val_loss: 2.6149e-05 - val_mae: 0.0051\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step   \n",
      "✅ Done: tomato_Chitradurga_daily.csv | MAE=75.06, RMSE=146.29, R2=0.98, MAPE=5.78%, Accuracy=94.22%\n",
      "🚀 Processing: tomato_Davangere_daily.csv\n",
      "Epoch 1/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - loss: 0.0299 - mae: 0.1002 - val_loss: 0.0187 - val_mae: 0.0784\n",
      "Epoch 2/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0073 - mae: 0.0653 - val_loss: 0.0176 - val_mae: 0.0780\n",
      "Epoch 3/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0058 - mae: 0.0576 - val_loss: 0.0170 - val_mae: 0.0805\n",
      "Epoch 4/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0050 - mae: 0.0525 - val_loss: 0.0170 - val_mae: 0.0839\n",
      "Epoch 5/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0048 - mae: 0.0522 - val_loss: 0.0154 - val_mae: 0.0758\n",
      "Epoch 6/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0042 - mae: 0.0476 - val_loss: 0.0155 - val_mae: 0.0737\n",
      "Epoch 7/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0040 - mae: 0.0463 - val_loss: 0.0127 - val_mae: 0.0686\n",
      "Epoch 8/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0039 - mae: 0.0461 - val_loss: 0.0120 - val_mae: 0.0656\n",
      "Epoch 9/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0039 - mae: 0.0465 - val_loss: 0.0130 - val_mae: 0.0690\n",
      "Epoch 10/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0038 - mae: 0.0452 - val_loss: 0.0119 - val_mae: 0.0815\n",
      "Epoch 11/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0037 - mae: 0.0446 - val_loss: 0.0102 - val_mae: 0.0671\n",
      "Epoch 12/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0036 - mae: 0.0443 - val_loss: 0.0129 - val_mae: 0.0727\n",
      "Epoch 13/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0037 - mae: 0.0443 - val_loss: 0.0100 - val_mae: 0.0625\n",
      "Epoch 14/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0036 - mae: 0.0436 - val_loss: 0.0099 - val_mae: 0.0637\n",
      "Epoch 15/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0036 - mae: 0.0440 - val_loss: 0.0121 - val_mae: 0.0812\n",
      "Epoch 16/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0037 - mae: 0.0449 - val_loss: 0.0098 - val_mae: 0.0618\n",
      "Epoch 17/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0036 - mae: 0.0434 - val_loss: 0.0098 - val_mae: 0.0613\n",
      "Epoch 18/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0036 - mae: 0.0430 - val_loss: 0.0098 - val_mae: 0.0614\n",
      "Epoch 19/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0036 - mae: 0.0433 - val_loss: 0.0098 - val_mae: 0.0630\n",
      "Epoch 20/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0035 - mae: 0.0425 - val_loss: 0.0100 - val_mae: 0.0628\n",
      "Epoch 21/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0037 - mae: 0.0444 - val_loss: 0.0097 - val_mae: 0.0616\n",
      "Epoch 22/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0036 - mae: 0.0432 - val_loss: 0.0100 - val_mae: 0.0664\n",
      "Epoch 23/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0035 - mae: 0.0431 - val_loss: 0.0097 - val_mae: 0.0618\n",
      "Epoch 24/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0035 - mae: 0.0426 - val_loss: 0.0098 - val_mae: 0.0629\n",
      "Epoch 25/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0036 - mae: 0.0437 - val_loss: 0.0100 - val_mae: 0.0625\n",
      "Epoch 26/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0036 - mae: 0.0434 - val_loss: 0.0099 - val_mae: 0.0676\n",
      "Epoch 27/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0035 - mae: 0.0424 - val_loss: 0.0100 - val_mae: 0.0627\n",
      "Epoch 28/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0035 - mae: 0.0426 - val_loss: 0.0106 - val_mae: 0.0680\n",
      "Epoch 29/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0035 - mae: 0.0430 - val_loss: 0.0097 - val_mae: 0.0641\n",
      "Epoch 30/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0035 - mae: 0.0430 - val_loss: 0.0106 - val_mae: 0.0681\n",
      "Epoch 31/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0035 - mae: 0.0423 - val_loss: 0.0097 - val_mae: 0.0639\n",
      "Epoch 32/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0035 - mae: 0.0423 - val_loss: 0.0102 - val_mae: 0.0672\n",
      "Epoch 33/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0035 - mae: 0.0426 - val_loss: 0.0099 - val_mae: 0.0624\n",
      "Epoch 34/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0035 - mae: 0.0427 - val_loss: 0.0100 - val_mae: 0.0643\n",
      "Epoch 35/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0034 - mae: 0.0422 - val_loss: 0.0099 - val_mae: 0.0684\n",
      "Epoch 36/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0034 - mae: 0.0422 - val_loss: 0.0108 - val_mae: 0.0761\n",
      "Epoch 37/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0035 - mae: 0.0423 - val_loss: 0.0096 - val_mae: 0.0626\n",
      "Epoch 38/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0035 - mae: 0.0424 - val_loss: 0.0097 - val_mae: 0.0632\n",
      "Epoch 39/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0034 - mae: 0.0423 - val_loss: 0.0096 - val_mae: 0.0627\n",
      "Epoch 40/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0034 - mae: 0.0421 - val_loss: 0.0100 - val_mae: 0.0621\n",
      "Epoch 41/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0035 - mae: 0.0424 - val_loss: 0.0104 - val_mae: 0.0710\n",
      "Epoch 42/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0034 - mae: 0.0422 - val_loss: 0.0098 - val_mae: 0.0652\n",
      "Epoch 43/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0034 - mae: 0.0420 - val_loss: 0.0104 - val_mae: 0.0692\n",
      "Epoch 44/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0034 - mae: 0.0420 - val_loss: 0.0102 - val_mae: 0.0657\n",
      "Epoch 45/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0034 - mae: 0.0416 - val_loss: 0.0097 - val_mae: 0.0619\n",
      "Epoch 46/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0034 - mae: 0.0419 - val_loss: 0.0110 - val_mae: 0.0691\n",
      "Epoch 47/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0034 - mae: 0.0419 - val_loss: 0.0097 - val_mae: 0.0637\n",
      "Epoch 48/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0034 - mae: 0.0417 - val_loss: 0.0096 - val_mae: 0.0622\n",
      "Epoch 49/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0034 - mae: 0.0422 - val_loss: 0.0098 - val_mae: 0.0647\n",
      "Epoch 50/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0034 - mae: 0.0418 - val_loss: 0.0099 - val_mae: 0.0636\n",
      "Epoch 51/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0034 - mae: 0.0415 - val_loss: 0.0100 - val_mae: 0.0686\n",
      "Epoch 52/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0034 - mae: 0.0418 - val_loss: 0.0098 - val_mae: 0.0656\n",
      "Epoch 53/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0034 - mae: 0.0418 - val_loss: 0.0101 - val_mae: 0.0691\n",
      "Epoch 54/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0034 - mae: 0.0415 - val_loss: 0.0098 - val_mae: 0.0652\n",
      "Epoch 55/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0034 - mae: 0.0417 - val_loss: 0.0097 - val_mae: 0.0637\n",
      "Epoch 56/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0034 - mae: 0.0417 - val_loss: 0.0097 - val_mae: 0.0627\n",
      "Epoch 57/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0034 - mae: 0.0416 - val_loss: 0.0101 - val_mae: 0.0661\n",
      "Epoch 58/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0034 - mae: 0.0417 - val_loss: 0.0098 - val_mae: 0.0632\n",
      "Epoch 59/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0034 - mae: 0.0417 - val_loss: 0.0099 - val_mae: 0.0644\n",
      "Epoch 60/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0034 - mae: 0.0417 - val_loss: 0.0101 - val_mae: 0.0682\n",
      "Epoch 61/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0034 - mae: 0.0416 - val_loss: 0.0100 - val_mae: 0.0655\n",
      "Epoch 62/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0034 - mae: 0.0415 - val_loss: 0.0099 - val_mae: 0.0637\n",
      "Epoch 63/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0034 - mae: 0.0420 - val_loss: 0.0101 - val_mae: 0.0664\n",
      "Epoch 64/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0034 - mae: 0.0414 - val_loss: 0.0102 - val_mae: 0.0627\n",
      "Epoch 65/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0034 - mae: 0.0416 - val_loss: 0.0099 - val_mae: 0.0644\n",
      "Epoch 66/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0033 - mae: 0.0414 - val_loss: 0.0099 - val_mae: 0.0629\n",
      "Epoch 67/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0033 - mae: 0.0414 - val_loss: 0.0103 - val_mae: 0.0688\n",
      "Epoch 68/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0034 - mae: 0.0414 - val_loss: 0.0100 - val_mae: 0.0631\n",
      "Epoch 69/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0034 - mae: 0.0415 - val_loss: 0.0100 - val_mae: 0.0644\n",
      "Epoch 70/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0033 - mae: 0.0413 - val_loss: 0.0105 - val_mae: 0.0694\n",
      "Epoch 71/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0033 - mae: 0.0414 - val_loss: 0.0100 - val_mae: 0.0639\n",
      "Epoch 72/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0034 - mae: 0.0415 - val_loss: 0.0100 - val_mae: 0.0630\n",
      "Epoch 73/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0034 - mae: 0.0417 - val_loss: 0.0100 - val_mae: 0.0648\n",
      "Epoch 74/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0033 - mae: 0.0414 - val_loss: 0.0100 - val_mae: 0.0638\n",
      "Epoch 75/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0033 - mae: 0.0414 - val_loss: 0.0106 - val_mae: 0.0677\n",
      "Epoch 76/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0034 - mae: 0.0415 - val_loss: 0.0107 - val_mae: 0.0693\n",
      "Epoch 77/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0033 - mae: 0.0413 - val_loss: 0.0104 - val_mae: 0.0675\n",
      "Epoch 78/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0033 - mae: 0.0415 - val_loss: 0.0102 - val_mae: 0.0662\n",
      "Epoch 79/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0033 - mae: 0.0414 - val_loss: 0.0103 - val_mae: 0.0665\n",
      "Epoch 80/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0034 - mae: 0.0415 - val_loss: 0.0104 - val_mae: 0.0672\n",
      "Epoch 81/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0034 - mae: 0.0417 - val_loss: 0.0102 - val_mae: 0.0656\n",
      "Epoch 82/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0033 - mae: 0.0412 - val_loss: 0.0103 - val_mae: 0.0677\n",
      "Epoch 83/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0033 - mae: 0.0414 - val_loss: 0.0100 - val_mae: 0.0645\n",
      "Epoch 84/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0033 - mae: 0.0414 - val_loss: 0.0100 - val_mae: 0.0648\n",
      "Epoch 85/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0033 - mae: 0.0413 - val_loss: 0.0104 - val_mae: 0.0664\n",
      "Epoch 86/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0033 - mae: 0.0413 - val_loss: 0.0103 - val_mae: 0.0677\n",
      "Epoch 87/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0034 - mae: 0.0416 - val_loss: 0.0104 - val_mae: 0.0634\n",
      "Epoch 88/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0033 - mae: 0.0414 - val_loss: 0.0100 - val_mae: 0.0634\n",
      "Epoch 89/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0033 - mae: 0.0411 - val_loss: 0.0103 - val_mae: 0.0627\n",
      "Epoch 90/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0033 - mae: 0.0411 - val_loss: 0.0101 - val_mae: 0.0636\n",
      "Epoch 91/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0033 - mae: 0.0413 - val_loss: 0.0105 - val_mae: 0.0638\n",
      "Epoch 92/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0033 - mae: 0.0413 - val_loss: 0.0103 - val_mae: 0.0665\n",
      "Epoch 93/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0033 - mae: 0.0413 - val_loss: 0.0100 - val_mae: 0.0639\n",
      "Epoch 94/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0033 - mae: 0.0412 - val_loss: 0.0101 - val_mae: 0.0631\n",
      "Epoch 95/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0033 - mae: 0.0414 - val_loss: 0.0102 - val_mae: 0.0651\n",
      "Epoch 96/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0033 - mae: 0.0411 - val_loss: 0.0100 - val_mae: 0.0640\n",
      "Epoch 97/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0033 - mae: 0.0412 - val_loss: 0.0101 - val_mae: 0.0639\n",
      "Epoch 98/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0033 - mae: 0.0413 - val_loss: 0.0104 - val_mae: 0.0687\n",
      "Epoch 99/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0033 - mae: 0.0414 - val_loss: 0.0100 - val_mae: 0.0642\n",
      "Epoch 100/100\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0033 - mae: 0.0412 - val_loss: 0.0105 - val_mae: 0.0670\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n",
      "✅ Done: tomato_Davangere_daily.csv | MAE=382.88, RMSE=568.64, R2=0.63, MAPE=49.93%, Accuracy=50.07%\n",
      "🚀 Processing: tomato_Dharwad_daily.csv\n",
      "Epoch 1/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 0.3085 - mae: 0.3411 - val_loss: 0.0412 - val_mae: 0.0777\n",
      "Epoch 2/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0112 - mae: 0.0826 - val_loss: 0.0380 - val_mae: 0.0924\n",
      "Epoch 3/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0094 - mae: 0.0757 - val_loss: 0.0366 - val_mae: 0.1332\n",
      "Epoch 4/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0092 - mae: 0.0743 - val_loss: 0.0377 - val_mae: 0.1170\n",
      "Epoch 5/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0087 - mae: 0.0712 - val_loss: 0.0391 - val_mae: 0.0803\n",
      "Epoch 6/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0082 - mae: 0.0693 - val_loss: 0.0369 - val_mae: 0.1147\n",
      "Epoch 7/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0071 - mae: 0.0635 - val_loss: 0.0371 - val_mae: 0.1024\n",
      "Epoch 8/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0071 - mae: 0.0641 - val_loss: 0.0359 - val_mae: 0.1138\n",
      "Epoch 9/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0066 - mae: 0.0607 - val_loss: 0.0367 - val_mae: 0.1084\n",
      "Epoch 10/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0057 - mae: 0.0551 - val_loss: 0.0364 - val_mae: 0.1102\n",
      "Epoch 11/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0054 - mae: 0.0526 - val_loss: 0.0379 - val_mae: 0.0892\n",
      "Epoch 12/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0048 - mae: 0.0506 - val_loss: 0.0373 - val_mae: 0.1009\n",
      "Epoch 13/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0045 - mae: 0.0484 - val_loss: 0.0380 - val_mae: 0.0922\n",
      "Epoch 14/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0047 - mae: 0.0479 - val_loss: 0.0381 - val_mae: 0.0894\n",
      "Epoch 15/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0045 - mae: 0.0469 - val_loss: 0.0386 - val_mae: 0.0905\n",
      "Epoch 16/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0044 - mae: 0.0460 - val_loss: 0.0363 - val_mae: 0.1181\n",
      "Epoch 17/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0043 - mae: 0.0445 - val_loss: 0.0374 - val_mae: 0.1066\n",
      "Epoch 18/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0044 - mae: 0.0446 - val_loss: 0.0387 - val_mae: 0.0872\n",
      "Epoch 19/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0040 - mae: 0.0425 - val_loss: 0.0390 - val_mae: 0.0834\n",
      "Epoch 20/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0037 - mae: 0.0405 - val_loss: 0.0378 - val_mae: 0.0947\n",
      "Epoch 21/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0039 - mae: 0.0403 - val_loss: 0.0384 - val_mae: 0.0886\n",
      "Epoch 22/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0039 - mae: 0.0398 - val_loss: 0.0367 - val_mae: 0.1160\n",
      "Epoch 23/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0040 - mae: 0.0430 - val_loss: 0.0384 - val_mae: 0.0863\n",
      "Epoch 24/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0036 - mae: 0.0386 - val_loss: 0.0378 - val_mae: 0.0953\n",
      "Epoch 25/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0036 - mae: 0.0385 - val_loss: 0.0383 - val_mae: 0.0926\n",
      "Epoch 26/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0037 - mae: 0.0384 - val_loss: 0.0394 - val_mae: 0.0858\n",
      "Epoch 27/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0037 - mae: 0.0384 - val_loss: 0.0401 - val_mae: 0.0825\n",
      "Epoch 28/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0035 - mae: 0.0358 - val_loss: 0.0368 - val_mae: 0.1059\n",
      "Epoch 29/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0036 - mae: 0.0372 - val_loss: 0.0381 - val_mae: 0.0939\n",
      "Epoch 30/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0033 - mae: 0.0353 - val_loss: 0.0392 - val_mae: 0.0813\n",
      "Epoch 31/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0035 - mae: 0.0363 - val_loss: 0.0402 - val_mae: 0.0743\n",
      "Epoch 32/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0033 - mae: 0.0352 - val_loss: 0.0382 - val_mae: 0.0936\n",
      "Epoch 33/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0033 - mae: 0.0332 - val_loss: 0.0363 - val_mae: 0.1104\n",
      "Epoch 34/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0037 - mae: 0.0376 - val_loss: 0.0412 - val_mae: 0.0739\n",
      "Epoch 35/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0032 - mae: 0.0330 - val_loss: 0.0367 - val_mae: 0.1043\n",
      "Epoch 36/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0034 - mae: 0.0346 - val_loss: 0.0372 - val_mae: 0.1095\n",
      "Epoch 37/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0033 - mae: 0.0353 - val_loss: 0.0375 - val_mae: 0.0960\n",
      "Epoch 38/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0034 - mae: 0.0340 - val_loss: 0.0386 - val_mae: 0.0892\n",
      "Epoch 39/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0032 - mae: 0.0318 - val_loss: 0.0394 - val_mae: 0.0850\n",
      "Epoch 40/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0032 - mae: 0.0322 - val_loss: 0.0367 - val_mae: 0.1020\n",
      "Epoch 41/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0035 - mae: 0.0385 - val_loss: 0.0372 - val_mae: 0.1049\n",
      "Epoch 42/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0033 - mae: 0.0364 - val_loss: 0.0377 - val_mae: 0.1008\n",
      "Epoch 43/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0030 - mae: 0.0297 - val_loss: 0.0384 - val_mae: 0.0942\n",
      "Epoch 44/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0032 - mae: 0.0309 - val_loss: 0.0402 - val_mae: 0.0820\n",
      "Epoch 45/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0031 - mae: 0.0312 - val_loss: 0.0396 - val_mae: 0.0826\n",
      "Epoch 46/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0032 - mae: 0.0310 - val_loss: 0.0397 - val_mae: 0.0844\n",
      "Epoch 47/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0031 - mae: 0.0310 - val_loss: 0.0392 - val_mae: 0.0843\n",
      "Epoch 48/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0033 - mae: 0.0342 - val_loss: 0.0368 - val_mae: 0.1032\n",
      "Epoch 49/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0032 - mae: 0.0313 - val_loss: 0.0374 - val_mae: 0.0978\n",
      "Epoch 50/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0030 - mae: 0.0304 - val_loss: 0.0407 - val_mae: 0.0778\n",
      "Epoch 51/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0030 - mae: 0.0306 - val_loss: 0.0367 - val_mae: 0.1008\n",
      "Epoch 52/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0032 - mae: 0.0347 - val_loss: 0.0397 - val_mae: 0.0805\n",
      "Epoch 53/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0030 - mae: 0.0287 - val_loss: 0.0396 - val_mae: 0.0830\n",
      "Epoch 54/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0031 - mae: 0.0300 - val_loss: 0.0366 - val_mae: 0.1074\n",
      "Epoch 55/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0033 - mae: 0.0349 - val_loss: 0.0369 - val_mae: 0.1045\n",
      "Epoch 56/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0030 - mae: 0.0288 - val_loss: 0.0386 - val_mae: 0.0887\n",
      "Epoch 57/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0031 - mae: 0.0306 - val_loss: 0.0407 - val_mae: 0.0748\n",
      "Epoch 58/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0033 - mae: 0.0342 - val_loss: 0.0369 - val_mae: 0.1088\n",
      "Epoch 59/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0031 - mae: 0.0302 - val_loss: 0.0376 - val_mae: 0.1006\n",
      "Epoch 60/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0032 - mae: 0.0315 - val_loss: 0.0401 - val_mae: 0.0787\n",
      "Epoch 61/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0031 - mae: 0.0291 - val_loss: 0.0388 - val_mae: 0.0868\n",
      "Epoch 62/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0033 - mae: 0.0348 - val_loss: 0.0379 - val_mae: 0.0955\n",
      "Epoch 63/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0031 - mae: 0.0291 - val_loss: 0.0397 - val_mae: 0.0793\n",
      "Epoch 64/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0032 - mae: 0.0315 - val_loss: 0.0385 - val_mae: 0.0928\n",
      "Epoch 65/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0033 - mae: 0.0322 - val_loss: 0.0421 - val_mae: 0.0773\n",
      "Epoch 66/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0033 - mae: 0.0339 - val_loss: 0.0366 - val_mae: 0.1186\n",
      "Epoch 67/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0034 - mae: 0.0365 - val_loss: 0.0389 - val_mae: 0.0865\n",
      "Epoch 68/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0031 - mae: 0.0318 - val_loss: 0.0397 - val_mae: 0.0810\n",
      "Epoch 69/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0030 - mae: 0.0285 - val_loss: 0.0384 - val_mae: 0.0901\n",
      "Epoch 70/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0032 - mae: 0.0319 - val_loss: 0.0361 - val_mae: 0.1167\n",
      "Epoch 71/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0033 - mae: 0.0311 - val_loss: 0.0379 - val_mae: 0.0907\n",
      "Epoch 72/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0033 - mae: 0.0356 - val_loss: 0.0438 - val_mae: 0.0854\n",
      "Epoch 73/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0030 - mae: 0.0289 - val_loss: 0.0370 - val_mae: 0.0994\n",
      "Epoch 74/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0030 - mae: 0.0283 - val_loss: 0.0384 - val_mae: 0.0879\n",
      "Epoch 75/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0030 - mae: 0.0289 - val_loss: 0.0384 - val_mae: 0.0923\n",
      "Epoch 76/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0033 - mae: 0.0323 - val_loss: 0.0380 - val_mae: 0.0944\n",
      "Epoch 77/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0032 - mae: 0.0311 - val_loss: 0.0385 - val_mae: 0.0913\n",
      "Epoch 78/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0030 - mae: 0.0289 - val_loss: 0.0372 - val_mae: 0.0976\n",
      "Epoch 79/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0030 - mae: 0.0277 - val_loss: 0.0393 - val_mae: 0.0859\n",
      "Epoch 80/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0031 - mae: 0.0320 - val_loss: 0.0410 - val_mae: 0.0728\n",
      "Epoch 81/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0030 - mae: 0.0298 - val_loss: 0.0379 - val_mae: 0.0951\n",
      "Epoch 82/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0030 - mae: 0.0293 - val_loss: 0.0376 - val_mae: 0.1004\n",
      "Epoch 83/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0030 - mae: 0.0274 - val_loss: 0.0388 - val_mae: 0.0869\n",
      "Epoch 84/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0037 - mae: 0.0407 - val_loss: 0.0435 - val_mae: 0.0866\n",
      "Epoch 85/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0031 - mae: 0.0297 - val_loss: 0.0380 - val_mae: 0.0886\n",
      "Epoch 86/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0030 - mae: 0.0297 - val_loss: 0.0372 - val_mae: 0.0962\n",
      "Epoch 87/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0029 - mae: 0.0269 - val_loss: 0.0396 - val_mae: 0.0771\n",
      "Epoch 88/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0030 - mae: 0.0294 - val_loss: 0.0372 - val_mae: 0.0965\n",
      "Epoch 89/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0030 - mae: 0.0282 - val_loss: 0.0387 - val_mae: 0.0863\n",
      "Epoch 90/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0030 - mae: 0.0283 - val_loss: 0.0386 - val_mae: 0.0849\n",
      "Epoch 91/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0031 - mae: 0.0301 - val_loss: 0.0390 - val_mae: 0.0807\n",
      "Epoch 92/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0030 - mae: 0.0293 - val_loss: 0.0393 - val_mae: 0.0826\n",
      "Epoch 93/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0030 - mae: 0.0273 - val_loss: 0.0423 - val_mae: 0.0756\n",
      "Epoch 94/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0034 - mae: 0.0369 - val_loss: 0.0398 - val_mae: 0.0780\n",
      "Epoch 95/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0031 - mae: 0.0300 - val_loss: 0.0383 - val_mae: 0.0930\n",
      "Epoch 96/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0030 - mae: 0.0276 - val_loss: 0.0379 - val_mae: 0.0912\n",
      "Epoch 97/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0029 - mae: 0.0260 - val_loss: 0.0397 - val_mae: 0.0773\n",
      "Epoch 98/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0030 - mae: 0.0291 - val_loss: 0.0441 - val_mae: 0.0922\n",
      "Epoch 99/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0031 - mae: 0.0316 - val_loss: 0.0366 - val_mae: 0.1044\n",
      "Epoch 100/100\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0030 - mae: 0.0295 - val_loss: 0.0369 - val_mae: 0.0992\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step  \n",
      "✅ Done: tomato_Dharwad_daily.csv | MAE=411.61, RMSE=732.44, R2=0.27, MAPE=25.07%, Accuracy=74.93%\n",
      "🚀 Processing: tomato_Gadag_daily.csv\n",
      "Epoch 1/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 0.0582 - mae: 0.1778 - val_loss: 0.0282 - val_mae: 0.1610\n",
      "Epoch 2/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0197 - mae: 0.1126 - val_loss: 0.0532 - val_mae: 0.2223\n",
      "Epoch 3/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0170 - mae: 0.1048 - val_loss: 0.0342 - val_mae: 0.1785\n",
      "Epoch 4/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0137 - mae: 0.0927 - val_loss: 0.0395 - val_mae: 0.1919\n",
      "Epoch 5/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0128 - mae: 0.0888 - val_loss: 0.0129 - val_mae: 0.0992\n",
      "Epoch 6/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0110 - mae: 0.0820 - val_loss: 0.0317 - val_mae: 0.1722\n",
      "Epoch 7/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0107 - mae: 0.0788 - val_loss: 0.0292 - val_mae: 0.1653\n",
      "Epoch 8/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0094 - mae: 0.0725 - val_loss: 0.0120 - val_mae: 0.0959\n",
      "Epoch 9/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0087 - mae: 0.0688 - val_loss: 0.0090 - val_mae: 0.0598\n",
      "Epoch 10/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0078 - mae: 0.0642 - val_loss: 0.0178 - val_mae: 0.1276\n",
      "Epoch 11/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0074 - mae: 0.0615 - val_loss: 0.0097 - val_mae: 0.0798\n",
      "Epoch 12/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0065 - mae: 0.0549 - val_loss: 0.0091 - val_mae: 0.0734\n",
      "Epoch 13/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0063 - mae: 0.0542 - val_loss: 0.0098 - val_mae: 0.0837\n",
      "Epoch 14/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0056 - mae: 0.0481 - val_loss: 0.0087 - val_mae: 0.0443\n",
      "Epoch 15/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0056 - mae: 0.0488 - val_loss: 0.0090 - val_mae: 0.0440\n",
      "Epoch 16/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0052 - mae: 0.0464 - val_loss: 0.0144 - val_mae: 0.0844\n",
      "Epoch 17/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0047 - mae: 0.0434 - val_loss: 0.0091 - val_mae: 0.0444\n",
      "Epoch 18/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0047 - mae: 0.0411 - val_loss: 0.0073 - val_mae: 0.0477\n",
      "Epoch 19/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0045 - mae: 0.0392 - val_loss: 0.0100 - val_mae: 0.0553\n",
      "Epoch 20/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0044 - mae: 0.0398 - val_loss: 0.0085 - val_mae: 0.0401\n",
      "Epoch 21/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0041 - mae: 0.0367 - val_loss: 0.0092 - val_mae: 0.0480\n",
      "Epoch 22/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0041 - mae: 0.0372 - val_loss: 0.0127 - val_mae: 0.0778\n",
      "Epoch 23/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0040 - mae: 0.0354 - val_loss: 0.0069 - val_mae: 0.0390\n",
      "Epoch 24/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0044 - mae: 0.0416 - val_loss: 0.0075 - val_mae: 0.0316\n",
      "Epoch 25/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0040 - mae: 0.0352 - val_loss: 0.0067 - val_mae: 0.0428\n",
      "Epoch 26/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0041 - mae: 0.0378 - val_loss: 0.0120 - val_mae: 0.0752\n",
      "Epoch 27/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0035 - mae: 0.0304 - val_loss: 0.0141 - val_mae: 0.0885\n",
      "Epoch 28/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0038 - mae: 0.0328 - val_loss: 0.0120 - val_mae: 0.0757\n",
      "Epoch 29/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0036 - mae: 0.0310 - val_loss: 0.0111 - val_mae: 0.0694\n",
      "Epoch 30/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0037 - mae: 0.0310 - val_loss: 0.0190 - val_mae: 0.1140\n",
      "Epoch 31/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0043 - mae: 0.0376 - val_loss: 0.0119 - val_mae: 0.0759\n",
      "Epoch 32/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0035 - mae: 0.0305 - val_loss: 0.0138 - val_mae: 0.0882\n",
      "Epoch 33/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0037 - mae: 0.0314 - val_loss: 0.0140 - val_mae: 0.0893\n",
      "Epoch 34/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0036 - mae: 0.0308 - val_loss: 0.0102 - val_mae: 0.0651\n",
      "Epoch 35/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0037 - mae: 0.0322 - val_loss: 0.0188 - val_mae: 0.1137\n",
      "Epoch 36/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0037 - mae: 0.0325 - val_loss: 0.0121 - val_mae: 0.0792\n",
      "Epoch 37/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0035 - mae: 0.0305 - val_loss: 0.0332 - val_mae: 0.1659\n",
      "Epoch 38/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0038 - mae: 0.0335 - val_loss: 0.0127 - val_mae: 0.0832\n",
      "Epoch 39/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0034 - mae: 0.0276 - val_loss: 0.0159 - val_mae: 0.1011\n",
      "Epoch 40/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0035 - mae: 0.0288 - val_loss: 0.0182 - val_mae: 0.1124\n",
      "Epoch 41/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0034 - mae: 0.0289 - val_loss: 0.0229 - val_mae: 0.1317\n",
      "Epoch 42/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0035 - mae: 0.0300 - val_loss: 0.0168 - val_mae: 0.1060\n",
      "Epoch 43/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0036 - mae: 0.0329 - val_loss: 0.0204 - val_mae: 0.1223\n",
      "Epoch 44/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0033 - mae: 0.0262 - val_loss: 0.0141 - val_mae: 0.0929\n",
      "Epoch 45/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0033 - mae: 0.0267 - val_loss: 0.0192 - val_mae: 0.1176\n",
      "Epoch 46/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0035 - mae: 0.0298 - val_loss: 0.0144 - val_mae: 0.0954\n",
      "Epoch 47/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0035 - mae: 0.0295 - val_loss: 0.0122 - val_mae: 0.0826\n",
      "Epoch 48/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0034 - mae: 0.0306 - val_loss: 0.0242 - val_mae: 0.1381\n",
      "Epoch 49/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0037 - mae: 0.0336 - val_loss: 0.0112 - val_mae: 0.0770\n",
      "Epoch 50/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0036 - mae: 0.0333 - val_loss: 0.0225 - val_mae: 0.1317\n",
      "Epoch 51/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0036 - mae: 0.0322 - val_loss: 0.0276 - val_mae: 0.1502\n",
      "Epoch 52/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0040 - mae: 0.0396 - val_loss: 0.0190 - val_mae: 0.1178\n",
      "Epoch 53/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0040 - mae: 0.0374 - val_loss: 0.0232 - val_mae: 0.1347\n",
      "Epoch 54/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0037 - mae: 0.0337 - val_loss: 0.0079 - val_mae: 0.0529\n",
      "Epoch 55/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0035 - mae: 0.0307 - val_loss: 0.0101 - val_mae: 0.0712\n",
      "Epoch 56/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0034 - mae: 0.0286 - val_loss: 0.0178 - val_mae: 0.1139\n",
      "Epoch 57/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0034 - mae: 0.0286 - val_loss: 0.0107 - val_mae: 0.0761\n",
      "Epoch 58/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0034 - mae: 0.0299 - val_loss: 0.0074 - val_mae: 0.0502\n",
      "Epoch 59/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0033 - mae: 0.0263 - val_loss: 0.0131 - val_mae: 0.0919\n",
      "Epoch 60/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0032 - mae: 0.0250 - val_loss: 0.0163 - val_mae: 0.1080\n",
      "Epoch 61/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0032 - mae: 0.0256 - val_loss: 0.0229 - val_mae: 0.1357\n",
      "Epoch 62/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0033 - mae: 0.0271 - val_loss: 0.0096 - val_mae: 0.0704\n",
      "Epoch 63/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0036 - mae: 0.0318 - val_loss: 0.0123 - val_mae: 0.0873\n",
      "Epoch 64/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0033 - mae: 0.0286 - val_loss: 0.0115 - val_mae: 0.0836\n",
      "Epoch 65/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0033 - mae: 0.0265 - val_loss: 0.0183 - val_mae: 0.1181\n",
      "Epoch 66/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0033 - mae: 0.0265 - val_loss: 0.0196 - val_mae: 0.1239\n",
      "Epoch 67/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0035 - mae: 0.0301 - val_loss: 0.0097 - val_mae: 0.0737\n",
      "Epoch 68/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0034 - mae: 0.0300 - val_loss: 0.0136 - val_mae: 0.0975\n",
      "Epoch 69/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0033 - mae: 0.0274 - val_loss: 0.0099 - val_mae: 0.0760\n",
      "Epoch 70/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0034 - mae: 0.0294 - val_loss: 0.0183 - val_mae: 0.1191\n",
      "Epoch 71/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0038 - mae: 0.0366 - val_loss: 0.0147 - val_mae: 0.1031\n",
      "Epoch 72/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0031 - mae: 0.0244 - val_loss: 0.0112 - val_mae: 0.0845\n",
      "Epoch 73/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0033 - mae: 0.0291 - val_loss: 0.0141 - val_mae: 0.1012\n",
      "Epoch 74/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0033 - mae: 0.0282 - val_loss: 0.0187 - val_mae: 0.1219\n",
      "Epoch 75/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0032 - mae: 0.0258 - val_loss: 0.0121 - val_mae: 0.0916\n",
      "Epoch 76/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0031 - mae: 0.0255 - val_loss: 0.0079 - val_mae: 0.0648\n",
      "Epoch 77/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0037 - mae: 0.0344 - val_loss: 0.0149 - val_mae: 0.1061\n",
      "Epoch 78/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0034 - mae: 0.0322 - val_loss: 0.0177 - val_mae: 0.1189\n",
      "Epoch 79/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0031 - mae: 0.0246 - val_loss: 0.0072 - val_mae: 0.0590\n",
      "Epoch 80/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0032 - mae: 0.0277 - val_loss: 0.0136 - val_mae: 0.1003\n",
      "Epoch 81/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0032 - mae: 0.0271 - val_loss: 0.0148 - val_mae: 0.1067\n",
      "Epoch 82/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0032 - mae: 0.0282 - val_loss: 0.0127 - val_mae: 0.0965\n",
      "Epoch 83/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0033 - mae: 0.0296 - val_loss: 0.0280 - val_mae: 0.1576\n",
      "Epoch 84/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0033 - mae: 0.0311 - val_loss: 0.0044 - val_mae: 0.0295\n",
      "Epoch 85/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0032 - mae: 0.0253 - val_loss: 0.0075 - val_mae: 0.0651\n",
      "Epoch 86/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0032 - mae: 0.0270 - val_loss: 0.0137 - val_mae: 0.1028\n",
      "Epoch 87/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0030 - mae: 0.0243 - val_loss: 0.0079 - val_mae: 0.0681\n",
      "Epoch 88/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0035 - mae: 0.0344 - val_loss: 0.0054 - val_mae: 0.0457\n",
      "Epoch 89/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0031 - mae: 0.0268 - val_loss: 0.0104 - val_mae: 0.0856\n",
      "Epoch 90/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0030 - mae: 0.0247 - val_loss: 0.0130 - val_mae: 0.1001\n",
      "Epoch 91/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0031 - mae: 0.0263 - val_loss: 0.0241 - val_mae: 0.1461\n",
      "Epoch 92/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0032 - mae: 0.0295 - val_loss: 0.0115 - val_mae: 0.0924\n",
      "Epoch 93/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0031 - mae: 0.0266 - val_loss: 0.0049 - val_mae: 0.0451\n",
      "Epoch 94/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0033 - mae: 0.0293 - val_loss: 0.0070 - val_mae: 0.0643\n",
      "Epoch 95/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0032 - mae: 0.0289 - val_loss: 0.0173 - val_mae: 0.1209\n",
      "Epoch 96/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0031 - mae: 0.0267 - val_loss: 0.0096 - val_mae: 0.0834\n",
      "Epoch 97/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0030 - mae: 0.0253 - val_loss: 0.0187 - val_mae: 0.1274\n",
      "Epoch 98/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0031 - mae: 0.0266 - val_loss: 0.0179 - val_mae: 0.1243\n",
      "Epoch 99/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0032 - mae: 0.0274 - val_loss: 0.0059 - val_mae: 0.0586\n",
      "Epoch 100/100\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0030 - mae: 0.0255 - val_loss: 0.0107 - val_mae: 0.0908\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step  \n",
      "✅ Done: tomato_Gadag_daily.csv | MAE=428.7, RMSE=605.39, R2=0.92, MAPE=9.22%, Accuracy=90.78%\n",
      "🚀 Processing: tomato_Hassan_daily.csv\n",
      "Epoch 1/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - loss: 0.0127 - mae: 0.0674 - val_loss: 0.0098 - val_mae: 0.0624\n",
      "Epoch 2/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0024 - mae: 0.0376 - val_loss: 0.0122 - val_mae: 0.0701\n",
      "Epoch 3/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0022 - mae: 0.0357 - val_loss: 0.0105 - val_mae: 0.0638\n",
      "Epoch 4/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0021 - mae: 0.0346 - val_loss: 0.0102 - val_mae: 0.0632\n",
      "Epoch 5/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0020 - mae: 0.0335 - val_loss: 0.0128 - val_mae: 0.0743\n",
      "Epoch 6/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0020 - mae: 0.0336 - val_loss: 0.0091 - val_mae: 0.0608\n",
      "Epoch 7/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0019 - mae: 0.0325 - val_loss: 0.0073 - val_mae: 0.0560\n",
      "Epoch 8/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0019 - mae: 0.0323 - val_loss: 0.0073 - val_mae: 0.0560\n",
      "Epoch 9/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0019 - mae: 0.0320 - val_loss: 0.0076 - val_mae: 0.0575\n",
      "Epoch 10/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0314 - val_loss: 0.0059 - val_mae: 0.0531\n",
      "Epoch 11/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0315 - val_loss: 0.0062 - val_mae: 0.0538\n",
      "Epoch 12/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0311 - val_loss: 0.0059 - val_mae: 0.0528\n",
      "Epoch 13/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0309 - val_loss: 0.0061 - val_mae: 0.0533\n",
      "Epoch 14/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0310 - val_loss: 0.0060 - val_mae: 0.0544\n",
      "Epoch 15/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0308 - val_loss: 0.0059 - val_mae: 0.0531\n",
      "Epoch 16/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0308 - val_loss: 0.0065 - val_mae: 0.0561\n",
      "Epoch 17/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0308 - val_loss: 0.0058 - val_mae: 0.0526\n",
      "Epoch 18/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0308 - val_loss: 0.0060 - val_mae: 0.0541\n",
      "Epoch 19/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0308 - val_loss: 0.0058 - val_mae: 0.0528\n",
      "Epoch 20/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0307 - val_loss: 0.0058 - val_mae: 0.0529\n",
      "Epoch 21/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0307 - val_loss: 0.0059 - val_mae: 0.0529\n",
      "Epoch 22/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0307 - val_loss: 0.0060 - val_mae: 0.0530\n",
      "Epoch 23/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0058 - val_mae: 0.0527\n",
      "Epoch 24/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0059 - val_mae: 0.0537\n",
      "Epoch 25/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0064 - val_mae: 0.0543\n",
      "Epoch 26/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0307 - val_loss: 0.0058 - val_mae: 0.0528\n",
      "Epoch 27/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0307 - val_loss: 0.0059 - val_mae: 0.0528\n",
      "Epoch 28/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0307 - val_loss: 0.0060 - val_mae: 0.0531\n",
      "Epoch 29/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0058 - val_mae: 0.0528\n",
      "Epoch 30/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0058 - val_mae: 0.0528\n",
      "Epoch 31/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0064 - val_mae: 0.0542\n",
      "Epoch 32/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0058 - val_mae: 0.0529\n",
      "Epoch 33/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0061 - val_mae: 0.0534\n",
      "Epoch 34/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0058 - val_mae: 0.0528\n",
      "Epoch 35/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0058 - val_mae: 0.0529\n",
      "Epoch 36/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0058 - val_mae: 0.0528\n",
      "Epoch 37/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0059 - val_mae: 0.0532\n",
      "Epoch 38/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0058 - val_mae: 0.0533\n",
      "Epoch 39/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0307 - val_loss: 0.0058 - val_mae: 0.0529\n",
      "Epoch 40/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0058 - val_mae: 0.0528\n",
      "Epoch 41/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0063 - val_mae: 0.0564\n",
      "Epoch 42/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0305 - val_loss: 0.0059 - val_mae: 0.0530\n",
      "Epoch 43/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0065 - val_mae: 0.0565\n",
      "Epoch 44/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0058 - val_mae: 0.0529\n",
      "Epoch 45/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0059 - val_mae: 0.0529\n",
      "Epoch 46/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0058 - val_mae: 0.0529\n",
      "Epoch 47/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0307 - val_loss: 0.0058 - val_mae: 0.0530\n",
      "Epoch 48/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0305 - val_loss: 0.0058 - val_mae: 0.0533\n",
      "Epoch 49/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0060 - val_mae: 0.0532\n",
      "Epoch 50/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0059 - val_mae: 0.0537\n",
      "Epoch 51/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0059 - val_mae: 0.0531\n",
      "Epoch 52/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0058 - val_mae: 0.0531\n",
      "Epoch 53/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0059 - val_mae: 0.0530\n",
      "Epoch 54/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0060 - val_mae: 0.0532\n",
      "Epoch 55/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0305 - val_loss: 0.0060 - val_mae: 0.0547\n",
      "Epoch 56/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0305 - val_loss: 0.0058 - val_mae: 0.0532\n",
      "Epoch 57/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0059 - val_mae: 0.0535\n",
      "Epoch 58/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0305 - val_loss: 0.0059 - val_mae: 0.0533\n",
      "Epoch 59/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0059 - val_mae: 0.0530\n",
      "Epoch 60/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0305 - val_loss: 0.0058 - val_mae: 0.0532\n",
      "Epoch 61/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0305 - val_loss: 0.0058 - val_mae: 0.0529\n",
      "Epoch 62/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0305 - val_loss: 0.0058 - val_mae: 0.0530\n",
      "Epoch 63/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0059 - val_mae: 0.0536\n",
      "Epoch 64/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0059 - val_mae: 0.0531\n",
      "Epoch 65/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0305 - val_loss: 0.0059 - val_mae: 0.0531\n",
      "Epoch 66/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0059 - val_mae: 0.0537\n",
      "Epoch 67/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0059 - val_mae: 0.0530\n",
      "Epoch 68/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0059 - val_mae: 0.0530\n",
      "Epoch 69/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0059 - val_mae: 0.0530\n",
      "Epoch 70/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0305 - val_loss: 0.0061 - val_mae: 0.0535\n",
      "Epoch 71/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0058 - val_mae: 0.0529\n",
      "Epoch 72/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0305 - val_loss: 0.0059 - val_mae: 0.0529\n",
      "Epoch 73/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0062 - val_mae: 0.0560\n",
      "Epoch 74/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0305 - val_loss: 0.0062 - val_mae: 0.0556\n",
      "Epoch 75/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0059 - val_mae: 0.0538\n",
      "Epoch 76/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0058 - val_mae: 0.0531\n",
      "Epoch 77/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0305 - val_loss: 0.0060 - val_mae: 0.0531\n",
      "Epoch 78/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0305 - val_loss: 0.0059 - val_mae: 0.0531\n",
      "Epoch 79/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0058 - val_mae: 0.0530\n",
      "Epoch 80/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0061 - val_mae: 0.0533\n",
      "Epoch 81/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0305 - val_loss: 0.0059 - val_mae: 0.0540\n",
      "Epoch 82/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0059 - val_mae: 0.0530\n",
      "Epoch 83/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0058 - val_mae: 0.0530\n",
      "Epoch 84/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0305 - val_loss: 0.0062 - val_mae: 0.0537\n",
      "Epoch 85/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0059 - val_mae: 0.0540\n",
      "Epoch 86/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0061 - val_mae: 0.0535\n",
      "Epoch 87/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0061 - val_mae: 0.0535\n",
      "Epoch 88/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0064 - val_mae: 0.0544\n",
      "Epoch 89/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0058 - val_mae: 0.0531\n",
      "Epoch 90/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0305 - val_loss: 0.0058 - val_mae: 0.0531\n",
      "Epoch 91/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0062 - val_mae: 0.0537\n",
      "Epoch 92/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0060 - val_mae: 0.0532\n",
      "Epoch 93/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0305 - val_loss: 0.0062 - val_mae: 0.0538\n",
      "Epoch 94/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0059 - val_mae: 0.0532\n",
      "Epoch 95/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0305 - val_loss: 0.0058 - val_mae: 0.0531\n",
      "Epoch 96/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0305 - val_loss: 0.0060 - val_mae: 0.0532\n",
      "Epoch 97/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0058 - val_mae: 0.0534\n",
      "Epoch 98/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0305 - val_loss: 0.0059 - val_mae: 0.0531\n",
      "Epoch 99/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0305 - val_loss: 0.0058 - val_mae: 0.0530\n",
      "Epoch 100/100\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0305 - val_loss: 0.0059 - val_mae: 0.0530\n",
      "\u001b[1m923/923\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step\n",
      "✅ Done: tomato_Hassan_daily.csv | MAE=416.49, RMSE=609.12, R2=0.58, MAPE=52.15%, Accuracy=47.85%\n",
      "🚀 Processing: tomato_Haveri_daily.csv\n",
      "Epoch 1/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - loss: 0.1920 - mae: 0.2579 - val_loss: 0.2672 - val_mae: 0.4251\n",
      "Epoch 2/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0252 - mae: 0.1254 - val_loss: 0.1650 - val_mae: 0.3436\n",
      "Epoch 3/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0205 - mae: 0.1129 - val_loss: 0.1382 - val_mae: 0.3158\n",
      "Epoch 4/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0184 - mae: 0.1086 - val_loss: 0.1258 - val_mae: 0.3105\n",
      "Epoch 5/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0159 - mae: 0.1006 - val_loss: 0.0683 - val_mae: 0.2398\n",
      "Epoch 6/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0146 - mae: 0.0960 - val_loss: 0.0510 - val_mae: 0.2055\n",
      "Epoch 7/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0126 - mae: 0.0900 - val_loss: 0.0361 - val_mae: 0.1718\n",
      "Epoch 8/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0126 - mae: 0.0914 - val_loss: 0.0463 - val_mae: 0.2033\n",
      "Epoch 9/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0110 - mae: 0.0856 - val_loss: 0.0309 - val_mae: 0.1687\n",
      "Epoch 10/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0102 - mae: 0.0835 - val_loss: 0.0128 - val_mae: 0.0878\n",
      "Epoch 11/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0096 - mae: 0.0813 - val_loss: 0.0164 - val_mae: 0.1204\n",
      "Epoch 12/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0087 - mae: 0.0779 - val_loss: 0.0094 - val_mae: 0.0664\n",
      "Epoch 13/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0083 - mae: 0.0765 - val_loss: 0.0077 - val_mae: 0.0646\n",
      "Epoch 14/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0084 - mae: 0.0773 - val_loss: 0.0063 - val_mae: 0.0643\n",
      "Epoch 15/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0079 - mae: 0.0747 - val_loss: 0.0058 - val_mae: 0.0626\n",
      "Epoch 16/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0082 - mae: 0.0755 - val_loss: 0.0069 - val_mae: 0.0450\n",
      "Epoch 17/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0073 - mae: 0.0728 - val_loss: 0.0053 - val_mae: 0.0413\n",
      "Epoch 18/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0071 - mae: 0.0717 - val_loss: 0.0047 - val_mae: 0.0444\n",
      "Epoch 19/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0073 - mae: 0.0727 - val_loss: 0.0054 - val_mae: 0.0643\n",
      "Epoch 20/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0072 - mae: 0.0722 - val_loss: 0.0065 - val_mae: 0.0474\n",
      "Epoch 21/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0068 - mae: 0.0706 - val_loss: 0.0176 - val_mae: 0.1034\n",
      "Epoch 22/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0072 - mae: 0.0728 - val_loss: 0.0085 - val_mae: 0.0705\n",
      "Epoch 23/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0065 - mae: 0.0691 - val_loss: 0.0079 - val_mae: 0.0571\n",
      "Epoch 24/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0065 - mae: 0.0692 - val_loss: 0.0065 - val_mae: 0.0526\n",
      "Epoch 25/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0063 - mae: 0.0687 - val_loss: 0.0155 - val_mae: 0.0993\n",
      "Epoch 26/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0064 - mae: 0.0685 - val_loss: 0.0056 - val_mae: 0.0431\n",
      "Epoch 27/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0065 - mae: 0.0692 - val_loss: 0.0095 - val_mae: 0.0697\n",
      "Epoch 28/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0066 - mae: 0.0690 - val_loss: 0.0051 - val_mae: 0.0387\n",
      "Epoch 29/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0067 - mae: 0.0695 - val_loss: 0.0043 - val_mae: 0.0361\n",
      "Epoch 30/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0063 - mae: 0.0684 - val_loss: 0.0056 - val_mae: 0.0409\n",
      "Epoch 31/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0062 - mae: 0.0680 - val_loss: 0.0054 - val_mae: 0.0510\n",
      "Epoch 32/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0065 - mae: 0.0695 - val_loss: 0.0066 - val_mae: 0.0479\n",
      "Epoch 33/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0060 - mae: 0.0672 - val_loss: 0.0104 - val_mae: 0.0755\n",
      "Epoch 34/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0063 - mae: 0.0685 - val_loss: 0.0083 - val_mae: 0.0652\n",
      "Epoch 35/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0062 - mae: 0.0683 - val_loss: 0.0069 - val_mae: 0.0526\n",
      "Epoch 36/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0059 - mae: 0.0670 - val_loss: 0.0075 - val_mae: 0.0578\n",
      "Epoch 37/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0061 - mae: 0.0678 - val_loss: 0.0060 - val_mae: 0.0453\n",
      "Epoch 38/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0064 - mae: 0.0691 - val_loss: 0.0045 - val_mae: 0.0352\n",
      "Epoch 39/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0063 - mae: 0.0680 - val_loss: 0.0104 - val_mae: 0.0786\n",
      "Epoch 40/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0060 - mae: 0.0682 - val_loss: 0.0077 - val_mae: 0.0589\n",
      "Epoch 41/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0062 - mae: 0.0680 - val_loss: 0.0082 - val_mae: 0.0634\n",
      "Epoch 42/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0059 - mae: 0.0674 - val_loss: 0.0107 - val_mae: 0.0749\n",
      "Epoch 43/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0063 - mae: 0.0679 - val_loss: 0.0065 - val_mae: 0.0456\n",
      "Epoch 44/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0063 - mae: 0.0687 - val_loss: 0.0045 - val_mae: 0.0391\n",
      "Epoch 45/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0062 - mae: 0.0679 - val_loss: 0.0088 - val_mae: 0.0652\n",
      "Epoch 46/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0061 - mae: 0.0676 - val_loss: 0.0081 - val_mae: 0.0577\n",
      "Epoch 47/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0058 - mae: 0.0667 - val_loss: 0.0122 - val_mae: 0.0825\n",
      "Epoch 48/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0058 - mae: 0.0666 - val_loss: 0.0167 - val_mae: 0.1060\n",
      "Epoch 49/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0061 - mae: 0.0676 - val_loss: 0.0134 - val_mae: 0.0854\n",
      "Epoch 50/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0057 - mae: 0.0664 - val_loss: 0.0203 - val_mae: 0.1161\n",
      "Epoch 51/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0064 - mae: 0.0693 - val_loss: 0.0174 - val_mae: 0.1062\n",
      "Epoch 52/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0065 - mae: 0.0689 - val_loss: 0.0102 - val_mae: 0.0764\n",
      "Epoch 53/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0063 - mae: 0.0686 - val_loss: 0.0144 - val_mae: 0.0932\n",
      "Epoch 54/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0059 - mae: 0.0670 - val_loss: 0.0101 - val_mae: 0.0709\n",
      "Epoch 55/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0063 - mae: 0.0685 - val_loss: 0.0172 - val_mae: 0.1059\n",
      "Epoch 56/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0061 - mae: 0.0679 - val_loss: 0.0158 - val_mae: 0.0956\n",
      "Epoch 57/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0060 - mae: 0.0671 - val_loss: 0.0153 - val_mae: 0.0953\n",
      "Epoch 58/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0058 - mae: 0.0666 - val_loss: 0.0093 - val_mae: 0.0662\n",
      "Epoch 59/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0060 - mae: 0.0673 - val_loss: 0.0112 - val_mae: 0.0745\n",
      "Epoch 60/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0059 - mae: 0.0674 - val_loss: 0.0157 - val_mae: 0.1031\n",
      "Epoch 61/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0062 - mae: 0.0679 - val_loss: 0.0122 - val_mae: 0.0814\n",
      "Epoch 62/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0062 - mae: 0.0682 - val_loss: 0.0123 - val_mae: 0.0839\n",
      "Epoch 63/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0059 - mae: 0.0678 - val_loss: 0.0195 - val_mae: 0.1153\n",
      "Epoch 64/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0059 - mae: 0.0674 - val_loss: 0.0140 - val_mae: 0.0967\n",
      "Epoch 65/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0057 - mae: 0.0665 - val_loss: 0.0085 - val_mae: 0.0611\n",
      "Epoch 66/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0058 - mae: 0.0669 - val_loss: 0.0107 - val_mae: 0.0726\n",
      "Epoch 67/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0056 - mae: 0.0664 - val_loss: 0.0100 - val_mae: 0.0739\n",
      "Epoch 68/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0058 - mae: 0.0663 - val_loss: 0.0134 - val_mae: 0.0885\n",
      "Epoch 69/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0060 - mae: 0.0672 - val_loss: 0.0098 - val_mae: 0.0722\n",
      "Epoch 70/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0062 - mae: 0.0680 - val_loss: 0.0222 - val_mae: 0.1185\n",
      "Epoch 71/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0057 - mae: 0.0665 - val_loss: 0.0062 - val_mae: 0.0408\n",
      "Epoch 72/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0057 - mae: 0.0663 - val_loss: 0.0148 - val_mae: 0.0953\n",
      "Epoch 73/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0057 - mae: 0.0670 - val_loss: 0.0078 - val_mae: 0.0540\n",
      "Epoch 74/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0058 - mae: 0.0665 - val_loss: 0.0173 - val_mae: 0.1020\n",
      "Epoch 75/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0059 - mae: 0.0672 - val_loss: 0.0096 - val_mae: 0.0685\n",
      "Epoch 76/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0059 - mae: 0.0674 - val_loss: 0.0148 - val_mae: 0.0983\n",
      "Epoch 77/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0057 - mae: 0.0665 - val_loss: 0.0084 - val_mae: 0.0607\n",
      "Epoch 78/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0057 - mae: 0.0662 - val_loss: 0.0079 - val_mae: 0.0569\n",
      "Epoch 79/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0059 - mae: 0.0673 - val_loss: 0.0227 - val_mae: 0.1260\n",
      "Epoch 80/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0061 - mae: 0.0672 - val_loss: 0.0118 - val_mae: 0.0797\n",
      "Epoch 81/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0056 - mae: 0.0658 - val_loss: 0.0083 - val_mae: 0.0570\n",
      "Epoch 82/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0056 - mae: 0.0659 - val_loss: 0.0129 - val_mae: 0.0823\n",
      "Epoch 83/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0058 - mae: 0.0663 - val_loss: 0.0102 - val_mae: 0.0719\n",
      "Epoch 84/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0054 - mae: 0.0651 - val_loss: 0.0175 - val_mae: 0.0976\n",
      "Epoch 85/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0057 - mae: 0.0666 - val_loss: 0.0074 - val_mae: 0.0648\n",
      "Epoch 86/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0058 - mae: 0.0670 - val_loss: 0.0185 - val_mae: 0.1147\n",
      "Epoch 87/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0060 - mae: 0.0672 - val_loss: 0.0086 - val_mae: 0.0699\n",
      "Epoch 88/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0057 - mae: 0.0666 - val_loss: 0.0068 - val_mae: 0.0476\n",
      "Epoch 89/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0056 - mae: 0.0665 - val_loss: 0.0117 - val_mae: 0.0801\n",
      "Epoch 90/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0054 - mae: 0.0654 - val_loss: 0.0120 - val_mae: 0.0842\n",
      "Epoch 91/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0057 - mae: 0.0665 - val_loss: 0.0127 - val_mae: 0.0857\n",
      "Epoch 92/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0055 - mae: 0.0655 - val_loss: 0.0096 - val_mae: 0.0695\n",
      "Epoch 93/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0056 - mae: 0.0661 - val_loss: 0.0148 - val_mae: 0.0961\n",
      "Epoch 94/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0057 - mae: 0.0669 - val_loss: 0.0072 - val_mae: 0.0483\n",
      "Epoch 95/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0057 - mae: 0.0665 - val_loss: 0.0061 - val_mae: 0.0408\n",
      "Epoch 96/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0057 - mae: 0.0659 - val_loss: 0.0158 - val_mae: 0.0943\n",
      "Epoch 97/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0059 - mae: 0.0671 - val_loss: 0.0143 - val_mae: 0.0876\n",
      "Epoch 98/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0055 - mae: 0.0656 - val_loss: 0.0100 - val_mae: 0.0708\n",
      "Epoch 99/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0054 - mae: 0.0653 - val_loss: 0.0183 - val_mae: 0.1132\n",
      "Epoch 100/100\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0057 - mae: 0.0659 - val_loss: 0.0213 - val_mae: 0.1224\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step   \n",
      "✅ Done: tomato_Haveri_daily.csv | MAE=790.28, RMSE=966.69, R2=0.83, MAPE=35.79%, Accuracy=64.21%\n",
      "🚀 Processing: tomato_Kalburgi_daily.csv\n",
      "Epoch 1/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - loss: 0.2484 - mae: 0.2854 - val_loss: 0.0150 - val_mae: 0.1060\n",
      "Epoch 2/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0330 - mae: 0.1362 - val_loss: 0.0128 - val_mae: 0.0952\n",
      "Epoch 3/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0321 - mae: 0.1356 - val_loss: 0.0268 - val_mae: 0.1514\n",
      "Epoch 4/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0292 - mae: 0.1289 - val_loss: 0.0229 - val_mae: 0.1373\n",
      "Epoch 5/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0311 - mae: 0.1321 - val_loss: 0.0137 - val_mae: 0.1004\n",
      "Epoch 6/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0315 - mae: 0.1366 - val_loss: 0.0129 - val_mae: 0.0958\n",
      "Epoch 7/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0288 - mae: 0.1302 - val_loss: 0.0185 - val_mae: 0.1208\n",
      "Epoch 8/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0287 - mae: 0.1279 - val_loss: 0.0127 - val_mae: 0.0964\n",
      "Epoch 9/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0291 - mae: 0.1288 - val_loss: 0.0236 - val_mae: 0.1376\n",
      "Epoch 10/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0255 - mae: 0.1189 - val_loss: 0.0086 - val_mae: 0.0741\n",
      "Epoch 11/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0258 - mae: 0.1186 - val_loss: 0.0212 - val_mae: 0.1313\n",
      "Epoch 12/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0257 - mae: 0.1193 - val_loss: 0.0103 - val_mae: 0.0842\n",
      "Epoch 13/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0235 - mae: 0.1153 - val_loss: 0.0180 - val_mae: 0.1172\n",
      "Epoch 14/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0247 - mae: 0.1182 - val_loss: 0.0070 - val_mae: 0.0671\n",
      "Epoch 15/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0223 - mae: 0.1091 - val_loss: 0.0049 - val_mae: 0.0575\n",
      "Epoch 16/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0230 - mae: 0.1099 - val_loss: 0.0083 - val_mae: 0.0742\n",
      "Epoch 17/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0229 - mae: 0.1109 - val_loss: 0.0247 - val_mae: 0.1402\n",
      "Epoch 18/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0227 - mae: 0.1107 - val_loss: 0.0047 - val_mae: 0.0546\n",
      "Epoch 19/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0205 - mae: 0.1030 - val_loss: 0.0141 - val_mae: 0.1025\n",
      "Epoch 20/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0215 - mae: 0.1073 - val_loss: 0.0118 - val_mae: 0.0891\n",
      "Epoch 21/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0211 - mae: 0.1088 - val_loss: 0.0148 - val_mae: 0.1026\n",
      "Epoch 22/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0201 - mae: 0.1019 - val_loss: 0.0074 - val_mae: 0.0670\n",
      "Epoch 23/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0192 - mae: 0.0988 - val_loss: 0.0108 - val_mae: 0.0851\n",
      "Epoch 24/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0196 - mae: 0.0996 - val_loss: 0.0106 - val_mae: 0.0824\n",
      "Epoch 25/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0183 - mae: 0.0949 - val_loss: 0.0216 - val_mae: 0.1291\n",
      "Epoch 26/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0187 - mae: 0.0973 - val_loss: 0.0073 - val_mae: 0.0685\n",
      "Epoch 27/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0187 - mae: 0.0971 - val_loss: 0.0096 - val_mae: 0.0793\n",
      "Epoch 28/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0176 - mae: 0.0932 - val_loss: 0.0091 - val_mae: 0.0769\n",
      "Epoch 29/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0177 - mae: 0.0931 - val_loss: 0.0062 - val_mae: 0.0600\n",
      "Epoch 30/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0167 - mae: 0.0899 - val_loss: 0.0084 - val_mae: 0.0716\n",
      "Epoch 31/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0180 - mae: 0.0935 - val_loss: 0.0220 - val_mae: 0.1290\n",
      "Epoch 32/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0191 - mae: 0.0988 - val_loss: 0.0095 - val_mae: 0.0751\n",
      "Epoch 33/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0168 - mae: 0.0903 - val_loss: 0.0084 - val_mae: 0.0727\n",
      "Epoch 34/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0175 - mae: 0.0920 - val_loss: 0.0240 - val_mae: 0.1355\n",
      "Epoch 35/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0163 - mae: 0.0868 - val_loss: 0.0147 - val_mae: 0.0989\n",
      "Epoch 36/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0198 - mae: 0.0993 - val_loss: 0.0068 - val_mae: 0.0626\n",
      "Epoch 37/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0159 - mae: 0.0874 - val_loss: 0.0060 - val_mae: 0.0595\n",
      "Epoch 38/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0174 - mae: 0.0899 - val_loss: 0.0131 - val_mae: 0.0932\n",
      "Epoch 39/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0171 - mae: 0.0934 - val_loss: 0.0173 - val_mae: 0.1122\n",
      "Epoch 40/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0173 - mae: 0.0903 - val_loss: 0.0150 - val_mae: 0.1025\n",
      "Epoch 41/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0182 - mae: 0.0934 - val_loss: 0.0095 - val_mae: 0.0787\n",
      "Epoch 42/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0164 - mae: 0.0874 - val_loss: 0.0193 - val_mae: 0.1202\n",
      "Epoch 43/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0187 - mae: 0.0980 - val_loss: 0.0154 - val_mae: 0.1046\n",
      "Epoch 44/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0185 - mae: 0.0955 - val_loss: 0.0059 - val_mae: 0.0628\n",
      "Epoch 45/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0165 - mae: 0.0909 - val_loss: 0.0088 - val_mae: 0.0754\n",
      "Epoch 46/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0171 - mae: 0.0901 - val_loss: 0.0209 - val_mae: 0.1268\n",
      "Epoch 47/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0160 - mae: 0.0868 - val_loss: 0.0094 - val_mae: 0.0771\n",
      "Epoch 48/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0166 - mae: 0.0881 - val_loss: 0.0072 - val_mae: 0.0653\n",
      "Epoch 49/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0158 - mae: 0.0860 - val_loss: 0.0052 - val_mae: 0.0580\n",
      "Epoch 50/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0171 - mae: 0.0914 - val_loss: 0.0128 - val_mae: 0.0932\n",
      "Epoch 51/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0163 - mae: 0.0895 - val_loss: 0.0062 - val_mae: 0.0602\n",
      "Epoch 52/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0166 - mae: 0.0879 - val_loss: 0.0109 - val_mae: 0.0833\n",
      "Epoch 53/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0160 - mae: 0.0857 - val_loss: 0.0054 - val_mae: 0.0572\n",
      "Epoch 54/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0160 - mae: 0.0860 - val_loss: 0.0084 - val_mae: 0.0706\n",
      "Epoch 55/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0163 - mae: 0.0862 - val_loss: 0.0105 - val_mae: 0.0807\n",
      "Epoch 56/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0158 - mae: 0.0857 - val_loss: 0.0062 - val_mae: 0.0600\n",
      "Epoch 57/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0155 - mae: 0.0849 - val_loss: 0.0085 - val_mae: 0.0732\n",
      "Epoch 58/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0159 - mae: 0.0854 - val_loss: 0.0101 - val_mae: 0.0795\n",
      "Epoch 59/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0168 - mae: 0.0893 - val_loss: 0.0071 - val_mae: 0.0655\n",
      "Epoch 60/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0153 - mae: 0.0842 - val_loss: 0.0096 - val_mae: 0.0785\n",
      "Epoch 61/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0163 - mae: 0.0871 - val_loss: 0.0089 - val_mae: 0.0751\n",
      "Epoch 62/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0157 - mae: 0.0848 - val_loss: 0.0120 - val_mae: 0.0878\n",
      "Epoch 63/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0161 - mae: 0.0863 - val_loss: 0.0116 - val_mae: 0.0873\n",
      "Epoch 64/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0159 - mae: 0.0870 - val_loss: 0.0067 - val_mae: 0.0640\n",
      "Epoch 65/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0165 - mae: 0.0899 - val_loss: 0.0063 - val_mae: 0.0605\n",
      "Epoch 66/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0170 - mae: 0.0909 - val_loss: 0.0206 - val_mae: 0.1221\n",
      "Epoch 67/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0157 - mae: 0.0855 - val_loss: 0.0083 - val_mae: 0.0714\n",
      "Epoch 68/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0162 - mae: 0.0869 - val_loss: 0.0101 - val_mae: 0.0790\n",
      "Epoch 69/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0156 - mae: 0.0856 - val_loss: 0.0077 - val_mae: 0.0665\n",
      "Epoch 70/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0164 - mae: 0.0901 - val_loss: 0.0228 - val_mae: 0.1301\n",
      "Epoch 71/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0156 - mae: 0.0836 - val_loss: 0.0098 - val_mae: 0.0785\n",
      "Epoch 72/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0159 - mae: 0.0868 - val_loss: 0.0136 - val_mae: 0.0958\n",
      "Epoch 73/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0164 - mae: 0.0888 - val_loss: 0.0166 - val_mae: 0.1063\n",
      "Epoch 74/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0158 - mae: 0.0847 - val_loss: 0.0058 - val_mae: 0.0583\n",
      "Epoch 75/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0167 - mae: 0.0878 - val_loss: 0.0160 - val_mae: 0.1090\n",
      "Epoch 76/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0155 - mae: 0.0854 - val_loss: 0.0088 - val_mae: 0.0747\n",
      "Epoch 77/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0155 - mae: 0.0851 - val_loss: 0.0154 - val_mae: 0.1041\n",
      "Epoch 78/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0155 - mae: 0.0852 - val_loss: 0.0188 - val_mae: 0.1193\n",
      "Epoch 79/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0151 - mae: 0.0845 - val_loss: 0.0081 - val_mae: 0.0707\n",
      "Epoch 80/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0154 - mae: 0.0841 - val_loss: 0.0118 - val_mae: 0.0880\n",
      "Epoch 81/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0151 - mae: 0.0844 - val_loss: 0.0097 - val_mae: 0.0778\n",
      "Epoch 82/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0157 - mae: 0.0887 - val_loss: 0.0053 - val_mae: 0.0563\n",
      "Epoch 83/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0158 - mae: 0.0870 - val_loss: 0.0109 - val_mae: 0.0818\n",
      "Epoch 84/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0154 - mae: 0.0850 - val_loss: 0.0091 - val_mae: 0.0745\n",
      "Epoch 85/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0163 - mae: 0.0891 - val_loss: 0.0064 - val_mae: 0.0614\n",
      "Epoch 86/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0154 - mae: 0.0845 - val_loss: 0.0051 - val_mae: 0.0561\n",
      "Epoch 87/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0159 - mae: 0.0860 - val_loss: 0.0090 - val_mae: 0.0762\n",
      "Epoch 88/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0155 - mae: 0.0856 - val_loss: 0.0059 - val_mae: 0.0587\n",
      "Epoch 89/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0149 - mae: 0.0831 - val_loss: 0.0095 - val_mae: 0.0772\n",
      "Epoch 90/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0154 - mae: 0.0866 - val_loss: 0.0113 - val_mae: 0.0880\n",
      "Epoch 91/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0161 - mae: 0.0901 - val_loss: 0.0061 - val_mae: 0.0596\n",
      "Epoch 92/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0160 - mae: 0.0870 - val_loss: 0.0057 - val_mae: 0.0582\n",
      "Epoch 93/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0158 - mae: 0.0855 - val_loss: 0.0081 - val_mae: 0.0692\n",
      "Epoch 94/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0158 - mae: 0.0869 - val_loss: 0.0083 - val_mae: 0.0716\n",
      "Epoch 95/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0160 - mae: 0.0856 - val_loss: 0.0116 - val_mae: 0.0887\n",
      "Epoch 96/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0147 - mae: 0.0830 - val_loss: 0.0084 - val_mae: 0.0699\n",
      "Epoch 97/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0158 - mae: 0.0872 - val_loss: 0.0092 - val_mae: 0.0742\n",
      "Epoch 98/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0155 - mae: 0.0868 - val_loss: 0.0073 - val_mae: 0.0664\n",
      "Epoch 99/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0156 - mae: 0.0852 - val_loss: 0.0057 - val_mae: 0.0586\n",
      "Epoch 100/100\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0157 - mae: 0.0854 - val_loss: 0.0109 - val_mae: 0.0834\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step  \n",
      "✅ Done: tomato_Kalburgi_daily.csv | MAE=834.26, RMSE=1170.85, R2=0.57, MAPE=65.44%, Accuracy=34.56%\n",
      "🚀 Processing: tomato_Kolar_daily.csv\n",
      "Epoch 1/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 9ms/step - loss: 0.0120 - mae: 0.0539 - val_loss: 0.0071 - val_mae: 0.0519\n",
      "Epoch 2/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0274 - val_loss: 0.0060 - val_mae: 0.0585\n",
      "Epoch 3/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 0.0013 - mae: 0.0250 - val_loss: 0.0047 - val_mae: 0.0430\n",
      "Epoch 4/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 0.0011 - mae: 0.0234 - val_loss: 0.0038 - val_mae: 0.0439\n",
      "Epoch 5/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 0.0011 - mae: 0.0228 - val_loss: 0.0037 - val_mae: 0.0383\n",
      "Epoch 6/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 9ms/step - loss: 0.0011 - mae: 0.0221 - val_loss: 0.0036 - val_mae: 0.0405\n",
      "Epoch 7/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 0.0010 - mae: 0.0218 - val_loss: 0.0039 - val_mae: 0.0444\n",
      "Epoch 8/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 0.0011 - mae: 0.0219 - val_loss: 0.0036 - val_mae: 0.0392\n",
      "Epoch 9/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 0.0010 - mae: 0.0217 - val_loss: 0.0036 - val_mae: 0.0420\n",
      "Epoch 10/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 0.0010 - mae: 0.0218 - val_loss: 0.0036 - val_mae: 0.0416\n",
      "Epoch 11/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 0.0010 - mae: 0.0215 - val_loss: 0.0038 - val_mae: 0.0385\n",
      "Epoch 12/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 0.0010 - mae: 0.0215 - val_loss: 0.0039 - val_mae: 0.0461\n",
      "Epoch 13/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 0.0010 - mae: 0.0215 - val_loss: 0.0038 - val_mae: 0.0420\n",
      "Epoch 14/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 9ms/step - loss: 0.0010 - mae: 0.0214 - val_loss: 0.0037 - val_mae: 0.0407\n",
      "Epoch 15/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 0.0010 - mae: 0.0215 - val_loss: 0.0039 - val_mae: 0.0423\n",
      "Epoch 16/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 0.0010 - mae: 0.0212 - val_loss: 0.0039 - val_mae: 0.0422\n",
      "Epoch 17/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 0.0010 - mae: 0.0212 - val_loss: 0.0043 - val_mae: 0.0474\n",
      "Epoch 18/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 0.0010 - mae: 0.0212 - val_loss: 0.0041 - val_mae: 0.0432\n",
      "Epoch 19/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 0.0010 - mae: 0.0211 - val_loss: 0.0045 - val_mae: 0.0457\n",
      "Epoch 20/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 0.0010 - mae: 0.0211 - val_loss: 0.0045 - val_mae: 0.0480\n",
      "Epoch 21/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 9.9275e-04 - mae: 0.0209 - val_loss: 0.0047 - val_mae: 0.0438\n",
      "Epoch 22/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 9.9003e-04 - mae: 0.0208 - val_loss: 0.0045 - val_mae: 0.0482\n",
      "Epoch 23/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 9.9133e-04 - mae: 0.0208 - val_loss: 0.0047 - val_mae: 0.0463\n",
      "Epoch 24/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 9.9161e-04 - mae: 0.0208 - val_loss: 0.0044 - val_mae: 0.0480\n",
      "Epoch 25/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 9.8184e-04 - mae: 0.0207 - val_loss: 0.0043 - val_mae: 0.0457\n",
      "Epoch 26/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 9.8041e-04 - mae: 0.0206 - val_loss: 0.0042 - val_mae: 0.0415\n",
      "Epoch 27/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 9.8174e-04 - mae: 0.0206 - val_loss: 0.0043 - val_mae: 0.0451\n",
      "Epoch 28/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 9.7795e-04 - mae: 0.0206 - val_loss: 0.0042 - val_mae: 0.0428\n",
      "Epoch 29/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 9.7821e-04 - mae: 0.0206 - val_loss: 0.0041 - val_mae: 0.0437\n",
      "Epoch 30/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 9.7334e-04 - mae: 0.0206 - val_loss: 0.0041 - val_mae: 0.0449\n",
      "Epoch 31/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 9.7447e-04 - mae: 0.0205 - val_loss: 0.0039 - val_mae: 0.0420\n",
      "Epoch 32/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 9.6824e-04 - mae: 0.0204 - val_loss: 0.0040 - val_mae: 0.0435\n",
      "Epoch 33/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 9.6789e-04 - mae: 0.0204 - val_loss: 0.0040 - val_mae: 0.0429\n",
      "Epoch 34/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 9.6779e-04 - mae: 0.0204 - val_loss: 0.0039 - val_mae: 0.0411\n",
      "Epoch 35/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 9.6595e-04 - mae: 0.0204 - val_loss: 0.0039 - val_mae: 0.0411\n",
      "Epoch 36/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 9.7017e-04 - mae: 0.0204 - val_loss: 0.0038 - val_mae: 0.0432\n",
      "Epoch 37/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 9.6524e-04 - mae: 0.0204 - val_loss: 0.0037 - val_mae: 0.0393\n",
      "Epoch 38/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 9ms/step - loss: 9.7077e-04 - mae: 0.0204 - val_loss: 0.0039 - val_mae: 0.0411\n",
      "Epoch 39/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 9.6815e-04 - mae: 0.0204 - val_loss: 0.0039 - val_mae: 0.0434\n",
      "Epoch 40/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 9.6399e-04 - mae: 0.0203 - val_loss: 0.0038 - val_mae: 0.0417\n",
      "Epoch 41/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 9.6678e-04 - mae: 0.0204 - val_loss: 0.0037 - val_mae: 0.0399\n",
      "Epoch 42/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 9.6751e-04 - mae: 0.0203 - val_loss: 0.0038 - val_mae: 0.0404\n",
      "Epoch 43/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 9.6601e-04 - mae: 0.0204 - val_loss: 0.0037 - val_mae: 0.0414\n",
      "Epoch 44/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 9.6622e-04 - mae: 0.0204 - val_loss: 0.0042 - val_mae: 0.0467\n",
      "Epoch 45/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 9.6479e-04 - mae: 0.0203 - val_loss: 0.0039 - val_mae: 0.0404\n",
      "Epoch 46/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 9.6508e-04 - mae: 0.0204 - val_loss: 0.0040 - val_mae: 0.0394\n",
      "Epoch 47/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 9.6550e-04 - mae: 0.0204 - val_loss: 0.0037 - val_mae: 0.0414\n",
      "Epoch 48/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 9.6314e-04 - mae: 0.0203 - val_loss: 0.0037 - val_mae: 0.0405\n",
      "Epoch 49/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 9.6264e-04 - mae: 0.0204 - val_loss: 0.0038 - val_mae: 0.0395\n",
      "Epoch 50/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 9.6331e-04 - mae: 0.0203 - val_loss: 0.0037 - val_mae: 0.0397\n",
      "Epoch 51/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 9.6047e-04 - mae: 0.0203 - val_loss: 0.0038 - val_mae: 0.0431\n",
      "Epoch 52/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 9ms/step - loss: 9.6129e-04 - mae: 0.0203 - val_loss: 0.0037 - val_mae: 0.0405\n",
      "Epoch 53/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 9.6435e-04 - mae: 0.0204 - val_loss: 0.0039 - val_mae: 0.0415\n",
      "Epoch 54/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 9.6853e-04 - mae: 0.0204 - val_loss: 0.0038 - val_mae: 0.0429\n",
      "Epoch 55/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 9.6184e-04 - mae: 0.0204 - val_loss: 0.0037 - val_mae: 0.0424\n",
      "Epoch 56/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 9.6018e-04 - mae: 0.0203 - val_loss: 0.0037 - val_mae: 0.0420\n",
      "Epoch 57/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 9.6172e-04 - mae: 0.0203 - val_loss: 0.0036 - val_mae: 0.0397\n",
      "Epoch 58/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 9.6149e-04 - mae: 0.0203 - val_loss: 0.0038 - val_mae: 0.0413\n",
      "Epoch 59/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 9.5892e-04 - mae: 0.0203 - val_loss: 0.0038 - val_mae: 0.0417\n",
      "Epoch 60/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 9.6267e-04 - mae: 0.0203 - val_loss: 0.0037 - val_mae: 0.0407\n",
      "Epoch 61/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 9.6045e-04 - mae: 0.0203 - val_loss: 0.0036 - val_mae: 0.0391\n",
      "Epoch 62/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 9.6513e-04 - mae: 0.0203 - val_loss: 0.0038 - val_mae: 0.0418\n",
      "Epoch 63/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 9.6153e-04 - mae: 0.0204 - val_loss: 0.0037 - val_mae: 0.0391\n",
      "Epoch 64/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 9.6335e-04 - mae: 0.0204 - val_loss: 0.0038 - val_mae: 0.0387\n",
      "Epoch 65/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 9.5945e-04 - mae: 0.0203 - val_loss: 0.0038 - val_mae: 0.0411\n",
      "Epoch 66/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 9.5882e-04 - mae: 0.0203 - val_loss: 0.0037 - val_mae: 0.0388\n",
      "Epoch 67/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 9ms/step - loss: 9.6529e-04 - mae: 0.0203 - val_loss: 0.0038 - val_mae: 0.0427\n",
      "Epoch 68/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 9.5787e-04 - mae: 0.0203 - val_loss: 0.0037 - val_mae: 0.0420\n",
      "Epoch 69/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 9.5981e-04 - mae: 0.0203 - val_loss: 0.0036 - val_mae: 0.0394\n",
      "Epoch 70/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 9ms/step - loss: 9.5856e-04 - mae: 0.0202 - val_loss: 0.0037 - val_mae: 0.0411\n",
      "Epoch 71/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 9.5989e-04 - mae: 0.0203 - val_loss: 0.0037 - val_mae: 0.0402\n",
      "Epoch 72/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 9.5912e-04 - mae: 0.0202 - val_loss: 0.0036 - val_mae: 0.0385\n",
      "Epoch 73/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 9.6098e-04 - mae: 0.0203 - val_loss: 0.0038 - val_mae: 0.0431\n",
      "Epoch 74/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 9.5468e-04 - mae: 0.0202 - val_loss: 0.0037 - val_mae: 0.0414\n",
      "Epoch 75/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 9.5876e-04 - mae: 0.0203 - val_loss: 0.0038 - val_mae: 0.0420\n",
      "Epoch 76/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 9.5939e-04 - mae: 0.0203 - val_loss: 0.0036 - val_mae: 0.0409\n",
      "Epoch 77/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 9.5772e-04 - mae: 0.0202 - val_loss: 0.0036 - val_mae: 0.0395\n",
      "Epoch 78/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 9.5774e-04 - mae: 0.0203 - val_loss: 0.0039 - val_mae: 0.0438\n",
      "Epoch 79/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 9.5999e-04 - mae: 0.0202 - val_loss: 0.0036 - val_mae: 0.0393\n",
      "Epoch 80/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - loss: 9.5845e-04 - mae: 0.0203 - val_loss: 0.0038 - val_mae: 0.0409\n",
      "Epoch 81/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 9.6067e-04 - mae: 0.0203 - val_loss: 0.0041 - val_mae: 0.0430\n",
      "Epoch 82/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 9.5879e-04 - mae: 0.0202 - val_loss: 0.0036 - val_mae: 0.0392\n",
      "Epoch 83/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 9.5591e-04 - mae: 0.0202 - val_loss: 0.0038 - val_mae: 0.0410\n",
      "Epoch 84/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 9ms/step - loss: 9.5828e-04 - mae: 0.0203 - val_loss: 0.0036 - val_mae: 0.0397\n",
      "Epoch 85/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 9.5983e-04 - mae: 0.0202 - val_loss: 0.0040 - val_mae: 0.0426\n",
      "Epoch 86/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 9.5897e-04 - mae: 0.0203 - val_loss: 0.0037 - val_mae: 0.0405\n",
      "Epoch 87/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 9.5580e-04 - mae: 0.0202 - val_loss: 0.0036 - val_mae: 0.0393\n",
      "Epoch 88/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 9.5550e-04 - mae: 0.0202 - val_loss: 0.0036 - val_mae: 0.0403\n",
      "Epoch 89/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 9.5527e-04 - mae: 0.0202 - val_loss: 0.0036 - val_mae: 0.0397\n",
      "Epoch 90/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 9.5765e-04 - mae: 0.0202 - val_loss: 0.0039 - val_mae: 0.0430\n",
      "Epoch 91/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 9.5550e-04 - mae: 0.0202 - val_loss: 0.0038 - val_mae: 0.0428\n",
      "Epoch 92/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 9.5858e-04 - mae: 0.0203 - val_loss: 0.0036 - val_mae: 0.0407\n",
      "Epoch 93/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 9.5419e-04 - mae: 0.0202 - val_loss: 0.0036 - val_mae: 0.0386\n",
      "Epoch 94/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 9.5359e-04 - mae: 0.0202 - val_loss: 0.0038 - val_mae: 0.0398\n",
      "Epoch 95/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 9.5594e-04 - mae: 0.0202 - val_loss: 0.0036 - val_mae: 0.0394\n",
      "Epoch 96/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 9.5760e-04 - mae: 0.0202 - val_loss: 0.0036 - val_mae: 0.0399\n",
      "Epoch 97/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 9.5680e-04 - mae: 0.0202 - val_loss: 0.0036 - val_mae: 0.0389\n",
      "Epoch 98/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 9.5513e-04 - mae: 0.0202 - val_loss: 0.0036 - val_mae: 0.0392\n",
      "Epoch 99/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 9.6013e-04 - mae: 0.0203 - val_loss: 0.0036 - val_mae: 0.0396\n",
      "Epoch 100/100\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 9.5509e-04 - mae: 0.0202 - val_loss: 0.0036 - val_mae: 0.0401\n",
      "\u001b[1m1308/1308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step\n",
      "✅ Done: tomato_Kolar_daily.csv | MAE=275.86, RMSE=443.52, R2=0.74, MAPE=26.56%, Accuracy=73.44%\n",
      "🚀 Processing: tomato_MadikeriKodagu_daily.csv\n",
      "Epoch 1/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.1100 - mae: 0.2317 - val_loss: 0.0046 - val_mae: 0.0574\n",
      "Epoch 2/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0516 - mae: 0.1796 - val_loss: 0.0049 - val_mae: 0.0560\n",
      "Epoch 3/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0477 - mae: 0.1727 - val_loss: 0.0097 - val_mae: 0.0855\n",
      "Epoch 4/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0467 - mae: 0.1707 - val_loss: 0.0027 - val_mae: 0.0437\n",
      "Epoch 5/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0471 - mae: 0.1713 - val_loss: 0.0153 - val_mae: 0.1151\n",
      "Epoch 6/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0451 - mae: 0.1670 - val_loss: 0.0041 - val_mae: 0.0520\n",
      "Epoch 7/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0449 - mae: 0.1666 - val_loss: 0.0034 - val_mae: 0.0468\n",
      "Epoch 8/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0442 - mae: 0.1646 - val_loss: 0.0022 - val_mae: 0.0379\n",
      "Epoch 9/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0442 - mae: 0.1646 - val_loss: 0.0031 - val_mae: 0.0437\n",
      "Epoch 10/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0438 - mae: 0.1642 - val_loss: 0.0058 - val_mae: 0.0650\n",
      "Epoch 11/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0441 - mae: 0.1652 - val_loss: 0.0022 - val_mae: 0.0364\n",
      "Epoch 12/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0434 - mae: 0.1626 - val_loss: 0.0017 - val_mae: 0.0321\n",
      "Epoch 13/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0439 - mae: 0.1633 - val_loss: 0.0015 - val_mae: 0.0291\n",
      "Epoch 14/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0429 - mae: 0.1618 - val_loss: 0.0018 - val_mae: 0.0318\n",
      "Epoch 15/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0430 - mae: 0.1623 - val_loss: 0.0035 - val_mae: 0.0532\n",
      "Epoch 16/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0426 - mae: 0.1614 - val_loss: 0.0083 - val_mae: 0.0843\n",
      "Epoch 17/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0427 - mae: 0.1616 - val_loss: 0.0029 - val_mae: 0.0456\n",
      "Epoch 18/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0427 - mae: 0.1619 - val_loss: 9.4013e-04 - val_mae: 0.0197\n",
      "Epoch 19/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0423 - mae: 0.1605 - val_loss: 0.0011 - val_mae: 0.0207\n",
      "Epoch 20/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0422 - mae: 0.1599 - val_loss: 0.0013 - val_mae: 0.0249\n",
      "Epoch 21/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0431 - mae: 0.1627 - val_loss: 0.0057 - val_mae: 0.0700\n",
      "Epoch 22/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0420 - mae: 0.1593 - val_loss: 0.0012 - val_mae: 0.0236\n",
      "Epoch 23/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0422 - mae: 0.1604 - val_loss: 7.6309e-04 - val_mae: 0.0153\n",
      "Epoch 24/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0417 - mae: 0.1588 - val_loss: 0.0011 - val_mae: 0.0206\n",
      "Epoch 25/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0417 - mae: 0.1583 - val_loss: 0.0032 - val_mae: 0.0508\n",
      "Epoch 26/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0420 - mae: 0.1594 - val_loss: 0.0022 - val_mae: 0.0395\n",
      "Epoch 27/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0413 - mae: 0.1572 - val_loss: 8.6527e-04 - val_mae: 0.0168\n",
      "Epoch 28/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0417 - mae: 0.1588 - val_loss: 0.0035 - val_mae: 0.0534\n",
      "Epoch 29/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0417 - mae: 0.1590 - val_loss: 0.0037 - val_mae: 0.0552\n",
      "Epoch 30/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0412 - mae: 0.1582 - val_loss: 0.0021 - val_mae: 0.0383\n",
      "Epoch 31/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0416 - mae: 0.1585 - val_loss: 0.0036 - val_mae: 0.0549\n",
      "Epoch 32/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0413 - mae: 0.1576 - val_loss: 0.0030 - val_mae: 0.0488\n",
      "Epoch 33/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0418 - mae: 0.1591 - val_loss: 0.0064 - val_mae: 0.0767\n",
      "Epoch 34/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0410 - mae: 0.1572 - val_loss: 0.0016 - val_mae: 0.0323\n",
      "Epoch 35/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0410 - mae: 0.1571 - val_loss: 0.0033 - val_mae: 0.0529\n",
      "Epoch 36/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0413 - mae: 0.1584 - val_loss: 0.0170 - val_mae: 0.1283\n",
      "Epoch 37/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0407 - mae: 0.1562 - val_loss: 0.0058 - val_mae: 0.0721\n",
      "Epoch 38/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0407 - mae: 0.1564 - val_loss: 0.0048 - val_mae: 0.0652\n",
      "Epoch 39/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0410 - mae: 0.1578 - val_loss: 6.9113e-04 - val_mae: 0.0179\n",
      "Epoch 40/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0405 - mae: 0.1564 - val_loss: 5.5943e-04 - val_mae: 0.0070\n",
      "Epoch 41/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0408 - mae: 0.1567 - val_loss: 5.3294e-04 - val_mae: 0.0064\n",
      "Epoch 42/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0405 - mae: 0.1561 - val_loss: 0.0096 - val_mae: 0.0952\n",
      "Epoch 43/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0410 - mae: 0.1575 - val_loss: 0.0013 - val_mae: 0.0274\n",
      "Epoch 44/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0412 - mae: 0.1578 - val_loss: 7.0181e-04 - val_mae: 0.0139\n",
      "Epoch 45/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0406 - mae: 0.1566 - val_loss: 0.0052 - val_mae: 0.0666\n",
      "Epoch 46/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0406 - mae: 0.1563 - val_loss: 0.0026 - val_mae: 0.0431\n",
      "Epoch 47/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0406 - mae: 0.1567 - val_loss: 0.0019 - val_mae: 0.0364\n",
      "Epoch 48/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0405 - mae: 0.1558 - val_loss: 0.0210 - val_mae: 0.1412\n",
      "Epoch 49/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0405 - mae: 0.1558 - val_loss: 0.0095 - val_mae: 0.0950\n",
      "Epoch 50/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0404 - mae: 0.1563 - val_loss: 0.0034 - val_mae: 0.0543\n",
      "Epoch 51/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0406 - mae: 0.1565 - val_loss: 0.0062 - val_mae: 0.0751\n",
      "Epoch 52/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0408 - mae: 0.1563 - val_loss: 0.0045 - val_mae: 0.0627\n",
      "Epoch 53/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0407 - mae: 0.1568 - val_loss: 0.0119 - val_mae: 0.1047\n",
      "Epoch 54/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0406 - mae: 0.1567 - val_loss: 0.0030 - val_mae: 0.0491\n",
      "Epoch 55/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0404 - mae: 0.1559 - val_loss: 7.9714e-04 - val_mae: 0.0167\n",
      "Epoch 56/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0404 - mae: 0.1556 - val_loss: 0.0194 - val_mae: 0.1367\n",
      "Epoch 57/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0408 - mae: 0.1574 - val_loss: 0.0082 - val_mae: 0.0866\n",
      "Epoch 58/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0405 - mae: 0.1563 - val_loss: 0.0128 - val_mae: 0.1100\n",
      "Epoch 59/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0405 - mae: 0.1561 - val_loss: 0.0010 - val_mae: 0.0206\n",
      "Epoch 60/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0409 - mae: 0.1570 - val_loss: 0.0036 - val_mae: 0.0547\n",
      "Epoch 61/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0405 - mae: 0.1561 - val_loss: 0.0083 - val_mae: 0.0867\n",
      "Epoch 62/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0406 - mae: 0.1557 - val_loss: 0.0040 - val_mae: 0.0587\n",
      "Epoch 63/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0403 - mae: 0.1558 - val_loss: 0.0202 - val_mae: 0.1397\n",
      "Epoch 64/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0407 - mae: 0.1564 - val_loss: 0.0043 - val_mae: 0.0599\n",
      "Epoch 65/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0405 - mae: 0.1558 - val_loss: 0.0214 - val_mae: 0.1437\n",
      "Epoch 66/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0408 - mae: 0.1568 - val_loss: 0.0091 - val_mae: 0.0926\n",
      "Epoch 67/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0403 - mae: 0.1556 - val_loss: 0.0031 - val_mae: 0.0503\n",
      "Epoch 68/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0404 - mae: 0.1560 - val_loss: 0.0065 - val_mae: 0.0761\n",
      "Epoch 69/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0406 - mae: 0.1560 - val_loss: 0.0066 - val_mae: 0.0773\n",
      "Epoch 70/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0405 - mae: 0.1563 - val_loss: 0.0042 - val_mae: 0.0597\n",
      "Epoch 71/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0402 - mae: 0.1555 - val_loss: 0.0057 - val_mae: 0.0712\n",
      "Epoch 72/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0403 - mae: 0.1552 - val_loss: 0.0013 - val_mae: 0.0274\n",
      "Epoch 73/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0403 - mae: 0.1559 - val_loss: 7.6740e-04 - val_mae: 0.0204\n",
      "Epoch 74/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0408 - mae: 0.1566 - val_loss: 6.8065e-04 - val_mae: 0.0108\n",
      "Epoch 75/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0403 - mae: 0.1550 - val_loss: 8.6922e-04 - val_mae: 0.0167\n",
      "Epoch 76/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0403 - mae: 0.1551 - val_loss: 0.0097 - val_mae: 0.0945\n",
      "Epoch 77/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0407 - mae: 0.1563 - val_loss: 0.0158 - val_mae: 0.1219\n",
      "Epoch 78/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0402 - mae: 0.1554 - val_loss: 7.4099e-04 - val_mae: 0.0142\n",
      "Epoch 79/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0406 - mae: 0.1561 - val_loss: 0.0019 - val_mae: 0.0367\n",
      "Epoch 80/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0403 - mae: 0.1553 - val_loss: 0.0052 - val_mae: 0.0674\n",
      "Epoch 81/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0406 - mae: 0.1560 - val_loss: 0.0126 - val_mae: 0.1077\n",
      "Epoch 82/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0402 - mae: 0.1550 - val_loss: 0.0062 - val_mae: 0.0750\n",
      "Epoch 83/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0403 - mae: 0.1554 - val_loss: 0.0060 - val_mae: 0.0738\n",
      "Epoch 84/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0403 - mae: 0.1553 - val_loss: 6.1049e-04 - val_mae: 0.0073\n",
      "Epoch 85/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0403 - mae: 0.1559 - val_loss: 0.0189 - val_mae: 0.1339\n",
      "Epoch 86/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0405 - mae: 0.1555 - val_loss: 0.0066 - val_mae: 0.0778\n",
      "Epoch 87/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0404 - mae: 0.1553 - val_loss: 0.0040 - val_mae: 0.0587\n",
      "Epoch 88/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0404 - mae: 0.1552 - val_loss: 0.0057 - val_mae: 0.0716\n",
      "Epoch 89/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0404 - mae: 0.1554 - val_loss: 0.0051 - val_mae: 0.0668\n",
      "Epoch 90/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0404 - mae: 0.1552 - val_loss: 0.0061 - val_mae: 0.0741\n",
      "Epoch 91/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0405 - mae: 0.1555 - val_loss: 0.0195 - val_mae: 0.1360\n",
      "Epoch 92/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0407 - mae: 0.1563 - val_loss: 0.0053 - val_mae: 0.0684\n",
      "Epoch 93/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0406 - mae: 0.1561 - val_loss: 0.0056 - val_mae: 0.0704\n",
      "Epoch 94/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0402 - mae: 0.1551 - val_loss: 0.0109 - val_mae: 0.1008\n",
      "Epoch 95/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0401 - mae: 0.1550 - val_loss: 0.0155 - val_mae: 0.1211\n",
      "Epoch 96/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0405 - mae: 0.1562 - val_loss: 0.0122 - val_mae: 0.1071\n",
      "Epoch 97/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0407 - mae: 0.1559 - val_loss: 0.0097 - val_mae: 0.0949\n",
      "Epoch 98/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0400 - mae: 0.1552 - val_loss: 0.0057 - val_mae: 0.0715\n",
      "Epoch 99/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0407 - mae: 0.1559 - val_loss: 0.0098 - val_mae: 0.0957\n",
      "Epoch 100/100\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0404 - mae: 0.1557 - val_loss: 0.0067 - val_mae: 0.0775\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step   \n",
      "✅ Done: tomato_MadikeriKodagu_daily.csv | MAE=241.65, RMSE=315.0, R2=0.44, MAPE=30.92%, Accuracy=69.08%\n",
      "🚀 Processing: tomato_Mandya_daily.csv\n",
      "Epoch 1/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0204 - mae: 0.0688 - val_loss: 0.0116 - val_mae: 0.0636\n",
      "Epoch 2/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0025 - mae: 0.0366 - val_loss: 0.0122 - val_mae: 0.0602\n",
      "Epoch 3/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0019 - mae: 0.0309 - val_loss: 0.0124 - val_mae: 0.0609\n",
      "Epoch 4/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0295 - val_loss: 0.0122 - val_mae: 0.0606\n",
      "Epoch 5/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0017 - mae: 0.0286 - val_loss: 0.0115 - val_mae: 0.0603\n",
      "Epoch 6/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0017 - mae: 0.0286 - val_loss: 0.0118 - val_mae: 0.0594\n",
      "Epoch 7/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0016 - mae: 0.0283 - val_loss: 0.0125 - val_mae: 0.0609\n",
      "Epoch 8/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0016 - mae: 0.0281 - val_loss: 0.0109 - val_mae: 0.0627\n",
      "Epoch 9/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0016 - mae: 0.0282 - val_loss: 0.0117 - val_mae: 0.0604\n",
      "Epoch 10/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0016 - mae: 0.0275 - val_loss: 0.0106 - val_mae: 0.0599\n",
      "Epoch 11/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0016 - mae: 0.0281 - val_loss: 0.0128 - val_mae: 0.0626\n",
      "Epoch 12/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0016 - mae: 0.0274 - val_loss: 0.0106 - val_mae: 0.0588\n",
      "Epoch 13/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0016 - mae: 0.0272 - val_loss: 0.0111 - val_mae: 0.0587\n",
      "Epoch 14/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0016 - mae: 0.0269 - val_loss: 0.0104 - val_mae: 0.0579\n",
      "Epoch 15/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0016 - mae: 0.0274 - val_loss: 0.0114 - val_mae: 0.0591\n",
      "Epoch 16/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0016 - mae: 0.0268 - val_loss: 0.0105 - val_mae: 0.0606\n",
      "Epoch 17/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0016 - mae: 0.0268 - val_loss: 0.0111 - val_mae: 0.0611\n",
      "Epoch 18/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0264 - val_loss: 0.0080 - val_mae: 0.0536\n",
      "Epoch 19/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0263 - val_loss: 0.0080 - val_mae: 0.0532\n",
      "Epoch 20/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0264 - val_loss: 0.0081 - val_mae: 0.0527\n",
      "Epoch 21/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0261 - val_loss: 0.0069 - val_mae: 0.0540\n",
      "Epoch 22/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0261 - val_loss: 0.0077 - val_mae: 0.0525\n",
      "Epoch 23/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0259 - val_loss: 0.0071 - val_mae: 0.0511\n",
      "Epoch 24/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0259 - val_loss: 0.0077 - val_mae: 0.0519\n",
      "Epoch 25/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0259 - val_loss: 0.0066 - val_mae: 0.0509\n",
      "Epoch 26/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0257 - val_loss: 0.0075 - val_mae: 0.0516\n",
      "Epoch 27/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0258 - val_loss: 0.0082 - val_mae: 0.0529\n",
      "Epoch 28/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0258 - val_loss: 0.0063 - val_mae: 0.0513\n",
      "Epoch 29/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 0.0070 - val_mae: 0.0506\n",
      "Epoch 30/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 0.0065 - val_mae: 0.0523\n",
      "Epoch 31/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 0.0067 - val_mae: 0.0506\n",
      "Epoch 32/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0257 - val_loss: 0.0071 - val_mae: 0.0508\n",
      "Epoch 33/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 0.0067 - val_mae: 0.0520\n",
      "Epoch 34/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 0.0065 - val_mae: 0.0531\n",
      "Epoch 35/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0257 - val_loss: 0.0066 - val_mae: 0.0519\n",
      "Epoch 36/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 0.0072 - val_mae: 0.0511\n",
      "Epoch 37/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 0.0065 - val_mae: 0.0511\n",
      "Epoch 38/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 0.0070 - val_mae: 0.0517\n",
      "Epoch 39/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0257 - val_loss: 0.0076 - val_mae: 0.0518\n",
      "Epoch 40/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0067 - val_mae: 0.0517\n",
      "Epoch 41/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 0.0074 - val_mae: 0.0515\n",
      "Epoch 42/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 0.0083 - val_mae: 0.0529\n",
      "Epoch 43/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 0.0075 - val_mae: 0.0516\n",
      "Epoch 44/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 0.0072 - val_mae: 0.0510\n",
      "Epoch 45/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 0.0067 - val_mae: 0.0515\n",
      "Epoch 46/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 0.0072 - val_mae: 0.0514\n",
      "Epoch 47/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0071 - val_mae: 0.0509\n",
      "Epoch 48/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 0.0069 - val_mae: 0.0516\n",
      "Epoch 49/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0069 - val_mae: 0.0510\n",
      "Epoch 50/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 0.0067 - val_mae: 0.0520\n",
      "Epoch 51/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 0.0071 - val_mae: 0.0514\n",
      "Epoch 52/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0068 - val_mae: 0.0522\n",
      "Epoch 53/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0070 - val_mae: 0.0518\n",
      "Epoch 54/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 0.0080 - val_mae: 0.0524\n",
      "Epoch 55/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0071 - val_mae: 0.0520\n",
      "Epoch 56/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 0.0073 - val_mae: 0.0514\n",
      "Epoch 57/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 0.0083 - val_mae: 0.0529\n",
      "Epoch 58/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 0.0075 - val_mae: 0.0519\n",
      "Epoch 59/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 0.0075 - val_mae: 0.0516\n",
      "Epoch 60/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0074 - val_mae: 0.0521\n",
      "Epoch 61/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0074 - val_mae: 0.0515\n",
      "Epoch 62/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 0.0081 - val_mae: 0.0525\n",
      "Epoch 63/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 0.0076 - val_mae: 0.0518\n",
      "Epoch 64/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0069 - val_mae: 0.0527\n",
      "Epoch 65/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0071 - val_mae: 0.0515\n",
      "Epoch 66/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0074 - val_mae: 0.0514\n",
      "Epoch 67/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0076 - val_mae: 0.0519\n",
      "Epoch 68/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0070 - val_mae: 0.0530\n",
      "Epoch 69/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0081 - val_mae: 0.0525\n",
      "Epoch 70/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0086 - val_mae: 0.0535\n",
      "Epoch 71/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0077 - val_mae: 0.0521\n",
      "Epoch 72/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0073 - val_mae: 0.0551\n",
      "Epoch 73/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0072 - val_mae: 0.0521\n",
      "Epoch 74/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0074 - val_mae: 0.0526\n",
      "Epoch 75/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0070 - val_mae: 0.0525\n",
      "Epoch 76/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0072 - val_mae: 0.0530\n",
      "Epoch 77/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0082 - val_mae: 0.0527\n",
      "Epoch 78/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0081 - val_mae: 0.0531\n",
      "Epoch 79/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 0.0076 - val_mae: 0.0531\n",
      "Epoch 80/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0085 - val_mae: 0.0532\n",
      "Epoch 81/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0078 - val_mae: 0.0531\n",
      "Epoch 82/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0082 - val_mae: 0.0532\n",
      "Epoch 83/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0090 - val_mae: 0.0542\n",
      "Epoch 84/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0086 - val_mae: 0.0538\n",
      "Epoch 85/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 0.0086 - val_mae: 0.0534\n",
      "Epoch 86/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0090 - val_mae: 0.0541\n",
      "Epoch 87/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0085 - val_mae: 0.0535\n",
      "Epoch 88/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0090 - val_mae: 0.0542\n",
      "Epoch 89/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0092 - val_mae: 0.0549\n",
      "Epoch 90/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 0.0090 - val_mae: 0.0551\n",
      "Epoch 91/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0100 - val_mae: 0.0557\n",
      "Epoch 92/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0091 - val_mae: 0.0545\n",
      "Epoch 93/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0093 - val_mae: 0.0552\n",
      "Epoch 94/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0098 - val_mae: 0.0559\n",
      "Epoch 95/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0094 - val_mae: 0.0557\n",
      "Epoch 96/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0100 - val_mae: 0.0557\n",
      "Epoch 97/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0106 - val_mae: 0.0569\n",
      "Epoch 98/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0101 - val_mae: 0.0563\n",
      "Epoch 99/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0098 - val_mae: 0.0574\n",
      "Epoch 100/100\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0107 - val_mae: 0.0569\n",
      "\u001b[1m545/545\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step\n",
      "✅ Done: tomato_Mandya_daily.csv | MAE=388.88, RMSE=715.11, R2=0.4, MAPE=58.75%, Accuracy=41.25%\n",
      "🚀 Processing: tomato_Mysore_daily.csv\n",
      "Epoch 1/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - loss: 0.0138 - mae: 0.0617 - val_loss: 0.0046 - val_mae: 0.0431\n",
      "Epoch 2/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0020 - mae: 0.0325 - val_loss: 0.0042 - val_mae: 0.0424\n",
      "Epoch 3/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0297 - val_loss: 0.0040 - val_mae: 0.0428\n",
      "Epoch 4/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0017 - mae: 0.0293 - val_loss: 0.0040 - val_mae: 0.0460\n",
      "Epoch 5/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0017 - mae: 0.0285 - val_loss: 0.0040 - val_mae: 0.0427\n",
      "Epoch 6/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - loss: 0.0017 - mae: 0.0284 - val_loss: 0.0040 - val_mae: 0.0433\n",
      "Epoch 7/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0016 - mae: 0.0275 - val_loss: 0.0038 - val_mae: 0.0428\n",
      "Epoch 8/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - loss: 0.0016 - mae: 0.0272 - val_loss: 0.0038 - val_mae: 0.0426\n",
      "Epoch 9/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - loss: 0.0016 - mae: 0.0269 - val_loss: 0.0039 - val_mae: 0.0424\n",
      "Epoch 10/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0016 - mae: 0.0268 - val_loss: 0.0039 - val_mae: 0.0423\n",
      "Epoch 11/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0264 - val_loss: 0.0038 - val_mae: 0.0424\n",
      "Epoch 12/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0265 - val_loss: 0.0038 - val_mae: 0.0428\n",
      "Epoch 13/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0264 - val_loss: 0.0040 - val_mae: 0.0430\n",
      "Epoch 14/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0261 - val_loss: 0.0037 - val_mae: 0.0430\n",
      "Epoch 15/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0260 - val_loss: 0.0038 - val_mae: 0.0440\n",
      "Epoch 16/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0260 - val_loss: 0.0038 - val_mae: 0.0426\n",
      "Epoch 17/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0259 - val_loss: 0.0042 - val_mae: 0.0425\n",
      "Epoch 18/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0259 - val_loss: 0.0038 - val_mae: 0.0428\n",
      "Epoch 19/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0259 - val_loss: 0.0038 - val_mae: 0.0433\n",
      "Epoch 20/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0257 - val_loss: 0.0040 - val_mae: 0.0424\n",
      "Epoch 21/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0257 - val_loss: 0.0042 - val_mae: 0.0479\n",
      "Epoch 22/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0258 - val_loss: 0.0038 - val_mae: 0.0427\n",
      "Epoch 23/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 0.0038 - val_mae: 0.0427\n",
      "Epoch 24/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 0.0038 - val_mae: 0.0442\n",
      "Epoch 25/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 0.0038 - val_mae: 0.0427\n",
      "Epoch 26/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 0.0038 - val_mae: 0.0435\n",
      "Epoch 27/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0038 - val_mae: 0.0428\n",
      "Epoch 28/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 0.0038 - val_mae: 0.0428\n",
      "Epoch 29/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0040 - val_mae: 0.0429\n",
      "Epoch 30/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 0.0037 - val_mae: 0.0429\n",
      "Epoch 31/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 0.0038 - val_mae: 0.0435\n",
      "Epoch 32/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0038 - val_mae: 0.0426\n",
      "Epoch 33/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0039 - val_mae: 0.0424\n",
      "Epoch 34/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0039 - val_mae: 0.0426\n",
      "Epoch 35/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0038 - val_mae: 0.0426\n",
      "Epoch 36/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0037 - val_mae: 0.0432\n",
      "Epoch 37/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0038 - val_mae: 0.0437\n",
      "Epoch 38/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0038 - val_mae: 0.0427\n",
      "Epoch 39/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0038 - val_mae: 0.0431\n",
      "Epoch 40/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0038 - val_mae: 0.0430\n",
      "Epoch 41/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0038 - val_mae: 0.0433\n",
      "Epoch 42/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0039 - val_mae: 0.0426\n",
      "Epoch 43/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0039 - val_mae: 0.0425\n",
      "Epoch 44/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0038 - val_mae: 0.0434\n",
      "Epoch 45/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0037 - val_mae: 0.0429\n",
      "Epoch 46/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0038 - val_mae: 0.0434\n",
      "Epoch 47/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0038 - val_mae: 0.0435\n",
      "Epoch 48/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0038 - val_mae: 0.0433\n",
      "Epoch 49/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0038 - val_mae: 0.0424\n",
      "Epoch 50/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0038 - val_mae: 0.0429\n",
      "Epoch 51/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0038 - val_mae: 0.0434\n",
      "Epoch 52/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0038 - val_mae: 0.0429\n",
      "Epoch 53/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0037 - val_mae: 0.0431\n",
      "Epoch 54/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0038 - val_mae: 0.0425\n",
      "Epoch 55/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0038 - val_mae: 0.0435\n",
      "Epoch 56/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0037 - val_mae: 0.0431\n",
      "Epoch 57/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0038 - val_mae: 0.0437\n",
      "Epoch 58/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0038 - val_mae: 0.0426\n",
      "Epoch 59/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0037 - val_mae: 0.0432\n",
      "Epoch 60/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0037 - val_mae: 0.0430\n",
      "Epoch 61/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0038 - val_mae: 0.0432\n",
      "Epoch 62/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0038 - val_mae: 0.0434\n",
      "Epoch 63/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0039 - val_mae: 0.0426\n",
      "Epoch 64/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0039 - val_mae: 0.0450\n",
      "Epoch 65/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0039 - val_mae: 0.0425\n",
      "Epoch 66/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0038 - val_mae: 0.0429\n",
      "Epoch 67/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0039 - val_mae: 0.0453\n",
      "Epoch 68/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0038 - val_mae: 0.0425\n",
      "Epoch 69/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0038 - val_mae: 0.0430\n",
      "Epoch 70/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0039 - val_mae: 0.0430\n",
      "Epoch 71/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0043 - val_mae: 0.0484\n",
      "Epoch 72/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0038 - val_mae: 0.0426\n",
      "Epoch 73/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0038 - val_mae: 0.0427\n",
      "Epoch 74/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0038 - val_mae: 0.0443\n",
      "Epoch 75/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0038 - val_mae: 0.0426\n",
      "Epoch 76/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0038 - val_mae: 0.0428\n",
      "Epoch 77/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0038 - val_mae: 0.0426\n",
      "Epoch 78/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0253 - val_loss: 0.0037 - val_mae: 0.0428\n",
      "Epoch 79/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0038 - val_mae: 0.0438\n",
      "Epoch 80/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0038 - val_mae: 0.0424\n",
      "Epoch 81/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0038 - val_mae: 0.0426\n",
      "Epoch 82/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0038 - val_mae: 0.0446\n",
      "Epoch 83/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0037 - val_mae: 0.0430\n",
      "Epoch 84/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0038 - val_mae: 0.0437\n",
      "Epoch 85/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0038 - val_mae: 0.0431\n",
      "Epoch 86/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0038 - val_mae: 0.0425\n",
      "Epoch 87/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0253 - val_loss: 0.0038 - val_mae: 0.0426\n",
      "Epoch 88/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0038 - val_mae: 0.0437\n",
      "Epoch 89/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0253 - val_loss: 0.0038 - val_mae: 0.0429\n",
      "Epoch 90/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0038 - val_mae: 0.0439\n",
      "Epoch 91/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0038 - val_mae: 0.0434\n",
      "Epoch 92/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0038 - val_mae: 0.0436\n",
      "Epoch 93/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0253 - val_loss: 0.0038 - val_mae: 0.0427\n",
      "Epoch 94/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0038 - val_mae: 0.0434\n",
      "Epoch 95/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0038 - val_mae: 0.0439\n",
      "Epoch 96/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0253 - val_loss: 0.0038 - val_mae: 0.0432\n",
      "Epoch 97/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0253 - val_loss: 0.0038 - val_mae: 0.0434\n",
      "Epoch 98/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0042 - val_mae: 0.0478\n",
      "Epoch 99/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0039 - val_mae: 0.0429\n",
      "Epoch 100/100\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0038 - val_mae: 0.0425\n",
      "\u001b[1m855/855\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step\n",
      "✅ Done: tomato_Mysore_daily.csv | MAE=427.66, RMSE=662.22, R2=0.43, MAPE=37.92%, Accuracy=62.08%\n",
      "🚀 Processing: tomato_Shimoga_daily.csv\n",
      "Epoch 1/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.0339 - mae: 0.0922 - val_loss: 0.0054 - val_mae: 0.0431\n",
      "Epoch 2/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0037 - mae: 0.0475 - val_loss: 0.0056 - val_mae: 0.0421\n",
      "Epoch 3/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0023 - mae: 0.0370 - val_loss: 0.0049 - val_mae: 0.0414\n",
      "Epoch 4/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0018 - mae: 0.0314 - val_loss: 0.0057 - val_mae: 0.0453\n",
      "Epoch 5/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0286 - val_loss: 0.0047 - val_mae: 0.0410\n",
      "Epoch 6/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0013 - mae: 0.0256 - val_loss: 0.0048 - val_mae: 0.0467\n",
      "Epoch 7/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0012 - mae: 0.0235 - val_loss: 0.0046 - val_mae: 0.0470\n",
      "Epoch 8/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0012 - mae: 0.0245 - val_loss: 0.0048 - val_mae: 0.0449\n",
      "Epoch 9/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0237 - val_loss: 0.0051 - val_mae: 0.0408\n",
      "Epoch 10/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0011 - mae: 0.0222 - val_loss: 0.0048 - val_mae: 0.0449\n",
      "Epoch 11/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0010 - mae: 0.0219 - val_loss: 0.0054 - val_mae: 0.0530\n",
      "Epoch 12/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0011 - mae: 0.0220 - val_loss: 0.0062 - val_mae: 0.0459\n",
      "Epoch 13/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0011 - mae: 0.0226 - val_loss: 0.0057 - val_mae: 0.0446\n",
      "Epoch 14/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0011 - mae: 0.0222 - val_loss: 0.0063 - val_mae: 0.0520\n",
      "Epoch 15/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0010 - mae: 0.0213 - val_loss: 0.0062 - val_mae: 0.0452\n",
      "Epoch 16/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0010 - mae: 0.0217 - val_loss: 0.0063 - val_mae: 0.0486\n",
      "Epoch 17/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0010 - mae: 0.0210 - val_loss: 0.0079 - val_mae: 0.0543\n",
      "Epoch 18/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0010 - mae: 0.0216 - val_loss: 0.0064 - val_mae: 0.0468\n",
      "Epoch 19/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0011 - mae: 0.0224 - val_loss: 0.0063 - val_mae: 0.0464\n",
      "Epoch 20/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0010 - mae: 0.0214 - val_loss: 0.0063 - val_mae: 0.0462\n",
      "Epoch 21/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 9.8415e-04 - mae: 0.0208 - val_loss: 0.0068 - val_mae: 0.0482\n",
      "Epoch 22/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0010 - mae: 0.0214 - val_loss: 0.0064 - val_mae: 0.0459\n",
      "Epoch 23/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0010 - mae: 0.0212 - val_loss: 0.0063 - val_mae: 0.0456\n",
      "Epoch 24/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 9.2910e-04 - mae: 0.0197 - val_loss: 0.0064 - val_mae: 0.0457\n",
      "Epoch 25/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 9.4152e-04 - mae: 0.0199 - val_loss: 0.0069 - val_mae: 0.0486\n",
      "Epoch 26/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 9.7436e-04 - mae: 0.0206 - val_loss: 0.0064 - val_mae: 0.0460\n",
      "Epoch 27/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0010 - mae: 0.0211 - val_loss: 0.0064 - val_mae: 0.0462\n",
      "Epoch 28/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 9.3689e-04 - mae: 0.0199 - val_loss: 0.0064 - val_mae: 0.0460\n",
      "Epoch 29/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 9.3339e-04 - mae: 0.0199 - val_loss: 0.0068 - val_mae: 0.0473\n",
      "Epoch 30/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 9.3706e-04 - mae: 0.0199 - val_loss: 0.0066 - val_mae: 0.0459\n",
      "Epoch 31/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0010 - mae: 0.0209 - val_loss: 0.0065 - val_mae: 0.0493\n",
      "Epoch 32/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 9.5641e-04 - mae: 0.0204 - val_loss: 0.0066 - val_mae: 0.0466\n",
      "Epoch 33/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 9.3423e-04 - mae: 0.0199 - val_loss: 0.0066 - val_mae: 0.0471\n",
      "Epoch 34/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 9.4356e-04 - mae: 0.0202 - val_loss: 0.0070 - val_mae: 0.0479\n",
      "Epoch 35/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 9.6748e-04 - mae: 0.0205 - val_loss: 0.0067 - val_mae: 0.0471\n",
      "Epoch 36/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 9.1812e-04 - mae: 0.0197 - val_loss: 0.0068 - val_mae: 0.0472\n",
      "Epoch 37/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 9.3297e-04 - mae: 0.0199 - val_loss: 0.0067 - val_mae: 0.0471\n",
      "Epoch 38/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 9.5364e-04 - mae: 0.0200 - val_loss: 0.0069 - val_mae: 0.0486\n",
      "Epoch 39/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 9.1019e-04 - mae: 0.0194 - val_loss: 0.0074 - val_mae: 0.0507\n",
      "Epoch 40/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 9.1470e-04 - mae: 0.0194 - val_loss: 0.0067 - val_mae: 0.0467\n",
      "Epoch 41/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 9.1676e-04 - mae: 0.0193 - val_loss: 0.0074 - val_mae: 0.0520\n",
      "Epoch 42/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 9.2927e-04 - mae: 0.0197 - val_loss: 0.0073 - val_mae: 0.0507\n",
      "Epoch 43/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 9.1023e-04 - mae: 0.0194 - val_loss: 0.0066 - val_mae: 0.0480\n",
      "Epoch 44/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 9.2410e-04 - mae: 0.0197 - val_loss: 0.0070 - val_mae: 0.0481\n",
      "Epoch 45/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 9.3939e-04 - mae: 0.0201 - val_loss: 0.0071 - val_mae: 0.0492\n",
      "Epoch 46/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 9.2067e-04 - mae: 0.0194 - val_loss: 0.0066 - val_mae: 0.0471\n",
      "Epoch 47/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 8.9642e-04 - mae: 0.0190 - val_loss: 0.0068 - val_mae: 0.0482\n",
      "Epoch 48/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 9.0223e-04 - mae: 0.0190 - val_loss: 0.0066 - val_mae: 0.0475\n",
      "Epoch 49/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 9.3441e-04 - mae: 0.0199 - val_loss: 0.0070 - val_mae: 0.0494\n",
      "Epoch 50/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 9.0485e-04 - mae: 0.0190 - val_loss: 0.0066 - val_mae: 0.0474\n",
      "Epoch 51/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 9.0354e-04 - mae: 0.0190 - val_loss: 0.0070 - val_mae: 0.0501\n",
      "Epoch 52/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 9.0638e-04 - mae: 0.0193 - val_loss: 0.0066 - val_mae: 0.0467\n",
      "Epoch 53/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 9.0767e-04 - mae: 0.0195 - val_loss: 0.0072 - val_mae: 0.0511\n",
      "Epoch 54/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 8.9013e-04 - mae: 0.0189 - val_loss: 0.0071 - val_mae: 0.0511\n",
      "Epoch 55/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 8.9138e-04 - mae: 0.0189 - val_loss: 0.0071 - val_mae: 0.0502\n",
      "Epoch 56/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 8.8475e-04 - mae: 0.0187 - val_loss: 0.0070 - val_mae: 0.0496\n",
      "Epoch 57/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 8.8918e-04 - mae: 0.0189 - val_loss: 0.0077 - val_mae: 0.0543\n",
      "Epoch 58/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 9.1894e-04 - mae: 0.0192 - val_loss: 0.0066 - val_mae: 0.0483\n",
      "Epoch 59/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 8.9371e-04 - mae: 0.0188 - val_loss: 0.0065 - val_mae: 0.0482\n",
      "Epoch 60/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 9.1382e-04 - mae: 0.0194 - val_loss: 0.0073 - val_mae: 0.0520\n",
      "Epoch 61/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 8.8175e-04 - mae: 0.0185 - val_loss: 0.0073 - val_mae: 0.0515\n",
      "Epoch 62/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 9.0643e-04 - mae: 0.0191 - val_loss: 0.0067 - val_mae: 0.0484\n",
      "Epoch 63/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 8.9643e-04 - mae: 0.0192 - val_loss: 0.0068 - val_mae: 0.0495\n",
      "Epoch 64/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 8.7985e-04 - mae: 0.0186 - val_loss: 0.0070 - val_mae: 0.0496\n",
      "Epoch 65/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 9.0107e-04 - mae: 0.0191 - val_loss: 0.0066 - val_mae: 0.0483\n",
      "Epoch 66/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 9.0837e-04 - mae: 0.0191 - val_loss: 0.0067 - val_mae: 0.0488\n",
      "Epoch 67/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 8.9177e-04 - mae: 0.0189 - val_loss: 0.0067 - val_mae: 0.0496\n",
      "Epoch 68/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 8.8734e-04 - mae: 0.0191 - val_loss: 0.0076 - val_mae: 0.0550\n",
      "Epoch 69/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 8.9342e-04 - mae: 0.0191 - val_loss: 0.0072 - val_mae: 0.0515\n",
      "Epoch 70/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 8.7809e-04 - mae: 0.0187 - val_loss: 0.0071 - val_mae: 0.0516\n",
      "Epoch 71/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 8.9916e-04 - mae: 0.0191 - val_loss: 0.0067 - val_mae: 0.0491\n",
      "Epoch 72/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 9.0999e-04 - mae: 0.0192 - val_loss: 0.0066 - val_mae: 0.0491\n",
      "Epoch 73/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 8.9321e-04 - mae: 0.0190 - val_loss: 0.0071 - val_mae: 0.0520\n",
      "Epoch 74/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 8.8623e-04 - mae: 0.0188 - val_loss: 0.0069 - val_mae: 0.0496\n",
      "Epoch 75/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 8.7952e-04 - mae: 0.0185 - val_loss: 0.0068 - val_mae: 0.0491\n",
      "Epoch 76/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 8.7778e-04 - mae: 0.0186 - val_loss: 0.0067 - val_mae: 0.0483\n",
      "Epoch 77/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 8.7293e-04 - mae: 0.0186 - val_loss: 0.0071 - val_mae: 0.0513\n",
      "Epoch 78/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 8.8577e-04 - mae: 0.0189 - val_loss: 0.0072 - val_mae: 0.0518\n",
      "Epoch 79/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 8.8366e-04 - mae: 0.0187 - val_loss: 0.0067 - val_mae: 0.0487\n",
      "Epoch 80/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 8.9281e-04 - mae: 0.0192 - val_loss: 0.0068 - val_mae: 0.0494\n",
      "Epoch 81/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 8.9322e-04 - mae: 0.0187 - val_loss: 0.0069 - val_mae: 0.0503\n",
      "Epoch 82/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 8.8388e-04 - mae: 0.0188 - val_loss: 0.0067 - val_mae: 0.0491\n",
      "Epoch 83/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 8.8916e-04 - mae: 0.0190 - val_loss: 0.0069 - val_mae: 0.0500\n",
      "Epoch 84/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 8.7940e-04 - mae: 0.0186 - val_loss: 0.0070 - val_mae: 0.0502\n",
      "Epoch 85/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 8.8545e-04 - mae: 0.0188 - val_loss: 0.0071 - val_mae: 0.0515\n",
      "Epoch 86/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 8.7172e-04 - mae: 0.0186 - val_loss: 0.0072 - val_mae: 0.0520\n",
      "Epoch 87/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 8.9943e-04 - mae: 0.0190 - val_loss: 0.0073 - val_mae: 0.0522\n",
      "Epoch 88/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 8.7031e-04 - mae: 0.0187 - val_loss: 0.0074 - val_mae: 0.0535\n",
      "Epoch 89/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 8.7359e-04 - mae: 0.0186 - val_loss: 0.0072 - val_mae: 0.0522\n",
      "Epoch 90/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 8.7784e-04 - mae: 0.0186 - val_loss: 0.0070 - val_mae: 0.0506\n",
      "Epoch 91/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 8.9746e-04 - mae: 0.0189 - val_loss: 0.0070 - val_mae: 0.0507\n",
      "Epoch 92/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 8.6750e-04 - mae: 0.0185 - val_loss: 0.0070 - val_mae: 0.0509\n",
      "Epoch 93/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 8.7877e-04 - mae: 0.0187 - val_loss: 0.0073 - val_mae: 0.0524\n",
      "Epoch 94/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 8.7095e-04 - mae: 0.0184 - val_loss: 0.0072 - val_mae: 0.0516\n",
      "Epoch 95/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 8.5833e-04 - mae: 0.0182 - val_loss: 0.0071 - val_mae: 0.0508\n",
      "Epoch 96/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 8.8756e-04 - mae: 0.0188 - val_loss: 0.0068 - val_mae: 0.0497\n",
      "Epoch 97/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 8.7544e-04 - mae: 0.0184 - val_loss: 0.0069 - val_mae: 0.0502\n",
      "Epoch 98/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 8.6623e-04 - mae: 0.0184 - val_loss: 0.0070 - val_mae: 0.0508\n",
      "Epoch 99/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 8.7075e-04 - mae: 0.0184 - val_loss: 0.0071 - val_mae: 0.0506\n",
      "Epoch 100/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 8.5627e-04 - mae: 0.0183 - val_loss: 0.0072 - val_mae: 0.0506\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n",
      "✅ Done: tomato_Shimoga_daily.csv | MAE=439.57, RMSE=811.26, R2=0.32, MAPE=65.69%, Accuracy=34.31%\n",
      "🚀 Processing: tomato_Tumkur_daily.csv\n",
      "Epoch 1/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 0.0669 - mae: 0.1190 - val_loss: 0.0551 - val_mae: 0.1764\n",
      "Epoch 2/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0062 - mae: 0.0623 - val_loss: 0.0453 - val_mae: 0.1599\n",
      "Epoch 3/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0045 - mae: 0.0533 - val_loss: 0.0402 - val_mae: 0.1514\n",
      "Epoch 4/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0032 - mae: 0.0442 - val_loss: 0.0407 - val_mae: 0.1529\n",
      "Epoch 5/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0023 - mae: 0.0372 - val_loss: 0.0414 - val_mae: 0.1511\n",
      "Epoch 6/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0017 - mae: 0.0318 - val_loss: 0.0398 - val_mae: 0.1501\n",
      "Epoch 7/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0013 - mae: 0.0277 - val_loss: 0.0432 - val_mae: 0.1568\n",
      "Epoch 8/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0011 - mae: 0.0255 - val_loss: 0.0428 - val_mae: 0.1544\n",
      "Epoch 9/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 9.9946e-04 - mae: 0.0233 - val_loss: 0.0321 - val_mae: 0.1372\n",
      "Epoch 10/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 8.7708e-04 - mae: 0.0215 - val_loss: 0.0418 - val_mae: 0.1517\n",
      "Epoch 11/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 8.4940e-04 - mae: 0.0210 - val_loss: 0.0376 - val_mae: 0.1430\n",
      "Epoch 12/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 7.1638e-04 - mae: 0.0186 - val_loss: 0.0351 - val_mae: 0.1383\n",
      "Epoch 13/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 6.4203e-04 - mae: 0.0172 - val_loss: 0.0252 - val_mae: 0.1232\n",
      "Epoch 14/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 6.5026e-04 - mae: 0.0177 - val_loss: 0.0266 - val_mae: 0.1197\n",
      "Epoch 15/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 5.9903e-04 - mae: 0.0168 - val_loss: 0.0258 - val_mae: 0.1238\n",
      "Epoch 16/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 5.9907e-04 - mae: 0.0166 - val_loss: 0.0290 - val_mae: 0.1270\n",
      "Epoch 17/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 5.6083e-04 - mae: 0.0159 - val_loss: 0.0311 - val_mae: 0.1325\n",
      "Epoch 18/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 5.7191e-04 - mae: 0.0162 - val_loss: 0.0187 - val_mae: 0.1069\n",
      "Epoch 19/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 5.8038e-04 - mae: 0.0166 - val_loss: 0.0315 - val_mae: 0.1334\n",
      "Epoch 20/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 5.0074e-04 - mae: 0.0145 - val_loss: 0.0246 - val_mae: 0.1189\n",
      "Epoch 21/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 5.7096e-04 - mae: 0.0165 - val_loss: 0.0295 - val_mae: 0.1292\n",
      "Epoch 22/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 5.0979e-04 - mae: 0.0149 - val_loss: 0.0193 - val_mae: 0.1052\n",
      "Epoch 23/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 4.6894e-04 - mae: 0.0141 - val_loss: 0.0213 - val_mae: 0.1101\n",
      "Epoch 24/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 5.0208e-04 - mae: 0.0149 - val_loss: 0.0178 - val_mae: 0.1004\n",
      "Epoch 25/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 4.6906e-04 - mae: 0.0140 - val_loss: 0.0228 - val_mae: 0.1121\n",
      "Epoch 26/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 4.6181e-04 - mae: 0.0139 - val_loss: 0.0238 - val_mae: 0.1161\n",
      "Epoch 27/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 4.4986e-04 - mae: 0.0135 - val_loss: 0.0118 - val_mae: 0.0841\n",
      "Epoch 28/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 5.5793e-04 - mae: 0.0165 - val_loss: 0.0193 - val_mae: 0.1040\n",
      "Epoch 29/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 4.4213e-04 - mae: 0.0135 - val_loss: 0.0111 - val_mae: 0.0766\n",
      "Epoch 30/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 4.3436e-04 - mae: 0.0134 - val_loss: 0.0112 - val_mae: 0.0789\n",
      "Epoch 31/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 4.8816e-04 - mae: 0.0149 - val_loss: 0.0099 - val_mae: 0.0740\n",
      "Epoch 32/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 4.2959e-04 - mae: 0.0132 - val_loss: 0.0112 - val_mae: 0.0799\n",
      "Epoch 33/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 4.8456e-04 - mae: 0.0146 - val_loss: 0.0066 - val_mae: 0.0568\n",
      "Epoch 34/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 4.4639e-04 - mae: 0.0141 - val_loss: 0.0113 - val_mae: 0.0826\n",
      "Epoch 35/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 4.4598e-04 - mae: 0.0140 - val_loss: 0.0047 - val_mae: 0.0438\n",
      "Epoch 36/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 4.2294e-04 - mae: 0.0134 - val_loss: 0.0084 - val_mae: 0.0669\n",
      "Epoch 37/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 4.2491e-04 - mae: 0.0134 - val_loss: 0.0125 - val_mae: 0.0842\n",
      "Epoch 38/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 4.2662e-04 - mae: 0.0134 - val_loss: 0.0146 - val_mae: 0.0923\n",
      "Epoch 39/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 4.3418e-04 - mae: 0.0137 - val_loss: 0.0099 - val_mae: 0.0761\n",
      "Epoch 40/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 4.4511e-04 - mae: 0.0140 - val_loss: 0.0050 - val_mae: 0.0461\n",
      "Epoch 41/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 4.3851e-04 - mae: 0.0136 - val_loss: 0.0102 - val_mae: 0.0757\n",
      "Epoch 42/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 4.3363e-04 - mae: 0.0137 - val_loss: 0.0062 - val_mae: 0.0539\n",
      "Epoch 43/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 4.1794e-04 - mae: 0.0130 - val_loss: 0.0050 - val_mae: 0.0417\n",
      "Epoch 44/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 3.9698e-04 - mae: 0.0125 - val_loss: 0.0045 - val_mae: 0.0218\n",
      "Epoch 45/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 4.0096e-04 - mae: 0.0128 - val_loss: 0.0056 - val_mae: 0.0300\n",
      "Epoch 46/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 4.5222e-04 - mae: 0.0143 - val_loss: 0.0061 - val_mae: 0.0547\n",
      "Epoch 47/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 4.1648e-04 - mae: 0.0131 - val_loss: 0.0049 - val_mae: 0.0428\n",
      "Epoch 48/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 4.0671e-04 - mae: 0.0130 - val_loss: 0.0094 - val_mae: 0.0746\n",
      "Epoch 49/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 4.0317e-04 - mae: 0.0127 - val_loss: 0.0063 - val_mae: 0.0558\n",
      "Epoch 50/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 4.0774e-04 - mae: 0.0127 - val_loss: 0.0061 - val_mae: 0.0546\n",
      "Epoch 51/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 4.1406e-04 - mae: 0.0131 - val_loss: 0.0092 - val_mae: 0.0744\n",
      "Epoch 52/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 4.2697e-04 - mae: 0.0132 - val_loss: 0.0048 - val_mae: 0.0427\n",
      "Epoch 53/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 4.3544e-04 - mae: 0.0135 - val_loss: 0.0042 - val_mae: 0.0366\n",
      "Epoch 54/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 4.0762e-04 - mae: 0.0128 - val_loss: 0.0041 - val_mae: 0.0264\n",
      "Epoch 55/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 4.1248e-04 - mae: 0.0129 - val_loss: 0.0046 - val_mae: 0.0397\n",
      "Epoch 56/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 3.9504e-04 - mae: 0.0125 - val_loss: 0.0054 - val_mae: 0.0500\n",
      "Epoch 57/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 3.9836e-04 - mae: 0.0128 - val_loss: 0.0078 - val_mae: 0.0668\n",
      "Epoch 58/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 3.8603e-04 - mae: 0.0123 - val_loss: 0.0046 - val_mae: 0.0392\n",
      "Epoch 59/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 4.0746e-04 - mae: 0.0131 - val_loss: 0.0042 - val_mae: 0.0356\n",
      "Epoch 60/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 3.8951e-04 - mae: 0.0126 - val_loss: 0.0042 - val_mae: 0.0249\n",
      "Epoch 61/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 4.3486e-04 - mae: 0.0138 - val_loss: 0.0043 - val_mae: 0.0249\n",
      "Epoch 62/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 4.0844e-04 - mae: 0.0132 - val_loss: 0.0049 - val_mae: 0.0436\n",
      "Epoch 63/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 4.1537e-04 - mae: 0.0131 - val_loss: 0.0044 - val_mae: 0.0350\n",
      "Epoch 64/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 3.8961e-04 - mae: 0.0120 - val_loss: 0.0050 - val_mae: 0.0465\n",
      "Epoch 65/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 4.1712e-04 - mae: 0.0131 - val_loss: 0.0051 - val_mae: 0.0301\n",
      "Epoch 66/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 4.1944e-04 - mae: 0.0132 - val_loss: 0.0053 - val_mae: 0.0307\n",
      "Epoch 67/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 3.9561e-04 - mae: 0.0125 - val_loss: 0.0046 - val_mae: 0.0429\n",
      "Epoch 68/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 3.6551e-04 - mae: 0.0113 - val_loss: 0.0041 - val_mae: 0.0302\n",
      "Epoch 69/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 3.9492e-04 - mae: 0.0123 - val_loss: 0.0052 - val_mae: 0.0496\n",
      "Epoch 70/100\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 4.2374e-04 - mae: 0.0133 - val_loss: 0.0044 - val_mae: 0.0389\n",
      "Epoch 71/100\n",
      "\u001b[1m125/276\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 4.0058e-04 - mae: 0.0121"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "import joblib  # For saving models as .pkl\n",
    "\n",
    "# -----------------------------\n",
    "# Suppress Warnings\n",
    "# -----------------------------\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "pd.options.mode.chained_assignment = None  # Avoid SettingWithCopyWarning\n",
    "\n",
    "# -----------------------------\n",
    "# Output directories\n",
    "# -----------------------------\n",
    "input_folder = \"dataset\"\n",
    "output_models = \"tat_gqa_output_models\"\n",
    "output_csv = \"tat_gqa_output_csv\"\n",
    "output_graphs = \"tat_gqa_output_graphs\"\n",
    "output_logs = \"tat_gqa_output_logs\"\n",
    "metrics_file = \"tat_gqa_metrics.csv\"\n",
    "\n",
    "for folder in [output_models, output_csv, output_graphs, output_logs]:\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Function to create dataset\n",
    "# -----------------------------\n",
    "def create_dataset(data, look_back=30):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - look_back):\n",
    "        X.append(data[i:i + look_back, 0])\n",
    "        y.append(data[i + look_back, 0])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# -----------------------------\n",
    "# Grouped Query Attention Layer\n",
    "# -----------------------------\n",
    "class GroupedQueryAttention(layers.Layer):\n",
    "    def __init__(self, num_groups=2, key_dim=64, dropout_rate=0.1, **kwargs):\n",
    "        super(GroupedQueryAttention, self).__init__(**kwargs)\n",
    "        self.num_groups = num_groups\n",
    "        self.key_dim = key_dim\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.k_dense = layers.Dense(key_dim)\n",
    "        self.v_dense = layers.Dense(key_dim)\n",
    "        self.q_dense_groups = [layers.Dense(key_dim) for _ in range(num_groups)]\n",
    "        self.dropout = layers.Dropout(dropout_rate)\n",
    "        self.output_dense = layers.Dense(key_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        K = self.k_dense(x)\n",
    "        V = self.v_dense(x)\n",
    "        group_outputs = []\n",
    "        for q_layer in self.q_dense_groups:\n",
    "            Q = q_layer(x)\n",
    "            scores = tf.matmul(Q, K, transpose_b=True) / tf.math.sqrt(tf.cast(self.key_dim, tf.float32))\n",
    "            attention_weights = tf.nn.softmax(scores, axis=-1)\n",
    "            attn_output = tf.matmul(attention_weights, V)\n",
    "            group_outputs.append(attn_output)\n",
    "        concat = tf.concat(group_outputs, axis=-1)\n",
    "        output = self.output_dense(concat)\n",
    "        output = self.dropout(output)\n",
    "        return output\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(GroupedQueryAttention, self).get_config()\n",
    "        config.update({\n",
    "            \"num_groups\": self.num_groups,\n",
    "            \"key_dim\": self.key_dim,\n",
    "            \"dropout_rate\": self.dropout_rate\n",
    "        })\n",
    "        return config\n",
    "\n",
    "# -----------------------------\n",
    "# TAT-GQA Model\n",
    "# -----------------------------\n",
    "def build_tat_gqa_model(input_shape, d_model=64, num_groups=2, ff_dim=128, dropout_rate=0.2):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = GroupedQueryAttention(num_groups=num_groups, key_dim=d_model, dropout_rate=dropout_rate)(inputs)\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x + inputs)\n",
    "    ff = layers.Dense(ff_dim, activation='relu')(x)\n",
    "    ff = layers.Dense(input_shape[1])(ff)\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x + ff)\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    outputs = layers.Dense(1)(x)\n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=0.001),\n",
    "                  loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# -----------------------------\n",
    "# Metrics storage\n",
    "# -----------------------------\n",
    "metrics_list = []\n",
    "\n",
    "# -----------------------------\n",
    "# Training Configuration\n",
    "# -----------------------------\n",
    "look_back = 30\n",
    "epochs = 100\n",
    "batch_size = 16\n",
    "\n",
    "# -----------------------------\n",
    "# Process each CSV file\n",
    "# -----------------------------\n",
    "for file in os.listdir(input_folder):\n",
    "    if not file.endswith(\".csv\"):\n",
    "        continue\n",
    "\n",
    "    file_path = os.path.join(input_folder, file)\n",
    "    print(f\"🚀 Processing: {file}\")\n",
    "\n",
    "    # Load CSV\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to read {file}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Parse dates safely (no infer_datetime_format)\n",
    "    df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "    df = df.dropna(subset=['Date']).sort_values('Date')\n",
    "\n",
    "    # Check if column exists\n",
    "    if 'Average Price' not in df.columns:\n",
    "        print(f\"⚠️ Skipping {file}: 'Average Price' column not found.\")\n",
    "        continue\n",
    "\n",
    "    # Handle missing price values\n",
    "    df['Average Price'] = df['Average Price'].fillna(df['Average Price'].mean())\n",
    "\n",
    "    # Moving averages (for visualization only)\n",
    "    df['MA_7'] = df['Average Price'].rolling(window=7).mean().fillna(df['Average Price'].mean())\n",
    "    df['MA_30'] = df['Average Price'].rolling(window=30).mean().fillna(df['Average Price'].mean())\n",
    "\n",
    "    # Prepare scaled data\n",
    "    values = df[['Average Price']].astype('float32').values\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_values = scaler.fit_transform(values)\n",
    "    X, y = create_dataset(scaled_values, look_back)\n",
    "    X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
    "\n",
    "    # Build and train model\n",
    "    model = build_tat_gqa_model(input_shape=(look_back, 1))\n",
    "    history = model.fit(\n",
    "        X, y,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_split=0.2,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Save training log\n",
    "    log_file = os.path.join(output_logs, file.replace(\".csv\", \"_tat_gqa_training.txt\"))\n",
    "    with open(log_file, \"w\") as f:\n",
    "        f.write(\"Epoch\\tLoss\\tVal_Loss\\n\")\n",
    "        for i in range(len(history.history['loss'])):\n",
    "            f.write(f\"{i+1}\\t{history.history['loss'][i]:.6f}\\t{history.history['val_loss'][i]:.6f}\\n\")\n",
    "\n",
    "    # Predictions\n",
    "    predictions = model.predict(X)\n",
    "    predictions_rescaled = scaler.inverse_transform(predictions)\n",
    "    df['Predicted'] = [np.nan] * look_back + list(predictions_rescaled.flatten())\n",
    "\n",
    "    # Round values for clean output\n",
    "    df['Average Price'] = df['Average Price'].round(2)\n",
    "    df['Predicted'] = df['Predicted'].round(2)\n",
    "\n",
    "    # Metrics Calculation\n",
    "    y_true = df['Average Price'].values[look_back:]\n",
    "    y_pred = predictions_rescaled.flatten()\n",
    "\n",
    "    # Avoid division by zero or NaN in MAPE\n",
    "    mask = y_true != 0\n",
    "    if np.any(mask):\n",
    "        mape = np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100\n",
    "    else:\n",
    "        mape = 0.0\n",
    "\n",
    "    mae = round(mean_absolute_error(y_true, y_pred), 2)\n",
    "    rmse = round(np.sqrt(mean_squared_error(y_true, y_pred)), 2)\n",
    "    r2 = round(r2_score(y_true, y_pred), 2)\n",
    "    mape = round(mape, 2)\n",
    "    accuracy = round(100 - mape, 2)\n",
    "\n",
    "    metrics_list.append([file.replace(\".csv\", \"\"), mae, rmse, r2, mape, accuracy])\n",
    "\n",
    "    # Save model as .pkl\n",
    "    model_file = os.path.join(output_models, file.replace(\".csv\", \"_tat_gqa_model.pkl\"))\n",
    "    joblib.dump(model, model_file)\n",
    "\n",
    "    # Save predictions to CSV\n",
    "    save_df = df[['Date', 'Average Price', 'Predicted']].rename(columns={'Average Price': 'Actual'})\n",
    "    updated_csv_path = os.path.join(output_csv, file.replace(\".csv\", \"_tat_gqa_updated.csv\"))\n",
    "    save_df.to_csv(updated_csv_path, index=False)\n",
    "\n",
    "    # Plot Graph\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(df['Date'], df['Average Price'], label='Actual', color='blue')\n",
    "    plt.plot(df['Date'], df['MA_7'], label='MA 7', color='orange')\n",
    "    plt.plot(df['Date'], df['MA_30'], label='MA 30', color='green')\n",
    "    plt.plot(df['Date'], df['Predicted'], label='Predicted (TAT-GQA)', color='red', linestyle='dashed')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Price')\n",
    "    plt.title(f'Price Prediction (TAT-GQA) - {file}')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    graph_file = os.path.join(output_graphs, file.replace(\".csv\", \"_tat_gqa_graph.png\"))\n",
    "    plt.savefig(graph_file)\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"✅ Done: {file} | MAE={mae}, RMSE={rmse}, R2={r2}, MAPE={mape}%, Accuracy={accuracy}%\")\n",
    "\n",
    "# -----------------------------\n",
    "# Save Metrics\n",
    "# -----------------------------\n",
    "metrics_df = pd.DataFrame(metrics_list, columns=['District', 'MAE', 'RMSE', 'R2', 'MAPE(%)', 'Accuracy(%)'])\n",
    "metrics_df.to_csv(metrics_file, index=False)\n",
    "print(f\"📊 All metrics saved to: {metrics_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8025e866-4dbe-418e-8255-b7dbfe24ac3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TAT+HA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "903db5b5-f9f7-4c52-9736-39dee5d9c8f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2092/2092 - 30s - 14ms/step - loss: 9.6616e-04 - mae: 0.0204 - val_loss: 0.0039 - val_mae: 0.0391\n",
      "Epoch 50/50\n",
      "2092/2092 - 31s - 15ms/step - loss: 9.6764e-04 - mae: 0.0204 - val_loss: 0.0039 - val_mae: 0.0395\n",
      "✅ Done with tomato_Kolar_daily.csv | MAE=271.06, RMSE=446.48, R2=0.74, MAPE=25.54%, Accuracy=74.46%\n",
      "\n",
      "🚀 Processing: tomato_MadikeriKodagu_daily.csv\n",
      "Epoch 1/50\n",
      "253/253 - 11s - 44ms/step - loss: 0.0721 - mae: 0.2085 - val_loss: 0.0185 - val_mae: 0.1221\n",
      "Epoch 2/50\n",
      "253/253 - 3s - 11ms/step - loss: 0.0495 - mae: 0.1763 - val_loss: 0.0080 - val_mae: 0.0756\n",
      "Epoch 3/50\n",
      "253/253 - 4s - 18ms/step - loss: 0.0462 - mae: 0.1688 - val_loss: 0.0043 - val_mae: 0.0576\n",
      "Epoch 4/50\n",
      "253/253 - 3s - 11ms/step - loss: 0.0465 - mae: 0.1688 - val_loss: 0.0024 - val_mae: 0.0374\n",
      "Epoch 5/50\n",
      "253/253 - 4s - 16ms/step - loss: 0.0443 - mae: 0.1651 - val_loss: 0.0055 - val_mae: 0.0663\n",
      "Epoch 6/50\n",
      "253/253 - 4s - 14ms/step - loss: 0.0440 - mae: 0.1639 - val_loss: 0.0023 - val_mae: 0.0362\n",
      "Epoch 7/50\n",
      "253/253 - 3s - 12ms/step - loss: 0.0445 - mae: 0.1652 - val_loss: 0.0015 - val_mae: 0.0300\n",
      "Epoch 8/50\n",
      "253/253 - 3s - 10ms/step - loss: 0.0448 - mae: 0.1654 - val_loss: 0.0093 - val_mae: 0.0923\n",
      "Epoch 9/50\n",
      "253/253 - 4s - 16ms/step - loss: 0.0439 - mae: 0.1646 - val_loss: 0.0037 - val_mae: 0.0540\n",
      "Epoch 10/50\n",
      "253/253 - 5s - 20ms/step - loss: 0.0431 - mae: 0.1618 - val_loss: 0.0043 - val_mae: 0.0577\n",
      "Epoch 11/50\n",
      "253/253 - 3s - 10ms/step - loss: 0.0432 - mae: 0.1616 - val_loss: 0.0102 - val_mae: 0.0969\n",
      "Epoch 12/50\n",
      "253/253 - 4s - 17ms/step - loss: 0.0440 - mae: 0.1639 - val_loss: 0.0085 - val_mae: 0.0880\n",
      "Epoch 13/50\n",
      "253/253 - 4s - 17ms/step - loss: 0.0435 - mae: 0.1630 - val_loss: 0.0077 - val_mae: 0.0832\n",
      "Epoch 14/50\n",
      "253/253 - 3s - 11ms/step - loss: 0.0426 - mae: 0.1603 - val_loss: 0.0011 - val_mae: 0.0199\n",
      "Epoch 15/50\n",
      "253/253 - 3s - 10ms/step - loss: 0.0435 - mae: 0.1630 - val_loss: 0.0371 - val_mae: 0.1905\n",
      "Epoch 16/50\n",
      "253/253 - 5s - 19ms/step - loss: 0.0426 - mae: 0.1608 - val_loss: 0.0011 - val_mae: 0.0219\n",
      "Epoch 17/50\n",
      "253/253 - 5s - 18ms/step - loss: 0.0425 - mae: 0.1608 - val_loss: 0.0187 - val_mae: 0.1342\n",
      "Epoch 18/50\n",
      "253/253 - 3s - 14ms/step - loss: 0.0433 - mae: 0.1622 - val_loss: 0.0018 - val_mae: 0.0311\n",
      "Epoch 19/50\n",
      "253/253 - 3s - 12ms/step - loss: 0.0420 - mae: 0.1593 - val_loss: 0.0032 - val_mae: 0.0503\n",
      "Epoch 20/50\n",
      "253/253 - 5s - 19ms/step - loss: 0.0425 - mae: 0.1610 - val_loss: 0.0014 - val_mae: 0.0270\n",
      "Epoch 21/50\n",
      "253/253 - 4s - 17ms/step - loss: 0.0435 - mae: 0.1634 - val_loss: 0.0188 - val_mae: 0.1342\n",
      "Epoch 22/50\n",
      "253/253 - 3s - 10ms/step - loss: 0.0427 - mae: 0.1604 - val_loss: 0.0016 - val_mae: 0.0287\n",
      "Epoch 23/50\n",
      "253/253 - 5s - 19ms/step - loss: 0.0427 - mae: 0.1607 - val_loss: 8.0423e-04 - val_mae: 0.0130\n",
      "Epoch 24/50\n",
      "253/253 - 4s - 17ms/step - loss: 0.0423 - mae: 0.1594 - val_loss: 0.0013 - val_mae: 0.0236\n",
      "Epoch 25/50\n",
      "253/253 - 5s - 18ms/step - loss: 0.0426 - mae: 0.1609 - val_loss: 0.0015 - val_mae: 0.0262\n",
      "Epoch 26/50\n",
      "253/253 - 4s - 15ms/step - loss: 0.0426 - mae: 0.1604 - val_loss: 0.0019 - val_mae: 0.0325\n",
      "Epoch 27/50\n",
      "253/253 - 4s - 17ms/step - loss: 0.0421 - mae: 0.1593 - val_loss: 0.0020 - val_mae: 0.0332\n",
      "Epoch 28/50\n",
      "253/253 - 3s - 11ms/step - loss: 0.0427 - mae: 0.1613 - val_loss: 0.0016 - val_mae: 0.0283\n",
      "Epoch 29/50\n",
      "253/253 - 4s - 16ms/step - loss: 0.0423 - mae: 0.1600 - val_loss: 0.0011 - val_mae: 0.0236\n",
      "Epoch 30/50\n",
      "253/253 - 5s - 20ms/step - loss: 0.0425 - mae: 0.1609 - val_loss: 0.0053 - val_mae: 0.0671\n",
      "Epoch 31/50\n",
      "253/253 - 5s - 19ms/step - loss: 0.0425 - mae: 0.1601 - val_loss: 0.0053 - val_mae: 0.0680\n",
      "Epoch 32/50\n",
      "253/253 - 3s - 12ms/step - loss: 0.0423 - mae: 0.1597 - val_loss: 0.0017 - val_mae: 0.0297\n",
      "Epoch 33/50\n",
      "253/253 - 3s - 10ms/step - loss: 0.0426 - mae: 0.1602 - val_loss: 0.0097 - val_mae: 0.0951\n",
      "Epoch 34/50\n",
      "253/253 - 3s - 11ms/step - loss: 0.0419 - mae: 0.1593 - val_loss: 0.0015 - val_mae: 0.0275\n",
      "Epoch 35/50\n",
      "253/253 - 3s - 10ms/step - loss: 0.0420 - mae: 0.1584 - val_loss: 0.0128 - val_mae: 0.1099\n",
      "Epoch 36/50\n",
      "253/253 - 4s - 16ms/step - loss: 0.0424 - mae: 0.1604 - val_loss: 0.0042 - val_mae: 0.0582\n",
      "Epoch 37/50\n",
      "253/253 - 5s - 20ms/step - loss: 0.0424 - mae: 0.1603 - val_loss: 0.0015 - val_mae: 0.0292\n",
      "Epoch 38/50\n",
      "253/253 - 4s - 17ms/step - loss: 0.0418 - mae: 0.1582 - val_loss: 0.0014 - val_mae: 0.0263\n",
      "Epoch 39/50\n",
      "253/253 - 4s - 15ms/step - loss: 0.0419 - mae: 0.1588 - val_loss: 0.0046 - val_mae: 0.0626\n",
      "Epoch 40/50\n",
      "253/253 - 2s - 10ms/step - loss: 0.0422 - mae: 0.1602 - val_loss: 0.0051 - val_mae: 0.0651\n",
      "Epoch 41/50\n",
      "253/253 - 4s - 15ms/step - loss: 0.0421 - mae: 0.1598 - val_loss: 0.0108 - val_mae: 0.0997\n",
      "Epoch 42/50\n",
      "253/253 - 4s - 17ms/step - loss: 0.0419 - mae: 0.1591 - val_loss: 0.0024 - val_mae: 0.0406\n",
      "Epoch 43/50\n",
      "253/253 - 4s - 15ms/step - loss: 0.0424 - mae: 0.1595 - val_loss: 7.8261e-04 - val_mae: 0.0141\n",
      "Epoch 44/50\n",
      "253/253 - 3s - 10ms/step - loss: 0.0421 - mae: 0.1587 - val_loss: 0.0063 - val_mae: 0.0745\n",
      "Epoch 45/50\n",
      "253/253 - 3s - 10ms/step - loss: 0.0418 - mae: 0.1580 - val_loss: 0.0013 - val_mae: 0.0239\n",
      "Epoch 46/50\n",
      "253/253 - 3s - 10ms/step - loss: 0.0423 - mae: 0.1598 - val_loss: 0.0010 - val_mae: 0.0225\n",
      "Epoch 47/50\n",
      "253/253 - 5s - 18ms/step - loss: 0.0423 - mae: 0.1600 - val_loss: 0.0042 - val_mae: 0.0584\n",
      "Epoch 48/50\n",
      "253/253 - 2s - 9ms/step - loss: 0.0416 - mae: 0.1583 - val_loss: 0.0030 - val_mae: 0.0469\n",
      "Epoch 49/50\n",
      "253/253 - 3s - 10ms/step - loss: 0.0422 - mae: 0.1593 - val_loss: 0.0042 - val_mae: 0.0585\n",
      "Epoch 50/50\n",
      "253/253 - 4s - 16ms/step - loss: 0.0417 - mae: 0.1587 - val_loss: 0.0055 - val_mae: 0.0690\n",
      "✅ Done with tomato_MadikeriKodagu_daily.csv | MAE=247.04, RMSE=322.07, R2=0.42, MAPE=31.56%, Accuracy=68.44%\n",
      "\n",
      "🚀 Processing: tomato_Mandya_daily.csv\n",
      "Epoch 1/50\n",
      "872/872 - 16s - 18ms/step - loss: 0.0159 - mae: 0.0626 - val_loss: 0.0140 - val_mae: 0.0655\n",
      "Epoch 2/50\n",
      "872/872 - 16s - 19ms/step - loss: 0.0023 - mae: 0.0347 - val_loss: 0.0123 - val_mae: 0.0608\n",
      "Epoch 3/50\n",
      "872/872 - 16s - 19ms/step - loss: 0.0020 - mae: 0.0326 - val_loss: 0.0148 - val_mae: 0.0656\n",
      "Epoch 4/50\n",
      "872/872 - 11s - 13ms/step - loss: 0.0018 - mae: 0.0302 - val_loss: 0.0136 - val_mae: 0.0631\n",
      "Epoch 5/50\n",
      "872/872 - 9s - 11ms/step - loss: 0.0018 - mae: 0.0299 - val_loss: 0.0120 - val_mae: 0.0634\n",
      "Epoch 6/50\n",
      "872/872 - 11s - 12ms/step - loss: 0.0017 - mae: 0.0288 - val_loss: 0.0118 - val_mae: 0.0599\n",
      "Epoch 7/50\n",
      "872/872 - 17s - 19ms/step - loss: 0.0017 - mae: 0.0288 - val_loss: 0.0121 - val_mae: 0.0624\n",
      "Epoch 8/50\n",
      "872/872 - 15s - 17ms/step - loss: 0.0016 - mae: 0.0281 - val_loss: 0.0120 - val_mae: 0.0602\n",
      "Epoch 9/50\n",
      "872/872 - 14s - 16ms/step - loss: 0.0016 - mae: 0.0281 - val_loss: 0.0121 - val_mae: 0.0611\n",
      "Epoch 10/50\n",
      "872/872 - 15s - 17ms/step - loss: 0.0016 - mae: 0.0275 - val_loss: 0.0099 - val_mae: 0.0619\n",
      "Epoch 11/50\n",
      "872/872 - 12s - 14ms/step - loss: 0.0017 - mae: 0.0285 - val_loss: 0.0100 - val_mae: 0.0566\n",
      "Epoch 12/50\n",
      "872/872 - 15s - 17ms/step - loss: 0.0016 - mae: 0.0278 - val_loss: 0.0110 - val_mae: 0.0578\n",
      "Epoch 13/50\n",
      "872/872 - 16s - 19ms/step - loss: 0.0016 - mae: 0.0274 - val_loss: 0.0087 - val_mae: 0.0594\n",
      "Epoch 14/50\n",
      "872/872 - 11s - 13ms/step - loss: 0.0016 - mae: 0.0270 - val_loss: 0.0085 - val_mae: 0.0607\n",
      "Epoch 15/50\n",
      "872/872 - 16s - 18ms/step - loss: 0.0016 - mae: 0.0273 - val_loss: 0.0081 - val_mae: 0.0530\n",
      "Epoch 16/50\n",
      "872/872 - 15s - 17ms/step - loss: 0.0016 - mae: 0.0271 - val_loss: 0.0089 - val_mae: 0.0540\n",
      "Epoch 17/50\n",
      "872/872 - 17s - 19ms/step - loss: 0.0015 - mae: 0.0268 - val_loss: 0.0081 - val_mae: 0.0529\n",
      "Epoch 18/50\n",
      "872/872 - 16s - 18ms/step - loss: 0.0015 - mae: 0.0268 - val_loss: 0.0081 - val_mae: 0.0574\n",
      "Epoch 19/50\n",
      "872/872 - 15s - 17ms/step - loss: 0.0015 - mae: 0.0268 - val_loss: 0.0078 - val_mae: 0.0524\n",
      "Epoch 20/50\n",
      "872/872 - 16s - 18ms/step - loss: 0.0015 - mae: 0.0268 - val_loss: 0.0103 - val_mae: 0.0577\n",
      "Epoch 21/50\n",
      "872/872 - 16s - 18ms/step - loss: 0.0015 - mae: 0.0262 - val_loss: 0.0089 - val_mae: 0.0540\n",
      "Epoch 22/50\n",
      "872/872 - 15s - 18ms/step - loss: 0.0015 - mae: 0.0265 - val_loss: 0.0083 - val_mae: 0.0535\n",
      "Epoch 23/50\n",
      "872/872 - 15s - 18ms/step - loss: 0.0015 - mae: 0.0260 - val_loss: 0.0092 - val_mae: 0.0546\n",
      "Epoch 24/50\n",
      "872/872 - 16s - 19ms/step - loss: 0.0015 - mae: 0.0262 - val_loss: 0.0088 - val_mae: 0.0542\n",
      "Epoch 25/50\n",
      "872/872 - 14s - 16ms/step - loss: 0.0015 - mae: 0.0261 - val_loss: 0.0095 - val_mae: 0.0551\n",
      "Epoch 26/50\n",
      "872/872 - 16s - 19ms/step - loss: 0.0015 - mae: 0.0259 - val_loss: 0.0081 - val_mae: 0.0529\n",
      "Epoch 27/50\n",
      "872/872 - 15s - 17ms/step - loss: 0.0015 - mae: 0.0259 - val_loss: 0.0089 - val_mae: 0.0542\n",
      "Epoch 28/50\n",
      "872/872 - 14s - 16ms/step - loss: 0.0015 - mae: 0.0257 - val_loss: 0.0080 - val_mae: 0.0535\n",
      "Epoch 29/50\n",
      "872/872 - 16s - 18ms/step - loss: 0.0015 - mae: 0.0259 - val_loss: 0.0105 - val_mae: 0.0569\n",
      "Epoch 30/50\n",
      "872/872 - 15s - 17ms/step - loss: 0.0015 - mae: 0.0257 - val_loss: 0.0085 - val_mae: 0.0540\n",
      "Epoch 31/50\n",
      "872/872 - 16s - 19ms/step - loss: 0.0015 - mae: 0.0257 - val_loss: 0.0110 - val_mae: 0.0577\n",
      "Epoch 32/50\n",
      "872/872 - 13s - 15ms/step - loss: 0.0015 - mae: 0.0257 - val_loss: 0.0101 - val_mae: 0.0564\n",
      "Epoch 33/50\n",
      "872/872 - 13s - 15ms/step - loss: 0.0015 - mae: 0.0257 - val_loss: 0.0094 - val_mae: 0.0558\n",
      "Epoch 34/50\n",
      "872/872 - 15s - 17ms/step - loss: 0.0015 - mae: 0.0257 - val_loss: 0.0107 - val_mae: 0.0574\n",
      "Epoch 35/50\n",
      "872/872 - 16s - 18ms/step - loss: 0.0015 - mae: 0.0257 - val_loss: 0.0096 - val_mae: 0.0553\n",
      "Epoch 36/50\n",
      "872/872 - 16s - 19ms/step - loss: 0.0015 - mae: 0.0257 - val_loss: 0.0092 - val_mae: 0.0547\n",
      "Epoch 37/50\n",
      "872/872 - 14s - 16ms/step - loss: 0.0015 - mae: 0.0258 - val_loss: 0.0089 - val_mae: 0.0540\n",
      "Epoch 38/50\n",
      "872/872 - 10s - 12ms/step - loss: 0.0015 - mae: 0.0257 - val_loss: 0.0108 - val_mae: 0.0574\n",
      "Epoch 39/50\n",
      "872/872 - 16s - 18ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 0.0116 - val_mae: 0.0588\n",
      "Epoch 40/50\n",
      "872/872 - 14s - 16ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 0.0099 - val_mae: 0.0562\n",
      "Epoch 41/50\n",
      "872/872 - 11s - 12ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 0.0094 - val_mae: 0.0551\n",
      "Epoch 42/50\n",
      "872/872 - 14s - 16ms/step - loss: 0.0015 - mae: 0.0257 - val_loss: 0.0092 - val_mae: 0.0545\n",
      "Epoch 43/50\n",
      "872/872 - 14s - 16ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0110 - val_mae: 0.0579\n",
      "Epoch 44/50\n",
      "872/872 - 15s - 17ms/step - loss: 0.0015 - mae: 0.0257 - val_loss: 0.0093 - val_mae: 0.0552\n",
      "Epoch 45/50\n",
      "872/872 - 14s - 16ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0091 - val_mae: 0.0550\n",
      "Epoch 46/50\n",
      "872/872 - 14s - 16ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 0.0100 - val_mae: 0.0559\n",
      "Epoch 47/50\n",
      "872/872 - 17s - 19ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 0.0088 - val_mae: 0.0538\n",
      "Epoch 48/50\n",
      "872/872 - 16s - 18ms/step - loss: 0.0015 - mae: 0.0257 - val_loss: 0.0103 - val_mae: 0.0567\n",
      "Epoch 49/50\n",
      "872/872 - 15s - 17ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 0.0100 - val_mae: 0.0562\n",
      "Epoch 50/50\n",
      "872/872 - 14s - 17ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 0.0097 - val_mae: 0.0555\n",
      "✅ Done with tomato_Mandya_daily.csv | MAE=393.28, RMSE=696.52, R2=0.43, MAPE=58.33%, Accuracy=41.67%\n",
      "\n",
      "🚀 Processing: tomato_Mysore_daily.csv\n",
      "Epoch 1/50\n",
      "1367/1367 - 28s - 20ms/step - loss: 0.0139 - mae: 0.0548 - val_loss: 0.0048 - val_mae: 0.0431\n",
      "Epoch 2/50\n",
      "1367/1367 - 25s - 19ms/step - loss: 0.0021 - mae: 0.0328 - val_loss: 0.0042 - val_mae: 0.0462\n",
      "Epoch 3/50\n",
      "1367/1367 - 20s - 15ms/step - loss: 0.0018 - mae: 0.0305 - val_loss: 0.0041 - val_mae: 0.0439\n",
      "Epoch 4/50\n",
      "1367/1367 - 25s - 18ms/step - loss: 0.0017 - mae: 0.0293 - val_loss: 0.0040 - val_mae: 0.0444\n",
      "Epoch 5/50\n",
      "1367/1367 - 21s - 15ms/step - loss: 0.0016 - mae: 0.0282 - val_loss: 0.0040 - val_mae: 0.0421\n",
      "Epoch 6/50\n",
      "1367/1367 - 25s - 18ms/step - loss: 0.0016 - mae: 0.0277 - val_loss: 0.0044 - val_mae: 0.0503\n",
      "Epoch 7/50\n",
      "1367/1367 - 25s - 18ms/step - loss: 0.0016 - mae: 0.0273 - val_loss: 0.0041 - val_mae: 0.0429\n",
      "Epoch 8/50\n",
      "1367/1367 - 25s - 18ms/step - loss: 0.0016 - mae: 0.0269 - val_loss: 0.0048 - val_mae: 0.0462\n",
      "Epoch 9/50\n",
      "1367/1367 - 24s - 18ms/step - loss: 0.0016 - mae: 0.0270 - val_loss: 0.0037 - val_mae: 0.0431\n",
      "Epoch 10/50\n",
      "1367/1367 - 16s - 12ms/step - loss: 0.0015 - mae: 0.0265 - val_loss: 0.0039 - val_mae: 0.0441\n",
      "Epoch 11/50\n",
      "1367/1367 - 21s - 15ms/step - loss: 0.0015 - mae: 0.0264 - val_loss: 0.0047 - val_mae: 0.0461\n",
      "Epoch 12/50\n",
      "1367/1367 - 23s - 17ms/step - loss: 0.0015 - mae: 0.0261 - val_loss: 0.0038 - val_mae: 0.0430\n",
      "Epoch 13/50\n",
      "1367/1367 - 25s - 18ms/step - loss: 0.0015 - mae: 0.0260 - val_loss: 0.0039 - val_mae: 0.0424\n",
      "Epoch 14/50\n",
      "1367/1367 - 22s - 16ms/step - loss: 0.0015 - mae: 0.0259 - val_loss: 0.0039 - val_mae: 0.0422\n",
      "Epoch 15/50\n",
      "1367/1367 - 24s - 18ms/step - loss: 0.0015 - mae: 0.0259 - val_loss: 0.0040 - val_mae: 0.0422\n",
      "Epoch 16/50\n",
      "1367/1367 - 22s - 16ms/step - loss: 0.0015 - mae: 0.0259 - val_loss: 0.0040 - val_mae: 0.0425\n",
      "Epoch 17/50\n",
      "1367/1367 - 20s - 15ms/step - loss: 0.0015 - mae: 0.0257 - val_loss: 0.0038 - val_mae: 0.0424\n",
      "Epoch 18/50\n",
      "1367/1367 - 22s - 16ms/step - loss: 0.0015 - mae: 0.0258 - val_loss: 0.0038 - val_mae: 0.0438\n",
      "Epoch 19/50\n",
      "1367/1367 - 21s - 15ms/step - loss: 0.0015 - mae: 0.0257 - val_loss: 0.0039 - val_mae: 0.0427\n",
      "Epoch 20/50\n",
      "1367/1367 - 25s - 18ms/step - loss: 0.0015 - mae: 0.0257 - val_loss: 0.0043 - val_mae: 0.0480\n",
      "Epoch 21/50\n",
      "1367/1367 - 24s - 18ms/step - loss: 0.0015 - mae: 0.0257 - val_loss: 0.0038 - val_mae: 0.0434\n",
      "Epoch 22/50\n",
      "1367/1367 - 22s - 16ms/step - loss: 0.0015 - mae: 0.0257 - val_loss: 0.0038 - val_mae: 0.0437\n",
      "Epoch 23/50\n",
      "1367/1367 - 24s - 17ms/step - loss: 0.0015 - mae: 0.0257 - val_loss: 0.0039 - val_mae: 0.0424\n",
      "Epoch 24/50\n",
      "1367/1367 - 22s - 16ms/step - loss: 0.0015 - mae: 0.0257 - val_loss: 0.0038 - val_mae: 0.0425\n",
      "Epoch 25/50\n",
      "1367/1367 - 17s - 12ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 0.0039 - val_mae: 0.0425\n",
      "Epoch 26/50\n",
      "1367/1367 - 23s - 17ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 0.0038 - val_mae: 0.0434\n",
      "Epoch 27/50\n",
      "1367/1367 - 23s - 17ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 0.0039 - val_mae: 0.0429\n",
      "Epoch 28/50\n",
      "1367/1367 - 23s - 17ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 0.0038 - val_mae: 0.0425\n",
      "Epoch 29/50\n",
      "1367/1367 - 24s - 18ms/step - loss: 0.0015 - mae: 0.0257 - val_loss: 0.0043 - val_mae: 0.0477\n",
      "Epoch 30/50\n",
      "1367/1367 - 25s - 18ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 0.0038 - val_mae: 0.0426\n",
      "Epoch 31/50\n",
      "1367/1367 - 23s - 17ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 0.0038 - val_mae: 0.0425\n",
      "Epoch 32/50\n",
      "1367/1367 - 23s - 17ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 0.0037 - val_mae: 0.0431\n",
      "Epoch 33/50\n",
      "1367/1367 - 25s - 18ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 0.0038 - val_mae: 0.0430\n",
      "Epoch 34/50\n",
      "1367/1367 - 21s - 15ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0038 - val_mae: 0.0430\n",
      "Epoch 35/50\n",
      "1367/1367 - 25s - 18ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0038 - val_mae: 0.0435\n",
      "Epoch 36/50\n",
      "1367/1367 - 22s - 16ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 0.0037 - val_mae: 0.0431\n",
      "Epoch 37/50\n",
      "1367/1367 - 20s - 14ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 0.0038 - val_mae: 0.0434\n",
      "Epoch 38/50\n",
      "1367/1367 - 25s - 19ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0038 - val_mae: 0.0427\n",
      "Epoch 39/50\n",
      "1367/1367 - 23s - 17ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 0.0039 - val_mae: 0.0449\n",
      "Epoch 40/50\n",
      "1367/1367 - 23s - 17ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 0.0038 - val_mae: 0.0431\n",
      "Epoch 41/50\n",
      "1367/1367 - 22s - 16ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0038 - val_mae: 0.0442\n",
      "Epoch 42/50\n",
      "1367/1367 - 24s - 17ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 0.0037 - val_mae: 0.0430\n",
      "Epoch 43/50\n",
      "1367/1367 - 23s - 17ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0038 - val_mae: 0.0426\n",
      "Epoch 44/50\n",
      "1367/1367 - 25s - 18ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 0.0038 - val_mae: 0.0428\n",
      "Epoch 45/50\n",
      "1367/1367 - 21s - 15ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0038 - val_mae: 0.0432\n",
      "Epoch 46/50\n",
      "1367/1367 - 21s - 15ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0037 - val_mae: 0.0429\n",
      "Epoch 47/50\n",
      "1367/1367 - 19s - 14ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0038 - val_mae: 0.0443\n",
      "Epoch 48/50\n",
      "1367/1367 - 26s - 19ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 0.0038 - val_mae: 0.0424\n",
      "Epoch 49/50\n",
      "1367/1367 - 24s - 18ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0037 - val_mae: 0.0430\n",
      "Epoch 50/50\n",
      "1367/1367 - 26s - 19ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 0.0038 - val_mae: 0.0434\n",
      "✅ Done with tomato_Mysore_daily.csv | MAE=441.09, RMSE=661.83, R2=0.43, MAPE=40.98%, Accuracy=59.02%\n",
      "\n",
      "🚀 Processing: tomato_Shimoga_daily.csv\n",
      "Epoch 1/50\n",
      "418/418 - 10s - 25ms/step - loss: 0.0320 - mae: 0.0835 - val_loss: 0.0062 - val_mae: 0.0475\n",
      "Epoch 2/50\n",
      "418/418 - 7s - 16ms/step - loss: 0.0025 - mae: 0.0378 - val_loss: 0.0056 - val_mae: 0.0445\n",
      "Epoch 3/50\n",
      "418/418 - 8s - 19ms/step - loss: 0.0017 - mae: 0.0305 - val_loss: 0.0052 - val_mae: 0.0420\n",
      "Epoch 4/50\n",
      "418/418 - 8s - 19ms/step - loss: 0.0016 - mae: 0.0291 - val_loss: 0.0051 - val_mae: 0.0410\n",
      "Epoch 5/50\n",
      "418/418 - 4s - 10ms/step - loss: 0.0013 - mae: 0.0261 - val_loss: 0.0050 - val_mae: 0.0496\n",
      "Epoch 6/50\n",
      "418/418 - 7s - 18ms/step - loss: 0.0013 - mae: 0.0250 - val_loss: 0.0048 - val_mae: 0.0443\n",
      "Epoch 7/50\n",
      "418/418 - 8s - 20ms/step - loss: 0.0011 - mae: 0.0232 - val_loss: 0.0048 - val_mae: 0.0467\n",
      "Epoch 8/50\n",
      "418/418 - 8s - 20ms/step - loss: 0.0011 - mae: 0.0226 - val_loss: 0.0047 - val_mae: 0.0430\n",
      "Epoch 9/50\n",
      "418/418 - 4s - 10ms/step - loss: 0.0011 - mae: 0.0226 - val_loss: 0.0047 - val_mae: 0.0398\n",
      "Epoch 10/50\n",
      "418/418 - 8s - 19ms/step - loss: 0.0011 - mae: 0.0233 - val_loss: 0.0071 - val_mae: 0.0544\n",
      "Epoch 11/50\n",
      "418/418 - 7s - 16ms/step - loss: 0.0010 - mae: 0.0219 - val_loss: 0.0047 - val_mae: 0.0405\n",
      "Epoch 12/50\n",
      "418/418 - 4s - 10ms/step - loss: 9.9841e-04 - mae: 0.0210 - val_loss: 0.0051 - val_mae: 0.0408\n",
      "Epoch 13/50\n",
      "418/418 - 7s - 17ms/step - loss: 9.9993e-04 - mae: 0.0211 - val_loss: 0.0049 - val_mae: 0.0404\n",
      "Epoch 14/50\n",
      "418/418 - 6s - 15ms/step - loss: 9.9156e-04 - mae: 0.0209 - val_loss: 0.0056 - val_mae: 0.0442\n",
      "Epoch 15/50\n",
      "418/418 - 8s - 18ms/step - loss: 0.0011 - mae: 0.0225 - val_loss: 0.0047 - val_mae: 0.0414\n",
      "Epoch 16/50\n",
      "418/418 - 8s - 18ms/step - loss: 9.8755e-04 - mae: 0.0206 - val_loss: 0.0061 - val_mae: 0.0480\n",
      "Epoch 17/50\n",
      "418/418 - 7s - 17ms/step - loss: 9.9264e-04 - mae: 0.0210 - val_loss: 0.0049 - val_mae: 0.0409\n",
      "Epoch 18/50\n",
      "418/418 - 6s - 14ms/step - loss: 9.4516e-04 - mae: 0.0200 - val_loss: 0.0058 - val_mae: 0.0452\n",
      "Epoch 19/50\n",
      "418/418 - 8s - 20ms/step - loss: 9.4491e-04 - mae: 0.0199 - val_loss: 0.0049 - val_mae: 0.0412\n",
      "Epoch 20/50\n",
      "418/418 - 7s - 17ms/step - loss: 9.6272e-04 - mae: 0.0205 - val_loss: 0.0050 - val_mae: 0.0474\n",
      "Epoch 21/50\n",
      "418/418 - 8s - 19ms/step - loss: 9.9722e-04 - mae: 0.0210 - val_loss: 0.0048 - val_mae: 0.0437\n",
      "Epoch 22/50\n",
      "418/418 - 7s - 18ms/step - loss: 9.7652e-04 - mae: 0.0207 - val_loss: 0.0048 - val_mae: 0.0444\n",
      "Epoch 23/50\n",
      "418/418 - 6s - 14ms/step - loss: 9.6234e-04 - mae: 0.0202 - val_loss: 0.0056 - val_mae: 0.0435\n",
      "Epoch 24/50\n",
      "418/418 - 8s - 19ms/step - loss: 9.4379e-04 - mae: 0.0201 - val_loss: 0.0053 - val_mae: 0.0445\n",
      "Epoch 25/50\n",
      "418/418 - 6s - 15ms/step - loss: 9.5785e-04 - mae: 0.0200 - val_loss: 0.0049 - val_mae: 0.0429\n",
      "Epoch 26/50\n",
      "418/418 - 7s - 17ms/step - loss: 9.4041e-04 - mae: 0.0199 - val_loss: 0.0050 - val_mae: 0.0420\n",
      "Epoch 27/50\n",
      "418/418 - 8s - 18ms/step - loss: 9.3012e-04 - mae: 0.0195 - val_loss: 0.0059 - val_mae: 0.0451\n",
      "Epoch 28/50\n",
      "418/418 - 5s - 12ms/step - loss: 9.7587e-04 - mae: 0.0204 - val_loss: 0.0051 - val_mae: 0.0453\n",
      "Epoch 29/50\n",
      "418/418 - 6s - 15ms/step - loss: 9.3341e-04 - mae: 0.0198 - val_loss: 0.0052 - val_mae: 0.0432\n",
      "Epoch 30/50\n",
      "418/418 - 7s - 17ms/step - loss: 9.1905e-04 - mae: 0.0192 - val_loss: 0.0053 - val_mae: 0.0428\n",
      "Epoch 31/50\n",
      "418/418 - 7s - 18ms/step - loss: 9.1922e-04 - mae: 0.0194 - val_loss: 0.0056 - val_mae: 0.0441\n",
      "Epoch 32/50\n",
      "418/418 - 6s - 15ms/step - loss: 9.2169e-04 - mae: 0.0193 - val_loss: 0.0058 - val_mae: 0.0450\n",
      "Epoch 33/50\n",
      "418/418 - 4s - 10ms/step - loss: 9.5189e-04 - mae: 0.0202 - val_loss: 0.0052 - val_mae: 0.0454\n",
      "Epoch 34/50\n",
      "418/418 - 7s - 18ms/step - loss: 9.2453e-04 - mae: 0.0196 - val_loss: 0.0052 - val_mae: 0.0436\n",
      "Epoch 35/50\n",
      "418/418 - 8s - 18ms/step - loss: 9.2588e-04 - mae: 0.0193 - val_loss: 0.0052 - val_mae: 0.0429\n",
      "Epoch 36/50\n",
      "418/418 - 5s - 12ms/step - loss: 9.1053e-04 - mae: 0.0189 - val_loss: 0.0055 - val_mae: 0.0451\n",
      "Epoch 37/50\n",
      "418/418 - 6s - 15ms/step - loss: 9.2963e-04 - mae: 0.0195 - val_loss: 0.0057 - val_mae: 0.0454\n",
      "Epoch 38/50\n",
      "418/418 - 8s - 20ms/step - loss: 9.2136e-04 - mae: 0.0194 - val_loss: 0.0058 - val_mae: 0.0452\n",
      "Epoch 39/50\n",
      "418/418 - 6s - 15ms/step - loss: 9.1752e-04 - mae: 0.0193 - val_loss: 0.0056 - val_mae: 0.0458\n",
      "Epoch 40/50\n",
      "418/418 - 6s - 14ms/step - loss: 9.2809e-04 - mae: 0.0196 - val_loss: 0.0053 - val_mae: 0.0434\n",
      "Epoch 41/50\n",
      "418/418 - 4s - 9ms/step - loss: 8.9971e-04 - mae: 0.0189 - val_loss: 0.0058 - val_mae: 0.0455\n",
      "Epoch 42/50\n",
      "418/418 - 7s - 17ms/step - loss: 9.1859e-04 - mae: 0.0193 - val_loss: 0.0054 - val_mae: 0.0439\n",
      "Epoch 43/50\n",
      "418/418 - 5s - 13ms/step - loss: 9.2028e-04 - mae: 0.0193 - val_loss: 0.0054 - val_mae: 0.0445\n",
      "Epoch 44/50\n",
      "418/418 - 7s - 16ms/step - loss: 9.1633e-04 - mae: 0.0193 - val_loss: 0.0052 - val_mae: 0.0438\n",
      "Epoch 45/50\n",
      "418/418 - 8s - 19ms/step - loss: 8.9916e-04 - mae: 0.0189 - val_loss: 0.0058 - val_mae: 0.0486\n",
      "Epoch 46/50\n",
      "418/418 - 8s - 18ms/step - loss: 9.0278e-04 - mae: 0.0191 - val_loss: 0.0053 - val_mae: 0.0437\n",
      "Epoch 47/50\n",
      "418/418 - 4s - 10ms/step - loss: 9.0716e-04 - mae: 0.0192 - val_loss: 0.0054 - val_mae: 0.0449\n",
      "Epoch 48/50\n",
      "418/418 - 7s - 16ms/step - loss: 9.1177e-04 - mae: 0.0192 - val_loss: 0.0053 - val_mae: 0.0448\n",
      "Epoch 49/50\n",
      "418/418 - 4s - 10ms/step - loss: 9.1463e-04 - mae: 0.0193 - val_loss: 0.0066 - val_mae: 0.0496\n",
      "Epoch 50/50\n",
      "418/418 - 7s - 17ms/step - loss: 9.1867e-04 - mae: 0.0192 - val_loss: 0.0053 - val_mae: 0.0439\n",
      "✅ Done with tomato_Shimoga_daily.csv | MAE=407.07, RMSE=737.67, R2=0.44, MAPE=60.92%, Accuracy=39.08%\n",
      "\n",
      "🚀 Processing: tomato_Tumkur_daily.csv\n",
      "Epoch 1/50\n",
      "276/276 - 15s - 55ms/step - loss: 0.1431 - mae: 0.1417 - val_loss: 0.0571 - val_mae: 0.1806\n",
      "Epoch 2/50\n",
      "276/276 - 11s - 40ms/step - loss: 0.0036 - mae: 0.0476 - val_loss: 0.0550 - val_mae: 0.1775\n",
      "Epoch 3/50\n",
      "276/276 - 12s - 42ms/step - loss: 0.0031 - mae: 0.0435 - val_loss: 0.0341 - val_mae: 0.1487\n",
      "Epoch 4/50\n",
      "276/276 - 11s - 41ms/step - loss: 0.0023 - mae: 0.0367 - val_loss: 0.0481 - val_mae: 0.1648\n",
      "Epoch 5/50\n",
      "276/276 - 11s - 41ms/step - loss: 0.0017 - mae: 0.0324 - val_loss: 0.0655 - val_mae: 0.2034\n",
      "Epoch 6/50\n",
      "276/276 - 11s - 41ms/step - loss: 0.0014 - mae: 0.0287 - val_loss: 0.0646 - val_mae: 0.2002\n",
      "Epoch 7/50\n",
      "276/276 - 12s - 42ms/step - loss: 0.0012 - mae: 0.0264 - val_loss: 0.0574 - val_mae: 0.1806\n",
      "Epoch 8/50\n",
      "276/276 - 12s - 42ms/step - loss: 9.1637e-04 - mae: 0.0225 - val_loss: 0.0544 - val_mae: 0.1749\n",
      "Epoch 9/50\n",
      "276/276 - 12s - 42ms/step - loss: 0.0010 - mae: 0.0240 - val_loss: 0.0495 - val_mae: 0.1686\n",
      "Epoch 10/50\n",
      "276/276 - 12s - 42ms/step - loss: 7.8465e-04 - mae: 0.0206 - val_loss: 0.0554 - val_mae: 0.1770\n",
      "Epoch 11/50\n",
      "276/276 - 12s - 42ms/step - loss: 9.5808e-04 - mae: 0.0232 - val_loss: 0.0491 - val_mae: 0.1655\n",
      "Epoch 12/50\n",
      "276/276 - 12s - 42ms/step - loss: 8.2338e-04 - mae: 0.0210 - val_loss: 0.0413 - val_mae: 0.1546\n",
      "Epoch 13/50\n",
      "276/276 - 12s - 42ms/step - loss: 7.0871e-04 - mae: 0.0192 - val_loss: 0.0435 - val_mae: 0.1574\n",
      "Epoch 14/50\n",
      "276/276 - 11s - 40ms/step - loss: 7.1372e-04 - mae: 0.0193 - val_loss: 0.0550 - val_mae: 0.1763\n",
      "Epoch 15/50\n",
      "276/276 - 12s - 42ms/step - loss: 6.5555e-04 - mae: 0.0183 - val_loss: 0.0411 - val_mae: 0.1527\n",
      "Epoch 16/50\n",
      "276/276 - 11s - 41ms/step - loss: 6.9647e-04 - mae: 0.0188 - val_loss: 0.0431 - val_mae: 0.1565\n",
      "Epoch 17/50\n",
      "276/276 - 12s - 43ms/step - loss: 6.8800e-04 - mae: 0.0187 - val_loss: 0.0375 - val_mae: 0.1451\n",
      "Epoch 18/50\n",
      "276/276 - 12s - 42ms/step - loss: 6.1961e-04 - mae: 0.0174 - val_loss: 0.0392 - val_mae: 0.1477\n",
      "Epoch 19/50\n",
      "276/276 - 12s - 42ms/step - loss: 5.7952e-04 - mae: 0.0166 - val_loss: 0.0359 - val_mae: 0.1436\n",
      "Epoch 20/50\n",
      "276/276 - 12s - 43ms/step - loss: 5.4061e-04 - mae: 0.0163 - val_loss: 0.0391 - val_mae: 0.1490\n",
      "Epoch 21/50\n",
      "276/276 - 12s - 42ms/step - loss: 5.6590e-04 - mae: 0.0164 - val_loss: 0.0368 - val_mae: 0.1452\n",
      "Epoch 22/50\n",
      "276/276 - 12s - 43ms/step - loss: 5.1691e-04 - mae: 0.0155 - val_loss: 0.0366 - val_mae: 0.1440\n",
      "Epoch 23/50\n",
      "276/276 - 11s - 39ms/step - loss: 5.6143e-04 - mae: 0.0167 - val_loss: 0.0356 - val_mae: 0.1414\n",
      "Epoch 24/50\n",
      "276/276 - 12s - 42ms/step - loss: 5.2525e-04 - mae: 0.0156 - val_loss: 0.0348 - val_mae: 0.1373\n",
      "Epoch 25/50\n",
      "276/276 - 12s - 42ms/step - loss: 5.3641e-04 - mae: 0.0159 - val_loss: 0.0335 - val_mae: 0.1367\n",
      "Epoch 26/50\n",
      "276/276 - 11s - 38ms/step - loss: 4.8143e-04 - mae: 0.0144 - val_loss: 0.0367 - val_mae: 0.1424\n",
      "Epoch 27/50\n",
      "276/276 - 11s - 39ms/step - loss: 4.8668e-04 - mae: 0.0148 - val_loss: 0.0323 - val_mae: 0.1335\n",
      "Epoch 28/50\n",
      "276/276 - 12s - 42ms/step - loss: 5.0789e-04 - mae: 0.0150 - val_loss: 0.0309 - val_mae: 0.1300\n",
      "Epoch 29/50\n",
      "276/276 - 11s - 41ms/step - loss: 5.1623e-04 - mae: 0.0156 - val_loss: 0.0339 - val_mae: 0.1372\n",
      "Epoch 30/50\n",
      "276/276 - 12s - 42ms/step - loss: 5.1789e-04 - mae: 0.0157 - val_loss: 0.0292 - val_mae: 0.1253\n",
      "Epoch 31/50\n",
      "276/276 - 12s - 42ms/step - loss: 4.5941e-04 - mae: 0.0142 - val_loss: 0.0236 - val_mae: 0.1156\n",
      "Epoch 32/50\n",
      "276/276 - 11s - 41ms/step - loss: 5.0716e-04 - mae: 0.0155 - val_loss: 0.0317 - val_mae: 0.1312\n",
      "Epoch 33/50\n",
      "276/276 - 11s - 41ms/step - loss: 4.6737e-04 - mae: 0.0146 - val_loss: 0.0285 - val_mae: 0.1245\n",
      "Epoch 34/50\n",
      "276/276 - 12s - 45ms/step - loss: 5.2502e-04 - mae: 0.0159 - val_loss: 0.0234 - val_mae: 0.1118\n",
      "Epoch 35/50\n",
      "276/276 - 9s - 34ms/step - loss: 4.5021e-04 - mae: 0.0138 - val_loss: 0.0145 - val_mae: 0.0923\n",
      "Epoch 36/50\n",
      "276/276 - 9s - 31ms/step - loss: 4.4684e-04 - mae: 0.0138 - val_loss: 0.0173 - val_mae: 0.0958\n",
      "Epoch 37/50\n",
      "276/276 - 9s - 34ms/step - loss: 4.4951e-04 - mae: 0.0137 - val_loss: 0.0201 - val_mae: 0.1059\n",
      "Epoch 38/50\n",
      "276/276 - 8s - 29ms/step - loss: 4.7227e-04 - mae: 0.0147 - val_loss: 0.0140 - val_mae: 0.0883\n",
      "Epoch 39/50\n",
      "276/276 - 11s - 40ms/step - loss: 4.1982e-04 - mae: 0.0132 - val_loss: 0.0115 - val_mae: 0.0802\n",
      "Epoch 40/50\n",
      "276/276 - 16s - 57ms/step - loss: 4.9301e-04 - mae: 0.0155 - val_loss: 0.0102 - val_mae: 0.0743\n",
      "Epoch 41/50\n",
      "276/276 - 20s - 74ms/step - loss: 4.1607e-04 - mae: 0.0129 - val_loss: 0.0187 - val_mae: 0.1012\n",
      "Epoch 42/50\n",
      "276/276 - 16s - 57ms/step - loss: 4.5655e-04 - mae: 0.0140 - val_loss: 0.0104 - val_mae: 0.0753\n",
      "Epoch 43/50\n",
      "276/276 - 16s - 56ms/step - loss: 4.0486e-04 - mae: 0.0125 - val_loss: 0.0115 - val_mae: 0.0813\n",
      "Epoch 44/50\n",
      "276/276 - 16s - 57ms/step - loss: 4.3238e-04 - mae: 0.0138 - val_loss: 0.0123 - val_mae: 0.0830\n",
      "Epoch 45/50\n",
      "276/276 - 16s - 57ms/step - loss: 3.8649e-04 - mae: 0.0121 - val_loss: 0.0057 - val_mae: 0.0555\n",
      "Epoch 46/50\n",
      "276/276 - 15s - 56ms/step - loss: 4.0393e-04 - mae: 0.0123 - val_loss: 0.0036 - val_mae: 0.0338\n",
      "Epoch 47/50\n",
      "276/276 - 16s - 56ms/step - loss: 4.0023e-04 - mae: 0.0126 - val_loss: 0.0115 - val_mae: 0.0807\n",
      "Epoch 48/50\n",
      "276/276 - 16s - 56ms/step - loss: 4.1229e-04 - mae: 0.0132 - val_loss: 0.0079 - val_mae: 0.0677\n",
      "Epoch 49/50\n",
      "276/276 - 15s - 54ms/step - loss: 4.2408e-04 - mae: 0.0132 - val_loss: 0.0067 - val_mae: 0.0625\n",
      "Epoch 50/50\n",
      "276/276 - 16s - 57ms/step - loss: 4.2562e-04 - mae: 0.0132 - val_loss: 0.0131 - val_mae: 0.0866\n",
      "✅ Done with tomato_Tumkur_daily.csv | MAE=288.52, RMSE=608.7, R2=0.81, MAPE=16.65%, Accuracy=83.35%\n",
      "\n",
      "🚀 Processing: tomato_Udupi_daily.csv\n",
      "Epoch 1/50\n",
      "328/328 - 27s - 81ms/step - loss: 0.0318 - mae: 0.1036 - val_loss: 0.0344 - val_mae: 0.1110\n",
      "Epoch 2/50\n",
      "328/328 - 16s - 48ms/step - loss: 0.0061 - mae: 0.0592 - val_loss: 0.0286 - val_mae: 0.1096\n",
      "Epoch 3/50\n",
      "328/328 - 15s - 45ms/step - loss: 0.0044 - mae: 0.0489 - val_loss: 0.0285 - val_mae: 0.1013\n",
      "Epoch 4/50\n",
      "328/328 - 16s - 49ms/step - loss: 0.0033 - mae: 0.0415 - val_loss: 0.0248 - val_mae: 0.0982\n",
      "Epoch 5/50\n",
      "328/328 - 14s - 43ms/step - loss: 0.0029 - mae: 0.0386 - val_loss: 0.0234 - val_mae: 0.0959\n",
      "Epoch 6/50\n",
      "328/328 - 16s - 48ms/step - loss: 0.0027 - mae: 0.0369 - val_loss: 0.0238 - val_mae: 0.0955\n",
      "Epoch 7/50\n",
      "328/328 - 17s - 51ms/step - loss: 0.0025 - mae: 0.0353 - val_loss: 0.0218 - val_mae: 0.0937\n",
      "Epoch 8/50\n",
      "328/328 - 15s - 47ms/step - loss: 0.0028 - mae: 0.0379 - val_loss: 0.0238 - val_mae: 0.0995\n",
      "Epoch 9/50\n",
      "328/328 - 15s - 47ms/step - loss: 0.0025 - mae: 0.0353 - val_loss: 0.0214 - val_mae: 0.0927\n",
      "Epoch 10/50\n",
      "328/328 - 15s - 46ms/step - loss: 0.0024 - mae: 0.0344 - val_loss: 0.0203 - val_mae: 0.0995\n",
      "Epoch 11/50\n",
      "328/328 - 16s - 48ms/step - loss: 0.0024 - mae: 0.0340 - val_loss: 0.0205 - val_mae: 0.1041\n",
      "Epoch 12/50\n",
      "328/328 - 15s - 47ms/step - loss: 0.0025 - mae: 0.0363 - val_loss: 0.0194 - val_mae: 0.0916\n",
      "Epoch 13/50\n",
      "328/328 - 16s - 47ms/step - loss: 0.0023 - mae: 0.0336 - val_loss: 0.0194 - val_mae: 0.0943\n",
      "Epoch 14/50\n",
      "328/328 - 16s - 48ms/step - loss: 0.0023 - mae: 0.0331 - val_loss: 0.0183 - val_mae: 0.0917\n",
      "Epoch 15/50\n",
      "328/328 - 16s - 49ms/step - loss: 0.0023 - mae: 0.0339 - val_loss: 0.0187 - val_mae: 0.0889\n",
      "Epoch 16/50\n",
      "328/328 - 16s - 49ms/step - loss: 0.0025 - mae: 0.0350 - val_loss: 0.0183 - val_mae: 0.0882\n",
      "Epoch 17/50\n",
      "328/328 - 16s - 47ms/step - loss: 0.0023 - mae: 0.0336 - val_loss: 0.0178 - val_mae: 0.0892\n",
      "Epoch 18/50\n",
      "328/328 - 16s - 49ms/step - loss: 0.0023 - mae: 0.0340 - val_loss: 0.0190 - val_mae: 0.0971\n",
      "Epoch 19/50\n",
      "328/328 - 16s - 48ms/step - loss: 0.0024 - mae: 0.0342 - val_loss: 0.0194 - val_mae: 0.0903\n",
      "Epoch 20/50\n",
      "328/328 - 16s - 48ms/step - loss: 0.0023 - mae: 0.0339 - val_loss: 0.0185 - val_mae: 0.0913\n",
      "Epoch 21/50\n",
      "328/328 - 16s - 48ms/step - loss: 0.0022 - mae: 0.0327 - val_loss: 0.0176 - val_mae: 0.0887\n",
      "Epoch 22/50\n",
      "328/328 - 16s - 48ms/step - loss: 0.0022 - mae: 0.0318 - val_loss: 0.0202 - val_mae: 0.0955\n",
      "Epoch 23/50\n",
      "328/328 - 21s - 63ms/step - loss: 0.0022 - mae: 0.0322 - val_loss: 0.0181 - val_mae: 0.0885\n",
      "Epoch 24/50\n",
      "328/328 - 15s - 47ms/step - loss: 0.0022 - mae: 0.0331 - val_loss: 0.0177 - val_mae: 0.0891\n",
      "Epoch 25/50\n",
      "328/328 - 16s - 48ms/step - loss: 0.0022 - mae: 0.0321 - val_loss: 0.0191 - val_mae: 0.0938\n",
      "Epoch 26/50\n",
      "328/328 - 16s - 48ms/step - loss: 0.0022 - mae: 0.0330 - val_loss: 0.0242 - val_mae: 0.1078\n",
      "Epoch 27/50\n",
      "328/328 - 20s - 60ms/step - loss: 0.0023 - mae: 0.0334 - val_loss: 0.0190 - val_mae: 0.0969\n",
      "Epoch 28/50\n",
      "328/328 - 16s - 47ms/step - loss: 0.0022 - mae: 0.0325 - val_loss: 0.0197 - val_mae: 0.1022\n",
      "Epoch 29/50\n",
      "328/328 - 16s - 48ms/step - loss: 0.0022 - mae: 0.0324 - val_loss: 0.0178 - val_mae: 0.0893\n",
      "Epoch 30/50\n",
      "328/328 - 16s - 49ms/step - loss: 0.0023 - mae: 0.0336 - val_loss: 0.0191 - val_mae: 0.0950\n",
      "Epoch 31/50\n",
      "328/328 - 16s - 49ms/step - loss: 0.0022 - mae: 0.0326 - val_loss: 0.0183 - val_mae: 0.0922\n",
      "Epoch 32/50\n",
      "328/328 - 16s - 48ms/step - loss: 0.0022 - mae: 0.0323 - val_loss: 0.0230 - val_mae: 0.1050\n",
      "Epoch 33/50\n",
      "328/328 - 15s - 46ms/step - loss: 0.0022 - mae: 0.0321 - val_loss: 0.0197 - val_mae: 0.0991\n",
      "Epoch 34/50\n",
      "328/328 - 17s - 52ms/step - loss: 0.0023 - mae: 0.0336 - val_loss: 0.0208 - val_mae: 0.0975\n",
      "Epoch 35/50\n",
      "328/328 - 16s - 49ms/step - loss: 0.0022 - mae: 0.0324 - val_loss: 0.0192 - val_mae: 0.0955\n",
      "Epoch 36/50\n",
      "328/328 - 16s - 48ms/step - loss: 0.0022 - mae: 0.0328 - val_loss: 0.0203 - val_mae: 0.0939\n",
      "Epoch 37/50\n",
      "328/328 - 16s - 49ms/step - loss: 0.0022 - mae: 0.0319 - val_loss: 0.0177 - val_mae: 0.0891\n",
      "Epoch 38/50\n",
      "328/328 - 16s - 49ms/step - loss: 0.0021 - mae: 0.0314 - val_loss: 0.0198 - val_mae: 0.0943\n",
      "Epoch 39/50\n",
      "328/328 - 16s - 47ms/step - loss: 0.0022 - mae: 0.0323 - val_loss: 0.0181 - val_mae: 0.0920\n",
      "Epoch 40/50\n",
      "328/328 - 16s - 47ms/step - loss: 0.0021 - mae: 0.0315 - val_loss: 0.0265 - val_mae: 0.1047\n",
      "Epoch 41/50\n",
      "328/328 - 15s - 45ms/step - loss: 0.0021 - mae: 0.0316 - val_loss: 0.0224 - val_mae: 0.0970\n",
      "Epoch 42/50\n",
      "328/328 - 17s - 51ms/step - loss: 0.0021 - mae: 0.0313 - val_loss: 0.0262 - val_mae: 0.1021\n",
      "Epoch 43/50\n",
      "328/328 - 15s - 47ms/step - loss: 0.0022 - mae: 0.0323 - val_loss: 0.0518 - val_mae: 0.1437\n",
      "Epoch 44/50\n",
      "328/328 - 16s - 48ms/step - loss: 0.0021 - mae: 0.0317 - val_loss: 0.0710 - val_mae: 0.1524\n",
      "Epoch 45/50\n",
      "328/328 - 16s - 48ms/step - loss: 0.0022 - mae: 0.0322 - val_loss: 0.0356 - val_mae: 0.1094\n",
      "Epoch 46/50\n",
      "328/328 - 15s - 47ms/step - loss: 0.0021 - mae: 0.0319 - val_loss: 0.0213 - val_mae: 0.0949\n",
      "Epoch 47/50\n",
      "328/328 - 16s - 48ms/step - loss: 0.0021 - mae: 0.0317 - val_loss: 0.0216 - val_mae: 0.0966\n",
      "Epoch 48/50\n",
      "328/328 - 15s - 47ms/step - loss: 0.0021 - mae: 0.0318 - val_loss: 0.0296 - val_mae: 0.1160\n",
      "Epoch 49/50\n",
      "328/328 - 15s - 47ms/step - loss: 0.0022 - mae: 0.0327 - val_loss: 0.0212 - val_mae: 0.0970\n",
      "Epoch 50/50\n",
      "328/328 - 15s - 47ms/step - loss: 0.0021 - mae: 0.0315 - val_loss: 0.0179 - val_mae: 0.0893\n",
      "✅ Done with tomato_Udupi_daily.csv | MAE=396.92, RMSE=682.95, R2=0.69, MAPE=21.99%, Accuracy=78.01%\n",
      "\n",
      "📊 Metrics saved to tat_ha_metrics.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import joblib\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "\n",
    "# =========================================================\n",
    "# CLEAN STARTUP – suppress all unnecessary warnings/logs\n",
    "# =========================================================\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # Disable TensorFlow INFO/WARNING logs\n",
    "tf.get_logger().setLevel(\"ERROR\")\n",
    "\n",
    "# =========================================================\n",
    "# Output directories\n",
    "# =========================================================\n",
    "input_folder = \"dataset\"\n",
    "output_models = \"tat_ha_output_models\"\n",
    "output_csv = \"tat_ha_output_csv\"\n",
    "output_graphs = \"tat_ha_output_graphs\"\n",
    "output_logs = \"tat_ha_output_logs\"\n",
    "metrics_file = \"tat_ha_metrics.csv\"\n",
    "\n",
    "os.makedirs(output_models, exist_ok=True)\n",
    "os.makedirs(output_csv, exist_ok=True)\n",
    "os.makedirs(output_graphs, exist_ok=True)\n",
    "os.makedirs(output_logs, exist_ok=True)\n",
    "\n",
    "# =========================================================\n",
    "# Dataset creation\n",
    "# =========================================================\n",
    "def create_dataset(data, look_back=30):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - look_back):\n",
    "        X.append(data[i:i + look_back, 0])\n",
    "        y.append(data[i + look_back, 0])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# =========================================================\n",
    "# Local Attention Layer\n",
    "# =========================================================\n",
    "class LocalAttention(layers.Layer):\n",
    "    def __init__(self, key_dim=64, dropout_rate=0.1, **kwargs):\n",
    "        super(LocalAttention, self).__init__(**kwargs)\n",
    "        self.key_dim = key_dim\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.q_dense = layers.Dense(key_dim)\n",
    "        self.k_dense = layers.Dense(key_dim)\n",
    "        self.v_dense = layers.Dense(key_dim)\n",
    "        self.dropout = layers.Dropout(dropout_rate)\n",
    "\n",
    "    def call(self, x):\n",
    "        Q = self.q_dense(x)\n",
    "        K = self.k_dense(x)\n",
    "        V = self.v_dense(x)\n",
    "        scores = tf.matmul(Q, K, transpose_b=True) / tf.math.sqrt(\n",
    "            tf.cast(tf.shape(K)[-1], tf.float32))\n",
    "        weights = tf.nn.softmax(scores, axis=-1)\n",
    "        output = tf.matmul(weights, V)\n",
    "        return self.dropout(output)\n",
    "\n",
    "# =========================================================\n",
    "# Hierarchical Attention Model\n",
    "# =========================================================\n",
    "def build_tat_ha_model(input_shape, d_model=64, ff_dim=128, dropout_rate=0.2):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    local_attn = LocalAttention(key_dim=d_model, dropout_rate=dropout_rate)(inputs)\n",
    "    local_attn = layers.LayerNormalization(epsilon=1e-6)(local_attn + inputs)\n",
    "\n",
    "    global_attn = layers.MultiHeadAttention(num_heads=4, key_dim=d_model)(local_attn, local_attn)\n",
    "    global_attn = layers.Dropout(dropout_rate)(global_attn)\n",
    "    global_attn = layers.LayerNormalization(epsilon=1e-6)(global_attn + local_attn)\n",
    "\n",
    "    ff = layers.Dense(ff_dim, activation='relu')(global_attn)\n",
    "    ff = layers.Dense(input_shape[1])(ff)\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(ff + global_attn)\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "\n",
    "    outputs = layers.Dense(1)(x)\n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=0.001),\n",
    "                  loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# =========================================================\n",
    "# Metrics list\n",
    "# =========================================================\n",
    "metrics_list = []\n",
    "\n",
    "# =========================================================\n",
    "# Process each CSV file\n",
    "# =========================================================\n",
    "look_back = 30\n",
    "for file in os.listdir(input_folder):\n",
    "    if not file.endswith(\".csv\"):\n",
    "        continue\n",
    "\n",
    "    file_path = os.path.join(input_folder, file)\n",
    "    print(f\"\\n🚀 Processing: {file}\")\n",
    "\n",
    "    # Load CSV\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Safe datetime conversion\n",
    "    df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "    df = df.dropna(subset=['Date']).sort_values('Date')\n",
    "\n",
    "    # Ensure target column exists\n",
    "    if 'Average Price' not in df.columns:\n",
    "        print(f\"⚠️ Skipping {file}: 'Average Price' missing.\")\n",
    "        continue\n",
    "\n",
    "    # Replace inplace warnings (no inplace=True used)\n",
    "    df['Average Price'] = df['Average Price'].fillna(df['Average Price'].mean())\n",
    "    df['MA_7'] = df['Average Price'].rolling(window=7).mean()\n",
    "    df['MA_30'] = df['Average Price'].rolling(window=30).mean()\n",
    "    df['MA_7'] = df['MA_7'].fillna(df['MA_7'].mean())\n",
    "    df['MA_30'] = df['MA_30'].fillna(df['MA_30'].mean())\n",
    "\n",
    "    # Prepare training data\n",
    "    values = df[['Average Price']].values.astype('float32')\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_values = scaler.fit_transform(values)\n",
    "    if len(scaled_values) <= look_back:\n",
    "        print(f\"⚠️ Skipping {file}: not enough data points.\")\n",
    "        continue\n",
    "\n",
    "    X, y = create_dataset(scaled_values, look_back)\n",
    "    X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
    "\n",
    "    # Build and train model (show epochs cleanly)\n",
    "    model = build_tat_ha_model(input_shape=(look_back, 1))\n",
    "    history = model.fit(X, y, epochs=50, batch_size=16, validation_split=0.2, verbose=2)\n",
    "\n",
    "    # Save logs\n",
    "    log_file = os.path.join(output_logs, file.replace(\".csv\", \"_tat_ha_training.txt\"))\n",
    "    with open(log_file, \"w\") as f:\n",
    "        f.write(\"Training Loss per Epoch:\\n\")\n",
    "        for i, loss in enumerate(history.history['loss']):\n",
    "            f.write(f\"Epoch {i + 1}: Loss={loss}, Val_Loss={history.history['val_loss'][i]}\\n\")\n",
    "\n",
    "    # Predictions\n",
    "    predictions = model.predict(X, verbose=0)\n",
    "    predictions_rescaled = scaler.inverse_transform(predictions)\n",
    "    df['Predicted'] = [np.nan] * look_back + list(predictions_rescaled.flatten())\n",
    "\n",
    "    # Round results\n",
    "    df['Average Price'] = df['Average Price'].round(2)\n",
    "    df['Predicted'] = df['Predicted'].round(2)\n",
    "\n",
    "    # Evaluate\n",
    "    y_true = df['Average Price'].values[look_back:]\n",
    "    y_pred = predictions_rescaled.flatten()\n",
    "    valid_idx = ~np.isnan(y_true) & ~np.isnan(y_pred) & (y_true != 0)\n",
    "\n",
    "    if not np.any(valid_idx):\n",
    "        print(f\"⚠️ Skipping metrics for {file}: invalid or zero values.\")\n",
    "        continue\n",
    "\n",
    "    y_true, y_pred = y_true[valid_idx], y_pred[valid_idx]\n",
    "    mae = round(mean_absolute_error(y_true, y_pred), 2)\n",
    "    rmse = round(np.sqrt(mean_squared_error(y_true, y_pred)), 2)\n",
    "    r2 = round(r2_score(y_true, y_pred), 2)\n",
    "    mape = round(np.mean(np.abs((y_true - y_pred) / np.maximum(y_true, 1e-10))) * 100, 2)\n",
    "    accuracy = round(max(0, min(100, 100 - mape)), 2)\n",
    "\n",
    "    metrics_list.append([file.replace(\".csv\", \"\"), mae, rmse, r2, mape, accuracy])\n",
    "\n",
    "    # Save model\n",
    "    model_file = os.path.join(output_models, file.replace(\".csv\", \"_tat_ha_model.pkl\"))\n",
    "    joblib.dump(model, model_file)\n",
    "\n",
    "    # Save updated CSV\n",
    "    save_df = df[['Date', 'Average Price', 'Predicted']].rename(columns={'Average Price': 'Actual'})\n",
    "    updated_csv_path = os.path.join(output_csv, file.replace(\".csv\", \"_tat_ha_updated.csv\"))\n",
    "    save_df.to_csv(updated_csv_path, index=False)\n",
    "\n",
    "    # Plot graph\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(df['Date'], df['Average Price'], label='Actual', color='blue')\n",
    "    plt.plot(df['Date'], df['MA_7'], label='MA 7', color='orange')\n",
    "    plt.plot(df['Date'], df['MA_30'], label='MA 30', color='green')\n",
    "    plt.plot(df['Date'], df['Predicted'], label='Predicted (TAT-HA)', color='red', linestyle='dashed')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Price')\n",
    "    plt.title(f'Price Prediction (TAT-HA) - {file}')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    graph_file = os.path.join(output_graphs, file.replace(\".csv\", \"_tat_ha_graph.png\"))\n",
    "    plt.savefig(graph_file)\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"✅ Done with {file} | MAE={mae}, RMSE={rmse}, R2={r2}, MAPE={mape}%, Accuracy={accuracy}%\")\n",
    "\n",
    "# Save metrics\n",
    "if metrics_list:\n",
    "    metrics_df = pd.DataFrame(metrics_list, columns=['District', 'MAE', 'RMSE', 'R2', 'MAPE(%)', 'Accuracy(%)'])\n",
    "    metrics_df.to_csv(metrics_file, index=False)\n",
    "    print(f\"\\n📊 Metrics saved to {metrics_file}\")\n",
    "else:\n",
    "    print(\"\\n⚠️ No valid data found to save metrics.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bc52020-1e62-4cb0-a04d-8ff71b507fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8e49d80-e4d1-4d60-8ca4-60ffeca4aefe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== Processing: tomato_Bangalore_daily.csv ==========\n",
      "Epoch 1/20\n",
      "\u001b[1m692/692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 0.0017 - mae: 0.0193 - val_loss: 0.0011 - val_mae: 0.0215\n",
      "Epoch 2/20\n",
      "\u001b[1m692/692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.0015 - mae: 0.0170 - val_loss: 0.0012 - val_mae: 0.0250\n",
      "Epoch 3/20\n",
      "\u001b[1m692/692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.0015 - mae: 0.0168 - val_loss: 0.0014 - val_mae: 0.0238\n",
      "Epoch 4/20\n",
      "\u001b[1m692/692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0167 - val_loss: 0.0025 - val_mae: 0.0282\n",
      "Epoch 5/20\n",
      "\u001b[1m692/692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0167 - val_loss: 0.0013 - val_mae: 0.0224\n",
      "Epoch 6/20\n",
      "\u001b[1m692/692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0167 - val_loss: 0.0016 - val_mae: 0.0240\n",
      "Epoch 7/20\n",
      "\u001b[1m692/692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0169 - val_loss: 0.0016 - val_mae: 0.0241\n",
      "Epoch 8/20\n",
      "\u001b[1m692/692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0167 - val_loss: 0.0013 - val_mae: 0.0227\n",
      "Epoch 9/20\n",
      "\u001b[1m692/692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0165 - val_loss: 0.0013 - val_mae: 0.0224\n",
      "Epoch 10/20\n",
      "\u001b[1m692/692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0014 - mae: 0.0166 - val_loss: 0.0024 - val_mae: 0.0275\n",
      "Epoch 11/20\n",
      "\u001b[1m692/692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0165 - val_loss: 0.0021 - val_mae: 0.0258\n",
      "Epoch 12/20\n",
      "\u001b[1m692/692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0167 - val_loss: 0.0017 - val_mae: 0.0250\n",
      "Epoch 13/20\n",
      "\u001b[1m692/692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0014 - mae: 0.0167 - val_loss: 0.0019 - val_mae: 0.0253\n",
      "Epoch 14/20\n",
      "\u001b[1m692/692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0014 - mae: 0.0166 - val_loss: 0.0014 - val_mae: 0.0238\n",
      "Epoch 15/20\n",
      "\u001b[1m692/692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0167 - val_loss: 0.0016 - val_mae: 0.0245\n",
      "Epoch 16/20\n",
      "\u001b[1m692/692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0014 - mae: 0.0165 - val_loss: 0.0011 - val_mae: 0.0224\n",
      "Epoch 17/20\n",
      "\u001b[1m692/692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.0014 - mae: 0.0166 - val_loss: 0.0021 - val_mae: 0.0264\n",
      "Epoch 18/20\n",
      "\u001b[1m692/692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0014 - mae: 0.0165 - val_loss: 0.0019 - val_mae: 0.0254\n",
      "Epoch 19/20\n",
      "\u001b[1m692/692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.0014 - mae: 0.0168 - val_loss: 0.0016 - val_mae: 0.0240\n",
      "Epoch 20/20\n",
      "\u001b[1m692/692\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0014 - mae: 0.0166 - val_loss: 0.0014 - val_mae: 0.0235\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step   \n",
      "✅ Done: tomato_Bangalore_daily | MAE=585.43, RMSE=927.18, R2=0.75, MAPE=28.08%, Accuracy=71.92%\n",
      "\n",
      "========== Processing: tomato_Belgaum_daily.csv ==========\n",
      "Epoch 1/20\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0019 - mae: 0.0243 - val_loss: 0.0028 - val_mae: 0.0314\n",
      "Epoch 2/20\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5.5928e-05 - mae: 0.0033 - val_loss: 0.0028 - val_mae: 0.0311\n",
      "Epoch 3/20\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5.4422e-05 - mae: 0.0029 - val_loss: 0.0028 - val_mae: 0.0312\n",
      "Epoch 4/20\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5.4658e-05 - mae: 0.0030 - val_loss: 0.0028 - val_mae: 0.0307\n",
      "Epoch 5/20\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 5.4990e-05 - mae: 0.0031 - val_loss: 0.0027 - val_mae: 0.0305\n",
      "Epoch 6/20\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 5.3320e-05 - mae: 0.0028 - val_loss: 0.0027 - val_mae: 0.0308\n",
      "Epoch 7/20\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5.4331e-05 - mae: 0.0031 - val_loss: 0.0027 - val_mae: 0.0308\n",
      "Epoch 8/20\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5.5814e-05 - mae: 0.0033 - val_loss: 0.0027 - val_mae: 0.0305\n",
      "Epoch 9/20\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5.4451e-05 - mae: 0.0029 - val_loss: 0.0027 - val_mae: 0.0305\n",
      "Epoch 10/20\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5.5975e-05 - mae: 0.0034 - val_loss: 0.0027 - val_mae: 0.0304\n",
      "Epoch 11/20\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5.5834e-05 - mae: 0.0034 - val_loss: 0.0027 - val_mae: 0.0306\n",
      "Epoch 12/20\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5.9325e-05 - mae: 0.0036 - val_loss: 0.0027 - val_mae: 0.0304\n",
      "Epoch 13/20\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5.3886e-05 - mae: 0.0030 - val_loss: 0.0027 - val_mae: 0.0300\n",
      "Epoch 14/20\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5.5450e-05 - mae: 0.0032 - val_loss: 0.0027 - val_mae: 0.0308\n",
      "Epoch 15/20\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 6.0103e-05 - mae: 0.0039 - val_loss: 0.0027 - val_mae: 0.0301\n",
      "Epoch 16/20\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5.5801e-05 - mae: 0.0034 - val_loss: 0.0027 - val_mae: 0.0304\n",
      "Epoch 17/20\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5.3961e-05 - mae: 0.0032 - val_loss: 0.0027 - val_mae: 0.0306\n",
      "Epoch 18/20\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 5.4783e-05 - mae: 0.0032 - val_loss: 0.0027 - val_mae: 0.0297\n",
      "Epoch 19/20\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5.4316e-05 - mae: 0.0032 - val_loss: 0.0027 - val_mae: 0.0297\n",
      "Epoch 20/20\n",
      "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 5.4349e-05 - mae: 0.0033 - val_loss: 0.0027 - val_mae: 0.0304\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step  \n",
      "✅ Done: tomato_Belgaum_daily | MAE=294.92, RMSE=503.25, R2=0.89, MAPE=10.59%, Accuracy=89.41%\n",
      "\n",
      "========== Processing: tomato_Bellary_daily.csv ==========\n",
      "Epoch 1/20\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0030 - mae: 0.0391 - val_loss: 0.0017 - val_mae: 0.0231\n",
      "Epoch 2/20\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0011 - mae: 0.0192 - val_loss: 0.0016 - val_mae: 0.0224\n",
      "Epoch 3/20\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0011 - mae: 0.0185 - val_loss: 0.0019 - val_mae: 0.0240\n",
      "Epoch 4/20\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0011 - mae: 0.0189 - val_loss: 0.0021 - val_mae: 0.0264\n",
      "Epoch 5/20\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0011 - mae: 0.0188 - val_loss: 0.0021 - val_mae: 0.0253\n",
      "Epoch 6/20\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0011 - mae: 0.0185 - val_loss: 0.0018 - val_mae: 0.0251\n",
      "Epoch 7/20\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0011 - mae: 0.0184 - val_loss: 0.0020 - val_mae: 0.0247\n",
      "Epoch 8/20\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0011 - mae: 0.0185 - val_loss: 0.0018 - val_mae: 0.0226\n",
      "Epoch 9/20\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0011 - mae: 0.0182 - val_loss: 0.0021 - val_mae: 0.0250\n",
      "Epoch 10/20\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0010 - mae: 0.0181 - val_loss: 0.0022 - val_mae: 0.0268\n",
      "Epoch 11/20\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0011 - mae: 0.0184 - val_loss: 0.0022 - val_mae: 0.0241\n",
      "Epoch 12/20\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0010 - mae: 0.0181 - val_loss: 0.0022 - val_mae: 0.0239\n",
      "Epoch 13/20\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0010 - mae: 0.0178 - val_loss: 0.0022 - val_mae: 0.0250\n",
      "Epoch 14/20\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0010 - mae: 0.0180 - val_loss: 0.0021 - val_mae: 0.0243\n",
      "Epoch 15/20\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0010 - mae: 0.0178 - val_loss: 0.0020 - val_mae: 0.0244\n",
      "Epoch 16/20\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0010 - mae: 0.0177 - val_loss: 0.0025 - val_mae: 0.0263\n",
      "Epoch 17/20\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0010 - mae: 0.0180 - val_loss: 0.0020 - val_mae: 0.0252\n",
      "Epoch 18/20\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0010 - mae: 0.0178 - val_loss: 0.0022 - val_mae: 0.0250\n",
      "Epoch 19/20\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0010 - mae: 0.0181 - val_loss: 0.0025 - val_mae: 0.0250\n",
      "Epoch 20/20\n",
      "\u001b[1m147/147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0010 - mae: 0.0179 - val_loss: 0.0026 - val_mae: 0.0257\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step  \n",
      "✅ Done: tomato_Bellary_daily | MAE=177.87, RMSE=351.07, R2=0.89, MAPE=15.16%, Accuracy=84.84%\n",
      "\n",
      "========== Processing: tomato_Chamrajnagar_daily.csv ==========\n",
      "Epoch 1/20\n",
      "\u001b[1m401/401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 4.4245e-04 - mae: 0.0140 - val_loss: 0.0020 - val_mae: 0.0312\n",
      "Epoch 2/20\n",
      "\u001b[1m401/401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 3.8312e-04 - mae: 0.0127 - val_loss: 0.0021 - val_mae: 0.0316\n",
      "Epoch 3/20\n",
      "\u001b[1m401/401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 3.6209e-04 - mae: 0.0124 - val_loss: 0.0025 - val_mae: 0.0340\n",
      "Epoch 4/20\n",
      "\u001b[1m401/401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 3.5151e-04 - mae: 0.0122 - val_loss: 0.0036 - val_mae: 0.0400\n",
      "Epoch 5/20\n",
      "\u001b[1m401/401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 3.4156e-04 - mae: 0.0119 - val_loss: 0.0035 - val_mae: 0.0390\n",
      "Epoch 6/20\n",
      "\u001b[1m401/401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 3.3821e-04 - mae: 0.0118 - val_loss: 0.0049 - val_mae: 0.0437\n",
      "Epoch 7/20\n",
      "\u001b[1m401/401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 3.3474e-04 - mae: 0.0118 - val_loss: 0.0050 - val_mae: 0.0424\n",
      "Epoch 8/20\n",
      "\u001b[1m401/401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 3.3160e-04 - mae: 0.0118 - val_loss: 0.0063 - val_mae: 0.0454\n",
      "Epoch 9/20\n",
      "\u001b[1m401/401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 3.3170e-04 - mae: 0.0118 - val_loss: 0.0066 - val_mae: 0.0446\n",
      "Epoch 10/20\n",
      "\u001b[1m401/401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 3.2837e-04 - mae: 0.0117 - val_loss: 0.0076 - val_mae: 0.0448\n",
      "Epoch 11/20\n",
      "\u001b[1m401/401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 3.2549e-04 - mae: 0.0117 - val_loss: 0.0072 - val_mae: 0.0418\n",
      "Epoch 12/20\n",
      "\u001b[1m401/401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 3.2177e-04 - mae: 0.0117 - val_loss: 0.0091 - val_mae: 0.0463\n",
      "Epoch 13/20\n",
      "\u001b[1m401/401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 3.1578e-04 - mae: 0.0114 - val_loss: 0.0105 - val_mae: 0.0488\n",
      "Epoch 14/20\n",
      "\u001b[1m401/401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 3.1396e-04 - mae: 0.0116 - val_loss: 0.0078 - val_mae: 0.0409\n",
      "Epoch 15/20\n",
      "\u001b[1m401/401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 3.0802e-04 - mae: 0.0114 - val_loss: 0.0096 - val_mae: 0.0448\n",
      "Epoch 16/20\n",
      "\u001b[1m401/401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 3.0189e-04 - mae: 0.0113 - val_loss: 0.0079 - val_mae: 0.0405\n",
      "Epoch 17/20\n",
      "\u001b[1m401/401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 2.9829e-04 - mae: 0.0111 - val_loss: 0.0070 - val_mae: 0.0406\n",
      "Epoch 18/20\n",
      "\u001b[1m401/401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 2.9735e-04 - mae: 0.0112 - val_loss: 0.0067 - val_mae: 0.0399\n",
      "Epoch 19/20\n",
      "\u001b[1m401/401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 2.9200e-04 - mae: 0.0110 - val_loss: 0.0053 - val_mae: 0.0360\n",
      "Epoch 20/20\n",
      "\u001b[1m401/401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 2.8968e-04 - mae: 0.0109 - val_loss: 0.0060 - val_mae: 0.0400\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step   \n",
      "✅ Done: tomato_Chamrajnagar_daily | MAE=1968.35, RMSE=3810.31, R2=-1.47, MAPE=74.51%, Accuracy=25.49%\n",
      "\n",
      "========== Processing: tomato_Chikmagalur_daily.csv ==========\n",
      "Epoch 1/20\n",
      "\u001b[1m583/583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0029 - mae: 0.0358 - val_loss: 0.0093 - val_mae: 0.0642\n",
      "Epoch 2/20\n",
      "\u001b[1m583/583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0028 - mae: 0.0345 - val_loss: 0.0111 - val_mae: 0.0691\n",
      "Epoch 3/20\n",
      "\u001b[1m583/583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0028 - mae: 0.0345 - val_loss: 0.0117 - val_mae: 0.0700\n",
      "Epoch 4/20\n",
      "\u001b[1m583/583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0027 - mae: 0.0344 - val_loss: 0.0150 - val_mae: 0.0798\n",
      "Epoch 5/20\n",
      "\u001b[1m583/583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0027 - mae: 0.0344 - val_loss: 0.0126 - val_mae: 0.0714\n",
      "Epoch 6/20\n",
      "\u001b[1m583/583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0027 - mae: 0.0343 - val_loss: 0.0171 - val_mae: 0.0815\n",
      "Epoch 7/20\n",
      "\u001b[1m583/583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0027 - mae: 0.0341 - val_loss: 0.0209 - val_mae: 0.0894\n",
      "Epoch 8/20\n",
      "\u001b[1m583/583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0027 - mae: 0.0343 - val_loss: 0.0140 - val_mae: 0.0734\n",
      "Epoch 9/20\n",
      "\u001b[1m583/583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0027 - mae: 0.0341 - val_loss: 0.0175 - val_mae: 0.0825\n",
      "Epoch 10/20\n",
      "\u001b[1m583/583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0027 - mae: 0.0341 - val_loss: 0.0199 - val_mae: 0.0858\n",
      "Epoch 11/20\n",
      "\u001b[1m583/583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0027 - mae: 0.0341 - val_loss: 0.0146 - val_mae: 0.0746\n",
      "Epoch 12/20\n",
      "\u001b[1m583/583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0027 - mae: 0.0341 - val_loss: 0.0198 - val_mae: 0.0854\n",
      "Epoch 13/20\n",
      "\u001b[1m583/583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0027 - mae: 0.0341 - val_loss: 0.0217 - val_mae: 0.0886\n",
      "Epoch 14/20\n",
      "\u001b[1m583/583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0027 - mae: 0.0341 - val_loss: 0.0214 - val_mae: 0.0867\n",
      "Epoch 15/20\n",
      "\u001b[1m583/583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0027 - mae: 0.0340 - val_loss: 0.0228 - val_mae: 0.0915\n",
      "Epoch 16/20\n",
      "\u001b[1m583/583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0027 - mae: 0.0340 - val_loss: 0.0206 - val_mae: 0.0849\n",
      "Epoch 17/20\n",
      "\u001b[1m583/583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0027 - mae: 0.0340 - val_loss: 0.0169 - val_mae: 0.0784\n",
      "Epoch 18/20\n",
      "\u001b[1m583/583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0027 - mae: 0.0341 - val_loss: 0.0168 - val_mae: 0.0785\n",
      "Epoch 19/20\n",
      "\u001b[1m583/583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0027 - mae: 0.0340 - val_loss: 0.0186 - val_mae: 0.0817\n",
      "Epoch 20/20\n",
      "\u001b[1m583/583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0027 - mae: 0.0340 - val_loss: 0.0183 - val_mae: 0.0807\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step   \n",
      "✅ Done: tomato_Chikmagalur_daily | MAE=886.05, RMSE=1483.86, R2=-0.23, MAPE=61.49%, Accuracy=38.51%\n",
      "\n",
      "========== Processing: tomato_Chitradurga_daily.csv ==========\n",
      "Epoch 1/20\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0129 - mae: 0.0549 - val_loss: 5.2763e-08 - val_mae: 2.2970e-04\n",
      "Epoch 2/20\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 8.5495e-05 - mae: 0.0055 - val_loss: 7.1326e-06 - val_mae: 0.0027\n",
      "Epoch 3/20\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 6.5591e-05 - mae: 0.0040 - val_loss: 1.3193e-06 - val_mae: 0.0011\n",
      "Epoch 4/20\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 6.1770e-05 - mae: 0.0038 - val_loss: 2.2167e-05 - val_mae: 0.0047\n",
      "Epoch 5/20\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 6.2294e-05 - mae: 0.0039 - val_loss: 4.8072e-06 - val_mae: 0.0022\n",
      "Epoch 6/20\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 5.8427e-05 - mae: 0.0037 - val_loss: 2.7180e-06 - val_mae: 0.0016\n",
      "Epoch 7/20\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 5.7605e-05 - mae: 0.0036 - val_loss: 1.4187e-06 - val_mae: 0.0012\n",
      "Epoch 8/20\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 5.5469e-05 - mae: 0.0035 - val_loss: 4.8047e-07 - val_mae: 6.9316e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 5.7034e-05 - mae: 0.0039 - val_loss: 4.6852e-07 - val_mae: 6.8448e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 5.4165e-05 - mae: 0.0033 - val_loss: 5.6090e-07 - val_mae: 7.4893e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 5.4852e-05 - mae: 0.0036 - val_loss: 3.1651e-06 - val_mae: 0.0018\n",
      "Epoch 12/20\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 5.4188e-05 - mae: 0.0035 - val_loss: 8.6970e-07 - val_mae: 9.3257e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 5.5216e-05 - mae: 0.0037 - val_loss: 2.2476e-06 - val_mae: 0.0015\n",
      "Epoch 14/20\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 5.4840e-05 - mae: 0.0037 - val_loss: 6.9841e-06 - val_mae: 0.0026\n",
      "Epoch 15/20\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 5.4805e-05 - mae: 0.0038 - val_loss: 6.9345e-06 - val_mae: 0.0026\n",
      "Epoch 16/20\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 5.7844e-05 - mae: 0.0041 - val_loss: 5.4891e-09 - val_mae: 7.4089e-05\n",
      "Epoch 17/20\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 5.2946e-05 - mae: 0.0034 - val_loss: 3.7624e-08 - val_mae: 1.9397e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 5.4732e-05 - mae: 0.0037 - val_loss: 1.0024e-05 - val_mae: 0.0032\n",
      "Epoch 19/20\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 5.2916e-05 - mae: 0.0037 - val_loss: 3.5474e-09 - val_mae: 5.9560e-05\n",
      "Epoch 20/20\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 5.3521e-05 - mae: 0.0037 - val_loss: 1.6797e-06 - val_mae: 0.0013\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step \n",
      "✅ Done: tomato_Chitradurga_daily | MAE=6.7, RMSE=6.7, R2=0.0, MAPE=0.67%, Accuracy=99.33%\n",
      "\n",
      "========== Processing: tomato_Davangere_daily.csv ==========\n",
      "Epoch 1/20\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0046 - mae: 0.0483 - val_loss: 0.0037 - val_mae: 0.0350\n",
      "Epoch 2/20\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0033 - mae: 0.0403 - val_loss: 0.0043 - val_mae: 0.0411\n",
      "Epoch 3/20\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0031 - mae: 0.0390 - val_loss: 0.0040 - val_mae: 0.0385\n",
      "Epoch 4/20\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0029 - mae: 0.0373 - val_loss: 0.0049 - val_mae: 0.0424\n",
      "Epoch 5/20\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0028 - mae: 0.0353 - val_loss: 0.0049 - val_mae: 0.0385\n",
      "Epoch 6/20\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0027 - mae: 0.0345 - val_loss: 0.0045 - val_mae: 0.0375\n",
      "Epoch 7/20\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0027 - mae: 0.0346 - val_loss: 0.0044 - val_mae: 0.0393\n",
      "Epoch 8/20\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0026 - mae: 0.0338 - val_loss: 0.0044 - val_mae: 0.0395\n",
      "Epoch 9/20\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0026 - mae: 0.0337 - val_loss: 0.0045 - val_mae: 0.0386\n",
      "Epoch 10/20\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0026 - mae: 0.0335 - val_loss: 0.0048 - val_mae: 0.0398\n",
      "Epoch 11/20\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0026 - mae: 0.0329 - val_loss: 0.0045 - val_mae: 0.0379\n",
      "Epoch 12/20\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0026 - mae: 0.0330 - val_loss: 0.0045 - val_mae: 0.0381\n",
      "Epoch 13/20\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0026 - mae: 0.0328 - val_loss: 0.0047 - val_mae: 0.0387\n",
      "Epoch 14/20\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0026 - mae: 0.0330 - val_loss: 0.0046 - val_mae: 0.0379\n",
      "Epoch 15/20\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0026 - mae: 0.0327 - val_loss: 0.0045 - val_mae: 0.0386\n",
      "Epoch 16/20\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0026 - mae: 0.0329 - val_loss: 0.0045 - val_mae: 0.0384\n",
      "Epoch 17/20\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0025 - mae: 0.0325 - val_loss: 0.0045 - val_mae: 0.0373\n",
      "Epoch 18/20\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0025 - mae: 0.0327 - val_loss: 0.0047 - val_mae: 0.0402\n",
      "Epoch 19/20\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0025 - mae: 0.0329 - val_loss: 0.0044 - val_mae: 0.0380\n",
      "Epoch 20/20\n",
      "\u001b[1m242/242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0025 - mae: 0.0322 - val_loss: 0.0045 - val_mae: 0.0376\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step  \n",
      "✅ Done: tomato_Davangere_daily | MAE=306.48, RMSE=546.01, R2=0.84, MAPE=22.86%, Accuracy=77.14%\n",
      "\n",
      "========== Processing: tomato_Dharwad_daily.csv ==========\n",
      "Epoch 1/20\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0267 - mae: 0.1443 - val_loss: 0.0364 - val_mae: 0.1125\n",
      "Epoch 2/20\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0035 - mae: 0.0359 - val_loss: 0.0182 - val_mae: 0.0583\n",
      "Epoch 3/20\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0027 - mae: 0.0311 - val_loss: 0.0121 - val_mae: 0.0379\n",
      "Epoch 4/20\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0021 - mae: 0.0235 - val_loss: 0.0090 - val_mae: 0.0337\n",
      "Epoch 5/20\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0017 - mae: 0.0182 - val_loss: 0.0066 - val_mae: 0.0254\n",
      "Epoch 6/20\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0017 - mae: 0.0152 - val_loss: 0.0060 - val_mae: 0.0237\n",
      "Epoch 7/20\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0017 - mae: 0.0156 - val_loss: 0.0065 - val_mae: 0.0226\n",
      "Epoch 8/20\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0016 - mae: 0.0150 - val_loss: 0.0060 - val_mae: 0.0207\n",
      "Epoch 9/20\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0017 - mae: 0.0157 - val_loss: 0.0063 - val_mae: 0.0223\n",
      "Epoch 10/20\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0017 - mae: 0.0169 - val_loss: 0.0064 - val_mae: 0.0231\n",
      "Epoch 11/20\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0016 - mae: 0.0159 - val_loss: 0.0064 - val_mae: 0.0268\n",
      "Epoch 12/20\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0017 - mae: 0.0168 - val_loss: 0.0060 - val_mae: 0.0210\n",
      "Epoch 13/20\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0017 - mae: 0.0165 - val_loss: 0.0062 - val_mae: 0.0254\n",
      "Epoch 14/20\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0016 - mae: 0.0160 - val_loss: 0.0062 - val_mae: 0.0220\n",
      "Epoch 15/20\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0017 - mae: 0.0162 - val_loss: 0.0063 - val_mae: 0.0218\n",
      "Epoch 16/20\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0017 - mae: 0.0172 - val_loss: 0.0062 - val_mae: 0.0237\n",
      "Epoch 17/20\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0016 - mae: 0.0152 - val_loss: 0.0061 - val_mae: 0.0229\n",
      "Epoch 18/20\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0016 - mae: 0.0170 - val_loss: 0.0059 - val_mae: 0.0253\n",
      "Epoch 19/20\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0017 - mae: 0.0169 - val_loss: 0.0061 - val_mae: 0.0231\n",
      "Epoch 20/20\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0017 - mae: 0.0164 - val_loss: 0.0060 - val_mae: 0.0258\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step \n",
      "✅ Done: tomato_Dharwad_daily | MAE=184.79, RMSE=552.99, R2=0.86, MAPE=4.2%, Accuracy=95.8%\n",
      "\n",
      "========== Processing: tomato_Gadag_daily.csv ==========\n",
      "Epoch 1/20\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.1876 - mae: 0.3849 - val_loss: 0.3672 - val_mae: 0.5997\n",
      "Epoch 2/20\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0391 - mae: 0.1531 - val_loss: 0.0017 - val_mae: 0.0201\n",
      "Epoch 3/20\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0059 - mae: 0.0608 - val_loss: 0.0020 - val_mae: 0.0364\n",
      "Epoch 4/20\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0021 - mae: 0.0327 - val_loss: 0.0036 - val_mae: 0.0487\n",
      "Epoch 5/20\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 8.9931e-04 - mae: 0.0189 - val_loss: 0.0042 - val_mae: 0.0538\n",
      "Epoch 6/20\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 6.9842e-04 - mae: 0.0139 - val_loss: 0.0040 - val_mae: 0.0521\n",
      "Epoch 7/20\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.2394e-04 - mae: 0.0119 - val_loss: 0.0042 - val_mae: 0.0545\n",
      "Epoch 8/20\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.1687e-04 - mae: 0.0113 - val_loss: 0.0026 - val_mae: 0.0366\n",
      "Epoch 9/20\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.1434e-04 - mae: 0.0117 - val_loss: 0.0041 - val_mae: 0.0537\n",
      "Epoch 10/20\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.8954e-04 - mae: 0.0099 - val_loss: 0.0029 - val_mae: 0.0411\n",
      "Epoch 11/20\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.7809e-04 - mae: 0.0095 - val_loss: 0.0034 - val_mae: 0.0473\n",
      "Epoch 12/20\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.7541e-04 - mae: 0.0096 - val_loss: 0.0026 - val_mae: 0.0371\n",
      "Epoch 13/20\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 5.8596e-04 - mae: 0.0109 - val_loss: 0.0041 - val_mae: 0.0537\n",
      "Epoch 14/20\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 5.6624e-04 - mae: 0.0099 - val_loss: 0.0030 - val_mae: 0.0420\n",
      "Epoch 15/20\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.6575e-04 - mae: 0.0092 - val_loss: 0.0029 - val_mae: 0.0419\n",
      "Epoch 16/20\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.6640e-04 - mae: 0.0102 - val_loss: 0.0021 - val_mae: 0.0287\n",
      "Epoch 17/20\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.4812e-04 - mae: 0.0090 - val_loss: 0.0027 - val_mae: 0.0384\n",
      "Epoch 18/20\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.5335e-04 - mae: 0.0094 - val_loss: 0.0022 - val_mae: 0.0315\n",
      "Epoch 19/20\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.4529e-04 - mae: 0.0092 - val_loss: 0.0022 - val_mae: 0.0324\n",
      "Epoch 20/20\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.4796e-04 - mae: 0.0093 - val_loss: 0.0018 - val_mae: 0.0246\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step \n",
      "✅ Done: tomato_Gadag_daily | MAE=205.31, RMSE=358.67, R2=0.84, MAPE=2.9%, Accuracy=97.1%\n",
      "\n",
      "========== Processing: tomato_Hassan_daily.csv ==========\n",
      "Epoch 1/20\n",
      "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 0.0023 - mae: 0.0353 - val_loss: 0.0084 - val_mae: 0.0610\n",
      "Epoch 2/20\n",
      "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0021 - mae: 0.0333 - val_loss: 0.0073 - val_mae: 0.0573\n",
      "Epoch 3/20\n",
      "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0020 - mae: 0.0332 - val_loss: 0.0084 - val_mae: 0.0611\n",
      "Epoch 4/20\n",
      "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0020 - mae: 0.0332 - val_loss: 0.0082 - val_mae: 0.0602\n",
      "Epoch 5/20\n",
      "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0020 - mae: 0.0332 - val_loss: 0.0070 - val_mae: 0.0559\n",
      "Epoch 6/20\n",
      "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0020 - mae: 0.0332 - val_loss: 0.0088 - val_mae: 0.0625\n",
      "Epoch 7/20\n",
      "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0020 - mae: 0.0331 - val_loss: 0.0086 - val_mae: 0.0614\n",
      "Epoch 8/20\n",
      "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0020 - mae: 0.0331 - val_loss: 0.0071 - val_mae: 0.0559\n",
      "Epoch 9/20\n",
      "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0020 - mae: 0.0331 - val_loss: 0.0087 - val_mae: 0.0623\n",
      "Epoch 10/20\n",
      "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0020 - mae: 0.0331 - val_loss: 0.0084 - val_mae: 0.0610\n",
      "Epoch 11/20\n",
      "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0020 - mae: 0.0331 - val_loss: 0.0076 - val_mae: 0.0578\n",
      "Epoch 12/20\n",
      "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0020 - mae: 0.0330 - val_loss: 0.0077 - val_mae: 0.0580\n",
      "Epoch 13/20\n",
      "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0020 - mae: 0.0331 - val_loss: 0.0098 - val_mae: 0.0650\n",
      "Epoch 14/20\n",
      "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0020 - mae: 0.0331 - val_loss: 0.0094 - val_mae: 0.0636\n",
      "Epoch 15/20\n",
      "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0020 - mae: 0.0330 - val_loss: 0.0082 - val_mae: 0.0592\n",
      "Epoch 16/20\n",
      "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0020 - mae: 0.0330 - val_loss: 0.0074 - val_mae: 0.0570\n",
      "Epoch 17/20\n",
      "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0020 - mae: 0.0330 - val_loss: 0.0114 - val_mae: 0.0674\n",
      "Epoch 18/20\n",
      "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0020 - mae: 0.0330 - val_loss: 0.0100 - val_mae: 0.0615\n",
      "Epoch 19/20\n",
      "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0020 - mae: 0.0330 - val_loss: 0.0168 - val_mae: 0.0747\n",
      "Epoch 20/20\n",
      "\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0020 - mae: 0.0329 - val_loss: 0.0221 - val_mae: 0.0818\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step   \n",
      "✅ Done: tomato_Hassan_daily | MAE=983.86, RMSE=1785.44, R2=-0.78, MAPE=38.27%, Accuracy=61.73%\n",
      "\n",
      "========== Processing: tomato_Haveri_daily.csv ==========\n",
      "Epoch 1/20\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.1050 - mae: 0.2500 - val_loss: 0.0322 - val_mae: 0.1664\n",
      "Epoch 2/20\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0093 - mae: 0.0837 - val_loss: 0.0031 - val_mae: 0.0511\n",
      "Epoch 3/20\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0062 - mae: 0.0697 - val_loss: 0.0024 - val_mae: 0.0444\n",
      "Epoch 4/20\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0061 - mae: 0.0695 - val_loss: 0.0016 - val_mae: 0.0354\n",
      "Epoch 5/20\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0060 - mae: 0.0691 - val_loss: 0.0011 - val_mae: 0.0303\n",
      "Epoch 6/20\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0060 - mae: 0.0687 - val_loss: 0.0016 - val_mae: 0.0345\n",
      "Epoch 7/20\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0061 - mae: 0.0685 - val_loss: 9.6279e-04 - val_mae: 0.0277\n",
      "Epoch 8/20\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0060 - mae: 0.0685 - val_loss: 0.0011 - val_mae: 0.0288\n",
      "Epoch 9/20\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0059 - mae: 0.0684 - val_loss: 0.0012 - val_mae: 0.0293\n",
      "Epoch 10/20\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0059 - mae: 0.0683 - val_loss: 8.8247e-04 - val_mae: 0.0267\n",
      "Epoch 11/20\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0060 - mae: 0.0678 - val_loss: 0.0013 - val_mae: 0.0321\n",
      "Epoch 12/20\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0059 - mae: 0.0676 - val_loss: 8.2137e-04 - val_mae: 0.0255\n",
      "Epoch 13/20\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0059 - mae: 0.0677 - val_loss: 9.4565e-04 - val_mae: 0.0272\n",
      "Epoch 14/20\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0057 - mae: 0.0666 - val_loss: 0.0017 - val_mae: 0.0355\n",
      "Epoch 15/20\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0057 - mae: 0.0667 - val_loss: 7.5012e-04 - val_mae: 0.0238\n",
      "Epoch 16/20\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0057 - mae: 0.0662 - val_loss: 7.8377e-04 - val_mae: 0.0231\n",
      "Epoch 17/20\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0056 - mae: 0.0656 - val_loss: 6.9552e-04 - val_mae: 0.0221\n",
      "Epoch 18/20\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0054 - mae: 0.0650 - val_loss: 0.0010 - val_mae: 0.0282\n",
      "Epoch 19/20\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0055 - mae: 0.0646 - val_loss: 7.2481e-04 - val_mae: 0.0181\n",
      "Epoch 20/20\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0055 - mae: 0.0641 - val_loss: 6.6337e-04 - val_mae: 0.0210\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step \n",
      "✅ Done: tomato_Haveri_daily | MAE=174.67, RMSE=214.42, R2=1.0, MAPE=12.9%, Accuracy=87.1%\n",
      "\n",
      "========== Processing: tomato_Kalburgi_daily.csv ==========\n",
      "Epoch 1/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.0323 - mae: 0.1148 - val_loss: 0.0035 - val_mae: 0.0509\n",
      "Epoch 2/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0104 - mae: 0.0780 - val_loss: 0.0011 - val_mae: 0.0265\n",
      "Epoch 3/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0072 - mae: 0.0501 - val_loss: 9.8805e-04 - val_mae: 0.0228\n",
      "Epoch 4/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0070 - mae: 0.0496 - val_loss: 0.0011 - val_mae: 0.0252\n",
      "Epoch 5/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0068 - mae: 0.0487 - val_loss: 0.0011 - val_mae: 0.0244\n",
      "Epoch 6/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0067 - mae: 0.0494 - val_loss: 9.9469e-04 - val_mae: 0.0232\n",
      "Epoch 7/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0064 - mae: 0.0459 - val_loss: 9.6910e-04 - val_mae: 0.0225\n",
      "Epoch 8/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0066 - mae: 0.0483 - val_loss: 8.8951e-04 - val_mae: 0.0211\n",
      "Epoch 9/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0063 - mae: 0.0457 - val_loss: 9.1254e-04 - val_mae: 0.0212\n",
      "Epoch 10/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0063 - mae: 0.0452 - val_loss: 8.9889e-04 - val_mae: 0.0215\n",
      "Epoch 11/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0061 - mae: 0.0448 - val_loss: 9.5201e-04 - val_mae: 0.0223\n",
      "Epoch 12/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0059 - mae: 0.0434 - val_loss: 9.6534e-04 - val_mae: 0.0222\n",
      "Epoch 13/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0060 - mae: 0.0441 - val_loss: 8.7583e-04 - val_mae: 0.0207\n",
      "Epoch 14/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0058 - mae: 0.0437 - val_loss: 8.1426e-04 - val_mae: 0.0198\n",
      "Epoch 15/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0058 - mae: 0.0423 - val_loss: 7.8856e-04 - val_mae: 0.0194\n",
      "Epoch 16/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0057 - mae: 0.0423 - val_loss: 0.0012 - val_mae: 0.0273\n",
      "Epoch 17/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0059 - mae: 0.0463 - val_loss: 8.7650e-04 - val_mae: 0.0216\n",
      "Epoch 18/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0060 - mae: 0.0464 - val_loss: 7.5739e-04 - val_mae: 0.0190\n",
      "Epoch 19/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0056 - mae: 0.0416 - val_loss: 0.0015 - val_mae: 0.0325\n",
      "Epoch 20/20\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0065 - mae: 0.0501 - val_loss: 7.7737e-04 - val_mae: 0.0192\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step \n",
      "✅ Done: tomato_Kalburgi_daily | MAE=190.45, RMSE=276.03, R2=0.86, MAPE=14.51%, Accuracy=85.49%\n",
      "\n",
      "========== Processing: tomato_Kolar_daily.csv ==========\n",
      "Epoch 1/20\n",
      "\u001b[1m1047/1047\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 0.0013 - mae: 0.0231 - val_loss: 0.0042 - val_mae: 0.0444\n",
      "Epoch 2/20\n",
      "\u001b[1m1047/1047\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0011 - mae: 0.0216 - val_loss: 0.0042 - val_mae: 0.0420\n",
      "Epoch 3/20\n",
      "\u001b[1m1047/1047\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 0.0011 - mae: 0.0216 - val_loss: 0.0043 - val_mae: 0.0435\n",
      "Epoch 4/20\n",
      "\u001b[1m1047/1047\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0011 - mae: 0.0215 - val_loss: 0.0045 - val_mae: 0.0432\n",
      "Epoch 5/20\n",
      "\u001b[1m1047/1047\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0011 - mae: 0.0216 - val_loss: 0.0044 - val_mae: 0.0428\n",
      "Epoch 6/20\n",
      "\u001b[1m1047/1047\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0011 - mae: 0.0216 - val_loss: 0.0045 - val_mae: 0.0442\n",
      "Epoch 7/20\n",
      "\u001b[1m1047/1047\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0011 - mae: 0.0216 - val_loss: 0.0046 - val_mae: 0.0433\n",
      "Epoch 8/20\n",
      "\u001b[1m1047/1047\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0011 - mae: 0.0215 - val_loss: 0.0044 - val_mae: 0.0455\n",
      "Epoch 9/20\n",
      "\u001b[1m1047/1047\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 0.0011 - mae: 0.0214 - val_loss: 0.0046 - val_mae: 0.0459\n",
      "Epoch 10/20\n",
      "\u001b[1m1047/1047\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0011 - mae: 0.0214 - val_loss: 0.0045 - val_mae: 0.0441\n",
      "Epoch 11/20\n",
      "\u001b[1m1047/1047\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0011 - mae: 0.0215 - val_loss: 0.0045 - val_mae: 0.0439\n",
      "Epoch 12/20\n",
      "\u001b[1m1047/1047\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0011 - mae: 0.0214 - val_loss: 0.0044 - val_mae: 0.0447\n",
      "Epoch 13/20\n",
      "\u001b[1m1047/1047\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0011 - mae: 0.0213 - val_loss: 0.0044 - val_mae: 0.0425\n",
      "Epoch 14/20\n",
      "\u001b[1m1047/1047\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0011 - mae: 0.0213 - val_loss: 0.0046 - val_mae: 0.0453\n",
      "Epoch 15/20\n",
      "\u001b[1m1047/1047\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0011 - mae: 0.0214 - val_loss: 0.0042 - val_mae: 0.0445\n",
      "Epoch 16/20\n",
      "\u001b[1m1047/1047\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 0.0011 - mae: 0.0213 - val_loss: 0.0047 - val_mae: 0.0438\n",
      "Epoch 17/20\n",
      "\u001b[1m1047/1047\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0011 - mae: 0.0213 - val_loss: 0.0043 - val_mae: 0.0435\n",
      "Epoch 18/20\n",
      "\u001b[1m1047/1047\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0011 - mae: 0.0213 - val_loss: 0.0042 - val_mae: 0.0429\n",
      "Epoch 19/20\n",
      "\u001b[1m1047/1047\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0011 - mae: 0.0214 - val_loss: 0.0043 - val_mae: 0.0444\n",
      "Epoch 20/20\n",
      "\u001b[1m1047/1047\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.0011 - mae: 0.0213 - val_loss: 0.0042 - val_mae: 0.0420\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step    \n",
      "✅ Done: tomato_Kolar_daily | MAE=478.05, RMSE=735.63, R2=0.67, MAPE=31.68%, Accuracy=68.32%\n",
      "\n",
      "========== Processing: tomato_MadikeriKodagu_daily.csv ==========\n",
      "Epoch 1/20\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0701 - mae: 0.2019 - val_loss: 0.0088 - val_mae: 0.0897\n",
      "Epoch 2/20\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0451 - mae: 0.1665 - val_loss: 3.6234e-04 - val_mae: 0.0182\n",
      "Epoch 3/20\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0416 - mae: 0.1560 - val_loss: 3.3302e-04 - val_mae: 0.0165\n",
      "Epoch 4/20\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0378 - mae: 0.1433 - val_loss: 7.0799e-04 - val_mae: 0.0262\n",
      "Epoch 5/20\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0362 - mae: 0.1368 - val_loss: 0.0015 - val_mae: 0.0366\n",
      "Epoch 6/20\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0353 - mae: 0.1316 - val_loss: 0.0063 - val_mae: 0.0777\n",
      "Epoch 7/20\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0343 - mae: 0.1282 - val_loss: 0.0025 - val_mae: 0.0484\n",
      "Epoch 8/20\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0344 - mae: 0.1273 - val_loss: 2.8413e-04 - val_mae: 0.0119\n",
      "Epoch 9/20\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0340 - mae: 0.1263 - val_loss: 2.3011e-04 - val_mae: 0.0099\n",
      "Epoch 10/20\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0337 - mae: 0.1261 - val_loss: 0.0030 - val_mae: 0.0514\n",
      "Epoch 11/20\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0334 - mae: 0.1251 - val_loss: 0.0023 - val_mae: 0.0429\n",
      "Epoch 12/20\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0329 - mae: 0.1229 - val_loss: 0.0017 - val_mae: 0.0335\n",
      "Epoch 13/20\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0327 - mae: 0.1239 - val_loss: 4.9896e-04 - val_mae: 0.0173\n",
      "Epoch 14/20\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0320 - mae: 0.1210 - val_loss: 0.0068 - val_mae: 0.0770\n",
      "Epoch 15/20\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0315 - mae: 0.1207 - val_loss: 0.0035 - val_mae: 0.0513\n",
      "Epoch 16/20\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0299 - mae: 0.1171 - val_loss: 8.4557e-04 - val_mae: 0.0240\n",
      "Epoch 17/20\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0287 - mae: 0.1134 - val_loss: 0.0021 - val_mae: 0.0357\n",
      "Epoch 18/20\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0276 - mae: 0.1120 - val_loss: 0.0067 - val_mae: 0.0731\n",
      "Epoch 19/20\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0265 - mae: 0.1088 - val_loss: 0.0011 - val_mae: 0.0243\n",
      "Epoch 20/20\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0255 - mae: 0.1045 - val_loss: 0.0019 - val_mae: 0.0358\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step\n",
      "✅ Done: tomato_MadikeriKodagu_daily | MAE=60.91, RMSE=74.48, R2=0.75, MAPE=4.54%, Accuracy=95.46%\n",
      "\n",
      "========== Processing: tomato_Mandya_daily.csv ==========\n",
      "Epoch 1/20\n",
      "\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.0017 - mae: 0.0272 - val_loss: 0.0081 - val_mae: 0.0535\n",
      "Epoch 2/20\n",
      "\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0015 - mae: 0.0258 - val_loss: 0.0114 - val_mae: 0.0591\n",
      "Epoch 3/20\n",
      "\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0015 - mae: 0.0253 - val_loss: 0.0305 - val_mae: 0.0819\n",
      "Epoch 4/20\n",
      "\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0014 - mae: 0.0251 - val_loss: 0.0679 - val_mae: 0.1038\n",
      "Epoch 5/20\n",
      "\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0014 - mae: 0.0251 - val_loss: 0.0539 - val_mae: 0.0941\n",
      "Epoch 6/20\n",
      "\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0014 - mae: 0.0250 - val_loss: 0.0659 - val_mae: 0.1049\n",
      "Epoch 7/20\n",
      "\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0014 - mae: 0.0251 - val_loss: 0.0556 - val_mae: 0.0977\n",
      "Epoch 8/20\n",
      "\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0014 - mae: 0.0250 - val_loss: 0.0409 - val_mae: 0.0910\n",
      "Epoch 9/20\n",
      "\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0014 - mae: 0.0248 - val_loss: 0.0473 - val_mae: 0.0973\n",
      "Epoch 10/20\n",
      "\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0014 - mae: 0.0248 - val_loss: 0.0427 - val_mae: 0.0894\n",
      "Epoch 11/20\n",
      "\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0014 - mae: 0.0247 - val_loss: 0.0842 - val_mae: 0.1154\n",
      "Epoch 12/20\n",
      "\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0014 - mae: 0.0248 - val_loss: 0.0393 - val_mae: 0.0962\n",
      "Epoch 13/20\n",
      "\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0014 - mae: 0.0246 - val_loss: 0.0488 - val_mae: 0.1011\n",
      "Epoch 14/20\n",
      "\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0014 - mae: 0.0246 - val_loss: 0.0341 - val_mae: 0.0850\n",
      "Epoch 15/20\n",
      "\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0014 - mae: 0.0246 - val_loss: 0.0364 - val_mae: 0.0912\n",
      "Epoch 16/20\n",
      "\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0014 - mae: 0.0245 - val_loss: 0.0382 - val_mae: 0.0904\n",
      "Epoch 17/20\n",
      "\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0014 - mae: 0.0245 - val_loss: 0.0492 - val_mae: 0.1002\n",
      "Epoch 18/20\n",
      "\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0013 - mae: 0.0244 - val_loss: 0.0416 - val_mae: 0.0942\n",
      "Epoch 19/20\n",
      "\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0013 - mae: 0.0244 - val_loss: 0.0362 - val_mae: 0.0972\n",
      "Epoch 20/20\n",
      "\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0013 - mae: 0.0242 - val_loss: 0.0530 - val_mae: 0.1067\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step   \n",
      "✅ Done: tomato_Mandya_daily | MAE=1328.29, RMSE=2867.16, R2=-2.61, MAPE=62.77%, Accuracy=37.23%\n",
      "\n",
      "========== Processing: tomato_Mysore_daily.csv ==========\n",
      "Epoch 1/20\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - loss: 0.0018 - mae: 0.0277 - val_loss: 0.0044 - val_mae: 0.0450\n",
      "Epoch 2/20\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0016 - mae: 0.0268 - val_loss: 0.0043 - val_mae: 0.0441\n",
      "Epoch 3/20\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0016 - mae: 0.0266 - val_loss: 0.0043 - val_mae: 0.0440\n",
      "Epoch 4/20\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0016 - mae: 0.0267 - val_loss: 0.0046 - val_mae: 0.0451\n",
      "Epoch 5/20\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0016 - mae: 0.0267 - val_loss: 0.0047 - val_mae: 0.0456\n",
      "Epoch 6/20\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0016 - mae: 0.0266 - val_loss: 0.0044 - val_mae: 0.0465\n",
      "Epoch 7/20\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0017 - mae: 0.0269 - val_loss: 0.0047 - val_mae: 0.0454\n",
      "Epoch 8/20\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0016 - mae: 0.0267 - val_loss: 0.0045 - val_mae: 0.0453\n",
      "Epoch 9/20\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0016 - mae: 0.0267 - val_loss: 0.0042 - val_mae: 0.0439\n",
      "Epoch 10/20\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0016 - mae: 0.0266 - val_loss: 0.0043 - val_mae: 0.0434\n",
      "Epoch 11/20\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0016 - mae: 0.0266 - val_loss: 0.0042 - val_mae: 0.0439\n",
      "Epoch 12/20\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0016 - mae: 0.0266 - val_loss: 0.0045 - val_mae: 0.0443\n",
      "Epoch 13/20\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0016 - mae: 0.0265 - val_loss: 0.0043 - val_mae: 0.0441\n",
      "Epoch 14/20\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0016 - mae: 0.0264 - val_loss: 0.0042 - val_mae: 0.0436\n",
      "Epoch 15/20\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0016 - mae: 0.0265 - val_loss: 0.0042 - val_mae: 0.0442\n",
      "Epoch 16/20\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0016 - mae: 0.0265 - val_loss: 0.0046 - val_mae: 0.0451\n",
      "Epoch 17/20\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0016 - mae: 0.0265 - val_loss: 0.0043 - val_mae: 0.0437\n",
      "Epoch 18/20\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0016 - mae: 0.0265 - val_loss: 0.0041 - val_mae: 0.0436\n",
      "Epoch 19/20\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0016 - mae: 0.0265 - val_loss: 0.0047 - val_mae: 0.0434\n",
      "Epoch 20/20\n",
      "\u001b[1m685/685\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 0.0016 - mae: 0.0265 - val_loss: 0.0043 - val_mae: 0.0441\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step   \n",
      "✅ Done: tomato_Mysore_daily | MAE=667.15, RMSE=990.68, R2=0.18, MAPE=37.33%, Accuracy=62.67%\n",
      "\n",
      "========== Processing: tomato_Shimoga_daily.csv ==========\n",
      "Epoch 1/20\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0011 - mae: 0.0208 - val_loss: 0.0018 - val_mae: 0.0215\n",
      "Epoch 2/20\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 9.5005e-04 - mae: 0.0187 - val_loss: 0.0016 - val_mae: 0.0194\n",
      "Epoch 3/20\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 9.2226e-04 - mae: 0.0184 - val_loss: 0.0018 - val_mae: 0.0209\n",
      "Epoch 4/20\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 8.7227e-04 - mae: 0.0180 - val_loss: 0.0021 - val_mae: 0.0230\n",
      "Epoch 5/20\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 7.7174e-04 - mae: 0.0168 - val_loss: 0.0029 - val_mae: 0.0297\n",
      "Epoch 6/20\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 7.1491e-04 - mae: 0.0159 - val_loss: 0.0028 - val_mae: 0.0272\n",
      "Epoch 7/20\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 6.9524e-04 - mae: 0.0152 - val_loss: 0.0039 - val_mae: 0.0325\n",
      "Epoch 8/20\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 6.7642e-04 - mae: 0.0150 - val_loss: 0.0047 - val_mae: 0.0343\n",
      "Epoch 9/20\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 6.6299e-04 - mae: 0.0148 - val_loss: 0.0040 - val_mae: 0.0310\n",
      "Epoch 10/20\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 6.5719e-04 - mae: 0.0147 - val_loss: 0.0073 - val_mae: 0.0418\n",
      "Epoch 11/20\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 6.3694e-04 - mae: 0.0145 - val_loss: 0.0094 - val_mae: 0.0468\n",
      "Epoch 12/20\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 6.2850e-04 - mae: 0.0145 - val_loss: 0.0120 - val_mae: 0.0535\n",
      "Epoch 13/20\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 6.2386e-04 - mae: 0.0148 - val_loss: 0.0138 - val_mae: 0.0580\n",
      "Epoch 14/20\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 6.0558e-04 - mae: 0.0145 - val_loss: 0.0164 - val_mae: 0.0616\n",
      "Epoch 15/20\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 5.9337e-04 - mae: 0.0143 - val_loss: 0.0192 - val_mae: 0.0654\n",
      "Epoch 16/20\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 6.0105e-04 - mae: 0.0148 - val_loss: 0.0190 - val_mae: 0.0627\n",
      "Epoch 17/20\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 5.7612e-04 - mae: 0.0143 - val_loss: 0.0275 - val_mae: 0.0779\n",
      "Epoch 18/20\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 5.7115e-04 - mae: 0.0141 - val_loss: 0.0286 - val_mae: 0.0760\n",
      "Epoch 19/20\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 5.6189e-04 - mae: 0.0141 - val_loss: 0.0337 - val_mae: 0.0842\n",
      "Epoch 20/20\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 5.5186e-04 - mae: 0.0138 - val_loss: 0.0357 - val_mae: 0.0840\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step   \n",
      "✅ Done: tomato_Shimoga_daily | MAE=1469.29, RMSE=3305.69, R2=-3.76, MAPE=119.33%, Accuracy=-19.33%\n",
      "\n",
      "========== Processing: tomato_Tumkur_daily.csv ==========\n",
      "Epoch 1/20\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 8.6956e-04 - mae: 0.0178 - val_loss: 0.0138 - val_mae: 0.0907\n",
      "Epoch 2/20\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 1.4925e-04 - mae: 0.0065 - val_loss: 9.5884e-04 - val_mae: 0.0191\n",
      "Epoch 3/20\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.3404e-04 - mae: 0.0063 - val_loss: 7.8163e-04 - val_mae: 0.0124\n",
      "Epoch 4/20\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 1.3045e-04 - mae: 0.0060 - val_loss: 7.4462e-04 - val_mae: 0.0095\n",
      "Epoch 5/20\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.2837e-04 - mae: 0.0058 - val_loss: 7.4382e-04 - val_mae: 0.0116\n",
      "Epoch 6/20\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.2778e-04 - mae: 0.0058 - val_loss: 7.8276e-04 - val_mae: 0.0153\n",
      "Epoch 7/20\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.2924e-04 - mae: 0.0060 - val_loss: 8.1409e-04 - val_mae: 0.0168\n",
      "Epoch 8/20\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 1.2712e-04 - mae: 0.0060 - val_loss: 8.9540e-04 - val_mae: 0.0192\n",
      "Epoch 9/20\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.2555e-04 - mae: 0.0059 - val_loss: 7.9608e-04 - val_mae: 0.0165\n",
      "Epoch 10/20\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 1.2573e-04 - mae: 0.0059 - val_loss: 7.9943e-04 - val_mae: 0.0172\n",
      "Epoch 11/20\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 1.2601e-04 - mae: 0.0060 - val_loss: 6.5632e-04 - val_mae: 0.0121\n",
      "Epoch 12/20\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.2413e-04 - mae: 0.0058 - val_loss: 7.6426e-04 - val_mae: 0.0168\n",
      "Epoch 13/20\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.2317e-04 - mae: 0.0057 - val_loss: 7.3545e-04 - val_mae: 0.0162\n",
      "Epoch 14/20\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.2403e-04 - mae: 0.0060 - val_loss: 7.5592e-04 - val_mae: 0.0176\n",
      "Epoch 15/20\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.2354e-04 - mae: 0.0059 - val_loss: 8.8765e-04 - val_mae: 0.0206\n",
      "Epoch 16/20\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.2269e-04 - mae: 0.0059 - val_loss: 5.7640e-04 - val_mae: 0.0110\n",
      "Epoch 17/20\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.2211e-04 - mae: 0.0059 - val_loss: 5.9338e-04 - val_mae: 0.0128\n",
      "Epoch 18/20\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 1.2284e-04 - mae: 0.0060 - val_loss: 5.6920e-04 - val_mae: 0.0117\n",
      "Epoch 19/20\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 1.1778e-04 - mae: 0.0056 - val_loss: 5.2224e-04 - val_mae: 0.0097\n",
      "Epoch 20/20\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 1.1795e-04 - mae: 0.0055 - val_loss: 6.0329e-04 - val_mae: 0.0152\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step \n",
      "✅ Done: tomato_Tumkur_daily | MAE=171.31, RMSE=277.55, R2=0.98, MAPE=5.5%, Accuracy=94.5%\n",
      "\n",
      "========== Processing: tomato_Udupi_daily.csv ==========\n",
      "Epoch 1/20\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0025 - mae: 0.0299 - val_loss: 0.0032 - val_mae: 0.0291\n",
      "Epoch 2/20\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 4.5498e-04 - mae: 0.0144 - val_loss: 0.0031 - val_mae: 0.0272\n",
      "Epoch 3/20\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 4.4512e-04 - mae: 0.0144 - val_loss: 0.0031 - val_mae: 0.0272\n",
      "Epoch 4/20\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 4.2686e-04 - mae: 0.0140 - val_loss: 0.0029 - val_mae: 0.0257\n",
      "Epoch 5/20\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 4.2166e-04 - mae: 0.0140 - val_loss: 0.0030 - val_mae: 0.0291\n",
      "Epoch 6/20\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 4.1207e-04 - mae: 0.0138 - val_loss: 0.0024 - val_mae: 0.0240\n",
      "Epoch 7/20\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 4.0707e-04 - mae: 0.0138 - val_loss: 0.0023 - val_mae: 0.0232\n",
      "Epoch 8/20\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 3.8561e-04 - mae: 0.0132 - val_loss: 0.0022 - val_mae: 0.0210\n",
      "Epoch 9/20\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 3.8557e-04 - mae: 0.0133 - val_loss: 0.0021 - val_mae: 0.0242\n",
      "Epoch 10/20\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 3.7576e-04 - mae: 0.0131 - val_loss: 0.0020 - val_mae: 0.0216\n",
      "Epoch 11/20\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 3.5679e-04 - mae: 0.0126 - val_loss: 0.0018 - val_mae: 0.0205\n",
      "Epoch 12/20\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 3.4690e-04 - mae: 0.0124 - val_loss: 0.0020 - val_mae: 0.0207\n",
      "Epoch 13/20\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 3.3828e-04 - mae: 0.0122 - val_loss: 0.0023 - val_mae: 0.0234\n",
      "Epoch 14/20\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 3.3921e-04 - mae: 0.0122 - val_loss: 0.0027 - val_mae: 0.0246\n",
      "Epoch 15/20\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 3.4017e-04 - mae: 0.0124 - val_loss: 0.0025 - val_mae: 0.0246\n",
      "Epoch 16/20\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 3.2693e-04 - mae: 0.0119 - val_loss: 0.0030 - val_mae: 0.0263\n",
      "Epoch 17/20\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 3.1990e-04 - mae: 0.0118 - val_loss: 0.0041 - val_mae: 0.0318\n",
      "Epoch 18/20\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 3.1973e-04 - mae: 0.0119 - val_loss: 0.0053 - val_mae: 0.0316\n",
      "Epoch 19/20\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 3.1728e-04 - mae: 0.0119 - val_loss: 0.0043 - val_mae: 0.0306\n",
      "Epoch 20/20\n",
      "\u001b[1m165/165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 3.0906e-04 - mae: 0.0117 - val_loss: 0.0041 - val_mae: 0.0295\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step  \n",
      "✅ Done: tomato_Udupi_daily | MAE=280.66, RMSE=607.03, R2=0.9, MAPE=8.38%, Accuracy=91.62%\n",
      "\n",
      "📊 Metrics saved to: output_lstm_csv\\lstm_metrics.csv\n",
      "\n",
      "🎉 All districts processed successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "# -----------------------------\n",
    "# 🧹 Clean console output\n",
    "# -----------------------------\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "tf.get_logger().setLevel(\"ERROR\")\n",
    "\n",
    "# -----------------------------\n",
    "# Folders\n",
    "# -----------------------------\n",
    "input_folder = \"dataset\"\n",
    "output_models = \"output_lstm_models\"\n",
    "output_csv = \"output_lstm_csv\"\n",
    "output_graphs = \"output_lstm_graphs\"\n",
    "output_logs = \"output_lstm_logs\"\n",
    "metrics_file = os.path.join(output_csv, \"lstm_metrics.csv\")\n",
    "\n",
    "os.makedirs(output_models, exist_ok=True)\n",
    "os.makedirs(output_csv, exist_ok=True)\n",
    "os.makedirs(output_graphs, exist_ok=True)\n",
    "os.makedirs(output_logs, exist_ok=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Function to create sequences\n",
    "# -----------------------------\n",
    "def create_sequences(data, seq_length=5):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i+seq_length])\n",
    "        y.append(data[i+seq_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# -----------------------------\n",
    "# Store metrics\n",
    "# -----------------------------\n",
    "metrics_list = []\n",
    "\n",
    "# -----------------------------\n",
    "# Start Processing CSVs\n",
    "# -----------------------------\n",
    "seq_length = 5\n",
    "\n",
    "for file in os.listdir(input_folder):\n",
    "    if file.endswith(\".csv\"):\n",
    "        district_name = file.split(\".\")[0]\n",
    "        print(f\"\\n========== Processing: {file} ==========\")\n",
    "\n",
    "        df = pd.read_csv(os.path.join(input_folder, file))\n",
    "\n",
    "        df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "        df = df.dropna(subset=['Date'])\n",
    "        df = df.sort_values('Date')\n",
    "\n",
    "        # Fill missing prices\n",
    "        df['Average Price'] = df['Average Price'].fillna(df['Average Price'].mean())\n",
    "\n",
    "        # Moving averages (for graph only)\n",
    "        df['MA_7'] = df['Average Price'].rolling(7).mean().fillna(df['Average Price'].mean())\n",
    "        df['MA_30'] = df['Average Price'].rolling(30).mean().fillna(df['Average Price'].mean())\n",
    "\n",
    "        # Scaling\n",
    "        scaler = MinMaxScaler()\n",
    "        price_scaled = scaler.fit_transform(df['Average Price'].values.reshape(-1, 1))\n",
    "\n",
    "        # Create sequences\n",
    "        X, y = create_sequences(price_scaled, seq_length)\n",
    "\n",
    "        # Train-test split (80-20)\n",
    "        split = int(0.8 * len(X))\n",
    "        X_train, X_test = X[:split], X[split:]\n",
    "        y_train, y_test = y[:split], y[split:]\n",
    "\n",
    "        # Reshape to (samples, seq_length, 1)\n",
    "        X_train = X_train.reshape((X_train.shape[0], seq_length, 1))\n",
    "        X_test = X_test.reshape((X_test.shape[0], seq_length, 1))\n",
    "\n",
    "        # -----------------------------\n",
    "        # Build LSTM model\n",
    "        # -----------------------------\n",
    "        model = Sequential([\n",
    "            LSTM(50, activation='relu', input_shape=(seq_length, 1)),\n",
    "            Dense(1)\n",
    "        ])\n",
    "        model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "        # -----------------------------\n",
    "        # Train Model\n",
    "        # -----------------------------\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            epochs=20,\n",
    "            batch_size=32,\n",
    "            validation_data=(X_test, y_test),\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        # -----------------------------\n",
    "        # Predictions\n",
    "        # -----------------------------\n",
    "        y_pred_scaled = model.predict(X_test)\n",
    "        y_pred = scaler.inverse_transform(y_pred_scaled)\n",
    "        y_true = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "        y_true_round = np.round(y_true, 2)\n",
    "        y_pred_round = np.round(y_pred, 2)\n",
    "\n",
    "        # -----------------------------\n",
    "        # Save Predictions\n",
    "        # -----------------------------\n",
    "        df_pred = df.iloc[seq_length + split:].copy()\n",
    "        df_pred = df_pred[['Date']].copy()\n",
    "        df_pred['Actual'] = y_true_round.flatten()\n",
    "        df_pred['Predicted'] = y_pred_round.flatten()\n",
    "\n",
    "        df_pred.to_csv(os.path.join(output_csv, f\"{district_name}_lstm_updated.csv\"), index=False)\n",
    "\n",
    "        # -----------------------------\n",
    "        # Metrics\n",
    "        # -----------------------------\n",
    "        mae_val = round(mean_absolute_error(y_true, y_pred), 2)\n",
    "        rmse_val = round(np.sqrt(mean_squared_error(y_true, y_pred)), 2)  # FIXED\n",
    "        r2_val = round(r2_score(y_true, y_pred), 2)\n",
    "        mape_val = round(np.mean(np.abs((y_true - y_pred) / y_true)) * 100, 2)\n",
    "        accuracy_val = round(100 - mape_val, 2)\n",
    "\n",
    "        metrics_list.append([district_name, mae_val, rmse_val, r2_val, mape_val, accuracy_val])\n",
    "\n",
    "        print(f\"✅ Done: {district_name} | MAE={mae_val}, RMSE={rmse_val}, R2={r2_val}, MAPE={mape_val}%, Accuracy={accuracy_val}%\")\n",
    "\n",
    "        # -----------------------------\n",
    "        # Save Model\n",
    "        # -----------------------------\n",
    "        model_path = os.path.join(output_models, f\"{district_name}_lstm_model.pkl\")\n",
    "        joblib.dump(model, model_path)\n",
    "\n",
    "        # -----------------------------\n",
    "        # Prediction Graph\n",
    "        # -----------------------------\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(df['Date'], df['Average Price'], label='Actual Price', color='blue')\n",
    "        plt.plot(df['Date'], df['MA_7'], label='MA 7', color='orange')\n",
    "        plt.plot(df['Date'], df['MA_30'], label='MA 30', color='green')\n",
    "        plt.plot(df_pred['Date'], df_pred['Predicted'], label='Predicted', color='red', linestyle='dashed')\n",
    "        plt.title(f\"LSTM Daily Prediction - {district_name}\")\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Average Price')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.savefig(os.path.join(output_graphs, f\"{district_name}_lstm_graph.png\"))\n",
    "        plt.close()\n",
    "\n",
    "        # -----------------------------\n",
    "        # Training Loss Graph\n",
    "        # -----------------------------\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        plt.plot(history.history['loss'], label='Training Loss')\n",
    "        plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "        plt.title(f\"Training Loss - {district_name}\")\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.savefig(os.path.join(output_graphs, f\"{district_name}_lstm_training_loss.png\"))\n",
    "        plt.close()\n",
    "\n",
    "# -----------------------------\n",
    "# Save Metrics\n",
    "# -----------------------------\n",
    "metrics_df = pd.DataFrame(\n",
    "    metrics_list,\n",
    "    columns=['District', 'MAE', 'RMSE', 'R2', 'MAPE(%)', 'Accuracy(%)']\n",
    ")\n",
    "metrics_df.to_csv(metrics_file, index=False)\n",
    "\n",
    "print(f\"\\n📊 Metrics saved to: {metrics_file}\")\n",
    "print(\"\\n🎉 All districts processed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cecf9a-e487-42c6-bd4c-d113939625ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c15f2cc0-69e0-42f6-b5ff-32be87e43b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Processing: tomato_Bangalore_daily.csv\n",
      "Epoch 1/20\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 27ms/step - loss: 0.0016 - mae: 0.0194 - val_loss: 0.0010 - val_mae: 0.0211\n",
      "Epoch 2/20\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 26ms/step - loss: 0.0015 - mae: 0.0186 - val_loss: 0.0011 - val_mae: 0.0212\n",
      "Epoch 3/20\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 28ms/step - loss: 0.0014 - mae: 0.0178 - val_loss: 0.0019 - val_mae: 0.0301\n",
      "Epoch 4/20\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 25ms/step - loss: 0.0014 - mae: 0.0176 - val_loss: 0.0011 - val_mae: 0.0218\n",
      "Epoch 5/20\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 28ms/step - loss: 0.0013 - mae: 0.0174 - val_loss: 9.5545e-04 - val_mae: 0.0207\n",
      "Epoch 6/20\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 29ms/step - loss: 0.0013 - mae: 0.0172 - val_loss: 0.0010 - val_mae: 0.0208\n",
      "Epoch 7/20\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 27ms/step - loss: 0.0013 - mae: 0.0172 - val_loss: 0.0012 - val_mae: 0.0225\n",
      "Epoch 8/20\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 27ms/step - loss: 0.0013 - mae: 0.0169 - val_loss: 0.0011 - val_mae: 0.0220\n",
      "Epoch 9/20\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 31ms/step - loss: 0.0013 - mae: 0.0171 - val_loss: 0.0014 - val_mae: 0.0233\n",
      "Epoch 10/20\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 30ms/step - loss: 0.0013 - mae: 0.0170 - val_loss: 0.0011 - val_mae: 0.0217\n",
      "Epoch 11/20\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 28ms/step - loss: 0.0013 - mae: 0.0169 - val_loss: 0.0012 - val_mae: 0.0225\n",
      "Epoch 12/20\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 29ms/step - loss: 0.0013 - mae: 0.0168 - val_loss: 0.0011 - val_mae: 0.0216\n",
      "Epoch 13/20\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 29ms/step - loss: 0.0013 - mae: 0.0169 - val_loss: 0.0012 - val_mae: 0.0229\n",
      "Epoch 14/20\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 30ms/step - loss: 0.0013 - mae: 0.0168 - val_loss: 0.0014 - val_mae: 0.0240\n",
      "Epoch 15/20\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 28ms/step - loss: 0.0013 - mae: 0.0167 - val_loss: 0.0012 - val_mae: 0.0223\n",
      "Epoch 16/20\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 27ms/step - loss: 0.0013 - mae: 0.0167 - val_loss: 0.0013 - val_mae: 0.0228\n",
      "Epoch 17/20\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 28ms/step - loss: 0.0013 - mae: 0.0166 - val_loss: 0.0013 - val_mae: 0.0234\n",
      "Epoch 18/20\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 26ms/step - loss: 0.0013 - mae: 0.0168 - val_loss: 0.0013 - val_mae: 0.0228\n",
      "Epoch 19/20\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 29ms/step - loss: 0.0013 - mae: 0.0166 - val_loss: 0.0019 - val_mae: 0.0256\n",
      "Epoch 20/20\n",
      "\u001b[1m1382/1382\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 27ms/step - loss: 0.0013 - mae: 0.0167 - val_loss: 0.0017 - val_mae: 0.0246\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step\n",
      "✅ Done with tomato_Bangalore_daily.csv | MAE=611.7, RMSE=1011.16, R2=0.7, MAPE=26.17%, Accuracy=73.83%\n",
      "\n",
      "🚀 Processing: tomato_Belgaum_daily.csv\n",
      "Epoch 1/20\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 31ms/step - loss: 6.1491e-04 - mae: 0.0155 - val_loss: 0.0030 - val_mae: 0.0341\n",
      "Epoch 2/20\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - loss: 2.2793e-04 - mae: 0.0104 - val_loss: 0.0028 - val_mae: 0.0316\n",
      "Epoch 3/20\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - loss: 1.9119e-04 - mae: 0.0095 - val_loss: 0.0027 - val_mae: 0.0317\n",
      "Epoch 4/20\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - loss: 1.5692e-04 - mae: 0.0086 - val_loss: 0.0027 - val_mae: 0.0322\n",
      "Epoch 5/20\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - loss: 1.3312e-04 - mae: 0.0077 - val_loss: 0.0028 - val_mae: 0.0331\n",
      "Epoch 6/20\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - loss: 1.4523e-04 - mae: 0.0082 - val_loss: 0.0026 - val_mae: 0.0305\n",
      "Epoch 7/20\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - loss: 1.4264e-04 - mae: 0.0081 - val_loss: 0.0025 - val_mae: 0.0300\n",
      "Epoch 8/20\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - loss: 1.4260e-04 - mae: 0.0080 - val_loss: 0.0031 - val_mae: 0.0371\n",
      "Epoch 9/20\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - loss: 1.3363e-04 - mae: 0.0078 - val_loss: 0.0024 - val_mae: 0.0291\n",
      "Epoch 10/20\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - loss: 1.2717e-04 - mae: 0.0074 - val_loss: 0.0025 - val_mae: 0.0299\n",
      "Epoch 11/20\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - loss: 1.4244e-04 - mae: 0.0079 - val_loss: 0.0024 - val_mae: 0.0295\n",
      "Epoch 12/20\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - loss: 1.2444e-04 - mae: 0.0073 - val_loss: 0.0025 - val_mae: 0.0308\n",
      "Epoch 13/20\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - loss: 1.2888e-04 - mae: 0.0075 - val_loss: 0.0024 - val_mae: 0.0298\n",
      "Epoch 14/20\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - loss: 1.2708e-04 - mae: 0.0075 - val_loss: 0.0024 - val_mae: 0.0289\n",
      "Epoch 15/20\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - loss: 1.2732e-04 - mae: 0.0074 - val_loss: 0.0024 - val_mae: 0.0296\n",
      "Epoch 16/20\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - loss: 1.2117e-04 - mae: 0.0073 - val_loss: 0.0023 - val_mae: 0.0283\n",
      "Epoch 17/20\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - loss: 1.2048e-04 - mae: 0.0071 - val_loss: 0.0024 - val_mae: 0.0301\n",
      "Epoch 18/20\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 32ms/step - loss: 1.1561e-04 - mae: 0.0071 - val_loss: 0.0023 - val_mae: 0.0284\n",
      "Epoch 19/20\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - loss: 1.2458e-04 - mae: 0.0075 - val_loss: 0.0023 - val_mae: 0.0286\n",
      "Epoch 20/20\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - loss: 1.1961e-04 - mae: 0.0071 - val_loss: 0.0023 - val_mae: 0.0288\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step\n",
      "✅ Done with tomato_Belgaum_daily.csv | MAE=279.2, RMSE=464.7, R2=0.91, MAPE=10.5%, Accuracy=89.5%\n",
      "\n",
      "🚀 Processing: tomato_Bellary_daily.csv\n",
      "Epoch 1/20\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 31ms/step - loss: 0.0017 - mae: 0.0256 - val_loss: 0.0019 - val_mae: 0.0232\n",
      "Epoch 2/20\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - loss: 0.0012 - mae: 0.0217 - val_loss: 0.0013 - val_mae: 0.0210\n",
      "Epoch 3/20\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 23ms/step - loss: 0.0012 - mae: 0.0213 - val_loss: 0.0019 - val_mae: 0.0242\n",
      "Epoch 4/20\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - loss: 0.0011 - mae: 0.0210 - val_loss: 0.0013 - val_mae: 0.0223\n",
      "Epoch 5/20\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - loss: 0.0012 - mae: 0.0208 - val_loss: 0.0023 - val_mae: 0.0308\n",
      "Epoch 6/20\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - loss: 0.0011 - mae: 0.0207 - val_loss: 0.0020 - val_mae: 0.0243\n",
      "Epoch 7/20\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - loss: 0.0011 - mae: 0.0203 - val_loss: 0.0013 - val_mae: 0.0202\n",
      "Epoch 8/20\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - loss: 0.0011 - mae: 0.0205 - val_loss: 0.0021 - val_mae: 0.0270\n",
      "Epoch 9/20\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - loss: 0.0011 - mae: 0.0202 - val_loss: 0.0016 - val_mae: 0.0213\n",
      "Epoch 10/20\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - loss: 0.0011 - mae: 0.0201 - val_loss: 0.0032 - val_mae: 0.0272\n",
      "Epoch 11/20\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - loss: 0.0011 - mae: 0.0202 - val_loss: 0.0024 - val_mae: 0.0248\n",
      "Epoch 12/20\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - loss: 0.0011 - mae: 0.0197 - val_loss: 0.0023 - val_mae: 0.0251\n",
      "Epoch 13/20\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - loss: 0.0011 - mae: 0.0199 - val_loss: 0.0030 - val_mae: 0.0281\n",
      "Epoch 14/20\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - loss: 0.0011 - mae: 0.0194 - val_loss: 0.0034 - val_mae: 0.0280\n",
      "Epoch 15/20\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - loss: 0.0011 - mae: 0.0200 - val_loss: 0.0027 - val_mae: 0.0249\n",
      "Epoch 16/20\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - loss: 0.0010 - mae: 0.0191 - val_loss: 0.0046 - val_mae: 0.0327\n",
      "Epoch 17/20\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 28ms/step - loss: 0.0011 - mae: 0.0196 - val_loss: 0.0019 - val_mae: 0.0232\n",
      "Epoch 18/20\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - loss: 0.0011 - mae: 0.0195 - val_loss: 0.0039 - val_mae: 0.0296\n",
      "Epoch 19/20\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - loss: 0.0011 - mae: 0.0198 - val_loss: 0.0022 - val_mae: 0.0232\n",
      "Epoch 20/20\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - loss: 0.0010 - mae: 0.0194 - val_loss: 0.0040 - val_mae: 0.0338\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step  \n",
      "✅ Done with tomato_Bellary_daily.csv | MAE=234.13, RMSE=435.16, R2=0.83, MAPE=23.27%, Accuracy=76.73%\n",
      "\n",
      "🚀 Processing: tomato_Chamrajnagar_daily.csv\n",
      "Epoch 1/20\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 25ms/step - loss: 3.9273e-04 - mae: 0.0135 - val_loss: 0.0016 - val_mae: 0.0273\n",
      "Epoch 2/20\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 28ms/step - loss: 3.3337e-04 - mae: 0.0122 - val_loss: 0.0016 - val_mae: 0.0273\n",
      "Epoch 3/20\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 25ms/step - loss: 3.1751e-04 - mae: 0.0119 - val_loss: 0.0016 - val_mae: 0.0279\n",
      "Epoch 4/20\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 26ms/step - loss: 3.0891e-04 - mae: 0.0116 - val_loss: 0.0018 - val_mae: 0.0305\n",
      "Epoch 5/20\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 24ms/step - loss: 3.0092e-04 - mae: 0.0113 - val_loss: 0.0019 - val_mae: 0.0297\n",
      "Epoch 6/20\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 24ms/step - loss: 2.9945e-04 - mae: 0.0112 - val_loss: 0.0019 - val_mae: 0.0298\n",
      "Epoch 7/20\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 28ms/step - loss: 2.9849e-04 - mae: 0.0113 - val_loss: 0.0019 - val_mae: 0.0308\n",
      "Epoch 8/20\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 26ms/step - loss: 2.9628e-04 - mae: 0.0112 - val_loss: 0.0020 - val_mae: 0.0306\n",
      "Epoch 9/20\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 27ms/step - loss: 2.9466e-04 - mae: 0.0111 - val_loss: 0.0021 - val_mae: 0.0317\n",
      "Epoch 10/20\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 27ms/step - loss: 2.9415e-04 - mae: 0.0110 - val_loss: 0.0021 - val_mae: 0.0317\n",
      "Epoch 11/20\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 27ms/step - loss: 2.9066e-04 - mae: 0.0109 - val_loss: 0.0022 - val_mae: 0.0317\n",
      "Epoch 12/20\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 25ms/step - loss: 2.9275e-04 - mae: 0.0110 - val_loss: 0.0025 - val_mae: 0.0333\n",
      "Epoch 13/20\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 25ms/step - loss: 2.8966e-04 - mae: 0.0109 - val_loss: 0.0022 - val_mae: 0.0312\n",
      "Epoch 14/20\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 27ms/step - loss: 2.8884e-04 - mae: 0.0108 - val_loss: 0.0023 - val_mae: 0.0324\n",
      "Epoch 15/20\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 28ms/step - loss: 2.8914e-04 - mae: 0.0108 - val_loss: 0.0023 - val_mae: 0.0322\n",
      "Epoch 16/20\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 29ms/step - loss: 2.8936e-04 - mae: 0.0108 - val_loss: 0.0021 - val_mae: 0.0323\n",
      "Epoch 17/20\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 27ms/step - loss: 2.8712e-04 - mae: 0.0108 - val_loss: 0.0022 - val_mae: 0.0320\n",
      "Epoch 18/20\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 26ms/step - loss: 2.9031e-04 - mae: 0.0108 - val_loss: 0.0023 - val_mae: 0.0325\n",
      "Epoch 19/20\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 23ms/step - loss: 2.8672e-04 - mae: 0.0108 - val_loss: 0.0023 - val_mae: 0.0328\n",
      "Epoch 20/20\n",
      "\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 25ms/step - loss: 2.8819e-04 - mae: 0.0108 - val_loss: 0.0023 - val_mae: 0.0326\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step\n",
      "✅ Done with tomato_Chamrajnagar_daily.csv | MAE=1603.85, RMSE=2371.21, R2=0.04, MAPE=86.29%, Accuracy=13.71%\n",
      "\n",
      "🚀 Processing: tomato_Chikmagalur_daily.csv\n",
      "Epoch 1/20\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 26ms/step - loss: 0.0027 - mae: 0.0347 - val_loss: 0.0081 - val_mae: 0.0594\n",
      "Epoch 2/20\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 24ms/step - loss: 0.0024 - mae: 0.0326 - val_loss: 0.0093 - val_mae: 0.0629\n",
      "Epoch 3/20\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 24ms/step - loss: 0.0024 - mae: 0.0323 - val_loss: 0.0095 - val_mae: 0.0630\n",
      "Epoch 4/20\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 25ms/step - loss: 0.0024 - mae: 0.0320 - val_loss: 0.0096 - val_mae: 0.0632\n",
      "Epoch 5/20\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 24ms/step - loss: 0.0024 - mae: 0.0319 - val_loss: 0.0107 - val_mae: 0.0654\n",
      "Epoch 6/20\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 24ms/step - loss: 0.0023 - mae: 0.0318 - val_loss: 0.0094 - val_mae: 0.0622\n",
      "Epoch 7/20\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 24ms/step - loss: 0.0023 - mae: 0.0316 - val_loss: 0.0109 - val_mae: 0.0658\n",
      "Epoch 8/20\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 24ms/step - loss: 0.0023 - mae: 0.0317 - val_loss: 0.0101 - val_mae: 0.0636\n",
      "Epoch 9/20\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 25ms/step - loss: 0.0023 - mae: 0.0314 - val_loss: 0.0102 - val_mae: 0.0640\n",
      "Epoch 10/20\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 23ms/step - loss: 0.0023 - mae: 0.0313 - val_loss: 0.0102 - val_mae: 0.0642\n",
      "Epoch 11/20\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 24ms/step - loss: 0.0023 - mae: 0.0313 - val_loss: 0.0102 - val_mae: 0.0643\n",
      "Epoch 12/20\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 24ms/step - loss: 0.0023 - mae: 0.0312 - val_loss: 0.0110 - val_mae: 0.0659\n",
      "Epoch 13/20\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 27ms/step - loss: 0.0023 - mae: 0.0312 - val_loss: 0.0103 - val_mae: 0.0644\n",
      "Epoch 14/20\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 24ms/step - loss: 0.0023 - mae: 0.0313 - val_loss: 0.0132 - val_mae: 0.0708\n",
      "Epoch 15/20\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 26ms/step - loss: 0.0023 - mae: 0.0312 - val_loss: 0.0098 - val_mae: 0.0634\n",
      "Epoch 16/20\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 25ms/step - loss: 0.0023 - mae: 0.0313 - val_loss: 0.0113 - val_mae: 0.0667\n",
      "Epoch 17/20\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 27ms/step - loss: 0.0023 - mae: 0.0312 - val_loss: 0.0111 - val_mae: 0.0661\n",
      "Epoch 18/20\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 25ms/step - loss: 0.0023 - mae: 0.0311 - val_loss: 0.0105 - val_mae: 0.0649\n",
      "Epoch 19/20\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 26ms/step - loss: 0.0023 - mae: 0.0311 - val_loss: 0.0103 - val_mae: 0.0649\n",
      "Epoch 20/20\n",
      "\u001b[1m1165/1165\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 25ms/step - loss: 0.0023 - mae: 0.0313 - val_loss: 0.0117 - val_mae: 0.0675\n",
      "\u001b[1m146/146\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step\n",
      "✅ Done with tomato_Chikmagalur_daily.csv | MAE=741.17, RMSE=1187.56, R2=0.22, MAPE=56.69%, Accuracy=43.31%\n",
      "\n",
      "🚀 Processing: tomato_Chitradurga_daily.csv\n",
      "Epoch 1/20\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 31ms/step - loss: 0.0027 - mae: 0.0284 - val_loss: 2.5484e-07 - val_mae: 5.0482e-04\n",
      "Epoch 2/20\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - loss: 0.0010 - mae: 0.0180 - val_loss: 4.7830e-05 - val_mae: 0.0069\n",
      "Epoch 3/20\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - loss: 0.0010 - mae: 0.0179 - val_loss: 1.6093e-05 - val_mae: 0.0040\n",
      "Epoch 4/20\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - loss: 9.8101e-04 - mae: 0.0177 - val_loss: 1.9724e-05 - val_mae: 0.0044\n",
      "Epoch 5/20\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - loss: 7.6170e-04 - mae: 0.0148 - val_loss: 6.5961e-05 - val_mae: 0.0081\n",
      "Epoch 6/20\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - loss: 8.0246e-04 - mae: 0.0155 - val_loss: 6.9553e-06 - val_mae: 0.0026\n",
      "Epoch 7/20\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - loss: 6.5201e-04 - mae: 0.0139 - val_loss: 1.8204e-04 - val_mae: 0.0135\n",
      "Epoch 8/20\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - loss: 6.4936e-04 - mae: 0.0138 - val_loss: 3.9239e-06 - val_mae: 0.0020\n",
      "Epoch 9/20\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - loss: 7.2261e-04 - mae: 0.0146 - val_loss: 2.3594e-05 - val_mae: 0.0049\n",
      "Epoch 10/20\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - loss: 7.6281e-04 - mae: 0.0155 - val_loss: 1.6153e-05 - val_mae: 0.0040\n",
      "Epoch 11/20\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - loss: 6.5177e-04 - mae: 0.0146 - val_loss: 2.1820e-05 - val_mae: 0.0047\n",
      "Epoch 12/20\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - loss: 6.8940e-04 - mae: 0.0153 - val_loss: 1.3191e-05 - val_mae: 0.0036\n",
      "Epoch 13/20\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 27ms/step - loss: 7.0395e-04 - mae: 0.0147 - val_loss: 2.5744e-05 - val_mae: 0.0051\n",
      "Epoch 14/20\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - loss: 5.7804e-04 - mae: 0.0137 - val_loss: 1.1593e-07 - val_mae: 3.4049e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - loss: 6.0022e-04 - mae: 0.0141 - val_loss: 7.4443e-06 - val_mae: 0.0027\n",
      "Epoch 16/20\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - loss: 6.0771e-04 - mae: 0.0138 - val_loss: 1.2378e-05 - val_mae: 0.0035\n",
      "Epoch 17/20\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - loss: 5.7286e-04 - mae: 0.0139 - val_loss: 1.4601e-08 - val_mae: 1.2083e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - loss: 5.7621e-04 - mae: 0.0133 - val_loss: 1.3087e-05 - val_mae: 0.0036\n",
      "Epoch 19/20\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - loss: 5.7865e-04 - mae: 0.0143 - val_loss: 2.0216e-05 - val_mae: 0.0045\n",
      "Epoch 20/20\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 27ms/step - loss: 5.8091e-04 - mae: 0.0143 - val_loss: 6.6141e-05 - val_mae: 0.0081\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step  \n",
      "✅ Done with tomato_Chitradurga_daily.csv | MAE=42.03, RMSE=42.03, R2=0.0, MAPE=4.2%, Accuracy=95.8%\n",
      "\n",
      "🚀 Processing: tomato_Davangere_daily.csv\n",
      "Epoch 1/20\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 27ms/step - loss: 0.0034 - mae: 0.0413 - val_loss: 0.0055 - val_mae: 0.0438\n",
      "Epoch 2/20\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 24ms/step - loss: 0.0030 - mae: 0.0379 - val_loss: 0.0057 - val_mae: 0.0429\n",
      "Epoch 3/20\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 25ms/step - loss: 0.0028 - mae: 0.0364 - val_loss: 0.0056 - val_mae: 0.0447\n",
      "Epoch 4/20\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 26ms/step - loss: 0.0028 - mae: 0.0360 - val_loss: 0.0064 - val_mae: 0.0457\n",
      "Epoch 5/20\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 24ms/step - loss: 0.0028 - mae: 0.0359 - val_loss: 0.0061 - val_mae: 0.0446\n",
      "Epoch 6/20\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 25ms/step - loss: 0.0027 - mae: 0.0357 - val_loss: 0.0064 - val_mae: 0.0462\n",
      "Epoch 7/20\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 25ms/step - loss: 0.0027 - mae: 0.0356 - val_loss: 0.0068 - val_mae: 0.0474\n",
      "Epoch 8/20\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 26ms/step - loss: 0.0027 - mae: 0.0353 - val_loss: 0.0061 - val_mae: 0.0442\n",
      "Epoch 9/20\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 24ms/step - loss: 0.0027 - mae: 0.0347 - val_loss: 0.0067 - val_mae: 0.0473\n",
      "Epoch 10/20\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - loss: 0.0027 - mae: 0.0352 - val_loss: 0.0063 - val_mae: 0.0478\n",
      "Epoch 11/20\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 24ms/step - loss: 0.0027 - mae: 0.0352 - val_loss: 0.0072 - val_mae: 0.0520\n",
      "Epoch 12/20\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 26ms/step - loss: 0.0026 - mae: 0.0348 - val_loss: 0.0071 - val_mae: 0.0482\n",
      "Epoch 13/20\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 24ms/step - loss: 0.0027 - mae: 0.0348 - val_loss: 0.0064 - val_mae: 0.0462\n",
      "Epoch 14/20\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - loss: 0.0026 - mae: 0.0348 - val_loss: 0.0068 - val_mae: 0.0476\n",
      "Epoch 15/20\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 24ms/step - loss: 0.0026 - mae: 0.0346 - val_loss: 0.0066 - val_mae: 0.0470\n",
      "Epoch 16/20\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 25ms/step - loss: 0.0026 - mae: 0.0344 - val_loss: 0.0064 - val_mae: 0.0464\n",
      "Epoch 17/20\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 25ms/step - loss: 0.0026 - mae: 0.0343 - val_loss: 0.0062 - val_mae: 0.0471\n",
      "Epoch 18/20\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 26ms/step - loss: 0.0026 - mae: 0.0344 - val_loss: 0.0069 - val_mae: 0.0503\n",
      "Epoch 19/20\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 25ms/step - loss: 0.0026 - mae: 0.0346 - val_loss: 0.0062 - val_mae: 0.0457\n",
      "Epoch 20/20\n",
      "\u001b[1m483/483\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 26ms/step - loss: 0.0026 - mae: 0.0344 - val_loss: 0.0070 - val_mae: 0.0499\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step\n",
      "✅ Done with tomato_Davangere_daily.csv | MAE=407.01, RMSE=682.77, R2=0.74, MAPE=29.84%, Accuracy=70.16%\n",
      "\n",
      "🚀 Processing: tomato_Dharwad_daily.csv\n",
      "Epoch 1/20\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 51ms/step - loss: 0.0063 - mae: 0.0542 - val_loss: 0.0089 - val_mae: 0.0301\n",
      "Epoch 2/20\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0025 - mae: 0.0334 - val_loss: 0.0050 - val_mae: 0.0221\n",
      "Epoch 3/20\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0026 - mae: 0.0339 - val_loss: 0.0057 - val_mae: 0.0245\n",
      "Epoch 4/20\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0024 - mae: 0.0311 - val_loss: 0.0050 - val_mae: 0.0254\n",
      "Epoch 5/20\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.0020 - mae: 0.0278 - val_loss: 0.0044 - val_mae: 0.0230\n",
      "Epoch 6/20\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.0022 - mae: 0.0280 - val_loss: 0.0061 - val_mae: 0.0320\n",
      "Epoch 7/20\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0020 - mae: 0.0285 - val_loss: 0.0042 - val_mae: 0.0140\n",
      "Epoch 8/20\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.0022 - mae: 0.0276 - val_loss: 0.0048 - val_mae: 0.0221\n",
      "Epoch 9/20\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0020 - mae: 0.0281 - val_loss: 0.0056 - val_mae: 0.0335\n",
      "Epoch 10/20\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0022 - mae: 0.0272 - val_loss: 0.0048 - val_mae: 0.0209\n",
      "Epoch 11/20\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 0.0019 - mae: 0.0263 - val_loss: 0.0038 - val_mae: 0.0287\n",
      "Epoch 12/20\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0019 - mae: 0.0268 - val_loss: 0.0049 - val_mae: 0.0251\n",
      "Epoch 13/20\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0019 - mae: 0.0248 - val_loss: 0.0037 - val_mae: 0.0121\n",
      "Epoch 14/20\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0019 - mae: 0.0248 - val_loss: 0.0048 - val_mae: 0.0200\n",
      "Epoch 15/20\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 0.0020 - mae: 0.0273 - val_loss: 0.0042 - val_mae: 0.0165\n",
      "Epoch 16/20\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.0020 - mae: 0.0258 - val_loss: 0.0041 - val_mae: 0.0154\n",
      "Epoch 17/20\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0019 - mae: 0.0253 - val_loss: 0.0035 - val_mae: 0.0178\n",
      "Epoch 18/20\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 0.0019 - mae: 0.0243 - val_loss: 0.0041 - val_mae: 0.0182\n",
      "Epoch 19/20\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0019 - mae: 0.0244 - val_loss: 0.0047 - val_mae: 0.0257\n",
      "Epoch 20/20\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0019 - mae: 0.0251 - val_loss: 0.0039 - val_mae: 0.0203\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 144ms/step\n",
      "✅ Done with tomato_Dharwad_daily.csv | MAE=145.41, RMSE=444.7, R2=0.91, MAPE=4.2%, Accuracy=95.8%\n",
      "\n",
      "🚀 Processing: tomato_Gadag_daily.csv\n",
      "Epoch 1/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 53ms/step - loss: 0.0368 - mae: 0.1299 - val_loss: 0.0076 - val_mae: 0.0844\n",
      "Epoch 2/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0050 - mae: 0.0537 - val_loss: 0.0017 - val_mae: 0.0262\n",
      "Epoch 3/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0042 - mae: 0.0476 - val_loss: 0.0018 - val_mae: 0.0305\n",
      "Epoch 4/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0041 - mae: 0.0470 - val_loss: 0.0036 - val_mae: 0.0564\n",
      "Epoch 5/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0036 - mae: 0.0451 - val_loss: 0.0020 - val_mae: 0.0357\n",
      "Epoch 6/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.0035 - mae: 0.0440 - val_loss: 0.0015 - val_mae: 0.0123\n",
      "Epoch 7/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0034 - mae: 0.0430 - val_loss: 0.0015 - val_mae: 0.0155\n",
      "Epoch 8/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 0.0031 - mae: 0.0404 - val_loss: 0.0020 - val_mae: 0.0288\n",
      "Epoch 9/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 0.0027 - mae: 0.0398 - val_loss: 0.0023 - val_mae: 0.0427\n",
      "Epoch 10/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0029 - mae: 0.0400 - val_loss: 0.0014 - val_mae: 0.0146\n",
      "Epoch 11/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0030 - mae: 0.0404 - val_loss: 0.0016 - val_mae: 0.0183\n",
      "Epoch 12/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0026 - mae: 0.0377 - val_loss: 0.0014 - val_mae: 0.0146\n",
      "Epoch 13/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0023 - mae: 0.0355 - val_loss: 0.0013 - val_mae: 0.0110\n",
      "Epoch 14/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.0025 - mae: 0.0362 - val_loss: 0.0026 - val_mae: 0.0470\n",
      "Epoch 15/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0024 - mae: 0.0359 - val_loss: 0.0014 - val_mae: 0.0163\n",
      "Epoch 16/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0023 - mae: 0.0354 - val_loss: 0.0017 - val_mae: 0.0333\n",
      "Epoch 17/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 0.0023 - mae: 0.0355 - val_loss: 0.0013 - val_mae: 0.0107\n",
      "Epoch 18/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.0022 - mae: 0.0342 - val_loss: 0.0016 - val_mae: 0.0319\n",
      "Epoch 19/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0020 - mae: 0.0324 - val_loss: 0.0013 - val_mae: 0.0215\n",
      "Epoch 20/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 0.0017 - mae: 0.0307 - val_loss: 0.0013 - val_mae: 0.0150\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 163ms/step\n",
      "✅ Done with tomato_Gadag_daily.csv | MAE=124.88, RMSE=299.42, R2=0.89, MAPE=1.93%, Accuracy=98.07%\n",
      "\n",
      "🚀 Processing: tomato_Hassan_daily.csv\n",
      "Epoch 1/20\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 94ms/step - loss: 0.0019 - mae: 0.0321 - val_loss: 0.0062 - val_mae: 0.0542\n",
      "Epoch 2/20\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 88ms/step - loss: 0.0017 - mae: 0.0301 - val_loss: 0.0060 - val_mae: 0.0517\n",
      "Epoch 3/20\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 88ms/step - loss: 0.0017 - mae: 0.0300 - val_loss: 0.0056 - val_mae: 0.0511\n",
      "Epoch 4/20\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 87ms/step - loss: 0.0016 - mae: 0.0297 - val_loss: 0.0062 - val_mae: 0.0521\n",
      "Epoch 5/20\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 88ms/step - loss: 0.0016 - mae: 0.0295 - val_loss: 0.0062 - val_mae: 0.0522\n",
      "Epoch 6/20\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 87ms/step - loss: 0.0016 - mae: 0.0296 - val_loss: 0.0066 - val_mae: 0.0532\n",
      "Epoch 7/20\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 87ms/step - loss: 0.0016 - mae: 0.0293 - val_loss: 0.0065 - val_mae: 0.0530\n",
      "Epoch 8/20\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 87ms/step - loss: 0.0016 - mae: 0.0294 - val_loss: 0.0059 - val_mae: 0.0515\n",
      "Epoch 9/20\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 88ms/step - loss: 0.0016 - mae: 0.0294 - val_loss: 0.0059 - val_mae: 0.0511\n",
      "Epoch 10/20\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 88ms/step - loss: 0.0016 - mae: 0.0294 - val_loss: 0.0089 - val_mae: 0.0613\n",
      "Epoch 11/20\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 87ms/step - loss: 0.0016 - mae: 0.0294 - val_loss: 0.0060 - val_mae: 0.0516\n",
      "Epoch 12/20\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 87ms/step - loss: 0.0016 - mae: 0.0293 - val_loss: 0.0061 - val_mae: 0.0519\n",
      "Epoch 13/20\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 87ms/step - loss: 0.0016 - mae: 0.0293 - val_loss: 0.0061 - val_mae: 0.0516\n",
      "Epoch 14/20\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 88ms/step - loss: 0.0016 - mae: 0.0293 - val_loss: 0.0063 - val_mae: 0.0525\n",
      "Epoch 15/20\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 87ms/step - loss: 0.0016 - mae: 0.0292 - val_loss: 0.0068 - val_mae: 0.0534\n",
      "Epoch 16/20\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 87ms/step - loss: 0.0016 - mae: 0.0293 - val_loss: 0.0061 - val_mae: 0.0516\n",
      "Epoch 17/20\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 82ms/step - loss: 0.0016 - mae: 0.0293 - val_loss: 0.0070 - val_mae: 0.0540\n",
      "Epoch 18/20\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 87ms/step - loss: 0.0016 - mae: 0.0292 - val_loss: 0.0065 - val_mae: 0.0525\n",
      "Epoch 19/20\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 89ms/step - loss: 0.0016 - mae: 0.0292 - val_loss: 0.0072 - val_mae: 0.0550\n",
      "Epoch 20/20\n",
      "\u001b[1m1476/1476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 87ms/step - loss: 0.0016 - mae: 0.0292 - val_loss: 0.0064 - val_mae: 0.0521\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 39ms/step\n",
      "✅ Done with tomato_Hassan_daily.csv | MAE=626.89, RMSE=960.24, R2=0.48, MAPE=31.8%, Accuracy=68.2%\n",
      "\n",
      "🚀 Processing: tomato_Haveri_daily.csv\n",
      "Epoch 1/20\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 79ms/step - loss: 0.0177 - mae: 0.0987 - val_loss: 8.2413e-04 - val_mae: 0.0220\n",
      "Epoch 2/20\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 62ms/step - loss: 0.0083 - mae: 0.0754 - val_loss: 0.0028 - val_mae: 0.0422\n",
      "Epoch 3/20\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 62ms/step - loss: 0.0082 - mae: 0.0751 - val_loss: 0.0025 - val_mae: 0.0369\n",
      "Epoch 4/20\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 61ms/step - loss: 0.0074 - mae: 0.0722 - val_loss: 0.0039 - val_mae: 0.0430\n",
      "Epoch 5/20\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 71ms/step - loss: 0.0068 - mae: 0.0683 - val_loss: 0.0034 - val_mae: 0.0462\n",
      "Epoch 6/20\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 68ms/step - loss: 0.0071 - mae: 0.0704 - val_loss: 0.0027 - val_mae: 0.0294\n",
      "Epoch 7/20\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 68ms/step - loss: 0.0062 - mae: 0.0654 - val_loss: 0.0046 - val_mae: 0.0444\n",
      "Epoch 8/20\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 58ms/step - loss: 0.0062 - mae: 0.0642 - val_loss: 0.0037 - val_mae: 0.0321\n",
      "Epoch 9/20\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 67ms/step - loss: 0.0060 - mae: 0.0621 - val_loss: 0.0044 - val_mae: 0.0345\n",
      "Epoch 10/20\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 65ms/step - loss: 0.0054 - mae: 0.0589 - val_loss: 0.0052 - val_mae: 0.0436\n",
      "Epoch 11/20\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 68ms/step - loss: 0.0057 - mae: 0.0595 - val_loss: 0.0056 - val_mae: 0.0447\n",
      "Epoch 12/20\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 63ms/step - loss: 0.0053 - mae: 0.0570 - val_loss: 0.0068 - val_mae: 0.0352\n",
      "Epoch 13/20\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - loss: 0.0052 - mae: 0.0564 - val_loss: 0.0073 - val_mae: 0.0527\n",
      "Epoch 14/20\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 60ms/step - loss: 0.0049 - mae: 0.0550 - val_loss: 0.0084 - val_mae: 0.0464\n",
      "Epoch 15/20\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - loss: 0.0050 - mae: 0.0548 - val_loss: 0.0100 - val_mae: 0.0520\n",
      "Epoch 16/20\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 59ms/step - loss: 0.0048 - mae: 0.0539 - val_loss: 0.0114 - val_mae: 0.0644\n",
      "Epoch 17/20\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 64ms/step - loss: 0.0046 - mae: 0.0530 - val_loss: 0.0119 - val_mae: 0.0581\n",
      "Epoch 18/20\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 65ms/step - loss: 0.0046 - mae: 0.0527 - val_loss: 0.0126 - val_mae: 0.0606\n",
      "Epoch 19/20\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 62ms/step - loss: 0.0047 - mae: 0.0532 - val_loss: 0.0189 - val_mae: 0.0767\n",
      "Epoch 20/20\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 60ms/step - loss: 0.0046 - mae: 0.0523 - val_loss: 0.0127 - val_mae: 0.0478\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step\n",
      "✅ Done with tomato_Haveri_daily.csv | MAE=397.7, RMSE=937.49, R2=0.93, MAPE=16.41%, Accuracy=83.59%\n",
      "\n",
      "🚀 Processing: tomato_Kalburgi_daily.csv\n",
      "Epoch 1/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 81ms/step - loss: 0.0160 - mae: 0.0834 - val_loss: 0.0021 - val_mae: 0.0372\n",
      "Epoch 2/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 60ms/step - loss: 0.0083 - mae: 0.0554 - val_loss: 0.0020 - val_mae: 0.0367\n",
      "Epoch 3/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - loss: 0.0078 - mae: 0.0538 - val_loss: 9.6333e-04 - val_mae: 0.0235\n",
      "Epoch 4/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - loss: 0.0075 - mae: 0.0533 - val_loss: 0.0010 - val_mae: 0.0236\n",
      "Epoch 5/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 59ms/step - loss: 0.0074 - mae: 0.0510 - val_loss: 0.0012 - val_mae: 0.0272\n",
      "Epoch 6/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - loss: 0.0071 - mae: 0.0506 - val_loss: 8.9233e-04 - val_mae: 0.0216\n",
      "Epoch 7/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - loss: 0.0070 - mae: 0.0500 - val_loss: 9.6649e-04 - val_mae: 0.0231\n",
      "Epoch 8/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - loss: 0.0064 - mae: 0.0470 - val_loss: 7.6314e-04 - val_mae: 0.0191\n",
      "Epoch 9/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 59ms/step - loss: 0.0063 - mae: 0.0463 - val_loss: 7.3069e-04 - val_mae: 0.0184\n",
      "Epoch 10/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 61ms/step - loss: 0.0061 - mae: 0.0451 - val_loss: 7.4091e-04 - val_mae: 0.0181\n",
      "Epoch 11/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 60ms/step - loss: 0.0066 - mae: 0.0467 - val_loss: 0.0011 - val_mae: 0.0262\n",
      "Epoch 12/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - loss: 0.0065 - mae: 0.0464 - val_loss: 7.2337e-04 - val_mae: 0.0190\n",
      "Epoch 13/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 64ms/step - loss: 0.0058 - mae: 0.0431 - val_loss: 7.4167e-04 - val_mae: 0.0191\n",
      "Epoch 14/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 61ms/step - loss: 0.0064 - mae: 0.0445 - val_loss: 7.6248e-04 - val_mae: 0.0197\n",
      "Epoch 15/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - loss: 0.0064 - mae: 0.0480 - val_loss: 7.3091e-04 - val_mae: 0.0190\n",
      "Epoch 16/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 58ms/step - loss: 0.0064 - mae: 0.0445 - val_loss: 7.4359e-04 - val_mae: 0.0192\n",
      "Epoch 17/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - loss: 0.0062 - mae: 0.0436 - val_loss: 7.1817e-04 - val_mae: 0.0189\n",
      "Epoch 18/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 60ms/step - loss: 0.0057 - mae: 0.0429 - val_loss: 8.5601e-04 - val_mae: 0.0222\n",
      "Epoch 19/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 61ms/step - loss: 0.0064 - mae: 0.0473 - val_loss: 6.5973e-04 - val_mae: 0.0172\n",
      "Epoch 20/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - loss: 0.0061 - mae: 0.0438 - val_loss: 0.0018 - val_mae: 0.0363\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 149ms/step\n",
      "✅ Done with tomato_Kalburgi_daily.csv | MAE=359.1, RMSE=414.22, R2=0.68, MAPE=29.28%, Accuracy=70.72%\n",
      "\n",
      "🚀 Processing: tomato_Kolar_daily.csv\n",
      "Epoch 1/20\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 48ms/step - loss: 0.0011 - mae: 0.0222 - val_loss: 0.0035 - val_mae: 0.0396\n",
      "Epoch 2/20\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 49ms/step - loss: 0.0010 - mae: 0.0212 - val_loss: 0.0037 - val_mae: 0.0393\n",
      "Epoch 3/20\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 48ms/step - loss: 0.0010 - mae: 0.0211 - val_loss: 0.0035 - val_mae: 0.0396\n",
      "Epoch 4/20\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 41ms/step - loss: 9.9211e-04 - mae: 0.0209 - val_loss: 0.0036 - val_mae: 0.0387\n",
      "Epoch 5/20\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 46ms/step - loss: 9.8614e-04 - mae: 0.0207 - val_loss: 0.0035 - val_mae: 0.0404\n",
      "Epoch 6/20\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 46ms/step - loss: 9.8230e-04 - mae: 0.0209 - val_loss: 0.0035 - val_mae: 0.0400\n",
      "Epoch 7/20\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 50ms/step - loss: 9.7486e-04 - mae: 0.0207 - val_loss: 0.0035 - val_mae: 0.0383\n",
      "Epoch 8/20\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 51ms/step - loss: 9.8204e-04 - mae: 0.0207 - val_loss: 0.0035 - val_mae: 0.0402\n",
      "Epoch 9/20\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 50ms/step - loss: 9.7323e-04 - mae: 0.0206 - val_loss: 0.0038 - val_mae: 0.0399\n",
      "Epoch 10/20\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 49ms/step - loss: 9.7070e-04 - mae: 0.0205 - val_loss: 0.0038 - val_mae: 0.0394\n",
      "Epoch 11/20\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 49ms/step - loss: 9.7664e-04 - mae: 0.0206 - val_loss: 0.0039 - val_mae: 0.0399\n",
      "Epoch 12/20\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 49ms/step - loss: 9.6705e-04 - mae: 0.0205 - val_loss: 0.0039 - val_mae: 0.0394\n",
      "Epoch 13/20\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 50ms/step - loss: 9.7003e-04 - mae: 0.0206 - val_loss: 0.0037 - val_mae: 0.0400\n",
      "Epoch 14/20\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 48ms/step - loss: 9.6965e-04 - mae: 0.0206 - val_loss: 0.0036 - val_mae: 0.0390\n",
      "Epoch 15/20\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 50ms/step - loss: 9.6596e-04 - mae: 0.0205 - val_loss: 0.0036 - val_mae: 0.0417\n",
      "Epoch 16/20\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 50ms/step - loss: 9.6884e-04 - mae: 0.0205 - val_loss: 0.0038 - val_mae: 0.0395\n",
      "Epoch 17/20\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 50ms/step - loss: 9.7210e-04 - mae: 0.0205 - val_loss: 0.0036 - val_mae: 0.0416\n",
      "Epoch 18/20\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 50ms/step - loss: 9.6278e-04 - mae: 0.0204 - val_loss: 0.0039 - val_mae: 0.0404\n",
      "Epoch 19/20\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 50ms/step - loss: 9.6046e-04 - mae: 0.0204 - val_loss: 0.0039 - val_mae: 0.0403\n",
      "Epoch 20/20\n",
      "\u001b[1m2092/2092\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 50ms/step - loss: 9.6499e-04 - mae: 0.0205 - val_loss: 0.0038 - val_mae: 0.0398\n",
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step\n",
      "✅ Done with tomato_Kolar_daily.csv | MAE=453.13, RMSE=703.23, R2=0.7, MAPE=30.49%, Accuracy=69.51%\n",
      "\n",
      "🚀 Processing: tomato_MadikeriKodagu_daily.csv\n",
      "Epoch 1/20\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 38ms/step - loss: 0.0460 - mae: 0.1643 - val_loss: 4.8033e-04 - val_mae: 0.0115\n",
      "Epoch 2/20\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 32ms/step - loss: 0.0338 - mae: 0.1319 - val_loss: 0.0023 - val_mae: 0.0405\n",
      "Epoch 3/20\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - loss: 0.0304 - mae: 0.1224 - val_loss: 0.0034 - val_mae: 0.0431\n",
      "Epoch 4/20\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - loss: 0.0296 - mae: 0.1205 - val_loss: 0.0083 - val_mae: 0.0812\n",
      "Epoch 5/20\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - loss: 0.0280 - mae: 0.1150 - val_loss: 0.0066 - val_mae: 0.0435\n",
      "Epoch 6/20\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - loss: 0.0269 - mae: 0.1121 - val_loss: 0.0078 - val_mae: 0.0490\n",
      "Epoch 7/20\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - loss: 0.0269 - mae: 0.1133 - val_loss: 0.0099 - val_mae: 0.0609\n",
      "Epoch 8/20\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - loss: 0.0270 - mae: 0.1121 - val_loss: 0.0062 - val_mae: 0.0210\n",
      "Epoch 9/20\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - loss: 0.0270 - mae: 0.1106 - val_loss: 0.0080 - val_mae: 0.0444\n",
      "Epoch 10/20\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - loss: 0.0271 - mae: 0.1126 - val_loss: 0.0062 - val_mae: 0.0350\n",
      "Epoch 11/20\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - loss: 0.0271 - mae: 0.1117 - val_loss: 0.0091 - val_mae: 0.0447\n",
      "Epoch 12/20\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - loss: 0.0263 - mae: 0.1111 - val_loss: 0.0168 - val_mae: 0.0753\n",
      "Epoch 13/20\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - loss: 0.0261 - mae: 0.1095 - val_loss: 0.0084 - val_mae: 0.0571\n",
      "Epoch 14/20\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - loss: 0.0261 - mae: 0.1095 - val_loss: 0.0089 - val_mae: 0.0354\n",
      "Epoch 15/20\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - loss: 0.0261 - mae: 0.1086 - val_loss: 0.0126 - val_mae: 0.0439\n",
      "Epoch 16/20\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 32ms/step - loss: 0.0259 - mae: 0.1082 - val_loss: 0.0111 - val_mae: 0.0329\n",
      "Epoch 17/20\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - loss: 0.0261 - mae: 0.1090 - val_loss: 0.0143 - val_mae: 0.0465\n",
      "Epoch 18/20\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - loss: 0.0256 - mae: 0.1067 - val_loss: 0.0158 - val_mae: 0.0322\n",
      "Epoch 19/20\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - loss: 0.0263 - mae: 0.1102 - val_loss: 0.0161 - val_mae: 0.0265\n",
      "Epoch 20/20\n",
      "\u001b[1m253/253\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - loss: 0.0255 - mae: 0.1066 - val_loss: 0.0196 - val_mae: 0.0389\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step  \n",
      "✅ Done with tomato_MadikeriKodagu_daily.csv | MAE=66.07, RMSE=237.8, R2=-1.56, MAPE=5.6%, Accuracy=94.4%\n",
      "\n",
      "🚀 Processing: tomato_Mandya_daily.csv\n",
      "Epoch 1/20\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 30ms/step - loss: 0.0015 - mae: 0.0260 - val_loss: 0.0053 - val_mae: 0.0460\n",
      "Epoch 2/20\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 29ms/step - loss: 0.0014 - mae: 0.0247 - val_loss: 0.0067 - val_mae: 0.0494\n",
      "Epoch 3/20\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 29ms/step - loss: 0.0014 - mae: 0.0243 - val_loss: 0.0080 - val_mae: 0.0513\n",
      "Epoch 4/20\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 30ms/step - loss: 0.0013 - mae: 0.0238 - val_loss: 0.0191 - val_mae: 0.0700\n",
      "Epoch 5/20\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 29ms/step - loss: 0.0013 - mae: 0.0235 - val_loss: 0.0227 - val_mae: 0.0711\n",
      "Epoch 6/20\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 30ms/step - loss: 0.0013 - mae: 0.0232 - val_loss: 0.0181 - val_mae: 0.0653\n",
      "Epoch 7/20\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 29ms/step - loss: 0.0013 - mae: 0.0232 - val_loss: 0.0201 - val_mae: 0.0675\n",
      "Epoch 8/20\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 30ms/step - loss: 0.0013 - mae: 0.0231 - val_loss: 0.0191 - val_mae: 0.0677\n",
      "Epoch 9/20\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 29ms/step - loss: 0.0012 - mae: 0.0228 - val_loss: 0.0181 - val_mae: 0.0665\n",
      "Epoch 10/20\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 29ms/step - loss: 0.0012 - mae: 0.0226 - val_loss: 0.0198 - val_mae: 0.0699\n",
      "Epoch 11/20\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 29ms/step - loss: 0.0012 - mae: 0.0226 - val_loss: 0.0189 - val_mae: 0.0700\n",
      "Epoch 12/20\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 29ms/step - loss: 0.0012 - mae: 0.0227 - val_loss: 0.0184 - val_mae: 0.0682\n",
      "Epoch 13/20\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 29ms/step - loss: 0.0012 - mae: 0.0225 - val_loss: 0.0175 - val_mae: 0.0676\n",
      "Epoch 14/20\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 30ms/step - loss: 0.0012 - mae: 0.0226 - val_loss: 0.0206 - val_mae: 0.0732\n",
      "Epoch 15/20\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 29ms/step - loss: 0.0012 - mae: 0.0223 - val_loss: 0.0173 - val_mae: 0.0671\n",
      "Epoch 16/20\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 29ms/step - loss: 0.0012 - mae: 0.0223 - val_loss: 0.0174 - val_mae: 0.0680\n",
      "Epoch 17/20\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 29ms/step - loss: 0.0012 - mae: 0.0222 - val_loss: 0.0176 - val_mae: 0.0686\n",
      "Epoch 18/20\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 29ms/step - loss: 0.0012 - mae: 0.0223 - val_loss: 0.0186 - val_mae: 0.0717\n",
      "Epoch 19/20\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 28ms/step - loss: 0.0012 - mae: 0.0223 - val_loss: 0.0143 - val_mae: 0.0629\n",
      "Epoch 20/20\n",
      "\u001b[1m872/872\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 29ms/step - loss: 0.0012 - mae: 0.0222 - val_loss: 0.0154 - val_mae: 0.0648\n",
      "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step   \n",
      "✅ Done with tomato_Mandya_daily.csv | MAE=806.72, RMSE=1543.01, R2=-0.04, MAPE=45.1%, Accuracy=54.9%\n",
      "\n",
      "🚀 Processing: tomato_Mysore_daily.csv\n",
      "Epoch 1/20\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 30ms/step - loss: 0.0016 - mae: 0.0267 - val_loss: 0.0039 - val_mae: 0.0421\n",
      "Epoch 2/20\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 29ms/step - loss: 0.0014 - mae: 0.0252 - val_loss: 0.0036 - val_mae: 0.0423\n",
      "Epoch 3/20\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 28ms/step - loss: 0.0014 - mae: 0.0250 - val_loss: 0.0035 - val_mae: 0.0405\n",
      "Epoch 4/20\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 28ms/step - loss: 0.0014 - mae: 0.0247 - val_loss: 0.0036 - val_mae: 0.0419\n",
      "Epoch 5/20\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 28ms/step - loss: 0.0014 - mae: 0.0248 - val_loss: 0.0035 - val_mae: 0.0410\n",
      "Epoch 6/20\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 29ms/step - loss: 0.0014 - mae: 0.0245 - val_loss: 0.0035 - val_mae: 0.0412\n",
      "Epoch 7/20\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 29ms/step - loss: 0.0014 - mae: 0.0245 - val_loss: 0.0035 - val_mae: 0.0414\n",
      "Epoch 8/20\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 29ms/step - loss: 0.0014 - mae: 0.0245 - val_loss: 0.0037 - val_mae: 0.0427\n",
      "Epoch 9/20\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 29ms/step - loss: 0.0014 - mae: 0.0245 - val_loss: 0.0036 - val_mae: 0.0403\n",
      "Epoch 10/20\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 28ms/step - loss: 0.0014 - mae: 0.0244 - val_loss: 0.0035 - val_mae: 0.0402\n",
      "Epoch 11/20\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 28ms/step - loss: 0.0014 - mae: 0.0244 - val_loss: 0.0035 - val_mae: 0.0405\n",
      "Epoch 12/20\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 28ms/step - loss: 0.0014 - mae: 0.0243 - val_loss: 0.0036 - val_mae: 0.0410\n",
      "Epoch 13/20\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 29ms/step - loss: 0.0013 - mae: 0.0243 - val_loss: 0.0038 - val_mae: 0.0408\n",
      "Epoch 14/20\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 29ms/step - loss: 0.0014 - mae: 0.0243 - val_loss: 0.0035 - val_mae: 0.0409\n",
      "Epoch 15/20\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 29ms/step - loss: 0.0013 - mae: 0.0242 - val_loss: 0.0035 - val_mae: 0.0408\n",
      "Epoch 16/20\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 28ms/step - loss: 0.0013 - mae: 0.0241 - val_loss: 0.0039 - val_mae: 0.0434\n",
      "Epoch 17/20\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 28ms/step - loss: 0.0013 - mae: 0.0243 - val_loss: 0.0037 - val_mae: 0.0414\n",
      "Epoch 18/20\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 28ms/step - loss: 0.0013 - mae: 0.0242 - val_loss: 0.0037 - val_mae: 0.0406\n",
      "Epoch 19/20\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 28ms/step - loss: 0.0013 - mae: 0.0241 - val_loss: 0.0035 - val_mae: 0.0408\n",
      "Epoch 20/20\n",
      "\u001b[1m1367/1367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 29ms/step - loss: 0.0013 - mae: 0.0242 - val_loss: 0.0036 - val_mae: 0.0401\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step\n",
      "✅ Done with tomato_Mysore_daily.csv | MAE=607.32, RMSE=908.52, R2=0.31, MAPE=36.15%, Accuracy=63.85%\n",
      "\n",
      "🚀 Processing: tomato_Shimoga_daily.csv\n",
      "Epoch 1/20\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 31ms/step - loss: 9.8838e-04 - mae: 0.0202 - val_loss: 0.0021 - val_mae: 0.0239\n",
      "Epoch 2/20\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 27ms/step - loss: 7.4567e-04 - mae: 0.0168 - val_loss: 0.0029 - val_mae: 0.0295\n",
      "Epoch 3/20\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 28ms/step - loss: 7.2192e-04 - mae: 0.0162 - val_loss: 0.0029 - val_mae: 0.0293\n",
      "Epoch 4/20\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 27ms/step - loss: 7.1789e-04 - mae: 0.0165 - val_loss: 0.0038 - val_mae: 0.0349\n",
      "Epoch 5/20\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 28ms/step - loss: 6.8221e-04 - mae: 0.0157 - val_loss: 0.0057 - val_mae: 0.0446\n",
      "Epoch 6/20\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 28ms/step - loss: 6.4925e-04 - mae: 0.0153 - val_loss: 0.0053 - val_mae: 0.0411\n",
      "Epoch 7/20\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 28ms/step - loss: 6.6488e-04 - mae: 0.0155 - val_loss: 0.0045 - val_mae: 0.0377\n",
      "Epoch 8/20\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - loss: 6.5182e-04 - mae: 0.0152 - val_loss: 0.0049 - val_mae: 0.0391\n",
      "Epoch 9/20\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 28ms/step - loss: 6.4562e-04 - mae: 0.0152 - val_loss: 0.0061 - val_mae: 0.0439\n",
      "Epoch 10/20\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - loss: 6.3205e-04 - mae: 0.0150 - val_loss: 0.0052 - val_mae: 0.0408\n",
      "Epoch 11/20\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 28ms/step - loss: 6.4380e-04 - mae: 0.0152 - val_loss: 0.0057 - val_mae: 0.0418\n",
      "Epoch 12/20\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 28ms/step - loss: 6.2620e-04 - mae: 0.0148 - val_loss: 0.0061 - val_mae: 0.0431\n",
      "Epoch 13/20\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 28ms/step - loss: 6.3952e-04 - mae: 0.0151 - val_loss: 0.0061 - val_mae: 0.0430\n",
      "Epoch 14/20\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 28ms/step - loss: 6.3498e-04 - mae: 0.0149 - val_loss: 0.0078 - val_mae: 0.0486\n",
      "Epoch 15/20\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 28ms/step - loss: 6.2502e-04 - mae: 0.0146 - val_loss: 0.0074 - val_mae: 0.0473\n",
      "Epoch 16/20\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 28ms/step - loss: 6.1553e-04 - mae: 0.0148 - val_loss: 0.0072 - val_mae: 0.0462\n",
      "Epoch 17/20\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 28ms/step - loss: 6.1162e-04 - mae: 0.0144 - val_loss: 0.0114 - val_mae: 0.0593\n",
      "Epoch 18/20\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 28ms/step - loss: 6.1473e-04 - mae: 0.0147 - val_loss: 0.0084 - val_mae: 0.0495\n",
      "Epoch 19/20\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 28ms/step - loss: 6.2324e-04 - mae: 0.0148 - val_loss: 0.0091 - val_mae: 0.0521\n",
      "Epoch 20/20\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 27ms/step - loss: 6.0380e-04 - mae: 0.0144 - val_loss: 0.0099 - val_mae: 0.0542\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step  \n",
      "✅ Done with tomato_Shimoga_daily.csv | MAE=948.51, RMSE=1738.75, R2=-0.31, MAPE=142.91%, Accuracy=-42.91%\n",
      "\n",
      "🚀 Processing: tomato_Tumkur_daily.csv\n",
      "Epoch 1/20\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 31ms/step - loss: 2.3968e-04 - mae: 0.0099 - val_loss: 6.8663e-04 - val_mae: 0.0141\n",
      "Epoch 2/20\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - loss: 1.8148e-04 - mae: 0.0086 - val_loss: 4.4383e-04 - val_mae: 0.0073\n",
      "Epoch 3/20\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - loss: 1.5543e-04 - mae: 0.0075 - val_loss: 3.9030e-04 - val_mae: 0.0065\n",
      "Epoch 4/20\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - loss: 1.4949e-04 - mae: 0.0074 - val_loss: 3.6463e-04 - val_mae: 0.0058\n",
      "Epoch 5/20\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - loss: 1.5252e-04 - mae: 0.0075 - val_loss: 3.9197e-04 - val_mae: 0.0089\n",
      "Epoch 6/20\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - loss: 1.5502e-04 - mae: 0.0078 - val_loss: 8.4449e-04 - val_mae: 0.0212\n",
      "Epoch 7/20\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - loss: 1.4298e-04 - mae: 0.0070 - val_loss: 3.3418e-04 - val_mae: 0.0053\n",
      "Epoch 8/20\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - loss: 1.4197e-04 - mae: 0.0072 - val_loss: 0.0013 - val_mae: 0.0268\n",
      "Epoch 9/20\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - loss: 1.3638e-04 - mae: 0.0068 - val_loss: 0.0017 - val_mae: 0.0338\n",
      "Epoch 10/20\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - loss: 1.4949e-04 - mae: 0.0075 - val_loss: 3.5159e-04 - val_mae: 0.0090\n",
      "Epoch 11/20\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - loss: 1.3756e-04 - mae: 0.0068 - val_loss: 3.5178e-04 - val_mae: 0.0088\n",
      "Epoch 12/20\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - loss: 1.3778e-04 - mae: 0.0069 - val_loss: 3.1599e-04 - val_mae: 0.0062\n",
      "Epoch 13/20\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - loss: 1.3580e-04 - mae: 0.0070 - val_loss: 3.1439e-04 - val_mae: 0.0069\n",
      "Epoch 14/20\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - loss: 1.3449e-04 - mae: 0.0068 - val_loss: 9.8343e-04 - val_mae: 0.0228\n",
      "Epoch 15/20\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - loss: 1.4063e-04 - mae: 0.0068 - val_loss: 6.1511e-04 - val_mae: 0.0174\n",
      "Epoch 16/20\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - loss: 1.4181e-04 - mae: 0.0072 - val_loss: 0.0012 - val_mae: 0.0261\n",
      "Epoch 17/20\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - loss: 1.4036e-04 - mae: 0.0069 - val_loss: 3.2860e-04 - val_mae: 0.0099\n",
      "Epoch 18/20\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - loss: 1.3084e-04 - mae: 0.0066 - val_loss: 0.0013 - val_mae: 0.0277\n",
      "Epoch 19/20\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - loss: 1.2543e-04 - mae: 0.0064 - val_loss: 2.4836e-04 - val_mae: 0.0049\n",
      "Epoch 20/20\n",
      "\u001b[1m276/276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - loss: 1.2927e-04 - mae: 0.0064 - val_loss: 2.7044e-04 - val_mae: 0.0076\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step  \n",
      "✅ Done with tomato_Tumkur_daily.csv | MAE=85.59, RMSE=185.83, R2=0.99, MAPE=3.89%, Accuracy=96.11%\n",
      "\n",
      "🚀 Processing: tomato_Udupi_daily.csv\n",
      "Epoch 1/20\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 29ms/step - loss: 0.0013 - mae: 0.0229 - val_loss: 0.0029 - val_mae: 0.0316\n",
      "Epoch 2/20\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - loss: 6.1640e-04 - mae: 0.0174 - val_loss: 0.0026 - val_mae: 0.0317\n",
      "Epoch 3/20\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - loss: 6.0068e-04 - mae: 0.0172 - val_loss: 0.0019 - val_mae: 0.0210\n",
      "Epoch 4/20\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - loss: 5.0328e-04 - mae: 0.0158 - val_loss: 0.0019 - val_mae: 0.0203\n",
      "Epoch 5/20\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - loss: 4.7520e-04 - mae: 0.0153 - val_loss: 0.0021 - val_mae: 0.0247\n",
      "Epoch 6/20\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - loss: 4.7426e-04 - mae: 0.0153 - val_loss: 0.0023 - val_mae: 0.0291\n",
      "Epoch 7/20\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - loss: 5.0023e-04 - mae: 0.0157 - val_loss: 0.0025 - val_mae: 0.0291\n",
      "Epoch 8/20\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - loss: 4.5900e-04 - mae: 0.0149 - val_loss: 0.0023 - val_mae: 0.0258\n",
      "Epoch 9/20\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 4.4044e-04 - mae: 0.0146 - val_loss: 0.0027 - val_mae: 0.0287\n",
      "Epoch 10/20\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - loss: 4.4732e-04 - mae: 0.0147 - val_loss: 0.0024 - val_mae: 0.0256\n",
      "Epoch 11/20\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - loss: 4.2616e-04 - mae: 0.0143 - val_loss: 0.0025 - val_mae: 0.0271\n",
      "Epoch 12/20\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 4.5305e-04 - mae: 0.0149 - val_loss: 0.0024 - val_mae: 0.0260\n",
      "Epoch 13/20\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - loss: 4.2720e-04 - mae: 0.0144 - val_loss: 0.0025 - val_mae: 0.0285\n",
      "Epoch 14/20\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 4.1789e-04 - mae: 0.0141 - val_loss: 0.0024 - val_mae: 0.0266\n",
      "Epoch 15/20\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 4.0253e-04 - mae: 0.0141 - val_loss: 0.0028 - val_mae: 0.0300\n",
      "Epoch 16/20\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 4.0808e-04 - mae: 0.0139 - val_loss: 0.0026 - val_mae: 0.0260\n",
      "Epoch 17/20\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - loss: 4.0454e-04 - mae: 0.0139 - val_loss: 0.0029 - val_mae: 0.0285\n",
      "Epoch 18/20\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 3.8131e-04 - mae: 0.0134 - val_loss: 0.0028 - val_mae: 0.0261\n",
      "Epoch 19/20\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 4.0840e-04 - mae: 0.0143 - val_loss: 0.0028 - val_mae: 0.0268\n",
      "Epoch 20/20\n",
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - loss: 3.9722e-04 - mae: 0.0138 - val_loss: 0.0030 - val_mae: 0.0292\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step  \n",
      "✅ Done with tomato_Udupi_daily.csv | MAE=278.58, RMSE=519.9, R2=0.93, MAPE=10.03%, Accuracy=89.97%\n",
      "\n",
      "📊 Metrics saved to gru_output_csv\\gru_metrics.csv\n",
      "\n",
      "✅ All districts processed successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import joblib\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Dense, Dropout\n",
    "\n",
    "# -----------------------------\n",
    "# Output paths\n",
    "# -----------------------------\n",
    "input_folder = \"dataset\"\n",
    "output_models = \"gru_output_models\"\n",
    "output_csv = \"gru_output_csv\"\n",
    "output_graphs = \"gru_output_graphs\"\n",
    "output_logs = \"gru_output_logs\"\n",
    "metrics_file = os.path.join(output_csv, \"gru_metrics.csv\")\n",
    "\n",
    "os.makedirs(output_models, exist_ok=True)\n",
    "os.makedirs(output_csv, exist_ok=True)\n",
    "os.makedirs(output_graphs, exist_ok=True)\n",
    "os.makedirs(output_logs, exist_ok=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Function to create dataset\n",
    "# -----------------------------\n",
    "def create_dataset(data, look_back=30):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - look_back):\n",
    "        X.append(data[i:i + look_back, 0])\n",
    "        y.append(data[i + look_back, 0])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# -----------------------------\n",
    "# Metrics storage\n",
    "# -----------------------------\n",
    "metrics_list = []\n",
    "\n",
    "# -----------------------------\n",
    "# Process each CSV file\n",
    "# -----------------------------\n",
    "look_back = 30\n",
    "for file in os.listdir(input_folder):\n",
    "    if file.endswith(\".csv\"):\n",
    "        district_name = file.split(\".\")[0]\n",
    "        print(f\"\\n🚀 Processing: {file}\")\n",
    "\n",
    "        df = pd.read_csv(os.path.join(input_folder, file))\n",
    "\n",
    "        df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "        df = df.dropna(subset=['Date'])\n",
    "        df = df.sort_values('Date')\n",
    "\n",
    "        df['Average Price'] = df['Average Price'].fillna(df['Average Price'].mean())\n",
    "\n",
    "        df['MA_7'] = df['Average Price'].rolling(window=7).mean().fillna(df['Average Price'].mean())\n",
    "        df['MA_30'] = df['Average Price'].rolling(window=30).mean().fillna(df['Average Price'].mean())\n",
    "\n",
    "        values = df[['Average Price']].values\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        scaled_values = scaler.fit_transform(values)\n",
    "\n",
    "        X, y = create_dataset(scaled_values, look_back)\n",
    "        X = X.reshape((X.shape[0], X.shape[1], 1))\n",
    "\n",
    "        split = int(len(X) * 0.8)\n",
    "        X_train, X_test = X[:split], X[split:]\n",
    "        y_train, y_test = y[:split], y[split:]\n",
    "\n",
    "        model = Sequential([\n",
    "            GRU(64, return_sequences=True, input_shape=(look_back, 1)),\n",
    "            Dropout(0.2),\n",
    "            GRU(32),\n",
    "            Dropout(0.2),\n",
    "            Dense(1)\n",
    "        ])\n",
    "        model.compile(optimizer=\"adam\", loss=\"mse\", metrics=['mae'])\n",
    "\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            epochs=20,\n",
    "            batch_size=16,\n",
    "            validation_data=(X_test, y_test),\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        # Save training log\n",
    "        log_file = os.path.join(output_logs, f\"{district_name}_gru_training.txt\")\n",
    "        with open(log_file, \"w\") as f:\n",
    "            f.write(\"Epoch\\tTrain_Loss\\tVal_Loss\\n\")\n",
    "            for i, (loss, val_loss) in enumerate(zip(history.history['loss'], history.history['val_loss'])):\n",
    "                f.write(f\"{i+1}\\t{loss:.6f}\\t{val_loss:.6f}\\n\")\n",
    "\n",
    "        # Predictions\n",
    "        y_pred_scaled = model.predict(X_test)\n",
    "        y_pred = scaler.inverse_transform(y_pred_scaled)\n",
    "        y_true = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "        y_true_round = np.round(y_true, 2)\n",
    "        y_pred_round = np.round(y_pred, 2)\n",
    "\n",
    "        df_pred = df.iloc[-len(y_true):].copy()\n",
    "        df_pred = df_pred[['Date']].reset_index(drop=True)\n",
    "        df_pred['Actual'] = y_true_round.flatten()\n",
    "        df_pred['Predicted'] = y_pred_round.flatten()\n",
    "        df_pred.to_csv(os.path.join(output_csv, f\"{district_name}_gru_updated.csv\"), index=False)\n",
    "\n",
    "        # -----------------------------\n",
    "        # FIXED METRICS (NO ERROR)\n",
    "        # -----------------------------\n",
    "        mae_val = round(mean_absolute_error(y_true, y_pred), 2)\n",
    "        rmse_val = round(np.sqrt(mean_squared_error(y_true, y_pred)), 2)  # FIXED\n",
    "        r2_val = round(r2_score(y_true, y_pred), 2)\n",
    "        mape_val = round(np.mean(np.abs((y_true - y_pred) / y_true)) * 100, 2)\n",
    "        accuracy_val = round(100 - mape_val, 2)\n",
    "\n",
    "        metrics_list.append([district_name, mae_val, rmse_val, r2_val, mape_val, accuracy_val])\n",
    "\n",
    "        print(\n",
    "            f\"✅ Done with {file} | \"\n",
    "            f\"MAE={mae_val}, RMSE={rmse_val}, R2={r2_val}, \"\n",
    "            f\"MAPE={mape_val}%, Accuracy={accuracy_val}%\"\n",
    "        )\n",
    "\n",
    "        # Save model\n",
    "        model_file = os.path.join(output_models, f\"{district_name}_gru_model.pkl\")\n",
    "        joblib.dump(model, model_file)\n",
    "\n",
    "        # Graphs\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(df['Date'], df['Average Price'], label=\"Actual\", color=\"blue\")\n",
    "        plt.plot(df['Date'], df['MA_7'], label=\"MA_7\", color=\"orange\")\n",
    "        plt.plot(df['Date'], df['MA_30'], label=\"MA_30\", color=\"green\")\n",
    "        plt.plot(df_pred['Date'], df_pred['Predicted'], label=\"Predicted (GRU)\", color=\"red\", linestyle=\"dashed\")\n",
    "        plt.xlabel(\"Date\")\n",
    "        plt.ylabel(\"Average Price\")\n",
    "        plt.title(f\"GRU Predictions - {district_name}\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.savefig(os.path.join(output_graphs, f\"{district_name}_gru_graph.png\"))\n",
    "        plt.close()\n",
    "\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        plt.plot(history.history['loss'], label='Train Loss')\n",
    "        plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "        plt.title(f\"GRU Training Loss - {district_name}\")\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        plt.savefig(os.path.join(output_graphs, f\"{district_name}_gru_loss.png\"))\n",
    "        plt.close()\n",
    "\n",
    "# Save metrics CSV\n",
    "metrics_df = pd.DataFrame(\n",
    "    metrics_list,\n",
    "    columns=['District', 'MAE', 'RMSE', 'R2', 'MAPE(%)', 'Accuracy(%)']\n",
    ")\n",
    "metrics_df.to_csv(metrics_file, index=False)\n",
    "\n",
    "print(\"\\n📊 Metrics saved to\", metrics_file)\n",
    "print(\"\\n✅ All districts processed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7280145-ae59-4988-9d9c-e17652cb5c29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
